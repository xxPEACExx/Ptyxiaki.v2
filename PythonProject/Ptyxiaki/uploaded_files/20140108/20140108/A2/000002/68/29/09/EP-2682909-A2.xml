<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2682909-A2" country="EP" doc-number="2682909" kind="A2" date="20140108" family-id="45613787" file-reference-id="256401" date-produced="20180824" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="146584843" ucid="EP-2682909-A2"><document-id><country>EP</country><doc-number>2682909</doc-number><kind>A2</kind><date>20140108</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-11860625-A" is-representative="NO"><document-id mxw-id="PAPP154847035" load-source="docdb" format="epo"><country>EP</country><doc-number>11860625</doc-number><kind>A</kind><date>20111230</date><lang>KO</lang></document-id><document-id mxw-id="PAPP196399978" load-source="docdb" format="original"><country>EP</country><doc-number>11860625.0</doc-number><date>20111230</date></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC140555636" ucid="KR-20110019570-A" load-source="docdb"><document-id format="epo"><country>KR</country><doc-number>20110019570</doc-number><kind>A</kind><date>20110304</date></document-id></priority-claim><priority-claim mxw-id="PPC140553963" ucid="KR-2011010388-W" linkage-type="W" load-source="docdb"><document-id format="epo"><country>KR</country><doc-number>2011010388</doc-number><kind>W</kind><date>20111230</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL2100279051" load-source="docdb">G06Q  30/02        20120101AFI20140717BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-2077476321" load-source="docdb" scheme="CPC">G06Q  30/02        20130101 LI20150408BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2077479599" load-source="docdb" scheme="CPC">G06Q  30/0207      20130101 LI20150408BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989621051" load-source="docdb" scheme="CPC">G06K   9/18        20130101 FI20130801BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT132359162" lang="DE" load-source="patent-office">VERFAHREN ZUR UNTERSTÜTZUNG MEHRERER BENUTZER ZUR GLEICHZEITIGEN DURCHFÜHRUNG VON ERHEBUNGEN, SERVER UND COMPUTERLESBARES AUFZEICHNUNGSMEDIUM</invention-title><invention-title mxw-id="PT132359163" lang="EN" load-source="patent-office">METHOD FOR SUPPORTING A PLURALITY OF USERS TO SIMULTANEOUSLY PERFORM COLLECTION, SERVER, AND COMPUTER READABLE RECORDING MEDIUM</invention-title><invention-title mxw-id="PT132359164" lang="FR" load-source="patent-office">PROCÉDÉ POUR SUPPORTER QU'UNE PLURALITÉ D'UTILISATEURS RÉALISENT SIMULTANÉMENT UNE COLLECTION, SERVEUR ET SUPPORT D'ENREGISTREMENT LISIBLE PAR ORDINATEUR</invention-title></technical-data><parties><applicants><applicant mxw-id="PPAR919517683" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>INTEL CORP</last-name><address><country>US</country></address></addressbook></applicant><applicant mxw-id="PPAR919546139" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>INTEL CORPORATION</last-name></addressbook></applicant><applicant mxw-id="PPAR919018443" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Intel Corporation</last-name><iid>101072220</iid><address><street>2200 Mission College Boulevard</street><city>Santa Clara, CA 95054</city><country>US</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR919537103" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>RYU JUNG HEE</last-name><address><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR919520311" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>RYU, JUNG HEE</last-name></addressbook></inventor><inventor mxw-id="PPAR919017506" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>RYU, JUNG HEE</last-name><address><street>224-301 Jugong Apt. Dunchon 1-dong Gangdong-gu</street><city>Seoul 134-772</city><country>KR</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR919015681" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Goddar, Heinz J.</last-name><iid>100002032</iid><address><street>Boehmert &amp; Boehmert Pettenkoferstrasse 20-22</street><city>80336 München</city><country>DE</country></address></addressbook></agent></agents></parties><international-convention-data><pct-or-regional-filing-data ucid="KR-2011010388-W"><document-id><country>KR</country><doc-number>2011010388</doc-number><kind>W</kind><date>20111230</date><lang>KO</lang></document-id></pct-or-regional-filing-data><pct-or-regional-publishing-data ucid="WO-2012121480-A2"><document-id><country>WO</country><doc-number>2012121480</doc-number><kind>A2</kind><date>20120913</date><lang>KO</lang></document-id></pct-or-regional-publishing-data><designated-states><ep-contracting-states><country mxw-id="DS549738205" load-source="docdb">AL</country><country mxw-id="DS549739045" load-source="docdb">AT</country><country mxw-id="DS549738206" load-source="docdb">BE</country><country mxw-id="DS549739872" load-source="docdb">BG</country><country mxw-id="DS549741445" load-source="docdb">CH</country><country mxw-id="DS549811997" load-source="docdb">CY</country><country mxw-id="DS549739046" load-source="docdb">CZ</country><country mxw-id="DS549907245" load-source="docdb">DE</country><country mxw-id="DS549738207" load-source="docdb">DK</country><country mxw-id="DS549812010" load-source="docdb">EE</country><country mxw-id="DS549739220" load-source="docdb">ES</country><country mxw-id="DS549739873" load-source="docdb">FI</country><country mxw-id="DS549739874" load-source="docdb">FR</country><country mxw-id="DS549738208" load-source="docdb">GB</country><country mxw-id="DS549738209" load-source="docdb">GR</country><country mxw-id="DS549738210" load-source="docdb">HR</country><country mxw-id="DS549812011" load-source="docdb">HU</country><country mxw-id="DS549741446" load-source="docdb">IE</country><country mxw-id="DS549738211" load-source="docdb">IS</country><country mxw-id="DS549739875" load-source="docdb">IT</country><country mxw-id="DS549812012" load-source="docdb">LI</country><country mxw-id="DS549907246" load-source="docdb">LT</country><country mxw-id="DS549739047" load-source="docdb">LU</country><country mxw-id="DS549907247" load-source="docdb">LV</country><country mxw-id="DS549907248" load-source="docdb">MC</country><country mxw-id="DS549741078" load-source="docdb">MK</country><country mxw-id="DS549741079" load-source="docdb">MT</country><country mxw-id="DS549739221" load-source="docdb">NL</country><country mxw-id="DS549739876" load-source="docdb">NO</country><country mxw-id="DS549739222" load-source="docdb">PL</country><country mxw-id="DS549739877" load-source="docdb">PT</country><country mxw-id="DS549739223" load-source="docdb">RO</country><country mxw-id="DS549739878" load-source="docdb">RS</country><country mxw-id="DS549739224" load-source="docdb">SE</country><country mxw-id="DS549741447" load-source="docdb">SI</country><country mxw-id="DS549741080" load-source="docdb">SK</country><country mxw-id="DS549741081" load-source="docdb">SM</country><country mxw-id="DS549812013" load-source="docdb">TR</country></ep-contracting-states></designated-states></international-convention-data></bibliographic-data><abstract mxw-id="PA128673015" lang="EN" load-source="patent-office"><p id="pa01" num="0001">According to the present invention, it provides a method for assisting multiple users to simultaneously perform a collection comprising of (a) a step in which it is determined whether each piece of digital data generated for an object in an input image is generated under preset place conditions with reference to information observed by a position recognition module of each terminal device, and determined whether each piece of digital data is generated under preset time conditions with reference to information obtained by a time recognition module of each terminal device; (b) a step in which digital data are generated under the preset place conditions, and a specific user group is selected under the predetermined time conditions; and (c) a step in which reward information is provided to the specific user group.<img id="iaf01" file="imgaf001.tif" wi="120" he="76" img-content="drawing" img-format="tif"/></p></abstract><abstract mxw-id="PA128737160" lang="EN" source="EPO" load-source="docdb"><p>According to the present invention, it provides a method for assisting multiple users to simultaneously perform a collection comprising of (a) a step in which it is determined whether each piece of digital data generated for an object in an input image is generated under preset place conditions with reference to information observed by a position recognition module of each terminal device, and determined whether each piece of digital data is generated under preset time conditions with reference to information obtained by a time recognition module of each terminal device; (b) a step in which digital data are generated under the preset place conditions, and a specific user group is selected under the predetermined time conditions; and (c) a step in which reward information is provided to the specific user group.</p></abstract><description mxw-id="PDES63959003" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><heading id="h0001"><b>Technical Field</b></heading><p id="p0001" num="0001">The present invention relates to a method, a server, and a computer-readable recording medium for assisting multiple users to perform collections simultaneously, and more specifically, to the method, the server, and the computer-readable recording medium for leading multiple users to collectively perform collections of an object by providing information on a mission, relating to the object, which may be performed and information on rewards to be granted if the mission is completed to the multiple users, recognizing whether digital data made by the multiple users was created within a preset time condition and additionally recognizing whether the digital data was created within a preset place condition and/or whether the objects included in the digital data correspond to a specific object, selecting a specified group of users who complete the mission by creating the digital data while satisfying the above-mentioned conditions, and providing rewards corresponding to the object for the users included in the selected specified group of users.</p><heading id="h0002"><b>Background Technology</b></heading><p id="p0002" num="0002">Recently, due to the widespread use of the Internet, it has become common to provide information converted in a digital form which was once offered in print form, such as books. As the information converted into digital data may be shared and delivered in real time by many users, thanks to the spread of the Internet and a 3G network or other high-speed communications systems, it is widely used compared to printed materials which have relative shortcomings from the perspective of sharing and information delivery.</p><p id="p0003" num="0003">In particular, a technology of providing detailed information on an object existing in reality by using an image of the object taken in real time by a user terminal or other recognition information of the object acquired thereby has been recently introduced.</p><p id="p0004" num="0004">When a variety of services, e.g., services of providing detailed information relating to numerous objects existing in reality as shown above, are provided, it is difficult to effectively store an image taken or other recognition information inputted by the user terminal. Even if a user wants to store only the information on an object with relatively high interest (or high importance) differentially, it is complicated and vexatious to systematically record and store the information. Therefore, it is true that it has certain limits in leading to a more active participation of those in demand.<!-- EPO <DP n="2"> --></p><p id="p0005" num="0005">Accordingly, the applicant came to develop a technology of leading multiple users to more actively participate in a variety of services relating to objects in the real world by applying a concept of SNS, an issue in the field of IT.</p><heading id="h0003"><b>Detailed Description of the Invention</b></heading><heading id="h0004"><b>Technical Tasks</b></heading><p id="p0006" num="0006">It is an object of the present invention to solve all the problems described above.</p><p id="p0007" num="0007">It is another object of the present invention to encourage collective desire for the participation of users by providing information on a mission, in relation to an object, which may be simultaneously performed by multiple users and information on rewards which can be offered if the mission is completely performed and granting the rewards corresponding to the object to selected users who have actually completed the mission.</p><p id="p0008" num="0008">It is still another object of the present invention to activate an SNS by leading a group of users to create digital data through the simultaneous performance of the same act through the use of mob psychology of the users.</p><heading id="h0005"><b>Means for Solving Tasks</b></heading><p id="p0009" num="0009">To achieve the above objectives, the representative configuration of the present invention is described below:</p><p id="p0010" num="0010">In accordance with one aspect of the present invention, there is provided a method for assisting multiple users to perform a collection simultaneously comprising of (a) a step in which it is determined or recognized whether each of the digital data that multiple users created with respect to the object included in the image inputted via each terminal was created within a preset place condition by referring to information acquired by a location recognition module of the respective terminal and whether each of the digital data created was created within a preset time condition by referring to information acquired by a time recognition module of the respective terminal, (b) a step in which a specified group of users who created the digital data created within the preset place condition and within the preset time condition, with the specified group of users including a first to an n-th user, are selected among the multiple users; and (c) a step in which information on rewards corresponding to the object is provided for users included in the specified group of users.</p><p id="p0011" num="0011">In accordance with another aspect of the present invention, there is provided a method for assisting multiple users to perform a collection simultaneously comprising of (a) a step in which it is determined or recognized whether each of the digital data that multiple users created with respect to the object included in the image inputted via each terminal was created within a preset time condition by referring to information acquired by a time recognition module of the respective terminal and whether each object corresponds to a preset specific<!-- EPO <DP n="3"> --> object by referring to information acquired by an object recognition module of the respective terminal, (b) a step in which a specified group of users who created the digital data created within the preset time condition and performed so that an object included in the created digital data might be applicable to the specific object, with the specified group of users, including a first to an n-th user, are selected among the multiple users, and (c) a step in which information on rewards corresponding to the object is provided for users included in the specified group of users.</p><p id="p0012" num="0012">In accordance with still another aspect of the present invention, there is provided a method for assisting multiple users to perform a collection simultaneously comprising of (a) a step in which multiple users determine or recognize whether each of the digital data created by the terminal was created with a preset place condition by referring to current location information provided by the location recognition module of a respective terminal and whether each of the created digital data was created with a preset time condition by referring to information acquired by a time recognition module of the respective terminal, (b) a step in which a specified group of users who created the digital data created within the preset place condition and within the preset time condition, with the specified group of users including a first to an n-th user, are selected among the multiple users; and (c) a step in which information on rewards corresponding to the object is provided for users included in the specified group of users.</p><p id="p0013" num="0013">In accordance with still another aspect of the present invention, there is provided a server for assisting multiple users to perform a collection simultaneously comprising of a condition determining part that determines or recognizes whether each of the digital data that multiple users created with respect to the object included in the inputted image inputted via each terminal was created within a preset place condition by referring to information acquired by a location recognition module of the respective terminal and whether each of the digital data created was created within a preset time condition by referring to information acquired by a time recognition module of the respective terminal, a user selecting part that selects a specified group of users who created the digital data created within the preset place condition and within the preset time condition, with the specified group of users including a first to an n-th user, among the multiple users, and a reward information managing part that provides information on rewards corresponding to the object for users included in the specified group of users.</p><p id="p0014" num="0014">In accordance with still another aspect of the present invention, there is provided a server for assisting multiple users to perform a collection simultaneously comprising of a condition determining part that determines or recognizes whether each of the digital data that multiple users created with respect to the object included in the inputted image inputted via each terminal was created within a preset time condition by referring to information acquired by a<!-- EPO <DP n="4"> --> time recognition module of the respective terminal and whether each object corresponds to a preset specific object by referring to information acquired by an object recognition module of the respective terminal, a user selecting part that selects a specified group of users who created the digital data created within the preset time condition and where each object corresponds to a preset specific object included in the digital data, with the specified group of users including a first to an n-th user, among the multiple users, and a reward information managing part that provides information on rewards corresponding to the object for users included in the specified group of users.</p><p id="p0015" num="0015">In accordance with still another aspect of the present invention, there is provided a server for assisting multiple users to perform a collection simultaneously comprising of a condition determining part that determines or recognizes whether each of the digital data created by the terminal was created with a preset place condition by referring to current location information provided by the location recognition module of a respective terminal and whether each of the created digital data was created with a preset time condition by referring to information acquired by a time recognition module of the respective terminal, a user selecting part that selects a specified group of users who created the digital data created within the preset place condition and within the preset time condition, with the specified group of users including a first to an n-th user, among the multiple users, and a reward information managing part that provides information on rewards corresponding to the object for users included in the specified group of users.</p><p id="p0016" num="0016">In addition, other methods and systems for implementing the present invention and other computer-readable recoding mediums for recording a computer program to run the methods are further provided.</p><heading id="h0006"><b>Effects of the Invention</b></heading><p id="p0017" num="0017">According the present invention, as rewards corresponding to an applicable object are paid to a specific group of users who have performing a mission, an explosive increase in users may be promoted by leading users to perform a collection on an object as a group.</p><heading id="h0007"><b>Brief Description of the Drawings</b></heading><p id="p0018" num="0018"><ul><li><figref idrefs="f0001">Figure 1</figref> is a diagram schematically representing a configuration of a whole server to assist multiple users to perform collections simultaneously in accordance with one example embodiment of the present invention.</li><li><figref idrefs="f0001">Figure 2</figref> is a drawing exemplarily illustrating an internal configuration of a user terminal (200) in accordance with one example embodiment of the present invention.<!-- EPO <DP n="5"> --></li><li><figref idrefs="f0001">Figures 3a</figref> and <figref idrefs="f0002">3b</figref> are diagrams exemplarily showing digital data in the form of a collection page including information on an auto comment and information on an image of a recognized object in accordance with one example embodiment of the present invention.</li><li><figref idrefs="f0002">Figure 4</figref> is a drawing exemplarily representing an internal configuration of a simultaneous collection supporting server (300) in accordance with one example embodiment of the present invention.</li></ul></p><heading id="h0008">&lt;Description of Reference Numerals&gt;</heading><p id="p0019" num="0019"><ul><li>100: communication network</li><li>200: user terminal</li><li>210: digital data managing part</li><li>220: location recognition module</li><li>230: time recognition module</li><li>240: object recognition module</li><li>250: communication part</li><li>260: control part</li><li>300: simultaneous collection supporting server</li><li>310: condition determining part</li><li>320: user selecting part</li><li>330: reward information managing part</li><li>340: communication part</li><li>350: control part</li><li>301: collection page</li><li>311: recognition information on object identity</li><li>321: auto comment</li><li>331: image on recognized object</li></ul></p><heading id="h0009"><b>Forms for Implementing the Invention</b></heading><p id="p0020" num="0020">In the following detailed description of the present invention, reference is made to the accompanying drawings that show specific examples as illustrations in which the present invention may be practiced. These examples are described in sufficient detail to enable those skilled in the art to practice the invention. It is to be understood that the various examples of the invention, although different, are not necessarily mutually exclusive. For example, a particular feature, structure, or characteristic described herein in connection with one example may be implemented within other examples without departing from the spirit and scope of the invention. In addition, it is to be understood that the location or arrangement of individual elements within each disclosed example may be modified without departing from the spirit<!-- EPO <DP n="6"> --> and scope of the invention. The following detailed description is, therefore, not to be taken in a limiting sense, and the scope of the present invention is defined only by the accompanying claims, if they are appropriately interpreted, along with the full range of equivalents which the claims claim. In the drawings, similar numerals refer to the same or similar functionality throughout the several aspects.</p><p id="p0021" num="0021">In the following is described the present invention in detail referring to the preferred examples of the present invention so that those having common knowledge of the technical field to which the present invention belongs may easily practice the present invention.</p><heading id="h0010">[Preferred Embodiments of the Invention]</heading><p id="p0022" num="0022">Herein, a "collection" refers to an action of a user to digitally collect an object in which a user is interested; and more specifically, it may be defined as a series of processes for acquiring recognition reference information on the object (e.g., a taken image, a near field communication tag, information showing that the object has been selected, etc.) which the user intends to collect by using the user's terminal and transmitting the acquired recognition reference information to a server which performs other subsequent functions (e.g., a function of recognizing an object, creating and storing a collection page, determining a condition, etc.). For example, a process for taking an image of the cover of a book by using his or her terminal and transmitting the taken image to the server to thereby allow information on the book to be collected may correspond to the collection for the book. Further, an act of the user going to an Italian restaurant named "Alio" and selecting "Alio" by using the terminal itself may be an applicable collection for "Alio".</p><p id="p0023" num="0023">Furthermore, the "collection" may indicate not only a process for transmitting the acquired recognition reference information to the server by using the user terminal but also a process for recognizing the object from the recognition reference information and a process for creating, and storing, a page (so-called a collection page) by combining digital data such as information on an identity of the recognized object (including a type, a characteristic, etc., of the object), information on a place where, and a time when, the recognition reference information on the object was acquired, information on a comment regarding the object, an image corresponding to the object, etc.</p><heading id="h0011"><u>Configuration of the Whole System</u></heading><p id="p0024" num="0024"><figref idrefs="f0001">Figure 1</figref> is a diagram schematically representing a configuration of a whole server to assist multiple users to perform collections simultaneously in accordance with one example embodiment of the present invention.</p><p id="p0025" num="0025">As illustrated in <figref idrefs="f0001">Figure 1</figref>, the whole system in accordance with one example embodiment of the present invention may include a communication network (100), a user terminal (200), and a simultaneous collection supporting server (300).<!-- EPO <DP n="7"> --></p><p id="p0026" num="0026">First, the communication network (100) in accordance with one example embodiment of the present invention may be configured to be wired or wireless regardless of its communication format and may be configured in the form of a mobile telecommunication network, a local area network (LAN), a metropolitan area network (MAN), a wide area network (WAN), an artificial satellite network, and other diverse networks. More specifically, the network (100) in the present invention should be understood as a concept inclusive of all network services such as publicly known World Wide Web (www), Code Division Multiple Access (CDMA), Wideband Code Division Multiple Access (WCDMA), Global System for Mobile communications (GSM) and the like.</p><p id="p0027" num="0027">Next, each user terminal (200) in accordance with an example embodiment of the present invention may perform a function of enabling each user to select an object of his or her interest and create digital data with respect to the object through a camera module, etc., present in each user terminal (200) and transmitting the digital data to the simultaneous collection supporting server (300). Specifically, the user terminal (200) may transmit the digital data, such as a simply taken photo, to the simultaneous collection supporting server (300) or recognize the identity of the object included in the digital data such as the photo and the place where, and the time when, the digital data was created, and transmit, to the simultaneous collection supporting server (300), after including the recognition information on the identity of the object and the place where, and the time when, the digital data was created in the digital data.</p><p id="p0028" num="0028">In accordance with another example embodiment of the present invention, the user terminal (200) may display information on certain objects selectable around a current location by referring to the information on the current location provided by a location recognition module and if a request of a user for a specific object is received, it may create, and transmit to the simultaneous collection supporting server (300), the digital data indicating that the object was selected.</p><p id="p0029" num="0029">In addition, the user terminal (200) in accordance with an example embodiment of the present invention may also perform a function of receiving, from the simultaneous collection supporting server (300), information on a mission, relating to an object, which may be performed, and information on rewards which may be provided if the mission is completely performed.</p><p id="p0030" num="0030">On the other hand, in accordance with one example embodiment of the present invention, the user terminal (200) is a digital device which includes a function of accessing the communication network (100) or the simultaneous collection supporting server (300) and communicating with it. Such digital devices, including a personal computer (e.g., desktop, laptop, etc.), a workstation, a PDA, a web pad, a cellular phone, which are furnished with<!-- EPO <DP n="8"> --> memory means and microprocessors with a calculation ability, may be adopted as the user terminal (200) in accordance with the present invention.</p><p id="p0031" num="0031">The detailed explanation on an internal configuration and components of the user terminal (200) will be made later.</p><p id="p0032" num="0032">Next, the simultaneous collection supporting server (300) in accordance with an example embodiment of the present invention may perform a function of providing the information on the mission with respect to the object which may be performed simultaneously by multiple users and the information on the rewards which may be provided if the mission is performed.</p><p id="p0033" num="0033">Furthermore, the simultaneous collection supporting server (300) in accordance with an example embodiment of the present invention may perform a function of recognizing whether respective digital data created by multiple users was created within a preset time condition whether the respective digital data was created within a preset place condition, i.e., within a preset scope of the place, and/or whether the objects included in the digital data correspond to a specific object.</p><p id="p0034" num="0034">Furthermore, in accordance with one example embodiment of the present invention, the simultaneous collection supporting server (300) may select a specified group of users who have completely performed the mission by creating the digital data while satisfying various conditions as shown above and providing the information on the rewards corresponding to the object for the users in the selected specified user group. Herein, the relationship among members of the specified user group may be a friend relationship, included in the same group by application, etc., to belong to the same group from the beginning, or a stranger relationship.</p><p id="p0035" num="0035">Details will be forthcoming about the internal configuration and configuration factors of the simultaneous collection supporting server (300).</p><heading id="h0012"><u>Configuration of the User Terminal</u></heading><p id="p0036" num="0036"><figref idrefs="f0001">Figure 2</figref> is a drawing exemplarily illustrating an internal configuration of a user terminal (200) in accordance with one example embodiment of the present invention.</p><p id="p0037" num="0037">By referring to <figref idrefs="f0001">Figure 2</figref>, the user terminal (200) may include a digital data managing part (210), a location recognition module (220), a time recognition module (230), an object recognition module (240), a communication part (250), and a control part (260).</p><p id="p0038" num="0038">In accordance with one example embodiment of the present invention, at least some of the digital data managing part (210), the location recognition module (220), the time recognition module (230), the object recognition module (240), the communication part (250), and the control part (260) may be program modules included in or, communicating with, the user terminal (200). However, <figref idrefs="f0001">Figure 2</figref> exemplifies that the digital data managing part (210), the location recognition module (220), the time recognition module (230), the object recognition module (240), the communication part (250), and the control part (260) are all included in the user terminal (200). Such program modules may be included in the user terminal (200) in the<!-- EPO <DP n="9"> --> form of an operating system, an application program module, and other program modules and may be stored in various well-known memory devices physically. In addition, such program modules may also be stored in a remote storage device capable of communicating with the simultaneous collection supporting server (300). The program modules may include, but not be limited to, a routine, a subroutine, a program, an object, a component, and a data structure for executing a specific operation or a type of specific abstract data that will be described in accordance with the present invention.</p><p id="p0039" num="0039">First of all, the digital data managing part (210) in accordance with one example embodiment of the present invention may perform a function of allowing digital data of the object to be created based on an inputted image at the user's request and to be transmitted to the simultaneous collection supporting server (300) with at least recognition information on a place where and at a time when the digital data was created or at least recognition information on the identity of the object included in the digital data and a time when the digital data was created by using the location recognition module (220), the time recognition module (230), and the object recognition module (240), which will be explained later. More specifically, the digital data managing part (210) in accordance with one example embodiment of the present invention may include a photographing apparatus such as a CCD camera to acquire the inputted image including the object.</p><p id="p0040" num="0040">Furthermore, the digital data managing part (210) in accordance with one example embodiment of the present invention may also perform a function of displaying information on objects selectable around the current location by referring to the information on the current location provided by the location recognition module (220) which will be explained later and, if the request of the user for a specific object is received, perform a function of allowing digital data indicating the specific object was selected to be created. At the time, the digital data may be created to include even information on the time when the object was selected.</p><p id="p0041" num="0041">Next, if digital data of the object included in the inputted image are created by the digital data managing part (210), the location recognition module (220) in accordance with one example embodiment of the present invention may perform a function of calculating and recording the current location of the user terminal (200), by using a technology for acquiring location information including GPS technology, A-GPS technology, WPS technology and cell-based location based service (LBS), in order to recognize the place where the digital data was created. In addition, the location recognition module (220) in accordance with one example embodiment of the present invention may perform a function of calculating, and transmitting to the digital data managing part (210), the current location of the user terminal (200) to enable the user to create digital data indicating that the object around the current location was selected. Thus, the location recognition module (220) may include a GPS module, a mobile telecommunication module, etc.<!-- EPO <DP n="10"> --></p><p id="p0042" num="0042">Next, if the digital data of the object are created, the time recognition module (230) in accordance with one example embodiment of the present invention may perform a function of recognizing and recording the time when the digital data are created.</p><p id="p0043" num="0043">Next, if the digital data of the specific object are created, the object recognition module (240) in accordance with one example embodiment of the present invention may perform a function of recognizing the identity of the object by using an object recognition technology, an optical character recognition (OCR) technology, a barcode recognition technology, etc.</p><p id="p0044" num="0044">Herein, as an object recognition technology used to recognize a specific object included in the digital data from different angles and at different distances, the article entitled "<nplcit id="ncit0001" npl-type="s"><text>A Comparison of Affine Region Detectors" authored jointly by K. MIKOLAJCZYK and seven others and published in "International Journal of Computer Vision" in November 2005</text></nplcit> may be referred to (The whole content of the article must be considered to have been combined herein). The article describes a method for detecting affine invariant regions to accurately recognize the same object photographed from different angles. Surely, the object recognition technologies applicable to the present invention are not limited only to the method mentioned in the article and it will be able to reproduce the present invention by applying various modified examples. To use the object recognition technology for recognizing the identity of the object by computing degrees of similarity through image matching, the object recognition module (240) may be interfaced with certain databases (not illustrated) where the reference object images and the corresponding identifiers are recorded.</p><p id="p0045" num="0045">Moreover, the certain optical character recognition (OCR) technology for recognizing certain character strings included in the digital data may refer to the specification of Korea Patent Application No. <patcit id="pcit0001" dnum="KR20060078850"><text>2006-0078850</text></patcit>, wherein the specification must be considered to have been combined in its entirety. The specification discloses a method for creating each candidate character forming a character string included in the inputted image and performing character recognition on each created candidate character. Herein, the OCR technology which is applicable to the present invention is not limited to the method described in the specification but various modified examples may be introduced.</p><p id="p0046" num="0046">In addition, the technology for recognizing a barcode included in the digital data may refer to the specification of Korea Patent Registration No. <patcit id="pcit0002" dnum="KR0791704"><text>0791704</text></patcit>, wherein all must be considered to have been combined herein. The specification describes a method for extracting a barcode field by analyzing the adjacency relationship of connection fields on the basis of the characteristics of the barcode, determining a unit width which is to be used as a module width of the barcode by referring to a width of the connection field of black pixels in the extracted barcode field and collating a barcode pattern with an input width pattern to thereby recognize the barcode. Herein, the barcode recognition technology which is applicable to the present<!-- EPO <DP n="11"> --> invention is not limited to the method described in the specification but various modified examples may be introduced.</p><p id="p0047" num="0047">In addition, for the technology recognizing a QR code of the object included in the digital data, the specifications of Korea Patent Registration No. <patcit id="pcit0003" dnum="KR0852656"><text>0852656</text></patcit> may be referred to, of which all must be considered to have been combined herein. The specification describes a method for recognizing a QR code by recognizing location detecting patterns of respective two-dimensional codes from the inputted image, selecting at least two location detecting patterns and determining whether the minimal units of the location detection patterns are the same or not and performing a calculation specifying the locations of the two-dimensional codes by using the location detection patterns if the minimal units are the same. Herein, the QR code recognition technology applicable to the present invention is not limited to the method described in the specification but various modified examples may be introduced.</p><p id="p0048" num="0048">On the other hand, in accordance with one example embodiment of the present invention, the digital data managing part (210) was explained above with an example of transmitting, to the simultaneous collection supporting server (300), the created digital data with at least some of the recognition information on the place where and on the time when the digital data was created, and recognition information on the identity of the object, acquired respectively by the location recognition module (220), the time recognition module (230), and the object recognition module (240), but the present invention is not limited only to this case. The digital data managing part (210) in accordance with one example embodiment of the present invention may allow the digital data to be created in the form of a collection page which includes information on an auto comment containing a phrase (or a sentence) properly assembled under the grammar of a language by using the recognition information on the identity of the object and the recognition information on the place where, and the time when, the digital data was created and image information on the recognized object. More specifically, the digital data created in the form of such collection page may be described as below by referring to <figref idrefs="f0001">Figures 3a</figref> and <figref idrefs="f0002">3b</figref>.</p><p id="p0049" num="0049"><figref idrefs="f0001">Figures 3a</figref> and <figref idrefs="f0002">3b</figref> are diagrams exemplarily showing digital data in the form of a collection page including information on an auto comment and information on an image of a recognized object in accordance with one example embodiment of the present invention.</p><p id="p0050" num="0050">By referring to <figref idrefs="f0001">Figure 3a</figref>, when a book entitled "Dream Like Jobs and Achieve Like Gates" is included in an image inputted into the user terminal (200), the object recognition module (240) will be able to recognize the object included in the inputted image as the book "Dream Like Jobs and Achieve Like Gates" by applying the object recognition technology, the OCR technology, and/or the barcode recognition technology to the inputted image.</p><p id="p0051" num="0051">By referring to <figref idrefs="f0002">Figure 3b</figref>, it can be verified that the digital data managing part (210) allows digital data to be automatically created in the form of a collection page (301) including the<!-- EPO <DP n="12"> --> thumbnail image (331) of the recognized book and the auto comment (321) properly assembled under Korean grammar by using at least some of the information on the identity of the book (311) obtained by the object recognition module (240), the information on the place where the inputted image was created ("XX Bookstore") acquired by the location recognition module (220), and the information on the time when the inputted image was created ("Oct. 20, 2010") acquired by the time recognition module (230).</p><p id="p0052" num="0052">Next, in accordance with an example embodiment of the present invention, the communication part (250) may perform a function of allowing the user terminal (200) of the present invention to communicate with an external device.</p><p id="p0053" num="0053">Lastly, in accordance with an example embodiment of the present invention, the control part (260) performs a function of controlling the flow of the data among the digital data managing part (210), the location recognition module (220), the time recognition module (230), the object recognition module (240), and the communication part (250). In other words, the control part (260) may control the flow of data from outside or among the components of the user terminal (200) to allow the digital data managing part (210), the location recognition module (220), the time recognition module (230), the object recognition module (240), and the communication part (250) to perform their unique functions.</p><heading id="h0013"><u>Configuration of the Simultaneous Collection Supporting Server</u></heading><p id="p0054" num="0054"><figref idrefs="f0002">Figure 4</figref> is a drawing exemplarily representing an internal configuration of a simultaneous collection supporting server (300) in accordance with one example embodiment of the present invention.</p><p id="p0055" num="0055">By referring to <figref idrefs="f0002">Figure 4</figref>, the simultaneous collection supporting server (300) may include a condition determining part (310), a user selecting part (320), a reward information managing part (330), a communication part (340), and a control part (350).</p><p id="p0056" num="0056">In accordance with an example embodiment of the present invention, at least some of the condition determining part (310), the user selecting part (320), the reward information managing part (330), the communication part (340), and the control part (350) may be included in the simultaneous collection supporting server (300) or may be program modules communicable with the simultaneous collection supporting server (300). However, <figref idrefs="f0002">Figure 4</figref> illustrates such an example that the condition determining part (310), the user selecting part (320), the reward information managing part (330), the communication part (340), and the control part (350) are included in the simultaneous collection supporting server (300). Such program modules may be included in the simultaneous collection supporting server (300) in the form of an operating system, an application program module and other program modules, and may be stored in various well-known storage devices physically. In addition, such program modules may also be stored in a remote storage device capable of communicating with the simultaneous collection supporting server (300). The program modules may include,<!-- EPO <DP n="13"> --> but not be limited to, a routine, a subroutine, a program, an object, a component, and a data structure for executing a specific operation or a type of specific abstract data that will be described in accordance with the present invention.</p><p id="p0057" num="0057">Furthermore, in accordance with an example embodiment of the present invention, the condition determining part (310) may perform a function of recognizing whether respective digital data of an object(s) generated by multiple users through their terminals (200) was created within the preset place condition and the preset scope of the time by referring to information acquired by the location recognition module (220) and the time recognition module (230) of respective user terminals (200). For example, if mission information such as "Please get a collection by dropping by Dunkin' Donuts Gangnam Store at 7:00 p.m. on Jan. 21, 2011" is provided for multiple users by the reward information managing part (330) to be explained later, the condition determining part (210) may check whether the digital data generated through the respective user terminals (200) by the multiple users was created while satisfying both the time condition (i.e., 7:00 p.m. on Jan. 21, 2011) and the place condition (i.e., Starbucks [sic] Gangnam Store) of the mission.</p><p id="p0058" num="0058">In accordance with one example embodiment of the present invention, the user selecting part (320) may perform a function of selecting a specified group of users, (including a first to an n-th user) among multiple users, who created digital data within the preset place condition and the preset scope of the time.</p><p id="p0059" num="0059">While it was described above on the process for the condition determining part (310) and the user selecting part (320) determining or recognizing whether respective digital data created by respective users satisfy the preset place condition and the preset scope of the time and selecting a group of users who satisfy the above-mentioned two conditions, the condition determining part (310) and the user selecting part (320) in accordance with one example embodiment of the present invention may additionally determine or recognize whether the objects included in the digital data correspond to a specific object or not by referring to the object recognition modules (240) of respective user terminals (200) depending upon the nature of the mission information provided by the reward information managing part (330) to be described later and select users who satisfy all the above-mentioned conditions.</p><p id="p0060" num="0060">More specifically, if mission information such as "Please collect a chocolate donut at Dunkin' Donuts Gangnam Store at 7:00 p.m. on Jan. 21, 2011" is provided for multiple users, the condition determining part (310) may check whether respective digital data generated through respective user terminals (200) by multiple users was created with respect to the specific object (i.e., the chocolate donut) while satisfying the time condition (i.e., at 7:00 p.m. on Jan. 21, 2011) and the place condition (i.e., Dunkin' Donuts Gangnam Store) and the user selecting part (320) may select a specified group of users who created the digital data while satisfying all the conditions.<!-- EPO <DP n="14"> --></p><p id="p0061" num="0061">Similarly, the condition determining part (310) and the user selecting part (320) in accordance with one example embodiment of the present invention may also determine or recognize whether the digital data was created with respect to the specific object within the preset scope of the time and select users who satisfy the condition depending on the nature of the mission information provided by the reward information managing part (330) to be explained later. For example, if mission information such as "Please collect Sonata's newly launched car model at 7:00 p.m. on Jan. 21, 2011" is provided for multiple users, the condition determining part (310) may check whether respective digital data made through user terminals (200) by multiple users was created with respect to the specific object (i.e., Sonata car model) while satisfying the time condition (i.e., at 7:00 p.m. on Jan. 21, 2011) and the user selecting part (320) may select the specified group of users who created the digital data while satisfying the aforementioned conditions.</p><p id="p0062" num="0062">As such, if it is necessary to determine or recognize whether the objects included in the digital data correspond to the specific object or not depending on the nature of the mission information, the condition determining part (310) in accordance with one example embodiment of the present invention may compute degrees of similarity through matching an image of an object included in the digital data with pre-stored images of a specific object and if the computed degrees of similarity exceed the preset degree of similarity threshold, it may determine or recognize that the object included in the digital data corresponds to the specific object.</p><p id="p0063" num="0063">Next, in accordance with one example embodiment of the present invention, the reward information managing part (330) may perform a function to provide the mission information, in relation to the object, which may be performed by the multiple users and the information on the extent of the rewards provided if the mission is completely performed and provide the reward information corresponding to the object to users in a specified user group if there exists a specified group of users determined to have completely performed the mission. More specifically, the mission information provided by the reward information managing part (330) may be in the form of information requested to create the digital data of the specific object at the same place simultaneously by two or more users, as exemplarily described above, and the reward information provided by the reward information managing part (330) may include the coupon information issued by a company which is associated with the specific object.</p><p id="p0064" num="0064">Next, the communication part (340) in accordance with one example embodiment of the present invention may perform a function of allowing the simultaneous collection supporting server (300) to communicate with an external device.</p><p id="p0065" num="0065">Lastly, the control part (350) in accordance with one example embodiment of the present invention may perform a function of controlling the flow of data among the condition determining part (310), the user selecting part (320), the reward information managing part<!-- EPO <DP n="15"> --> (330), and the communication part (340). In other words, the control part (350) may control the flow of data from outside or among the components of the simultaneous collection supporting server (300) to allow the condition determining part (310), the user selecting part (320), the reward information managing part (330), and the communication part (340) to perform their unique functions.</p><p id="p0066" num="0066">The examples described above according to the present invention can be implemented in the form of a program command that may be executed through a variety of computer components and recorded on a computer-readable recording media. The computer readable media may include solely or in combination, program commands, data files and data structures. The program commands recorded on the computer-readable recording medium may be specially designed and configured for the present invention or may be known to and be usable by a person skilled in the field of computer software. Examples of the computer-readable recording medium include magnetic media such as hard disk, floppy disk, and magnetic tape, optical media such as CD-ROM and DVD, include magnetic media such as hard disk, floppy disk, magnetic tape, optical media such as CD-ROM and DVD, magneto-optical media such as floptical disk and hardware devices such as ROM, RAM and flash memory specially configured to store and execute program commands. Program commands include not only a machine language code made by a complier but also a high level code that can be used by an interpreter etc., which is executed by a computer. The hardware device may be configured to work as one or more software modules to perform the action according to the present invention, and its reverse is also the same.</p><p id="p0067" num="0067">While the present invention has been described so far by certain details such as specific components and limited examples and drawings, they were merely provided to promote overall understanding of the present invention, and the present invention is not limited by the examples above. A person with the common knowledge of the field to which the present invention belongs may attempt various modifications and changes based on such description.</p><p id="p0068" num="0068">Therefore, the thought of the present invention must not be confined to the explained examples, and the claims to be described later as well as everything including variations equal or equivalent to the claims would belong to the category of the thought of the present invention.</p></description><claims mxw-id="PCLM56982023" lang="EN" load-source="patent-office"><!-- EPO <DP n="16"> --><claim id="c-en-0001" num="0001"><claim-text>A method for assisting multiple users to perform a collection simultaneously comprising of
<claim-text>(a) a step in which digital data created with respect to recognition reference information of an object, including at least one piece of a taken image of the object, a near field communication tag of the object and information itself indicating that the object was selected, are acquired from a terminal of each of the multiple users;</claim-text>
<claim-text>(b) a step in which it is determined or recognized whether the respective digital data on the recognition reference information acquired through the terminals was created within a preset place condition by referring to information acquired by location recognition modules of the respective terminals and whether the respective digital data on the recognition reference information acquired through the terminals was created within a preset scope of the time by referring to information acquired by time recognition modules thereof;</claim-text>
<claim-text>(c) a step in which a specified group of users, including a first to an n-th user among the multiple users, who create the digital data within the preset place condition and within the preset scope of the time are selected; and</claim-text>
<claim-text>(d) a step in which information on rewards corresponding to the object is provided for users included in the specified group of users.</claim-text></claim-text></claim><claim id="c-en-0002" num="0002"><claim-text>The method recited in Claim 1, wherein the step (b) is <b>characterized by</b> additionally determining or recognizing whether each object included in the digital data acquired through the respective terminals corresponds to a specific object or not by referring to information acquired by the object recognition module of each of the terminals, and the step (c) is <b>characterized by</b> selecting the users who created the digital data created within the preset place condition and created within the present scope of time and for whom the object included in the created digital data corresponds to the specific object among the multiple users as the specified group of users.</claim-text></claim><claim id="c-en-0003" num="0003"><claim-text>The method recited in Claim 2 wherein degrees of similarity are computed through matching an image of an object included in the digital data with pre-stored images of a specific object and if the computed degrees of similarity exceed the preset degree of similarity threshold, it is determined or recognized that the object included in the digital data corresponds to the specific object.<!-- EPO <DP n="17"> --></claim-text></claim><claim id="c-en-0004" num="0004"><claim-text>The method recited in Claim 2 wherein<br/>
the object recognition module acquires information on the identity of an object by using at least one of the character recognition technology for identifying an object by recognizing at least one of character, number or symbol included in the digital data, the barcode recognition technology for recognizing an object from barcodes included in the digital data, and the QR code recognition technology for recognizing an object from QR codes included in the digital data.</claim-text></claim><claim id="c-en-0005" num="0005"><claim-text>The method recited in Claim 1 wherein<br/>
the digital data include information on an auto comment containing a phrase or a sentence properly assembled under grammar of a language by using at least one piece of recognition information on the identity of the object, recognition information on the place when the digital data was created, and recognition information on the time where the digital data was created and a collection page comprising information on the image with respect to the recognized object.</claim-text></claim><claim id="c-en-0006" num="0006"><claim-text>The method recited in Claim 1 wherein<br/>
it further includes a step prior to the step (a) in which mission information, in relation with the object, that may be performed and reward information that is provided if the mission is performed is provided to the multiple users.</claim-text></claim><claim id="c-en-0007" num="0007"><claim-text>The method recited in Claim 6 wherein<br/>
the mission information includes information for which two or more users make a request to create digital data on the object at the same place simultaneously.</claim-text></claim><claim id="c-en-0008" num="0008"><claim-text>The method recited in Claim 1 wherein,<br/>
in the step (d), the reward information includes the coupon information issued by a company which is associated with the object.</claim-text></claim><claim id="c-en-0009" num="0009"><claim-text>A method for assisting multiple users to perform a collection simultaneously comprising of
<claim-text>(a) a step in which the identity of the object is recognized by using at least one of an object recognition technology for recognizing the identities of the objects by matching images of the objects, if inputted on respective screens of terminals, with a pre-stored reference object image to compute degrees of similarity and by determining whether those degrees of similarity exceed a preset degree of similarity<!-- EPO <DP n="18"> --> threshold, an optical character recognition technology for identifying the objects by recognizing at least one of character, number or symbol included on the objects and a barcode recognition technology for recognizing the identities of the objects from barcodes included thereon,</claim-text>
<claim-text>(b) a step in which information on an auto comment containing a phrase or a sentence properly assembled under grammar of a language by using at least one piece of recognition information on the identity of the object, and recognition information on a place where, and a time when, an inputted image of the object was created and digital data including at least a part of the information on the image of the recognized object are acquired,</claim-text>
<claim-text>(c) a step in which, if multiple users receive a registration request for the digital data from each terminal, it is determined or recognized whether the digital data for the object was created within a preset scope of time by referring to information acquired by a time recognition module of the terminal used to acquire the digital data for the object and whether the object corresponds to a preset specific object by referring to information acquired by an object recognition module of the terminal,</claim-text>
<claim-text>(d) a step in which a specified group of users including a first to an n-th user are selected among the multiple users who created the created digital data within the preset scope of time and performed so that the object included in the created digital data might correspond to the specific object, and</claim-text>
<claim-text>(e) a step in which reward information corresponding to the object is provided for users included in the specified group of users.</claim-text></claim-text></claim><claim id="c-en-0010" num="0010"><claim-text>The method recited in Claim 9 wherein<br/>
if further includes a step prior to the step (a) in which mission information, in relation with the object, that may be performed and reward information that is provided if the mission is performed is provided to the multiple users.</claim-text></claim><claim id="c-en-0011" num="0011"><claim-text>The method recited in Claim 10 wherein<br/>
the mission information includes information for which two or more users make a request to create digital data on the object at the same place simultaneously.</claim-text></claim><claim id="c-en-0012" num="0012"><claim-text>A method for assisting multiple users to perform a collection simultaneously comprising of
<claim-text>(a) a step in which digital data, formed by at least some of images of objects, information on near field communication tags and information itself indicating that<!-- EPO <DP n="19"> --> the objects were selected, created by the respective terminals of the multiple users, are acquired from a terminal of each of the multiple users,</claim-text>
<claim-text>(b) a step in which it is determined or recognized whether the respective digital data was created within a preset place condition by referring to information on current locations provided by location recognition modules of the respective terminals and whether the respective digital data was created within a preset scope of the time by referring to information acquired by time recognition modules thereof,</claim-text>
<claim-text>(c) a step in which a specified group of users, including a first to an n-th user among the multiple users, who create the digital data within the preset place condition and within the preset scope of the time are selected, and</claim-text>
<claim-text>(d) a step in which information on rewards corresponding to the object is provided for users included in the specified group of users.</claim-text></claim-text></claim><claim id="c-en-0013" num="0013"><claim-text>The method recited in Claim 12 wherein<br/>
it further includes a step prior to step (a) in which mission information, in relation to the object, that may be performed, and reward information that is provided if the mission is performed, is provided to the multiple users.</claim-text></claim><claim id="c-en-0014" num="0014"><claim-text>The method recited in Claim 13 wherein<br/>
the mission information includes information for which two or more users make a request to create digital data on the object at the same place simultaneously.</claim-text></claim><claim id="c-en-0015" num="0015"><claim-text>A server for assisting multiple users to perform a collection simultaneously comprising of<br/>
a digital data acquiring part that acquires digital data created with respect to recognition reference information of an object, including at least one piece of taken image of the object, a near field communication tag of the object and information itself indicating that the object was selected, from a terminal of each of the multiple users,<br/>
a condition determining part that determines or recognizes whether the respective digital data on the recognition reference information acquired through the terminals was created within a preset place condition by referring to location recognition modules of the respective terminals and whether the respective digital data on the recognition reference information acquired through the terminals was created within a preset scope of the time by referring to information acquired by time recognition modules thereof,<br/>
<!-- EPO <DP n="20"> -->a user selecting part that selects a specified group of users, including a first to an n-th users among the multiple users, who create the digital data within the preset place condition and within the preset scope of the time, and<br/>
a reward information managing part that provides information on rewards corresponding to the object for users included in the specified group of users.</claim-text></claim><claim id="c-en-0016" num="0016"><claim-text>The server recited in Claim 15 wherein,<br/>
the condition determining part is <b>characterized by</b> additionally determining or recognizing whether each object included in the digital data acquired through the respective terminals corresponds to a specific object or not by referring to information acquired by the object recognition module of each of the terminals, and the user selecting part is <b>characterized by</b> selecting the users who created the digital data created within the preset place condition and created within the present scope of time and for whom the object included in the created digital data corresponds to the specific object among the multiple users as the specified group of users.</claim-text></claim><claim id="c-en-0017" num="0017"><claim-text>The server recited Claim 16 wherein,<br/>
the condition determining part computes degrees of similarity through matching an image of an object included in the digital data with pre-stored images of a specific obj ect and if the computed degrees of similarity exceed the preset degree of similarity threshold, it is determined or recognized that the object included in the digital data corresponds to the specific object.</claim-text></claim><claim id="c-en-0018" num="0018"><claim-text>The server recited in Claim 16 wherein,<br/>
the object recognition module acquires information on the identity of an object by using at least one of the character recognition technology for identifying an object by recognizing at least one of character, number or symbol included in the digital data, the barcode recognition technology for recognizing an object from barcodes included in the digital data, and the QR code recognition technology for recognizing an object from QR codes included in the digital data.</claim-text></claim><claim id="c-en-0019" num="0019"><claim-text>The server recited in Claim 15 wherein<br/>
the digital data include information on an auto comment containing a phrase or a sentence properly assembled under grammar of a language by using at least one piece of recognition information on the identity of the object, recognition information on the place when the digital data was created, and recognition information on the time<!-- EPO <DP n="21"> --> where the digital data was created and a collection page comprising information on the image with respect to the recognized object.</claim-text></claim><claim id="c-en-0020" num="0020"><claim-text>The server recited in Claim 15 wherein,<br/>
the reward information managing part provides mission information, in relation with the object, that may be performed and reward information that is provided if the mission is performed</claim-text></claim><claim id="c-en-0021" num="0021"><claim-text>This server recited in Claim 20 wherein,<br/>
the mission information includes information for which two or more users make a request to create digital data on the object at the same place simultaneously.</claim-text></claim><claim id="c-en-0022" num="0022"><claim-text>The server recited in Claim 15 wherein,<br/>
the reward information includes the coupon information issued by a company which is associated with the object.</claim-text></claim><claim id="c-en-0023" num="0023"><claim-text>A server for assisting multiple users to perform a collection simultaneously comprising of<br/>
a digital data acquiring part that recognizes identities of objects by using at least one of an object recognition technology for recognizing the identities of the objects by matching images of the objects, if inputted on respective screens of terminals, with a pre-stored reference object image to compute degrees of similarity and by using an identifier of the reference object image whose degree of similarity exceeds a preset degree of similarity threshold, an optical character recognition technology for identifying the objects by recognizing at least one of characters, numbers or symbols included in the objects and a barcode recognition technology for recognizing the identities of the objects from barcodes included therein and acquires each of the digital data respectively having at least some of information on an image of the recognized object and information on an auto comment containing a phrase or a sentence properly assembled under the grammar of a language by using at least one piece of recognition information on the identity of the object and recognition information on the place where, and the time when, the inputted image was created,<br/>
a condition determining part that determines or recognizes whether the respective digital data of the object was created within a preset scope of the time by referring to information acquired by time recognition modules of the respective terminals and whether the object corresponds to the preset specific object by referring to<!-- EPO <DP n="22"> --> information acquired by the object recognition modules thereof if requests for the multiple users to register the digital data are received from their respective terminals, a user selecting part that selects a specified group of users, including a first to an n-th users among the multiple users, who create the digital data within the preset scope of the time and perform to make the objects included in the created digital data correspond to the specific object, and<br/>
a reward information managing part that provides information on rewards corresponding to the specific object for users included in the specified group of users.</claim-text></claim><claim id="c-en-0024" num="0024"><claim-text>The server recited in Claim 23 wherein,<br/>
the reward information managing part provides mission information, in relation to the object, that may be performed, and reward information that is provided if the mission is performed</claim-text></claim><claim id="c-en-0025" num="0025"><claim-text>This server recited in Claim 24 wherein,<br/>
the mission information includes information for which two or more users make a request to create digital data on the object at the same place simultaneously.</claim-text></claim><claim id="c-en-0026" num="0026"><claim-text>A server for assisting multiple users to perform a collection simultaneously comprising of<br/>
a digital data acquiring part that acquires, from a terminal of each of the multiple users, each of the digital data formed by at least some of an image, information on a near field communication tag, and information itself indicating that the object was selected, created by respective terminals of the multiple users,<br/>
a condition determining part that determines or recognizes whether the respective digital data was created within a preset place condition by referring to information on current locations provided by location recognition modules of the respective terminals and whether the respective digital data was created within a preset scope of the time by referring to information acquired by time recognition modules thereof,<br/>
a user selecting part that selects a specified group of users, including a first to an n-th users among the multiple users, who create the digital data within the preset place condition and within the preset scope of the time, and<br/>
a reward information managing part that provides information on rewards for users included in the specified group of users.<!-- EPO <DP n="23"> --></claim-text></claim><claim id="c-en-0027" num="0027"><claim-text>The server recited in Claim 26 wherein,<br/>
the reward information managing part provides mission information, in relation with the object, that may be performed and reward information that is provided if the mission is performed</claim-text></claim><claim id="c-en-0028" num="0028"><claim-text>This server recited in Claim 27 wherein,<br/>
the mission information includes information for which two or more users make a request to create digital data on the object at the same place simultaneously.</claim-text></claim><claim id="c-en-0029" num="0029"><claim-text>A computer-readable recording medium on which a computer program is recorded to<br/>
execute the method according to any one of Claim 1 to Claim 14.</claim-text></claim></claims><drawings mxw-id="PDW16670418" load-source="patent-office"><!-- EPO <DP n="24"> --><figure id="f0001" num="1,2,3a"><img id="if0001" file="imgf0001.tif" wi="130" he="206" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="25"> --><figure id="f0002" num="3b,4"><img id="if0002" file="imgf0002.tif" wi="127" he="230" img-content="drawing" img-format="tif"/></figure></drawings><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
