<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2682899-A2" country="EP" doc-number="2682899" kind="A2" date="20140108" family-id="48740929" file-reference-id="257354" date-produced="20180824" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="146584853" ucid="EP-2682899-A2"><document-id><country>EP</country><doc-number>2682899</doc-number><kind>A2</kind><date>20140108</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-13174840-A" is-representative="YES"><document-id mxw-id="PAPP154847045" load-source="docdb" format="epo"><country>EP</country><doc-number>13174840</doc-number><kind>A</kind><date>20130703</date><lang>EN</lang></document-id><document-id mxw-id="PAPP226109166" load-source="docdb" format="original"><country>EP</country><doc-number>13174840.2</doc-number><date>20130703</date></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC140549194" ucid="JP-2012149865-A" load-source="docdb"><document-id format="epo"><country>JP</country><doc-number>2012149865</doc-number><kind>A</kind><date>20120703</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL-2092281225" load-source="docdb">G06K   9/00        20060101AFI20150127BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-1848629537" load-source="docdb" scheme="CPC">G08G   1/166       20130101 LI20170210BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1848635385" load-source="docdb" scheme="CPC">G08G   1/167       20130101 LI20170210BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989649182" load-source="docdb" scheme="CPC">G06K   9/00825     20130101 LI20130917BHEP        </classification-cpc><classification-cpc mxw-id="PCL1991312649" load-source="docdb" scheme="CPC">H04N   7/18        20130101 FI20140102BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT132359192" lang="DE" load-source="patent-office">Umgebungserkennungsvorrichtung</invention-title><invention-title mxw-id="PT132359193" lang="EN" load-source="patent-office">Environment recognition device</invention-title><invention-title mxw-id="PT132359194" lang="FR" load-source="patent-office">Dispositif de reconnaissance d'environnement</invention-title><citations><patent-citations><patcit mxw-id="PCIT242942472" load-source="docdb" ucid="JP-2000011298-A"><document-id format="epo"><country>JP</country><doc-number>2000011298</doc-number><kind>A</kind><date>20000114</date></document-id><sources><source name="APP" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT242942473" load-source="docdb" ucid="JP-2005346287-A"><document-id format="epo"><country>JP</country><doc-number>2005346287</doc-number><kind>A</kind><date>20051215</date></document-id><sources><source name="APP" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT242942471" load-source="docdb" ucid="JP-H08193831-A"><document-id format="epo"><country>JP</country><doc-number>H08193831</doc-number><kind>A</kind><date>19960730</date></document-id><sources><source name="APP" created-by-npl="N"/></sources></patcit></patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR919540755" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>CLARION CO LTD</last-name><address><country>JP</country></address></addressbook></applicant><applicant mxw-id="PPAR919526182" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>CLARION CO., LTD.</last-name></addressbook></applicant><applicant mxw-id="PPAR919007803" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Clarion Co., Ltd.</last-name><iid>101216579</iid><address><street>7-2, Shintoshin Chuo-ku Saitama-shi</street><city>Saitama 330-0081</city><country>JP</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR919520517" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>UTAGAWA Akira</last-name><address><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR919516509" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>Utagawa, Akira</last-name></addressbook></inventor><inventor mxw-id="PPAR919008937" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Utagawa, Akira</last-name><address><street>c/o Hitachi, Ltd., Intellectual Property Group 6-1, Marunouchi 1-chome, Chiyoda-ku</street><city>Tokyo, 100-8220</city><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR919527728" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>TAKEMURA MASAYUKI</last-name><address><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR919521286" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>TAKEMURA, MASAYUKI</last-name></addressbook></inventor><inventor mxw-id="PPAR919014876" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>TAKEMURA, MASAYUKI</last-name><address><street>c/o Hitachi, Ltd., Intellectual Property Group 6-1, Marunouchi 1-chome, Chiyoda-ku</street><city>Tokyo, 100-8220</city><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR919530249" load-source="docdb" sequence="3" format="epo"><addressbook><last-name>MURAMATSU SHOJI</last-name><address><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR919521040" load-source="docdb" sequence="3" format="intermediate"><addressbook><last-name>MURAMATSU, SHOJI</last-name></addressbook></inventor><inventor mxw-id="PPAR919010179" load-source="patent-office" sequence="3" format="original"><addressbook><last-name>MURAMATSU, SHOJI</last-name><address><street>c/o Hitachi, Ltd., Intellectual Property Group 6-1, Marunouchi 1-chome, Chiyoda-ku</street><city>Tokyo, 100-8220</city><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR919522066" load-source="docdb" sequence="4" format="epo"><addressbook><last-name>KIYOHARA MASAHIRO</last-name><address><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR919514709" load-source="docdb" sequence="4" format="intermediate"><addressbook><last-name>KIYOHARA, MASAHIRO</last-name></addressbook></inventor><inventor mxw-id="PPAR919012132" load-source="patent-office" sequence="4" format="original"><addressbook><last-name>KIYOHARA, MASAHIRO</last-name><address><street>c/o Hitachi, Ltd., Intellectual Property Group 6-1, Marunouchi 1-chome, Chiyoda-ku</street><city>Tokyo, 100-8220</city><country>JP</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR919008854" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>MERH-IP Matias Erny Reichl Hoffmann</last-name><iid>101060911</iid><address><street>Paul-Heyse-Strasse 29</street><city>80336 MÃ¼nchen</city><country>DE</country></address></addressbook></agent></agents></parties><international-convention-data><designated-states><ep-contracting-states><country mxw-id="DS549741550" load-source="docdb">AL</country><country mxw-id="DS549809550" load-source="docdb">AT</country><country mxw-id="DS549739922" load-source="docdb">BE</country><country mxw-id="DS549738256" load-source="docdb">BG</country><country mxw-id="DS549907292" load-source="docdb">CH</country><country mxw-id="DS549739923" load-source="docdb">CY</country><country mxw-id="DS549811687" load-source="docdb">CZ</country><country mxw-id="DS549741552" load-source="docdb">DE</country><country mxw-id="DS549739924" load-source="docdb">DK</country><country mxw-id="DS549739925" load-source="docdb">EE</country><country mxw-id="DS549739540" load-source="docdb">ES</country><country mxw-id="DS549738257" load-source="docdb">FI</country><country mxw-id="DS549907293" load-source="docdb">FR</country><country mxw-id="DS549741557" load-source="docdb">GB</country><country mxw-id="DS549739926" load-source="docdb">GR</country><country mxw-id="DS549741558" load-source="docdb">HR</country><country mxw-id="DS549811688" load-source="docdb">HU</country><country mxw-id="DS549739565" load-source="docdb">IE</country><country mxw-id="DS549739927" load-source="docdb">IS</country><country mxw-id="DS549738258" load-source="docdb">IT</country><country mxw-id="DS549739928" load-source="docdb">LI</country><country mxw-id="DS549738259" load-source="docdb">LT</country><country mxw-id="DS549739267" load-source="docdb">LU</country><country mxw-id="DS549738260" load-source="docdb">LV</country><country mxw-id="DS549738265" load-source="docdb">MC</country><country mxw-id="DS549739268" load-source="docdb">MK</country><country mxw-id="DS549739269" load-source="docdb">MT</country><country mxw-id="DS549739566" load-source="docdb">NL</country><country mxw-id="DS549812218" load-source="docdb">NO</country><country mxw-id="DS549739567" load-source="docdb">PL</country><country mxw-id="DS549738266" load-source="docdb">PT</country><country mxw-id="DS549811689" load-source="docdb">RO</country><country mxw-id="DS549738267" load-source="docdb">RS</country><country mxw-id="DS549739568" load-source="docdb">SE</country><country mxw-id="DS549907294" load-source="docdb">SI</country><country mxw-id="DS549812219" load-source="docdb">SK</country><country mxw-id="DS549812220" load-source="docdb">SM</country><country mxw-id="DS549739270" load-source="docdb">TR</country></ep-contracting-states><ep-extended-states><ep-extended-state-data><country>BA</country></ep-extended-state-data><ep-extended-state-data><country>ME</country></ep-extended-state-data></ep-extended-states></designated-states></international-convention-data></bibliographic-data><abstract mxw-id="PA128673025" lang="EN" load-source="patent-office"><p id="pa01" num="0001">An environment recognition device includes: an image acquisition unit; a light spot feature amount extraction unit (102) that extracts a feature amount of a light spot from the image; a lens dirtiness judgment unit (103) that judges dirt adhering to a surface of a lens of the imaging unit; a headlight detection condition setting unit (104) that sets, based on result of judgment by the lens dirtiness judgment unit (103), in a parameter that is preliminarily related, a detection condition under which a light spot extracted by the light spot feature amount extraction unit (102) is judged to be a headlight; an approaching headlight judgment unit (105) that judges a particular light spot out of the light spots that corresponds to the parameter as an approaching headlight based on the parameter; and a vehicle annunciation signal outputting unit (106) that outputs a vehicle annunciation signal based on detection result of the approaching headlight judgment unit (105).
<img id="iaf01" file="imgaf001.tif" wi="95" he="80" img-content="drawing" img-format="tif"/></p></abstract><abstract mxw-id="PA128737170" lang="EN" source="EPO" load-source="docdb"><p>An environment recognition device includes: an image acquisition unit; a light spot feature amount extraction unit (102) that extracts a feature amount of a light spot from the image; a lens dirtiness judgment unit (103) that judges dirt adhering to a surface of a lens of the imaging unit; a headlight detection condition setting unit (104) that sets, based on result of judgment by the lens dirtiness judgment unit (103), in a parameter that is preliminarily related, a detection condition under which a light spot extracted by the light spot feature amount extraction unit (102) is judged to be a headlight; an approaching headlight judgment unit (105) that judges a particular light spot out of the light spots that corresponds to the parameter as an approaching headlight based on the parameter; and a vehicle annunciation signal outputting unit (106) that outputs a vehicle annunciation signal based on detection result of the approaching headlight judgment unit (105).</p></abstract><description mxw-id="PDES63959013" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><p id="p0001" num="0001">The disclosure of the following priority application(s) is/are herein incorporated by reference: <patcit id="pcit0001" dnum="JP2012149865A"><text>2012-149865 filed July 3, 2012</text></patcit>.</p><p id="p0002" num="0002">The present invention relates to an environment recognition device, which recognizes a vehicle that is running behind one's own vehicle.</p><p id="p0003" num="0003"><patcit id="pcit0002" dnum="JP2000011298A"><text>JP 2000-11298 A</text></patcit> proposes a rear and side monitoring device for a vehicle that detects a traffic lane and can give a warning to the driver that it is risky to change the present traffic lane based on result of detection of the traffic lane if it is judged that such is necessary.</p><p id="p0004" num="0004"><patcit id="pcit0003" dnum="JPH08193831A"><text>JP H08-193831 A</text></patcit> discloses a rear and side monitoring device for a vehicle that correctly grasps an inter-vehicular distance between one's own vehicle and a vehicle approaching thereto and a relative speed between one's own vehicle and the approaching vehicle to properly detect a vehicle that possibly approaches too much to the one's own vehicle so that a proper warming can be given.</p><p id="p0005" num="0005"><patcit id="pcit0004" dnum="JP2005346287A"><text>JP 2005-346287 A</text></patcit> proposes an image recognizing method and apparatus for stably recognizing an object to be recognized independently of a change in a distance up to the object to be recognized.</p><p id="p0006" num="0006">What is important for a warning device that gives a warning in case that upon changing the traffic lane, there exists a highly risky vehicle on a traffic lane to which one's own vehicle is going to change its lane is to detect a vehicle stably as much as possible before a warning can be given. This is called a rear and side (posterolateral) blind angle warning. In order to realize this function by capturing images of rearward by an imaging device such as a camera, it is necessary to set the imaging device (e.g., camera) at a position where there will be no blind angle therefor. That is, it is necessary to set the imaging device at the outside of the vehicle interior, for example, left and right side-mirror sections or a bumper section, so that the imaging device will not be hindered its field of view by the one's own vehicle. According to the present invention, attention is paid to a problem to be solved when realizing rear and side blind angle warning by image recognition using a rear-side camera outside of the vehicle interior that is set at the bumper section.<!-- EPO <DP n="2"> --></p><p id="p0007" num="0007">When realizing the rear and side blind angle warning by image recognition using a camera, it is necessary to take into consideration that recognition performance varies from an image to an image. More specifically, images that can be obtained from a camera may differ greatly between a case of running on a dry road surface in a shiny daytime and a case of running on a wet road surface in a rainy nighttime, and hence required recognition performance may greatly differ between the above two cases. When a car is driven in a time zone of from evening to night, as compared with daytime, images may differ greatly in brightness between daytime and nighttime. In addition, images may differ because one's own vehicle and another vehicle run with their headlights and tail lamps being lit, images may become different depending on whether or not there are street lamps and whether or not there is reflection of light by a reflector on the road surface or on a guiderail, and so on.</p><p id="p0008" num="0008">In case that the camera is set at outside of the vehicle interior, there is a possibility that during the running, dirt such as fugitive dust, mud, water droplets, or the like on the road surface is swirled up and adheres to a surface of the lens. If the dirt adheres to the surface of lens (hereafter, sometimes referred to as "lens surface" for short), images will be changed. As a result, if the running of the vehicle is continued without removing the dirt on the lens surface, recognition performance of the warning device will be changed depending on the degree of dirtiness of the lens surface caused by the dirt but independently of the actual weather. In order to realize the rear and side blind angle warning by image recognition by using a camera set at the outside of the vehicle interior, there is a need for a blind angle warning device that can minimize performance degradation by the dirt that adheres to the lens surface.</p><p id="p0009" num="0009">An object to which a particular attention is to be paid is to increase the performance of detection of a vehicle (hereafter sometimes referred to as "vehicle detection", for short) at nighttime when the dirt adheres to the lens surface. So far as the detection of a vehicle is to be performed by image recognition, presence or absence of vehicles is judged based on feature amounts on the basis of brightness, contrast and edge of images. If slight dirtiness is present on the lens surface, the entire image will have a decreased contrast and hence the image as a whole is expressed somewhat blurred as compared with the case in which no dirt adheres to the lens surface. Since images obtained at nighttime contain lower feature amounts of the vehicle, it is necessary to perform vehicle detection using the lower feature amounts in combination with information about headlight and tail lamp. Furthermore, in case that slight dirtiness is present on the lens, it<!-- EPO <DP n="3"> --> may happen that no feature amount of a vehicle can be obtained from the images obtained at nighttime. That is, in order to perform vehicle detection at nighttime in case that slight dirtiness is present on the lens, it is necessary to extract a headlight from light spots that are constituted by high brightness regions and perform vehicle detection based on the detected headlights since no vehicle body is recognizable.</p><p id="p0010" num="0010">According to the technology of <patcit id="pcit0005" dnum="JP2000011298A"><text>JP 2000-11298 A</text></patcit>, a lane marking in the view field of the rear-side camera is not always clear at nighttime and hence it is difficult to judge whether or not approaching the lane marking. In addition, since no countermeasure to the dirt adhering to the lens is provided, there may occur non-detection of a vehicle or erroneous detection of a vehicle in which an object other than a vehicle is judged to be a vehicle due to the dirtiness of lens. Furthermore, at nighttime, the visibility of a vehicle is decreased, so that the accuracy of detection is greatly decreased.</p><p id="p0011" num="0011">According to the technology of <patcit id="pcit0006" dnum="JPH08193831A"><text>JP H08-193831 A</text></patcit>, no consideration is made on the dirtiness of the lens of the camera and hence it is difficult to give a warning at a proper timing. This is because if the size of a light spot varies because of the lens dirtiness, result of calculation of the relative position of another vehicle varies.</p><p id="p0012" num="0012">The device disclosed in <patcit id="pcit0007" dnum="JP2005346287A"><text>JP 2005-346287 A</text></patcit> is not equipped with a mechanism that dynamically switches vehicle judgment patterns to an optimal one according to each situation when images vary depending on weather and time zone. Since no consideration is made on the state of lens dirtiness, the vehicle judgment pattern is not optimal when the lens is dirty.</p><p id="p0013" num="0013">From the above, the present invention has for its object to provide an environment recognition device that performs vehicle detection stably even if the lens of the imaging device is dirty.</p><p id="p0014" num="0014">In order to solve the above problem, the environment recognition device according to a first aspect of the present invention comprises: an image acquisition unit that acquires an image; a light spot feature amount extraction unit that extracts a feature amount of a light spot from the image; a lens slight dirtiness judgment unit that judges dirt adhering to a surface of a lens of an imaging unit; a headlight detection condition setting unit that sets, based on result of judgment by the lens slight dirtiness judgment unit, in a parameter that is preliminarily related, a detection condition under which a light spot out of the light spots extracted by the light spot feature amount extraction unit is judged to be a headlight; an approaching headlight judgment unit that judges a particular light spot out of the light spots that corresponds to the parameter as an approaching headlight based on<!-- EPO <DP n="4"> --> the parameter set by the headlight detection condition setting unit; and / or a vehicle annunciation signal outputting unit that outputs a vehicle annunciation signal based on a result of the detection by the approaching headlight judgment unit.</p><p id="p0015" num="0015">The environment recognition device according to a second aspect of the present invention comprises: an image acquisition unit that acquires an image; a light spot feature amount extraction unit that extracts a feature amount of a light spot from the image; a high brightness feature amount analysis unit that acquires an image state of the acquired image based on the feature amount of the light spot extracted by the light spot feature amount extraction unit; a headlight detection condition setting unit that sets, based on the image state acquired by the high brightness feature amount analysis unit, in a parameter that is preliminarily related, a detection condition under which a light spot out of light spots extracted by the light spot feature amount extraction unit is judged to be a headlight; an approaching headlight judgment unit that judges a particular light spot out of the light spots that corresponds to the parameter as an approaching headlight based on the parameter set by the headlight detection condition setting unit; and / or a vehicle annunciation signal outputting unit that outputs a vehicle annunciation signal based on a result of the detection by the approaching headlight judgment unit.</p><p id="p0016" num="0016">The environment recognition device according to a third aspect of the present invention comprises: an image acquisition unit that acquires an image; a lens dirtiness judgment unit that judges dirt adhering to a surface of a lens of the imaging unit; a headlight detection condition setting unit that sets, based on result of judgment by the lens dirtiness judgment unit, in a parameter that is preliminarily related, a detection condition under which a headlight is judged from the image; a light spot feature amount extraction unit that extracts a feature amount of a light spot from the image; an optical flow unit that detects a position and a speed of another vehicle from a temporal variation of a feature amount in the image; an approaching vehicle judgment unit that judges whether or not another vehicle is approaching based on the feature amount of the light spot extracted by the light spot feature amount extraction unit or detection result of the optical flow unit; and / or a vehicle annunciation signal outputting unit that outputs a vehicle annunciation signal based on detection result of the approaching vehicle judgment unit, wherein the headlight detection condition setting unit switches, based on the result of judgment by the lens dirtiness judgment unit, between execution of processing by the light spot feature amount extraction unit and execution of processing by the optical flow unit.<!-- EPO <DP n="5"> --></p><heading id="h0001">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p0017" num="0017"><ul><li><figref idrefs="f0001">FIG. 1</figref> presents a diagram showing a constructive example of an environment recognition device according to the present invention;</li><li><figref idrefs="f0002">FIG. 2</figref> presents a diagram showing another constructive example of an environment recognition device according to the present invention;</li><li><figref idrefs="f0003">FIG. 3</figref> presents a diagram showing a constructive example of the light spot feature amount extraction unit according to the present invention;</li><li><figref idrefs="f0004">FIG. 4</figref> presents a diagram showing a constructive example of the headlight detection condition setting unit shown in <figref idrefs="f0002">FIG. 2</figref>;</li><li><figref idrefs="f0005">FIG. 5</figref> presents a diagram showing another constructive example of an environment recognition device according to the present invention;</li><li><figref idrefs="f0006">FIG. 6</figref> presents a diagram showing another constructive example of an environment recognition device according to the present invention;</li><li><figref idrefs="f0007">FIG. 7A</figref> presents a diagram showing an example of an image captured by a rear-side camera according to the present invention;</li><li><figref idrefs="f0007">FIG. 7B</figref> presents a diagram showing an example of an image captured by a rear-side camera according to the present invention;</li><li><figref idrefs="f0008">FIG. 8A</figref> presents a diagram explaining processing of a light spot feature amount extraction unit according to the present invention;</li><li><figref idrefs="f0008">FIG. 8B</figref> presents a diagram explaining processing of a light spot feature amount extraction unit according to the present invention;</li><li><figref idrefs="f0008">FIG. 8C</figref> presents a diagram explaining processing of a light spot feature amount extraction unit according to the present invention;</li><li><figref idrefs="f0008">FIG. 8D</figref> presents a diagram explaining processing of a light spot feature amount extraction unit according to the present invention;</li><li><figref idrefs="f0009">FIG. 9A</figref> presents a diagram explaining processing of a headlight detection condition setting unit according to the present invention.</li><li><figref idrefs="f0009">FIG. 9B</figref> presents a diagram explaining processing of a headlight detection condition setting unit according to the present invention.</li><li><figref idrefs="f0009">FIG. 9C</figref> presents a diagram explaining processing of a headlight detection condition setting unit according to the present invention.</li></ul></p><heading id="h0002">DETAILED DESCRIPTION OF THE INVENTION</heading><p id="p0018" num="0018">Hereafter, an embodiment is explained wither reference to the drawings.<!-- EPO <DP n="6"> --></p><heading id="h0003">FIRST EMBODIMENT</heading><p id="p0019" num="0019">Referring to <figref idrefs="f0001">FIG. 1</figref>, an environment recognition device 10 according to a first embodiment of the present invention is explained.</p><p id="p0020" num="0020">The environment recognition device 10 according to a first embodiment comprises an image acquisition unit 101 that acquires an image (frame), a light spot feature amount extraction unit 102 that extracts at least one feature amount of a light spot out of brightness information, time variation and geometry information from the acquired image, a lens dirtiness judgment unit 103 that evaluates and judges slight dirt adhering to a surface of a lens of the imaging unit that is set at the outside of a vehicle interior, a headlight detection condition setting unit 104 that sets, in a parameter that is preliminarily related to and based on a result of judgment by the lens dirtiness judgment unit 103, a condition of detection under which a particular light spot is judged to be a headlight from the light spots extracted by the light spot feature amount extraction unit 102; an approaching headlight judgment unit 105 that judges a particular light spot that corresponds to the parameter out of the light spots as an approaching headlight based on the parameter set by the headlight detection condition setting unit 104; and a vehicle annunciation signal outputting unit 106 that outputs a vehicle annunciation signal based on the condition of detection of the approaching headlight judgment unit 105.</p><p id="p0021" num="0021">The environment recognition device 10 is featured to change a parameter based on which a particular headlight is detected out of the light spots on the basis of a result of judgment by the lens dirtiness judgment unit 103. In case that slight dirt adheres to the lens, a contrast of image decreases and hence vehicle feature amounts contained in the image cannot be obtained sufficiently. When an image obtained at nighttime is used, contrast is already low enough even if no slight dirt adheres to the lens, so that if slight dirt adheres to the lens, it is becomes more difficult to perform vehicle detection. By using the construction according to the present invention, the vehicle detection can be performed properly by adjusting the headlight detection condition even when the lens is slightly dirty. Hereafter, the respective constituent components of the environment recognition device 10 are explained.</p><p id="p0022" num="0022">The lens dirtiness judgment unit 103 performs judgment of slight dirt that is accumulated on the lens of the imaging unit. This is done by various methods and explanation is made in sequence.</p><p id="p0023" num="0023">A first method is to judge whether an image in question is obtained through a lens<!-- EPO <DP n="7"> --> to which slight dirt adheres or not, from the image acquired by the image acquisition unit 101 by using an image processing technology. The judgment can be performed by evaluating a feature amount of the image obtained when slight dirt adheres to the lens. A second method is to estimate a state of the lens being slightly dirty from information about the vehicle or information obtained from environment. For example, when running time is prolonged, the possibility that dirt adheres to the lens becomes higher. According to the method, such information is used or information about an off-road running state of the vehicle is obtained, which is used to detect if the vehicle is in a state in which dirt is more apt to adhere thereto. This method when combined with the first method can tell what types of dirt is apt to adhere depending on the environment of driving, so that the accuracy of evaluation of slight dirtiness can be increased. A third method is to physically scan the dirt that adheres to the lens by using an external sensor. By using the above methods, the state of slight dirtiness of lens (hereafter, sometimes referred to as "lens slight dirtiness" for short) can be acquired.</p><p id="p0024" num="0024">The lens dirtiness judgment unit 103 outputs a degree of lens dirtiness using the above state of slight dirtiness. The output from the lens dirtiness judgment unit 103 may be binary information of whether slight dirtiness is present or absent (present/absent) on the lens, or a normalized index of lens dirtiness expressing the degree of slight dirtiness of lens stepwise depending on density of dirtiness. As compared with a case in which the headlight detection condition is changed based on the binary information of present/absent, use of the headlight detection condition according to stepwise indices of lens dirtiness makes it possible to increase the performance of detecting a headlight. The degree of slight dirtiness of lens may be obtained by calculating the slight dirt that adheres to the lens for every processing cycle or every few processing cycles. When the calculation is performed for every processing cycle, the state of slight dirtiness of lens is instantaneously reflected, so that processing can be always performed based on the newest state of lens. That is, even if the state of lens varies greatly for the reason that there is much swirled matter from the road surface, for example, in the case of rainy weather, or off-road running, always optimal processing can be performed. On the other hand, when calculation is performed for every few cycles, there occurs some delay but instead, it is possible to achieve a decrease in load. The slight dirtiness of lens which is a target of evaluation according to the present invention is dirtiness caused by dirt that has accumulated over a time, so that it is unnecessary to watch always the newest state of lens. Alternatively, an hourly average of results of processing each time may be obtained, which may be output<!-- EPO <DP n="8"> --> as the result of the judgment. In case lens dirtiness over a long time length is a target of evaluation, an extreme value that appears momentary is a noise. So, use of the hourly average is effective in reducing noises. In addition to the degree of dirtiness, a position at which the slight dirt adheres may be output or the type of the slight dirt may be acquired and output together with that information. For example, if it is determined that the slight dirt adheres only on the left side, it is possible to change only the condition relating to the left side, so that occurrence of erroneous detection or non-detection with respect to the right side can be decreased.</p><p id="p0025" num="0025">The light spot feature amount extraction unit 102 can extract, from the image, objects that appear in the image as light spots, such as a headlight/tail lamp of a vehicle, reflected light from the road surface, a street lamp, reflected light from a guardrail, and off-street neon billboard or billboards and so on. A light spot can be extracted as an assembly of pixels having the same feature amount using at least one of feature amounts selected from brightness information, edge strength, and a difference in brightness from peripheral pixels. The extracted light spot is given additional information, i.e., geometry information such as position on the image or shape of block, and at least one time sequence information out of moving speed, change in shape of the light spot and a change in brightness obtained from past frames, and those pieces of information are used for dynamically extracting a necessary light spot depending on the result obtained by the lens dirtiness judgment unit 103.</p><p id="p0026" num="0026">The headlight detection condition setting unit 104 related to the result of judgment of the slight dirtiness extracts a particular light spot based on the feature amount of the light spot out of the light spots that matches the feature amount condition of a light spot that is preliminarily set and deems that light spot to be a headlight. The condition under which a light spot is judged to be a headlight may be constituted by at least one of factors, for example, position, area, brightness or brightness distribution, temporal direction of change of position of light spot in the image.</p><p id="p0027" num="0027">The approaching headlight judgment unit 105 generates a headlight judgment signal based on the result obtained by the headlight detection condition setting unit 104.</p><p id="p0028" num="0028">The vehicle annunciation signal outputting unit 106 outputs an annunciation signal based on the result of judgment by the approaching headlight judgment unit 105.</p><heading id="h0004">SECOND EMBODIMENT</heading><p id="p0029" num="0029">The environment recognition device 10 according to a second embodiment is<!-- EPO <DP n="9"> --> shown in <figref idrefs="f0002">FIG. 2</figref>. This embodiment differs when compared with the embodiment shown in <figref idrefs="f0001">FIG. 1</figref> in that instead of the lens dirtiness judgment unit 103 and the headlight detection condition setting unit 104 related to the result of the judgment of slight dirtiness, the environment recognition device according to the second embodiment comprises a high brightness feature amount analysis unit 201 and a headlight detection condition setting unit 202 that is related to the result of the high brightness feature amount analysis unit 201. The high brightness feature amount analysis unit 201 uses image information and light spot feature amounts obtained from at least one of the image acquisition unit 101 and the light spot feature amount extraction unit 102 and acquires an image state that corresponds to lens slight dirtiness by image analysis. The effect achieved by using this means is that it is possible to judge a case where it is difficult to recognize vehicles at nighttime although actually slight dirt does not adhere to the lens, and it is possible to perform vehicle detection using an optimal headlight detection condition. For example, in case of it being foggy, it may happen due to a decrease in visibility in an image that the image having a quality equivalent to that of an image obtained when the lens is in a state in which slight dirt adheres thereto although actually it is not the case that slight dirt adheres to the lens and thus the performance of vehicle detection is decreased in the same manner as that in the case where actually slight dirt adheres to the lens. Even in such a case, it is possible to detect a decrease in visibility similarly to the case of the slight dirtiness of lens, so that optimal vehicle detection can be performed by detection of a headlight.</p><p id="p0030" num="0030">The content of processing is specifically explained. The light spot feature amount extraction unit 102 may be configured as shown in, for example, <figref idrefs="f0003">FIG. 3</figref>. A light spot region extraction unit 301 can extract a light spot region from the acquired image and output the extracted region. A labeling processing unit 302 assigns a number that is called "label number" to each region. The label number is unique to each region. A light spot geometry information selection unit 303 calculates position of gravity center and area of the region and evaluates whether or not the region is to be stored based on the calculated geometry information (position of gravity center and size of the region), so that it is possible to prevent unnecessary light spot information from being stored. By using the stored light spot information, calculation is performed what a position in real world the light spot is found when it is converted into a bird's eye view. A light spot gravity center position obtaining unit 304 can perform this calculation based on an assumption that the gravity center position of a light spot exists at the height of the headlight in real space and stores a result together with a corresponding label number.<!-- EPO <DP n="10"> --></p><p id="p0031" num="0031">The function that can be achieved by the configuration shown in <figref idrefs="f0003">FIG. 3</figref> is explained with reference to <figref idrefs="f0008">FIGS. 8A to 8D</figref>. First, the light spot feature amount extraction unit 102 inputs an image containing a road surface and a vehicle and other objects on rear and side of one's own vehicle, that is an output from the image acquisition unit 101 as shown in <figref idrefs="f0008">FIG. 8A</figref>. Here, reference numeral 802 indicates reflected light generated when light from head lights 704, 705 of another vehicle 701 is reflected on the road surface. On the other hand, reference numeral 801 indicates light generated by a light emitting body that is present off-street, such as a street lamp, a billboard of town, a guardrail or illumination of a building, or reflected light of the light from such light emitting body. The light spot region extraction unit 301 extracts light spots from the image. The light spots include light spots other than light from headlights, for example, high brightness regions 801 and 802. <figref idrefs="f0008">FIG. 8B</figref> shows a state in which label numbers are assigned to the light spots extracted by the light spot region extraction unit 301 in order to distinguish individual light spots. On this occasion, in order to remove noises, those light spots that have very small area of a high brightness region are excluded. For this reason, although the region 801 shown in <figref idrefs="f0008">FIG. 8A</figref> contains four high brightness regions whereas in <figref idrefs="f0008">FIG. 8B</figref>, there are two high brightness regions. The light spot geometry information selection unit 303 is explained with reference to <figref idrefs="f0008">FIG. 8C</figref>. In order to remove unnecessary light spot information, the light spots are selected based on area and geometry information. Here, it is assumed that a headlight is close to a circle and reflected light is close to an eclipse. <figref idrefs="f0008">FIG. 8C</figref> illustrates the processing based on this assumption. In this processing, the area of a light spot is compared with the area of a circumscribed rectangle of the light spot. If a ratio of the area of the light spot to the area of the circumscribed rectangle of the light spot is equal to or larger than a predetermined value, the light spot is judged to be a headlight whereas if the ratio is smaller than the predetermined value, the light spot is judged to be reflected light. The light spot geometry information selection unit 303 further performs calculation using a bird's eye view position of the gravity center of light spot. <figref idrefs="f0008">FIG. 8D</figref> shows an example of the calculation. The reference numerals in <figref idrefs="f0008">FIG. 8D</figref> correspond to those in <figref idrefs="f0008">FIG. 8C</figref>. In <figref idrefs="f0008">FIG. 8D</figref>, reference numeral 803 represents a light spot farther than others and thus it is depicted more rearward in <figref idrefs="f0008">FIG. 8D</figref>. Reference numeral 807 represents a light spot that is present off-street and reference numerals 805, 806 represent headlights of a vehicle that runs on a next traffic lane, they are depicted at their respective bird's eye view positions, with the 805, 806 being depicted as light spots on the adjacent traffic lane.</p><p id="p0032" num="0032">The high brightness feature amount analysis unit 201 can be implemented by the<!-- EPO <DP n="11"> --> following method. The characteristic features that appear on the image when the lens is in a state of slight dirtiness are explained with reference to <figref idrefs="f0007">FIGS. 7A and 7B. FIGS. 7A and 7B</figref> present each a schematic diagram showing an image captured by a rear-side camera on the vehicle.</p><p id="p0033" num="0033"><figref idrefs="f0007">FIG. 7A</figref> presents a diagram showing an image of a rearward of the own vehicle at nighttime captured by using a clean lens without dirt adhering thereto. <figref idrefs="f0007">FIG. 7B</figref> presents a diagram showing an image of a rearward of the own vehicle at nighttime captured by using a lens with slight dirt thereon. Reference numeral 702 designates a white line. The white line divides the road surface into a traffic lane on which one's own vehicle runs, a right-side adjacent lane that is adjacent to the right side of the own vehicle and a left-side adjacent lane that is adjacent to the left side of the own vehicle. Reference numeral 701 designates a vehicle that runs on the left-side adjacent lane, with a front section and a right side of the vehicle being depicted by using a box. Reference numeral 704 designates an inside headlight and reference numeral 705 designates an outside headlight. Reference numeral 703 designates a headlight of a vehicle farther than the vehicle 701. <figref idrefs="f0007">FIG. 7A</figref> indicates that when the lens is not in a state of being slightly dirty, an actual shape of a light spot (here, headlight) substantially corresponds to the shape of the light spot on the frame.</p><p id="p0034" num="0034">On the other hand, <figref idrefs="f0007">FIG. 7B</figref> indicates that when the lens is in a state of being slightly dirty, the actual shape of the light spot differs from the shape of the light spot on the image. The broken line in <figref idrefs="f0007">FIG. 7B</figref> shows the actual shape of a headlight and indicates that on the image, due to the lens slight dirtiness, the headlights 703, 704, 705 in <figref idrefs="f0007">FIG. 7A</figref> are seen larger than what they actually are, as indicated by reference numerals 706, 707, 708 in <figref idrefs="f0007">FIG. 7B</figref>. When the lens is in a state of being slightly dirty, the light irradiated from the light spot comes in the slight dirt before it comes in the lens. Since the incident light is diffused by the slight dirt, the light that comes in the lens will be broader than it actually is. By this effect, even if the vehicle body should have originally been captured in the image, the vehicle body could not be visually recognized in the image because of halation due to reflection of light caused by the slight dirt on the lens. If this characteristic can be detected in the image, a state that is desired to be detected can be judged. For example, a high brightness feature amount, which is necessary for setting conditions of a light spot when the lens is in a state of being slightly dirty, can be obtained from brightness distribution of the light spot. Area of a high brightness region and breadth of light in a spatial direction obtained when calculating a change of brightness in a temporal and spatial directions<!-- EPO <DP n="12"> --> obtained from the whole or a portion of the image acquired by the image acquisition unit 101 can be output as the high brightness feature amount.</p><p id="p0035" num="0035">The headlight detection condition setting unit 202, which is related to a result of the high brightness feature amount analysis unit 201, can be implemented by the configuration shown in <figref idrefs="f0004">FIG. 4</figref>. The headlight detection condition setting unit 202, which is related to a result of the high brightness feature amount analysis unit 201, comprises an area condition setting unit 401 that when the result obtained by the high brightness feature amount analysis unit 201 is that the lens is in a state of being slightly dirty, sets the magnitude of area that is to be judged as a headlight on the basis of the magnitude of area that a light spot occupies in the image; a moving direction condition setting unit 402 that sets a condition under which a light spot is to be judged as a headlight, that is, how close or far the light spot on a current image is to or from the light spot in a previous image; a shape condition setting unit 403 that sets a condition on a shape of a light spot under which a particular light spot out of light spots is to be judged as a headlight; and a position condition setting unit 404 that sets a condition under which a particular light spot out of light spots is to be judged as a headlight, that is, what coordinates the gravity center of the particular light spot should have or what coordinates the four contact points of a circumscribed rectangle of the particular light spot should have in order for the particular light spot to be judged as a headlight.</p><p id="p0036" num="0036">The area condition setting unit 401 can decrease the occurrence of non-detection when the lens is with dirt by setting an area threshold value when the lens is with dirt smaller than an area threshold value when the lens is without dirt. Alternatively, the area condition setting unit 401 can decrease occurrence of erroneous detection when the lens is with dirt by setting the area threshold value when the lens is with dirt larger than the area threshold value when the lens is without dirt.</p><p id="p0037" num="0037">The moving direction condition setting unit 402 performs judgment whether or not a light spot is deemed as a headlight based on a moving direction and a distance of movement of the light spot. Generally, in case that a light spot in an image is a headlight, it can move in any direction, so that it is difficult to judge a light spot to be a headlight only based on whether the light spot is approaching to or leaving from the own vehicle. To secure minimum performance when the lens is with slight dirt, it is useful to add a condition that the light spot is approaching. It is possible that a leaving light spot is an object at rest. On the other hand, it is highly possible that a light spot that is approaching and satisfies conditions other than those set by the moving direction condition setting unit<!-- EPO <DP n="13"> --> 402 is a headlight of an approaching vehicle. Therefore, the moving direction condition setting unit 402 sets as a condition that when the lens is with slight dirt, a light spot in an image should be approaching at a speed within a predetermined range. When no dirt adheres to the lens, if a light spot that moves at a low speed is judged to be a headlight, there is a possibility that a headlight of a vehicle that is running outside of the adjacent traffic lane may be erroneously detected. For this reason, it is advisable to set a condition that the speed of the light spot should be equivalent to or higher than a predetermined threshold value in order to exclude light spots at low speeds. On the other hand, when the lens is with slight dirt, there is not so high a possibility that the reflected light is erroneously detected, so that the moving speed threshold value may be set at a value lower than that when the lens is without dirt.</p><p id="p0038" num="0038">The shape condition setting unit 403 may set a headlight detection condition paying attention to the property that when the lens is with slight dirt, a light spot broadens due to the slight dirt. Accordingly, a light spot being closer to a circle in shape may be adopted as a headlight detection condition. However, a light spot being closer to a circle in shape may be used as the headlight detection condition regardless of whether or not the lens is with slight dirt thereon. This is effective in decreasing erroneous detection making good use of the fact that reflected light from the road surface and reflected light from a guardrail appear each as a slender light. In addition, when the lens is with slight dirt, reflected light has low brightness due to the dirt, so that the possibility of erroneous detection is decreased. Therefore, by decreasing a threshold value for determining whether or not the shape of a light spot is close to a circle, the occurrence of non-detection can be decreased.</p><p id="p0039" num="0039">Referring to <figref idrefs="f0009">FIGS. 9A to 9C</figref>, explanation is made on important points about the headlight detection condition setting unit 202 related to the result of analysis by the high brightness feature amount analysis unit 201. Referring to <figref idrefs="f0009">FIGS. 9A and 9B</figref>, the setting by the moving direction condition setting unit 402 is explained. <figref idrefs="f0009">FIG. 9A</figref> presents a diagram showing an image at present time that is acquired by the rear-side camera. On the other hand, <figref idrefs="f0009">FIG. 9B</figref> presents a diagram showing an image at a next time that is acquired by the rear-side camera. Reference numeral 901 designates a position of gravity center of an inside headlight at present time of another vehicle and reference numeral 902 designates a position of gravity center of the inside headlight of the other vehicle at next time. In <figref idrefs="f0009">FIG. 9B</figref>, comparing the position 901 of gravity center of the light spot at present time with the position 902 of gravity center of the light spot at next time, it can be seen that the position<!-- EPO <DP n="14"> --> 902 is closer to the own vehicle than the position 901 is. The moving direction of a light spot is considered as a condition. First, roughly, there are two types. One is a case in which the light spot is moving rearward, that is, the light spot is leaving from the own vehicle and a case in which the light spot is moving frontward, that is, the light spot is approaching to the own vehicle. The moving direction of the other vehicle can be any one of them and hence it cannot be said that a leaving light spot is other than a vehicle. Even if an approaching light spot is present on the adjacent traffic lane, it is also possible that reflected light of the headlight of the other vehicle that is running outside the adjacent traffic lane is present on the adjacent traffic lane. Accordingly, an approaching light spot does not always mean that it is a vehicle on the adjacent traffic lane. However, if slight dirt adheres to the lens, the light spot as a whole tends to expand in images and it is difficult to obtain feature amounts of the vehicle. Accordingly, in case that it can be seen from the images that there is a high risk, it is no problem to determine that the approaching light spot on the adjacent traffic lane is a vehicle. Due to the slight dirt, reflected light having not so high a brightness becomes difficult to be seen, so that even if the approaching light spot is deemed to be a vehicle, the frequency of occurrence of erroneous detection does not increase so much.</p><p id="p0040" num="0040">Referring to <figref idrefs="f0009">FIG. 9C</figref>, explanation is made on operations of the positional condition setting unit 404. A right-side adjacent lane width 905, a left-side adjacent lane width 906 and a near position 907, in principle, are set at predetermined positions based on the own vehicle's rear and right side vehicle detection region 903 and the own vehicle's rear and left side vehicle detection region 904 that are set based on the lane positions. To decrease occurrence of non-detection of a vehicle when the lens is with slight dirt, the right side adjacent traffic lane width 905 and left side adjacent traffic lane width 906 may be set wider than those in case that the lens is without dirt. On the other hand, to suppress occurrence of erroneous detection, the right side adjacent traffic lane width 905 and left side adjacent traffic lane width 906 may be set narrower than those in case that the lens is without dirt. The near position 907 is changed when the annunciation signal generation timing is to be put forward or backward.</p><heading id="h0005">THIRD EMBODIMENT</heading><p id="p0041" num="0041">According to a third embodiment, the optical flow and the light spot feature amount extraction are switched between them based on a headlight detection condition related to the slight dirtiness judgment. <figref idrefs="f0005">FIG. 5</figref> shows a configuration of the device<!-- EPO <DP n="15"> --> according to the third embodiment.</p><p id="p0042" num="0042">In a case other than the case where slight dirtiness detection is performed, it is supposed that the visibility of the vehicle body section is high, and vehicle feature amounts are extracted by using a vehicle detection logic, which detects a position and a speed of another vehicle from temporal variation of feature amounts in the image by an optical flow unit 501 that uses an optical flow instead of light spot feature amounts. In a case where slight dirtiness judgment is performed, it is supposed that the visibility of the body section of a vehicle is low, and hence when it is attempted to extract feature amounts by using optical flow, it is difficult to obtain correct results. Instead, feature amounts of a headlight of a vehicle are extracted. With the optical flow, it is difficult to perform correct detection at nighttime, due to the lens with dirt, when pattern matching is done after the feature amounts are extracted whereas light spot extraction allows extraction of a light spot that is characteristic of slight dirt. That is, either the light spot feature amount extraction unit 102 or the optical flow unit 501 is used by switching them. In case that lens dirtiness judgment is not performed, it is deemed that the visibility of the vehicle body of an approaching vehicle is high, and vehicle detection using optical flow is performed. On the other hand, in case that the lens is judged to be dirty, the visibility of the vehicle body is low so that feature amount detection using optical flow gives low reliability. Accordingly in this case, vehicle detection by detecting a headlight based on light spot extraction is performed to secure reliability. In other words, by switching the optical flow and the light spot extraction function based on the lens dirtiness judgment, it is possible to perform vehicle detection solely with this device independently of whether or not the lens is with dirt. An approaching vehicle judgment unit 502 judges whether or not another vehicle is approaching based on the feature amounts of the light spot extracted by the light spot feature amount extraction unit 102 or based on the detection result of the optical flow unit 501. The vehicle annunciation signal outputting unit 106 outputs a vehicle annunciation signal to the outside based on the detection result of the approaching vehicle judgment unit 502.</p><heading id="h0006">FOURTH EMBODIMENT</heading><p id="p0043" num="0043">An environment recognition device according to a fourth embodiment of the present invention that can detect a vehicle by pattern matching related to slight dirtiness judgment is explained. <figref idrefs="f0006">FIG. 6</figref> shows the structure of it.</p><p id="p0044" num="0044">First, explanation is made on vehicle detection using pattern matching. A pattern<!-- EPO <DP n="16"> --> matching judgment condition setting unit 601 stores in advance feature amounts prepared based on images of typical vehicle types, such as a sedan, a SUV, a truck, and a bus, type by type as vehicle data. A vehicle detection condition setting unit 602 extracts a portion of images acquired in an actual driving environment and calculates feature amounts of the extracted image similar to the preliminary stored vehicle data. Then, the result of calculation is compared with the vehicle data type by type. If vehicle data of a vehicle type that has the highest similarity is found, a result of evaluation that it is highly possible that the corresponding type of vehicle is present on the adjacent traffic lane is output. Based on the result, various pieces of information are acquired, such as a depth position and a lateral position of at which the possibility of presence of the other vehicle is highest that is obtained based on a vehicle height which is predetermined according to a vehicle type; duration and strength of warning based on a vehicle length set for each vehicle type (for example, a risk of a truck is higher than a risk of a passenger car, and hence strength of warning for the truck is set higher than the passenger car and so on), information about a brake lamp and a turn signal lamp and so on. The approaching vehicle judgment unit 502 decides whether or not annunciation to the driver is necessary based on the various pieces of information mentioned above. The lateral position of the other vehicle can be used when judgment is performed as to whether or not the other vehicle is present on the adjacent traffic lane. The depth position of the other vehicle is used in combination with the information about moving speed, brake lamp, and turn signal lamp. If it is determined that, depending on the moving speed and the depth of another vehicle, a risk of another vehicle colliding with the own vehicle is high when the own vehicle changes its traffic lane without paying attention to the other vehicle, it is necessary that an annunciation is given. However, a risk may be evaluated higher or lower when a brake lamp or a turn signal lamp, respectively, is turned on. The intensity of risk may determine a degree of an increase or a decrease in the risk when the brake lamp is turned on.</p><p id="p0045" num="0045">Then, explanation is made on the vehicle detection by pattern matching related to the slight dirtiness judgment. In case that the feature amount data for each vehicle type is set independently of whether or not the lens is with dirt thereon, it may happen that the feature amount data of a vehicle contained in the image acquired by the image acquisition unit 101 differs greatly from the feature amount data of the vehicle that is stored in advance even when the vehicle type is the same, and thus, it is difficult to perform the vehicle detection correctly. For this reason, the pattern matching judgment condition setting unit 601 stores the vehicle data for each vehicle type depending on the degree of<!-- EPO <DP n="17"> --> slight dirtiness on the lens and uses the data by switching depending on the degree of dirtiness, so that it is possible to perform vehicle detection correctly when the lens is slightly dirty. According to the present embodiment, the feature amount data of the vehicle that is used in pattern matching can be changed depending on the degree of slight dirtiness of lens and therefore, optimal vehicle detection depending on the degree of slight dirt of lens can be performed. Furthermore, an object to which the present embodiment can be applied is not limited to a headlight. Therefore, vehicle detection can be performed stably even when no headlight is turned on (daytime, etc.) or even when it is impossible to perform vehicle detection only with feature amounts of headlight depending on the type of slight dirt on the lens.</p><p id="p0046" num="0046">According to the embodiments of the present invention, there can be provided an environment recognition device that performs vehicle detection stably at night even if the lens of the imaging device is with dirt.</p><p id="p0047" num="0047">Features, components and specific details of the structures of the above-described embodiments may be exchanged or combined to form further embodiments optimized for the respective application. As far as those modifications are apparent for an expert skilled in the art they shall be disclosed implicitly by the above description without specifying explicitly every possible combination.</p></description><claims mxw-id="PCLM56982034" lang="EN" load-source="patent-office"><!-- EPO <DP n="18"> --><claim id="c-en-0001" num="0001"><claim-text>An environment recognition device comprising:
<claim-text>an image acquisition unit (101) that acquires an image captured by an imaging unit;</claim-text>
<claim-text>a light spot feature amount extraction unit (102) that extracts a feature amount of a light spot from the image;</claim-text>
<claim-text>a lens dirtiness judgment unit (103) that judges dirt adhering to a surface of a lens of the imaging unit;</claim-text>
<claim-text>a headlight detection condition setting unit (202) that sets, based on result of judgment by the lens dirtiness judgment unit (103), in a parameter that is preliminarily related, a detection condition under which a light spot out of light spots extracted by the light spot feature amount extraction unit (102) is judged to be a headlight;</claim-text>
<claim-text>an approaching headlight judgment unit (105) that judges a particular light spot out of the light spots that corresponds to the parameter as an approaching headlight based on the parameter set by the headlight detection condition setting unit (202); and</claim-text>
<claim-text>a vehicle annunciation signal outputting unit (106) that outputs a vehicle annunciation signal based on detection result of the approaching headlight judgment unit (105).</claim-text></claim-text></claim><claim id="c-en-0002" num="0002"><claim-text>An environment recognition device comprising:
<claim-text>an image acquisition unit (101) that acquires an image captured by an imaging unit;</claim-text>
<claim-text>a light spot feature amount extraction unit (102) that extracts a feature amount of a light spot from the image;</claim-text>
<claim-text>a high brightness feature amount analysis unit (201) that acquires an image state of the acquired image based on the feature amount of the light spot extracted by the light spot feature amount extraction unit (102);</claim-text>
<claim-text>a headlight detection condition setting unit (202) that sets, based on the image state acquired by the high brightness feature amount analysis unit (201), in a parameter that is preliminarily related, a detection condition under which a light spot out of light spots extracted by the light spot feature amount extraction unit (102) is judged to be a headlight;<!-- EPO <DP n="19"> --></claim-text>
<claim-text>an approaching headlight judgment unit (105) that judges a particular light spot out of the light spots that corresponds to the parameter as an approaching headlight based on the parameter set by the headlight detection condition setting unit (202); and</claim-text>
<claim-text>a vehicle annunciation signal outputting unit (106) that outputs a vehicle annunciation signal based on the detection condition of the approaching headlight judgment unit (105).</claim-text></claim-text></claim><claim id="c-en-0003" num="0003"><claim-text>An environment recognition device comprising:
<claim-text>an image acquisition unit (101) that acquires an image captured by an imaging device;</claim-text>
<claim-text>a lens dirtiness judgment unit (103) that judges dirt adhering to a surface of a lens of the imaging unit;</claim-text>
<claim-text>a headlight detection condition setting unit (202) that sets, based on result of judgment by the lens dirtiness judgment unit (103), in a parameter that is preliminarily related, a detection condition under which a headlight is judged from the image;</claim-text>
<claim-text>a light spot feature amount extraction unit (102) that extracts a feature amount of a light spot from the image;</claim-text>
<claim-text>an optical flow unit (501) that detects a position and a speed of another vehicle from a temporal variation of a feature amount in the image;</claim-text>
<claim-text>an approaching vehicle judgment unit (502) that judges whether or not another vehicle is approaching based on the feature amount of the light spot extracted by the light spot feature amount extraction unit (102) or detection result of the optical flow unit (501); and</claim-text>
<claim-text>a vehicle annunciation signal outputting unit (106) that outputs a vehicle annunciation signal based on detection result of the approaching vehicle judgment unit (502), wherein</claim-text>
<claim-text>the headlight detection condition setting unit (202) switches, based on the result of judgment by the lens dirtiness judgment unit (103), between execution of processing by the light spot feature amount extraction unit (102) and execution of processing by the optical flow unit (501).</claim-text></claim-text></claim></claims><drawings mxw-id="PDW16670428" load-source="patent-office"><!-- EPO <DP n="20"> --><figure id="f0001" num="1"><img id="if0001" file="imgf0001.tif" wi="158" he="132" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="21"> --><figure id="f0002" num="2"><img id="if0002" file="imgf0002.tif" wi="157" he="151" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="22"> --><figure id="f0003" num="3"><img id="if0003" file="imgf0003.tif" wi="144" he="119" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="23"> --><figure id="f0004" num="4"><img id="if0004" file="imgf0004.tif" wi="139" he="193" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="24"> --><figure id="f0005" num="5"><img id="if0005" file="imgf0005.tif" wi="150" he="219" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="25"> --><figure id="f0006" num="6"><img id="if0006" file="imgf0006.tif" wi="153" he="157" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="26"> --><figure id="f0007" num="7A,7B"><img id="if0007" file="imgf0007.tif" wi="121" he="108" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="27"> --><figure id="f0008" num="8A,8B,8C,8D"><img id="if0008" file="imgf0008.tif" wi="126" he="218" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="28"> --><figure id="f0009" num="9A,9B,9C"><img id="if0009" file="imgf0009.tif" wi="125" he="189" img-content="drawing" img-format="tif"/></figure></drawings><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
