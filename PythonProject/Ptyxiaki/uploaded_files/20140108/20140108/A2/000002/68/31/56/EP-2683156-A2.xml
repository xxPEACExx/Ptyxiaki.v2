<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2683156-A2" country="EP" doc-number="2683156" kind="A2" date="20140108" family-id="42014020" file-reference-id="298574" date-produced="20180824" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="146585093" ucid="EP-2683156-A2"><document-id><country>EP</country><doc-number>2683156</doc-number><kind>A2</kind><date>20140108</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-13004748-A" is-representative="NO"><document-id mxw-id="PAPP154847285" load-source="docdb" format="epo"><country>EP</country><doc-number>13004748</doc-number><kind>A</kind><date>20091209</date><lang>EN</lang></document-id><document-id mxw-id="PAPP181745984" load-source="docdb" format="original"><country>EP</country><doc-number>13004748.3</doc-number><date>20091209</date></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC140553244" ucid="EP-09015237-A" linkage-type="3" load-source="docdb"><document-id format="epo"><country>EP</country><doc-number>09015237</doc-number><kind>A</kind><date>20091209</date></document-id></priority-claim><priority-claim mxw-id="PPC140548355" ucid="US-12214208-P" load-source="docdb"><document-id format="epo"><country>US</country><doc-number>12214208</doc-number><kind>P</kind><date>20081212</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL-2117098689" load-source="docdb">H04N   5/232       20060101ALI20150107BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-2117101628" load-source="docdb">H04N   5/33        20060101AFI20150107BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL1989627744" load-source="docdb" scheme="CPC">H04N   5/23238     20130101 LI20130603BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989629498" load-source="docdb" scheme="CPC">H04N   5/33        20130101 LI20130603BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989631069" load-source="docdb" scheme="CPC">H04N   5/23296     20130101 LA20131204BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989631847" load-source="docdb" scheme="CPC">H04N   5/232       20130101 LI20130603BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989646570" load-source="docdb" scheme="CPC">G01J2005/0077      20130101 LA20130425BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989646845" load-source="docdb" scheme="CPC">H04N   5/332       20130101 FI20130603BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989651887" load-source="docdb" scheme="CPC">H04N   5/23293     20130101 LI20130603BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT132359912" lang="DE" load-source="patent-office">Wärmebildkamera</invention-title><invention-title mxw-id="PT132359913" lang="EN" load-source="patent-office">Thermal imaging camera</invention-title><invention-title mxw-id="PT132359914" lang="FR" load-source="patent-office">Caméra à imagerie thermique</invention-title><citations><patent-citations><patcit mxw-id="PCIT242943005" load-source="docdb" ucid="DE-20305457-U1"><document-id format="epo"><country>DE</country><doc-number>20305457</doc-number><kind>U1</kind><date>20031106</date></document-id><sources><source name="APP" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT242943006" load-source="docdb" ucid="US-20050206743-A1"><document-id format="epo"><country>US</country><doc-number>20050206743</doc-number><kind>A1</kind><date>20050922</date></document-id><sources><source name="APP" created-by-npl="N"/></sources></patcit></patent-citations><non-patent-citations><nplcit><text>M. MULLER ET AL., REAL-TIME IMAGE PROCESSING AND FUSION FOR A NEW HIGH-SPEED DUAL-BAND INFRARED CAMERA</text><sources><source mxw-id="PNPL57741029" load-source="docdb" name="APP"/></sources></nplcit></non-patent-citations></citations></technical-data><related-documents><relation type="division"><child-doc ucid="EP-13004748-A"><document-id load-source="patent-office" format="epo"><country>EP</country><doc-number>13004748</doc-number><kind>A</kind><date>20091209</date></document-id></child-doc><parent-doc ucid="EP-09015237.2"><document-id load-source="patent-office" format="epo"><country>EP</country><doc-number>09015237.2</doc-number><date>20091209</date></document-id><parent-grant-document ucid="EP-2197199-B1"><document-id><country>EP</country><doc-number>2197199</doc-number><kind>B1</kind><date>20171018</date></document-id></parent-grant-document></parent-doc></relation></related-documents><parties><applicants><applicant mxw-id="PPAR919537305" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>TESTO AG</last-name><address><country>DE</country></address></addressbook></applicant><applicant mxw-id="PPAR919524279" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>TESTO AG</last-name></addressbook></applicant><applicant mxw-id="PPAR919006597" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Testo AG</last-name><iid>100765986</iid><address><street>Testo-Strasse 1</street><city>79853 Lenzkirch</city><country>DE</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR941138503" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>STRATMANN MARTIN DR</last-name><address><country>DE</country></address></addressbook></inventor><inventor mxw-id="PPAR941138506" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>STRATMANN, MARTIN DR.</last-name></addressbook></inventor><inventor mxw-id="PPAR919013232" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>The designation of the inventor has not yet been filed</last-name></addressbook></inventor><inventor mxw-id="PPAR941138505" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>MESSERSCHMID ANDREAS DIPL-ING BA</last-name><address><country>DE</country></address></addressbook></inventor><inventor mxw-id="PPAR941138504" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>MESSERSCHMID, ANDREAS, DIPL.-ING. BA</last-name></addressbook></inventor><inventor mxw-id="PPAR941138501" load-source="docdb" sequence="3" format="epo"><addressbook><last-name>ZAHN PATRICK</last-name><address><country>DE</country></address></addressbook></inventor><inventor mxw-id="PPAR941138502" load-source="docdb" sequence="3" format="intermediate"><addressbook><last-name>ZAHN, PATRICK</last-name></addressbook></inventor></inventors><agents><agent mxw-id="PPAR919013137" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Patent- und Rechtsanwaltssozietät Maucher, Börjes &amp; Kollegen</last-name><suffix>et al</suffix><iid>100060013</iid><address><street>Urachstrasse 23</street><city>79102 Freiburg i. Br.</city><country>DE</country></address></addressbook></agent></agents></parties><international-convention-data><designated-states><ep-contracting-states><country mxw-id="DS549742377" load-source="docdb">AT</country><country mxw-id="DS549744225" load-source="docdb">BE</country><country mxw-id="DS549816079" load-source="docdb">BG</country><country mxw-id="DS549818402" load-source="docdb">CH</country><country mxw-id="DS549744637" load-source="docdb">CY</country><country mxw-id="DS549742378" load-source="docdb">CZ</country><country mxw-id="DS549744226" load-source="docdb">DE</country><country mxw-id="DS549744638" load-source="docdb">DK</country><country mxw-id="DS549744639" load-source="docdb">EE</country><country mxw-id="DS549814080" load-source="docdb">ES</country><country mxw-id="DS549816080" load-source="docdb">FI</country><country mxw-id="DS549816081" load-source="docdb">FR</country><country mxw-id="DS549744227" load-source="docdb">GB</country><country mxw-id="DS549744640" load-source="docdb">GR</country><country mxw-id="DS549744228" load-source="docdb">HR</country><country mxw-id="DS549742379" load-source="docdb">HU</country><country mxw-id="DS549818403" load-source="docdb">IE</country><country mxw-id="DS549744241" load-source="docdb">IS</country><country mxw-id="DS549816086" load-source="docdb">IT</country><country mxw-id="DS549744649" load-source="docdb">LI</country><country mxw-id="DS549908460" load-source="docdb">LT</country><country mxw-id="DS549742380" load-source="docdb">LU</country><country mxw-id="DS549908461" load-source="docdb">LV</country><country mxw-id="DS549908462" load-source="docdb">MC</country><country mxw-id="DS549815586" load-source="docdb">MK</country><country mxw-id="DS549815587" load-source="docdb">MT</country><country mxw-id="DS549814081" load-source="docdb">NL</country><country mxw-id="DS549816087" load-source="docdb">NO</country><country mxw-id="DS549815588" load-source="docdb">PL</country><country mxw-id="DS549818404" load-source="docdb">PT</country><country mxw-id="DS549814094" load-source="docdb">RO</country><country mxw-id="DS549814095" load-source="docdb">SE</country><country mxw-id="DS549818405" load-source="docdb">SI</country><country mxw-id="DS549816088" load-source="docdb">SK</country><country mxw-id="DS549815589" load-source="docdb">SM</country><country mxw-id="DS549744650" load-source="docdb">TR</country></ep-contracting-states></designated-states></international-convention-data></bibliographic-data><abstract mxw-id="PA128673265" lang="EN" load-source="patent-office"><p id="pa01" num="0001">In a thermal imaging camera (30) for acquisition of thermographic images (32, 32a, 32b, 32c, 32d, 32e) of a measurement object (49), an electronic evaluation unit (80) is integrated into the thermal imaging camera (30); it is designed for recognition of corresponding partial regions of the acquired thermographic images (32, 32a, 32b, 32c, 32d, 32e), and with it, the acquired images (32, 32a, 32b, 32c, 32d, 32e) can be assembled into an overall image (50) by overlapping and stitching together the corresponding partial regions and displayed. The acquisition of the images (32, 32a, 32b, 32c, 32d, 32e) preferably takes place during the swiveling of the thermal imaging camera (30) over the solid angle region of the desired overall image (50).
<img id="iaf01" file="imgaf001.tif" wi="78" he="128" img-content="drawing" img-format="tif"/></p></abstract><abstract mxw-id="PA128737416" lang="EN" source="EPO" load-source="docdb"><p>In a thermal imaging camera (30) for acquisition of thermographic images (32, 32a, 32b, 32c, 32d, 32e) of a measurement object (49), an electronic evaluation unit (80) is integrated into the thermal imaging camera (30); it is designed for recognition of corresponding partial regions of the acquired thermographic images (32, 32a, 32b, 32c, 32d, 32e), and with it, the acquired images (32, 32a, 32b, 32c, 32d, 32e) can be assembled into an overall image (50) by overlapping and stitching together the corresponding partial regions and displayed. The acquisition of the images (32, 32a, 32b, 32c, 32d, 32e) preferably takes place during the swiveling of the thermal imaging camera (30) over the solid angle region of the desired overall image (50).</p></abstract><description mxw-id="PDES63959253" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><p id="p0001" num="0001">The invention relates to a thermal imaging camera for taking thermographic images of a measurement object in the infrared region with an indicator tool built in or on the housing for a false color representation of the taken thermographic images, where the thermal imaging camera is made as a hand-held unit. The representation of the thermographic images may use any kind of color mapping, e.g. false color representation, grey tone representation.</p><p id="p0002" num="0002">The invention additionally relates to a method for generating a thermographic image of a large measurement object.</p><p id="p0003" num="0003">A system for dual band acquisition of infrared images in which the IR images acquired in two spectral bands are combined into an image by overlapping by means of image processing in a computer system is known from the publication of M. Muller et al.: "Real-time image processing and fusion for a new high-speed dual-band infrared camera."</p><p id="p0004" num="0004">A digital photo apparatus for taking images in the visible spectral region in which an objective head<!-- EPO <DP n="2"> --> is designed so that it can rotate in manual or automatic mode on the housing is known from <patcit id="pcit0001" dnum="DE20305457U1"><text>DE 203 05 457 U1</text></patcit>.</p><p id="p0005" num="0005">A digital camera for taking images in the visible spectral region in which a one-dimensional panoramic image can be generated is known from <patcit id="pcit0002" dnum="US20050206743A1"><text>US 2005/0206743 A1</text></patcit>.</p><p id="p0006" num="0006">Thermal imaging cameras are frequently used to take thermographic images, thus images optically acquired in the infrared spectral region, in which temperature information obtained from the images taken of structures or parts of structures is represented in a false color representation, thus by means of a false color scale, or by brightness scales, or grey scales. From the thermographic images it is possible to obtain, among other things, information about the building's condition, such as condition of insulation, water damage and/or mold damage, and also for surveillance of room areas and for monitoring or control of manufacturing processes.</p><p id="p0007" num="0007">In taking images of buildings, it is required, on the one hand, to take an overall image and, on the other hand, to take individual images of portions of the building that are as detailed as possible. This produces high demands on the maximum possible resolution of the sensor field of the thermal imaging camera and, if the thermal imaging camera has an integrated display tool, on the maximum possible resolution of said display tool.</p><p id="p0008" num="0008">Since a high maximum possible resolution gives rise to high manufacturing costs, especially, for the detector field of the thermal imaging camera, one makes due by, optionally with a wide-angle lens, first taking an overall picture and then taking the additional individual pictures of the parts of the<!-- EPO <DP n="3"> --> building that are of interest using a telephoto lens, where the individual pictures offer higher resolution because of the smaller section that is chosen. Preferably the position of these individual pictures is entered into a printout of the overall picture for a better subsequent evaluation.</p><p id="p0009" num="0009">The invention is based on the task of creating a thermal imaging camera that enables the acquisition and display of large solid angle regions with high resolution.</p><p id="p0010" num="0010">The invention proposes a solution to this problem by providing a thermal imaging camera with the features of claim 1 and a method according to claim 11. Advantageous features are described in the dependent claims and the description of embodiments of the invention.</p><p id="p0011" num="0011"><figref idrefs="f0001">Figures 1A</figref> and <figref idrefs="f0002">1B</figref> provide an example of a thermal imaging camera 30 for use with the invention provided herein.</p><p id="p0012" num="0012">According to the invention it is provided that an electronic evaluation unit 80 (cf. the sectional view of the thermal imaging camera 30 in <figref idrefs="f0009">Fig. 8</figref>) is integrated into the thermal imaging camera 30 of the kind mentioned at the start, with which at least an acquired thermographic image 32 can be stitched with another acquired thermographic image 32 or a stored thermographic image in the edge regions, where the images each repeat the same section of the measurement object in said edge region, to form a new thermographic overall image and can be provided for combined display with the display tool 34, where the display tool 34 has a zoom function 36 for free selection of a segment of the overall image that is to be enlarged. Thus, the measurement object specifies a solid angle region for an overall image, which is minimally divided into partial solid angle regions, where<!-- EPO <DP n="4"> --> each partial solid angle region corresponds with sufficient overlap to an image to be acquired, and the acquired images 32 are combined into the overall image at the overlappings where they have a corresponding content. It is advantageous in this case that with each additionally acquired image 32, a new overall image can be generated in the thermal imaging camera and the resolution of said image is not limited by the size of the overall image. Thus, a thermal imaging camera is available with which large areas, for example, a building or an industrial plant or a landscape, can be photographed with high resolution, and the focal plane array needs only low resolution, so the manufacturing costs of the thermal imaging camera 30 are considerably reduced. <figref idrefs="f0003">Figure 2</figref> provides an example of an overall image 50 of the sensor fields taken with the thermal imaging camera 30. The display tool 34 also needs not have to have high requirements with regard to maximum possible resolution of the presentation if the display tool 34 is provided with controls for scrolling and/or zooming 36 (e.g., buttons, joysticks, touch pads) the displayed image.</p><p id="p0013" num="0013">The thermal imaging camera 30 that has been developed in this way is thus especially suitable for the requirements of building thermography. In particular, a thermal imaging camera 30 that can be used in one-hand operation because of its compact size, for example, at construction sites, is made available with the invention.</p><p id="p0014" num="0014">Preferably, the evaluation unit 80 contains an image recognition tool, with which partial areas with corresponding content can be identified when there is a number of acquired images 32. In <figref idrefs="f0009">Figure 8</figref>, an image recognition tool is integrated into electronic evaluation unit 80. <figref idrefs="f0003">Figure 2</figref> shows an object 49 to be at least partially imaged. <figref idrefs="f0004">Figure 3</figref> (52)<!-- EPO <DP n="5"> --> shows overlapped acquired images 32 (32a, 32b, 32c, 32d, 32e) taken of portions of the object 49 identified by the image recognition tool, which may be displayed on the display tool 34. The invention takes advantage of the finding that the computational capacity necessary for identification of the corresponding partial regions at which the images are stitched together can be integrated into the thermal imaging camera 30. Additional external computers, or the like, for subsequent processing of acquired images 32 with the goal of generating a stitched overall image 50 (<figref idrefs="f0006">Figure 5</figref>) thus can be omitted. The acquired images 32 are designated as images 1-20, although, as will be appreciated by those skilled in the art, any number of the images 32 may be utilized.</p><p id="p0015" num="0015">For example, it can be intended that points, lines, edges and/or structures marked with the image recognition tool can be identified. These identified marked points, lines, edges and/or structures do not necessarily correspond to points, lines, edges and/or structures of an image obtained in the visible spectral range and can be used for identification of the corresponding partial regions. More generally, the image recognition tool may be constructed such that it allows to identify image features such as SURF, SIFT or other transformation invariant features that may not necessarily be recognizable to the bare eye.</p><p id="p0016" num="0016">An advantageous embodiment of the invention can provide that partial regions in different images with corresponding content (i.e., identical or substantially similar content) in the horizontal and/or vertical edge regions of the thermographic images can be identified. In this manner, same image regions between different of the acquired images 32 may be identified. It is advantageous in this case that not only a panoramic image, as is well known, for example, in<!-- EPO <DP n="6"> --> landscape photography, but also an image composed in two dimensions, width and height, can be generated, as is advantageous for the photography of buildings and industrial plants and the like.</p><p id="p0017" num="0017">For identification of corresponding partial regions in the acquired images 32, it can be provided that the evaluation unit 80 has a tool for pattern recognition. In <figref idrefs="f0009">Figure 8</figref>, a pattern recognition tool is integrated into electronic evaluation unit 80.</p><p id="p0018" num="0018">For convenient taking of the overall image 50 from the individual acquired images 32, it can be provided that a triggering tool 40 is made, through the actuation of which an additional thermographic image can be taken. For use, thus, the camera is merely aimed at the last segment of the overall region to be photographed and a new image can be produced by means of the triggering tool 40 and the stored, and combined with the already acquired images 32. Preferably it is provided that the display tool 34 of the thermal imaging camera 30 show a timewise continuous image taken in the visible and/or infrared spectral regions. In this way, a swiveling of the thermal imaging camera 30 to a new position can be monitored in the display tool 34 when using the camera 30.</p><p id="p0019" num="0019">For an optimized display of the image currently being taken and the overall image 50 that has been generated, it can be provided that the enlargement scale of the display is automatically matched to the size of the current overall image 50.</p><p id="p0020" num="0020">An especially easily portable thermal imaging camera 30 results when the display can simultaneously show the<!-- EPO <DP n="7"> --> thermographic image acquired in the infrared region and an image acquired in the visible spectral region. A display of this kind can take place, for example, by overlapping the images, or by separate presentation in separate windows, or separate displays.</p><p id="p0021" num="0021">Preferably, however, it is provided that the thermographic image and the image taken in the visible spectral region can be represented on top of one another and/or overlapping and/or at least partially covering one another and/or fused using α-blending (alpha-blending), so that corresponding image segments from the same parts of the measurement object can be represented at the same site of the display tool 34 and/or in the same display scale. <figref idrefs="f0004">Figure 3</figref> provides an example of an IR image 52 with five acquired images 32a, 32b, 32c, 32d, 32e, as identified by the image recognition tool, overlapping.</p><p id="p0022" num="0022">A further improved possibility for generating a stitched image from the individually taken images results when the boundary of an already taken thermographic image, preferably the last acquired thermographic image 32, and/or a thermographic image currently being acquired, can be represented on the display by means of a labeling. Preferably, the labeling can be switched on and off. Through the labeling, a region of overlap can be made recognizable when taken the individual images, for example, by the edge labeling of the acquired image 32 being moved on the display tool 34 when the thermal imaging camera 30 is shifted into a new image-taking position.</p><p id="p0023" num="0023">According to one embodiment of the invention, the segment of the object photographed is preselected by the user and shown on the display as a black frame.<!-- EPO <DP n="8"> --></p><p id="p0024" num="0024">After aiming the camera 30 at the beginning of the scene to be stitched and starting the stitching process, the user swivels the camera 30 in front of the scene and from the frame sequence subsequent frames are stitched together and shown on the display 34 while the camera 30 is swiveled horizontally and/or vertically similar to the brush tool in an image processing program. <figref idrefs="f0006">Figure 5</figref> illustrates an image with brush-tool-like stitching of the boxes 1-20. To this end, a motion sensor may be used to detect the swivelling motion of the camera 30. Alternatively, not necessarily using a motion sensor, the swivelling motion is calculated using feature and/or pattern detection algorithms by comparing subsequent thermal images 32 of the acquired sequence in real time.</p><p id="p0025" num="0025">In a further improved realization, low distortion stripes 72, 74 from the image streams are used to improve the overall look and feel of the stitched image, as shown in <figref idrefs="f0007">Figure 6</figref> (70).</p><p id="p0026" num="0026">Thermal imaging systems/cameras 30 tend to be afflicted with optical distortions that are mostly caused by the optical lenses. Due to these so called barrel or pincushion distortions, the process of stitching acquired images 32 together to obtain one overall image 50 gets profoundly more complex and computationally expensive. To provide good stitching results it is of essence to remove this distortion field and therefore correct the geometry of the acquired image(s) 32. Using un-corrected images results in loss of detail and accuracy.</p><p id="p0027" num="0027">This problem scales with the number of acquired images 32 that are going to be stitched together and is therefore<!-- EPO <DP n="9"> --> provides an unwanted obstacle to inevitable for a video stitching approach where the imaging camera 30 is swiveled over the scene. This distortion correction has to be done in real-time and therefore, increases the overall costs of the computing unit due to its complexity.</p><p id="p0028" num="0028">The present invention provides a way to avoid this time consuming process and present a real-time video stitching approach for infrared imaging camera devices that is highly scalable and computationally frugal. Our approach takes into account, that the most common distortions that are caused by the shortcomings of low priced optical systems increase their effect on the image depending on the pixel distance of the center of the optical system. This means that there are regions in the acquired images with almost no distortion that could intervene in the stitching process.</p><p id="p0029" num="0029">The approach of the present invention identifies these regions, either manually or automatically and provides an area where information for the stitching process can be taken without the need to apply a distortion correction to the overall image 50. Having identified this sub-region of the overall image 50 the motion between two or more consecutive frames is determined. The motion determination process is either performed by correlation (cross correlation, normalized cross correlation (CCF/NCCF)), motion filters (Kalman-Filter, etc.), feature-based (SIFT, SURF, LOG, etc.) approaches or motion sensors that provide the needed accuracy. Having determined the actual vector that describes the motion of consecutive frames the new image parts can be determined and added to the overall image 50. Because the imaging system takes many acquired images 32 per second and the swiveling motion of the user is typically small according to the number of frames per second, the movement from one to<!-- EPO <DP n="10"> --> another pixel is quite small so that there will be a tight information cloud extracted out of the frame sequence that improves the result of the overall image 50 even more. Considering the consecutive frames do have many overlapping regions, the information extracted may be used in the stitching process to obtain the overall image 50 with a temporal noise reduction that is simply done by weighting the addition of the frame parts that are transferred into the overall image 50. This process of intelligent combination of the partial images not only results in a comprehensive overall image 50 with all information of the acquired frame sequence in it but also enhances the signal to noise ratio by filtering noise in the temporal domain.</p><p id="p0030" num="0030">Swiveling the imaging device over the scene to acquire a frame sequence with which the overall image 50 will be computed one gathers a new problem class that's concerning the image acquisition at different viewpoints. Images taken at different viewpoints from scenes where visible objects differ in their distance to the spectator (imaging device) show deformations in consecutive frames that can't be modeled by simple linear deformation models, such as translation and rotation. By combining such images, the overlap area may not include enough comparable information to computer an overall image 50 with no artifacts.</p><p id="p0031" num="0031">Our "stripe approach" that segments the image into better comparable parts is robust against such deformations evolving from scenes with objects distrusted at different depths inside the observed scene. Because the considered stripes of consecutive frames of an image sequence do not differ much and therefore have almost the same view points, artifacts will not be visible to the human eye, other than by stitching hole consecutive image frames together. This way an overall<!-- EPO <DP n="11"> --> image 50 can be obtained which conserves the authentic look and feel of the scene from which it was obtained.</p><p id="p0032" num="0032"><figref idrefs="f0008">Figure 7</figref> show the result of the application of the embodiment described above to a 3D scene 80 with objects in different distances from the camera 30. As one may see, the stitching causes distortions to the image, but provides a mechanism that works well for limiting the distortion using the almost undistorted distortion stripes 72, 74. Therefore, the 3D scene is created using acquired images 32.</p><p id="p0033" num="0033">Preferably, it is provided that the sensor signals of the motion sensor can be detected and evaluated by the evaluation unit.</p><p id="p0034" num="0034">In one embodiment of the invention, it can be provided that the resolution of the detector field of the thermal imaging camera 30 is lower than the resolution of the display tool 34. Thus thermographic images of high quality, especially resolution, can be made and displayed with the thermal imaging camera 30 without having to use a detector field with high resolution, thus a high pixel count per unit area. Such a detector field is especially undesirable because of its high manufacturing expense and price.</p><p id="p0035" num="0035">To solve this problem it is provided in a method of the kind mentioned at the start that thermographic images of parts of the measurement object are taken with a thermal imaging camera 30, that in the thermal imaging camera 30 partial regions with corresponding contents are identified in the acquired thermographic images 32, and that the acquired thermographic images 32 are stitched at the identified partial regions into an overall image 50 in the thermal imaging camera 30. <figref idrefs="f0005">Figure 4</figref> provides an example method 60.<!-- EPO <DP n="12"> --> Preferably, it is provided that the assembled overall image 50 is represented on a display tool 34 in the thermal imaging camera 30.</p><p id="p0036" num="0036">According to one embodiment of the invention, it can be provided that the represented overall image 50 is made appropriately current when taking an additional thermographic image by adding the additionally taken image to it. It is advantageous in this case that the generated overall image 50 can be immediately checked and that individual images that are still missing in the overall image 50 or that were insufficiently acquired can be immediately acquired after that.</p><p id="p0037" num="0037">To support the identification of corresponding partial regions, it can be provided that the thermal imaging camera 30 has a motion sensor (not shown) and that the measurement signals of the motion sensor are used by the evaluation unit to identify partial regions with corresponding contents. It is advantageous here that the thermal imaging camera 30 can, due to the sensor signals of at least one of one motion sensor (there is preferably at least one sensor provided for each independent direction of motion of the thermal imaging camera 30) make an assessment of the point at which corresponding partial regions could arise in the case of successively taken individual images. This can save computational capacity, which simplifies the instruction of the thermal imaging camera 30.</p><p id="p0038" num="0038">Using the method 60 of <figref idrefs="f0005">Figure 4</figref>, an especially easy possibility of generating the overall image 50 can provide that the acquisition of the thermographic images 32 in steps 62 and 66 and/or the formation of the overall image 50 on the<!-- EPO <DP n="13"> --> display tool takes place in real time during a swivel motion of the thermal imaging camera 30 in step 64.</p><p id="p0039" num="0039">For dynamic adjustment to partial regions of the overall image 50 that are of interest (and not of interest), it can be provided in step 68 that the resolution can be set for each acquisition of the thermographic images 32 in step 70. In this way, storage capacity and computational capacity in the thermal imaging camera 30 can be saved in step 76. Preferably, a tool for selecting the resolution, for example, a zoom function 36, as provided in step 74, for the currently acquired image 32 can be built into the thermal imaging camera 30.</p><p id="p0040" num="0040">To make use of the full resolution of the thermographic image that results from the assembly of individual images, it can be provided that a freely selectable image segment of the overall image 50 is enlarged on the display tool 34 of the thermal imaging camera 30 with a zoom function 36.</p><p id="p0041" num="0041">To carry out the method, the necessary tools and elements are built into a thermal imaging camera 30. For example, it can be provided that a thermal imaging camera 30 in accordance with the invention is used to carry out the method.</p><p id="p0042" num="0042">An electronic evaluation unit, provided in step 72, is integrated into the thermal imaging camera 30 for taking thermographic images of a measurement object; it is designed to recognize overlapping partial regions 32a, 32b, 32c, 32d, 32d of acquired thermographic images 32, and with it, the acquired images 32 can be assembled into an overall image 50 and displayed by overlapping corresponding partial regions. The acquisition of the image 32 takes place preferably during the swiveling of the thermal imaging camera 30 over the solid<!-- EPO <DP n="14"> --> angle region of the desired overall image 50.</p><p id="p0043" num="0043">In the thermal imaging camera (30) for acquisition of thermographic images (32, 32a, 32b, 32c, 32d, 32e) of a measurement object (49), an electronic evaluation unit (80) is integrated into the thermal imaging camera (30); it is designed for recognition of corresponding partial regions of the acquired thermographic images (32, 32a, 32b, 32c, 32d, 32e), and with it, the acquired images (32, 32a, 32b, 32c, 32d, 32e) can be assembled into an overall image (50) by overlapping and stitching together the corresponding partial regions and displayed. The acquisition of the images (32, 32a, 32b, 32c, 32d, 32e) preferably takes place during the swiveling of the thermal imaging camera (30) over the solid angle region of the desired overall image (50).</p></description><claims mxw-id="PCLM56982282" lang="EN" load-source="patent-office"><!-- EPO <DP n="15"> --><claim id="c-en-0001" num="0001"><claim-text>A thermal imaging camera (30) for taking thermographic images (32, 32a, 32b, 32c, 32d, 32e) of a measurement object (49) in the infrared region, with a display tool (34) built in or on the housing for a representation of the acquired thermographic images (32, 32a, 32b, 32c, 32d, 32e), where the thermal imaging camera (30) is made as a hand-held unit, <b>characterized by</b> the fact that an electronic evaluation unit (80) is integrated into it, with which at least one acquired thermographic image (32, 32a, 32b, 32c, 32d, 32e) can be stitched with another thermographic image (32, 32a, 32b, 32c, 32d, 32e), where the images (32, 32a, 32b, 32c, 32d, 32e) each repeat a same image region (72, 74) of the measurement object (49), said thermographic images (32, 32a, 32b, 32c, 32d, 32e) being stitched about said same image regions (72, 74) to form a thermographic overall image (50) that can be displayed with the display tool (34), where the display tool (34) has a zoom function for preferably free selection of an image segment of the overall image (50) that is to be magnified.</claim-text></claim><claim id="c-en-0002" num="0002"><claim-text>A thermal imaging camera according to claim 1, <b>characterized by</b> the fact that the electronic evaluation unit (80) contains an image recognition tool with which partial regions with the same image regions (72, 74) can be identified when there is a number of acquired thermographic images (32, 32a, 32b, 32c, 32d, 32e).</claim-text></claim><claim id="c-en-0003" num="0003"><claim-text>A thermal imaging camera according to claim 1 or 2, <b>characterized by</b> the fact that the same image region (72, 74) may extend horizontally and/or vertically.<!-- EPO <DP n="16"> --></claim-text></claim><claim id="c-en-0004" num="0004"><claim-text>A thermal imaging camera according to one of the claims 1 to 3, <b>characterized by</b> the fact that the electronic evaluation unit (80) has a tool for pattern and/or feature recognition.</claim-text></claim><claim id="c-en-0005" num="0005"><claim-text>A thermal imaging camera as in one of the claims 1 to 4, <b>characterized by</b> the fact that the thermal imaging camera (30) includes a trigger (40) configured such that through the actuation of which a thermographic image (32, 32a, 32b, 32c, 32d, 32e) can be taken.</claim-text></claim><claim id="c-en-0006" num="0006"><claim-text>A thermal imaging camera as in one of the claims 1 to 5, <b>characterized by</b> the fact that the scale of magnification of the display tool (34) is automatically adjusted to the size of the current overall image (50) and/or <b>characterized by</b> the fact that a representation of the thermographic image (32, 32a, 32b, 32c, 32d, 32e) acquired in the infrared spectral region and an image acquired in the visible spectral region can be represented at the same time by the display tool (34).</claim-text></claim><claim id="c-en-0007" num="0007"><claim-text>A thermal imaging camera as in one of the claims 1 to 6, <b>characterized by</b> the fact that the thermographic image (32, 32a, 32b, 32c, 32d, 32e) and the image acquired in the visible spectral region can be represented at least partially covering one another and/or α-blended, so that image segments of the same parts of the measurement object that correspond to each other can be represented at the same point on the display tool (34) and/or in the same display scale.</claim-text></claim><claim id="c-en-0008" num="0008"><claim-text>A thermal imaging camera as in one of the claims 1 to 7, <b>characterized by</b> the fact that the boundary of an already acquired thermographic image (32, 32a, 32b, 32c,<!-- EPO <DP n="17"> --> 32d, 32e), and a currently acquirable thermographic image (32, 32a, 32b, 32c, 32d, 32e) can be represented on the display tool by means of a switchable labeling and/or <b>characterized by</b> the fact that the segment of the measurement object acquired in the visible spectral region is larger than the segment of the measurement object acquired with an individual and/or with the assembled thermographic image (50).</claim-text></claim><claim id="c-en-0009" num="0009"><claim-text>A thermal imaging camera as in one of the claims 1 to 8, <b>characterized by</b> the fact that at least one motion sensor, with which a swiveling motion of the thermal imaging camera (30) can be detected, is integrated into the thermal imaging camera and/or <b>characterized by</b> the fact that the sensor signals of the motion sensor can be detected and evaluated by the electronic evaluation unit (80).</claim-text></claim><claim id="c-en-0010" num="0010"><claim-text>A thermal imaging camera as in one of the claims 1 to 9, further including a distortion mechanism that uses undistorted stripes (72, 74) to limit the distortions to the images (32, 32a, 32b, 32c, 32d, 32e).</claim-text></claim></claims><drawings mxw-id="PDW16670667" load-source="patent-office"><!-- EPO <DP n="18"> --><figure id="f0001" num="1A"><img id="if0001" file="imgf0001.tif" wi="142" he="211" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="19"> --><figure id="f0002" num="1B"><img id="if0002" file="imgf0002.tif" wi="130" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="20"> --><figure id="f0003" num="2"><img id="if0003" file="imgf0003.tif" wi="153" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="21"> --><figure id="f0004" num="3"><img id="if0004" file="imgf0004.tif" wi="165" he="228" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="22"> --><figure id="f0005" num="4"><img id="if0005" file="imgf0005.tif" wi="135" he="218" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="23"> --><figure id="f0006" num="5"><img id="if0006" file="imgf0006.tif" wi="157" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="24"> --><figure id="f0007" num="6"><img id="if0007" file="imgf0007.tif" wi="165" he="141" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="25"> --><figure id="f0008" num="7"><img id="if0008" file="imgf0008.tif" wi="94" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="26"> --><figure id="f0009" num="8"><img id="if0009" file="imgf0009.tif" wi="144" he="221" img-content="drawing" img-format="tif"/></figure></drawings><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
