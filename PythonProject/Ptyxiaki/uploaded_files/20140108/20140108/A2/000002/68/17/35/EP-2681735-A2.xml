<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2681735-A2" country="EP" doc-number="2681735" kind="A2" date="20140108" family-id="46753312" file-reference-id="303552" date-produced="20180822" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="146586071" ucid="EP-2681735-A2"><document-id><country>EP</country><doc-number>2681735</doc-number><kind>A2</kind><date>20140108</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-12752698-A" is-representative="NO"><document-id mxw-id="PAPP154848263" load-source="docdb" format="epo"><country>EP</country><doc-number>12752698</doc-number><kind>A</kind><date>20120302</date><lang>EN</lang></document-id><document-id mxw-id="PAPP180246583" load-source="docdb" format="original"><country>EP</country><doc-number>12752698.6</doc-number><date>20120302</date></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC140548727" ucid="US-201113039576-A" load-source="docdb"><document-id format="epo"><country>US</country><doc-number>201113039576</doc-number><kind>A</kind><date>20110303</date></document-id></priority-claim><priority-claim mxw-id="PPC140557603" ucid="US-2012027540-W" linkage-type="W" load-source="docdb"><document-id format="epo"><country>US</country><doc-number>2012027540</doc-number><kind>W</kind><date>20120302</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL-2092284179" load-source="docdb">G10L  21/0216      20130101AFI20150204BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-2092284479" load-source="docdb">H04R   3/00        20060101ALI20150204BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-2122371038" load-source="docdb" scheme="CPC">H04R   3/005       20130101 FI20150107BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2122371474" load-source="docdb" scheme="CPC">G10L2021/02168     20130101 LA20150107BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2122371872" load-source="docdb" scheme="CPC">G10L2021/02166     20130101 LA20150107BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2122381819" load-source="docdb" scheme="CPC">G10L  21/0216      20130101 LI20150107BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT132362846" lang="DE" load-source="patent-office">STRAHLFORMUNG FÜR MIKROFONANORDNUNGEN MIT ADAPTIVEM RAUSCHEN</invention-title><invention-title mxw-id="PT132362847" lang="EN" load-source="patent-office">NOISE ADAPTIVE BEAMFORMING FOR MICROPHONE ARRAYS</invention-title><invention-title mxw-id="PT132362848" lang="FR" load-source="patent-office">FORMATION DE FAISCEAUX ADAPTATIVE AU BRUIT POUR LES RÉSEAUX DE MICROPHONES</invention-title></technical-data><parties><applicants><applicant mxw-id="PPAR919519664" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>MICROSOFT CORP</last-name><address><country>US</country></address></addressbook></applicant><applicant mxw-id="PPAR919515860" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>MICROSOFT CORPORATION</last-name></addressbook></applicant><applicant mxw-id="PPAR919007471" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Microsoft Corporation</last-name><iid>101214593</iid><address><street>One Microsoft Way</street><city>Redmond, Washington 98052-6399</city><country>US</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR919544460" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>KIKKERI HARSHAVARDHANA N</last-name><address><country>US</country></address></addressbook></inventor><inventor mxw-id="PPAR919513955" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>KIKKERI, Harshavardhana N.</last-name></addressbook></inventor><inventor mxw-id="PPAR919014996" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>KIKKERI, Harshavardhana N.</last-name><address><street>c/o Microsoft Corporation LCA - International Patents One Microsoft Way</street><city>Redmond, Washington 98052-6399</city><country>US</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR919019153" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Fischer, Michael Maria</last-name><iid>101371614</iid><address><street>Olswang Germany LLP IP Rosental 4</street><city>80331 Munich</city><country>DE</country></address></addressbook></agent></agents></parties><international-convention-data><pct-or-regional-filing-data ucid="US-2012027540-W"><document-id><country>US</country><doc-number>2012027540</doc-number><kind>W</kind><date>20120302</date><lang>EN</lang></document-id></pct-or-regional-filing-data><pct-or-regional-publishing-data ucid="WO-2012119100-A2"><document-id><country>WO</country><doc-number>2012119100</doc-number><kind>A2</kind><date>20120907</date><lang>EN</lang></document-id></pct-or-regional-publishing-data><designated-states><ep-contracting-states><country mxw-id="DS549833709" load-source="docdb">AL</country><country mxw-id="DS549832582" load-source="docdb">AT</country><country mxw-id="DS549833714" load-source="docdb">BE</country><country mxw-id="DS549763529" load-source="docdb">BG</country><country mxw-id="DS549913144" load-source="docdb">CH</country><country mxw-id="DS549830893" load-source="docdb">CY</country><country mxw-id="DS549832583" load-source="docdb">CZ</country><country mxw-id="DS549844225" load-source="docdb">DE</country><country mxw-id="DS549830898" load-source="docdb">DK</country><country mxw-id="DS549830899" load-source="docdb">EE</country><country mxw-id="DS549755872" load-source="docdb">ES</country><country mxw-id="DS549763530" load-source="docdb">FI</country><country mxw-id="DS549763531" load-source="docdb">FR</country><country mxw-id="DS549833715" load-source="docdb">GB</country><country mxw-id="DS549830900" load-source="docdb">GR</country><country mxw-id="DS549833716" load-source="docdb">HR</country><country mxw-id="DS549832584" load-source="docdb">HU</country><country mxw-id="DS549913145" load-source="docdb">IE</country><country mxw-id="DS549833717" load-source="docdb">IS</country><country mxw-id="DS549763532" load-source="docdb">IT</country><country mxw-id="DS549830901" load-source="docdb">LI</country><country mxw-id="DS549844230" load-source="docdb">LT</country><country mxw-id="DS549832585" load-source="docdb">LU</country><country mxw-id="DS549844231" load-source="docdb">LV</country><country mxw-id="DS549844232" load-source="docdb">MC</country><country mxw-id="DS549756646" load-source="docdb">MK</country><country mxw-id="DS549756647" load-source="docdb">MT</country><country mxw-id="DS549755885" load-source="docdb">NL</country><country mxw-id="DS549763545" load-source="docdb">NO</country><country mxw-id="DS549755886" load-source="docdb">PL</country><country mxw-id="DS549913146" load-source="docdb">PT</country><country mxw-id="DS549755887" load-source="docdb">RO</country><country mxw-id="DS549913147" load-source="docdb">RS</country><country mxw-id="DS549755888" load-source="docdb">SE</country><country mxw-id="DS549913148" load-source="docdb">SI</country><country mxw-id="DS549756648" load-source="docdb">SK</country><country mxw-id="DS549756653" load-source="docdb">SM</country><country mxw-id="DS549830906" load-source="docdb">TR</country></ep-contracting-states></designated-states></international-convention-data><office-specific-data><eptags><ep-no-a-document-published>*</ep-no-a-document-published></eptags></office-specific-data></bibliographic-data><abstract mxw-id="PA99830018" ref-ucid="WO-2012119100-A2" lang="EN" load-source="patent-office"><p num="0000">The subject disclosure is directed towards a noise adaptive beamformer that dynamically selects between microphone array channels, based upon noise energy floor levels that are measured when no actual signal (e.g., no speech) is present. When speech (or a similar desired signal) is detected, the beamformer selects which microphone signal to use in signal processing, e.g., corresponding to the lowest noise channel. Multiple channels may be selected, with their signals combined. The beamformer transitions back to the noise measurement phase when the actual signal is no longer detected, so that the beamformer dynamically adapts as noise levels change, including on a per-microphone basis, to account for microphone hardware differences, changing noise sources, and individual microphone deterioration.</p></abstract><abstract mxw-id="PA100326846" ref-ucid="WO-2012119100-A2" lang="EN" source="national office" load-source="docdb"><p>The subject disclosure is directed towards a noise adaptive beamformer that dynamically selects between microphone array channels, based upon noise energy floor levels that are measured when no actual signal (e.g., no speech) is present. When speech (or a similar desired signal) is detected, the beamformer selects which microphone signal to use in signal processing, e.g., corresponding to the lowest noise channel. Multiple channels may be selected, with their signals combined. The beamformer transitions back to the noise measurement phase when the actual signal is no longer detected, so that the beamformer dynamically adapts as noise levels change, including on a per-microphone basis, to account for microphone hardware differences, changing noise sources, and individual microphone deterioration.</p></abstract><abstract mxw-id="PA99830019" ref-ucid="WO-2012119100-A2" lang="FR" load-source="patent-office"><p num="0000">L'invention se rapporte à un formeur de faisceaux adaptatif au bruit qui fait une sélection dynamique entre les canaux d'un réseau de microphones, en fonction des niveaux planchers de l'énergie du bruit qui sont mesurés quand aucun signal réel (par exemple des paroles) n'est présent. Lorsque des paroles (ou un signal souhaité similaire) sont détectées, ledit formeur de faisceaux sélectionne le signal de microphone à utiliser pour le traitement de signal, par exemple celui qui correspond au canal ayant le bruit le plus faible. Plusieurs canaux peuvent être sélectionnés, et leurs signaux peuvent être combinés. Lorsque le signal réel n'est plus détecté, le formeur de faisceaux repasse à la phase de mesure du bruit après une transition, ce qui lui permet de s'adapter de manière dynamique aux changements des niveaux de bruit, y compris microphone par microphone, afin de compenser les différences des microphones eux-mêmes, les sources de bruit changeantes ainsi que la détérioration d'un microphone individuel.</p></abstract><abstract mxw-id="PA100326847" ref-ucid="WO-2012119100-A2" lang="FR" source="national office" load-source="docdb"><p>L'invention se rapporte à un formeur de faisceaux adaptatif au bruit qui fait une sélection dynamique entre les canaux d'un réseau de microphones, en fonction des niveaux planchers de l'énergie du bruit qui sont mesurés quand aucun signal réel (par exemple des paroles) n'est présent. Lorsque des paroles (ou un signal souhaité similaire) sont détectées, ledit formeur de faisceaux sélectionne le signal de microphone à utiliser pour le traitement de signal, par exemple celui qui correspond au canal ayant le bruit le plus faible. Plusieurs canaux peuvent être sélectionnés, et leurs signaux peuvent être combinés. Lorsque le signal réel n'est plus détecté, le formeur de faisceaux repasse à la phase de mesure du bruit après une transition, ce qui lui permet de s'adapter de manière dynamique aux changements des niveaux de bruit, y compris microphone par microphone, afin de compenser les différences des microphones eux-mêmes, les sources de bruit changeantes ainsi que la détérioration d'un microphone individuel.</p></abstract><description mxw-id="PDES51232039" ref-ucid="WO-2012119100-A2" lang="EN" load-source="patent-office"><!-- EPO <DP n="3"/>--><p id="p0001" num="0001"> NOISE ADAPTIVE BEAMFORMING FOR MICROPHONE ARRAYS </p><p id="p0002" num="0002"> BACKGROUND </p><p id="p0003" num="0003"> [0001] Microphone arrays capture the signals from multiple sensors and process those signals in order to improve the signal-to-noise ratio. In conventional beamforming, the general approach is to combine the signals from all sensors (channels). One typical use of beamforming is to provide the combined signals to a speech recognizer for use in speech recognition. </p><p id="p0004" num="0004"> [0002] In practice, however this approach can actually degrade the overall performance, and indeed, sometimes performs worse than even a single microphone. In part this is because of individual hardware differences between the microphones, which can result in different microphones picking up different kinds and different amounts of noise. Another factor is that the noise sources may change dynamically. Still further, different microphones deteriorate differently, again leading to degraded performance. </p><p id="p0005" num="0005"> SUMMARY </p><p id="p0006" num="0006"> [0003] This Summary is provided to introduce a selection of representative concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter, nor is it intended to be used in any way that would limit the scope of the claimed subject matter. </p><p id="p0007" num="0007"> [0004] Briefly, various aspects of the subject matter described herein are directed towards a technology by which an adaptive beamformer / selector chooses which channels / microphones of an microphone array to use based upon noise floor data determined for each channel. In one implementation, energy levels during times of no actual signal (e.g., no speech) are obtained, and once an actual signal is present a channel selector selects which channel or channels to use in signal processing based upon the noise floor data. The noise floor data is repeatedly measured, whereby the adaptive beamformer dynamically adapts to changes in the noise floor data over time. </p><p id="p0008" num="0008">[0005] In one implementation, the channel selector selects a single channel at any one time for use in the signal processing (e.g., speech recognition) and discards the other channels' signals. In another implementation, the channel selector selects one or more channels, with the signals from each selected channel combined for use in signal processing when two or more are selected. 
<!-- EPO <DP n="4"/>-->
 [0006] In one aspect, a classifier determines when noise floor data is to be obtained in a noise measurement phase, and when a selection is to be made in a selection phase. The classifier may be based on a detected change in energy levels. </p><p id="p0009" num="0009">[0007] Other advantages may become apparent from the following detailed description when taken in conjunction with the drawings. </p><p id="p0010" num="0010"> BRIEF DESCRIPTION OF THE DRAWINGS </p><p id="p0011" num="0011">[0008] The present invention is illustrated by way of example and not limited in the accompanying figures in which like reference numerals indicate similar elements and in which: </p><p id="p0012" num="0012"> [0009] FIGURE 1 is a block diagram representing example components of a noise adaptive beamformer / selector for microphone arrays. </p><p id="p0013" num="0013">[0010] FIG. 2 is a representation of noise versus speech signals for the microphones of an example eight channel microphone array. </p><p id="p0014" num="0014">[0011] FIG. 3 is a block diagram representing a mechanism that estimates a noise energy floor for an input channel of a microphone array. </p><p id="p0015" num="0015">[0012] FIG. 4 is a block diagram representing how noise-based channel selection may be used by a noise adaptive beamformer / selector for adaptively providing signals to a speech recognizer. </p><p id="p0016" num="0016">[0013] FIG. 5 is a flow diagram representing example steps in a noise </p><p id="p0017" num="0017">measurement phase and a channel selection phase. </p><p id="p0018" num="0018">[0014] FIG. 6 is a block diagram representing an exemplary non-limiting computing system or operating environment in which one or more aspects of various embodiments described herein can be implemented. </p><p id="p0019" num="0019"> DETAILED DESCRIPTION </p><p id="p0020" num="0020"> [0015] Various aspects of the technology described herein are generally directed towards discarding the microphone signals that degrade performance, by not using noisy signals. The noise adaptive beamforming technology described herein attempts to minimize the adverse effects resulting from microphone hardware differences, dynamically changing noise sources microphone </p><p id="p0021" num="0021">deterioration and/or possibly other factors, resulting in signals that are good for speech recognition, for example, including initially and over a period of time as hardware degrades. 
<!-- EPO <DP n="5"/>-->
 [0016] It should be understood that any of the examples herein are non-limiting. For one, while speech recognition is one useful application of the technology described herein, any sound processing application (e.g., directional amplification and/or noise suppression) may likewise benefit. As such, the present invention is not limited to any particular embodiments, aspects, concepts, structures, functionalities or examples described herein. Rather, any of the embodiments, aspects, concepts, structures, functionalities or examples described herein are non-limiting, and the present invention may be used various ways that provide benefits and advantages in sound processing and/or speech recognition in general. </p><p id="p0022" num="0022"> [0017] FIG. 1 shows components of one example noise adaptive beamforming implementation. A plurality of microphones corresponding to microphone array channels 102i-102w each provide signals for selection and/or beamforming; it is understood that at least two such microphones, up to any practical number, may be present in a given array implementation. </p><p id="p0023" num="0023"> [0018] Also, the microphones of the array need not be arranged symmetrically, and indeed, in one implementation, the microphones are arranged asymmetrically for various reasons. One application of the technology described herein is for use in a mobile robot, which may autonomously move around and thus be dynamically exposed to different noise sources while awaiting speech from a person. </p><p id="p0024" num="0024"> [0019] As represented by the energy detectors 104i-104<sub>w</sub> in FIG. 1 , the noise adaptive beamforming technology described herein monitors the noise energy level in each microphone, including when there is no actual signal, that is, only noise. FIG. 2 is a representation of such energy levels of an example eight channel microphone array, in which the box 221 represents the "no actual signal" state for "MICY of the array. Initially, there is no true input signal, whereby the output of the microphones is only sensed noise. Note that the box 221 (as well as the other boxes) in FIG. 2 is not intended to represent an exact sampling frame or set of frames; (a typical sampling rate is 16K frames / second, for example). </p><p id="p0025" num="0025">[0020] When there is a signal, represented in FIG. 2 by the box 222, the energy increases, and the energy detectors 104r104<sub>w</sub> provide an estimate indicative of the increase per channel. Noise / speech classifiers 106i-106w may be used to determine (e.g., based on a trained delta energy level or threshold energy level) whether the signal is noise or speech, and feed such information to a channel 
<!-- EPO <DP n="6"/>-->
 selector 108. Note that each classifier may include its own normalization, filtering, smoothing and/or other such techniques to make its determination, e.g., the energy may need to remain increased over some number of frames or otherwise match speech patterns to be considered speech, so as to eliminate brief noise energy spikes and the like that may occur from being considered speech. Note that it is also feasible to have a single noise-or-speech classifier for all channels, e.g., use only one of the channels for classification, or mix some or all of the audio channels for the purposes of classification (while maintaining them separately for selection purposes). </p><p id="p0026" num="0026">[0021] Based on the noise levels, when speech is detected, the channel selector 108 dynamically determines which (one or ones) of the microphone's signals is to be used for further processing, e.g., speech processing, and which signals are to be discarded. In the example of FIG. 1 , the microphone MIC1 has a relatively large amount of noise when there is no signal, whereas the microphone MIC7 has the lowest amount of noise when there is no signal (box 227). Thus, when speech does occur (the approximate time corresponding to box 222 for each of the channels), the signal from the microphone MIC7 will likely be used, while the signal from the microphone MIC1 will likely be discarded. </p><p id="p0027" num="0027">[0022] In one implementation of noise adaptive beamforming, only the channel corresponding to the lowest noise signal is selected, e.g., in FIG. 2 only from microphone MIC7, because its noise floor when there is no signal is lower than that of the other microphones. In an alternative implementation, the channel selector 108 may select the signals from multiple channels, which are then combined into a combined signal for output. For example, the two lowest noise channels may be selected and combined. A threshold energy level or relative energy level data may be considered so as to not select more than the lowest noise channel if the next lowest is too noisy or relatively too noisy, and so on. As another alternative, each channel may be given a weight inversely related (in any suitable mathematical way) to that channel's noise and combined using a weighted combination. </p><p id="p0028" num="0028"> [0023] In this manner, the use of noise floor tracking automatically eliminates (or substantially reduces) the adverse effect of noisy microphones because noisy microphones have higher levels of noise, and thus their signals are not used. This approach also eliminates the effect of microphones that are closer to noise 
<!-- EPO <DP n="7"/>-->
 sources in a given situation, e.g., near a television speaker. Similarly, as microphone hardware wears out or otherwise becomes damaged (some microphones go bad and regularly produce high level of noise), the noise adaptive beamformer automatically eliminates the effect of such microphones. </p><p id="p0029" num="0029">[0024] FIG. 3 is a block diagram representing an example noise energy floor estimator mechanism 330, such as for use in an energy detector for one of the channels. The incoming audio sample 332 for a given microphone X may be filtered (block 334) to remove any DC component from the signal, and then processed (e.g., smoothed) by a hamming window function 336 (or other such function) as is known before inputting the result to a fast Fourier transform (FFT) 338. Based on the FFT output, a noise energy floor estimator 340 computes noise energy data 342 (e.g., a representative value) in a generally known manner. </p><p id="p0030" num="0030">[0025] As represented in FIG. 4, the noise energy data 442 for each channel is fed into the channel selector 108. Depending on the data 442 representing the noise energy level estimate from each microphone, when speech corresponding to audio samples 444i - 444<sub>w</sub> is detected, as represented by the classification data 446, the channel selector 108 decides whether or not use the signal from each microphone. The channel selector 108 outputs the selected signal as selected audio channel data 448 for feeding to a speech recognizer 450. Note that as represented by block 452, if the channel selector 108 is configured to select more than one channel and does so, the signals from the multiple channels may be combined using any of various methods. </p><p id="p0031" num="0031"> [0026] FIG. 5 summarizes various example operations related to channel selection and usage, beginning at step 502 where the classification is made as to whether the current input is noise or speech. If noise, step 504 selects a channel, and step 506 determines the noise energy floor for that channel, as described above. Step 508 represents computing the noise data for this channel, e.g., computing an average noise energy level over some number of frames, performing rounding, normalizing and/or the like so as to provide noise data that is expected by the channel selector. Step 510 associates the noise data with that channel, e.g., an identifier of that channel. </p><p id="p0032" num="0032"> [0027] Step 512 repeats the noise measurement phase processing of steps 504- 510 for each other channel. When the noise data for each channel is associated with a channel identity, the process returns to step 502 as described above. 
<!-- EPO <DP n="8"/>-->
 [0028] At some subsequent time, speech is detected, whereby step 502 </p><p id="p0033" num="0033">branches to step 514 to transition to a selection phase that selects the channel (or channels) that has the associated data indicative of the lowest noise level floor for use in further processing. In the event that more than one channel is selected at step 514, step 516 combines the signals from each channel. Step 518 outputs the selected channel's or combined channels' signal for use in further processing, e.g., speech recognition, before returning to step 502. </p><p id="p0034" num="0034"> [0029] Note that shown in FIG. 5 is an optional delay at step 520, which may be used to delay before switching back to estimating noise after speech was detected. While the speech recognizer may be continuously receiving input including both speech and noise, switching microphones during a brief pause may lead to reduced recognition accuracy. For example, the speaker's inhalation or other natural noises during a brief pause may be detected as noise by the microphone that otherwise has the best noise results, and switching away from this </p><p id="p0035" num="0035">microphone may provide speech input from another microphone that is noisier. Thus, by delaying, a speaker is given an opportunity to resume speaking instead of switching back to noise measurement during a brief pause. As an alternative (or in addition) to delaying, the channel selection operation may include smoothing, averaging and so forth to eliminate any such rapid microphone changes or the like. For example, if a microphone has had low noise relative to other microphones and thus has its signal selected for awhile, a sudden change in its noise floor energy may be ignored so as to not switch to another microphone because of a </p><p id="p0036" num="0036">momentary glitch or the like. </p><p id="p0037" num="0037"> [0030] As can be seen, described is a noise adaptive beamforming technology that uses noise floor levels to determine which of the microphones to use in beamforming. The noise adaptive beamforming technology updates this </p><p id="p0038" num="0038">information dynamically, so as to dynamically adapt to a changing environment (in contrast to traditional beamforming). </p><p id="p0039" num="0039">EXEMPLARY COMPUTING DEVICE </p><p id="p0040" num="0040">[0031] As mentioned, advantageously, the techniques described herein can be applied to any device. It can be understood, therefore, that handheld, portable and other computing devices and computing objects of all kinds including robots are contemplated for use in connection with the various embodiments. 
<!-- EPO <DP n="9"/>-->
 Accordingly, the below general purpose remote computer described below in FIG. 6 is but one example of a computing device. </p><p id="p0041" num="0041"> [0032] Embodiments can partly be implemented via an operating system, for use by a developer of services for a device or object, and/or included within </p><p id="p0042" num="0042">application software that operates to perform one or more functional aspects of the various embodiments described herein. Software may be described in the general context of computer executable instructions, such as program modules, being executed by one or more computers, such as client workstations, servers or other devices. Those skilled in the art will appreciate that computer systems have a variety of configurations and protocols that can be used to communicate data, and thus, no particular configuration or protocol is considered limiting. </p><p id="p0043" num="0043">[0033] FIG. 6 thus illustrates an example of a suitable computing system environment 600 in which one or aspects of the embodiments described herein can be implemented, although as made clear above, the computing system environment 600 is only one example of a suitable computing environment and is not intended to suggest any limitation as to scope of use or functionality. In addition, the computing system environment 600 is not intended to be interpreted as having any dependency relating to any one or combination of components illustrated in the exemplary computing system environment 600. </p><p id="p0044" num="0044">[0034] With reference to FIG. 6, an exemplary remote device for implementing one or more embodiments includes a general purpose computing device in the form of a computer 610. Components of computer 610 may include, but are not limited to, a processing unit 620, a system memory 630, and a system bus 622 that couples various system components including the system memory to the processing unit 620. </p><p id="p0045" num="0045"> [0035] Computer 610 typically includes a variety of computer readable media and can be any available media that can be accessed by computer 610. The system memory 630 may include computer storage media in the form of volatile and/or nonvolatile memory such as read only memory (ROM) and/or random access memory (RAM). By way of example, and not limitation, system memory</p><p id="p0046" num="0046">630 may also include an operating system, application programs, other program modules, and program data. </p><p id="p0047" num="0047"> [0036] A user can enter commands and information into the computer 610 through input devices 640. A monitor or other type of display device is also 
<!-- EPO <DP n="10"/>-->
 connected to the system bus 622 via an interface, such as output interface 650. In addition to a monitor, computers can also include other peripheral output devices such as speakers and a printer, which may be connected through output interface 650. </p><p id="p0048" num="0048">[0037] The computer 610 may operate in a networked or distributed environment using logical connections to one or more other remote computers, such as remote computer 670. The remote computer 670 may be a personal computer, a server, a router, a network PC, a peer device or other common network node, or any other remote media consumption or transmission device, and may include any or all of the elements described above relative to the computer 610. The logical connections depicted in Fig. 6 include a network 672, such local area network (LAN) or a wide area network (WAN), but may also include other networks/buses. Such networking environments are commonplace in homes, offices, enterprise- wide computer networks, intranets and the Internet. </p><p id="p0049" num="0049">[0038] As mentioned above, while exemplary embodiments have been described in connection with various computing devices and network architectures, the underlying concepts may be applied to any network system and any computing device or system in which it is desirable to improve efficiency of resource usage. </p><p id="p0050" num="0050">[0039] Also, there are multiple ways to implement the same or similar </p><p id="p0051" num="0051">functionality, e.g., an appropriate API, tool kit, driver code, operating system, control, standalone or downloadable software object, etc. which enables applications and services to take advantage of the techniques provided herein. Thus, embodiments herein are contemplated from the standpoint of an API (or other software object), as well as from a software or hardware object that implements one or more embodiments as described herein. Thus, various embodiments described herein can have aspects that are wholly in hardware, partly in hardware and partly in software, as well as in software. </p><p id="p0052" num="0052">[0040] The word "exemplary" is used herein to mean serving as an example, instance, or illustration. For the avoidance of doubt, the subject matter disclosed herein is not limited by such examples. In addition, any aspect or design described herein as "exemplary" is not necessarily to be construed as preferred or advantageous over other aspects or designs, nor is it meant to preclude equivalent exemplary structures and techniques known to those of ordinary skill in the art. Furthermore, to the extent that the terms "includes," "has," "contains," and 
<!-- EPO <DP n="11"/>-->
 other similar words are used, for the avoidance of doubt, such terms are intended to be inclusive in a manner similar to the term "comprising" as an open transition word without precluding any additional or other elements when employed in a claim. </p><p id="p0053" num="0053">[0041] As mentioned, the various techniques described herein may be </p><p id="p0054" num="0054">implemented in connection with hardware or software or, where appropriate, with a combination of both. As used herein, the terms "component," "module," "system" and the like are likewise intended to refer to a computer-related entity, either hardware, a combination of hardware and software, software, or software in execution. For example, a component may be, but is not limited to being, a process running on a processor, a processor, an object, an executable, a thread of execution, a program, and/or a computer. By way of illustration, both an application running on computer and the computer can be a component. One or more components may reside within a process and/or thread of execution and a component may be localized on one computer and/or distributed between two or more computers. </p><p id="p0055" num="0055"> [0042] The aforementioned systems have been described with respect to interaction between several components. It can be appreciated that such systems and components can include those components or specified sub-components, some of the specified components or sub-components, and/or additional components, and according to various permutations and combinations of the foregoing. Sub-components can also be implemented as components </p><p id="p0056" num="0056">communicatively coupled to other components rather than included within parent components (hierarchical). Additionally, it can be noted that one or more </p><p id="p0057" num="0057">components may be combined into a single component providing aggregate functionality or divided into several separate sub-components, and that any one or more middle layers, such as a management layer, may be provided to </p><p id="p0058" num="0058">communicatively couple to such sub-components in order to provide integrated functionality. Any components described herein may also interact with one or more other components not specifically described herein but generally known by those of skill in the art. </p><p id="p0059" num="0059"> [0043] In view of the exemplary systems described herein, methodologies that may be implemented in accordance with the described subject matter can also be appreciated with reference to the flowcharts of the various figures. While for 
<!-- EPO <DP n="12"/>-->
 purposes of simplicity of explanation, the methodologies are shown and described as a series of blocks, it is to be understood and appreciated that the various embodiments are not limited by the order of the blocks, as some blocks may occur in different orders and/or concurrently with other blocks from what is depicted and described herein. Where non-sequential, or branched, flow is illustrated via flowchart, it can be appreciated that various other branches, flow paths, and orders of the blocks, may be implemented which achieve the same or a similar result. Moreover, some illustrated blocks are optional in implementing the methodologies described hereinafter. </p><p id="p0060" num="0060">CONCLUSION </p><p id="p0061" num="0061"> [0044] While the invention is susceptible to various modifications and alternative constructions, certain illustrated embodiments thereof are shown in the drawings and have been described above in detail. It should be understood, however, that there is no intention to limit the invention to the specific forms disclosed, but on the contrary, the intention is to cover all modifications, alternative constructions, and equivalents falling within the spirit and scope of the invention. </p><p id="p0062" num="0062">[0045] In addition to the various embodiments described herein, it is to be understood that other similar embodiments can be used or modifications and additions can be made to the described embodiment(s) for performing the same or equivalent function of the corresponding embodiment(s) without deviating therefrom. Still further, multiple processing chips or multiple devices can share the performance of one or more functions described herein, and similarly, storage can be effected across a plurality of devices. Accordingly, the invention is not to be limited to any single embodiment, but rather is to be construed in breadth, spirit and scope in accordance with the appended claims. 
</p></description><claims mxw-id="PCLM44851173" ref-ucid="WO-2012119100-A2" lang="EN" load-source="patent-office"><claim-statement><!-- EPO <DP n="13"/>-->WHAT IS CLAIMED IS: </claim-statement><claim id="clm-0001" num="1"><claim-text> 1 . In a computing environment, a system comprising, a microphone array comprising a plurality of microphones corresponding to channels that each output signals, a mechanism coupled to the array configured to determine noise floor data for each channel, and a channel selector configured to select which channel or channels to use in signal processing based upon the noise floor data for each channel, in which the channel selector adapts dynamically to changes in the noise floor data. </claim-text></claim><claim id="clm-0002" num="2"><claim-text> 2. The system of claim 1 wherein the channel selector selects a single channel at any one time for use in the signal processing and discards the signals from each other channel during that time. </claim-text></claim><claim id="clm-0003" num="3"><claim-text> 3. The system of claim 1 wherein the channel selector selects one or more channels at any one time for use in the signal processing, and further comprising, a mechanism configured to combine the signals from each selected channel when two or more are selected. </claim-text></claim><claim id="clm-0004" num="4"><claim-text> 4. The system of claim 1 further comprising a classifier configured to determine when noise floor data is to be obtained. </claim-text></claim><claim id="clm-0005" num="5"><claim-text> 5. In a computing environment, a method performed at least in part on at least one processor, comprising: </claim-text><claim-text> (a) determining noise data during a noise measurement phase, including noise data for each channel of a plurality of channels that correspond to </claim-text><claim-text>microphones of a microphone array; </claim-text><claim-text> (b) using the noise data to select which channel or channels to use for signal processing following the noise measurement phase; and </claim-text><claim-text> (c) returning to step (a) to dynamically adapt channel selection as noise data changes over time. </claim-text></claim><claim id="clm-0006" num="6"><claim-text> 6. The method of claim 5 wherein determining the noise data </claim-text><claim-text>comprises computing data corresponding to an energy level for each channel. </claim-text></claim><claim id="clm-0007" num="7"><claim-text> 7. The method of claim 5 further comprising, classifying, based upon one or more input signals of the channels, whether the input signals correspond to noise or signals for signal processing, for use in determining when to transition from step (a) to step (b), and for use in determining when to transition from step (b) to step (c). <!-- EPO <DP n="14"/>--> </claim-text></claim><claim id="clm-0008" num="8"><claim-text>8. One or more computer-readable media having computer-executable instructions, which when executed perform steps, comprising: </claim-text><claim-text> (a) determining noise data during a noise measurement phase, including obtaining a noise floor energy level for each channel of a plurality of channels that correspond to microphones of a microphone array; </claim-text><claim-text> (b) detecting speech, and transitioning to a selection phase that uses the noise data to select which channel or channels to use for speech recognition; </claim-text><claim-text> (c) outputting a signal corresponding to the selected channel or channels for use for speech recognition; and </claim-text><claim-text> (d) returning to step (a) to dynamically adapt channel selection as noise data changes over time. </claim-text></claim><claim id="clm-0009" num="9"><claim-text> 9. The one or more computer-readable media of claim 8 wherein detecting speech comprises detecting a change from the noise floor energy level. </claim-text></claim><claim id="clm-0010" num="10"><claim-text> 10. The one or more computer-readable media of claim 8 wherein a plurality of channels are selected at step (b), and having further computer- executable instructions comprising, combining the signals from the selected channels into a combined signal for outputting at step (c). </claim-text></claim></claims><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
