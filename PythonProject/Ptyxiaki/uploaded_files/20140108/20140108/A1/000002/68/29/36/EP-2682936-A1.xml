<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2682936-A1" country="EP" doc-number="2682936" kind="A1" date="20140108" family-id="46419993" file-reference-id="216816" date-produced="20180824" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="146584816" ucid="EP-2682936-A1"><document-id><country>EP</country><doc-number>2682936</doc-number><kind>A1</kind><date>20140108</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-12174542-A" is-representative="YES"><document-id mxw-id="PAPP154847008" load-source="docdb" format="epo"><country>EP</country><doc-number>12174542</doc-number><kind>A</kind><date>20120702</date><lang>EN</lang></document-id><document-id mxw-id="PAPP178958773" load-source="docdb" format="original"><country>EP</country><doc-number>12174542.6</doc-number><date>20120702</date></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC140552361" ucid="EP-12174542-A" load-source="docdb"><document-id format="epo"><country>EP</country><doc-number>12174542</doc-number><kind>A</kind><date>20120702</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL1989315759" load-source="docdb">H04W  52/02        20090101ALI20130109BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1989317117" load-source="docdb">G09G   3/30        20060101ALN20130109BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1989319971" load-source="docdb">G09G   3/28        20130101ALN20130109BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1989320636" load-source="docdb">G09G   3/20        20060101ALI20130109BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1989322494" load-source="docdb">G09G   3/32        20060101ALN20130109BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1989323032" load-source="docdb">G09G   5/00        20060101AFI20130109BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL1991310103" load-source="docdb" scheme="CPC">G09G2320/0626      20130101 LA20140110BHEP        </classification-cpc><classification-cpc mxw-id="PCL1991312582" load-source="docdb" scheme="CPC">G09G2320/066       20130101 LA20140110BHEP        </classification-cpc><classification-cpc mxw-id="PCL1991312665" load-source="docdb" scheme="CPC">G09G2340/10        20130101 LA20140110BHEP        </classification-cpc><classification-cpc mxw-id="PCL1991312718" load-source="docdb" scheme="CPC">G09G   3/3208      20130101 LA20140110BHEP        </classification-cpc><classification-cpc mxw-id="PCL1991313033" load-source="docdb" scheme="CPC">G09G2340/16        20130101 LA20140110BHEP        </classification-cpc><classification-cpc mxw-id="PCL1991313093" load-source="docdb" scheme="CPC">G09G2360/16        20130101 LA20140110BHEP        </classification-cpc><classification-cpc mxw-id="PCL1991313335" load-source="docdb" scheme="CPC">G09G2340/12        20130101 LA20140110BHEP        </classification-cpc><classification-cpc mxw-id="PCL1991313575" load-source="docdb" scheme="CPC">G09G   5/00        20130101 LI20140110BHEP        </classification-cpc><classification-cpc mxw-id="PCL1991314454" load-source="docdb" scheme="CPC">G09G2330/021       20130101 LA20140110BHEP        </classification-cpc><classification-cpc mxw-id="PCL1991315747" load-source="docdb" scheme="CPC">G09G2354/00        20130101 LA20140110BHEP        </classification-cpc><classification-cpc mxw-id="PCL1991315993" load-source="docdb" scheme="CPC">G09G   3/2007      20130101 FI20140110BHEP        </classification-cpc><classification-cpc mxw-id="PCL1991316858" load-source="docdb" scheme="CPC">G09G2340/06        20130101 LA20140110BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT132359081" lang="DE" load-source="patent-office">Bildverarbeitung</invention-title><invention-title mxw-id="PT132359082" lang="EN" load-source="patent-office">Image processing</invention-title><invention-title mxw-id="PT132359083" lang="FR" load-source="patent-office">Traitement d'image</invention-title><citations><patent-citations><patcit mxw-id="PCIT242942402" load-source="docdb" ucid="EP-1870878-A2"><document-id format="epo"><country>EP</country><doc-number>1870878</doc-number><kind>A2</kind><date>20071226</date></document-id><sources><source name="SEA" category="I" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT242942403" load-source="docdb" ucid="EP-1962272-A1"><document-id format="epo"><country>EP</country><doc-number>1962272</doc-number><kind>A1</kind><date>20080827</date></document-id><sources><source name="SEA" category="I" created-by-npl="N"/></sources></patcit></patent-citations><non-patent-citations><nplcit><text>None</text><sources><source mxw-id="PNPL45210523" load-source="docdb" name="APP"/></sources></nplcit></non-patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR919517010" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>TP VISION HOLDING BV</last-name><address><country>NL</country></address></addressbook></applicant><applicant mxw-id="PPAR919525948" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>TP VISION HOLDING B.V.</last-name></addressbook></applicant><applicant mxw-id="PPAR919013643" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>TP Vision Holding B.V.</last-name><iid>101313696</iid><address><street>High Tech Campus 5</street><city>5656 AE Eindhoven</city><country>NL</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR919543050" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>HAMMER MARTIN</last-name><address><country>NL</country></address></addressbook></inventor><inventor mxw-id="PPAR919509148" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>HAMMER, MARTIN</last-name></addressbook></inventor><inventor mxw-id="PPAR919011929" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>HAMMER, MARTIN</last-name><address><street>c/o Prins Bernhardplein 200 Floor 8</street><city>1097 JB Amsterdam</city><country>NL</country></address></addressbook></inventor><inventor mxw-id="PPAR919530997" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>HINNEN KAREL JOHANNES GERHARDUS</last-name><address><country>NL</country></address></addressbook></inventor><inventor mxw-id="PPAR919525570" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>HINNEN, KAREL JOHANNES GERHARDUS</last-name></addressbook></inventor><inventor mxw-id="PPAR919010064" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>HINNEN, KAREL JOHANNES GERHARDUS</last-name><address><street>c/o Prins Bernhardplein 200 Floor 8</street><city>1097 JB Amsterdam</city><country>NL</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR919017424" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Nederlandsch Octrooibureau</last-name><iid>101379333</iid><address><street>P.O. Box 29720</street><city>2502 LS The Hague</city><country>NL</country></address></addressbook></agent></agents></parties><international-convention-data><designated-states><ep-contracting-states><country mxw-id="DS549737780" load-source="docdb">AL</country><country mxw-id="DS549737076" load-source="docdb">AT</country><country mxw-id="DS549737782" load-source="docdb">BE</country><country mxw-id="DS549737459" load-source="docdb">BG</country><country mxw-id="DS549739832" load-source="docdb">CH</country><country mxw-id="DS549739703" load-source="docdb">CY</country><country mxw-id="DS549737077" load-source="docdb">CZ</country><country mxw-id="DS549737783" load-source="docdb">DE</country><country mxw-id="DS549739704" load-source="docdb">DK</country><country mxw-id="DS549739705" load-source="docdb">EE</country><country mxw-id="DS549739007" load-source="docdb">ES</country><country mxw-id="DS549737460" load-source="docdb">FI</country><country mxw-id="DS549738832" load-source="docdb">FR</country><country mxw-id="DS549737784" load-source="docdb">GB</country><country mxw-id="DS549739706" load-source="docdb">GR</country><country mxw-id="DS549737785" load-source="docdb">HR</country><country mxw-id="DS549737078" load-source="docdb">HU</country><country mxw-id="DS549739837" load-source="docdb">IE</country><country mxw-id="DS549739707" load-source="docdb">IS</country><country mxw-id="DS549738833" load-source="docdb">IT</country><country mxw-id="DS549739708" load-source="docdb">LI</country><country mxw-id="DS549737685" load-source="docdb">LT</country><country mxw-id="DS549907109" load-source="docdb">LU</country><country mxw-id="DS549737686" load-source="docdb">LV</country><country mxw-id="DS549737687" load-source="docdb">MC</country><country mxw-id="DS549907110" load-source="docdb">MK</country><country mxw-id="DS549907111" load-source="docdb">MT</country><country mxw-id="DS549739008" load-source="docdb">NL</country><country mxw-id="DS549737079" load-source="docdb">NO</country><country mxw-id="DS549907112" load-source="docdb">PL</country><country mxw-id="DS549739709" load-source="docdb">PT</country><country mxw-id="DS549739113" load-source="docdb">RO</country><country mxw-id="DS549739710" load-source="docdb">RS</country><country mxw-id="DS549907113" load-source="docdb">SE</country><country mxw-id="DS549737786" load-source="docdb">SI</country><country mxw-id="DS549737080" load-source="docdb">SK</country><country mxw-id="DS549907114" load-source="docdb">SM</country><country mxw-id="DS549739838" load-source="docdb">TR</country></ep-contracting-states><ep-extended-states><ep-extended-state-data><country>BA</country></ep-extended-state-data><ep-extended-state-data><country>ME</country></ep-extended-state-data></ep-extended-states></designated-states></international-convention-data></bibliographic-data><abstract mxw-id="PA128672988" lang="EN" load-source="patent-office"><p id="pa01" num="0001">An image processing apparatus comprises a receiver (101) which receives a first image. An image generator (103) then generates a second image by setting luminances of the second image in response to chrominance gradients of the first image. Specifically, the luminances may be determined as a monotonically increasing function of the chrominance gradients. The average of the luminance of the second image may be set to be no more than 10% of an average luminance of the first image. The approach may increase luminances for changing image areas higher than for flat image areas. The approach may allow an extreme power reduction while still providing relevant visual information. In particular, perceptually significant features may be emphasized.
<img id="iaf01" file="imgaf001.tif" wi="146" he="111" img-content="drawing" img-format="tif"/></p></abstract><abstract mxw-id="PA128737133" lang="EN" source="EPO" load-source="docdb"><p>An image processing apparatus comprises a receiver (101) which receives a first image. An image generator (103) then generates a second image by setting luminances of the second image in response to chrominance gradients of the first image. Specifically, the luminances may be determined as a monotonically increasing function of the chrominance gradients. The average of the luminance of the second image may be set to be no more than 10% of an average luminance of the first image. The approach may increase luminances for changing image areas higher than for flat image areas. The approach may allow an extreme power reduction while still providing relevant visual information. In particular, perceptually significant features may be emphasized.</p></abstract><description mxw-id="PDES63958976" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><heading id="h0001"><b>Field of the invention</b></heading><p id="p0001" num="0001">The invention relates to a display system, an image processing apparatus, and a method of processing images, and in particular, but not exclusively to a system capable of presenting images with substantially reduced power consumption.</p><heading id="h0002"><b>Background of the Invention</b></heading><p id="p0002" num="0002">Power efficiency of electrical equipment is becoming increasingly important. This is particularly critical for battery powered devices, such as the small portable devices that are becoming increasingly ubiquitous. For example, the power efficiency of smart phones is critical in achieving high battery life. However, low power consumption is also very important for larger, static and mains driven devices. For example, the power consumption of large screen televisions is very significant, and since such displays are often used for extended lengths of time, it is important to reduce the power consumption as much as possible.</p><p id="p0003" num="0003">For many devices, a large proportion of the total power consumption is due to the power consumption of a display. Therefore, it is particularly important to reduce the power consumption for displays and a number of different techniques and algorithms have been proposed.</p><p id="p0004" num="0004">Furthermore, many use cases for displays do not require optimal image quality at all times. For example, televisions may often be used as background devices, or the image to be presented on a mobile device may already be of very low quality.</p><p id="p0005" num="0005">Therefore, it has been proposed to reduce power consumption by dimming or switching off the image that is presented by a display. This may result in significant power reduction, but also results in the image being removed completely or being degraded to a point where it is difficult to perceive. Thus, power reduction is achieved at the expense of a very substantial reduction in the information provided by the display. This may be inconvenient for many applications, and therefore an improved trade-off<!-- EPO <DP n="2"> --> between power consumption and visual output provided by a display would be advantageous.</p><p id="p0006" num="0006">Hence, an improved display arrangement would be advantageous, and in particular an arrangement allowing increased flexibility, reduced complexity, facilitated implementation, reduced power consumption, increased perceptibility, and/or improved performance would be advantageous.</p><heading id="h0003"><b>Summary of the Invention</b></heading><p id="p0007" num="0007">Accordingly, the Invention seeks to preferably mitigate, alleviate or eliminate one or more of the above mentioned disadvantages singly or in any combination.</p><p id="p0008" num="0008">According to an aspect of the invention there is provided an image processing apparatus comprising: a receiver for receiving a first image; an image generator for generating a second image by setting luminances of the second image in response to chrominance gradients of the first image.</p><p id="p0009" num="0009">The invention may in many scenarios allow an image to be generated which can provide improved perceptual information for a given brightness/ power consumption. In particular, it may generate an image with increased emphasis on perceptually significant features. This may in particular allow substantially reduced power consumption when displaying the second image while still allowing information of the original image to be perceived. For example, an outline image may be generated.</p><p id="p0010" num="0010">A chrominance gradient may be a luminance gradient, a chromaticity gradient or a combined luminance and chromaticity gradient. The gradient may reflect change as a function of spatial position. Thus, the term chrominance includes luminance only and chromaticity only, as well as combined luminance and chromaticity values.</p><p id="p0011" num="0011">The image generator may generate the second image to maintain the chromaticity of the first image. Thus, in some embodiments, only the luminances may be different between the first and second image. In other embodiments, the chromaticity may be changed. For example, the second image may be generated as a monochromatic image.<!-- EPO <DP n="3"> --></p><p id="p0012" num="0012">In accordance with an optional feature of the invention, the image generator is arranged to set luminances of the second image as a monotonically increasing function of the chrominance gradients.</p><p id="p0013" num="0013">This may in particular provide a suitable image for being displayed with reduced total light output, i.e. for a power reduced output. In particular, it may allow for perceptually significant features to be emphasized.</p><p id="p0014" num="0014">The monotonically increasing function may in particular be a non-linear function. The derivative of the monotonically increasing function may itself be a monotonically increasing function. This may improve the perception of image information with low average power consumption.</p><p id="p0015" num="0015">The luminance setting may be performed by a scaling of luminances of the first image. Thus, the function may provide scale factor as a function of the chrominance gradient. The function may be a monotonically increasing function (and may have a derivative which is also monotonically increasing.)</p><p id="p0016" num="0016">The luminance setting may be performed by determining luminances as a function of chrominance gradients and independently of a luminance of the first image. A one-to-one relationship between a chrominance gradient and a luminance may exist. The function may provide a luminance value as a function of a chrominance gradient value.</p><p id="p0017" num="0017">In accordance with an optional feature of the invention, the image generator is arranged to generate the second image to have an average luminance of no more than 10% of an average luminance of the first image.</p><p id="p0018" num="0018">The invention may generate a second image that retains much perceptual information of the first image even for very high reductions in average luminance, and thus in power consumption. Indeed, in many embodiments, the average luminance of the second image may be no more than 5% or even 3% of the average luminance of the first image. Thus, a very substantial power reduction can be achieved.<!-- EPO <DP n="4"> --></p><p id="p0019" num="0019">In accordance with an optional feature of the invention, the image generator comprises: a gradient processor for generating a gradient map for the first image; a luminance processor for setting the luminance values of pixels of the second image as a function of gradient values of corresponding positions in the gradient map.</p><p id="p0020" num="0020">This may provide a particularly advantageous approach for generating the second image. In particular, it may allow a low complexity approach for adapting the second image to perceptually significant features of the first image. A close adaptation can be achieved without necessitating a high computational resource.</p><p id="p0021" num="0021">The function may be a monotonically increasing function, and may have a derivative which is also a monotonically increasing function. The function may be non-linear.</p><p id="p0022" num="0022">The gradient map may comprise values indicative of the spatial gradient/change of a chrominance property for each position/pixel of the first image. The luminance value for a given position/pixel may be determined as a function of the determined gradient. E.g. the luminance for each position may be generated by applying a non-linear function to the spatial gradient determined for the position. For example, an exponential function may be applied to amplify gradient differences.</p><p id="p0023" num="0023">In accordance with an optional feature of the invention, the image generator further comprises: a chromaticity processor for setting chromaticity values of pixels of the second image as a function of chromaticity values of corresponding positions in the first image.</p><p id="p0024" num="0024">This may provide a second image which in many embodiments may be perceived to provide a closer correspondence to the first image. In particular, the chromaticity values of the second image may be set to be the same as the chromaticity values of the first image.</p><p id="p0025" num="0025">In contrast, in some embodiments, the chromaticity values of the second image may be set independently of the chromaticity values of the first image. For example, the chromaticity values may be set to generate a mono-chromatic image, e.g.<!-- EPO <DP n="5"> --> corresponding to a single color channel for an associated display, or to a black and white image. This may for example reduce power consumption in some embodiments.</p><p id="p0026" num="0026">In accordance with an optional feature of the invention, the image generator further comprises a processor for processing at least one of the gradient map and a luminance image derived from the gradient map, the processor being arranged to perform at least one of: a contrast enhancement; an edge enhancement; a spatial high pass filtering; a spatial low pass filtering; a spatial band pass filtering; and a temporal filtering.</p><p id="p0027" num="0027">This may in many embodiments provide improved generation of the second image and may in particular provide an image which provides an improved perceptual representation of the contents of the first image when displayed at substantially reduced power.</p><p id="p0028" num="0028">The contrast enhancement may in particular allow improved emphasis of perceptually significant features of the first image. In particular, it may allow a stronger emphasis of outlines of features of the first image.</p><p id="p0029" num="0029">The edge enhancement may in particular allow improved emphasis of perceptually significant features of the first image. In particular, it may allow a stronger emphasis of outlines of features of the first image.</p><p id="p0030" num="0030">The spatial high pass filtering may in particular allow improved emphasis of perceptually significant features of the first image. In particular, it may allow a stronger emphasis of outlines of features of the first image.</p><p id="p0031" num="0031">The spatial low pass filtering may in particular allow reduced emphasis of perceptually non-significant features of the first image. In particular, this may result in a stronger emphasis of outlines of features of the first image. The spatial low pass filtering may reduce noise in the second image thereby providing a stronger focus on the outlines of features.</p><p id="p0032" num="0032">The spatial band pass filtering may combine the advantages of a spatial high pass filtering and a spatial low pass filtering.<!-- EPO <DP n="6"> --></p><p id="p0033" num="0033">The temporal filtering may specifically be a low pass filtering which in particular may allow reduced emphasis of perceptually non-significant features of the first image. In particular, this may result in a stronger emphasis of outlines of features of the first image. The spatial low pass filtering may reduce noise in the second image thereby providing a stronger focus on the outlines of features. The spatial low pass filtering may also reduce flickering outlines which may appear distracting and thereby make the second image appear calm.</p><p id="p0034" num="0034">The luminance processor may be arranged to determine the luminance values for the second image in response to the gradient map after one or more of these (or indeed other) operations have been performed to the gradient map. Alternatively or additionally, the processing may be applied to the luminance image generated from the gradient map.</p><p id="p0035" num="0035">It will be appreciated that the processing may be performed as a separate operation applied to the gradient map/ luminance image, or may equivalently be performed (e.g. partly) as an integrated part of the determination of the luminances for the second image from an initial gradient map or of the determination of the depth map.</p><p id="p0036" num="0036">In accordance with an optional feature of the invention, the gradient processor is arranged to determine a chrominance gradient value in a plurality of directions for a first image position, and to determine a chrominance gradient for the gradient map for the first image position from the chrominance gradient values in the plurality of directions.</p><p id="p0037" num="0037">This may provide a particularly suitable gradient map and/or may reduce complexity/ resource demand and/or facilitated operation.</p><p id="p0038" num="0038">In accordance with an optional feature of the invention, the gradient processor is arranged to determine a gradient for a plurality of chrominance channels for a first image position, and to determine a chrominance gradient for the gradient map for the first image position from the gradients in the plurality of chrominance channels.<!-- EPO <DP n="7"> --></p><p id="p0039" num="0039">This may provide a particularly suitable gradient map and/or may reduce complexity/ resource demand and/or facilitate operation.</p><p id="p0040" num="0040">In accordance with an optional feature of the invention, the image generator comprises: a segmenter for segmenting the first image into segments in response to chrominance properties; a luminance processor arranged to generate luminance values for the second image by determining luminances of the first image differently for segment border regions than for segment non-border regions.</p><p id="p0041" num="0041">This may provide a particularly advantageous approach for generating the second image. In particular, it may allow a low complexity approach for adapting the second image to perceptually significant features of the first image. A close adaptation can be achieved without necessitating a high computational resource.</p><p id="p0042" num="0042">The luminance values may be generated by scaling luminance values of the input signals. The scale factors for the non- border regions may be lower than for adjacent border regions. In many embodiments, they may be no less than 3dB, 6 dB or 10dB lower.</p><p id="p0043" num="0043">The luminance values may be generated by setting the luminance values independently of the input image. For example, different fixed luminance values may be applied to border and non-border regions. The luminances of the non- border regions may be lower than for adjacent border regions by e.g. a factor of no less than dB, 6 dB, 10dB or 20dB.</p><p id="p0044" num="0044">The border regions include segment borders whereas the non-border regions do not include borders. The segment borders may be determined to surround the borders, and e.g. to have a fixed size, or a size dependent on image characteristics.</p><p id="p0045" num="0045">In accordance with an optional feature of the invention, the image generator is arranged to reduce chrominance variations within non-border regions.</p><p id="p0046" num="0046">This may provide an improved second image and may in particular reduce the emphasis of less perceptually significant image areas relative to more perceptually significant<!-- EPO <DP n="8"> --> image areas. In particular, it may in many embodiments and scenarios increase the focus on outlines of objects.</p><p id="p0047" num="0047">The image generator may reduce variations of a luminance property, a chromaticity property or a combined luminance and chromaticity property. The reduction of variation may for example correspond to a spatial low pass filtering within non-border regions.</p><p id="p0048" num="0048">In accordance with an optional feature of the invention, the image processing apparatus further comprises an image generator for generating a third image by combining the first and second image.</p><p id="p0049" num="0049">This may provide an improved image for many embodiments, and may in particular allow a gradual outline effect to be introduced. The approach may allow the image to be adapted to the current characteristics and/or preferences. The combination may for example be a mixing, a weighted combination, and specifically a weighted summation, with weights determined e.g. in response to a user attention indication and/or a battery charge status indication.</p><p id="p0050" num="0050">In accordance with an optional feature of the invention, the image generator is arranged to detect a first chrominance transition corresponding to an image object framing an active image area, and to reduce luminance for the second image for the first chrominance transition.</p><p id="p0051" num="0051">This may reduce, mitigate and/or avoid undesired transitions being highlighted.</p><p id="p0052" num="0052">In particular, the image generator may be arranged to detect an edge of black bars framing an image, and may reduce the luminance in the second image associated with the edge of the black bar. The reduction may be achieve e.g. by reducing the gradient values and/or by directly reducing the luminance by modifying the second image.</p><p id="p0053" num="0053">In accordance with an optional feature of the invention, there is provided a display system comprising the image processing apparatus and further comprising a display,<!-- EPO <DP n="9"> --> the display system further comprising a display driver arranged to generate a display image for displaying by the display from the second image.</p><p id="p0054" num="0054">The invention may provide an improved display system and may in particular in many embodiments provide a display system which can present an image that still provides perceptual information at very substantially reduced power consumption.</p><p id="p0055" num="0055">In accordance with an optional feature of the invention, the display system further comprises a user attention detector for generating an indication of user attentiveness; and wherein the display driver is arranged to generate the display image in response to a combination of the first and second image dependent on the indication of user attentiveness.</p><p id="p0056" num="0056">The invention may provide a display which may reduce power consumption very substantially when not actively watched by a user while at the same time providing visual cues representing the original image. In many embodiments, power reductions to around 2-4% of the power consumption of displaying the first image can be achieved while still providing a user with sufficient visual cues. For example, a display system may be generated which can detect that a user is not focusing on the display and accordingly switch to a background viewing mode which allows extreme reduction of the power consumption while still maintaining visibility of important features.</p><p id="p0057" num="0057">The system may allow improved power management and may in particular extend battery life. In many embodiments, the weighting of the first image is a monotonically increasing and the weighting of the second image is a monotonically decreasing function of the user attention indication.</p><p id="p0058" num="0058">The combination may be a binary weighting corresponding to a selection of either the first image or the second image.</p><p id="p0059" num="0059">In accordance with an optional feature of the invention, the display system further comprises a battery status detector for generating a battery status indication for a battery powering the display; and wherein the display driver is arranged to generate the<!-- EPO <DP n="10"> --> display image in response to a combination of the first and second image dependent on the battery status indication.</p><p id="p0060" num="0060">The system may allow improved power management and may in particular extend battery life. In many embodiments, the weighting of the first image is a monotonically increasing and the weighting of the second image is a monotonically decreasing function of the battery charge.</p><p id="p0061" num="0061">For example, when the battery charge drops below a given threshold, the system may switch from presenting the first image to presenting the second image. This may reduce the quality of the image while still allowing the significant features to be viewed yet may provide an extreme reduction in power consumption.</p><p id="p0062" num="0062">The combination may be a binary weighted combination corresponding to a selection of either the first image or the second image.</p><p id="p0063" num="0063">In accordance with an optional feature of the invention, the display system further comprises a battery status detector for generating a battery status indication for a battery powering the display; and wherein the image generator is arranged to determine the luminance of the second image in response to the battery status.</p><p id="p0064" num="0064">The system may allow improved power management and may in particular extend battery life.</p><p id="p0065" num="0065">According to an aspect of the invention there is provided a method of generating an image, the method comprising: receiving a first image; generating a second image by setting luminances of the second image in response to chrominance gradients of the first image.</p><p id="p0066" num="0066">These and other aspects, features and advantages of the invention will be apparent from and elucidated with reference to the embodiment(s) described hereinafter.</p><heading id="h0004"><b>Brief Description of the Drawings</b></heading><!-- EPO <DP n="11"> --><p id="p0067" num="0067">Embodiments of the invention will be described, by way of example only, with reference to the drawings, in which
<ul><li><figref idrefs="f0001">FIG. 1</figref> illustrates an example of an image display system in accordance with some embodiments of the invention;</li><li><figref idrefs="f0002">FIG. 2</figref> illustrates examples of images;</li><li><figref idrefs="f0003">FIG.3</figref> illustrates an example of an image display system in accordance with some embodiments of the invention;</li><li><figref idrefs="f0004">FIG.4</figref> illustrates an example of an image processor in accordance with some embodiments of the invention;</li><li><figref idrefs="f0005">FIG. 5</figref> illustrates an example of an original image and a modified image generated in accordance with an exemplary embodiment of the Applicant's invention;</li><li><figref idrefs="f0006">FIG.6</figref> illustrates an example of an image processor in accordance with some embodiments of the invention;</li><li><figref idrefs="f0007">FIG. 7</figref> illustrates an example of an original image and modified images generated in accordance with an exemplary embodiment of the Applicant's invention;</li><li><figref idrefs="f0008">FIG.8</figref> illustrates an example of an image display system in accordance with some embodiments of the invention; and</li><li><figref idrefs="f0009">FIG.9</figref> illustrates an example of an image display system in accordance with some embodiments of the invention.</li></ul></p><heading id="h0005"><b>Detailed Description of Some Embodiments of the Invention</b></heading><!-- EPO <DP n="12"> --><p id="p0068" num="0068"><figref idrefs="f0001">FIG. 1</figref> illustrates an example of an image display system in accordance with some embodiments of the invention.</p><p id="p0069" num="0069">The display system comprises a receiver 101 which receives an input image. The input image may be a single static image, such as a digital photo, or may be an image out of a sequence of images, such as a frame from a video stream.</p><p id="p0070" num="0070">The receiver 101 is coupled to an image generator 103 which generates a modified image from the input image, which is henceforth referred to as the original image. The image generator 103 is coupled to a display driver 105 which is further coupled to a display 107. The display driver 105 is arranged to drive the display to present the modified image.</p><p id="p0071" num="0071">In the specific example, the display 107 is an emissive-type display where each pixel or sub-pixel generates and emits light. Thus, the display is a system wherein the generation of light is highly localized and can be varied with high spatial resolution. This is in contrast to e.g. typical backlight displays wherein a common backlight is generated for a relatively large group of pixels with the pixels merely controlling the transmissivity and thus how much of the generated backlight is allowed to propagate to the front of the screen. In the specific example, the display is an OLED display. This (and similar) displays are particularly power efficient for images having a relatively low number of bright pixels, i.e. it is very power efficient when displaying images with few pixels at high brightness.</p><p id="p0072" num="0072">The image generator 103 is arranged to generate the modified image as a low-power version of the original image. Indeed, in many embodiments, the image generator 103 generates the modified image as an extreme low power version of the original image. The image generator 103 may specifically reduce the average luminance of the original image to less than 10%, and often less than 5%, or even less than 3%, of the original image. Since the power consumption of a display is mainly caused by the energy of the generated light, such a reduction of average luminance can provide an extreme reduction of the total power consumption, and in particular for emissive-type displays an extreme power consumption reduction can be achieved. Indeed, for such displays, the power consumption is often substantially proportional to the average light<!-- EPO <DP n="13"> --> generation. In many embodiments, the power consumption when displaying the modified image may be no more than 10%, 5% or even 3% of the power consumption of displaying the original image.</p><p id="p0073" num="0073">A dimming of an image to such extreme levels will typically significantly degrade the perception of the image, and indeed will typically result in the rendered image not being perceivable. However, in the system of <figref idrefs="f0001">FIG. 1</figref>, a modified image is generated that still provides a large amount of perceivable information of the original image. Thus, the system generates an extreme low power abstraction of the original image which however still provides perceptible visual cues relating to the content of the original image.</p><p id="p0074" num="0074">The image generator 103 of <figref idrefs="f0001">FIG. 1</figref> generates a modified image where perceptually significant features are strongly emphasized whereas less significant features may be attenuated significantly.</p><p id="p0075" num="0075">Specifically, the image generator 103 generates the modified image by locally determining and setting the luminance of the original image based on chrominance gradients of the original image.</p><p id="p0076" num="0076">Specifically, the luminance of the modified image may be set as a monotonically increasing function of the chrominance gradient. The luminance may be generated without consideration of the original image and thus be determined directly from the chrominance gradient. In other embodiments, the luminance may also be dependent on the luminance of the original image. E.g. the luminance at a given image position may be set as the luminance of the original image but scaled by a value that is a monotonically increasing function of the gradient at that position.</p><p id="p0077" num="0077">These approaches can generate a modified image where areas with large gradients will be (typically much) brighter than areas with smaller gradients. This results in an image wherein changing image features are emphasized by being made brighter than flat image areas. Indeed, the luminance scaling may be highly non-linear resulting in a very strong highlighting of features corresponding to large gradients and very strong<!-- EPO <DP n="14"> --> dimming of features that do not correspond to large gradients. Thus, changes or outlines in the original image are highlighted at the expense of flatter image areas.</p><p id="p0078" num="0078">The approach utilizes the rationale of spending most energy on accenting image transitions rather than flat areas. Compared to the original image, the transitions will therefore be much brighter than the flat areas for a given level of power consumption. Furthermore, the approach can improve the local contrast. Both features improve the visibility of objects, in particular at larger distances. The approach can provide a modified image which is a visual summary of the original images.</p><p id="p0079" num="0079">Examples of images that can be generated are illustrated in <figref idrefs="f0002">FIG. 2</figref> where the first column shows the original image, the second column shows the original image dimmed to an average luminance of 2% of the original image, and the third column shows a modified image which is also dimmed to an average luminance of 2% of the original image. As can be seen, the modified image provides significant perceptible cues of the original image despite the extreme power reduction.</p><p id="p0080" num="0080">The image generator 103 of <figref idrefs="f0001">FIG. 1</figref> comprises a gradient processor 109 which determines the chrominance gradient indications for the image. For example, the gradient processor 109 may determine a chrominance gradient for each pixel position of the image. As another example, the gradient processor 109 may identify specific areas for which a high gradient is considered to be present, e.g. by dividing the image into high gradient areas and low gradient areas (e.g. simply differentiated by a threshold although more advanced processing may of course be performed).</p><p id="p0081" num="0081">The chrominance gradient is a measure of a spatial rate of change for a luminance, chromaticity or combined luminance and chromaticity measure. The term chrominance thus includes luminance only, as well as chromaticity only, parameters or measures, and refers to a luminance and/or chromaticity. The gradient may for example be determined as a spatial rate of change for a luminance value, a color component value, or a chromaticity value. In some embodiments, a gradient may be determined in a plurality of spatial directions and/or over a plurality of different parameters/properties. The different gradients may then e.g. be combined (such as by a weighted summation<!-- EPO <DP n="15"> --> or averaging) or the gradient processor 109 may simply select one of the determined values (for example using the maximum).</p><p id="p0082" num="0082">The gradient processor 109 is coupled to a modification processor 111 which proceeds to determine luminance values for the modified image based on the gradient values.</p><p id="p0083" num="0083">Specifically, the modification processor may change luminance values of the original image to generate the modified image. E.g. the luminance of each pixel may be scaled with a scale factor that depends on a chrominance gradient value determined for the pixel position. The modification processor 111 thus modifies the brightness level setting dependent on the chrominance gradient (i.e. the actual luminance radiated may be a function of the original luminance value of the original image and a pixel value independent (local) brightness setting. The brightness setting may be considered to correspond to the maximum possible luminance value for the pixel).</p><p id="p0084" num="0084">The scaling of the luminance value of the original image is such that higher brightness levels are provided for higher gradient values. Thus, the effective localized brightness level is a monotonically increasing function of the chrominance gradient. The relationship may be highly non-linear such that lower gradient values result in much darker pixels than for higher gradient values.</p><p id="p0085" num="0085">In other embodiments, the luminance may be set directly from the gradient values without considering the original luminance values of the original image. For example, the luminance values may be determined as a direct one-to-one function of the gradient value. The function may again be highly non-linear in order to provide a strong emphasis on areas with significant gradients.</p><p id="p0086" num="0086">For example, a non-linearity in the form of a non-linearity would be a clipping function (clamping low values to zero) could be used. Another example is the application of a logistics function (sigmoidal shape) which latter allows clamping of low intensity values to zero (black) while high-intensity values are clipped to one (maximum brightness). In the extreme (infinite slope), the logistics function results in a binary output (binary thresholding). As a specific example, a non-linear function may be<!-- EPO <DP n="16"> --> generated by applying a threshold to a linear function (e.g. all gradients smaller than certain value are neglected or subjected to an exponential function).</p><p id="p0087" num="0087">Thus, in some embodiments, the luminance of the modified image may not depend on the original image. For example, in some embodiments, all pixels determined to belong to a high gradient image area may be set to have a given predetermined (bright) luminance whereas all pixels considered to belong to a region of low gradient may be set to a given (dark) luminance (such as e.g. black). This may result in the modified image being an outline image.</p><p id="p0088" num="0088">In the example, the modification processor 111 thus sets the luminance values of pixels of the modified image based on a chrominance gradient indication for the pixel position. The modification processor 111 may furthermore set the chromaticity of the output image to depend on the original image. Specifically, in many embodiments, the chromaticity of the pixels of the modified image may simply be set to correspond to the chromaticity of the corresponding pixels in the original image. This may result in maintenance of (at least some of) the color information of the image and may thus provide additional visual cues to the user.</p><p id="p0089" num="0089">In other embodiments, the chromaticity may not be set to be identical to the chromaticity of the input image. For example, in some embodiments, the chromaticity may be set to a predetermined value, and indeed this value may be constant for all pixels of the modified image. This may for example be used to provide a monochromatic image, such as a black and white (or greyscale image). Such an image may in some scenarios be easier to view at very low brightness settings. Also, in some embodiments, the display may have more efficient light emitters for some of the color primaries than for others, and by selecting the output color to correspond to power efficient primaries, an improved light output can be achieved for a given power consumption level.</p><p id="p0090" num="0090">The image generator 103 generates a modified image which has much lower luminance values and which can be presented with much lower power consumption but which still provides significant visual cues. The image generator 103 may for example scale the image to correspond to a desired (fixed) power consumption level.<!-- EPO <DP n="17"> --></p><p id="p0091" num="0091">The power consumption of e.g. an OLED display is proportional to the image load which for an RGB display may be defined as <maths id="math0001" num=""><math display="block"><mi>L</mi><mo>=</mo><mfenced separators=""><mstyle displaystyle="false"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>N</mi><mo>-</mo><mn>1</mn></mrow></munderover></mstyle><msub><mi>R</mi><mi>i</mi></msub><mo>+</mo><msub><mi>G</mi><mi>i</mi></msub><mo>+</mo><msub><mi>B</mi><mi>i</mi></msub></mfenced><mo>/</mo><mfenced separators=""><mn>3</mn><mo>⁢</mo><mi>N</mi></mfenced></math><img id="ib0001" file="imgb0001.tif" wi="68" he="18" img-content="math" img-format="tif"/></maths><br/>
where N is the total number of pixels and R<sub>i</sub>, G<sub>i</sub>, and B<sub>i</sub>, refer to the subpixel values in the linear light domain. It is noted that with the maximum luminance (full white, all sub-pixels set to 1 for drive values scaled to the interval of [0,1]) will result in 100% power consumption. The image generator 103 may then generate the modified image subject to a criterion that the image load (and thus power consumption) should be lower than a given threshold value. This threshold value may be a fixed predetermined value, or may e.g. be determined as function of the input image. For example, the threshold value may be determined as a function of the original image, for example by requiring that the modified image has an image load of no more than 10%, 5% or even 3% of the image load of the original image.</p><p id="p0092" num="0092">It will be appreciated that more complex and intelligent power management may be applied. For example, in situations where many pixels are calculated to be close to a maximum luminance, the threshold may be increased in order to prevent excessive amounts of signal clipping which may wash-out details and de-saturate the colors. Alternatively the threshold may be increased in order to prevent excessive heating of the display. The threshold may for example be set proportional to the display temperature (measured or modeled), i.e. the threshold may be set by thermal model or temperature sensor to reduce load in case of excessive heating.</p><p id="p0093" num="0093">The approach may allow an extreme reduction of the power consumption while capturing and enhancing the visibility of important features. Specifically, it may convert the original image into (possibly colored) contours or outlines that can be efficiently displayed by in particular emissive displays. The modified image represents a low-power version of the original image and may consist of dark flat regions and outlines defined by e.g. relatively few thin lines. Compared to the original image, the outlines/ transitions can therefore be much brighter for the same power consumption.<!-- EPO <DP n="18"> --></p><p id="p0094" num="0094">By allocating most of the energy to image transitional features, the brightness of details can be considerably enhanced while keeping the overall power consumption low. The approach may specifically exploit the fact that for emissive displays the brightness of individual pixels can be increased at low overall power cost.</p><p id="p0095" num="0095">The approach may be used in many different applications and user scenarios. For example, based on the user's attention, the image may switch between presenting the original image or the modified image. For example, it is an increasingly common usage scenario for televisions merely to be used to provide background content while a user is performing other tasks. In such scenarios, the television may be switched to provide a low power outline image which still allows information of the image to be gleaned.</p><p id="p0096" num="0096">As another example, the approach may be used to provide a standby operation wherein the full power image is presented during normal use, whereas a modified image is presented when switched the device is put in the stand-by mode. The modified image may for example be derived from a still image, such as a photo.</p><p id="p0097" num="0097">As yet another example, the approach may be used to reduce power consumption for battery powered devices, such as e.g. laptops, smartphones, tablets, remote controls, battery-powered televisions etc. This may for example be achieved by providing low power versions of various images to be displayed, such as when displaying websites etc.</p><p id="p0098" num="0098">In the example of <figref idrefs="f0001">FIG. 1</figref>, the modified image is presented directly. However, as illustrated in <figref idrefs="f0003">FIG. 3</figref>, in some embodiments the display driver 105 may be arranged to display an image from the original image and the modified image. The display image is then displayed by the display 107.</p><p id="p0099" num="0099">In some embodiments, the display driver 105 may simply select between the original image and the modified image, i.e. the display driver 105 may generate the displayed image as the power reduced image or the original full power image. The selection may for example be in response to a user input/ selection or may be fully or partially automatic.<!-- EPO <DP n="19"> --></p><p id="p0100" num="0100">In other embodiments, the display driver 105 may be a mixer or blender which can mix/blend the original image and the modified image. Thus, in such embodiments intermediate images between the extremes can be generated. Thus, a flexible and gradual emphasis of significant features and/or power consumption can be achieved.</p><p id="p0101" num="0101">As an example, such an approach may be used to provide a gradual transition between normal images and power reduced images. For example, when a television enters a reduced power mode, the display driver 105 may gradually reduce the weights of original image and increase the weight of the modified image in a weighted summation. When exiting the reduced power mode, the opposite operation may be performed.</p><p id="p0102" num="0102">In some embodiments, the display system may be a video display system and the images may be frames of a video sequence. In some such embodiments, the system may be arranged to only update the modified image for a subset of input images. In particular, the low-power modified image may be seen as an abstract version of the original image and accordingly the system may in some embodiments optionally update with a lower refresh rate than the input video in order to reduce computational cost. The refresh rate can e.g. be adjusted in response to the magnitude of the average or maximum temporal gradient (gradient between same pixel locations in consecutive frames).</p><p id="p0103" num="0103">It will be appreciated that different approaches for adjusting the luminances based on chrominance gradient values may be applied in different embodiments.</p><p id="p0104" num="0104"><figref idrefs="f0004">FIG. 4</figref> illustrates an example of the image generator 103. In the example, the image generator 103 is arranged to generate a gradient map for the input image and to determine the luminance of the modified image based on the gradient map.</p><p id="p0105" num="0105">Specifically, the image generator 103 comprises a gradient processor 401 which generates a gradient map/image. In the specific example, the gradient processor 401 determines a chrominance gradient value for each pixel position.<!-- EPO <DP n="20"> --></p><p id="p0106" num="0106">The gradient processor 401 is coupled to a luminance processor 403 which receives the gradient map. The luminance processor 403 then proceeds to generate luminance values for the modified image based on the gradient map.</p><p id="p0107" num="0107">Specifically, the luminance processor 403 may scale the luminance value of the original image in dependence on the gradient map to generate the modified image luminances. As a specific example, the luminance for a given pixel of the original image may first be determined (e.g. from RGB values or directly as the Y value of a Yuv representation). The luminance processor 403 may then scale this value by a scale factor that is dependent on the chrominance gradient for that pixel in the gradient map. The scale factor may typically be determined as a non-linear monotonically increasing function of the gradient value. Thus, typically a relatively high scale factor (resulting in a high luminance) is applied for pixels that have a high gradient value, i.e. where a significance chrominance change is occurring.</p><p id="p0108" num="0108">In other embodiments, the luminance of the original image is not considered, and the luminance for a position of the modified image is determined directly as a function of the gradient represented by the gradient map (image) at that position. This function may typically also be a non-linear monotonically increasing function of the gradient value.</p><p id="p0109" num="0109">In the example of <figref idrefs="f0004">FIG. 4</figref>, the scaling of the input image luminances or indeed the output luminances may thus for a given pixel be determined from the chrominance gradient value for the pixel.</p><p id="p0110" num="0110">The image generator 103 comprises a chromaticity processor 405 which determines chromaticity values of pixels of the modified image. In some embodiments, the chromaticity processor 405 may simply set the chromaticity values to a predetermined or fixed value. For example, a white or particularly efficient primary value may be set.</p><p id="p0111" num="0111">However, in the example of <figref idrefs="f0004">FIG. 4</figref>, the chromaticity values are determined from the input image. The chromaticity processor 405 is accordingly arranged to receive the original image and to generate chromaticity values for the modified image therefrom.<!-- EPO <DP n="21"> --></p><p id="p0112" num="0112">Specifically, the chromaticity value for a given pixel of the modified image may be set to the chromaticity value of the same pixel in the original image.</p><p id="p0113" num="0113">The luminance processor 403 and the chromaticity processor 405 are coupled to a combiner 407 which generates the modified image by combining the luminance values and the chromaticity values.</p><p id="p0114" num="0114">As an example, the original image may be provided in a Yuv color format or may be provided in an RGB color format that is converted into a Yuv format. The luminance value Y is modified by the luminance processor 403 to generate a modified luminance value dependent on the corresponding chrominance gradient, or alternatively a new luminance value may be generated directly from the gradient. The resulting image of luminance values Y are fed to the combiner 407. The chromaticity value pairs uv are fed to the chromaticity processor 405 which specifically may simply forward these without modification. A Yuv modified image is then generated by the combiner 407 by generating sets of Yuv values for each pixel. In case, an RGB modified image is desired the combiner 407 may perform a Yuv to RGB conversion.</p><p id="p0115" num="0115">Thus, in the example of <figref idrefs="f0004">FIG. 4</figref>, the image generator 103 determines a chrominance gradient map for the original image and then generates a modified image by setting the luminance of the modified image in response to the chrominance gradient map. Additionally, chromaticity values may be set to the same values as for the original image.</p><p id="p0116" num="0116">It will be appreciated that different approaches may be used for determining chrominance gradients. The chrominance gradient may specifically for each pixel be determined as a spatial rate of change in a luminance, chromaticity or combined luminance and chromaticity measure.</p><p id="p0117" num="0117">As a specific example, the change in luminance between adjacent pixels may be used as a chrominance gradient measure. As another example, the change in a chromaticity component may be used as a chrominance gradient, such as for example a change in a u or v value between adjacent pixels. As yet another example, the spatial change in one color channel (such as one of the R, G or B channels of an RGB image) may be used.<!-- EPO <DP n="22"> --></p><p id="p0118" num="0118">In some embodiments, chrominance gradient values may be determined in a plurality of directions for a given pixel. The chrominance gradient for the pixel may then be determined from the plurality of gradient values. Specifically, a maximum or average gradient value over the plurality of directions may be determined.</p><p id="p0119" num="0119">Additionally or alternatively, in some embodiments chrominance gradient values may be determined for a plurality of chrominance channels (including pure chromaticity or luminance channels). Specifically, chrominance gradient values may be determined for a plurality of color channels. The chrominance gradient for the pixel may then be determined from the plurality of gradient values. Specifically, a maximum or average gradient value over the plurality of chrominance channels (or color channels) may be determined.</p><p id="p0120" num="0120">In the specific example of <figref idrefs="f0004">FIG. 4</figref>, the gradient determination is based on four spatial differences (vertically up and down, horizontal left and right). In the example, the input image is an RGB image and for each direction, a change in the intensities of each of the three RGB channels is determined. This results in 12 gradient values. The gradient processor 401 then proceeds to determine the chrominance gradient for the pixel as the maximum gradient of the 12 gradient values. Practical experiments have demonstrated that such an approach provides a particularly useful estimation of the local gradients and results in advantageous identification of features that are suitable for being emphasized. It will be appreciated that other approaches may be used in other embodiments. For example, improved performance (at the expense of computational resource) may in some embodiments be found by determining gradient values for all nine neighbors of a pixel.</p><p id="p0121" num="0121">An example of a practical experiment applying the approach described above is illustrated in <figref idrefs="f0005">FIG 5</figref>. The figure shows greyscale photos of OLED displaying (to the left) an original image, and (to the right) the corresponding modified image. The power consumption of the modified image is only 2% of the original image. It should be noted that the photograph of the original image is considerably brighter and that a short shutter time has resulted in a noticeably darker background compared to the photograph of the modified image.<!-- EPO <DP n="23"> --></p><p id="p0122" num="0122">In some embodiments the image generator 103 may further comprise a processor arranged to process the map/image derived from the gradients. <figref idrefs="f0006">FIG. 6</figref> illustrates the image generator 103 including a post-processor 601 arranged to process the luminance image derived from the gradient map. However, it will be appreciated that in other embodiments, the processing may equivalently (e.g. partly) be applied to the gradient map rather than to the luminance image derived from the gradient map, e.g. the described processing may be applied to the output of the gradient processor 401. Indeed, in many embodiments, the luminance processor 403 may simply apply a simple e.g. linear function to the gradient map to determine luminance values. Thus, signal processing can equivalently be applied directly to gradient values or to luminance values derived from the gradient values (or partially to both). The following description will focus on the application of processing to the luminance image derived from the gradient map, but it will be appreciated that the operation may equivalently be applied to the gradient map. It will also be appreciated that the operations may (e.g. partly) be performed as part of the processing of the gradient map processor 401 or the luminance processor 403.</p><p id="p0123" num="0123">In some embodiments, the system may perform a contrast enhancement on the gradient map or the luminance image derived therefrom. In the example, the post-processor 601 may accordingly perform a contrast enhancement. In some scenarios and for some images, the gradient map/ luminance image may appear slightly noisy due to visibility of weak gradients. The application of a contrast enhancement step may reduce visibility of such noisy gradients and provide a more suitable modified image. It will be appreciated that any suitable contrast enhancement may be used. For example, it has been found that an approach of subtracting a constant value proportional to the average luminance/ gradient of the image from the luminance image/gradient map provided an improved contrast enhanced image.</p><p id="p0124" num="0124">In some embodiments, the system may apply an edge enhancement process. This may result in a clearer definition of outlines of image objects, and this may provide an image which an easier to perceive at extreme low overall brightness. Any suitable edge enhancement may be used.<!-- EPO <DP n="24"> --></p><p id="p0125" num="0125">In some embodiments, the post-processor 601 may be arranged to perform a spatial high pass filtering of the luminance image/ gradient map. This may result in a sharper definition of transitions between low gradient areas and high gradient areas thereby e.g. resulting in sharper outlines being drawn.</p><p id="p0126" num="0126">In some embodiments, the post-processor 601 may be arranged to perform a spatial low pass filtering of the luminance image/ gradient map. This may remove noise and in particular may reduce noise and variations within flat areas where low gradient values are found. Thus, it may generate an image wherein less significant features are further attenuated thereby providing a higher relative emphasis of significant features.</p><p id="p0127" num="0127">In some embodiments, the post-processor 601 may be arranged to perform a spatial band pass filtering of the luminance image/ gradient map. This may be optimized to both attenuate variations in flat areas yet provide a sharp outline transitions.</p><p id="p0128" num="0128">In some embodiments, the post-processor 601 may be arranged to perform a temporal filtering of the luminance image/ gradient map. In particular a temporal low pass filtering may be applied. In some scenarios flicker or other temporal artifacts may occur e.g. due to poor de-interlacing or noisy video. Such artifacts may effectively be reduced by performing a temporal low pass filtering of the gradient map or of the luminance signal derived therefrom.</p><p id="p0129" num="0129">In some embodiments, the image generator 103 is arranged to determine areas of high chrominance gradient by performing a segmentation of the original image. The segmentation can divide the image into areas that have similar chrominance properties. The inside of the individual segments may accordingly be considered to correspond to areas of relatively low chrominance gradients whereas the borders or transitions between the segments correspond to areas of high chrominance gradients.</p><p id="p0130" num="0130">As a specific example, the gradient processor 109 of <figref idrefs="f0001">FIG. 1</figref> may be arranged to perform a segmentation of the original image.</p><p id="p0131" num="0131">It will be appreciated that many different algorithms for image segmentation are known and that any of these may be used without detracting from the invention. For example,<!-- EPO <DP n="25"> --> segmentation may be performed based on super pixels. In this method, pixels are first combined into super-pixels based on local image properties. Thus, adjacent pixels having sufficiently similar luminance and chromaticity values are grouped together to form super-pixels. The method then proceeds to generate segments by grouping super-pixels together to provide segments that have very similar properties. The resulting image will thus have segments that are relatively flat and thus can be considered to have low chrominance gradients. The borders of the segments however may correspond to the transitions in the image and thus represent positions of high gradients. Typically, the segments will follow image objects and thus the borders of the segments tend to define outlines of image objects.</p><p id="p0132" num="0132">Following the segmentation, the gradient processor 109 may accordingly divide the image into regions of low chrominance gradients (corresponding to the inside/interior of the segments) and regions of high chrominance gradients (corresponding to the borders between segments).</p><p id="p0133" num="0133">As a specific example, the gradient processor 109 may generate border regions as a fixed number of pixels around a segment border. For example, all pixels within a given distance to a segment border may be considered to correspond to a border region and all pixels not within this distance may be considered to correspond to a non-border region. This threshold on the distance may for example be a predetermined value (say 10 or 20 pixels depending on how broad outline lines are desired) or may be dynamically determined (e.g. it may be dependent on luminance difference between the two segments divided by the border).</p><p id="p0134" num="0134">The resulting allocation of pixels into segment border regions and segment non-border regions is then communicated to the modification processor 111 which proceeds to generate the modified image by generating luminance values for the second image dependent on whether pixels belong to a border region or a non-border region. Thus the luminances are determined differently for segment border regions than for segment non-border regions.</p><p id="p0135" num="0135">In some embodiments, this may simply be done by allocating one luminance value to pixels in non-border regions and a different luminance value to pixels in border<!-- EPO <DP n="26"> --> regions. Typically, the first luminance value will be very dark (or even black) and the second luminance value will be relatively bright. A difference in luminance of at least 10dB or even 20dB or 30dB may often be applied.</p><p id="p0136" num="0136">In some embodiments, the modification processor 111 may generate the luminances of the segment and/or border regions from the luminance values of the original image. For example, a variable scaling may be applied. Specifically, the luminance values of all pixels within non-border regions may be reduced to a certain dynamic range corresponding to very dark values, or may e.g. be reduced by a constant factor (say 16dB). In contrast, the luminance of the pixels in the border regions may be maintained or may even be increased.</p><p id="p0137" num="0137">Performing a relative luminance determination may for example allow the system to generate a modified image as an outline image but with darker areas of the image still being darker and thus less noticeable. A more realistic image closer matching the original image may thus be generated.</p><p id="p0138" num="0138">In some embodiments, the system may furthermore reduce chrominance variations within non-border regions. Specifically, it may be arranged to reduce chromaticity variations within non-border regions. This may for example be achieved by applying spatial filtering to the non-border regions. Such an approach may remove or reduce texture thereby providing a flatter (and e.g. more "cartoonish") image which in many scenarios may be more suitable for low power viewing.</p><p id="p0139" num="0139">Images may come from many sources and be captured in many different ways, and in particular may be captured in many different aspect ratios. Similarly, displays have been developed with many different aspect ratios including the traditional 4:3 ratio, the more prevalent 16:9 ratio, or the less common 16:10 or 21:9 ratios. For this reason, images may be provided with framing image objects that define an active image area. For example, traditional 4:3 video sequences may be provided with vertical black bars to generate a 16:9 format; or a 16:9 format video may be provided with horizontal black bars to provide a 4:3 format etc.<!-- EPO <DP n="27"> --></p><p id="p0140" num="0140">The introduction of such framing image objects will typically result in a large chrominance gradient at the border of the framing object. However, in order to avoid that such a transition is highlighted in the modified image, the image generator 103 is in some embodiments arranged to detect chrominance gradient transitions that correspond to a framing image object and then to reduce the luminance for such a transition. The luminance may either be directly reduced in the modified image or this may be done indirectly by reducing the chrominance gradient value for the transition (e.g. directly in the gradient map.</p><p id="p0141" num="0141">It will be appreciated that different approaches for detecting edges of such framing objects may be used. For example, detection of horizontal bars may be achieved by first calculating the maximum value of the pixels (including the maximum of sub-pixels) in each line of the image. This provides a vector of maximum intensity values. The system may then proceed from top-to-bottom and from bottom-to-top using the criterion that if the maximum of the next line is below a value corresponding to a black bar (typically zero or very close to), then this line also belongs to the black bar. The edge is found for the first line for which the maximum is not below the threshold (i.e. the first line which is no longer "just black"). Detection of vertical black bars can be performed using the same approach and determining maxima of columns and moving left-to-right and right-to-left.</p><p id="p0142" num="0142"><figref idrefs="f0007">FIG. 7</figref> illustrates an example of such processing applied to an image. As shown, the input image has vertical black bars framing an active image area. From the image, a gradient map is generated. In addition, the image objects corresponding to the black bars are identified. The corresponding gradient transitions are then removed and the gradient map is used to provide the luminance image. Contrast enhancement and low pass filtering is applied to the resulting image to generate an extreme low power outline image.</p><p id="p0143" num="0143">In some implementations, the outlines in the gradient map may be slightly wider than the edge of a framing object. It may then be appreciated, that by applying morphological erosion to the vector of maximum intensity values and thereby extending the elements of zero (or very close to zero) values inwards towards the image centre, these wider outlines are also removed from the gradient map.<!-- EPO <DP n="28"> --></p><p id="p0144" num="0144">Over the years, the prevalence of displays and content has resulted in a different usage pattern emerging for displays. For example, whereas television was typically always the focus of concentrated attention a few decades ago, it is now increasingly being used as a background medium. For example, the television is on while the user is focusing on other activities such as surfing the internet, reading the newspaper, or perhaps carrying out household tasks such as ironing. However, although the television is only used as a background medium, the power consumption remains unchanged. Furthermore, powering the display off during such background use will result in the visual information completely disappearing and will be perceived to be inconvenient to the user. Similarly, dimming the screen will darken the image to a point where the visual information cannot be perceived at distance and/or will not provide any significant power reduction.</p><p id="p0145" num="0145">However, the Inventors have realized that a much improved user experience can be achieved by providing an low power image wherein visually important features have been highlighted by adjusting luminance characteristics in dependence on chrominance gradients.</p><p id="p0146" num="0146">An example of such a system is illustrated in <figref idrefs="f0008">FIG. 8</figref> which shows a display system corresponding to that of <figref idrefs="f0003">FIG. 3</figref> but further enhanced to include a user attention detector 801.</p><p id="p0147" num="0147">The user attention detector 801 generates a value which provides an estimate of whether the user is paying attention to the screen or not. It will be appreciated that any suitable algorithm or approach for generating a user attention indication may be used. For example, approaches have been developed which track a user's eyes and estimates whether these are directed to the screen or not.</p><p id="p0148" num="0148">As a specific example of a user attention, user distance from screen could be derived from the size of faces detected using a camera setup. One may compare the estimated distance with a threshold distance. For a plurality of users, the smallest estimate (closest to the screen) is used. Alternatively, a depth sensor based on structured light can be used in combination with face detection in order to accurately estimate the user<!-- EPO <DP n="29"> --> distance from the screen. It may also be possible to derive user attention from their horizontal position in the room etc.</p><p id="p0149" num="0149">The user attention detector 801 is coupled to the display driver 105 which is arranged to generate the output image based on the original image, the modified image and the user attention indication.</p><p id="p0150" num="0150">As a low complexity example, the display driver 105 may simply select between the original image and the modified image based on the user attention indication. Thus, if the indication is indicative of the user paying attention to the display 107, the display driver 105 selects the original image to be displayed. However, if the indicator is indicative of the user not paying attention to the screen, the display driver 105 switches to provide a display image corresponding to the modified image.</p><p id="p0151" num="0151">Thus, during normal operation no degradation is introduced. However, when the user is not paying attention, a very significant power consumption reduction is achieved and indeed the power consumption may be reduced to a few percent of the normal power consumption. Furthermore, this is achieved while still allowing the user to obtain information of the screen activity. For example, for a television, the user may still glean what is happening on the screen.</p><p id="p0152" num="0152">In some embodiments, the system does not perform a binary combination where the weights are either one or zero (i.e. corresponding to a selection) but combines the images using a gradual merging. Thus, fractional values of weights applied in the weighted combination (and specifically summation) may be used.</p><p id="p0153" num="0153">In some embodiments, the display may be battery operated. An example of such a system is shown in <figref idrefs="f0009">FIG. 9</figref> which corresponds to the system of <figref idrefs="f0003">FIG. 3</figref>. In the example of <figref idrefs="f0009">FIG. 9</figref>, the display 107 is driven by a power system 901 which comprises a battery that (at least sometimes) provides power to the display 107. Typically, the rest of the functionality will also be driven by the battery. For example, the system may be part of a mobile device such as a mobile phone or a tablet.<!-- EPO <DP n="30"> --></p><p id="p0154" num="0154">In the example, the system further comprises a battery detector 903 which is arranged to determine a battery status indication for the battery of the power system 901. The battery status indication may for example be an indication of a remaining charge of the battery.</p><p id="p0155" num="0155">In the example, the battery detector 903 is coupled to the display driver 105 which is arranged to generate the weighted combination between the original image and the modified image dependent on the battery status indication.</p><p id="p0156" num="0156">For example, a low complexity binary selection combination may be performed by setting the weight for the original image to one and the weight of the modified image to zero when the battery status indication indicates that the charge is above a given threshold. However, when the charge drops below the threshold, the weight for the modified image may be set to one and the weight of the original image may be set to zero. The same approach may alternatively or additionally be used in dependence on user interaction, for example dependent on whether a user is activating a touch screen or a keyboard.</p><p id="p0157" num="0157">Such an approach may provide a portable device which when reasonably charged provides a normal operation with a nice clear display that provides full information. However, when the battery charge drops below a given critical level, the portable device may automatically adapt to operate in a power save mode where the power consumption is substantially reduced. However, the approach will still allow the user to use and view the display and may thus the user can proceed to use the portable device.</p><p id="p0158" num="0158">In some embodiments, a more gradual change may be implemented where the output image is generated by blending the original image and the modified image. The image provided to the display may thus gradually transition from the original image to the modified image as the battery discharges.</p><p id="p0159" num="0159">As another example, the battery status indication may indicate whether the device is externally powered or whether it is powered by the battery. The device may then switch between the low power modified image and the high power original image depending on whether external power is provided.<!-- EPO <DP n="31"> --></p><p id="p0160" num="0160">In the previous example, the combination of the original image and the modified image was dependent on the battery status indicator. However, alternatively or additionally, the determination of the luminance of the modified image may be dependent on the battery status indicator.</p><p id="p0161" num="0161">For example, in embodiments wherein the luminance of the modified image is determined by scaling the original image luminances by a scale factor dependent on the chrominance gradient, the function used to determine the scale factor based on the chrominance gradient may be dependent on the battery status indication.</p><p id="p0162" num="0162">For example, for a fully charged battery, the scale factors may only be varied between, say, 80% and 100% dependent on the chrominance gradient value. This may result in a relatively minor emphasis of the visually significant features and may be used to perform a relatively minor power reduction. However, as the battery is discharged, the range used for scale factors may be increased. For example, when only 10% of the battery charge remains, the scale factors may be between 0 and 1 thereby allowing a more extreme power reduction. Furthermore, the non-linearity between the chrominance gradients and the scale factors may be increased as the battery charge reduces.</p><p id="p0163" num="0163">Such an approach may provide a flexible and attractive power management system wherein battery life may be extended substantially.</p><p id="p0164" num="0164">It will be appreciated that the above description for clarity has described embodiments of the invention with reference to different functional circuits, units and processors. However, it will be apparent that any suitable distribution of functionality between different functional circuits, units or processors may be used without detracting from the invention. For example, functionality illustrated to be performed by separate processors or controllers may be performed by the same processor or controllers. Hence, references to specific functional units or circuits are only to be seen as references to suitable means for providing the described functionality rather than indicative of a strict logical or physical structure or organization.<!-- EPO <DP n="32"> --></p><p id="p0165" num="0165">The invention can be implemented in any suitable form including hardware, software, firmware or any combination of these. The invention may optionally be implemented at least partly as computer software running on one or more data processors and/or digital signal processors. The elements and components of an embodiment of the invention may be physically, functionally and logically implemented in any suitable way. Indeed the functionality may be implemented in a single unit, in a plurality of units or as part of other functional units. As such, the invention may be implemented in a single unit or may be physically and functionally distributed between different units, circuits and processors.</p><p id="p0166" num="0166">Although the present invention has been described in connection with some embodiments, it is not intended to be limited to the specific form set forth herein. Rather, the scope of the present invention is limited only by the accompanying claims. Additionally, although a feature may appear to be described in connection with particular embodiments, one skilled in the art would recognize that various features of the described embodiments may be combined in accordance with the invention. In the claims, the term comprising does not exclude the presence of other elements or steps.</p><p id="p0167" num="0167">Furthermore, although individually listed, a plurality of means, elements, circuits or method steps may be implemented by e.g. a single circuit, unit or processor. Additionally, although individual features may be included in different claims, these may possibly be advantageously combined, and the inclusion in different claims does not imply that a combination of features is not feasible and/or advantageous. Also the inclusion of a feature in one category of claims does not imply a limitation to this category but rather indicates that the feature is equally applicable to other claim categories as appropriate. Furthermore, the order of features in the claims do not imply any specific order in which the features must be worked and in particular the order of individual steps in a method claim does not imply that the steps must be performed in this order. Rather, the steps may be performed in any suitable order. In addition, singular references do not exclude a plurality. Thus references to "a", "an", "first", "second" etc do not preclude a plurality. Reference signs in the claims are provided merely as a clarifying example shall not be construed as limiting the scope of the claims in any way.</p></description><claims mxw-id="PCLM56981996" lang="EN" load-source="patent-office"><!-- EPO <DP n="33"> --><claim id="c-en-0001" num="0001"><claim-text>An image processing apparatus comprising:
<claim-text>a receiver (101) for receiving a first image;</claim-text>
<claim-text>an image generator (103) for generating a second image by setting luminances of the second image in response to chrominance gradients of the first image.</claim-text></claim-text></claim><claim id="c-en-0002" num="0002"><claim-text>The image processing apparatus of claim 1 wherein the image generator (103) is arranged to set luminances of the second image as a monotonically increasing function of the chrominance gradients.</claim-text></claim><claim id="c-en-0003" num="0003"><claim-text>The image processing apparatus of claim 1 or 2 wherein the image generator (103) is arranged to generate the second image to have an average luminance of no more than 10% of an average luminance of the first image.</claim-text></claim><claim id="c-en-0004" num="0004"><claim-text>The image processing apparatus of claim 1, 2 or 3 wherein the image generator (103) comprises:
<claim-text>a gradient processor (401) for generating a gradient map for the first image;</claim-text>
<claim-text>a luminance processor (403) for setting the luminance values of pixels of the second image as a function of gradient values of corresponding positions in the gradient map.</claim-text></claim-text></claim><claim id="c-en-0005" num="0005"><claim-text>The image processing apparatus of claim 4 wherein the image generator (103) further comprises:
<claim-text>a chromaticity processor (405) for setting chromaticity values of pixels of the second image as a function of chromaticity values of corresponding positions in the first image.</claim-text></claim-text></claim><claim id="c-en-0006" num="0006"><claim-text>The image processing apparatus of claim 4 or 5 wherein the image generator (103) further comprises a processor (601) for processing at least one of the gradient map and a luminance image derived from the gradient map, the processor (601) being arranged to perform at least one of:
<claim-text>a contrast enhancement;<!-- EPO <DP n="34"> --></claim-text>
<claim-text>an edge enhancement;</claim-text>
<claim-text>a spatial high pass filtering;</claim-text>
<claim-text>a spatial low pass filtering;</claim-text>
<claim-text>a spatial band pass filtering; and</claim-text>
<claim-text>a temporal filtering.</claim-text></claim-text></claim><claim id="c-en-0007" num="0007"><claim-text>The image processing apparatus of claim 4 wherein the gradient processor (401) is arranged to determine a chrominance gradient value in a plurality of directions for a first image position, and to determine a chrominance gradient for the gradient map for the first image position from the chrominance gradient values in the plurality of directions.</claim-text></claim><claim id="c-en-0008" num="0008"><claim-text>The image processing apparatus of claim 4 or 7 wherein the gradient processor (401) is arranged to determine a gradient for a plurality of chrominance channels for a first image position, and to determine a chrominance gradient for the gradient map for the first image position from the gradients in the plurality of chrominance channels.</claim-text></claim><claim id="c-en-0009" num="0009"><claim-text>The image processing apparatus of claim 1, 2 or 3 wherein the image generator (103) comprises:
<claim-text>a segmenter (109) for segmenting the first image into segments in response to chrominance properties;</claim-text>
<claim-text>a luminance processor (111) arranged to generate luminance values for the second image by determining luminances of the first image differently for segment border regions than for segment non-border regions.</claim-text></claim-text></claim><claim id="c-en-0010" num="0010"><claim-text>The image processing apparatus of claim 9 wherein the image generator (103) is arranged to reduce chrominance variations within non-border regions.</claim-text></claim><claim id="c-en-0011" num="0011"><claim-text>The image processing apparatus of claim 1 further comprising an image generator (103) for generating a third image by combining the first and second image.</claim-text></claim><claim id="c-en-0012" num="0012"><claim-text>The image processing apparatus of claim 1 wherein the image generator (103) is arranged to detect a first chrominance transition corresponding to an image object<!-- EPO <DP n="35"> --> framing an active image area, and to reduce luminance for the second image for the first chrominance transition.</claim-text></claim><claim id="c-en-0013" num="0013"><claim-text>A display system comprising the image processing apparatus of claim 1 and further comprising a display (107), the display system further comprising a display driver (105) arranged to generate a display image for displaying by the display (107) from the second image.</claim-text></claim><claim id="c-en-0014" num="0014"><claim-text>The display system of claim 13 further comprising a user attention detector (801) for generating an indication of user attentiveness; and wherein the display driver (105) is arranged to generate the display image in response to a combination of the first and second image dependent on the indication of user attentiveness.</claim-text></claim><claim id="c-en-0015" num="0015"><claim-text>The display system of claim 13 further comprising a battery status detector (901) for generating a battery status indication for a battery powering the display (107); and wherein the display driver (105) is arranged to generate the display image in response to a combination of the first and second image dependent on the battery status indication.</claim-text></claim><claim id="c-en-0016" num="0016"><claim-text>The display system of claim 13 further comprising a battery status detector (901) for generating a battery status indication for a battery powering the display (107); and wherein the image generator (103) is arranged to determine the luminance of the second image in response to the battery status.</claim-text></claim><claim id="c-en-0017" num="0017"><claim-text>A method of generating an image, the method comprising:
<claim-text>receiving a first image;</claim-text>
<claim-text>generating a second image by setting luminances of the second image in response to chrominance gradients of the first image.</claim-text></claim-text></claim><claim id="c-en-0018" num="0018"><claim-text>A computer program product comprising computer program code means adapted to perform all the steps of claim 17 when said program is run on a computer.</claim-text></claim></claims><drawings mxw-id="PDW16670391" load-source="patent-office"><!-- EPO <DP n="36"> --><figure id="f0001" num="1"><img id="if0001" file="imgf0001.tif" wi="165" he="130" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="37"> --><figure id="f0002" num="2"><img id="if0002" file="imgf0002.tif" wi="165" he="145" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="38"> --><figure id="f0003" num="3"><img id="if0003" file="imgf0003.tif" wi="163" he="146" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="39"> --><figure id="f0004" num="4"><img id="if0004" file="imgf0004.tif" wi="165" he="183" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="40"> --><figure id="f0005" num="5"><img id="if0005" file="imgf0005.tif" wi="136" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="41"> --><figure id="f0006" num="6"><img id="if0006" file="imgf0006.tif" wi="162" he="144" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="42"> --><figure id="f0007" num="7"><img id="if0007" file="imgf0007.tif" wi="165" he="183" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="43"> --><figure id="f0008" num="8"><img id="if0008" file="imgf0008.tif" wi="165" he="173" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="44"> --><figure id="f0009" num="9"><img id="if0009" file="imgf0009.tif" wi="156" he="190" img-content="drawing" img-format="tif"/></figure></drawings><search-report-data><doc-page id="srep0001" file="srep0001.tif" wi="156" he="233" type="tif"/><doc-page id="srep0002" file="srep0002.tif" wi="156" he="233" type="tif"/><doc-page id="srep0003" file="srep0003.tif" wi="158" he="233" type="tif"/><doc-page id="srep0004" file="srep0004.tif" wi="158" he="233" type="tif"/></search-report-data><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
