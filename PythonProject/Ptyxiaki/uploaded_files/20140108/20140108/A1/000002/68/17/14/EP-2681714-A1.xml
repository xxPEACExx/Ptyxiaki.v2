<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2681714-A1" country="EP" doc-number="2681714" kind="A1" date="20140108" family-id="45930967" file-reference-id="318301" date-produced="20180822" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="146586092" ucid="EP-2681714-A1"><document-id><country>EP</country><doc-number>2681714</doc-number><kind>A1</kind><date>20140108</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-12712422-A" is-representative="NO"><document-id mxw-id="PAPP154848284" load-source="docdb" format="epo"><country>EP</country><doc-number>12712422</doc-number><kind>A</kind><date>20120229</date><lang>EN</lang></document-id><document-id mxw-id="PAPP174953047" load-source="docdb" format="original"><country>EP</country><doc-number>12712422.0</doc-number><date>20120229</date></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC140548399" ucid="TR-201101980-A" load-source="docdb"><document-id format="epo"><country>TR</country><doc-number>201101980</doc-number><kind>A</kind><date>20110301</date></document-id></priority-claim><priority-claim mxw-id="PPC140555021" ucid="TR-2012000039-W" linkage-type="W" load-source="docdb"><document-id format="epo"><country>TR</country><doc-number>2012000039</doc-number><kind>W</kind><date>20120229</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL1989319088" load-source="docdb">G06T   7/00        20060101AFI20120917BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-1861392073" load-source="docdb" scheme="CPC">G06T   7/11        20170101 LI20170102BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1861392099" load-source="docdb" scheme="CPC">G06T   7/155       20170101 LI20170102BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2051731745" load-source="docdb" scheme="CPC">G06T2207/30181     20130101 LA20150519BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2051734299" load-source="docdb" scheme="CPC">G06T2207/10032     20130101 LA20150519BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2051734795" load-source="docdb" scheme="CPC">G06T2207/30184     20130101 LA20150519BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2051735586" load-source="docdb" scheme="CPC">G06T2207/20036     20130101 LA20150519BHEP        </classification-cpc><classification-cpc mxw-id="PCL2032328586" load-source="docdb" scheme="CPC">G06T   7/0081      20130101 FI20140221BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT132362909" lang="DE" load-source="patent-office">OBJEKTBASIERTES SEGMENTIERUNGSVERFAHREN</invention-title><invention-title mxw-id="PT132362910" lang="EN" load-source="patent-office">AN OBJECT BASED SEGMENTATION METHOD</invention-title><invention-title mxw-id="PT132362911" lang="FR" load-source="patent-office">PROCÉDÉ DE SEGMENTATION BASÉE OBJET</invention-title></technical-data><parties><applicants><applicant mxw-id="PPAR919509567" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>ULUSOY ILKAY</last-name><address><country>TR</country></address></addressbook></applicant><applicant mxw-id="PPAR919537848" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>ULUSOY, Ilkay</last-name></addressbook></applicant><applicant mxw-id="PPAR919017574" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Ulusoy, Ilkay</last-name><iid>101335415</iid><address><street>ODTU, Elektrik Elektronik Muh. Bolumu</street><city>06531 Ankara</city><country>TR</country></address></addressbook></applicant><applicant mxw-id="PPAR919523899" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>AYTEKIN ORSAN</last-name><address><country>TR</country></address></addressbook></applicant><applicant mxw-id="PPAR919537943" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>AYTEKIN, Orsan</last-name></addressbook></applicant><applicant mxw-id="PPAR919011646" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>Aytekin, Orsan</last-name><iid>101335417</iid><address><street>ODTU KOSGEB Teknoloji Gelistirme Merkezi Mudurlugu, No:208 Cankaya</street><city>06531 Ankara</city><country>TR</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR919509603" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>ULUSOY ILKAY</last-name><address><country>TR</country></address></addressbook></inventor><inventor mxw-id="PPAR919507179" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>ULUSOY, Ilkay</last-name></addressbook></inventor><inventor mxw-id="PPAR919019506" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>ULUSOY, Ilkay</last-name><address><street>ODTU, Elektrik Elektronik Muh. Bolumu</street><city>06531 Ankara</city><country>TR</country></address></addressbook></inventor><inventor mxw-id="PPAR919527583" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>AYTEKIN ORSAN</last-name><address><country>TR</country></address></addressbook></inventor><inventor mxw-id="PPAR919518648" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>AYTEKIN, Orsan</last-name></addressbook></inventor><inventor mxw-id="PPAR919010618" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>AYTEKIN, Orsan</last-name><address><street>ODTU KOSGEB Teknoloji Gelistirme Merkezi Mudurlugu, No:208 Cankaya</street><city>06531 Ankara</city><country>TR</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR919014573" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Berkkam, Ayfer</last-name><iid>101119152</iid><address><street>AZe Patent Marka Ltd. Becker-Gundahl-Strasse 49</street><city>81479 Munich</city><country>DE</country></address></addressbook></agent></agents></parties><international-convention-data><pct-or-regional-filing-data ucid="TR-2012000039-W"><document-id><country>TR</country><doc-number>2012000039</doc-number><kind>W</kind><date>20120229</date><lang>EN</lang></document-id></pct-or-regional-filing-data><pct-or-regional-publishing-data ucid="WO-2012118459-A1"><document-id><country>WO</country><doc-number>2012118459</doc-number><kind>A1</kind><date>20120907</date><lang>EN</lang></document-id></pct-or-regional-publishing-data><designated-states><ep-contracting-states><country mxw-id="DS549831093" load-source="docdb">AL</country><country mxw-id="DS549844739" load-source="docdb">AT</country><country mxw-id="DS549831098" load-source="docdb">BE</country><country mxw-id="DS549756821" load-source="docdb">BG</country><country mxw-id="DS549756216" load-source="docdb">CH</country><country mxw-id="DS549834043" load-source="docdb">CY</country><country mxw-id="DS549844740" load-source="docdb">CZ</country><country mxw-id="DS549832867" load-source="docdb">DE</country><country mxw-id="DS549834044" load-source="docdb">DK</country><country mxw-id="DS549834045" load-source="docdb">EE</country><country mxw-id="DS549913242" load-source="docdb">ES</country><country mxw-id="DS549756822" load-source="docdb">FI</country><country mxw-id="DS549756823" load-source="docdb">FR</country><country mxw-id="DS549831099" load-source="docdb">GB</country><country mxw-id="DS549831100" load-source="docdb">GR</country><country mxw-id="DS549831101" load-source="docdb">HR</country><country mxw-id="DS549844741" load-source="docdb">HU</country><country mxw-id="DS549756221" load-source="docdb">IE</country><country mxw-id="DS549831106" load-source="docdb">IS</country><country mxw-id="DS549756824" load-source="docdb">IT</country><country mxw-id="DS549834050" load-source="docdb">LI</country><country mxw-id="DS549832868" load-source="docdb">LT</country><country mxw-id="DS549844746" load-source="docdb">LU</country><country mxw-id="DS549832869" load-source="docdb">LV</country><country mxw-id="DS549832874" load-source="docdb">MC</country><country mxw-id="DS549763943" load-source="docdb">MK</country><country mxw-id="DS549763944" load-source="docdb">MT</country><country mxw-id="DS549756829" load-source="docdb">NL</country><country mxw-id="DS549913243" load-source="docdb">NO</country><country mxw-id="DS549756830" load-source="docdb">PL</country><country mxw-id="DS549763953" load-source="docdb">PT</country><country mxw-id="DS549756831" load-source="docdb">RO</country><country mxw-id="DS549763954" load-source="docdb">RS</country><country mxw-id="DS549756832" load-source="docdb">SE</country><country mxw-id="DS549763955" load-source="docdb">SI</country><country mxw-id="DS549756222" load-source="docdb">SK</country><country mxw-id="DS549756223" load-source="docdb">SM</country><country mxw-id="DS549832875" load-source="docdb">TR</country></ep-contracting-states></designated-states></international-convention-data><office-specific-data><eptags><ep-no-a-document-published>*</ep-no-a-document-published></eptags></office-specific-data></bibliographic-data><abstract mxw-id="PA99831232" ref-ucid="WO-2012118459-A1" lang="EN" load-source="patent-office"><p num="0000">This invention is related to a method that enables the object based segmentation of especially air/satellite images that are displayed in high resolution. The aim of the invention is to determine automatically the borders of objects by using statistical, spatial and structural relationships/characteristics and also by using high resolution air/satellite image data. Another aim of the invention is to develop a method that can operate by being minimally affected by limiting aspects such as ambient light, weather conditions or resolution and that can provide the determination of an object as a whole instead of sensing it in pixels.</p></abstract><abstract mxw-id="PA100328056" ref-ucid="WO-2012118459-A1" lang="EN" source="national office" load-source="docdb"><p>This invention is related to a method that enables the object based segmentation of especially air/satellite images that are displayed in high resolution. The aim of the invention is to determine automatically the borders of objects by using statistical, spatial and structural relationships/characteristics and also by using high resolution air/satellite image data. Another aim of the invention is to develop a method that can operate by being minimally affected by limiting aspects such as ambient light, weather conditions or resolution and that can provide the determination of an object as a whole instead of sensing it in pixels.</p></abstract><abstract mxw-id="PA99831233" ref-ucid="WO-2012118459-A1" lang="FR" load-source="patent-office"><p num="0000">La présente invention concerne un procédé permettant la segmentation basée objet d'images aériennes/satellites, principalement, qui sont affichées en haute résolution. L'invention a pour objet de déterminer automatiquement les limites d'objets à l'aide de relations/caractéristiques statistiques, spatiales et structurelles, et également à l'aide de données d'images aériennes/satellites haute résolution. Un autre objet de l'invention consiste à développer un procédé qui peut fonctionner en étant affecté de façon minime par des aspects limitants tels que la lumière ambiante, les conditions atmosphériques ou la résolution et qui peut fournir la détermination d'un objet dans sa totalité au lieu de sa détection en pixels.</p></abstract><abstract mxw-id="PA100328057" ref-ucid="WO-2012118459-A1" lang="FR" source="national office" load-source="docdb"><p>La présente invention concerne un procédé permettant la segmentation basée objet d'images aériennes/satellites, principalement, qui sont affichées en haute résolution. L'invention a pour objet de déterminer automatiquement les limites d'objets à l'aide de relations/caractéristiques statistiques, spatiales et structurelles, et également à l'aide de données d'images aériennes/satellites haute résolution. Un autre objet de l'invention consiste à développer un procédé qui peut fonctionner en étant affecté de façon minime par des aspects limitants tels que la lumière ambiante, les conditions atmosphériques ou la résolution et qui peut fournir la détermination d'un objet dans sa totalité au lieu de sa détection en pixels.</p></abstract><description mxw-id="PDES51232488" ref-ucid="WO-2012118459-A1" lang="EN" load-source="patent-office"><!-- EPO <DP n="2"/>--><p id="p0001" num="0001"> AN OBJECT BASED SEGMENTATION METHOD </p><p id="p0002" num="0002">Technical Field </p><p id="p0003" num="0003"> This invention is related to a method that enables object based segmentation of especially air/satellite photographs that are viewed in high resolution. </p><p id="p0004" num="0004">State of the art (Background art) </p><p id="p0005" num="0005"> Various methods are being used in order to determine the borders of the objects in photographs in the state of the art. Some of these methods enable the segmentation of objects with the aid of frames in relation to determine the edges of the objects and the elements that separate these objects from other objects. Such a method is described in a PCT of a patent application numbered WO 2009/157946. </p><p id="p0006" num="0006"> Similarly in a USA patent numbered US 2007/253609 a method that is used to separate heart tissue with segmentation is described. </p><p id="p0007" num="0007"> It is aimed to carry out an information inference with 2 dimension with the said methods and generally sections are extracted to obtain 3 dimensional data and then the processes are repeated. However, it is impossible to understand the heights of objects when we only have one image data in our use. </p><p id="p0008" num="0008"> Another example known in the state of the art is described in the Chinese Patent application numbered CN101706950A. In this application a method which divides large images into small pieces and then puts them back together after processing procedures are carried out in these small pieces, is described. </p><p id="p0009" num="0009">Brief Description of the Invention </p><p id="p0010" num="0010"> The aim of the invention is to be able to determine the borders and outlines of objects automatically with the usage of statistical, spatial and structural features/relationships and with the usage of high resolution air/satellite image data. Another aim of the invention is to develop a method which enables to define the object as a whole instead of just a pixel and which can operate and work by being minimally affected by restricting elements such as ambient light, air conditions or resolution. 
<!-- EPO <DP n="3"/>-->
 Detailed description of the invention </p><p id="p0011" num="0011"> The invention uses a single band of the image data. This said band can be a grayscale band or it can be different spectral bands. The image data carries out a process with each pixel group in order to primarily determine primitive structures. </p><p id="p0012" num="0012"> Subsequently, the determination of the objects is provided by grouping the possible identical primitive structures together. </p><p id="p0013" num="0013"> By this means for an object to be perceived as a different object from its own because a part of this said object being less brighter due to a height difference or due to having its own shadow will be prevented. </p><p id="p0014" num="0014">This invention comprises 4 main steps in its most basic form: </p><p id="p0015" num="0015"> 1. To draw out primitive structures formed by pixel groups which have homogeneous brightness values within themselves following morphologic operations and to deduce the spatial size of the primitive structures, </p><p id="p0016" num="0016"> o Morphological opening and closing operations will be carried out by using an increasingly large disk type structuring elements. These operations will be carried out for each pixel until the first local maximum is reached and the diameter of the first local maximum structuring element and the type of opening/closing operation will be appointed as the attribute of that pixel. o All pixels with the same attributes are grouped together and primitive structures are obtained. </p><p id="p0017" num="0017"> 2. To establish primitive objects by measuring statistically the similarities of the primitive structures with their neighboring primitive structures and then regrouping the similar structures, </p><p id="p0018" num="0018"> o The mean value and standard deviation of the primitive structures are calculated. </p><p id="p0019" num="0019"> o Each primitive structure will be matched with the neighboring primitive structure which has the closest standard deviation and the mean value to itself. </p><p id="p0020" num="0020"> o If any of the primitive structures are not matched with any of its neighboring structures that structure will be a meaningful and different structure from its neighboring structures. If it has been matched with at least one of its neighboring structures that structure will be deemed to be a more meaningful 
<!-- EPO <DP n="4"/>-->
 structure collectively together with its neighbors and by joining this structure with its matching neighbors a primitive object will be obtained. </p><p id="p0021" num="0021"> 3. The determination of the range at each pixel that shows change in terms of spatial size and brightness values of the primitive objects, </p><p id="p0022" num="0022"> o The range value at a pixel will be determined as the standard deviation of the primitive object that contains the pixel. </p><p id="p0023" num="0023"> o The spatial size at a pixel is determined as the size (pixel count) of the primitive object that contains the pixel. </p><p id="p0024" num="0024"> 4. To filter the image by accepting that the spatial and range sizes of the primitive objects provide an estimate of the mean shift technique's bandwidths (range and spatial bandwidths) and to determine the preferred objects by grouping (segmenting) the pixels that belong to the same mode. </p><p id="p0025" num="0025"> o The mean shift method is dependent on estimating a density gradient. The thing that determines the segmenting resolution is the size of the bandwidths. The mean shift vector is the vector difference of the average of the points inside the bandwidths around the pixel at the test point and the said vector. The mean shift vector is proportional to the density gradient at that said point. The mean shift vector calculated iteratively converges to zero which addresses convergence point. It is deduced that the convergence point corresponds to a meaningful mode inside the tested picture or an object inside the picture. The pixels that establish connected components which converge to the same point and are within the range value of that point are grouped and segments are determined. </p><p id="p0026" num="0026"> The four steps described above can be used for other spectral bands one after the other and it can also be used to determine separate segments for each band. In order to reach more meaningful results by comparing the segments in the separate bands that have been obtained, the data acquired can be combined. </p><p id="p0027" num="0027"> It is possible to perform a segmentation procedure by separately applying the above mentioned steps for each frame of the video images that roll one after the other. Following this process the motion of an object can be determined by determining the relationship of each segment inside the frames to each other. 
</p></description><claims mxw-id="PCLM44851639" ref-ucid="WO-2012118459-A1" lang="EN" load-source="patent-office"><claim-statement><!-- EPO <DP n="5"/>--> CLAIMS </claim-statement><claim id="clm-0001" num="1"><claim-text> An object based segmentation method characterized in that it comprises the following steps in order to ensure segmentation of objects in an image; </claim-text><claim-text> o To carry out morphological opening and closing operations until a first local maximum is obtained for each pixel by using an increasingly large disk type structuring elements, </claim-text><claim-text> o To appoint the diameter of the first local maximum structuring element and the type of opening/closing operation as the attribute of that pixel, o To group all pixels with the same attributes together to obtain primitive structures, </claim-text><claim-text> • in order to draw out primitive structures formed by pixel groups which have homogeneous brightness values within themselves following morphologic operations and to deduce the spatial size of the primitive structures; </claim-text><claim-text> o To calculate the mean value and standard deviation of the primitive structures, </claim-text><claim-text> o To match each primitive structure with the neighboring primitive structure which has the closest standard deviation and mean value to itself,</claim-text><claim-text>• in order to establish primitive objects by measuring statistically the similarities of the primitive structures with their neighboring primitive structures and then regrouping the similar structures; </claim-text><claim-text> o to determine the range value at a pixel as the standard deviation of the primitive object that contains the pixel, </claim-text><claim-text> o to determine the spatial size at a pixel as the size (pixel count) of the primitive object that contains the pixel, </claim-text><claim-text> • in order to determine the range that shows change in terms of spatial size and brightness values of the primitive objects; </claim-text><claim-text> o to calculate the vectoral difference in relation to the pixel of the average of the points inside the bandwidths around the pixel at the mean shift test point and the segmentation resolution determined in proportion to the size of the bandwidths used with the mean shift method which is based on estimating the density gradient, <!-- EPO <DP n="6"/>--> o to assume that the zero convergence point corresponds to a meaningful mode inside the tested picture or an object inside the picture, </claim-text><claim-text> o to group and determine the segments of the pixels that establish connected components which converge to the same point and which are within the range value of that said point, </claim-text><claim-text> • in order to filter the image by accepting that the spatial and range sizes of the primitive objects provide an estimate of the mean shift technique's bandwidths (range and spatial bandwidths) and to determine the preferred objects by grouping (segmenting) the pixels that belong to the same mode. </claim-text></claim><claim id="clm-0002" num="2"><claim-text>2. An object based segmentation method according to Claim 1 characterized in that it comprises the step of determining during the related matching with a neighboring primitive structure that a structure which cannot be matched with any neighboring structures is assumed to be a meaningful structure on its own being different from its neighbors. </claim-text></claim><claim id="clm-0003" num="3"><claim-text>3. An object based segmentation method according to any of the preceding claims characterized in that, it comprises the step of obtaining a primitive object by assuming that a structure is more meaningful collectively together with the matching neighbor structure if any of the primitive structures have been matched with at least one of its neighboring structures and by combining this structure with this neighboring matched structure or structures. </claim-text></claim></claims><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
