<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2683179-A1" country="EP" doc-number="2683179" kind="A1" date="20140108" family-id="46724216" file-reference-id="318308" date-produced="20180824" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="146585070" ucid="EP-2683179-A1"><document-id><country>EP</country><doc-number>2683179</doc-number><kind>A1</kind><date>20140108</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-12175247-A" is-representative="YES"><document-id mxw-id="PAPP154847262" load-source="docdb" format="epo"><country>EP</country><doc-number>12175247</doc-number><kind>A</kind><date>20120706</date><lang>EN</lang></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC140550813" ucid="EP-12175247-A" load-source="docdb"><document-id format="epo"><country>EP</country><doc-number>12175247</doc-number><kind>A</kind><date>20120706</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL2102370370" load-source="ipcr">H04R   3/00        20060101ALN20140718BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL2102377410" load-source="ipcr">H04R  25/00        20060101AFI20140718BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL1991310077" load-source="docdb" scheme="CPC">H04R2225/43        20130101 LA20140110BHEP        </classification-cpc><classification-cpc mxw-id="PCL1991310455" load-source="docdb" scheme="CPC">H04R  25/407       20130101 LA20140110BHEP        </classification-cpc><classification-cpc mxw-id="PCL1991311958" load-source="docdb" scheme="CPC">H04R2430/03        20130101 LA20140110BHEP        </classification-cpc><classification-cpc mxw-id="PCL1991312967" load-source="docdb" scheme="CPC">H04R  25/353       20130101 FI20140110BHEP        </classification-cpc><classification-cpc mxw-id="PCL1991314830" load-source="docdb" scheme="CPC">H04R  25/552       20130101 LI20140110BHEP        </classification-cpc><classification-cpc mxw-id="PCL2079272416" load-source="docdb" scheme="CPC">H04R  25/43        20130101 LI20140527BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT132359843" lang="DE" load-source="patent-office">Binaurales Hörgerät mit Frequenzdemaskierung</invention-title><invention-title mxw-id="PT132359844" lang="EN" load-source="patent-office">A binaural hearing aid with frequency unmasking</invention-title><invention-title mxw-id="PT132359845" lang="FR" load-source="patent-office">Aide auditive binaurale avec démasquage de la fréquence</invention-title><citations><patent-citations><patcit mxw-id="PCIT242942983" load-source="docdb" ucid="EP-2360943-A1"><document-id format="epo"><country>EP</country><doc-number>2360943</doc-number><kind>A1</kind><date>20110824</date></document-id><sources><source name="SEA" category="A" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT242942982" load-source="docdb" ucid="US-20100067721-A1"><document-id format="epo"><country>US</country><doc-number>20100067721</doc-number><kind>A1</kind><date>20100318</date></document-id><sources><source name="SEA" category="X" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT242942981" load-source="docdb" ucid="WO-2002007479-A1"><document-id format="epo"><country>WO</country><doc-number>2002007479</doc-number><kind>A1</kind><date>20020124</date></document-id><sources><source name="APP" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT242942984" load-source="docdb" ucid="WO-2012076044-A1"><document-id format="epo"><country>WO</country><doc-number>2012076044</doc-number><kind>A1</kind><date>20120614</date></document-id><sources><source name="SEA" category="A" created-by-npl="N"/></sources></patcit></patent-citations><non-patent-citations><nplcit><text>KLAUS REINDL ET AL:  "Speech enhancement for binaural hearing aids based on blind source separation", COMMUNICATIONS, CONTROL AND SIGNAL PROCESSING (ISCCSP), 2010 4TH INTERNATIONAL SYMPOSIUM ON, IEEE, PISCATAWAY, NJ, USA, 3 March 2010 (2010-03-03), pages 1-6, XP031675605, ISBN: 978-1-4244-6285-8</text><sources><source mxw-id="PNPL45210827" load-source="docdb" name="SEA" category="A"/></sources></nplcit></non-patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR919534876" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>GN RESOUND AS</last-name><address><country>DK</country></address></addressbook></applicant><applicant mxw-id="PPAR919529473" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>GN RESOUND A/S</last-name></addressbook></applicant><applicant mxw-id="PPAR919019671" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>GN Resound A/S</last-name><iid>100972728</iid><address><street>Lautrupbjerg 7</street><city>2750 Ballerup</city><country>DK</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR919516618" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>GRAN KARL-FREDRIK JOHAN</last-name><address><country>SE</country></address></addressbook></inventor><inventor mxw-id="PPAR919535992" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>GRAN, KARL-FREDRIK JOHAN</last-name></addressbook></inventor><inventor mxw-id="PPAR919011803" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>GRAN, KARL-FREDRIK JOHAN</last-name><address><street>Trindelvägen 7</street><city>SE-216 11 Malmö</city><country>SE</country></address></addressbook></inventor><inventor mxw-id="PPAR919543212" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>DITTBERNER ANDREW BURKE</last-name><address><country>US</country></address></addressbook></inventor><inventor mxw-id="PPAR919508356" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>DITTBERNER, ANDREW BURKE</last-name></addressbook></inventor><inventor mxw-id="PPAR919011796" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>DITTBERNER, ANDREW BURKE</last-name><address><street>1175 Waterview Circle</street><city>Antioch, IL Illinois 60002</city><country>US</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR919010490" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Zacco Denmark A/S</last-name><iid>101287454</iid><address><street>Hans Bekkevolds Allé 7</street><city>2900 Hellerup</city><country>DK</country></address></addressbook></agent></agents></parties><international-convention-data><designated-states><ep-contracting-states><country mxw-id="DS549815213" load-source="docdb">AL</country><country mxw-id="DS549744408" load-source="docdb">AT</country><country mxw-id="DS549742119" load-source="docdb">BE</country><country mxw-id="DS549813767" load-source="docdb">BG</country><country mxw-id="DS549817964" load-source="docdb">CH</country><country mxw-id="DS549742120" load-source="docdb">CY</country><country mxw-id="DS549744421" load-source="docdb">CZ</country><country mxw-id="DS549815219" load-source="docdb">DE</country><country mxw-id="DS549742125" load-source="docdb">DK</country><country mxw-id="DS549742126" load-source="docdb">EE</country><country mxw-id="DS549815802" load-source="docdb">ES</country><country mxw-id="DS549813768" load-source="docdb">FI</country><country mxw-id="DS549817965" load-source="docdb">FR</country><country mxw-id="DS549815220" load-source="docdb">GB</country><country mxw-id="DS549742127" load-source="docdb">GR</country><country mxw-id="DS549815221" load-source="docdb">HR</country><country mxw-id="DS549744422" load-source="docdb">HU</country><country mxw-id="DS549817978" load-source="docdb">IE</country><country mxw-id="DS549742128" load-source="docdb">IS</country><country mxw-id="DS549813769" load-source="docdb">IT</country><country mxw-id="DS549742133" load-source="docdb">LI</country><country mxw-id="DS549813790" load-source="docdb">LT</country><country mxw-id="DS549743881" load-source="docdb">LU</country><country mxw-id="DS549813791" load-source="docdb">LV</country><country mxw-id="DS549813792" load-source="docdb">MC</country><country mxw-id="DS549743882" load-source="docdb">MK</country><country mxw-id="DS549743883" load-source="docdb">MT</country><country mxw-id="DS549815803" load-source="docdb">NL</country><country mxw-id="DS549908347" load-source="docdb">NO</country><country mxw-id="DS549815804" load-source="docdb">PL</country><country mxw-id="DS549743884" load-source="docdb">PT</country><country mxw-id="DS549817979" load-source="docdb">RO</country><country mxw-id="DS549743893" load-source="docdb">RS</country><country mxw-id="DS549815805" load-source="docdb">SE</country><country mxw-id="DS549744423" load-source="docdb">SI</country><country mxw-id="DS549908348" load-source="docdb">SK</country><country mxw-id="DS549908349" load-source="docdb">SM</country><country mxw-id="DS549813793" load-source="docdb">TR</country></ep-contracting-states><ep-extended-states><ep-extended-state-data><country>BA</country></ep-extended-state-data><ep-extended-state-data><country>ME</country></ep-extended-state-data></ep-extended-states></designated-states></international-convention-data></bibliographic-data><abstract mxw-id="PA128673242" lang="EN" load-source="patent-office"><p id="pa01" num="0001">A new binaural hearing aid system is provided that compensates for a hearing impaired user's loss of ability to understand speech in noise using a new method comprising the steps of<br/>
providing at least one microphone audio signal (18, 20) in response to sound, and providing an estimate of one of a target signal (26) and a noise signal (30) based on the at least one audio signal (18, 20),<br/>
frequency modifying at least one of the estimate of the target signal (26) and the estimate of the noise signal (30) in such a way that the estimate of the target signal (26) and the estimate of the noise signal (30) as modified substantially reside in different frequency bands, and<br/>
transmitting the estimate of the target signal as modified towards one of the eardrums of a user of the binaural hearing aid system (10), and<br/>
transmitting the estimate of the noise signal as modified towards the other one of the eardrums of the user.
<img id="iaf01" file="imgaf001.tif" wi="98" he="105" img-content="drawing" img-format="tif"/></p></abstract><abstract mxw-id="PA128737393" lang="EN" source="EPO" load-source="docdb"><p>A new binaural hearing aid system is provided that compensates for a hearing impaired user's loss of ability to understand speech in noise using a new method comprising the steps of 
providing at least one microphone audio signal (18, 20) in response to sound, and providing an estimate of one of a target signal (26) and a noise signal (30) based on the at least one audio signal (18, 20), 
frequency modifying at least one of the estimate of the target signal (26) and the estimate of the noise signal (30) in such a way that the estimate of the target signal (26) and the estimate of the noise signal (30) as modified substantially reside in different frequency bands, and 
transmitting the estimate of the target signal as modified towards one of the eardrums of a user of the binaural hearing aid system (10), and 
transmitting the estimate of the noise signal as modified towards the other one of the eardrums of the user.</p></abstract><description mxw-id="PDES63959230" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><heading id="h0001">FIELD OF TECHNOLOGY</heading><p id="p0001" num="0001">A new binaural hearing aid system is provided that compensates for a hearing impaired user's loss of ability to understand speech in noise.</p><heading id="h0002">BACKGROUND</heading><p id="p0002" num="0002">Hearing impaired individuals often experience at least two distinct problems: a hearing loss, which is an increase in hearing threshold level, and a loss of ability to understand high level speech in noise in comparison with normal hearing individuals. For most hearing impaired patients, the performance in speech-in-noise intelligibility tests is worse than for normal hearing people, even if the audibility of the incoming sounds is restored by amplification. An individual's speech reception threshold (SRT) is the signal-to-noise ratio required in a presented signal to achieve 50 percent correct word recognition in a hearing in noise test.</p><p id="p0003" num="0003">Today's digital hearing aids that use multi-channel amplification and compression signal processing can readily restore audibility of amplified sound for a hearing impaired individual. The patient's hearing ability can thus be improved by making previously inaudible speech cues audible.</p><p id="p0004" num="0004">Loss of capability to understand speech in noise is the most significant problem of most hearing aid users today. The traditional way of increasing SRT in hearing instruments, is to apply either beamforming or spectral subtraction techniques.</p><p id="p0005" num="0005">In the first case, at least one microphone in combination with a number of filters, fixed or adaptive, is used to enhance a signal from the presumed target direction and at the same time suppress all other signals.</p><p id="p0006" num="0006">In spectral subtraction techniques, the goal is to create an estimate of the long term noise spectrum and turn down gain in frequency bands where the instantaneous target signal power is lower than the long term noise power. Even though the methods are very different from a technological standpoint, they still have the common goal; enhance the target signal and remove the noise disturbance.</p><p id="p0007" num="0007">The methods cannot take listener intent into account and may remove parts of the audio signal which the listener is trying to focus on.<!-- EPO <DP n="2"> --></p><heading id="h0003">SUMMARY</heading><p id="p0008" num="0008">Below, a new and inventive method of enhancement of a target signal is disclosed. The new method makes use of the human auditory system's capability of concentrating on a target signal. A new and inventive binaural hearing aid system using the new method is also disclosed.</p><p id="p0009" num="0009">Throughout the present disclosure, a target signal is a signal representing sound that a person desires to listen to.</p><p id="p0010" num="0010">Speech, music, and sounds from the nature are examples of target signals.</p><p id="p0011" num="0011">Throughout the present disclosure, a masker signal is also a signal representing sound; however, sound that a person perceives to be interfering with the target signal in an undesirable way, e.g. making it difficult for the person to understand or enjoy the target signal.</p><p id="p0012" num="0012">The masker signal can be background speech, restaurant clatter, music (when speech is the target signal), traffic noise, etc.</p><p id="p0013" num="0013">Listening in complex sound fields is to a large extent facilitated by binaural processing in the auditory system. Due to diffraction effects by the pinna, concha, head and torso and due to reflection effects in reverberant environments, cues are imparted to the sound field, and are highly individual for the given subject.</p><p id="p0014" num="0014">The most important cues in binaural processing are interaural time differences (ITD) and interaural level differences (ILD). The ITD results from the difference in distance from the source to the two ears. This cue is primarily useful up till approximately 1.5 kHz and above this frequency the auditory system can no longer resolve the ITD cue.</p><p id="p0015" num="0015">The level difference is a result of diffraction and is determined by the relative position of the ears compared to the source. This cue is dominant above 2 kHz but the auditory system is equally sensitive to changes in ILD over the entire spectrum.</p><p id="p0016" num="0016">It has been argued that hearing impaired subjects benefit the most from the ITD cue as the hearing loss tends to be less severe in the lower frequencies.</p><p id="p0017" num="0017">In the new binaural hearing aid, speech intelligibility is increased by outputting the target signal and the masker signal to the eardrums of a user of the binaural hearing aid in different frequency bands.<!-- EPO <DP n="3"> --></p><p id="p0018" num="0018">In this way, energetic masking caused by simultaneous presence of the target signal and the masker signal is reduced by separation of the signals into different frequency bands.</p><p id="p0019" num="0019">It has been shown that for speech as the target signal and Gaussian noise as the masker signal, 15 dB SRT improvement can be obtained for listeners with normal hearing and approximately 10 dB SRT improvement for hearing impaired listeners.</p><p id="p0020" num="0020">The improvement is obtained without removal a part of the signal; rather, the target and masker signals are presented to the eardrums of the user in a way that the auditory system of the user's auditory system can perform natural noise reduction and separate the target signal from the masker signal.</p><p id="p0021" num="0021">Thus, a new hearing aid is provided, comprising<br/>
at least one microphone for provision of at least one microphone audio signal in response to sound received at the at least one microphone,<br/>
a signal separation unit configured to provide an estimate of a target signal and a masker signal based on the at least one microphone audio signal,<br/>
a frequency modifying unit configured to modify the frequency content of at least one of the estimates of the target signal and the masker signal so that, upon processing by the frequency modifying unit, the estimated target signal and the estimated masker signal are output substantially in different frequency bands,<br/>
a receiver for conversion of a combination of the estimate of the target signal and the estimate of the masker signal as modified and output by the frequency modifying unit into an acoustic signal for transmission towards one of the eardrums of a user of the binaural hearing aid system.</p><p id="p0022" num="0022">In one embodiment, two signals are said to be output substantially in different frequency bands of the hearing aid, when in a majority of the frequency bands, e.g. in more than 51 % of the frequency bands of the hearing aid, and in a major part of the time, e.g. in more than 51 % of the time; one of the signals, e.g. the target signal, in one of the frequency bands, and the other one of the signals, e.g. the masker signal, in another one of the frequency bands, have a signal level that is less than 20 %, such as less than 15 %, preferably less than 10 %, more preferred less than 5 %, most preferred less than 1 % of the signal level of the other signal.</p><p id="p0023" num="0023">The signal level may be an RMS-value, a peak value, an average amplitude value, etc, as defined in a predetermined time period.<!-- EPO <DP n="4"> --></p><p id="p0024" num="0024">The new hearing aid may constitute a first hearing aid of a new binaural hearing aid system further having a second hearing aid comprising at least one microphone for provision of respective at least one microphone audio signal in response to sound received at the at least one microphone, and wherein<br/>
a transceiver in the second hearing aid is connected for transmission of signals representing the at least one microphone audio signal to the first hearing aid, and wherein<br/>
a transceiver in the first hearing aid is connected for reception of the signals representing the at least one microphone audio signal of the second hearing aid, and wherein<br/>
the signal separation unit is configured to provide the estimate of the target signal and the estimate of the masker signal based on the at least one microphone audio signals of the first and second hearing aids.</p><p id="p0025" num="0025">Further, a new and inventive method is provided, comprising the steps of:
<ul><li>providing at least one microphone audio signal in response to sound, and</li><li>providing an estimate of a target signal and a masker signal based on the at least one audio signal,</li><li>frequency modifying at least one of the estimate of the target signal and the estimate of the masker signal in such a way that the estimate of the target signal and the estimate of the masker signal as modified substantially reside in different frequency bands, and</li><li>transmitting a combination of the estimate of the target signal and the estimate of the masker signal as modified towards one of the eardrums of a person.</li></ul></p><p id="p0026" num="0026">The frequency modifying unit may be configured to frequency shift one of the estimate of the target signal and the estimate of the masker signal into a frequency region where the other one of the estimate of the target signal and the estimate of the masker signal substantially is not present.</p><p id="p0027" num="0027">Further or alternatively, the frequency modifying unit may be configured to determine pitch and harmonics of the estimate of the target signal and the estimate of the masker signal, respectively, and frequency shift one of the estimate of the target signal and the estimate of the masker signal so that pitch and harmonics of the frequency shifted signal resides in between respective pitch and harmonics of the other signal.<!-- EPO <DP n="5"> --></p><p id="p0028" num="0028">Further or alternatively, the frequency modifying unit may comprise a filter-bank, and the frequency modifying unit may be configured to filter the estimate of the target signal with frequency bands assigned to the estimate of the target signal, and filter the estimate of the masker signal with other frequency bands assigned to the estimate of the masker signal.</p><p id="p0029" num="0029">The filter-bank may be tuned to the auditory filters of the intended user.</p><p id="p0030" num="0030">It has also been shown that manipulating the relative interaural phase and level of a target signal, i.e. a signal a listener desires to listen to, and of a masker signal, i.e. a signal the listener perceives as disturbing, can improve speech intelligibility significantly. It seems as if the auditory system is indeed adapted to separate signals with different ITD and ILD encoding to perform a natural type of masker reduction to facilitate focusing on the target signal.</p><p id="p0031" num="0031">It has been found that if the target signal is presented in anti-phase, i.e. phase shifted 180°, and the masker signal in-phase in the two ears, an increase of the Binaural Masking Level Difference (BMLD) of 13 dB can be achieved compared to when both signals are presented in-phase in the two ears. Depending on the type of masker signal, an improvement of 20 dB of the BMLD is achievable.</p><p id="p0032" num="0032">The reverse situation where the masker signal is presented out of phase and the target signal is presented in phase yields a slightly lower performance.</p><p id="p0033" num="0033">Thus, the frequency modifying unit may also be configured to phase shift the estimate of the target signal with relation to the estimate of the masker signal.</p><p id="p0034" num="0034">In this way, a user's capability of understanding speech in noise is further improved.</p><p id="p0035" num="0035">For example, if the target signal is designated S and the masker signal is designated N, the incoming sound signal is S+N. Based on the sound signal S+N, the target signal S is estimated, and the estimate is denoted ES. An estimate of the masker signal N is designated EN and may be determined by subtracting the estimate ES from the sound signal S+N.</p><p id="p0036" num="0036">In the following S, N, ES, EN designates each of the signals before frequency modification, or each of the signals after frequency modification, in the frequency modifying unit.</p><p id="p0037" num="0037">The estimate of the target signal ES may be phase shifted 180° with relation to the estimate of the masker signal EN by subtracting two times ES from the incoming signal S+N with the result: S+N-ES-ES. Since ES is approximately equal to S, the result of<!-- EPO <DP n="6"> --> the subtraction is approximately: N-ES which is approximately equal to -ES + EN, i.e. the estimate of the target signal ES has been phase shifted substantially by 180° with relation to the estimate of the masker signal. This operation may be performed before or after frequency modification in the frequency modifying unit.</p><p id="p0038" num="0038">It should be noted that a phase shift of exactly or approximately 180 ° is not required in order to obtain a significant improvement of SRT; rather such improvement is obtained with phase shift in the range from 135 ° - 225 ° , such as from 150° - 210°.</p><p id="p0039" num="0039">Now, the original signal S+N may be presented to one ear of a user, and the phase shifted signal N-ES, or more accurately S+N-2ES, may be presented to the other ear for improved BMLD and SRT as disclosed above.</p><p id="p0040" num="0040">Alternatively, both the target signal S and the masker signal N may be estimated and the sum of the estimates ES+EN may be presented to one ear of the user, and the phase shifted sum -ES+EN may be presented to the other ear for improved BMLD and SRT as disclosed above. This operation may be performed before or after frequency modification in the frequency modifying unit.</p><p id="p0041" num="0041">The target signal S and the masker signal may be swapped so that the masker signal estimate is phase shifted instead of the target signal for improved BMLD and SRT as disclosed above; however with decreased performance compared to phase shifting the target signal S.</p><p id="p0042" num="0042">Throughout the present disclosure, one signal is said to represent another signal when the one signal is a function of the other signal, for example the one signal may be formed by analogue-to-digital conversion, or digital-to analogue conversion of the other signal; or, the one signal may be formed by conversion from another acoustic signal to an electronic signal or vice versa; or the one signal may be formed by analogue or digital filtering or mixing of the other signal; or the one signal may be formed by transformation, such as frequency transformation, etc, of the other signal; etc.</p><p id="p0043" num="0043">Further, signals that are processed by specific circuitry, e.g. in a signal processor, may be identified by a name that may be used to identify any analogue or digital signal forming part of the signal path from the source of the signal in question to an input of the circuitry, e.g. signal processor, in question. For example an output signal of a microphone, i.e. the microphone audio signal, may be used to identify any analogue or digital signal forming part of the signal path from the output of the microphone to its input to the signal processor, including pre-processed microphone audio signals.<!-- EPO <DP n="7"> --></p><p id="p0044" num="0044">The at least one microphone may consist of a single microphone; however preferably, the at least one microphone comprises a single microphone, e.g. a plurality of microphones, such as two microphones. The at least one microphone may have more than two microphones for improved separation of the target signal and the masker signal.</p><p id="p0045" num="0045">For improved signal enhancement, the second hearing aid may also comprise at least one microphone for provision of microphone audio signals in response to sound received at the respective microphones. In this case, the transceiver of the first hearing aid is connected for reception of signals representing the microphone audio signals of the second hearing aid, and the signal separation unit is configured to provide the estimate of the target signal and the estimate of the masker signal based on the audio signals of the first and second hearing aids.</p><p id="p0046" num="0046">Preferably, the frequency modifying unit phase shifts the estimate of the target signal with relation to the estimate of the masker signal with a phase shift ranging from 150° to 210°, more preferred the phase shift is approximately equal to 180°, and most preferred equal to 180°.</p><p id="p0047" num="0047">The improvement of SRT as a function of the phase shift has a maximum at 180°; however the function is sine-shape with a flat maximum so that the improvement obtained by a phase shift ranging from 150° to 210° is close to the maximum improvement. Thus, the phase shift need not be exactly 180°, but preferably has a value within the range from 135° to 225°, more preferred from 150° to 210°.</p><p id="p0048" num="0048">Preferably, the target estimate is presented in opposite phase, i.e. 180° phase shifted with relation to each other, at the two ears of the user, while the masker signal estimate is presented in phase at the two ears of the user.</p><p id="p0049" num="0049">The signal separation unit may be configured to provide the estimates based on spectral characteristics of the audio signals as is well-known in the art of noise reduction. However, according to the new method, the masker signal estimate is not suppressed in the output presented to the user; rather the target estimate and the masker signal estimate is presented to the user in a way that improves the user's SRT as disclosed above.</p><p id="p0050" num="0050">The signal separation unit may be configured to provide the estimates based on statistical characteristics of the audio signals as is well-known in the art of noise reduction. However, according to the new method, the masker signal estimate is not<!-- EPO <DP n="8"> --> suppressed in the output presented to the user; rather the target estimate and the masker signal estimate is presented to the user in a way that improves the user's SRT.</p><p id="p0051" num="0051">The signal separation unit may comprise a beamformer, and the beam former may be configured to provide the estimates based on microphone audio signals of the first and second hearing aids. The beamformer of the signal separation unit is different from conventional beamformers in that the masker signal estimate is not suppressed in the output presented to the user; rather the target estimate and the masker signal estimate is presented to the user in a way that improves the user's SRT.</p><p id="p0052" num="0052">The beamformer combines the microphone audio signals output by the plurality of microphones into a target signal with varying sensitivity to sound sources in different directions in relation to the plurality of microphones. Throughout the present disclosure, a plot of the varying sensitivity as a function of the direction is denoted the directivity pattern. Typically, a directivity pattern has at least one direction wherein the microphone signals substantially cancel each other. Throughout the present disclosure, such a direction is denoted a null direction. A directivity pattern may comprise several null directions depending on the number of microphones of the plurality of microphones and depending on the signal processing.</p><p id="p0053" num="0053">The beamformer may be a fixed beamformer with a directional pattern that is fixed with relation to the head of the user. The beamformer may for example be based on at least two microphones, with a directional pattern that has a maximum in the front direction of the user, i.e. the forward looking direction of the user, and a null in the opposite direction, i.e. the rear direction of the user.</p><p id="p0054" num="0054">The beamformer may be based on more than two microphones, and may include microphones of both hearing aids using wireless or wired communication techniques. The increased distance between the microphones may be utilized to form a directional pattern with a narrow beam providing improved spatial separation of the target estimate from the masker signal estimate. The conventional output of the beamformer may be used as the target estimate, and the masker signal estimate may be provided by subtraction of the target estimate from the microphone audio signal of one of the microphones of the plurality of microphones.</p><p id="p0055" num="0055">When microphones of both hearing aids of the binaural hearing aid system cooperate with the beamformer, the respective microphone signals must be sampled substantially synchronously. Time shifts as small as 20 -30 µS between sampling instants of the respective microphone signals in the two hearing aids may lead to a perceivable shift in<!-- EPO <DP n="9"> --> the beam direction. Furthermore, a slowly time varying time shift between the sampling instants of the respective microphone signals, which inevitably will occur if the hearing aids are operated asynchronously, will result in an acoustic beam that appears to drift and focus in alternating directions.</p><p id="p0056" num="0056">Thus, the hearing aids of the binaural hearing aid system may be synchronized as for example discloses in more detail in <patcit id="pcit0001" dnum="WO0207479A"><text>WO 02/07479</text></patcit>.</p><p id="p0057" num="0057">The beamformer may comprise adaptive filters configured to filter respective microphone audio signals and to adapt the respective filter coefficients for adaptive beamforming towards a sound source. For example, the beamformer may adapt to optimize the signal to noise ratio.</p><p id="p0058" num="0058">An adaptable beamformer makes it possible to focus on a moving sound source or to focus on a non-moving sound source, while the user of the hearing aid system is moving. Furthermore, the adaptable beamformer is capable of adapting to changes in the sound environment, such as appearance of a new sound source, disappearance of a masker signal or noise source or movement of masker signal or noise sources relative to the user of the hearing aid system.</p><p id="p0059" num="0059">An adaptive beamformer may be designed under the assumption that the signals received at the at least one microphone can be modelled as a combination of a target signal from a pre-determined target direction plus masker or noise: <maths id="math0001" num=""><math display="block"><msub><mi>y</mi><mi>i</mi></msub><mfenced><mi>n</mi></mfenced><mo>=</mo><msub><mi>h</mi><mi>i</mi></msub><mfenced><mi>n</mi></mfenced><mo>*</mo><mi>s</mi><mfenced><mi>n</mi></mfenced><mo>+</mo><msub><mi>v</mi><mi>i</mi></msub><mfenced><mi>n</mi></mfenced></math><img id="ib0001" file="imgb0001.tif" wi="55" he="8" img-content="math" img-format="tif"/></maths><br/>
where <i>h<sub>i</sub></i>(<i>n</i>) is the impulse response of sound propagation from the source emitting the signal <i>s</i>(<i>n</i>) to the <i>i</i><sup>th</sup> microphone and <i>v<sub>i</sub></i>(<i>n</i>) is the masker signal at the same microphone. The masker signal can consist of both directional noise and other types of noise such as diffuse noise or babble noise.</p><p id="p0060" num="0060">The filter coefficients may adaptively be determined by solving the following optimization problem: <maths id="math0002" num=""><math display="block"><msubsup><mfenced open="{" close="}" separators=""><msub><mi>a</mi><mi>i</mi></msub><mfenced><mi>n</mi></mfenced></mfenced><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mn>4</mn></msubsup><mo>=</mo><mi>arg</mi><mspace width="1em"/><munder><mi>min</mi><msubsup><mfenced open="{" close="}" separators=""><msub><mi>a</mi><mi>i</mi></msub><mfenced><mi>n</mi></mfenced></mfenced><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mn>4</mn></msubsup></munder><mo>⁢</mo><msup><mrow><mo>‖</mo><mi>z</mi><mfenced><mi>n</mi></mfenced><mo>‖</mo></mrow><mn>2</mn></msup></math><img id="ib0002" file="imgb0002.tif" wi="70" he="14" img-content="math" img-format="tif"/></maths> <maths id="math0003" num=""><math display="block"><mi>subject to</mi><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mn>4</mn></munderover></mstyle><msub><mi>a</mi><mi>i</mi></msub><mfenced><mi>n</mi></mfenced><mo>*</mo><msub><mi>h</mi><mi>i</mi></msub><mfenced><mi>n</mi></mfenced><mo>=</mo><msub><mi>h</mi><mn>1</mn></msub><mfenced><mi>n</mi></mfenced></math><img id="ib0003" file="imgb0003.tif" wi="70" he="19" img-content="math" img-format="tif"/></maths></p><p id="p0061" num="0061">Finding a solution to this optimization could be done adaptively using least mean square, recursive least square, steepest descent or other types of numerical optimization algorithms.<!-- EPO <DP n="10"> --></p><p id="p0062" num="0062">Preferably, the signal separation unit is configured in such a way that the estimate of the target signal and the estimate of the masker signal include the spatial cues of the original signal. This can be achieved by appropriate microphone placements and/or proper pre/post processing of the microphone signals.</p><p id="p0063" num="0063">Each of the hearing aids of the binaural hearing aid may have a signal separation unit so that an estimate of the target signal and an estimate of the masker signal are available in each of the hearing aids, preferably with correct spatial cues.</p><p id="p0064" num="0064">Once the target and masker signal estimate has been determined, the signals are presented to the user in such a way that the SRT of the user is improved as disclosed above.</p><p id="p0065" num="0065">The new binaural hearing aid system may comprise a multi-channel first hearing aid in which the microphone audio signals are divided into a plurality of frequency channels.</p><p id="p0066" num="0066">Correspondingly, individual target signal estimates and masker signal estimates may be provided in each frequency channel of the plurality of frequency channels, or may be provided in one or more selected frequency channels of the plurality of frequency channels, or one or more target signal estimates and masker signal estimates may be provided for one or more respective groups of selected frequency channels of the plurality of frequency channels, or one target signal estimate and masker signal estimate may be provided based on all the frequency channels of the plurality of frequency channels.</p><p id="p0067" num="0067">The plurality of frequency channels may include warped frequency channels, for example all of the frequency channels may be warped frequency channels.</p><p id="p0068" num="0068">The new binaural hearing aid system may additionally provide circuitry used in accordance with other conventional methods of hearing loss compensation so that the new circuitry or other conventional circuitry can be selected for operation as appropriate in different types of sound environment. The different sound environments may include speech, babble speech, restaurant clatter, music, traffic noise, etc.</p><p id="p0069" num="0069">The new binaural hearing aid system may for example comprise a Digital Signal Processor (DSP), the processing of which is controlled by selectable signal processing algorithms, each of which having various parameters for adjustment of the actual signal processing performed. The gains in each of the frequency channels of a multi-channel hearing aid are examples of such parameters.<!-- EPO <DP n="11"> --></p><p id="p0070" num="0070">One of the selectable signal processing algorithms operates in accordance with the new method.</p><p id="p0071" num="0071">For example, various algorithms may be provided for conventional noise suppression, i.e. attenuation of undesired or noise signals and amplification of target signals.</p><p id="p0072" num="0072">Microphone audio signals obtained from different sound environments may possess very different characteristics, e.g. average and maximum sound pressure levels (SPLs) and/or frequency content. Therefore, each type of sound environment may be associated with a particular program wherein a particular setting of algorithm parameters of a signal processing algorithm provides processed sound of optimum signal quality in a specific sound environment. A set of such parameters may typically include parameters related to broadband gain, corner frequencies or slopes of frequency-selective filter algorithms and parameters controlling e.g. knee-points and compression ratios of Automatic Gain Control (AGC) algorithms.</p><p id="p0073" num="0073">Signal processing characteristics of each of the algorithms may be determined during an initial fitting session in a dispenser's office and programmed into the new binaural hearing aid system in a non-volatile memory area.</p><p id="p0074" num="0074">The new binaural hearing aid system may have a user interface, e.g. buttons, toggle switches, etc, of the hearing aid housings, or a remote control, so that the user of the new binaural hearing aid system can select one of the available signal processing algorithms to obtain the desired hearing loss compensation in the sound environment in question.</p><p id="p0075" num="0075">The new binaural hearing aid system may be capable of automatically classifying the user's sound environment into one of a number of sound environment categories, such as speech, babble speech, restaurant clatter, music, traffic noise, etc, and may automatically select the appropriate signal processing algorithm accordingly as known in the art.</p><heading id="h0004">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p0076" num="0076">In the following, preferred embodiments of the invention are explained in more detail with reference to the drawing, wherein
<dl id="dl0001" compact="compact"><dt>Fig. 1</dt><dd>schematically illustrates an exemplary new hearing aid,</dd><dt>Fig. 2</dt><dd>shows a plot of a frequency shifted masker signal,</dd><dt>Fig. 3</dt><dd>shows another plot of a frequency shifted masker signal,<!-- EPO <DP n="12"> --></dd><dt>Fig. 4</dt><dd>shows a plot of bandpass filters and bandpass filtered target and masker signals,</dd><dt>Fig. 5</dt><dd>schematically illustrates an exemplary new binaural hearing aid system,</dd><dt>Fig. 6</dt><dd>schematically illustrates an exemplary new binaural hearing aid system,</dd><dt>Fig. 7</dt><dd>schematically illustrates a signal separation unit with an adaptive beamformer based on two microphones,</dd><dt>Fig. 8</dt><dd>schematically illustrates a signal separation unit based on four microphones, and</dd><dt>Fig. 9</dt><dd>schematically illustrates an exemplary new binaural hearing aid system.</dd></dl></p><p id="p0077" num="0077">The present invention will now be described more fully hereinafter with reference to the accompanying drawings, in which exemplary embodiments of the invention are shown. The invention may, however, be embodied in different forms and should not be construed as limited to the embodiments set forth herein. Rather, these embodiments are provided so that this disclosure will be thorough and complete, and will fully convey the scope of the invention to those skilled in the art. Like reference numerals refer to like elements throughout. Like elements will, thus, not be described in detail with respect to the description of each figure.</p><heading id="h0005">DESCRIPTION OF PREFERRED EMBODIMENTS</heading><p id="p0078" num="0078"><figref idrefs="f0001">Fig. 1</figref> schematically illustrates an example of the new binaural hearing aid 10 that operates to enhance a target signal making use of the human auditory system's capability of concentrating on a target signal.</p><p id="p0079" num="0079">In the illustrated new hearing aid 10, speech intelligibility is increased by outputting a target signal and a masker signal to the eardrums of a user of the binaural hearing aid in different frequency bands.</p><p id="p0080" num="0080">In this way, energetic masking caused by simultaneous presence of the target signal and the masker signal is reduced by separation of the signals into different frequency bands.</p><p id="p0081" num="0081">It has been shown that for speech as the target signal and Gaussian noise as the masker signal, 15 dB SRT improvement can be obtained for listeners with normal hearing and approximately 10 dB SRT improvements for hearing impaired listeners.</p><p id="p0082" num="0082">The improvement is obtained without removal of a part of the signal; rather, the target and masker signals are presented to the eardrums of the user in a way that the<!-- EPO <DP n="13"> --> auditory system of the user's auditory system can perform natural noise reduction and separate the target signal from the masker signal.</p><p id="p0083" num="0083">The illustrated new hearing aid 10 comprises a microphone 14 for provision of a microphone audio signal 18 in response to sound received at the microphone 14. The microphone audio signal 18 may be pre-filtered in respective pre-filters (not shown) well-known in the art, and input to the signal separation unit 12.</p><p id="p0084" num="0084">The signal separation unit 12 is configured to provide an estimate of a target signal 26 and a masker signal 30 based on the microphone audio signal 18, a frequency modifying unit 52 configured to modify the frequency content of at least one of the estimates of the target signal 26 and the masker signal 30 so that, upon processing by the frequency modifying unit 52, the estimated target signal 26 and the estimated masker signal 30 are output substantially in different frequency bands.</p><p id="p0085" num="0085">A hearing loss processor 46 configured for hearing loss compensation as is well-known in the art of hearing aids processes a combination 32 of the estimated target signal 26 and estimated masker signal 30 as modified by the frequency modifying unit 52 into a hearing loss compensated audio signal 34, and an output transducer 48, in the illustrated example a receiver 48, converts the output 34 of the hearing loss processor 46 into an acoustic output signal that is transmitted towards the eardrum of the user wearing the hearing aid 10.</p><p id="p0086" num="0086">The frequency modifying unit 52 may be configured to frequency shift one of the estimate of the target signal 26 and the estimate of the masker signal 30 into a frequency region where the other one of the estimate of the target signal 26 and the estimate of the masker signal 30 substantially is not present as illustrated in <figref idrefs="f0002">Fig. 2</figref> showing a frequency shifted estimated masker signal 30.</p><p id="p0087" num="0087">Further or alternatively, the frequency modifying unit 52 may be configured to determine pitch and harmonics of the estimate of the target signal 26 and the estimate of the masker signal 30, respectively, and frequency shift one of the estimate of the target signal 26 and the estimate of the masker signal 30 so that pitch and harmonics of the frequency shifted signal resides in between respective pitch and harmonics of the other signal as illustrated in <figref idrefs="f0003">Fig. 3</figref>.</p><p id="p0088" num="0088">Further or alternatively, the frequency modifying unit 52 may comprise a filter-bank as shown in <figref idrefs="f0004">Fig. 4</figref>, and the frequency modifying unit 52 may be configured to filter the estimate of the target signal with frequency bands assigned to the estimate of the<!-- EPO <DP n="14"> --> target signal 26, and filter the estimate of the masker signal 30 with other frequency bands assigned to the estimate of the masker signal 30.</p><p id="p0089" num="0089">The filter-bank may be tuned to the auditory filters of the intended user.</p><p id="p0090" num="0090">In this way, a user's capability of understanding speech in noise is improved.</p><p id="p0091" num="0091">The masker signal can be background speech, restaurant clatter, music (when speech is the target signal), traffic noise, etc.</p><p id="p0092" num="0092">The microphone 14 may be substituted with two microphones, or an array of microphones with more than two microphones for improved separation of the target signal and the masker signal.</p><p id="p0093" num="0093">The signal separation unit 12 may be configured to provide the estimates based on spectral characteristics of the audio signals as is well-known in the art of noise reduction. However, according to the new method, the masker signal estimate is not suppressed in the output presented to the user; rather the target estimate and the masker signal estimate is presented to the user in a way that improves the user's SRT.</p><p id="p0094" num="0094">The signal separation unit 12 may be configured to provide the estimates based on statistical characteristics of the audio signals as is well-known in the art of noise reduction. However, according to the new method, the masker signal estimate is not suppressed in the output presented to the user; rather the target estimate and the masker signal estimate is presented to the user in a way that improves the user's SRT.</p><p id="p0095" num="0095">The signal separation unit 12 may comprise a beamformer. The beamformer of the signal separation unit 12 is different from conventional beamformers in that the masker signal estimate is not suppressed in the output presented to the user; rather the target estimate and the masker signal estimate is presented to the user in a way that improves the user's SRT.</p><p id="p0096" num="0096">The beamformer may be a fixed beamformer with a directional pattern that is fixed with relation to the head of the user. The beamformer may for example be based on at least two microphones, with a directional pattern that has a maximum in the front direction of the user, i.e. the forward looking direction of the user, and a null in the opposite direction, i.e. the rear direction of the user.</p><p id="p0097" num="0097">The beamformer may be based on more than two microphones. The conventional output of the beamformer may be used as the target estimate, and the masker signal estimate may be provided by subtraction of the target estimate from the microphone audio signal of one of the microphones of the plurality of microphones.<!-- EPO <DP n="15"> --></p><p id="p0098" num="0098">The beamformer may comprise adaptive filters configured to filter respective microphone audio signals and to adapt the respective filter coefficients for adaptive beamforming towards a sound source. For example, the beamformer may adapt to optimize the signal to noise ratio.</p><p id="p0099" num="0099">As explained above, an adaptable beamformer makes it possible to focus on a moving sound source or to focus on a non-moving sound source, while the user of the hearing aid system is moving. Furthermore, the adaptable beamformer is capable of adapting to changes in the sound environment, such as appearance of a new sound source, disappearance of a masker signal or noise source or movement of masker signal or noise sources relative to the user of the hearing aid system.</p><p id="p0100" num="0100">Preferably, the signal separation unit is configured in such a way that the estimate of the target signal and the estimate of the masker signal include the spatial cues of the original signal. This can be achieved by appropriate microphone placements and/or proper pre/post processing of the microphone signals.</p><p id="p0101" num="0101">Once the target and masker signal estimate has been determined, the signals are presented to the user in such a way that the SRT of the user is improved.</p><p id="p0102" num="0102">The new hearing aid 10 may be a multi-channel hearing aid in which the microphone audio signals are divided into a plurality of frequency channels.</p><p id="p0103" num="0103">Correspondingly, individual target signal estimates and masker signal estimates may be provided in each frequency channel of the plurality of frequency channels, or may be provided in one or more selected frequency channels of the plurality of frequency channels, or one or more target signal estimates and masker signal estimates may be provided for one or more respective groups of selected frequency channels of the plurality of frequency channels, or one target signal estimate and masker signal estimate may be provided based on all the frequency channels of the plurality of frequency channels.</p><p id="p0104" num="0104">The plurality of frequency channels may include warped frequency channels, for example all of the frequency channels may be warped frequency channels.</p><p id="p0105" num="0105">The new hearing aid 10 may additionally provide circuitry 46 used in accordance with other conventional methods of hearing loss compensation so that the new circuitry or other conventional circuitry can be selected for operation as appropriate in different types of sound environment. The different sound environments may include speech, babble speech, restaurant clatter, music, traffic noise, etc.<!-- EPO <DP n="16"> --></p><p id="p0106" num="0106">The new hearing aid 10 may for example comprise a Digital Signal Processor (DSP), the processing of which is controlled by selectable signal processing algorithms, each of which having various parameters for adjustment of the actual signal processing performed. The gains in each of the frequency channels of a multi-channel hearing aid are examples of such parameters.</p><p id="p0107" num="0107">One of the selectable signal processing algorithms operates in accordance with the disclosed method of signal enhancement.</p><p id="p0108" num="0108">For example, various algorithms may be provided for conventional noise suppression, i.e. attenuation of undesired or noise signals and amplification of target signals.</p><p id="p0109" num="0109">Microphone audio signals obtained from different sound environments may possess very different characteristics, e.g. average and maximum sound pressure levels (SPLs) and/or frequency content. Therefore, each type of sound environment may be associated with a particular program wherein a particular setting of algorithm parameters of a signal processing algorithm provides processed sound of optimum signal quality in a specific sound environment. A set of such parameters may typically include parameters related to broadband gain, corner frequencies or slopes of frequency-selective filter algorithms and parameters controlling e.g. knee-points and compression ratios of Automatic Gain Control (AGC) algorithms.</p><p id="p0110" num="0110">Signal processing characteristics of each of the algorithms may be determined during an initial fitting session in a dispenser's office and programmed into the new binaural hearing aid system in a non-volatile memory area.</p><p id="p0111" num="0111">The new hearing aid 10 may have a user interface, e.g. buttons, toggle switches, etc, of the hearing aid housings, or a remote control, so that the user of the new binaural hearing aid system can select one of the available signal processing algorithms to obtain the desired hearing loss compensation in the sound environment in question.</p><p id="p0112" num="0112">The new hearing aid 10 may be capable of automatically classifying the user's sound environment into one of a number of sound environment categories, such as speech, babble speech, restaurant clatter, music, traffic noise, etc, and may automatically select the appropriate signal processing algorithm accordingly as known in the art.</p><p id="p0113" num="0113"><figref idrefs="f0005">Fig. 5</figref> shows a new binaural hearing aid system 10 with first and second hearing aids 10A, 10B. The second hearing aid 10B has a receiver 48B and a transceiver (not shown) for reception of the input signal to the receiver 48B from the first hearing aid 10A by wired or wireless transmission. Thus, in the illustrated example, the acoustic<!-- EPO <DP n="17"> --> output signal emitted by the second hearing aid 10B is controlled by the first hearing aid 10A.</p><p id="p0114" num="0114">The first hearing aid 10A comprises one microphone 14 for provision of microphone audio signal 18 in response to sound received at the microphone 14. The microphone audio signal 18 may be pre-filtered in respective pre-filters (not shown) well-known in the art, and input to the signal separation unit 12. The signal separation unit 12 provides an estimate of the target signal 26 and an estimate of the masker signal 30 based on the possibly pre-filtered microphone audio signal 18 and outputs the estimates to the frequency modifying unit 52.</p><p id="p0115" num="0115">The frequency modifying unit 52 modifies the frequency content of the estimates of the target signal 26 and the masker signal 30 so that the estimated target signal 26 and the estimated masker signal 30 are output substantially in different frequency bands, e.g. as illustrated in <figref idrefs="f0002 f0003 f0004">Figs. 2 - 4</figref>, respectively.</p><p id="p0116" num="0116">The estimate of the target signal 26 is added to the estimate of the masker signal 30, at least one of which is frequency modified, in a first adder 42 and the output sum is input to an output transducer 48 that converts the output of first adder 42 into an acoustic output signal that is transmitted towards the eardrum of the user wearing the binaural hearing aid system 10.</p><p id="p0117" num="0117">Further, the estimate of the target signal 26 is subtracted; corresponding to a phase shift of 180°, from the estimate of the masker signal 30, at least one of which is frequency modified, in a second adder 50, and the output of the second adder 50 is transmitted to output transducer 48B for conversion into an acoustic output signal that is transmitted towards the other eardrum of the user wearing the binaural hearing aid system 10. In this way, the BMLD and SRT are improved.</p><p id="p0118" num="0118">The estimate of the target signal 26 and the estimate of the masker signal 30 may be swapped so that the estimate of the masker signal 20 is phase shifted 180° before presentation to one of the eardrums of the user instead of phase shifting the estimate of the target signal 26. The improvement in BMLD and SRT obtained in this way is smaller than the improvement obtained by phase shift of the estimate of the target signal 26.</p><p id="p0119" num="0119">The signal separation unit 12 may be configured to provide the estimate based on time-domain, spectral, and/or statistical characteristics of the microphone audio signal as is well-known in the art of noise reduction. Optionally, further processing may be applied to the respective signals before input to the respective receivers 48, 48B, e.g. for<!-- EPO <DP n="18"> --> hearing loss compensation of the respective signals as is well-known in the art of hearing aids.</p><p id="p0120" num="0120">The new binaural hearing aid system 10 shown in <figref idrefs="f0006">Fig. 6</figref> is similar to the hearing aid system shown in <figref idrefs="f0005">Fig. 5</figref> except for the fact that a microphone audio signal 18B output by a microphone 14B in the second hearing aid 10B is transmitted by wired or wireless transmission to the first hearing aid 10A and input to the signal separation unit 12 so that the signal separation unit 12 can base the estimate of the target signal and the estimate of the masker signal 30 on both, possibly pre-filtered, microphone audio signals 18, 18B, e.g. by beamforming as explained further below. The relatively large distance between the microphones 14, 14B, when a user wears the first and second hearing aids 10A, 10B in their intended positions at the respective ears of the user, makes it possible to form a narrow beam and therefore allow a good spatial separation of the target signal from the masker signal.</p><p id="p0121" num="0121">The frequency modifying unit 52 modifies the frequency content of the estimates of the target signal 26 and the masker signal 30 so that the estimated target signal 26 and the estimated masker signal 30 are output substantially in different frequency bands, e.g. as illustrated in <figref idrefs="f0002 f0003 f0004">Figs. 2 - 4</figref>, respectively.</p><p id="p0122" num="0122">The estimate of the target signal 26 is added to the estimate of the masker signal 30, at least one of which is frequency modified, in a first adder 42 and the output sum is input to an output transducer 48 that converts the output of first adder 42 into an acoustic output signal that is transmitted towards the eardrum of the user wearing the binaural hearing aid system 10.</p><p id="p0123" num="0123">Further, the frequency modified estimate of the target signal 26 is subtracted; corresponding to a phase shift of 180°, from the estimate of the masker signal 30, at least one of which is frequency modified, in a second adder 50, and the output of the second adder 50 is transmitted to output transducer 48B for conversion into an acoustic output signal that is transmitted towards the other eardrum of the user wearing the binaural hearing aid system 10. In this way, the BMLD and SRT are improved.</p><p id="p0124" num="0124">The estimate of the target signal 26 and the estimate of the masker signal 30 may be swapped so that the estimate of the masker signal 20 is phase shifted 180° before presentation to one of the eardrums of the user instead of phase shifting the estimate of the target signal 26. The improvement in BMLD and SRT obtained in this way is smaller than the improvement obtained by phase shift of the estimate of the target signal 26.<!-- EPO <DP n="19"> --></p><p id="p0125" num="0125">The signal separation unit 12 may be configured to provide the estimate based on time-domain, spectral, and/or statistical characteristics of the microphone audio signal as is well-known in the art of noise reduction. Optionally, further processing may be applied to the respective signals before input to the respective receivers 48, 48B, e.g. for hearing loss compensation of the respective signals.</p><p id="p0126" num="0126"><figref idrefs="f0007">Fig. 7</figref> schematically illustrates a digital signal separation unit 12 including an adaptive beamformer 10 with two microphones 14, 16.</p><p id="p0127" num="0127">The microphone audio signals 18, 20 are pre-filtered in conventional pre-filters 22, 24 before beamforming. The microphone audio signals 18, 20 may be digitized before or after the pre-filters 22, 24 by A/D converters (not shown). Signals before and after prefiltering and before and after analogue-digital conversion are all termed microphone audio signals.</p><p id="p0128" num="0128">The output 26 of first subtractor 28 generates the estimate of the target signal from the assumed target direction using adaptive beamforming. The estimate of the target signal 26 is subsequently presented to one of the two ears of the user and in opposite phase to the other of the two ears of the user. The output 30 of the adaptive filter 32 filtering the output of second subtractor 34 generates the masker signal estimate for subsequent presentation to both ears of the user.</p><p id="p0129" num="0129">The input x<sub>1</sub>(n) to the first microphone 14 is given by: <maths id="math0004" num=""><math display="block"><msub><mi>x</mi><mn>1</mn></msub><mfenced><mi>n</mi></mfenced><mo>=</mo><msub><mi>h</mi><mn>1</mn></msub><mfenced><mi>n</mi></mfenced><mo>*</mo><mi>s</mi><mfenced><mi>n</mi></mfenced><mo>+</mo><msub><mi>g</mi><mn>1</mn></msub><mfenced><mi>n</mi></mfenced><mo>*</mo><mi>q</mi><mfenced><mi>n</mi></mfenced></math><img id="ib0004" file="imgb0004.tif" wi="67" he="9" img-content="math" img-format="tif"/></maths><br/>
where h<sub>1</sub>(n) is the impulse response of sound propagation from the source emitting the signal <i>s</i>(<i>n</i>) to the first microphone 14 and <i>g</i><sub>1</sub>(<i>n</i>) is the the impulse response of sound propagation from the masker signal source emitting the signal q(n) to the first microphone 14.</p><p id="p0130" num="0130">The input x<sub>2</sub>(n) to the second microphone 16 is given by: <maths id="math0005" num=""><math display="block"><msub><mi>x</mi><mn>2</mn></msub><mfenced><mi>n</mi></mfenced><mo>=</mo><msub><mi>h</mi><mn>2</mn></msub><mfenced><mi>n</mi></mfenced><mo>*</mo><mi>s</mi><mfenced><mi>n</mi></mfenced><mo>+</mo><msub><mi>g</mi><mn>2</mn></msub><mfenced><mi>n</mi></mfenced><mo>*</mo><mi>q</mi><mfenced><mi>n</mi></mfenced></math><img id="ib0005" file="imgb0005.tif" wi="72" he="9" img-content="math" img-format="tif"/></maths><br/>
where h<sub>2</sub>(n) is the impulse response of sound propagation from the source emitting the signal s(n) to the second microphone 16 and g<sub>2</sub>(n) is the the impulse response of sound propagation from the masker signal source emitting the signal q(n) to the second microphone 16.<!-- EPO <DP n="20"> --></p><p id="p0131" num="0131">Then, the output 26 of the target signal is equal t<i>oh</i><sub>1</sub> (n) * <i>s</i>(<i>n</i>), and the output 30 of the masker signal estimate is equal to<i>g</i><sub>1</sub> (<i>n</i>) * <i>q</i>(<i>n</i>).</p><p id="p0132" num="0132"><figref idrefs="f0008">Fig. 8</figref> schematically illustrates a signal separation unit 12 based on four microphones 14, 16, 14B, 16B, two of which 14, 16are located in the first hearing aid 10Aand other two of which (not shown) 14B, 16B are located in the second hearing aid 10B (not shown).</p><p id="p0133" num="0133">The increased distance between the microphones may be utilized to form a directional pattern with a narrow beam providing improved spatial separation of the target estimate from the masker signal estimate. The conventional output of the beamformer may be used as the target estimate, and the masker signal estimate may be provided by subtraction of the target estimate from the microphone audio signal of one of the microphones of the plurality of microphones.</p><p id="p0134" num="0134">The microphone audio signals 18, 20 of the two microphones 22, 24 of the first hearing aid 10 are pre-filtered in respective pre-filters 22, 24 well-known in the art, into microphone audio signals y<sub>1</sub>(n), y<sub>2</sub>(n) and input to respective adaptive filters a<sub>1</sub>(n), a<sub>2</sub>(n).</p><p id="p0135" num="0135">The pre-filtered microphone audio signals of the two microphones14B, 16B (not shown) of the second hearing aid 10B (not shown) are encoded for transmission in the second hearing aid 10B (not shown) and transmitted to the first hearing aid 10A using wireless or wired data transmission. The transmitted data representing the microphone audio signals of the two microphones 14B, 16B (not shown)of the second hearing aid 10B are received by the transceiver 36 of the first hearing aid 10A and decoded in decoder 38 into two microphone audio signals y<sub>3</sub>(n), y<sub>4</sub>(n) and input to respective adaptive filters a<sub>3</sub>(n), a<sub>4</sub>(n).</p><p id="p0136" num="0136">The adaptive filters a<sub>1</sub>(n), a<sub>2</sub>(n), a<sub>3</sub>(n), a<sub>4</sub>(n) are configured to filter the respective microphone audio signals y<sub>1</sub>(n), y<sub>2</sub>(n), y<sub>3</sub>(n), y<sub>4</sub>(n) and to adapt the respective filter coefficients for adaptive beamforming towards a sound source.<!-- EPO <DP n="21"> --></p><p id="p0137" num="0137">The adaptable filters a<sub>1</sub>(n), a<sub>2</sub>(n), a<sub>3</sub>(n), a<sub>4</sub>(n) make it possible to focus on a moving sound source or to focus on a non-moving sound source, while the user of the hearing aid system is moving. Furthermore, the adaptable filters a<sub>1</sub>(n), a<sub>2</sub>(n), a<sub>3</sub>(n), a<sub>4</sub>(n) are capable of adapting to changes in the sound environment, such as appearance of a new sound source, disappearance of a masker signal or noise source or movement of masker signal or noise sources relative to the user of the hearing aid system.</p><p id="p0138" num="0138">The adaptive beamformer filters a<sub>1</sub>(n), a<sub>2</sub>(n), a<sub>3</sub>(n), a<sub>4</sub>(n) are designed under the assumption that the signals received at the at least one microphone 14, 16, 14B, 16B can be modelled as a combination of a target signal from a pre-determined target direction plus noise: <maths id="math0006" num=""><math display="block"><msub><mi>y</mi><mi>i</mi></msub><mfenced><mi>n</mi></mfenced><mo>=</mo><msub><mi>h</mi><mi>i</mi></msub><mfenced><mi>n</mi></mfenced><mo>*</mo><mi>s</mi><mfenced><mi>n</mi></mfenced><mo>+</mo><msub><mi>v</mi><mi>i</mi></msub><mfenced><mi>n</mi></mfenced></math><img id="ib0006" file="imgb0006.tif" wi="60" he="9" img-content="math" img-format="tif"/></maths><br/>
where <i>h<sub>i</sub></i>(<i>n</i>) is the impulse response of sound propagation from the source emitting the signal <i>s</i>(<i>n</i>) to the <i>i</i><sup>th</sup> microphone and <i>v<sub>i</sub></i>(<i>n</i>) is the noise signal at the same microphone. The masker signal can consist of both directional masker signal or noise and other types of masker signals or noise, such as diffuse noise or babble noise.</p><p id="p0139" num="0139">The filter coefficients may adaptively be determined by solving the following optimization problem: <maths id="math0007" num=""><math display="block"><msubsup><mfenced open="{" close="}" separators=""><msub><mi>a</mi><mi>i</mi></msub><mfenced><mi>n</mi></mfenced></mfenced><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mn>4</mn></msubsup><mo>=</mo><mi>arg</mi><mspace width="1em"/><munder><mi>min</mi><msubsup><mfenced open="{" close="}" separators=""><msub><mi>a</mi><mi>i</mi></msub><mfenced><mi>n</mi></mfenced></mfenced><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mn>4</mn></msubsup></munder><mo>⁢</mo><msup><mrow><mo>‖</mo><mi>z</mi><mfenced><mi>n</mi></mfenced><mo>‖</mo></mrow><mn>2</mn></msup></math><img id="ib0007" file="imgb0007.tif" wi="70" he="14" img-content="math" img-format="tif"/></maths> <maths id="math0008" num=""><math display="block"><mi>subject to</mi><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mn>4</mn></munderover></mstyle><msub><mi>a</mi><mi>i</mi></msub><mfenced><mi>n</mi></mfenced><mo>*</mo><msub><mi>h</mi><mi>i</mi></msub><mfenced><mi>n</mi></mfenced><mo>=</mo><msub><mi>h</mi><mn>1</mn></msub><mfenced><mi>n</mi></mfenced></math><img id="ib0008" file="imgb0008.tif" wi="70" he="18" img-content="math" img-format="tif"/></maths></p><p id="p0140" num="0140">Filter adaptation is preferably performed using the least mean square (LMS) algorithm, more preferred the normalized least means square (NLMS) algorithm; however other algorithms may also be used, such as recursive least square, steepest descent or other types of numerical optimization algorithms.</p><p id="p0141" num="0141">The outputs of the adaptive filters a<sub>1</sub>(n), a<sub>2</sub>(n), a<sub>3</sub>(n), a<sub>4</sub>(n) are added in adder 34, and the output 26 of adder 34 constitutes the estimate of the target signal <maths id="math0009" num=""><math display="block"><mi>z</mi><mfenced><mi>n</mi></mfenced><mo>=</mo><msub><mi>h</mi><mn>1</mn></msub><mo>⁢</mo><mover><mrow><mfenced><mi>n</mi></mfenced><mo>*</mo><mi>s</mi><mfenced><mi>n</mi></mfenced></mrow><mo>^</mo></mover><mn>.</mn></math><img id="ib0009" file="imgb0009.tif" wi="45" he="12" img-content="math" img-format="tif"/></maths></p><p id="p0142" num="0142">Subtractor 28 outputs an estimate of the masker signal: <maths id="math0010" num=""><math display="block"><mover><mrow><msub><mi>v</mi><mn>1</mn></msub><mfenced><mi>n</mi></mfenced></mrow><mo>^</mo></mover><mo>=</mo><msub><mi>y</mi><mn>1</mn></msub><mfenced><mi>n</mi></mfenced><mo>-</mo><mi>z</mi><mfenced><mi>n</mi></mfenced><mn>.</mn></math><img id="ib0010" file="imgb0010.tif" wi="45" he="12" img-content="math" img-format="tif"/></maths><!-- EPO <DP n="22"> --></p><p id="p0143" num="0143">Once the target and masker signal estimates have been determined, the signals are presented to the user in such a way that the SRT of the user is improved as schematically illustrated in <figref idrefs="f0007">Fig. 7</figref>.</p><p id="p0144" num="0144"><figref idrefs="f0009">Fig. 9</figref> shows an example of the new binaural hearing aid system 10.</p><p id="p0145" num="0145">The new binaural hearing aid system 10 has first and second hearing aids 10A, 10B with transceivers 36, 36B for data communication between the two hearing aids 10A, 10B. The first hearing aid 10A comprises at least one microphone with two microphones 14, 16 for provision of microphone audio signals 18, 20 in response to sound received at the respective microphones 14, 16. The microphone audio signals 18, 20 are pre-filtered in respective pre-filters 22, 24 well-known in the art, into microphone audio signals and input to the signal separation unit 12. The signal separation unit 12 is shown in more detail in <figref idrefs="f0008">Fig. 8</figref> and explained above with reference to <figref idrefs="f0008">Fig. 8</figref>.</p><p id="p0146" num="0146">The second hearing aid 10B also comprises at least one microphone with two microphones 14B, 16B for provision of microphone audio signals 18B, 20B in response to sound received at the respective microphones 14B, 16B. The microphone audio signals 18B, 20B are pre-filtered by pre-filters 22B, 24B as is well-known in the art. Then the pre-filtered microphone audio signals of the two microphones 22B, 24B are encoded in Codec 40B for transmission to the first hearing aid 10A using wireless data transmission. The transmitted data representing the microphone audio signals of the second hearing aid 10B are received by the transceiver 36 of the first hearing aid 10A and decoded in decoder 38 into two microphone audio signals that are input to the signal separation unit 12 as explained above with reference to <figref idrefs="f0008">Fig. 8</figref>.</p><p id="p0147" num="0147">The signal separation unit 12 is configured to provide the estimate of the target signal 26 and the estimate of the masker signal 30 based on the pre-filtered microphone audio signals of the first and second hearing aids 10A, 10B.</p><p id="p0148" num="0148">The relatively large distance between the microphones of the individual hearing aids 10A, 10B as compared to the distance between microphones of a single hearing aid, makes it possible to configure the beamformer of the signal separation unit 12, see <figref idrefs="f0008">Fig. 8</figref>, with a narrow beam directional pattern providing improved spatial separation of the estimate of the target signal 26 from the estimate of the masker signal 30. The conventional output of the beamformer is used as the estimate of the target signal 26, and the estimate of the masker signal 30 is provided by subtraction of the estimate of<!-- EPO <DP n="23"> --> the target signal 26 from the pre-filtered microphone audio signal of one of the microphones of the plurality of four microphones 14, 16, 14B, 16B.</p><p id="p0149" num="0149">Once the target and masker signal estimates have been determined, the signals are presented to the user in such a way that the SRT of the user is improved: The estimate of the target signal 26 is added to the estimate of the masker signal 30, at least one of which is frequency modified, in a first adder 42 and the output sum of the estimate of the target signal 26 and the estimate of the masker signal 30 is delayed in delay 44 and input to a signal processor 46 for hearing loss compensation. The delay 44 maintains the desired relative phase of the signals output by the first and second hearing aids 10A, 10B, respectively.</p><p id="p0150" num="0150">An output transducer 48, in the illustrated example a receiver 48, converts the output of the signal processor 46 into an acoustic output signal that is transmitted towards the eardrum of the user wearing the binaural hearing aid system 10.</p><p id="p0151" num="0151">Further, the estimate of the target signal 26 is subtracted; corresponding to a phase shift of 180°, from the estimate of the masker signal 30, at least one of which is frequency modified, in a second adder 50, and the output of the second adder 50 is encoded in Codec 40 for transmission by transceiver 36 to the second hearing aid 10B. In the second hearing aid 10B the transmitted sum is received by the transceiver 36B and decoded by decoder 38B and input to signal processor 46B for hearing loss compensation. An output transducer 48B, in the illustrated example a receiver 48B, converts the output of the signal processor 46B into an acoustic output signal that is transmitted towards the eardrum of the user wearing the binaural hearing aid system 10. In this way, the SRT of the user may be improved up to 20 dB depending on the sound environment.</p><p id="p0152" num="0152">The estimate of the target signal 26 and the estimate of the masker signal 30 may be swapped so that the estimate of the masker signal 20 is phase shifted 180° before presentation to one of the eardrums of the user instead of phase shifting the estimate of the target signal 26. The improvement in SRT obtained in this way is smaller than the improvement obtained by phase shift of the estimate of the target signal 26.</p></description><claims mxw-id="PCLM56982259" lang="EN" load-source="patent-office"><!-- EPO <DP n="24"> --><claim id="c-en-0001" num="0001"><claim-text>A hearing aid (10) comprising<br/>
at least one microphone (14, 16) for provision of at least one microphone audio signal (18, 20) in response to sound received at the at least one microphone (14, 16),<br/>
a signal separation unit (12) configured to provide an estimate of a target signal (26) and an estimate of a masker signal (30) based on the at least one microphone audio signal (18, 20),<br/>
a frequency modifying unit (52) configured to modify the frequency content of at least one of the estimates of the target signal (26) and the masker signal (30) so that, upon processing by the frequency modifying unit (52), the estimated target signal (26) and the estimated masker signal (30) are output substantially in different frequency bands,<br/>
a receiver (48) for conversion of combination of the estimate of the target signal (26) and the estimate of the masker signal (30) as modified and output by the frequency modifying unit (52)into an acoustic signal for transmission towards one of the eardrums of a user of the binaural hearing aid system (10).</claim-text></claim><claim id="c-en-0002" num="0002"><claim-text>A binaural hearing aid system (10), comprising<br/>
a first hearing aid (10A) according to claim 1, and<br/>
a second hearing aid (10B) comprising at least one microphone (14B, 16B) for provision of respective at least one microphone audio signal (18B, 20B) in response to sound received at the at least one microphone (14B, 16B), and wherein<br/>
a transceiver (36B) in the second hearing aid (10B) is connected for transmission of signals representing the at least one microphone audio signal (18B, 20B) to the first hearing aid (10A), and wherein<br/>
a transceiver (36) in the first hearing aid (10A) is connected for reception of the signals representing the at least one microphone audio signal (14B, 16B) of the second hearing aid (10B), and wherein<br/>
the signal separation unit (12) is configured to provide the estimate of the target signal (26) and the estimate of the masker signal (30) based on the at least one microphone audio signals (18, 20, 18B, 20B) of the first and second hearing aids (10A, 10B).<!-- EPO <DP n="25"> --></claim-text></claim><claim id="c-en-0003" num="0003"><claim-text>A binaural hearing aid system (10) according to claim 1 or 2, wherein the frequency modifying unit (52) is configured to<br/>
frequency shift one of the estimate of the target signal (26) and the estimate of the masker signal (30) into a frequency region where the other one of the estimate of the target signal (26) and the estimate of the masker signal (30) substantially is not present.</claim-text></claim><claim id="c-en-0004" num="0004"><claim-text>A binaural hearing aid system (10) according to claim 1 or 2, wherein the frequency modifying unit (52) is configured to<br/>
determine pitch and harmonics of the estimate of the target signal (26) and the estimate of the masker signal (30), respectively, and<br/>
frequency shift one of the estimate of the target signal (26) and the estimate of the masker signal (30) so that pitch and harmonics of the frequency shifted signal resides in between respective pitch and harmonics of the other signal.</claim-text></claim><claim id="c-en-0005" num="0005"><claim-text>A binaural hearing aid system (10) according to claim 1 or 2, wherein the frequency modifying unit (52) comprises<br/>
a filter-bank, and wherein the frequency modifying unit (52) is configured to<br/>
filter the estimate of the target signal (26) with frequency bands assigned to the estimate of the target signal (26), and<br/>
filter the estimate of the masker signal (30) with other frequency bands assigned to the estimate of the masker signal (30).</claim-text></claim><claim id="c-en-0006" num="0006"><claim-text>A binaural hearing aid system (10) according to claim 5, wherein the filter-bank is tuned to the auditory filters of the intended user.</claim-text></claim><claim id="c-en-0007" num="0007"><claim-text>A binaural hearing aid system (10) according to any of the previous claims, further comprising<br/>
a phase shift circuit (54) configured to phase shift one of the estimate of the target signal (26) and the estimate of the masker signal (30) with relation to the other one of the estimate of the target signal (26) and the estimate of the masker signal (30).</claim-text></claim><claim id="c-en-0008" num="0008"><claim-text>A binaural hearing aid system (10) according to any of the preceding claims, wherein the signal separation unit (12) is configured to provide the estimate based on spectral characteristics of the audio signals.<!-- EPO <DP n="26"> --></claim-text></claim><claim id="c-en-0009" num="0009"><claim-text>A binaural hearing aid system (10) according to any of the preceding claims, wherein the signal separation unit (12) is configured to provide the estimate based on statistical characteristics of the audio signals.</claim-text></claim><claim id="c-en-0010" num="0010"><claim-text>A binaural hearing aid system (10) according to any of the preceding claims, wherein the signal separation unit (12) comprises a beamformer.</claim-text></claim><claim id="c-en-0011" num="0011"><claim-text>A binaural hearing aid system (10) according to claim 2 and 10, wherein the beam former is configured to provide the estimate based on microphone audio signals (18, 20, 18B, 20B) of the first and second hearing aids (10A, 10B).</claim-text></claim><claim id="c-en-0012" num="0012"><claim-text>A binaural hearing aid system (10) according to claim 10 or 11, wherein the beam former comprises adaptive filters configured to filter respective microphone audio signals and to adapt the respective filter coefficients to minimize the sum of the output signals of the filters.</claim-text></claim><claim id="c-en-0013" num="0013"><claim-text>A method of signal enhancement in a hearing aid (10), the method comprising the steps of,<br/>
providing at least one microphone audio signal (18, 20) in response to sound, and providing an estimate of a target signal (26) and an estimate of a masker signal (30) based on the at least one audio signal (18, 20),<br/>
frequency modifying at least one of the estimate of the target signal (26) and the estimate of the masker signal (30) in such a way that after modification, the estimate of the target signal (26) and the estimate of the masker signal (30) substantially reside in different frequency bands, and<br/>
transmitting a combination of the estimate of the target signal (26) and the estimate of the masker signal (30) after modification towards one of the eardrums of a user of the hearing aid (10).</claim-text></claim><claim id="c-en-0014" num="0014"><claim-text>A method of signal enhancement according to claim 13, comprising the steps of:
<claim-text>providing at least one microphone audio signal (18, 20, 18B, 20B) at both ears of the user in response to sound received at both ears, and</claim-text>
<claim-text>providing the estimate of one of the target signal (26) and the masker signal (30) based on the microphone audio signals (18, 20, 18B, 20B) at both ears.</claim-text></claim-text></claim><claim id="c-en-0015" num="0015"><claim-text>A method of signal enhancement according to any of claims 13 or 14, comprising the step of beamforming based on the microphone audio signals.<!-- EPO <DP n="27"> --></claim-text></claim><claim id="c-en-0016" num="0016"><claim-text>A method of signal enhancement according to claim 14, comprising the step of adaptive filtering of the microphone audio signals by adapting the respective filter coefficients to minimize the sum of the adaptively filtered output signals.</claim-text></claim><claim id="c-en-0017" num="0017"><claim-text>A method of binaural signal enhancement according to any of claims 13 - 16, further comprising the step of<br/>
phase shifting one of the estimate of the target signal (26) and the estimate of the masker signal (30) with relation to the other one of the estimate of the target signal (26) and the estimate of the masker signal (30).</claim-text></claim></claims><drawings mxw-id="PDW16670644" load-source="patent-office"><!-- EPO <DP n="28"> --><figure id="f0001" num="1"><img id="if0001" file="imgf0001.tif" wi="165" he="206" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="29"> --><figure id="f0002" num="2"><img id="if0002" file="imgf0002.tif" wi="147" he="155" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="30"> --><figure id="f0003" num="3"><img id="if0003" file="imgf0003.tif" wi="142" he="157" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="31"> --><figure id="f0004" num="4"><img id="if0004" file="imgf0004.tif" wi="141" he="218" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="32"> --><figure id="f0005" num="5"><img id="if0005" file="imgf0005.tif" wi="165" he="220" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="33"> --><figure id="f0006" num="6"><img id="if0006" file="imgf0006.tif" wi="165" he="227" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="34"> --><figure id="f0007" num="7"><img id="if0007" file="imgf0007.tif" wi="165" he="164" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="35"> --><figure id="f0008" num="8"><img id="if0008" file="imgf0008.tif" wi="157" he="198" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="36"> --><figure id="f0009" num="9"><img id="if0009" file="imgf0009.tif" wi="164" he="221" img-content="drawing" img-format="tif"/></figure></drawings><search-report-data><doc-page id="srep0001" file="srep0001.tif" wi="156" he="233" type="tif"/><doc-page id="srep0002" file="srep0002.tif" wi="158" he="233" type="tif"/></search-report-data><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
