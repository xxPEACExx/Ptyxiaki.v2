<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2681915-A1" country="EP" doc-number="2681915" kind="A1" date="20140108" family-id="43881594" file-reference-id="302654" date-produced="20180823" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="146586373" ucid="EP-2681915-A1"><document-id><country>EP</country><doc-number>2681915</doc-number><kind>A1</kind><date>20140108</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-12706231-A" is-representative="NO"><document-id mxw-id="PAPP154848565" load-source="docdb" format="epo"><country>EP</country><doc-number>12706231</doc-number><kind>A</kind><date>20120220</date><lang>EN</lang></document-id><document-id mxw-id="PAPP220440079" load-source="docdb" format="original"><country>EP</country><doc-number>12706231.3</doc-number><date>20120220</date></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC140555435" ucid="EP-2012052880-W" linkage-type="W" load-source="docdb"><document-id format="epo"><country>EP</country><doc-number>2012052880</doc-number><kind>W</kind><date>20120220</date></document-id></priority-claim><priority-claim mxw-id="PPC140555747" ucid="GB-201103174-A" load-source="docdb"><document-id format="epo"><country>GB</country><doc-number>201103174</doc-number><kind>A</kind><date>20110224</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL-2092281332" load-source="docdb">H04N  19/89        20140101ALI20150212RMEP        </classification-ipcr><classification-ipcr mxw-id="PCL1989317315" load-source="docdb">H04N   7/36        20060101ALI20120911BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1989317336" load-source="docdb">H04N   7/50        20060101ALI20120911BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1989319863" load-source="docdb">H04N   7/26        20060101AFI20120911BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-2137519166" load-source="docdb" scheme="CPC">H04N  19/105       20141101 LI20141108BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2137523225" load-source="docdb" scheme="CPC">H04N  19/172       20130101 LI20141108BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2137523705" load-source="docdb" scheme="CPC">H04N  19/58        20141101 FI20141108BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2137525528" load-source="docdb" scheme="CPC">H04N  19/164       20141101 LI20141108BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2137527705" load-source="docdb" scheme="CPC">H04N  19/89        20141101 LI20141108BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2137527758" load-source="docdb" scheme="CPC">H04N  19/176       20130101 LI20141108BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2137528154" load-source="docdb" scheme="CPC">H04N  19/61        20141101 LI20141108BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2137532565" load-source="docdb" scheme="CPC">H04N  19/46        20130101 LI20141108BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2137533483" load-source="docdb" scheme="CPC">H04N  19/174       20141101 LI20141108BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT132363752" lang="DE" load-source="patent-office">FEEDBACK-BASIERTE AUSWAHL VON REFERENZFRAMES ZUR VIDEOKODIERUNG</invention-title><invention-title mxw-id="PT132363753" lang="EN" load-source="patent-office">FEEDBACK BASED REFERENCE FRAME SELECTION FOR VIDEO CODING</invention-title><invention-title mxw-id="PT132363754" lang="FR" load-source="patent-office">SÉLECTION DE TRAME DE RÉFÉRENCE SUR LA BASE DU PRINCIPE DE LA RÉTROACTION POUR LE CODAGE VIDÉO</invention-title></technical-data><parties><applicants><applicant mxw-id="PPAR919537744" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>SKYPE</last-name><address><country>IE</country></address></addressbook></applicant><applicant mxw-id="PPAR919544885" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>SKYPE</last-name></addressbook></applicant><applicant mxw-id="PPAR919014612" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Skype</last-name><iid>101289499</iid><address><street>70 Sir John Rogerson's Quay</street><city>Dublin 2</city><country>IE</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR919524622" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>ZHAO DAVID</last-name><address><country>SE</country></address></addressbook></inventor><inventor mxw-id="PPAR919535801" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>ZHAO, DAVID</last-name></addressbook></inventor><inventor mxw-id="PPAR919013924" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>ZHAO, DAVID</last-name><address><street>Honnorsgatan 24</street><city>S-17069 Solna</city><country>SE</country></address></addressbook></inventor><inventor mxw-id="PPAR919521699" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>SABLIN SERGEY</last-name><address><country>SE</country></address></addressbook></inventor><inventor mxw-id="PPAR919508222" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>SABLIN, SERGEY</last-name></addressbook></inventor><inventor mxw-id="PPAR919012482" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>SABLIN, SERGEY</last-name><address><street>Svartviksslingan 43</street><city>S-167 38 Bromma</city><country>SE</country></address></addressbook></inventor><inventor mxw-id="PPAR919544266" load-source="docdb" sequence="3" format="epo"><addressbook><last-name>JEFREMOV ANDREI</last-name><address><country>SE</country></address></addressbook></inventor><inventor mxw-id="PPAR919513618" load-source="docdb" sequence="3" format="intermediate"><addressbook><last-name>JEFREMOV, ANDREI</last-name></addressbook></inventor><inventor mxw-id="PPAR919011640" load-source="patent-office" sequence="3" format="original"><addressbook><last-name>JEFREMOV, ANDREI</last-name><address><street>Veckovagen 59-274</street><city>S-17762 Janfalla</city><country>SE</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR919015825" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Driver, Virginia Rozanne</last-name><iid>100028204</iid><address><street>Page White &amp; Farrer Bedford House John Street</street><city>London WC1N 2BF</city><country>GB</country></address></addressbook></agent></agents></parties><international-convention-data><pct-or-regional-filing-data ucid="EP-2012052880-W"><document-id><country>EP</country><doc-number>2012052880</doc-number><kind>W</kind><date>20120220</date><lang>EN</lang></document-id></pct-or-regional-filing-data><pct-or-regional-publishing-data ucid="WO-2012113763-A1"><document-id><country>WO</country><doc-number>2012113763</doc-number><kind>A1</kind><date>20120830</date><lang>EN</lang></document-id></pct-or-regional-publishing-data><designated-states><ep-contracting-states><country mxw-id="DS549837760" load-source="docdb">AL</country><country mxw-id="DS549770012" load-source="docdb">AT</country><country mxw-id="DS549837761" load-source="docdb">BE</country><country mxw-id="DS549837649" load-source="docdb">BG</country><country mxw-id="DS549837375" load-source="docdb">CH</country><country mxw-id="DS549837778" load-source="docdb">CY</country><country mxw-id="DS549914572" load-source="docdb">CZ</country><country mxw-id="DS549851356" load-source="docdb">DE</country><country mxw-id="DS549837779" load-source="docdb">DK</country><country mxw-id="DS549837780" load-source="docdb">EE</country><country mxw-id="DS549759814" load-source="docdb">ES</country><country mxw-id="DS549837654" load-source="docdb">FI</country><country mxw-id="DS549837655" load-source="docdb">FR</country><country mxw-id="DS549851357" load-source="docdb">GB</country><country mxw-id="DS549837781" load-source="docdb">GR</country><country mxw-id="DS549851366" load-source="docdb">HR</country><country mxw-id="DS549914573" load-source="docdb">HU</country><country mxw-id="DS549837376" load-source="docdb">IE</country><country mxw-id="DS549837802" load-source="docdb">IS</country><country mxw-id="DS549837656" load-source="docdb">IT</country><country mxw-id="DS549837803" load-source="docdb">LI</country><country mxw-id="DS549851367" load-source="docdb">LT</country><country mxw-id="DS549770017" load-source="docdb">LU</country><country mxw-id="DS549837657" load-source="docdb">LV</country><country mxw-id="DS549851368" load-source="docdb">MC</country><country mxw-id="DS549770018" load-source="docdb">MK</country><country mxw-id="DS549770019" load-source="docdb">MT</country><country mxw-id="DS549759815" load-source="docdb">NL</country><country mxw-id="DS549760251" load-source="docdb">NO</country><country mxw-id="DS549759816" load-source="docdb">PL</country><country mxw-id="DS549837662" load-source="docdb">PT</country><country mxw-id="DS549914574" load-source="docdb">RO</country><country mxw-id="DS549837663" load-source="docdb">RS</country><country mxw-id="DS549759821" load-source="docdb">SE</country><country mxw-id="DS549837377" load-source="docdb">SI</country><country mxw-id="DS549760252" load-source="docdb">SK</country><country mxw-id="DS549760257" load-source="docdb">SM</country><country mxw-id="DS549770020" load-source="docdb">TR</country></ep-contracting-states></designated-states></international-convention-data><office-specific-data><eptags><ep-no-a-document-published>*</ep-no-a-document-published></eptags></office-specific-data></bibliographic-data><abstract mxw-id="PA99626466" ref-ucid="WO-2012113763-A1" lang="EN" load-source="patent-office"><p num="0000">Method, system and control block for transmitting a video signal over a network, in which portions of the video signal are encoded with an encoder, and the encoded portions are transmitted over the network to a decoder. The encoder allocates index numbers to the transmitted portions of the video signal, each index number identifying a respective portion of the video signal. At least some of the portions of the video signal are stored in a buffer associated with the encoder. Feedback is received from the network at a control block remote from the encoder, the feedback indicating whether each of the transmitted portions has been correctly received. Based on the feedback, the control block determines a subset of the portions of the video signal stored in the buffer which are to be used by the encoder for encoding subsequent portions of the video signal. The control block transmits a message to the encoder, the message identifying the subset of portions of the video signal using the index numbers allocated to the portions in the subset of portions. In response to receiving the message from the control block, the encoder uses the index numbers in the message to identify and retrieve at least one portion of the subset of portions from the buffer, wherein the encoder encodes subsequent portions of the video signal using the at least one retrieved portion.</p></abstract><abstract mxw-id="PA99824985" ref-ucid="WO-2012113763-A1" lang="EN" source="national office" load-source="docdb"><p>Method, system and control block for transmitting a video signal over a network, in which portions of the video signal are encoded with an encoder, and the encoded portions are transmitted over the network to a decoder. The encoder allocates index numbers to the transmitted portions of the video signal, each index number identifying a respective portion of the video signal. At least some of the portions of the video signal are stored in a buffer associated with the encoder. Feedback is received from the network at a control block remote from the encoder, the feedback indicating whether each of the transmitted portions has been correctly received. Based on the feedback, the control block determines a subset of the portions of the video signal stored in the buffer which are to be used by the encoder for encoding subsequent portions of the video signal. The control block transmits a message to the encoder, the message identifying the subset of portions of the video signal using the index numbers allocated to the portions in the subset of portions. In response to receiving the message from the control block, the encoder uses the index numbers in the message to identify and retrieve at least one portion of the subset of portions from the buffer, wherein the encoder encodes subsequent portions of the video signal using the at least one retrieved portion.</p></abstract><abstract mxw-id="PA99626467" ref-ucid="WO-2012113763-A1" lang="FR" load-source="patent-office"><p num="0000">L'invention concerne un procédé, un système et un bloc de commande conçus pour transmettre un signal vidéo sur un réseau. Dans ledit système, des parties du signal vidéo sont codées avec un codeur et les parties codées sont transmises sur le réseau à un décodeur. Le codeur attribue des numéros d'index aux parties transmises du signal vidéo, chaque numéro d'index identifiant une partie respective du signal vidéo. Certaines au moins des parties du signal vidéo sont stockées dans un tampon associé au codeur. Une rétroaction est reçue en provenance du réseau au niveau d'un bloc de commande distant du codeur, la rétroaction indiquant si chacune des parties transmises a été reçue de manière correcte. Sur la base de la rétroaction, le bloc de commande détermine un sous-ensemble des parties du signal vidéo stockées dans le tampon qui doivent être utilisées par le codeur afin de coder des parties suivantes du signal vidéo. Le bloc de commande transmet un message au codeur, le message identifiant le sous-ensemble de parties du signal vidéo en utilisant les numéros d'index attribués aux parties dans le sous-ensemble de parties. En réponse à la réception du message en provenance du bloc de commande, le codeur utilise les numéros d'index dans le message afin d'identifier et rechercher une partie au moins du sous-ensemble de parties à partir du tampon, le codeur codant des parties suivantes du signal vidéo en utilisant la ou les parties recherchées.</p></abstract><abstract mxw-id="PA99824986" ref-ucid="WO-2012113763-A1" lang="FR" source="national office" load-source="docdb"><p>L'invention concerne un procédé, un système et un bloc de commande conçus pour transmettre un signal vidéo sur un réseau. Dans ledit système, des parties du signal vidéo sont codées avec un codeur et les parties codées sont transmises sur le réseau à un décodeur. Le codeur attribue des numéros d'index aux parties transmises du signal vidéo, chaque numéro d'index identifiant une partie respective du signal vidéo. Certaines au moins des parties du signal vidéo sont stockées dans un tampon associé au codeur. Une rétroaction est reçue en provenance du réseau au niveau d'un bloc de commande distant du codeur, la rétroaction indiquant si chacune des parties transmises a été reçue de manière correcte. Sur la base de la rétroaction, le bloc de commande détermine un sous-ensemble des parties du signal vidéo stockées dans le tampon qui doivent être utilisées par le codeur afin de coder des parties suivantes du signal vidéo. Le bloc de commande transmet un message au codeur, le message identifiant le sous-ensemble de parties du signal vidéo en utilisant les numéros d'index attribués aux parties dans le sous-ensemble de parties. En réponse à la réception du message en provenance du bloc de commande, le codeur utilise les numéros d'index dans le message afin d'identifier et rechercher une partie au moins du sous-ensemble de parties à partir du tampon, le codeur codant des parties suivantes du signal vidéo en utilisant la ou les parties recherchées.</p></abstract><description mxw-id="PDES50931606" ref-ucid="WO-2012113763-A1" lang="EN" load-source="patent-office"><!-- EPO <DP n="2"/>--><p id="p0001" num="0001"> FEEDBACK BASED REFERENCE FRAME SELECTION FOR </p><p id="p0002" num="0002"> VIDEO CODING </p><p id="p0003" num="0003">Field of the Invention </p><p id="p0004" num="0004">The present invention relates to transmitting a video signal over a network, particular the present invention relates to transmitting encoded portions of video signal over a network. </p><p id="p0005" num="0005">Background </p><p id="p0006" num="0006">In order to transmit a video signal over a network, the video signal may be encoded in discrete portions. Each portion of the video signal may be a frame of the video signal. Alternatively, each portion of the video signal may be a macroblock of pixels (e.g. a 16x16 block of pixels) within a frame of the video signal or a "slice" of a frame of the video signal. A slice is a section of a frame of the video signal which can be encoded and decoded independently. Encoded portions of the video signal can be transmitted over a network to a receiver and decoded in order to recover the original video signal (or at least an approximation of the original video signal) at the receiver. </p><p id="p0007" num="0007">In a system in which the portions of the video signal to be encoded are frames of the video signal, the video signal may be coded using two types of video frames: intra-frames (also known as key frames) and inter-frames. A key frame is compressed (i.e. encoded) using only the current video frame (using intra- frame prediction), in a similar manner to that used in image coding. In contrast, an inter-frame is compressed (i.e. encoded) using knowledge of at least one decoded frame preceding (or following) the inter-frame in the video signal, and as such allows much more efficient compression of the video signal, particularly when the scene in the frame is similar to that in the at least one preceding (or following) frame. In order for a decoder to correctly decode an image using an inter-frame, the decoder must have received all frames on which the inter frame depends. If any of those frames have not been received at the decoder then the decoding of the current inter-frame will result in errors. 
<!-- EPO <DP n="3"/>-->
 As such, frequent transmission of key frames is common in video streaming such that the decoder can recover lost information when packet loss occurs. In some alternative systems the receiver may request a key frame from the transmitter if packet loss is detected. </p><p id="p0008" num="0008">Key frames are large (and therefore require a large amount of bandwidth for transmission) relative to inter-frames and, as such, key frames may result in a poor quality frame. In order to address the problem of having to regularly transmit key frames, it is also known for some of the frames (e.g. reference frames) of the video signal to be stored at the decoder and at the encoder in order to reduce the number of key frames that are sent. In this case, recovery frames may be transmitted from the encoder to the decoder. Recovery frames are encoded using a stored reference frame that was sent earlier than the frame immediately preceding the recovery frame. Since the reference frames are stored both at the encoder and at the decoder, in the event that the decoder requests a recovery frame, the stored reference frame is used at the encoder to generate the recovery frame. The decoder can then correctly decode the recovery frame using the reference frame that is stored at the decoder. However, there remains a problem in that if the most recent reference frame is lost in transmission between the encoder and the decoder then the decoder will not be able to correctly decode the recovery frame. </p><p id="p0009" num="0009">There are video compression technologies (such as VP7 and VP8) in which the network tracks the state of the decoder and makes "recovery" decisions as to how best to encode frames based on feedback received from the receiver relating to the success of the transmission of the frames. Figure 1 shows a schematic diagram of a system 100 for implementing video compression according to VP7 or VP8. The system 100 comprises an encoder 102 and a remote interface 1 10. The encoder 102 comprises an encode block 104, a decode block 106 and a buffer 108. The encode block 104 of the encoder 102 is arranged to receive frames of an input video signal. The encode block 104 encodes the video frames to generate encoded video frames which are output from the encoder 102 for transmission to a receiver. The encoded video frames 
<!-- EPO <DP n="4"/>-->
 are also input to the decode block 106 where they are decoded and then stored in the buffer 108. The video frames stored in the buffer 108 may be passed to the encode block 104 for use in encoding subsequent frames of the video signal (e.g. for encoding inter-frames of the video signal). The interface 1 10 comprises a block 1 12 for receiving feedback from the network and for determining which of the frames transmitted to the receiver have been correctly received at the decoder of the receiver. The interface 1 10 also comprises a block 114 which receives the determination of which of the frames have been correctly received at the decoder of the receiver from block 1 12 and uses this information to determine a frame which has been correctly received at the decoder and which can therefore be used by the encode block 104 for encoding subsequent frames of the video signal. </p><p id="p0010" num="0010">The remote interface 1 10 can send an instruction to the encoder 102 to instruct the encoder 102 to store the next frame in a particular position in the buffer 108 (e.g. in position 1 in the buffer 108). This frame can then be used later for encoding subsequent frames of the video signal. If the remote interface 1 10 determines that the frame stored in the particular position in the buffer 108 has been correctly received at the decoder of the receiver then the block 1 14 sends a command to the encoder 102 to indicate that the frame stored in the particular position in the buffer 108 can be relied upon to encode subsequent frames of the video signal. The command sent from the interface 1 10 to the encoder 102 indicates the particular position in the reference frame buffer 108 of the frame. The encoder 102 then retrieves the frame at the particular position from the buffer 108 for use in generating subsequent frames because the encoder 102 can be confident that the frame at the particular position of the buffer 108 was correctly received at the decoder. </p><p id="p0011" num="0011">However, there are problems with the system 100 of VP7 and VP8. For example, the size of the reference frame buffer 108 in the encoder 102 is limited to store only the previous frame and two more frames (e.g. at particular positions). This significantly limits the number of possible frames which can be used for generating subsequent frames of the video signal. Furthermore, since the interface 1 10 is remote from the encoder 102 there may be a delay between 
<!-- EPO <DP n="5"/>-->
 sending the command from the interface 110 and receiving the command at the encoder 102 which can detrimentally affect the quality of the encoding performed by the encoder 102. Summary </p><p id="p0012" num="0012">According to a first aspect of the invention there is provided a method of transmitting a video signal over a network, the method comprising: encoding portions of the video signal with an encoder, and transmitting the encoded portions over the network to a decoder; the encoder allocating index numbers to the transmitted portions of the video signal, each index number identifying a respective portion of the video signal; storing at least some of the portions of the video signal in a buffer associated with the encoder; receiving feedback from the network at a control block remote from the encoder, the feedback indicating whether each of the transmitted portions has been correctly received; based on the feedback, the control block determining a subset of the portions of the video signal stored in the buffer which are to be used by the encoder for encoding subsequent portions of the video signal; the control block transmitting a message to the encoder, said message identifying the subset of portions of the video signal using the index numbers allocated to the portions in the subset of portions; and in response to receiving the message from the control block, the encoder using the index numbers in the message to identify and retrieve at least one portion of the subset of portions from the buffer, wherein the encoder encodes subsequent portions of the video signal using the at least one retrieved portion. </p><p id="p0013" num="0013">The portions of the video signal may be, for example, frames, macroblocks or slices of the video signal. Advantageously, since the index numbers are allocated to the portions of the video signal (rather than to positions in the buffer), the index numbers identify specific portions of the video signal (e.g. specific frames). This means that portions of the video signal stored in the buffer can be identified using their respective index numbers even if the portions are subsequently moved from their original position in the buffer. This is particularly useful because the control block is remote from the encoder and as 
<!-- EPO <DP n="6"/>-->
 such there may be a delay between transmitting the message from the control block and the encoder receiving the message. By using index numbers which identify the portions (e.g. frames) of the video signal, rather than identifying a position in the buffer, the control block can reliably identify the subset of portions which are to be used by the encoder for encoding subsequent portions of the video signal. Therefore, in preferred embodiments, the index numbers allow the encoder to uniquely identify which frame is identified by a particular index number. Preferably, the index numbers allocated to the portions within a time interval equal to the average Round Trip Time between the encoder and the decoder, are unique. </p><p id="p0014" num="0014">A frame may be identified at the encoder as a frame to be saved for future reference, such that the frame will not be removed from the buffer without explicit action from the encoder. With an H.264 encoder this can be achieved by marking the frame as a "long term reference" frame. With a VP8 encoder this can be achieved by marking the frame as a "golden" or an "alternative" frame. Other types of encoders may achieve this in different ways. </p><p id="p0015" num="0015">According to a second aspect of the invention there is provided a system for transmitting a video signal over a network, the system comprising: (i) an encoder which is configured to: encode portions of the video signal, and transmit the encoded portions over the network to a decoder; allocate index numbers to the transmitted portions of the video signal, each index number identifying a respective portion of the video signal; and store at least some of the portions of the video signal in a buffer associated with the encoder; and (ii) a control block which is remote from the encoder and which is configured to: receive feedback from the network, the feedback indicating whether each of the transmitted portions has been correctly received; determine, based on the feedback, a subset of the portions of the video signal stored in the buffer which are to be used by the encoder for encoding subsequent portions of the video signal; and transmit a message to the encoder, said message identifying the subset of portions of the video signal using the index numbers allocated to the 
<!-- EPO <DP n="7"/>-->
 portions in the subset of portions, wherein the encoder is configured to identify and retrieve, in response to receiving the message from the control block, at least one portion of the subset of portions from the buffer using the index numbers in the message, and to encode subsequent portions of the video signal using the at least one retrieved portion. </p><p id="p0016" num="0016">There may be a network connection or a USB connection between the encoder and the control block for transmitting the message from the control block to the encoder. The encoder may be a H.264 encoder. </p><p id="p0017" num="0017">According to a third aspect of the invention there is provided a method of controlling transmission of portions of a video signal which are encoded by an encoder and transmitted over a network to a decoder, wherein the encoder allocates index numbers to the transmitted portions of the video signal and stores at least some of the portions of the video signal in a buffer associated with the encoder, each index number identifying a respective portion of the video signal, the method comprising: receiving feedback from the network at a control block remote from the encoder, the feedback indicating whether each of the transmitted portions has been correctly received; based on the feedback, the control block determining a subset of the portions of the video signal stored in the buffer which are to be used by the encoder for encoding subsequent portions of the video signal; and the control block transmitting a message to the encoder, said message identifying the subset of portions of the video signal using the index numbers allocated to the portions in the subset of portions, such that the encoder can use the index numbers in the message to identify at least one portion of the subset of portions for encoding subsequent portions of the video signal. </p><p id="p0018" num="0018">According to a fourth aspect of the invention there is provided a computer program product comprising computer readable instructions for execution by computer processing means at a control block for controlling transmission of portions of a video signal, the instructions comprising instructions for carrying out the method according to the third aspect of the invention. 
<!-- EPO <DP n="8"/>-->
 According to a fifth aspect of the invention there is provided a control block for controlling transmission of portions of a video signal which are encoded by an encoder and transmitted over a network to a decoder, wherein the encoder allocates index numbers to the transmitted portions of the video signal and stores at least some of the portions of the video signal in a buffer associated with the encoder, each index number identifying a respective portion of the video signal, wherein the control block is remote from the encoder and the control block comprises: receiving means for receiving feedback from the network, the feedback indicating whether each of the transmitted portions has been correctly received; determining means for determining, based on the feedback, a subset of the portions of the video signal stored in the buffer which are to be used by the encoder for encoding subsequent portions of the video signal; and transmitting means for transmitting a message to the encoder, said message identifying the subset of portions of the video signal using the index numbers allocated to the portions in the subset of portions, such that the encoder can use the index numbers in the message to identify at least one portion of the subset of portions for encoding subsequent portions of the video signal. Brief Description of the Drawings </p><p id="p0019" num="0019">For a better understanding of the present invention and to show how the same may be put into effect, reference will now be made, by way of example, to the following drawings in which: </p><p id="p0020" num="0020">Figure 1 shows a schematic diagram of a prior art system for implementing video compression; </p><p id="p0021" num="0021"> Figure 2 shows a system for transmitting a video signal over a network according to a preferred embodiment; </p><p id="p0022" num="0022">Figure 3 shows a first sequence of video frames in a video signal; </p><p id="p0023" num="0023">Figure 4 shows a second sequence of video frames in a video signal; </p><p id="p0024" num="0024">Figure 5 is a graph representing the amount of data required to encode video frames using different types of encoding technique; 
<!-- EPO <DP n="9"/>-->
 Figure 6 shows a representation of how error propagates over time in the case of packet loss for a sequence of inter encoded frames, in a system which does not employ recovery frames; </p><p id="p0025" num="0025"> Figure 7 shows a representation of how error propagates over time in the case of packet loss for a sequence of inter encoded frames, in a system which does employ recovery frames; and </p><p id="p0026" num="0026"> Figure 8 is a flow chart for a process of transmitting a video signal over a network in accordance with a preferred embodiment. Detailed Description of Preferred Embodiments </p><p id="p0027" num="0027">Preferred embodiments of the invention will now be described by way of example only. With reference to Figure 2 there is described a system 200 for transmitting a video signal over a network according to a preferred embodiment. The system is used to stream a video signal over the network. The system 200 comprises an encoder 202 and a remote interface (or "control block") 210. The encoder is an H.264 encoder. In alternative embodiments, the encoder could be any other type of video encoder which can refer to previous frames of the video signal for encoding a current frame of the video signal (such as a VP7 or VP8 encoder). The encoder 202 comprises an encode block 204, a decode block 206 and a reference frame buffer 208. The encode block 204 of the encoder 202 is arranged to receive frames of an input video signal. The encode block 204 is arranged to encode the video frames to generate encoded video frames and side information which are output from the encoder 202 for transmission from the encoder 202. The encoded video frames may be transmitted over the network to a receiver, and may also be transmitted to the control block 210. The side information may (or may not) be transmitted with the encoded video frames over the network to the receiver and/or may (or may not) be transmitted to the network and/or to the control block 210. The encode block 204 is arranged to input the encoded video frames and side information to the decode block 206. An output of the decode block 206 is coupled to the reference frame buffer 208. The decode block 206 is arranged to decode the frames output 
<!-- EPO <DP n="10"/>-->
 from the encode block 204 and pass the decoded frames to the reference frame buffer 208. The reference frame buffer 208 is arranged to store at least some of the decoded frames. The reference frame buffer 208 is arranged to pass video frames stored therein to the encode block 204 for use in encoding subsequent frames of the video signal (e.g. for encoding inter-frames of the video signal). The control block 210 comprises a receive block 212 arranged to receive feedback from the network and to determine which of the frames transmitted to the receiver have been correctly received at the decoder of the receiver. The control block 210 also comprises a monitoring block 213 for receiving the transmitted frames and side information from the encoder 202. The control block 210 also comprises a decision block 214 which receives: (i) from receive block 212, the determination of which of the frames have been correctly received at the decoder of the receiver, and (ii) an output signal from the monitoring block 213, and uses this information to determine at least one reference frame which has been correctly received at the decoder and which can therefore be used by the encode block 204 for encoding subsequent frames of the video signal. </p><p id="p0028" num="0028">The control block 210 is remote from the encoder 202. In other words, the connection between the encoder 202 and the control block 210 uses an external interface, such as (i) an interface to communicate over a network such as the Internet (where the control block 210 is implemented on a different network node, to the network node at which the encoder is implemented) or (ii) an interface between a host device and a peripheral device connected to the host device (for example, where the encoder is implemented in a camera and the control block is implemented in a user terminal, the connection between the control block 210 and the encoder 202 may be a USB connection). To put it another way, the control block 210 is remote from the encoder 202 in the sense that the control block 210 is outside of the encoder code. Furthermore, the control block 210 may be implemented at a single node, or over multiple nodes. For example, the receive block 212, monitoring block 213 and decision block 214 may be implemented at different network nodes. Different CPUs may be used by the receive block 212, the monitoring block 213 and the decision block 214. Although the monitoring block 213 is shown as receiving both the side 
<!-- EPO <DP n="11"/>-->
 information and the encoded frames, in other embodiments, the monitoring block may receive one or none of the side information and the encoded frames from the encoder 202. The decision block 214 is arranged to send commands to the encoder 202 to indicate that one, or more, of the reference frames stored in the reference frame buffer 208 has been correctly decoded at the receiver and can be relied upon to encode subsequent frames of the video signal. As described above, some video frames may be encoded as inter frames meaning that they are encoded as a difference between the current frame and one (or more) of previous frames. Other video frames (called intra frames or key frames), may be encoded without reference to any other frames of the video signal. Figure 3 shows a sequence of video frames in which the shaded frames 302 are intra-frames and the unshaded frames 304 are inter-encoded frames. The arrows show how the encoding of each inter frame 304 is dependent upon the previous frames of the video signal back to the most recently encoded key frame 302. The use of inter-encoded frames allows the system to compress a typical video signal with great efficiency. However, the problem with such coding methodology in the real time communication over lossy links (or on links with high delay in the Transmission Control Protocol (TCP) case) is that losing any of the frames/portions of the video signal would usually cause errors in the decoding process of each frame until the next key frame is present in the video stream. </p><p id="p0029" num="0029">One solution to this problem is to use so called "Recovery frames". Figure 4 shows a sequence of video frames in a video signal, similar to that shown in Figure 3. Frames 402 are key frames, frames 404 are inter-encoded frames and frame 406 is a recovery frame. The arrow from the recovery frame 406 to the first key frame 402 indicates that the recovery frame 406 is encoded based on some frame from the past (in this case, the first key frame 402) rather than being encoded on the immediately preceding inter frame. As a result any frame 
<!-- EPO <DP n="12"/>-->
 between the first key frame 402 and the recovery frame 406 can be lost on the transmission connection, but the received Recovery frame 406 will be decodable based on the first key frame 402. Furthermore, the inter frames following the recovery frame 406 are decodable based on the correctly decoded recovery frame 406. </p><p id="p0030" num="0030">Recovery frames, which are encoded based on a previous frame in the video stream, are usually more efficient to encode than key frames are to encode. Figure 5 shows a graph representing typical amounts of data required to encode video frames using the different types of encoding technique described above. It can be seen from figure 5 that a key frame 502 requires more data than a recovery frame 506, which itself requires more data than an inter frame 504 to encode. Figure 5 demonstrates that generating a key frame is most expensive, followed by a recovery frame and followed by "normal", inter frames. Indeed, in general, it is advantageous to use as much information about previous frames as possible to increase coding efficiency, error protection and reduce jitter. Although Figure 5 represents typical amounts of data (for a typical video signal) in the frames according to the encoding technique used, the amount of data in a frame also depends upon the content of the video signal. For example, for purely random video signal the size of frames encoded with each encoding technique would be very similar to each other. For purely static video signals (i.e. in which a whole sequence of consecutive frames have the same image) the recovery and inter frames may have the same size. Figure 6 shows a representation of how error propagates over time in the case of packet loss for a sequence of inter encoded frames, in a system which does not employ recovery frames. All of the frames shown in Figure 6 are inter frames. Figure 6 shows that an encoder generates a sequence of inter frames 602. These frames are transmitted over a network to a decoder at a receiver. During transmission two of the inter frames transmitted from the encoder are lost or corrupted beyond repair. This is shown in line 604 of Figure 6. Line 606 of Figure 6 shows that the decoder has received all but the lost two of the video frames transmitted from the encoder. Line 608 of Figure 6 shows the error propagation through the sequence of inter frames of the video signal decoded 
<!-- EPO <DP n="13"/>-->
 at the decoder. The first arrow 610 indicates that there is no (or minimal) error in the first four decoded frames. However, the arrow 612 indicates, that there is significant error in the decoded video stream starting from the fifth frame and continuing through all subsequent frames shown in Figure 6. Although only the fifth and sixth frames are lost during the transmission, the seventh to tenth frames rely on the fifth and sixth frames of the video sequence in order to be correctly decoded. The error will continue to propagate in each subsequent frame of the video signal until the next key frame is transmitted from the encoder. </p><p id="p0031" num="0031">Figure 7 shows a representation of how error propagates over time in the case of packet loss for a sequence of inter encoded frames, in a system which does employ recovery frames, such as the system 200 of a preferred embodiment shown in Figure 2. A method for transmitting a video signal over a network in accordance with preferred embodiments is described below with reference to the flow chart shown in Figure 8 and in conjunction with Figures 2 and 7. </p><p id="p0032" num="0032">In step S802 the encode block 204 of the encoder 202 encodes video frames of the input video signal. The particular method used to encode the video frames may vary from frame to frame as described in more detail below. In step S804 the encode block 204 allocates an index number to each frame of the video signal. The index numbers allow each frame of the video signal to be identified. The encode block 204 also generates side information to accompany the encoded video frames. The side information simplifies the packetisation and handling of the video frames during transmission of the video frames over the network to a decoder at a receiver. The side information may, or may not, include the index numbers allocated to the video frames. The side information may indicate how a particular frame has been encoded (e.g. the encoding method used, and which other frames of the video signal were used by the encoder 202 to encode the current frame. </p><p id="p0033" num="0033">The encoded video frames are passed to the decode block 206 where they are decoded. The output of the decode block 206 should be the same as the output of the decoder at the receiver, assuming all of the video frames are successfully 
<!-- EPO <DP n="14"/>-->
 transmitted across the network to the receiver. By basing the encoding of subsequent frames of the video signal on the output of the decode block 206 the encode block 204 can accurately encode frames of the video signal in such a way that will be correctly decoded at the decoder at the receiver (assuming that no transmission errors occur). </p><p id="p0034" num="0034">Some of the frames of the video signal are designated as long term reference frames (or Future Reference frames, denoted "FR" in Figure 7). In step S806 the designated long term reference frames are stored in the reference frame buffer 208 for later use in generating subsequent frames of the video signal at the encoder 202. Figure 7 shows that alternate frames of the video signal have been designated as long term reference frames for storage in the long term reference buffer 208 (as indicated in line 704 of Figure 7). In other embodiments, different ones of the video frames may be designated as long term reference frames. For example, one in every three, or one in every four, frames may be a long term reference frame, and as such may be stored in the long term reference buffer 208 for subsequent use by the encode block 204. The side information transmitted with the encoded frames may indicate which of the frames are long term reference frames, such that the decoder at the receiver will know to store those frames in a long term reference buffer at the decoder for subsequent use in decoding frames of the video signal which have been encoded based on the long term reference frames (as described in more detail below). In step S808 the encoded frames of the video signal and possibly the side information are transmitted from the encoder 202 to the decoder at the receiver over the network. The side information may, or may not, be transmitted to the decoder of the receiver. The side information may not be needed for the decoding process at the receiver. The side information allows a more efficient handling of the video stream on the network level. The side information may be provided to the monitoring block 213 of the control block 210 as shown in Figure 2. The side information may include one or more of the following pieces of information: 
<!-- EPO <DP n="15"/>-->
 (i) the index number allocated to the frame that is currently being transmitted with the side information. As an alternative to including this information in the side information, the encoder 202 and the control block 210 can agree on a frame numbering strategy and can each independently allocate index numbers to the frames according to the same algorithm (e.g. increase index number by one for each frame, or a timer could be used to generate the index numbers. These methods may encounter problems if a frame is lost or delayed between the encoder 202 and the controller 210, and the numbering may become out of sync. </p><p id="p0035" num="0035"> (ii) an indication as to whether the frame was saved in reference frame buffer 208. Preferably, the indication may indicate the position in the buffer 208 at which the frame is stored. This information may be able to be read from slice headers with the encoded frames, but by including this information in the side information, the process by which the control block 210 can determine this information is simplified. </p><p id="p0036" num="0036"> (iii) the subset of frames which are used to encode the current frame. It can be useful for the control block 210 to know this information since it will give an indication of whether the video stream has been recovered or not. This information can be read from the bitstream, but it may be computationally expensive to retrieve this information from the bitstream. Therefore by including this information in the side information the computation required at the control block 210 can be reduced. </p><p id="p0037" num="0037">It can therefore be appreciated that the use of the side information has the advantage that control block 210 can be implemented more simply since it does not have to parse the bitstream to retrieve the information in the side information. The control block 210 may be implemented independently of the encoder. The term "independent" in this context means that the same control block 210 can be used to control several different encoders. This can be useful in software development since it reduces the amount of code needed. Assuming that the side information is agreed between the encoder implementations, control blocks can be identical for use with different encoders. If the side information is different for different encoders, or if the information is obtained from the bitstream rather than from side information, then only the 
<!-- EPO <DP n="16"/>-->
 monitoring block 213 needs to be developed in an encoder specific fashion. If the side information is transmitted to the decoder then this provides a mechanism for the decoder to know whether the video stream is decoded correctly. </p><p id="p0038" num="0038">However, in the example shown in Figure 7, two of the frames of the video signal are not successfully transmitted over the network to the decoder, as shown in line 706. The decoder at the receiver sends feedback messages over the network to acknowledge the receipt of the video frames. In step S810 these feedback messages are received at the control block 210. The receive block 212 of the control block 210 determines, from the feedback, which of the video frames transmitted from the encoder 202 have been successfully received at the decoder of the receiver. This information is passed to the decision block 214 of the control block 210. In step S812 the decision block 214 determines a subset of the long term reference frames stored in the reference frame buffer 208 which have been correctly received at the decoder of the receiver. The subset of the stored long term reference frames identifies those long term reference frames which can be used validly by the encoder 202 to encode subsequent frames of the video signal. </p><p id="p0039" num="0039">In step S814 a command (or "message") is transmitted from the decision block 214 of the control block 210 to the encoder 202 to indicate the subset of long term reference frames which can be used by the encode block 204 for encoding subsequent frames of the video signal. The subset may identify one or multiple long term reference frames. </p><p id="p0040" num="0040">In step S816 the encoder identifies the frames in the subset which are indicated in the command. The command identifies the frames in the subset using the index numbers of the frames. In this way it is the frames themselves which are indicated, rather than their position in the reference frame buffer 208. 
<!-- EPO <DP n="17"/>-->
 In step S818 the encode block 204 retrieves at least one suitable long term reference frame from the reference frame buffer 208 in accordance with the frames identified in the command, and then encodes at least one subsequent frame of the video signal using the retrieved long term reference frame(s). By basing the encoding of subsequent frames of the video signal on long term reference frame(s) that are identified in the command, the encoder can be sure to encode subsequent frames using previous frames that have been received correctly at the decoder of the receiver. As shown in Figure 7, the receiver acknowledges that the first two reference frames are correctly received at the decoder of the receiver. However, when a frame is lost during transmission over the network then the feedback from the decoder to the control block 210 indicates that the frames have not been correctly received at the decoder. The time between a frame being transmitted from the encoder 202 and the feedback for that frame being received at the control block 210 is approximately equal to the Round Trip Time (RTT) (denoted "Round Trip Network Delay" in Figure 7). The RTT is typically longer than the duration of a frame of the video signal (when the frame is played out). In this case, the control block 210 does not determine that a frame has been lost before the next frame of the video signal is encoded and transmitted. However, for the first frame after the control block 210 determines that a frame has been lost during transmission, the control block 210 determines that a Stream Recovery frame (denoted "SR" in Figure 7) is to be generated. In this case, the command sent from the control block 210 to the encoder 202 includes the index numbers indicating the first two (correctly received) long term reference frames, such that the Stream Recovery frame is encoded based on the first two long term reference frames by the encode block 204 of the encoder 202. Therefore, the Stream Recovery frame can be correctly decoded at the decoder of the receiver (based on the first two correctly received long term reference frames - which have been stored at a buffer of the decoder in the receiver). </p><p id="p0041" num="0041">The line 712 in Figure 7 shows the error propagation through the video signal at the decoder. The first four frames are correctly received and can be decoded (as indicated by arrow 714). The next two frames are not received at the 
<!-- EPO <DP n="18"/>-->
 decoder and as such cannot be decoded. The following frame also cannot be correctly decoded at the decoder because it was encoded at the encoder based on at least one of the preceding frames that was lost in transmission. Arrow 716 indicates that errors propagate through these three frames of the video signal. However, the Stream Recovery frame is then received at the decoder which was encoded based on the correctly received long term reference frames. The decoder can retrieve the correctly received long term reference frames from a buffer associated with the decoder and can correctly decode the Stream Recovery frame. The frames subsequent to the Stream Recovery frame can be correctly decoded because they are encoded based on the correctly received and decoded Stream Reference frame. Arrow 718 indicates that little or no error propagates through the frames subsequent to the Stream Recovery frame in the video signal. As can be seen from the above description the long term reference frames ("FR") are frames which are saved in the encoder memory (e.g. in reference frame buffer 208) and in the decoder memory for future reference. The Stream Recovery frame ("SR") is a frame which, based on the current network conditions, can perfectly recover the video stream. </p><p id="p0042" num="0042">The control block 210 acts as an encoder Application Programming Interface (API) for the encoder 202 which reports to the encoder 202 which frames can be used reliably as reference frames in the event of a packet loss. The control block 210 makes the decision (in the decision block 214) as to which long term reference frames should be used to encode subsequent frames based on the feedback received from the network regarding the success of the transmission of previous frames of the video signal. The control block 210 then simply tells the encoder 202 which long term reference frames to use for encoding subsequent frames of the video signal. Therefore, the encoder 202 does not need to be able to perform such a decision. This means that the encoder 202 can be simplified. It can be advantageous to implement the encoder 202 in a simple manner. In particular, the control block 210 can be used to provide the commands to any suitable type of encoder, such as an H.264 encoder, a VP8 or VP7 encoder. The use of side information as described above can simplify 
<!-- EPO <DP n="19"/>-->
 the implementation of the control block 210 making it less CPU intensive. The control block 210 maintains the state of the decoder buffer in order to determine how best to encode subsequent frames of the video signal. In one embodiment, the encoder 202 is implemented in a camera which is connected to a user terminal on which the control block 210 is implemented. In this embodiment the transmission of the encoded frames of the video signal can be transmitted from the encoder 202 to the network via the user terminal on which the control block 210 is implemented. </p><p id="p0043" num="0043">In another embodiment, the encoder 202 is implemented at a user terminal and the control block 210 is implemented at another node in the network (e.g. at a server node of the network or at the receiver node at which the decoder is implemented). By having the control block 210 remote from the encoder 202 the processing resources used to implement the encoder 202 and the control block 210 are advantageously separated from each other. </p><p id="p0044" num="0044">Furthermore, since the control block 210 makes the decisions as to which long term reference frames to base the encoding of subsequent frames on, the design and implementation of the encoder 202 can be simplified. For example, where the encoder is a H.264 encoder, the encoder may not have the notion of recovery frames, as described above. However, according to the H.264 standard, an H.264 encoder does have the ability to refer and store up to sixteen frames in the local memory, thereby allowing the control block 210 to be implemented in conjunction with a H.264 encoder as described above. </p><p id="p0045" num="0045">The method and system described above advantageously uses index numbers which identify frames (rather than buffer positions as in VP7 or VP8 described in the background section above). This enables the system to handle asynchronous modes of operation, which are typical for hardware encoders (e.g. where the encoder 202 is in a peripheral device and the control block 210 is in a user terminal) and remote systems (e.g. where the encoder 202 and control block are implemented at different network nodes, such as a server controlled remote encoder - for example where the encoder is implemented in a 
<!-- EPO <DP n="20"/>-->
 web browser plug-in - or a receiver controlled encoder where the control block is implemented at the receiver). These are considered to be asynchronous modes of operation because the time taken for the command to be transmitted from the control block 210 to the encoder 202 is longer than the time duration of a frame of the video signal during play out. Therefore, when the command is generated by the control block 210, the control block 210 cannot know what the contents of the reference frame buffer 208 will be when the command is received at the encoder 202. This could cause a problem if the buffer positions in the reference frame buffer 208 were used rather than the index numbers which identify the frames themselves. </p><p id="p0046" num="0046">The index numbers identify the frames in terms of absolute numbers. The term "absolute" here means that the modulo of the index number is larger than RTT T<sub>f</sub>, where T<sub>f</sub> is the duration of a frame of the video signal when it is played out. In this sense the index number will not repeat for frames generated within the Round Trip Time of the transmission of the encoded frames. Preferably the modulo of the index number is much larger than RTT T<sub>f</sub> to account for extraordinary losses and delays in the network. The index number could be used only inside the encoder 202 and does not have to be part of the bitstream, thereby maintaining compatibility with standard decoders. The index number could grow with each encoded frame. The encoder could be asked to use some "sensible" number of bits for frame identification. For example, the encoder may be an H.264 encoder and the minimum number of bits used in H.264 is 4 bits, such that a sequence of 16 frames have unique index numbers but after that the index numbers cycle and repeat for every 16 frames. This repetition of index number may be known as wrapping. If 8 bits are used for the index number we can have a sequence of 256 frames having unique index numbers. At 30 frames per second, this would represent a time of 8.5 seconds before the index numbers start to repeat. 8.5 seconds is much larger than the RTT in most communications, and as such using 8 bits for the index number of the frames is sufficient for treating the index numbers as being absolute (i.e. unique for frames within a time duration of the average RTT). It should be ensured that the wrap period of the index numbers is much longer than the typical RTT, such that the index numbers can be considered to be absolute (i.e. 
<!-- EPO <DP n="21"/>-->
 unique within the average RTT). In this sense, the index numbers provide a unique way of identifying a frame in the control block 210. The index numbers may be used only for communications between the control block 210 and the encoder 202, such that within the encoder 202 itself, a frame may be identified by some other identification method after the control block 210 has uniquely identified the frame to the encoder 202 using the index numbers described herein. </p><p id="p0047" num="0047">There is presented below an example to highlight the advantage of using index numbers that identify specific frames rather than using buffer positions to identify frames. Let us assume that the encoder 202 puts Frame X into position N in the reference frame buffer 208. Addressing the frame by X (rather than by N) gives unique mapping between frames (within counter X wrap time) and is therefore more robust, particularly in cases where there is a large delay (in time) for messages transmitted between the control block 210 and the encoder 202, or where there is a chance that commands sent from the control block 210 may actually be received at the encoder 202 in a different order, for example when the control block 210 is implemented on a server of the network or on the receiver. </p><p id="p0048" num="0048">Let us assume that the control block issues Command 0 which instructs the encoder 202 to recover the video stream using frame X (which is currently stored at position N in the reference frame buffer 208), and then issues Command 1 which instructs the encoder 202 to put a current frame (Y) into position N of the reference frame buffer. Then let us assume that Command 0 is delayed in the network such that Command 1 is received at the encoder 202 before Command 0. In embodiments of the present invention the encoder 202 realizes that frame X is not present in the reference frame buffer 208 when Command 0 is received at the encoder 202, and can then deal with the situation accordingly. For example, the encoder 202 may determine that a key frame must be generated, or may determine some other way of encoding the current frame using frames which are still present in the reference frame buffer 208. 
<!-- EPO <DP n="22"/>-->
 However, if this same situation occurred in a system in which the commands sent from the control block to the encoder identified positions in the reference frame buffer, rather than the absolute index numbers identifying frames of the preferred embodiments described above, then the encoder would try to recover the video stream using frame Y rather than frame X because frame Y would be in position N in the reference frame buffer when Command 0 was received at the encoder instructing the encoder to recover the video stream using the frame at position N in the reference frame buffer. This will most likely result in a broken video stream which may be difficult to recover from without resorting to generating a key frame (which as described above in relation to Figure 5 is costly in terms of the amount of data required to store and transmit the frame). </p><p id="p0049" num="0049">The control block 210 should be able to determine which of the transmitted frames of the video signal are stored in the reference frame buffer 208 at the encoder 202. In order to achieve this, the encoder 202 may send a message to the control block 210 to inform the control block 210 of which frames are stored in the reference frame buffer 208. Alternatively, all of the frames marked as long term reference frames are stored in the reference frame buffer 208, and the control block 210 monitors the transmitted frames and the side information to determine which frames are long term reference frames and are therefore stored in the reference frame buffer 208. </p><p id="p0050" num="0050">In summary of the above, embodiments of the present invention provide a system by which reference frames can be identified using "absolute", or "unique", index numbers. This is in contrast to the systems of the prior art which identify positions in the buffer. The production of side information by the encoder 202, aids the control block 210 (but not necessarily the decoder of the receiver) in identifying which frames need to be correctly received for the current frame to be decoded correctly (essentially a set of frames that the current frame is coded in dependence on). The control block 210 is external (or "remote") from the encoder 202 thereby separating the decision making process from the encoder 202. 
<!-- EPO <DP n="23"/>-->
 As described above, the index numbers of the frames may be transmitted in the side information with the transmitted frames to the receiver. Alternatively, instead of transmitting the index numbers, the system can make use of the Real-time Transport Protocol (RTP) to carefully monitor the feedback from the network which is sent as control signals using Real-time Transport Control Protocol (RTCP). In this way the control block 210 can keep track of the index numbers that the encoder will allocate to each frame (assuming the control block 210 uses the same numbering system as the encoder 202 uses for determining index numbers for the frames). </p><p id="p0051" num="0051">When the control block 210 can determine the index numbers allocated to the frames then the control block 210 can determine, from the feedback, the subset of the index numbers of the long term reference frames which have been successfully received at the decoder of the receiver, as described above. </p><p id="p0052" num="0052">Although in the preferred embodiments described above the method and system are applied to frames of the video signal, in other embodiments, the method and system are applied to other portions of the video signal such as slices or macroblocks. </p><p id="p0053" num="0053">Although in the preferred embodiments described above it is the long term reference frames which are stored in the reference frame buffer 208, in other embodiments, other types of frames (e.g. short term reference frames) may be stored for use in generating subsequent frames of the video signal. Short term reference frames will be removed from the buffer in an automatic fashion according to certain predefined rules. </p><p id="p0054" num="0054">The system of the preferred embodiments described above is used to stream a video signal over the network from the encoder to the decoder at the receiver. In this sense, the video frames may be played out at the receiver in real-time as they are decoded. If the video signal is not being played out in real-time as it is received then the decoder can request that the encoder re-transmits any frames that are lost or corrupted during transmission of the video signal over the network. 
<!-- EPO <DP n="24"/>-->
 The blocks shown in Figure 2 and the method steps shown in Figure 8 may be implemented in software or hardware modules within the encoder 202 and the control block 210. This is an implementation choice. </p><p id="p0055" num="0055">Furthermore, while this invention has been particularly shown and described with reference to preferred embodiments, it will be understood to those skilled in the art that various changes in form and detail may be made without departing from the scope of the invention as defined by the appendant claims. 
</p></description><claims mxw-id="PCLM44727565" ref-ucid="WO-2012113763-A1" lang="EN" load-source="patent-office"><claim-statement><!-- EPO <DP n="25"/>-->Claims </claim-statement><claim id="clm-0001" num="1"><claim-text>1 . A method of transmitting a video signal over a network, the method comprising: </claim-text><claim-text> encoding portions of the video signal with an encoder, and transmitting the encoded portions over the network to a decoder; </claim-text><claim-text> the encoder allocating index numbers to the transmitted portions of the video signal, each index number identifying a respective portion of the video signal; </claim-text><claim-text> storing at least some of the portions of the video signal in a buffer associated with the encoder; </claim-text><claim-text> receiving feedback from the network at a control block remote from the encoder, the feedback indicating whether each of the transmitted portions has been correctly received; </claim-text><claim-text> based on the feedback, the control block determining a subset of the portions of the video signal stored in the buffer which are to be used by the encoder for encoding subsequent portions of the video signal; </claim-text><claim-text> the control block transmitting a message to the encoder, said message identifying the subset of portions of the video signal using the index numbers allocated to the portions in the subset of portions; and </claim-text><claim-text> in response to receiving the message from the control block, the encoder using the index numbers in the message to identify and retrieve at least one portion of the subset of portions from the buffer, wherein the encoder encodes subsequent portions of the video signal using the at least one retrieved portion. </claim-text></claim><claim id="clm-0002" num="2"><claim-text>2. The method of claim 1 wherein the portions of the video signal are (i) frames of the video signal, (ii) macroblocks of the video signal, or (iii) slices of the video signal. </claim-text></claim><claim id="clm-0003" num="3"><claim-text>3. The method of claim 1 or 2 wherein one of the subsequent portions of the video signal which are encoded using the at least one retrieved portion, is a recovery portion of the video signal which is encoded based only on the at least one retrieved portion. <!-- EPO <DP n="26"/>--> </claim-text></claim><claim id="clm-0004" num="4"><claim-text>4. The method of any preceding claim wherein the index numbers allocated to the portions within a time interval equal to the average Round Trip Time between the encoder and the decoder, are unique. </claim-text></claim><claim id="clm-0005" num="5"><claim-text>5. The method of any preceding claim further comprising the encoder informing the control block of which portions of the video signal are stored in the buffer. </claim-text></claim><claim id="clm-0006" num="6"><claim-text>6. The method of any of claims 1 to 4 wherein the portions of the video signal are stored in the buffer if they are of a particular type, and wherein the method further comprises the control block monitoring the transmitted portions of the video signal and determining that those portions of the video signal which are of the particular type are stored in the buffer. </claim-text></claim><claim id="clm-0007" num="7"><claim-text>7. The method of any preceding claim wherein the portions of the video signal which are stored in the buffer are long term reference portions of the video signal. </claim-text></claim><claim id="clm-0008" num="8"><claim-text>8. The method of any preceding claim wherein the index numbers are transmitted with the portions of the video signal to which they are allocated. </claim-text></claim><claim id="clm-0009" num="9"><claim-text>9. The method of claim 8 wherein the index numbers are transmitted as side information accompanying the transmitted portions of the video signal to which they are allocated. </claim-text></claim><claim id="clm-0010" num="10"><claim-text>10. The method of any of claims 1 to 7 wherein the index numbers are not transmitted with the portions of the video signal to which they are allocated, and wherein the control block monitors the transmission of the portions of the video signal and uses the monitoring of the transmission of the portions of the video signal to thereby determine the index numbers which have been allocated to the transmitted portions of the video signal. <!-- EPO <DP n="27"/>--> </claim-text></claim><claim id="clm-0011" num="11"><claim-text>1 1 . The method of any preceding claim wherein the step of the control block transmitting the message to the encoder comprises transmitting the message over one of a network connection and a USB connection. </claim-text></claim><claim id="clm-0012" num="12"><claim-text>12. A system for transmitting a video signal over a network, the system comprising: </claim-text><claim-text> (i) an encoder which is configured to: </claim-text><claim-text> encode portions of the video signal, and transmit the encoded portions over the network to a decoder; </claim-text><claim-text> allocate index numbers to the transmitted portions of the video signal, each index number identifying a respective portion of the video signal; and </claim-text><claim-text> store at least some of the portions of the video signal in a buffer associated with the encoder; and </claim-text><claim-text> (ii) a control block which is remote from the encoder and which is configured to: </claim-text><claim-text> receive feedback from the network, the feedback indicating whether each of the transmitted portions has been correctly received; determine, based on the feedback, a subset of the portions of the video signal stored in the buffer which are to be used by the encoder for encoding subsequent portions of the video signal; and </claim-text><claim-text> transmit a message to the encoder, said message identifying the subset of portions of the video signal using the index numbers allocated to the portions in the subset of portions, </claim-text><claim-text> wherein the encoder is configured to identify and retrieve, in response to receiving the message from the control block, at least one portion of the subset of portions from the buffer using the index numbers in the message, and to encode subsequent portions of the video signal using the at least one retrieved portion. </claim-text></claim><claim id="clm-0013" num="13"><claim-text>13. The system of claim 12 wherein the portions of the video signal are (i) frames of the video signal, (ii) macroblocks of the video signal, or (iii) slices of the video signal. <!-- EPO <DP n="28"/>--> </claim-text></claim><claim id="clm-0014" num="14"><claim-text>14. The system of claim 12 or 13 wherein the encoder comprises means for transmitting the portions of the video signal over the network to the decoder and for transmitting the index numbers as side information accompanying the transmitted portions of the video signal to which they are allocated. </claim-text></claim><claim id="clm-0015" num="15"><claim-text>15. The system of any of claims 12 to 14 wherein the encoder is one of a H.264 encoder, a VP7 encoder and a VP8 encoder. </claim-text></claim><claim id="clm-0016" num="16"><claim-text>16. The system of any of claims 12 to 15 wherein there is one of a network connection and a USB connection between the encoder and the control block for transmitting the message. </claim-text></claim><claim id="clm-0017" num="17"><claim-text>17. The system of any of claims 12 to 16 wherein the encoder is situated in a user terminal and the control block is situated in either (i) a receiving node of the network in which the decoder is also situated, or (ii) a separate network node. </claim-text></claim><claim id="clm-0018" num="18"><claim-text>18. The system of any of claims 12 to 16 wherein the control block is situated in a user terminal and the encoder is situated in a peripheral device of the user terminal. </claim-text></claim><claim id="clm-0019" num="19"><claim-text>19. The system of claim 18 wherein the peripheral device is a camera. </claim-text></claim><claim id="clm-0020" num="20"><claim-text>20. A method of controlling transmission of portions of a video signal which are encoded by an encoder and transmitted over a network to a decoder, wherein the encoder allocates index numbers to the transmitted portions of the video signal and stores at least some of the portions of the video signal in a buffer associated with the encoder, each index number identifying a respective portion of the video signal, the method comprising: </claim-text><claim-text> receiving feedback from the network at a control block remote from the encoder, the feedback indicating whether each of the transmitted portions has been correctly received; <!-- EPO <DP n="29"/>--> based on the feedback, the control block determining a subset of the portions of the video signal stored in the buffer which are to be used by the encoder for encoding subsequent portions of the video signal; and </claim-text><claim-text> the control block transmitting a message to the encoder, said message identifying the subset of portions of the video signal using the index numbers allocated to the portions in the subset of portions, </claim-text><claim-text> such that the encoder can use the index numbers in the message to identify at least one portion of the subset of portions for encoding subsequent portions of the video signal. </claim-text></claim><claim id="clm-0021" num="21"><claim-text>21. A computer program product comprising computer readable instructions for execution by computer processing means at a control block for controlling transmission of portions of a video signal, the instructions comprising instructions for carrying out the method according to claim 20. </claim-text></claim><claim id="clm-0022" num="22"><claim-text>22. A control block for controlling transmission of portions of a video signal which are encoded by an encoder and transmitted over a network to a decoder, wherein the encoder allocates index numbers to the transmitted portions of the video signal and stores at least some of the portions of the video signal in a buffer associated with the encoder, each index number identifying a respective portion of the video signal, wherein the control block is remote from the encoder and the control block comprises: </claim-text><claim-text> receiving means for receiving feedback from the network, the feedback indicating whether each of the transmitted portions has been correctly received; </claim-text><claim-text> determining means for determining, based on the feedback, a subset of the portions of the video signal stored in the buffer which are to be used by the encoder for encoding subsequent portions of the video signal; and </claim-text><claim-text> transmitting means for transmitting a message to the encoder, said message identifying the subset of portions of the video signal using the index numbers allocated to the portions in the subset of portions, </claim-text><claim-text> such that the encoder can use the index numbers in the message to identify at least one portion of the subset of portions for encoding subsequent portions of the video signal. <!-- EPO <DP n="30"/>--> </claim-text></claim><claim id="clm-0023" num="23"><claim-text>23. The control block of claim 22 wherein the transmitting means is for transmitting the message to the encoder via one of a network connection and a USB connection between the control block and the encoder. </claim-text></claim></claims><amended-claims mxw-id="PCLM44727564" ref-ucid="WO-2012113763-A1" lang="EN" load-source="patent-office" amended-claim-type=""><heading><!-- EPO <DP n="31"/>-->AMENDED CLAIMS received by the International Bureau on 02 August 2012 (02.08.12) </heading><claim id="amd-clm-0001" num="1"><claim-text>1. A method of controlling transmission of portions of a video signal which have been encoded by an encoder for transmission over a network to a decoder, wherein the encoder has allocated index numbers to the transmitted portions of the video signal and has stored at least some of the portions of the video signal in a buffer associated with the encoder, each index number identifying a respective portion of the video signal, the method comprising: </claim-text><claim-text> receiving feedback from the network at a control block remote from the encoder, the feedback indicating whether each of the transmitted portions has been correctly received; </claim-text><claim-text> based on the feedback, the control block determining a subset of the portions of the video signal stored in the buffer which are to be used by the encoder for encoding subsequent portions of the video signal; and </claim-text><claim-text> the control block transmitting a message to the encoder, said message identifying the subset of portions of the video signal using the index numbers allocated to the portions in the subset of portions, </claim-text><claim-text> such that the encoder can use the index numbers in the message to identify at least one portion of the subset of portions for encoding subsequent portions of the video signal. </claim-text></claim><claim id="amd-clm-0002" num="2"><claim-text>2. A control block for controlling transmission of portions of a video signal which have been encoded by an encoder for transmission over a network to a decoder, wherein the encoder has allocated index numbers to the transmitted portions of the video signal and has stored at least some of the portions of the video signal in a buffer associated with the encoder, each index number identifying a respective portion of the video signal wherein the control block is remote from the encoder and the control block comprises: </claim-text><claim-text> receiving means for receiving feedback from the network, the feedback indicating whether each of the transmitted portions has been correctly received; </claim-text><claim-text> determining means for determining, based on the feedback, a subset of the portions of the video signal stored in the buffer which are to be used by the encoder for encoding subsequent portions of the video signal; and <!-- EPO <DP n="32"/>--> transmitting means for transmitting a message to the encoder, said message identifying the subset of portions of the video signal using the index numbers allocated to the portions in the subset of portions, </claim-text><claim-text> such that the encoder can use the index numbers in the message to identify at least one portion of the subset of portions for encoding subsequent portions of the video signal. </claim-text></claim><claim id="amd-clm-0003" num="3"><claim-text>3. The method or control block of claim 1 or 2 wherein the portions of the video signal are (i) frames of the video signal, (ii) macroblocks of the video signal, or (iii) slices of the video signal. </claim-text></claim><claim id="amd-clm-0004" num="4"><claim-text>4. The method or control block of claim 1 , 2 or 3 wherein one of the subsequent portions of the video signal which are encoded using the at least one retrieved portion, is a recovery portion of the video signal which is encoded based only on the at least one retrieved portion. </claim-text></claim><claim id="amd-clm-0005" num="5"><claim-text>5. The method or control block of any preceding claim wherein the index numbers allocated to the portions within a time interval equal to the average Round Trip Time between the encoder and the decoder, are unique. </claim-text></claim><claim id="amd-clm-0006" num="6"><claim-text>6. The method or control block of any preceding claim wherein: </claim-text><claim-text> the control block is informed by the encoder of which portions of the video signal are stored in the buffer; or </claim-text><claim-text> the portions of the video signal are stored in the buffer if they are of a particular type, and wherein the control block monitors the transmitted portions of the video signal and determines that those portions of the video signal which are of the particular type are stored in the buffer. </claim-text></claim><claim id="amd-clm-0007" num="7"><claim-text>7. The method or control block of any preceding claim wherein the portions of the video signal which are stored in the buffer are long term reference portions of the video signal. </claim-text></claim><claim id="amd-clm-0008" num="8"><claim-text>8. The method or control block of any preceding claim wherein: <!-- EPO <DP n="33"/>--> the index numbers are transmitted with the portions of the video signal to which they are allocated, wherein the index numbers are optionally transmitted as side information accompanying the transmitted portions of the video signal to which they are allocated, or </claim-text><claim-text> the index numbers are not transmitted with the portions of the video signal to which they are allocated, and wherein the control block monitors the transmission of the portions of the video signal and uses the monitoring of the transmission of the portions of the video signal to thereby determine the index numbers which have been allocated to the transmitted portions of the video signal. </claim-text></claim><claim id="amd-clm-0009" num="9"><claim-text>9. The method according to any of claims 1 and 3 to 8, wherein the transmission of the portions of the video signal comprises: </claim-text><claim-text> encoding portions of the video signal with the encoder, and transmitting the encoded portions over the network to the decoder; </claim-text><claim-text> the encoder allocating index numbers to the transmitted portions of the video signal, each index number identifying a respective portion of the video signal; and storing at least some of the portions of the video signal in the buffer associated with the encoder. </claim-text></claim><claim id="amd-clm-0010" num="10"><claim-text>10. A computer program product comprising computer readable instructions for execution by computer processing means at a control block for controlling transmission of portions of a video signal, the instructions comprising instructions for carrying out the method according to any of claims 1 and 3 to 9. </claim-text></claim></amended-claims><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
