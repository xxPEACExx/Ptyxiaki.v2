<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2682782-A1" country="EP" doc-number="2682782" kind="A1" date="20140108" family-id="46766211" file-reference-id="206443" date-produced="20180822" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="146585509" ucid="EP-2682782-A1"><document-id><country>EP</country><doc-number>2682782</doc-number><kind>A1</kind><date>20140108</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-13175174-A" is-representative="YES"><document-id mxw-id="PAPP154847701" load-source="docdb" format="epo"><country>EP</country><doc-number>13175174</doc-number><kind>A</kind><date>20130704</date><lang>EN</lang></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC140549819" ucid="GB-201211999-A" load-source="docdb"><document-id format="epo"><country>GB</country><doc-number>201211999</doc-number><kind>A</kind><date>20120705</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL1989316451" load-source="ipcr">G01S  15/93        20060101ALI20131014BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1989322866" load-source="ipcr">G01S  15/87        20060101AFI20131014BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL1989621955" load-source="docdb" scheme="CPC">G01S  15/872       20130101 LI20131010BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989635175" load-source="docdb" scheme="CPC">G01S  15/93        20130101 LI20131010BHEP        </classification-cpc><classification-cpc mxw-id="PCL1991311674" load-source="docdb" scheme="CPC">G05D   1/0011      20130101 FI20140102BHEP        </classification-cpc><classification-cpc mxw-id="PCL1991313677" load-source="docdb" scheme="CPC">G05D   1/0206      20130101 LI20140102BHEP        </classification-cpc><classification-cpc mxw-id="PCL1991314022" load-source="docdb" scheme="CPC">G05D   1/0202      20130101 LI20140102BHEP        </classification-cpc><classification-cpc mxw-id="PCL1991314735" load-source="docdb" scheme="CPC">G01S  15/42        20130101 LI20140102BHEP        </classification-cpc><classification-cpc mxw-id="PCL1991315070" load-source="docdb" scheme="CPC">G01S  15/874       20130101 LI20140110BHEP        </classification-cpc><classification-cpc mxw-id="PCL1991316402" load-source="docdb" scheme="CPC">G05D   1/0088      20130101 LI20140102BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT132361160" lang="DE" load-source="patent-office">Sensorslokalisierungsverfahren und -system</invention-title><invention-title mxw-id="PT132361161" lang="EN" load-source="patent-office">Sensor location method and system</invention-title><invention-title mxw-id="PT132361162" lang="FR" load-source="patent-office">Procédé et système de localisation de capteur</invention-title><citations><patent-citations><patcit mxw-id="PCIT242944372" load-source="docdb" ucid="US-5621807-A"><document-id format="epo"><country>US</country><doc-number>5621807</doc-number><kind>A</kind><date>19970415</date></document-id><sources><source name="SEA" category="X" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT242944373" load-source="docdb" ucid="US-6317387-B1"><document-id format="epo"><country>US</country><doc-number>6317387</doc-number><kind>B1</kind><date>20011113</date></document-id><sources><source name="SEA" category="Y" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT242944374" load-source="docdb" ucid="US-8031908-B2"><document-id format="epo"><country>US</country><doc-number>8031908</doc-number><kind>B2</kind><date>20111004</date></document-id><sources><source name="SEA" category="Y" created-by-npl="N"/></sources></patcit></patent-citations><non-patent-citations><nplcit><text>TILLET, R.D COMPUTERS AND ELECTRONICS IN AGRICULTURE vol. 6, no. 1, July 1991, pages 51 - 61</text><sources><source mxw-id="PNPL45211536" load-source="docdb" name="APP"/></sources></nplcit><nplcit><text>TRIGGS B ET AL:  "Sonar Localisation for Mobile Robots: A Model-Based Approach", 19920811; 19920811 - 19920814, 11 August 1992 (1992-08-11), pages 387-392, XP010287174,</text><sources><source mxw-id="PNPL45211537" load-source="docdb" name="SEA" category="X"/></sources></nplcit></non-patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR919513556" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>ROKE MANOR RESEARCH</last-name><address><country>GB</country></address></addressbook></applicant><applicant mxw-id="PPAR919514737" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>ROKE MANOR RESEARCH LIMITED</last-name></addressbook></applicant><applicant mxw-id="PPAR919007951" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>ROKE MANOR RESEARCH LIMITED</last-name><iid>100210020</iid><address><street>Old Salisbury Lane</street><city>Romsey, Hampshire SO51 0ZN</city><country>GB</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR919526529" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>SPENCE CHRISTOPHER ROBERT</last-name><address><country>GB</country></address></addressbook></inventor><inventor mxw-id="PPAR919530347" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>Spence, Christopher Robert</last-name></addressbook></inventor><inventor mxw-id="PPAR919009172" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Spence, Christopher Robert</last-name><address><street>120 The Dell</street><city>Southampton, SO15 2PX</city><country>GB</country></address></addressbook></inventor><inventor mxw-id="PPAR919542505" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>SPARKS EDMUND PETER</last-name><address><country>GB</country></address></addressbook></inventor><inventor mxw-id="PPAR919525236" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>SPARKS, EDMUND PETER</last-name></addressbook></inventor><inventor mxw-id="PPAR919017673" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>SPARKS, EDMUND PETER</last-name><address><street>Loders Cottage Wangfield Lane</street><city>Curdridge, SO32 2DA</city><country>GB</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR919006652" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Wallin, Nicholas James</last-name><iid>100048885</iid><address><street>Withers &amp; Rogers LLP 4 More London Riverside</street><city>London SE1 2AU</city><country>GB</country></address></addressbook></agent></agents></parties><international-convention-data><designated-states><ep-contracting-states><country mxw-id="DS549824194" load-source="docdb">AL</country><country mxw-id="DS549826348" load-source="docdb">AT</country><country mxw-id="DS549827972" load-source="docdb">BE</country><country mxw-id="DS549820949" load-source="docdb">BG</country><country mxw-id="DS549748425" load-source="docdb">CH</country><country mxw-id="DS549827973" load-source="docdb">CY</country><country mxw-id="DS549826349" load-source="docdb">CZ</country><country mxw-id="DS549824196" load-source="docdb">DE</country><country mxw-id="DS549827978" load-source="docdb">DK</country><country mxw-id="DS549827979" load-source="docdb">EE</country><country mxw-id="DS549749801" load-source="docdb">ES</country><country mxw-id="DS549820954" load-source="docdb">FI</country><country mxw-id="DS549748426" load-source="docdb">FR</country><country mxw-id="DS549824197" load-source="docdb">GB</country><country mxw-id="DS549827980" load-source="docdb">GR</country><country mxw-id="DS549824202" load-source="docdb">HR</country><country mxw-id="DS549826354" load-source="docdb">HU</country><country mxw-id="DS549749802" load-source="docdb">IE</country><country mxw-id="DS549827981" load-source="docdb">IS</country><country mxw-id="DS549820955" load-source="docdb">IT</country><country mxw-id="DS549827986" load-source="docdb">LI</country><country mxw-id="DS549820956" load-source="docdb">LT</country><country mxw-id="DS549910451" load-source="docdb">LU</country><country mxw-id="DS549820957" load-source="docdb">LV</country><country mxw-id="DS549820966" load-source="docdb">MC</country><country mxw-id="DS549910452" load-source="docdb">MK</country><country mxw-id="DS549910453" load-source="docdb">MT</country><country mxw-id="DS549910454" load-source="docdb">NL</country><country mxw-id="DS549748427" load-source="docdb">NO</country><country mxw-id="DS549910455" load-source="docdb">PL</country><country mxw-id="DS549749803" load-source="docdb">PT</country><country mxw-id="DS549751684" load-source="docdb">RO</country><country mxw-id="DS549749804" load-source="docdb">RS</country><country mxw-id="DS549910456" load-source="docdb">SE</country><country mxw-id="DS549824204" load-source="docdb">SI</country><country mxw-id="DS549748428" load-source="docdb">SK</country><country mxw-id="DS549748437" load-source="docdb">SM</country><country mxw-id="DS549827987" load-source="docdb">TR</country></ep-contracting-states><ep-extended-states><ep-extended-state-data><country>BA</country></ep-extended-state-data><ep-extended-state-data><country>ME</country></ep-extended-state-data></ep-extended-states></designated-states></international-convention-data></bibliographic-data><abstract mxw-id="PA128673681" lang="EN" load-source="patent-office"><p id="pa01" num="0001">The present invention applies model-based processing to a sensor output from a sensor such as a sonar, radar, or laser range finder. In particular, embodiments of the invention use a priori knowledge of a model signal return expected from a particular object to identify the location of the object relative to the sensor (and/or vice versa). In some embodiments the object is augmented with reflectors that return the sensor signal back towards the sensor so that the object can be more easily detected by the sensor. In preferred embodiments the reflectors are arranged in an a priori known pattern on the object, to help identify both the location and the orientation of the object with respect to the sensor. In the preferred embodiment, the sensor is a sonar, mounted on an unmanned underwater vehicle (UUV).
<img id="iaf01" file="imgaf001.tif" wi="159" he="99" img-content="drawing" img-format="tif"/></p></abstract><abstract mxw-id="PA128737840" lang="EN" source="EPO" load-source="docdb"><p>The present invention applies model-based processing to a sensor output from a sensor such as a sonar, radar, or laser range finder. In particular, embodiments of the invention use a priori knowledge of a model signal return expected from a particular object to identify the location of the object relative to the sensor (and/or vice versa). In some embodiments the object is augmented with reflectors that return the sensor signal back towards the sensor so that the object can be more easily detected by the sensor. In preferred embodiments the reflectors are arranged in an a priori known pattern on the object, to help identify both the location and the orientation of the object with respect to the sensor. In the preferred embodiment, the sensor is a sonar, mounted on an unmanned underwater vehicle (UUV).</p></abstract><description mxw-id="PDES63959669" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><heading id="h0001"><u>Technical Field</u></heading><p id="p0001" num="0001">The present invention relates to a method and system for determining the location of a sensor, and in particular in some embodiments to the relative location of a sensor mounted on a vehicle or other moving body with respect to another object. In preferred embodiments of the invention the sensor is of a type that emits a signal and detects objects in dependence on reflections of the emitted signal from the objects, by comparing the reflections against an <i>a priori</i> model of the object available to the sensor.</p><heading id="h0002"><u>Background to the Invention and Prior Art</u></heading><p id="p0002" num="0002">Image processing for computer vision is an established field. One technique that is known in the field of computer vision is that of model-based processing to identify objects within images. Generally, an a priori model having a number of image parameters representing an object to be detected within an image is first defined, and the model is then applied using various matching or best fit techniques to find corresponding objects in images matching the model. One early application of model based image processing is described by <nplcit id="ncit0001" npl-type="s"><text>Tillet, R.D. Computers and Electronics in Agriculture, Volume 6, Issue 1, July 1991, Pages 51-61</text></nplcit>, which reports on the development of a model-based technique to locate pigs in fairly unstructured scenes. According to Tillet, model-based image processing is potentially a very powerful technique for identifying and classifying images and is particularly relevant for biological objects such as animals, which are difficult to define in numerical terms. Within Tillet's paper the model is based on an image of a typical pig, viewed from above. The model can then be rotated, translated, scaled and bent laterally to find a good match within an image of another pig. The output of the model helps to segment and classify the pig, and the information can be used to guide further localized image processing.</p><p id="p0003" num="0003">Whilst therefore known for image based computer vision, model-based processing has so far not been applied to other sensor modalities, and particularly active sensors that rely on returns of a transmitted signal.<!-- EPO <DP n="2"> --></p><heading id="h0003"><u>Summary of the Invention</u></heading><p id="p0004" num="0004">The present invention addresses the above by applying model-based processing to a sensor output from a sensor such as a Sonar, radar, or laser range finder. In particular, embodiments of the invention use a priori knowledge of a model signal return expected from a particular object to identify the location of the object relative to the sensor (and/or vice versa). In some embodiments the object is augmented with reflectors that return the sensor signal back towards the sensor so that the object can be more easily detected by the sensor. In some more preferred embodiments the reflectors are arranged in an a priori known pattern on the object, to help identify both the location and the orientation of the object with respect to the sensor. In the preferred embodiment, the sensor is a sonar, mounted on an unmanned underwater vehicle (UUV).</p><p id="p0005" num="0005">In view of the above, from one aspect the present invention provides a method of locating an object with respect to a sensor, the sensor being of a type that emits energy and detects reflections of the emitted energy in order to detect objects. The method comprises obtaining an a priori model of a configuration of the object, the configuration providing a set of expected sensor returns. Sensor data from a sensor scan is received, the sensor data comprising a plurality of candidate sensor returns that may represent the object to be located. Then, from the candidate sensor returns, a plurality of locations for the object are hypothesised in dependence on a subset of the candidate sensor returns and the a priori model. From the hypothesised plurality of locations, one or more of the hypothesised locations are determined to provide a best fit of the a priori model to the sensor data in dependence at least on the other candidate sensor returns than those in the subset that formed the one or more best fit hypothesised locations. In some embodiments, all of the candidate sensor returns are used in the determination.</p><p id="p0006" num="0006">In one embodiment the object is provided with energy reflectors arranged to reflect the energy of the sensor, the reflector positions being included in the configuration of the object in the a priori model, wherein the candidate sensor returns are candidate reflector location returns. That is to say, in order to locate the desired object, the energy retro-reflectors are positioned around the object in the known configuration and are able to provide a clear sensor return, capturing the energy of the sensor and directing at least a portion of the energy back in the direction of the sensor itself.<!-- EPO <DP n="3"> --></p><p id="p0007" num="0007">In one embodiment the received sensor data is filtered to remove therefrom candidate returns that do not meet one or more criteria. The one or more criteria may include one or more selected from the group comprising:
<ol><li>a) relative signal strength compared to the signal strength of other candidate returns in the sensor data;</li><li>b) absolute signal strength; and/or</li><li>c) relative spatial location with respect to other candidate returns and the expected pattern of sensor returns given the object configuration in the a priori model.</li></ol></p><p id="p0008" num="0008">Preferably, where filtering occurs, a candidate return is filtered from the group if its relative spatial location with respect to other candidate returns indicates that it could not form part of the object given the object configuration in the a priori model.</p><p id="p0009" num="0009">In one embodiment the hypothesising is systematic, and a location is hypothesised for each subset of <i>n</i> candidate sensor returns that possibly fits the a priori model, wherein <i>n</i> is preferably 3. Here, the determining step may also include calculating quality measures indicative of the fit of the hypothesised locations to the set of sensor data, and selecting a location as the best-fit in dependence on the quality measures.</p><p id="p0010" num="0010">In another embodiment the hypothesising is pseudo-random, in that a plurality of pseudo-random locations within the sensor search space are hypothesised as the object location. Here, the determining step includes calculating quality measures indicative of the fit of the pseudo-random locations to the set of sensor data, and re-sampling the plurality of pseudo-random locations in dependence on the quality measures. The quality measure calculations and the re-sampling iterate until convergence on a location or one or more other iteration termination conditions is reached. For example, a certain number of iterations may be permitted, or for a certain amount of time, or iteration may continue until the re-sampled locations are within a certain small distance of each other.</p><p id="p0011" num="0011">In one embodiment the quality measure for a location is a weight in azimuth and distance calculated in dependence on the position of the candidate sensor returns. Preferably, the location selected as the best-fit is the highest calculated weight, and the calculated weight may be such that it assumes Gaussian noise in both the azimuth and distance measurements.<!-- EPO <DP n="4"> --> In one preferred embodiment the sensor is a sonar. Other sensors that may be used include laser rangefinders and radars.</p><p id="p0012" num="0012">A further aspect provides a method of controlling a vehicle, comprising sensing the location of an object using the method of the first aspect above, and autonomously controlling the movement of the unmanned vehicle in dependence on the sensed location of the object. The vehicle may be an unmanned vehicle, a manned submersible or a remotely operated vehicle (ROV). The unmanned vehicle is, therefore, able to locate an object itself, and subsequently use this location information to position itself with respect to the sensed object.</p><p id="p0013" num="0013">In one embodiment, the unmanned vehicle may be an unmanned underwater vehicle (UUV), and the sensor is a sonar. Additionally, the object may be a docking site, and autonomously controlling the movement of the unmanned underwater vehicle (UUV) may comprise moving the unmanned underwater vehicle (UUV) in dependence on the sensed location of the docking site, and then docking the unmanned underwater vehicle (UUV) on the docking site. Therefore, the unmanned underwater vehicle (UUV) can use the method of the present invention to determine the position of the docking site associated with a vessel such as a ship, and consequently dock itself based on the sensed location of the docking site.</p><p id="p0014" num="0014">Alternatively, the unmanned vehicle may be an unmanned aerial vehicle (UAV), and the sensor is a radar or laser-rangefinder. Preferably, the object may be a landing site, and autonomously controlling the movement of the unmanned aerial vehicle (UAV) may comprise moving the unmanned aerial vehicle (UAV) in dependence on the sensed location of the landing site, and landing the unmanned aerial vehicle (UAV) on the landing site.</p><p id="p0015" num="0015">Another aspect of the invention provides a system for locating an object with respect to a sensor, the sensor being of a type that emits energy and detects reflections of the emitted energy in order to detect objects. The system may comprise at least one memory and at least one processor, the at least one memory being arranged to store: i) an a priori model of a configuration of the object, the configuration providing a set of expected sensor returns; and ii) received sensor data from a sensor scan, the sensor data comprising a plurality of candidate sensor returns that may represent the object to be located. The at least one processor, may then be arranged in use to: i) from the candidate sensor returns, hypothesise a<!-- EPO <DP n="5"> --> plurality of locations for the object in dependence, for a hypothesised location, on a subset of the candidate sensor returns and the a priori model; and ii) from the hypothesised plurality of locations, determine one or more of the hypothesised locations to provide a best fit of the a priori model to the sensor data in dependence at least on the other candidate sensor returns than those in the subset that formed the one or more best fit hypothesised locations.</p><p id="p0016" num="0016">A further aspect of the invention provides a vehicle comprising a sensor, a propulsion unit, a steering unit, and a system according to the above aspect.</p><p id="p0017" num="0017">Further features and advantages will be apparent from the appended claims.</p><heading id="h0004"><u>Brief Description of the Drawings</u></heading><p id="p0018" num="0018">Further features and advantages of the present invention will become apparent from the following description of an embodiment thereof, presented by way of example only, and by reference to the drawings, wherein like reference numerals refer to like parts, and wherein:
<ul><li><figref idrefs="f0001">Figure 1</figref> is a diagram illustrating an operating environment of an embodiment of the invention;</li><li><figref idrefs="f0002">Figure 2</figref> is a diagram illustrating an example object to be detected;</li><li><figref idrefs="f0003">Figure 3</figref> is a screenshot of an example sensor return in an embodiment of the invention;</li><li><figref idrefs="f0004">Figure 4</figref> is a block diagram of the component parts of an UUV in an embodiment of the invention;</li><li><figref idrefs="f0004">Figure 5</figref> is a block diagram of an example controller of the UUV;</li><li><figref idrefs="f0005">Figure 6</figref> is a flow diagram of an embodiment of the invention;</li><li><figref idrefs="f0006">Figure 7</figref> is a flow diagram of an embodiment of the invention;</li><li><figref idrefs="f0007">Figure 8</figref> is an example plot illustrating the determined location of an object according to a first method;</li><li><figref idrefs="f0008">Figures 9 and 10</figref> are example plots illustrating the determined location of an object according to a second method; and</li><li><figref idrefs="f0009">Figure 11</figref> is a graph showing how the location of an object may be determined in embodiments of the invention.</li></ul><!-- EPO <DP n="6"> --></p><heading id="h0005"><u>Description of the Embodiments</u></heading><p id="p0019" num="0019"><figref idrefs="f0001">Figure 1</figref> illustrates one typical operating environment of an embodiment of the invention. Here, an unmanned underwater vehicle (UUV) 10 is provided with an active sonar unit which emits sound energy and detects reflections thereof to detect objects in the water. The UUV in this case is associated with a vessel 12 such as a rig or ship, which provides a "parking cage" or "garage" 14 for the UUV to dock with, either for retrieval or replenishment. The parking cage 14 is provided with sonar retro-reflectors 16, and in this particular embodiment sonar reflectors known as SonarBells®, available from Subsea Asset Location Technology Ltd (SALT), of Portland, Dorset, United Kingdom. SonarBells® are spherical buoys of different sizes that act to reflect an incident sonar wave back in the direction it came from. The spherical nature of the buoy and the material from which it is made results in a characteristic double return that allows for easier location thereof in the sonar return.</p><p id="p0020" num="0020">As shown in <figref idrefs="f0002">Figure 2</figref>, the cage 14 has different size sonar buoys mounted at different locations thereon. Specifically, in this embodiment, six buoys 16 of three different sizes are used and distributed at the front, middle, and back of the cage 14 in such a manner that each location has two buoys, one each of different sizes. By distributing the buoys 16 in this way the return therefrom can be used later to try and estimate the orientation of the cage, as well as its position with respect to the sonar on the UUV. It should be appreciated, however, that any number of retro-reflectors, of any size and orientation, may be used provided that they are arranged in an a priori known configuration such that a set of expected sensor returns may be obtained.</p><p id="p0021" num="0021"><figref idrefs="f0003">Figure 3</figref> illustrates an example sonar return from sonar buoys such as the SonarBells®. In the sonar image six sonar buoys were detected, and can be seen clearly in the sonar data.</p><p id="p0022" num="0022"><figref idrefs="f0004">Figure 4</figref> is a block diagram showing an example high level architectural configuration of the UUV 10. The UUV 10 will typically be provided with one or more external actuators 102, such as robot arms, cameras, lights, or the like, to allow the UUV to perform the tasks for which it is designed. The UUV is also provided with an active sonar 104, such as a Tritech Super SeaKing DST sonar, which is a mechanical scanning sonar available from Tritech International, of Westhill, Aberdeenshire, United Kingdom. A controller 106 that controls the actions of the UUV is also provided, as is a power supply 108 such as a battery or the like,<!-- EPO <DP n="7"> --> and a propulsion and steering unit 1010 that propels and steers the UUV on command from the controller. For example, the UUV may be an inspection vehicle for inspecting oil pipelines, well heads, or other underwater installations.</p><p id="p0023" num="0023">The controller 106 is shown in more detail in <figref idrefs="f0004">Figure 5</figref>. Here it can be seen that the controller 106 comprises a central processing unit 52, provided with memory 54 and an input/output interface 56 to allow the controller to interface with and control the other components of the UUV. A computer readable storage medium 58 such as a hard disk drive, flash memory, or the like is also provided, upon which is stored several software programs which when run by the CPU 52 allow the CPU 52 to control the UUV 10. Specifically, a control program 582 is provided that contains instructions to allow the CPU to control the UUV in its assigned tasks, as well as to control the basic functioning of the UUV, such as propulsion and steering. The control program 582 may in reality be several different programs, and the further operation of such is beyond the scope of the present description. In addition to the control program, a sonar processing program 582 is also provided that acts to process sonar signals generated by the sonar 104 and provide sonar results to a location determination program 586, which then uses the sonar results to determine the location of the UUV with respect to the cage 14. The sonar processing program 582 may be specifically designed to detect the returns from known reflectors. For example, such software is available from SALT, referenced earlier, to aid in the detection of sonar bouys such as the SonarBells®. As such, the precise operation of the sonar processing program is also beyond the scope of the present description, although the output thereof is of interest as input to the location determination program 586. In this respect embodiments of the invention are particularly concerned with the operation of the location determination program 586.</p><p id="p0024" num="0024">The overall operation of the present embodiment is shown in <figref idrefs="f0005">Figure 6</figref>. Specifically, the sonar 104 on the UUV 10 undertakes a scan, and the results are processed by the sonar processing program 584 in a manner known in the art, as discussed above, to provide a 2D sonar map. The location determination program 586 then takes the 2D sonar map and processes the information therein using a priori model based processing to identify within the map the location (and, if close by, orientation) of an object such as the parking cage 14, the a priori sonar return model for which is known in advance by the program. Having identified the desired object in the sonar return, the relative location of the UUV with respect to the object<!-- EPO <DP n="8"> --> is found, and the UUV may, in some embodiments, then be controlled to move in dependence on the found location, for example to steer toward or to avoid the object.</p><p id="p0025" num="0025"><figref idrefs="f0005">Figure 6</figref> gives further details of the operation of the location determination program 586. In particular, at s. 6.2 the program obtains a priori knowledge of the model that it is to look for in the sonar return. In the present embodiment, the object to be looked for is the parking cage 14, which is augmented with the sonar buoy retro-reflectors, of different sizes at different locations on the cage. For example, the program loads data relating to the model of the cage fitted with the sonar buoys into the memory, so that it can then be used by the program.</p><p id="p0026" num="0026">At s. 6.4 the sonar 104 is then controlled to undertake a scan, and the returning sonar data is processed by the sonar processing program 504, and a 2D map of candidate sonar buoy (reflector) locations provided to the location determination program 586. The processing of the sonar data to provide the 2D map is beyond the scope of the present application, suffice to say that suitable software is commercially available to use with the SonarBells®, and available from SALT, identified previously. An example 2D sonar return map is shown in <figref idrefs="f0007">Figure 8</figref>.</p><p id="p0027" num="0027">Having obtained the 2D map, at s.6.6 a 2D filtering process is undertaken by the location determination program 586, to remove possible sonar buoy location returns. This filtering is performed firstly on the returns individually, by looking at strength of return, signal to noise ratio, and the relative signal strength to other detections. Some of the candidate buoy location returns will thus be removed from the 2D map, as having signal characteristics that are too low for proper consideration, either absolutely, or relatively.</p><p id="p0028" num="0028">Further 2D filtering is also performed based on the location of the candidate sonar buoy locations returns relative to each other. In this respect, recall that the location determination program is provided with the a priori model of the sonar buoy locations on the cage 14, and hence has knowledge of the general configuration of sonar buoy returns expected to be seen. Hence, candidate sonar buoy returns in the 2D sonar data that are geographic outliers in that they are not surrounded by a sufficient number of other candidate returns to possibly match the a priori model may also be removed from consideration.<!-- EPO <DP n="9"> --></p><p id="p0029" num="0029">After conducting 2D filtering, at s.6.8 various relative locations of the desired object with respect to the sonar are hypothesized. In embodiments of the invention there are two ways to do this, either systematically or in a pseudo random way. In both cases there are potentially many thousands of possible location results (although there will likely be more with the systematic approach, and the number of hypotheses is controllable with the pseudo random approach), and a best fit match is then undertaken for each hypothesized location to try and match the candidate sonar buoy locations in the 2D data to the a priori model. In this respect, a weighting function is used to find a weight in both azimuth and distance for each hypothesized position given the candidate sonar buoy locations. This will find a location with the highest weight, which is selected as the location of the desired object i.e. the parking cage 14 in this embodiment. Where a pseudo random approach is first undertaken, several iterations may be undertaken, with spawning of new positions around those positions with the highest weights, until a location solution converges within appropriate termination conditions.</p><p id="p0030" num="0030">In some embodiments of the invention, both the systematic and pseudo random approaches are performed in parallel. Further details of each will be described next with respect to <figref idrefs="f0006">Figure 7</figref>.</p><p id="p0031" num="0031"><figref idrefs="f0006">Figure 7</figref> gives further details of the operation of the location determination program, which is provided with the a priori model of the object to be located, in this example the cage 14 provided with the sonar buoys. At. S. 7.2 the sonar 104 undertakes a sensor scan, and the results are processed to provide candidate reflector locations, being the candidate locations of the sonar buoys 16 on the cage 14. This is provided as 2D candidate reflector location data, as shown in <figref idrefs="f0007">Figure 8</figref>, and described previously. At s. 7.4, the 2D processing is again performed, again as described previously with respect to <figref idrefs="f0005">Figure 6</figref>. In more detail, however, in one embodiment a configurable bound is set on the maximum number of detections (candidate reflector locations). The detections (candidate reflector locations) are sorted by signal strength and/or correlation coefficient. Only the best detections are selected for further processing. In the second step, each detection is considered and its 2D distance to every other detection is calculated. The distance is calculated by converting the azimuth and range to a Euclidean x, y coordinate and then applying Pythagoras' rule. For each detection a check is done as to whether there are sufficient other detections within range of that detection that<!-- EPO <DP n="10"> --> are consistent with the arrangement of reflectors. This 2D filtering reduces the search space considerably.</p><p id="p0032" num="0032">Two different processing threads are then started, one to systematically search the candidate locations to find the best match, and the other to use a pseudo random technique that is able to manage the search space so that the location determination can occur in the time within sonar pings (or within some other controllable time, in any event). In this respect, one problem with the systematic search is that there can be many thousands or even millions of possible location solutions that need to checked, to determine the best match. However, by using a particle filter approach seeded with pseudo random locations then the number of possible locations to be matched can be kept to a manageable size.</p><p id="p0033" num="0033">Steps.7.6 to 7.10 illustrate the systematic approach. Firstly, at s.7.6 relative location hypotheses based on <i>x</i>, typically 3, reflector locations in the sonar data are found. For each set of three candidate reflector locations, a relative location of the object to the sonar is found as follows.</p><p id="p0034" num="0034">Let there be 3 reflectors or transponders with position vectors <b>B<sub>0</sub>, B<sub>1</sub></b> and <b>B<sub>2</sub></b> and there be a SONAR device at position vector <b>S</b>. The distances to the reflectors or transponders, as measured by the SONAR device are denoted <i>d</i><sub>0</sub>, <i>d</i><sub>1</sub> and <i>d</i><sub>2</sub>. <maths id="math0001" num="(1.1)"><math display="block"><msub><mi>d</mi><mi>i</mi></msub><mo>=</mo><mfenced open="|" close="|" separators=""><msub><mi mathvariant="bold">B</mi><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold">S</mi></mfenced><mo>,</mo><mspace width="1em"/><mi>i</mi><mo>=</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>2</mn></math><img id="ib0001" file="imgb0001.tif" wi="140" he="14" img-content="math" img-format="tif"/></maths></p><p id="p0035" num="0035">Reset the origin to be at <b>B</b><sub>2</sub>. The SONAR position in this new coordinate system is denoted P and the bell locations R0, R1, R2. i.e. <maths id="math0002" num="(1.2)"><math display="block"><msub><mi mathvariant="bold">R</mi><mi>i</mi></msub><mo>≡</mo><msub><mi mathvariant="bold">B</mi><mi>i</mi></msub><mo>-</mo><msub><mi mathvariant="bold">B</mi><mn>2</mn></msub><mo>,</mo><mspace width="1em"/><mi>i</mi><mo>=</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>2</mn></math><img id="ib0002" file="imgb0002.tif" wi="135" he="9" img-content="math" img-format="tif"/></maths> <maths id="math0003" num="(1.3)"><math display="block"><mi mathvariant="bold">P</mi><mo>≡</mo><mi mathvariant="bold">S</mi><mo>-</mo><msub><mi mathvariant="bold">B</mi><mi mathvariant="bold">z</mi></msub></math><img id="ib0003" file="imgb0003.tif" wi="135" he="9" img-content="math" img-format="tif"/></maths></p><p id="p0036" num="0036"><figref idrefs="f0009">Figure 11</figref> shows the arrangement with the origin reset, so: <maths id="math0004" num="(1.4)"><math display="block"><msub><mi>d</mi><mi>i</mi></msub><mo>=</mo><mfenced open="|" close="|" separators=""><msub><mi mathvariant="bold">R</mi><mi mathvariant="bold-italic">i</mi></msub><mo>-</mo><mi mathvariant="bold">P</mi></mfenced><mo>,</mo><mspace width="1em"/><mi>i</mi><mo>=</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>2</mn></math><img id="ib0004" file="imgb0004.tif" wi="141" he="12" img-content="math" img-format="tif"/></maths></p><p id="p0037" num="0037">This can be written without loss of generality as: <maths id="math0005" num="(1.5)"><math display="block"><msub><mi>d</mi><mi>i</mi></msub><mo>=</mo><mfenced open="|" close="|" separators=""><msub><mi mathvariant="bold">R</mi><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold">P</mi></mfenced><mo>,</mo><mspace width="1em"/><mi>i</mi><mo>=</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>2</mn></math><img id="ib0005" file="imgb0005.tif" wi="12" he="3" img-content="math" img-format="tif"/></maths> <maths id="math0006" num="(1.5)"><math display="block"><mi mathvariant="bold-italic">P</mi><mo>=</mo><msub><mi mathvariant="bold-italic">c</mi><mn>0</mn></msub><mo>⁢</mo><msub><mi mathvariant="bold-italic">R</mi><mn>0</mn></msub><mo>+</mo><msub><mi mathvariant="bold-italic">c</mi><mn>1</mn></msub><mo>⁢</mo><msub><mi mathvariant="bold-italic">R</mi><mn>1</mn></msub><mo>=</mo><msub><mi mathvariant="bold-italic">c</mi><mn>2</mn></msub><mo>⁢</mo><mi mathvariant="bold-italic">Q</mi></math><img id="ib0006" file="imgb0006.tif" wi="136" he="10" img-content="math" img-format="tif"/></maths> <maths id="math0007" num="(1.6)"><math display="block"><mi mathvariant="bold-italic">Q</mi><mo>=</mo><msub><mi mathvariant="bold-italic">R</mi><mn>0</mn></msub><mo>×</mo><msub><mi mathvariant="bold-italic">R</mi><mn>1</mn></msub></math><img id="ib0007" file="imgb0007.tif" wi="136" he="13" img-content="math" img-format="tif"/></maths><!-- EPO <DP n="11"> --></p><p id="p0038" num="0038">To solve, the coefficients {<i>c<sub>i</sub></i>} need to be found. Manipulation of 1.4 and 1.5 gives <maths id="math0008" num="(1.7)"><math display="block"><mi mathvariant="bold-italic">P</mi><mn mathvariant="bold-italic">.</mn><msub><mi mathvariant="bold-italic">R</mi><mn mathvariant="bold">0</mn></msub><mo>=</mo><msub><mi mathvariant="bold-italic">c</mi><mn mathvariant="bold">0</mn></msub><mo>⁢</mo><msup><msub><mi mathvariant="bold-italic">R</mi><mi>o</mi></msub><mn mathvariant="bold">2</mn></msup><mo>+</mo><msub><mi mathvariant="bold-italic">c</mi><mn mathvariant="bold">1</mn></msub><mo>⁢</mo><msub><mi mathvariant="bold-italic">R</mi><mn mathvariant="bold">0</mn></msub><mn mathvariant="bold-italic">.</mn><msub><mi mathvariant="bold-italic">R</mi><mn mathvariant="bold">1</mn></msub><mo>=</mo><mmultiscripts><msub><mo>/</mo><mn>2</mn></msub><mprescripts/><none/><mfenced separators=""><msup><msub><mi>d</mi><mn mathvariant="bold">2</mn></msub><mn mathvariant="bold">2</mn></msup><mo>+</mo><msup><msub><mi mathvariant="bold-italic">R</mi><mn mathvariant="bold">0</mn></msub><mn mathvariant="bold">2</mn></msup><mo>-</mo><msup><msub><mi>d</mi><mn mathvariant="bold">0</mn></msub><mn mathvariant="bold">2</mn></msup></mfenced></mmultiscripts></math><img id="ib0008" file="imgb0008.tif" wi="135" he="12" img-content="math" img-format="tif"/></maths> <maths id="math0009" num="(1.8)"><math display="block"><mi mathvariant="bold-italic">P</mi><mn mathvariant="bold-italic">.</mn><msub><mi mathvariant="bold-italic">R</mi><mn>1</mn></msub><mo>=</mo><msub><mi mathvariant="bold-italic">c</mi><mn>0</mn></msub><mo>⁢</mo><msub><mi mathvariant="bold-italic">R</mi><mn>0</mn></msub><mn>.</mn><msub><mi mathvariant="bold-italic">R</mi><mn>1</mn></msub><mo>+</mo><msub><mi mathvariant="bold-italic">c</mi><mn>1</mn></msub><mn mathvariant="bold-italic">.</mn><msup><msub><mi mathvariant="bold-italic">R</mi><mn>1</mn></msub><mn>2</mn></msup><mo>=</mo><mmultiscripts><msub><mo>/</mo><mn mathvariant="bold">2</mn></msub><mprescripts/><none/><mfenced separators=""><msup><msub><mi mathvariant="bold-italic">d</mi><mn mathvariant="bold">2</mn></msub><mn mathvariant="bold">2</mn></msup><mo>+</mo><msup><msub><mi mathvariant="bold-italic">R</mi><mn>1</mn></msub><mn mathvariant="bold">2</mn></msup><mo>-</mo><msup><msub><mi mathvariant="bold-italic">d</mi><mn>1</mn></msub><mn mathvariant="bold">2</mn></msup></mfenced></mmultiscripts></math><img id="ib0009" file="imgb0009.tif" wi="135" he="14" img-content="math" img-format="tif"/></maths></p><p id="p0039" num="0039">These can be written as simultaneous linear equations to be solved for {c<sub>0</sub>,c<sub>1</sub>}: <maths id="math0010" num="(1.9)"><math display="block"><mfenced open="[" close="]"><mtable><mtr><mtd><msup><msub><mi mathvariant="bold">R</mi><mn mathvariant="bold">0</mn></msub><mn mathvariant="bold">2</mn></msup></mtd><mtd><msub><mi mathvariant="bold">R</mi><mn mathvariant="bold">0</mn></msub><mn mathvariant="bold">.</mn><msub><mi mathvariant="bold">R</mi><mn mathvariant="bold">1</mn></msub></mtd></mtr><mtr><mtd><msub><mi mathvariant="bold">R</mi><mn mathvariant="bold">0</mn></msub><mn mathvariant="bold">.</mn><msub><mi mathvariant="bold">R</mi><mn mathvariant="bold">1</mn></msub></mtd><mtd><msup><msub><mi mathvariant="bold">R</mi><mn mathvariant="bold">1</mn></msub><mn mathvariant="bold">2</mn></msup></mtd></mtr></mtable></mfenced><mo>⁢</mo><mfenced open="[" close="]"><mtable><mtr><mtd><msub><mi mathvariant="bold-italic">C</mi><mn mathvariant="bold">0</mn></msub></mtd></mtr><mtr><mtd><msub><mi mathvariant="bold-italic">C</mi><mn mathvariant="normal">1</mn></msub></mtd></mtr></mtable></mfenced><mo>=</mo><mfenced open="[" close="]"><mtable><mtr><mtd><mmultiscripts><msub><mo>/</mo><mn mathvariant="bold">2</mn></msub><mprescripts/><none/><mfenced separators=""><msup><msub><mi mathvariant="bold">d</mi><mn mathvariant="bold">2</mn></msub><mn mathvariant="bold">2</mn></msup><mo>+</mo><msup><msub><mi mathvariant="bold">R</mi><mn mathvariant="bold">0</mn></msub><mn mathvariant="bold">2</mn></msup><mo>-</mo><msup><msub><mi mathvariant="bold">d</mi><mn mathvariant="bold">0</mn></msub><mn mathvariant="bold">2</mn></msup></mfenced></mmultiscripts></mtd></mtr><mtr><mtd><mmultiscripts><msub><mo>/</mo><mn mathvariant="bold">2</mn></msub><mprescripts/><none/><mfenced separators=""><msup><msub><mi mathvariant="bold">d</mi><mn mathvariant="bold">2</mn></msub><mn mathvariant="bold">2</mn></msup><mo>+</mo><msup><msub><mi mathvariant="bold">R</mi><mn mathvariant="bold">1</mn></msub><mn mathvariant="bold">2</mn></msup><mo>-</mo><msup><msub><mi mathvariant="bold">d</mi><mn mathvariant="bold">1</mn></msub><mn mathvariant="bold">2</mn></msup></mfenced></mmultiscripts></mtd></mtr></mtable></mfenced></math><img id="ib0010" file="imgb0010.tif" wi="141" he="21" img-content="math" img-format="tif"/></maths> algebraically <maths id="math0011" num="(1.10)"><math display="block"><mi mathvariant="bold">Mc</mi><mo>=</mo><mi mathvariant="bold">v</mi></math><img id="ib0011" file="imgb0011.tif" wi="137" he="18" img-content="math" img-format="tif"/></maths></p><p id="p0040" num="0040">To find c<sub>2</sub> use: <maths id="math0012" num="(1.11)"><math display="block"><msup><mi mathvariant="bold">P</mi><mn mathvariant="bold">2</mn></msup><mo>=</mo><msup><msub><mi mathvariant="bold">d</mi><mn mathvariant="bold">2</mn></msub><mn mathvariant="bold">2</mn></msup><mo>=</mo><mi mathvariant="bold">c</mi><mn mathvariant="bold">.</mn><mi mathvariant="bold">v</mi><mo>+</mo><msup><msub><mi mathvariant="bold">c</mi><mn mathvariant="bold">2</mn></msub><mn mathvariant="bold">2</mn></msup><mo>⁢</mo><msup><mi mathvariant="bold">Q</mi><mn mathvariant="bold">2</mn></msup></math><img id="ib0012" file="imgb0012.tif" wi="136" he="12" img-content="math" img-format="tif"/></maths></p><p id="p0041" num="0041">There are two solutions for c<sub>2</sub>, one the negative of the other. Substitute back to get <b>P</b>, then reset origin by adding <b>B</b><sub>2</sub> to get <b>S</b>.</p><p id="p0042" num="0042">These 2 candidate positions can be resolved to a single position by either considering the azimuth angles or by looking at the position of other reflectors or transponders, if there are more than 3. There are a number of ways this can be done. The techniques described take both into account.</p><p id="p0043" num="0043">If there are only 3 bells, but these can be unambiguously identified, then azimuth alone can resolve the ambiguity. The technique is as follows:</p><p id="p0044" num="0044">Call the candidate solutions <b>S</b><sub>0</sub> and <b>S</b><sub>1</sub>. Then the best solution <b>S</b><sub><i>i</i>best</sub> is obtained by: <maths id="math0013" num="(1.12)"><math display="block"><msub><mi mathvariant="bold">N</mi><mrow><mi mathvariant="bold">i</mi><mo>,</mo><mi mathvariant="bold">k</mi></mrow></msub><mo>=</mo><mmultiscripts><msub><mo>/</mo><mfenced open="|" close="|" separators=""><msub><mi mathvariant="bold">B</mi><mi mathvariant="bold">k</mi></msub><mo>-</mo><msub><mi mathvariant="bold">S</mi><mi mathvariant="italic">i</mi></msub></mfenced></msub><mprescripts/><none/><mrow><msub><mi mathvariant="bold">B</mi><mi mathvariant="bold">k</mi></msub><mo>-</mo><msub><mi mathvariant="bold">S</mi><mi mathvariant="bold-italic">i</mi></msub></mrow></mmultiscripts><mo>,</mo><mspace width="1em"/><mi>k</mi><mo>=</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mspace width="1em"/><mi>i</mi><mo>=</mo><mn>0</mn><mo>,</mo><mn>1</mn></math><img id="ib0013" file="imgb0013.tif" wi="142" he="15" img-content="math" img-format="tif"/></maths> <maths id="math0014" num="(1.13)"><math display="block"><msub><mi>i</mi><mi mathvariant="bold">best</mi></msub><mo>=</mo><munder><mi mathvariant="bold">argmin</mi><mrow><mi mathvariant="bold">i</mi><mo>⁢</mo><mfenced><mstyle displaystyle="false"><mstyle displaystyle="false"><munder><mo>∑</mo><mi mathvariant="bold">k</mi></munder></mstyle><mfenced separators=""><msub><mi mathvariant="bold">θ</mi><mi mathvariant="bold">k</mi></msub><mo>-</mo><msub><mi mathvariant="bold">θ</mi><mn mathvariant="bold">2</mn></msub><mo>-</mo><mfenced separators=""><msub><mi mathvariant="bold">N</mi><mrow><mi mathvariant="bold-italic">i</mi><mo>,</mo><mn mathvariant="bold">2</mn></mrow></msub><mo>×</mo><msub><mi mathvariant="bold">N</mi><mrow><mi mathvariant="bold">E</mi><mo>,</mo><mi mathvariant="bold">k</mi></mrow></msub></mfenced><mn mathvariant="bold">.</mn><mover><mi mathvariant="bold">z</mi><mo>^</mo></mover></mfenced></mstyle></mfenced></mrow></munder></math><img id="ib0014" file="imgb0014.tif" wi="141" he="18" img-content="math" img-format="tif"/></maths><br/>
where {θ<sub>k</sub>} are the azimuth angles corresponding to the measurements {<i>d</i><sub>k</sub>}. The azimuth is the angle around the local z axis of the SONAR according to the right hand rule.<!-- EPO <DP n="12"> --></p><p id="p0045" num="0045">Having found hypothesized locations for each set of three candidate reflector locations in the sonar data, at s. 7.8 a best fit quality measure is then found for each hypothesis, given the other candidate reflector locations. This quality measure is found as follows.</p><p id="p0046" num="0046">The weight of the <i>i</i><sup>th</sup> position, <i>w<sub>i</sub></i>, used assumes Gaussian noise in both the azimuth and distance measurements. The weight due to azimuth is thus: <maths id="math0015" num="(1.14)"><math display="block"><msubsup><mi>w</mi><mi>i</mi><mi>θ</mi></msubsup><mo>=</mo><mstyle displaystyle="true"><munder><mo>∏</mo><mi mathvariant="bold">k</mi></munder></mstyle><mfrac><mn>1</mn><mrow><mn>2</mn><mo>⁢</mo><mi mathvariant="bold">π</mi><mo>⁢</mo><msup><msub><mi mathvariant="bold">σ</mi><mi>θ</mi></msub><mn>2</mn></msup></mrow></mfrac><mo>⁢</mo><mi mathvariant="bold">exp</mi><mfenced separators=""><mo>-</mo><mfrac><msup><msub><mi mathvariant="bold">Δθ</mi><mi mathvariant="bold">ki</mi></msub><mn mathvariant="bold">2</mn></msup><mrow><mn mathvariant="bold">2</mn><mo>⁢</mo><msup><msub><mi mathvariant="bold">σ</mi><mi>θ</mi></msub><mn>2</mn></msup></mrow></mfrac></mfenced></math><img id="ib0015" file="imgb0015.tif" wi="140" he="19" img-content="math" img-format="tif"/></maths><br/>
where <maths id="math0016" num="(1.15)"><math display="block"><mi mathvariant="normal">Δ</mi><mo>⁢</mo><msub><mi>θ</mi><mi>ki</mi></msub><mo>=</mo><mi>atan</mi><mo>⁢</mo><mn mathvariant="normal">2</mn><mo>⁢</mo><mfenced separators=""><mi>sin</mi><mfenced separators=""><msub><mi mathvariant="normal">θ</mi><mi mathvariant="normal">k</mi></msub><mo>-</mo><msubsup><mi mathvariant="normal">S</mi><mi>ki</mi><mi mathvariant="normal">θ</mi></msubsup></mfenced><mn mathvariant="normal">.</mn><mi>cos</mi><mfenced separators=""><msub><mi mathvariant="normal">θ</mi><mi mathvariant="normal">k</mi></msub><mo>-</mo><msubsup><mi mathvariant="normal">S</mi><mi>ki</mi><mi mathvariant="normal">θ</mi></msubsup></mfenced></mfenced></math><img id="ib0016" file="imgb0016.tif" wi="137" he="10" img-content="math" img-format="tif"/></maths> and <maths id="math0017" num="(1.16)"><math display="block"><msubsup><mi mathvariant="normal">S</mi><mi>ki</mi><mi mathvariant="normal">θ</mi></msubsup><mo>=</mo><mi>atan</mi><mo>⁢</mo><mn mathvariant="normal">2</mn><mo>⁢</mo><mfenced separators=""><msub><mi mathvariant="normal">S</mi><mi mathvariant="normal">i</mi></msub><mn mathvariant="normal">.</mn><mover><mi mathvariant="normal">x</mi><mo>^</mo></mover><mo>-</mo><msub><mi mathvariant="normal">B</mi><mi mathvariant="normal">k</mi></msub><mn mathvariant="normal">.</mn><mover><mi mathvariant="normal">x</mi><mo>^</mo></mover><mo>,</mo><msub><mi mathvariant="normal">B</mi><mi mathvariant="normal">k</mi></msub><mn mathvariant="normal">.</mn><mover><mi mathvariant="normal">y</mi><mo>^</mo></mover><mo>-</mo><msub><mi mathvariant="normal">S</mi><mi mathvariant="normal">i</mi></msub><mn mathvariant="normal">.</mn><mover><mi mathvariant="normal">y</mi><mo>^</mo></mover></mfenced><mo>-</mo><msub><mi mathvariant="normal">θ</mi><mi mathvariant="normal">k</mi></msub></math><img id="ib0017" file="imgb0017.tif" wi="141" he="8" img-content="math" img-format="tif"/></maths><br/>
where k = 0..K where K is the number of bells in the system. Σ<sub>θ</sub> is the uncertainty in the azimuth measurement. <maths id="math0018" num=""><math display="inline"><msubsup><mi mathvariant="normal">s</mi><mi>ki</mi><mi mathvariant="normal">θ</mi></msubsup></math><img id="ib0018" file="imgb0018.tif" wi="8" he="10" img-content="math" img-format="tif" inline="yes"/></maths> is constrained such that <maths id="math0019" num=""><math display="inline"><mo>-</mo><mi mathvariant="normal">π</mi><mo>&lt;</mo><msubsup><mi mathvariant="normal">s</mi><mi>ki</mi><mi mathvariant="normal">θ</mi></msubsup><mo>≤</mo><mi mathvariant="normal">π</mi></math><img id="ib0019" file="imgb0019.tif" wi="19" he="8" img-content="math" img-format="tif" inline="yes"/></maths> by adding or subtracting multiples of 2π.</p><p id="p0047" num="0047">And the weight due to distance is thus: <maths id="math0020" num="(1.17)"><math display="block"><msubsup><mi>w</mi><mi>i</mi><mi>d</mi></msubsup><mo>=</mo><mstyle displaystyle="true"><munder><mo>∏</mo><mi mathvariant="bold">k</mi></munder></mstyle><mfrac><mn>1</mn><msqrt><mn>2</mn><mo>⁢</mo><msup><msub><mi mathvariant="normal">πσ</mi><mi>d</mi></msub><mn>2</mn></msup></msqrt></mfrac><mo>⁢</mo><mi mathvariant="bold">exp</mi><mfenced separators=""><mo>-</mo><mfrac><mfenced separators=""><mfenced open="|" close="|" separators=""><msub><mi mathvariant="bold">B</mi><mi mathvariant="bold-italic">k</mi></msub><mo>-</mo><msub><mi mathvariant="bold">S</mi><mi mathvariant="bold">i</mi></msub></mfenced><mo>-</mo><msub><mi>d</mi><mi mathvariant="bold">k</mi></msub></mfenced><mrow><mn>2</mn><mo>⁢</mo><msup><msub><mi mathvariant="normal">σ</mi><mi>d</mi></msub><mn>2</mn></msup></mrow></mfrac></mfenced></math><img id="ib0020" file="imgb0020.tif" wi="135" he="21" img-content="math" img-format="tif"/></maths><br/>
<i>d<sub>k</sub></i> is the measured distance to the <i>k</i><sup>th</sup> reflector. Σ<i><sub>d</sub></i> is the uncertainty in the distance measurement.</p><p id="p0048" num="0048">The weights are then combined. The log of these weights are usually used in the calculation as it is a faster calculation and is more accurate when the weight values get very small. The normalisation factors in the Gaussians are the same for all measurements, so are ignored. The combined log weight <i>W<sub>i</sub></i> is thus: <maths id="math0021" num="(1.18)"><math display="block"><msub><mi>W</mi><mi>i</mi></msub><mo>=</mo><mstyle displaystyle="false"><mstyle displaystyle="true"><munder><mo>∑</mo><mi mathvariant="bold">k</mi></munder></mstyle><mfenced separators=""><mfrac><mfenced separators=""><mfenced open="|" close="|" separators=""><msub><mi mathvariant="bold">B</mi><mi mathvariant="bold">K</mi></msub><mo>-</mo><msub><mi mathvariant="bold">S</mi><mi mathvariant="bold">i</mi></msub></mfenced><mo>-</mo><msub><mi>d</mi><mi mathvariant="normal">k</mi></msub></mfenced><mrow><mn>2</mn><mo>⁢</mo><msubsup><mi>σ</mi><mi>d</mi><mn>2</mn></msubsup></mrow></mfrac><mo>-</mo><mfrac><mrow><mi mathvariant="normal">Δ</mi><mo>⁢</mo><msubsup><mi>θ</mi><mi mathvariant="bold">ki</mi><mn>2</mn></msubsup></mrow><mrow><mn>2</mn><mo>⁢</mo><msubsup><mi>σ</mi><mi>θ</mi><mn>2</mn></msubsup></mrow></mfrac></mfenced></mstyle></math><img id="ib0021" file="imgb0021.tif" wi="136" he="19" img-content="math" img-format="tif"/></maths></p><p id="p0049" num="0049">The best hypothesis <i>i</i><sub>best</sub> is thus: <maths id="math0022" num="(1.19)"><math display="block"><msub><mi>i</mi><mi>best</mi></msub><mo>=</mo><munder><mi>argmax</mi><mrow><mi mathvariant="normal">i</mi><mfenced><msub><mi>W</mi><mi>i</mi></msub></mfenced></mrow></munder></math><img id="ib0022" file="imgb0022.tif" wi="136" he="13" img-content="math" img-format="tif"/></maths></p><p id="p0050" num="0050">The location that has the highest weight is thus selected, at s.7.10.<!-- EPO <DP n="13"> --></p><p id="p0051" num="0051">One problem with the systematic approach noted above is that there may be too many hypothesised locations to check within a reasonable amount of time, especially if the location is being used for real-time navigation of an autonomous vehicle. To get around this, therefore, another way to reduce the search space is to fix the number of solutions to be considered. To do this in the present embodiment an iterative technique is used based on a Particle Filter. The iterative approach replaces the linear algebra described in equations 1.1 to 1.11 above, however the weight calculation remains the same. The particle filter approach is as follows:
<ol><li>1. Generate a large number of candidate solutions (s. 7.12). In the experiments performed, this was done by pseudo randomly generating 2000 solutions in a shell around the SONAR. The average radius of the shell is the average detection distance, and the thickness is a multiple of the standard deviation of all detection distances. Another approach would be to seed the algorithm with the results of the linear algebra approach of equations 1.1 to 1.11 above, with random noise added. In that case the Particle filter approach is then used in subsequent calculation of positions as the sonar moves.</li><li>2. Apply 2D filtering, as above, to the detections (optional). In this Particle Filter approach, 2D filtering has the additional benefit of reducing the number of false local minima that can be accidentally found using the iterative approach.</li><li>3. At s.7.14 each candidate solution is then given a weight according to equation 1.18.<br/>
The approximate result from the current iteration is then the highest weighted solution. The uncertainty in the candidate solution can be calculated by considering the distribution and weights of the other solutions.</li><li>4. At s.7.16, use the weights generated in step 7.14 to generate a new set of candidate solutions (described in detail below). Measure a new set of detections (if available) then continue from point 2 above.</li><li>5. The algorithm proceeds either continuously, if the sonar is to be tracked over time, or stops after a fixed number of iterations is reached, or when the uncertainty is below a certain value (s.7.18 and s.7.20)</li></ol></p><p id="p0052" num="0052">In order to generate the new set of candidate solutions, i.e. point 4 above (s.7.16), first calculate a normalisation constant, η.<!-- EPO <DP n="14"> --> <maths id="math0023" num="(1.20)"><math display="block"><mi>η</mi><mo>=</mo><mstyle displaystyle="false"><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder></mstyle><mi>exp</mi><mfenced><msub><mi>W</mi><mi>i</mi></msub></mfenced></mstyle></math><img id="ib0023" file="imgb0023.tif" wi="137" he="15" img-content="math" img-format="tif"/></maths></p><p id="p0053" num="0053">Resample by selecting solutions at random a large number of times (2000 in the experiments performed), with replacement, such that each solution has a probability P<sub>i</sub> of being selected, given by: <maths id="math0024" num="(1.21)"><math display="block"><msub><mi>P</mi><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mi>exp</mi><mfenced><msub><mi>W</mi><mi>i</mi></msub></mfenced></mrow><mi>η</mi></mfrac></math><img id="ib0024" file="imgb0024.tif" wi="137" he="12" img-content="math" img-format="tif"/></maths></p><p id="p0054" num="0054">For each solution, then apply a motion model. For the experiments performed so far, the SONAR was approximately stationary, so the motion model consists of applying Gaussian noise to the position and azimuth of the solution. If the sonar is moving, then a linear and angular velocity component may also be added at this stage.</p><p id="p0055" num="0055"><figref idrefs="f0008">Figures 9 and 10</figref> illustrate the operation of the pseudo random particle filter approach. In particular, <figref idrefs="f0008">Figure 9</figref> shows that pseudo random positions may be initially selected all around the sonar search space, whilst <figref idrefs="f0008">Figure 10</figref> illustrates that the positions rapidly converge to the correct location.</p><p id="p0056" num="0056">With the above, therefore, the location of a sensor such as a sonar may be found with respect to a desired object, the a priori model of which is known to the sensor in advance so that the sensor may detect the object in its returned sensor data. The location may be found in two ways, either systematically, or using a pseudo random particle filter, but in both cases a quality measure is found for hypothesised locations based on candidate sensor returns in the sensor data matching the a priori model. In one preferred embodiment the sensor is a sonar, and the desired object is fitted with sonar reflectors in a known configuration, which are then used to match to the model.</p><p id="p0057" num="0057">In other embodiments, different sensors may be used, and in particular a radar, or laser rangefinder. In both cases the object to be located may be fitted with appropriate reflectors to reflect the incident sensor energy back to the sensor. The reflectors are preferably in a known configuration and incorporated into the model stored at the sensor, to help with identification of both location and orientation.</p><p id="p0058" num="0058">However, it is not necessary for both location and orientation of the object to be resolvable straight away, as orientation may be resolved once the vehicle is closer to the object.<!-- EPO <DP n="15"> --> Likewise, larger objects will be located more accurately from further away. For example, an oil rig will be detected and accurately located from further away than the parking cage of the embodiment.</p><p id="p0059" num="0059">Embodiments of the invention may find a number of uses, such as for navigation of vehicles, recovery of vehicles, as a safety back-up to a human operator, or for the control of the sensor emission itself. For example, if a sensor is being used to track an object and the location of the object with respect to the sensor is known from embodiments of the invention, the scan of the sensor can be restricted to the general location of the object. This has the effect of reducing the number of candidate locations, and hence lightens the processing load.</p><p id="p0060" num="0060">In further embodiments the model itself may be augmented, for example with navigational features, such as positions of hazards which are not detectable by the sensor. For example, where the sensor is a sonar, the model may be augmented with the location of navigation hazards to the UUV such as nets, mooring cables, or the like, so that the UUV knows not to approach the hazards.</p><p id="p0061" num="0061">In addition, the model could be augmented with user interface features, that cause the a particular display on an operator screen when the model determines that a particular location has been reached. For example, for docking operations of a UUV, or landing operations for a UAV, an operator display may be augmented with guidance markings to indicate approach directions to the docking/landing area.</p><p id="p0062" num="0062">In the above described embodiments a best fit of the model to the hypothesised locations is found by calculating a weight in distance and azimuth for each hypothesis. In other embodiments different techniques may be used to reduce the number of hypotheses. For example, given that the hypotheses are based on matching three candidate reflector locations in the sonar data, of the hypotheses those that match four candidate reflector locations may be found. Then, of those hypotheses that match four candidate locations, a check is made to see which will match five candidate reflector locations, and so on, until one or a small number of hypotheses are found that match the number of candidate reflector locations known to be on the object from the a priori model. Where more than one such location hypothesis is still live at this point, a quality measure such as the weight described previously may be used to decide between the candidate hypotheses.<!-- EPO <DP n="16"> --></p><p id="p0063" num="0063">In addition, in some embodiments of the invention the a priori model is augmented with information relating not simply to the location of reflectors on an object, but also to the expected type or size of reflection expected. For example, in the case of the SonarBells® which come in different sizes, different strength returns can be expected from the bouys of different sizes. By knowing the distribution of the sonar buoys of different sizes across an object in the a priori model, this distribution can then be looked for in the returned sonar data, as well as relative location, to help improve location matching and object orientation determination.</p><p id="p0064" num="0064">In further embodiments of the present invention, the retro-reflectors may be placed merely in the vicinity of the object to be detected. For example, in <figref idrefs="f0001">Figure 1</figref>, the sonar retro-reflectors 16 may be positioned on the rope 18 connecting the cage 14 to the vessel 12, and the a priori model is established based on this distribution of the buoys 16.</p><p id="p0065" num="0065">Various further modifications, whether by way of addition, deletion or substitution may be made to the above described embodiment to provide further embodiments, any and all of which are intended to be encompassed by the appended claims.</p></description><claims mxw-id="PCLM56982716" lang="EN" load-source="patent-office"><!-- EPO <DP n="17"> --><claim id="c-en-0001" num="0001"><claim-text>A system for locating an object with respect to a sensor, the sensor being of a type that emits energy and detects reflections of the emitted energy in order to detect objects, the system comprising:
<claim-text>at least one memory in which is stored:
<claim-text>i) an a priori model of a configuration of the object, the configuration providing a set of expected sensor returns; and</claim-text>
<claim-text>ii) received sensor data from a sensor scan, the sensor data comprising a<br/>
plurality of candidate sensor returns that may represent the object to be located;</claim-text></claim-text>
<claim-text>and at least one processor, arranged in use to:
<claim-text>i) from the candidate sensor returns, hypothesise a plurality of locations for the object in dependence, for a hypothesised location, on a subset of the candidate sensor returns and the a priori model; and</claim-text>
<claim-text>ii) from the hypothesised plurality of locations, determine one or more of the hypothesised locations to provide a best fit of the a priori model to the sensor data in dependence at least on the other candidate sensor returns than those in the subset that formed the one or more best fit hypothesised locations.</claim-text></claim-text></claim-text></claim><claim id="c-en-0002" num="0002"><claim-text>A system according to claim 1, wherein the object is provided with energy reflectors arranged to reflect the energy of the sensor, the reflector positions being included in the configuration of the object in the a priori model, wherein the candidate sensor returns are candidate reflector location returns.</claim-text></claim><claim id="c-en-0003" num="0003"><claim-text>A system according to claims 1 or 2, wherein the processor is further arranged to filter the received sensor data to remove therefrom candidate returns that do not meet one or more criteria.</claim-text></claim><claim id="c-en-0004" num="0004"><claim-text>A system according to claim 3, wherein the one or more criteria include one or more selected from the group comprising:
<claim-text>a) relative signal strength compared to the signal strength of other candidate returns in the sensor data;</claim-text>
<claim-text>b) absolute signal strength; and/or<!-- EPO <DP n="18"> --></claim-text>
<claim-text>c) relative spatial location with respect to other candidate returns and the expected pattern of sensor returns given the object configuration in the a priori model.</claim-text></claim-text></claim><claim id="c-en-0005" num="0005"><claim-text>A system according to claims 3 or 4, wherein a candidate return is filtered from the group if its relative spatial location with respect to other candidate returns indicates that it could not form part of the object given the object configuration in the a priori model.</claim-text></claim><claim id="c-en-0006" num="0006"><claim-text>A system according to any of claims 1 to 5, wherein the hypothesising is systematic, and a location is hypothesised for each subset of <i>n</i> candidate sensor returns that possibly fits the a priori model, wherein <i>n</i> is preferably 3;<br/>
wherein the determining includes calculating quality measures indicative of the fit of the hypothesised locations to the set of sensor data, and a location is selected as the best-fit in dependence on the quality measures.</claim-text></claim><claim id="c-en-0007" num="0007"><claim-text>A system according to any of claims 1 to 6, wherein the hypothesising is pseudo-random, in that a plurality of pseudo-random locations within the sensor search space are hypothesised as the object location; wherein the determining includes calculating quality measures indicative of the fit of the pseudo-random locations to the set of sensor data, and re-sampling the plurality of pseudo-random locations in dependence on the quality measures, the quality measure calculations and the re-sampling iterating until convergence on a location or one or more other iteration termination conditions is reached.</claim-text></claim><claim id="c-en-0008" num="0008"><claim-text>A system according to claims 6 or 7, wherein the quality measure for a location is a weight in azimuth and distance calculated in dependence on the position of the candidate sensor returns, wherein the location selected as the best-fit is the highest calculated weight, and wherein the calculated weight assumes Gaussian noise in both the azimuth and distance measurements.</claim-text></claim><claim id="c-en-0009" num="0009"><claim-text>A system according to any of claims 1 to 8, wherein the sensor is a sonar.</claim-text></claim><claim id="c-en-0010" num="0010"><claim-text>A vehicle, comprising:
<claim-text>a sensor;</claim-text>
<claim-text>a propulsion unit;</claim-text>
<claim-text>a steering unit; and<!-- EPO <DP n="19"> --></claim-text>
<claim-text>a system according to any of claims 1 to 8.</claim-text></claim-text></claim><claim id="c-en-0011" num="0011"><claim-text>A vehicle according to claim 10, wherein the vehicle is:
<claim-text>1) an unmanned underwater vehicle (UUV), and the sensor is a sonar; or</claim-text>
<claim-text>2) an unmanned aerial vehicle (UAV), and the sensor is a radar or laser-rangefinder; or</claim-text>
<claim-text>3) a manned submersible; or</claim-text>
<claim-text>4) a remotely operated vehicle (ROV).</claim-text></claim-text></claim><claim id="c-en-0012" num="0012"><claim-text>A method of locating an object with respect to a sensor, the sensor being of a type that emits energy and detects reflections of the emitted energy in order to detect objects, the method comprising:
<claim-text>obtaining an a priori model of a configuration of the object, the configuration providing a set of expected sensor returns;</claim-text>
<claim-text>receiving sensor data from a sensor scan, the sensor data comprising a plurality of candidate sensor returns that may represent the object to be located;</claim-text>
<claim-text>from the candidate sensor returns, hypothesising a plurality of locations for the object in dependence, for a hypothesised location, on a subset of the candidate sensor returns and the a priori model;</claim-text>
<claim-text>from the hypothesised plurality of locations, determining one or more of the hypothesised locations to provide a best fit of the a priori model to the sensor data in dependence at least on the other candidate sensor returns than those in the subset that formed the one or more best fit hypothesised locations.</claim-text></claim-text></claim><claim id="c-en-0013" num="0013"><claim-text>A method of controlling a vehicle, comprising sensing the location of an object using the method of claim 12, and autonomously controlling the movement of the vehicle in dependence on the sensed location of the object.</claim-text></claim><claim id="c-en-0014" num="0014"><claim-text>A method according to claim 13, wherein the object is a docking site, wherein the vehicle is an unmanned underwater vehicle (UUV), and wherein autonomously controlling the movement of the unmanned underwater vehicle (UUV) comprises:
<claim-text>a) moving the unmanned underwater vehicle (UUV) in dependence on the sensed location of the docking site; and</claim-text>
<claim-text>b) docking the unmanned underwater vehicle (UUV) on the docking site.</claim-text><!-- EPO <DP n="20"> --></claim-text></claim><claim id="c-en-0015" num="0015"><claim-text>A method according to claim 14, wherein the object is a landing site, wherein the vehicle is an unmanned aerial vehicle (UAV), and wherein autonomously controlling the movement of the unmanned aerial vehicle (UAV) comprises:
<claim-text>a) moving the unmanned aerial vehicle (UAV) in dependence on the sensed location of the landing site; and</claim-text>
<claim-text>b) landing the unmanned aerial vehicle (UAV) on the landing site.</claim-text></claim-text></claim></claims><drawings mxw-id="PDW16671056" load-source="patent-office"><!-- EPO <DP n="21"> --><figure id="f0001" num="1"><img id="if0001" file="imgf0001.tif" wi="150" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="22"> --><figure id="f0002" num="2"><img id="if0002" file="imgf0002.tif" wi="165" he="207" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="23"> --><figure id="f0003" num="3"><img id="if0003" file="imgf0003.tif" wi="165" he="206" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="24"> --><figure id="f0004" num="4,5"><img id="if0004" file="imgf0004.tif" wi="165" he="203" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="25"> --><figure id="f0005" num="6"><img id="if0005" file="imgf0005.tif" wi="132" he="199" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="26"> --><figure id="f0006" num="7"><img id="if0006" file="imgf0006.tif" wi="165" he="222" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="27"> --><figure id="f0007" num="8"><img id="if0007" file="imgf0007.tif" wi="165" he="174" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="28"> --><figure id="f0008" num="9,10"><img id="if0008" file="imgf0008.tif" wi="165" he="225" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="29"> --><figure id="f0009" num="11"><img id="if0009" file="imgf0009.tif" wi="155" he="191" img-content="drawing" img-format="tif"/></figure></drawings><search-report-data><doc-page id="srep0001" file="srep0001.tif" wi="153" he="233" type="tif"/><doc-page id="srep0002" file="srep0002.tif" wi="154" he="233" type="tif"/></search-report-data><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
