<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2681078-A1" country="EP" doc-number="2681078" kind="A1" date="20140108" family-id="45531447" file-reference-id="315080" date-produced="20180823" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="146586690" ucid="EP-2681078-A1"><document-id><country>EP</country><doc-number>2681078</doc-number><kind>A1</kind><date>20140108</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-11813360-A" is-representative="NO"><document-id mxw-id="PAPP154848882" load-source="docdb" format="epo"><country>EP</country><doc-number>11813360</doc-number><kind>A</kind><date>20111221</date><lang>EN</lang></document-id><document-id mxw-id="PAPP220440171" load-source="docdb" format="original"><country>EP</country><doc-number>11813360.2</doc-number><date>20111221</date><lang>EN</lang></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC140552372" ucid="IB-2011003099-W" linkage-type="W" load-source="docdb"><document-id format="epo"><country>IB</country><doc-number>2011003099</doc-number><kind>W</kind><date>20111221</date></document-id></priority-claim><priority-claim mxw-id="PPC140548921" ucid="JP-2010290842-A" load-source="docdb"><document-id format="epo"><country>JP</country><doc-number>2010290842</doc-number><kind>A</kind><date>20101227</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL1989316981" load-source="docdb">H04N   5/262       20060101ALI20120718BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1989317995" load-source="docdb">B60R   1/00        20060101AFI20120718BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1989323542" load-source="docdb">H04N   7/18        20060101ALI20120718BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL1989638401" load-source="docdb" scheme="CPC">B60R   1/00        20130101 LI20131018BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989641855" load-source="docdb" scheme="CPC">H04N   5/23293     20130101 LI20131018BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989642937" load-source="docdb" scheme="CPC">H04N   7/181       20130101 LI20131018BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989644998" load-source="docdb" scheme="CPC">H04N   7/18        20130101 FI20131010BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT132364703" lang="DE" load-source="patent-office">BILDBEREITSTELLUNGSVORRICHTUNG</invention-title><invention-title mxw-id="PT132364704" lang="EN" load-source="patent-office">IMAGE PROVIDING DEVICE</invention-title><invention-title mxw-id="PT132364705" lang="FR" load-source="patent-office">DISPOSITIF PRODUISANT DES IMAGES</invention-title><citations><non-patent-citations><nplcit><text>See references of WO 2012090045A1</text><sources><source mxw-id="PNPL67456096" load-source="docdb" name="SEA"/></sources></nplcit></non-patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR919540154" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>TOYOTA MOTOR CO LTD</last-name><address><country>JP</country></address></addressbook></applicant><applicant mxw-id="PPAR919529995" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>TOYOTA JIDOSHA KABUSHIKI KAISHA</last-name></addressbook></applicant><applicant mxw-id="PPAR919006249" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Toyota Jidosha Kabushiki Kaisha</last-name><iid>101030285</iid><address><street>1 Toyota-cho,</street><city>Toyota-shi, Aichi-ken 471-8571</city><country>JP</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR919506251" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>HIEI YU</last-name><address><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR919517477" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>HIEI, YU</last-name></addressbook></inventor><inventor mxw-id="PPAR919006735" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>HIEI, YU</last-name><address><street>c/o Toyota Jidosha Kabushiki Kaisha of 1 Toyota-cho</street><city>Toyota-shi Aichi-ken 471-8571</city><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR919516864" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>OKAMURA RYUJI</last-name><address><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR919527763" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>OKAMURA, RYUJI</last-name></addressbook></inventor><inventor mxw-id="PPAR919008077" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>OKAMURA, RYUJI</last-name><address><street>c/o Toyota Jidosha Kabushiki Kaisha of 1 Toyota-cho</street><city>Toyota-shi Aichi-ken 471-8571</city><country>JP</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR919013326" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>TBK-Patent</last-name><iid>100061560</iid><address><street>Bavariaring 4-6</street><city>80336 München</city><country>DE</country></address></addressbook></agent></agents></parties><international-convention-data><pct-or-regional-filing-data ucid="IB-2011003099-W"><document-id><country>IB</country><doc-number>2011003099</doc-number><kind>W</kind><date>20111221</date><lang>EN</lang></document-id></pct-or-regional-filing-data><pct-or-regional-publishing-data ucid="WO-2012090045-A1"><document-id><country>WO</country><doc-number>2012090045</doc-number><kind>A1</kind><date>20120705</date><lang>EN</lang></document-id></pct-or-regional-publishing-data><designated-states><ep-contracting-states><country mxw-id="DS549843670" load-source="docdb">AL</country><country mxw-id="DS549843858" load-source="docdb">AT</country><country mxw-id="DS549843671" load-source="docdb">BE</country><country mxw-id="DS549774848" load-source="docdb">BG</country><country mxw-id="DS549763949" load-source="docdb">CH</country><country mxw-id="DS549857779" load-source="docdb">CY</country><country mxw-id="DS549843859" load-source="docdb">CZ</country><country mxw-id="DS549916087" load-source="docdb">DE</country><country mxw-id="DS549843672" load-source="docdb">DK</country><country mxw-id="DS549857780" load-source="docdb">EE</country><country mxw-id="DS549763614" load-source="docdb">ES</country><country mxw-id="DS549774857" load-source="docdb">FI</country><country mxw-id="DS549774858" load-source="docdb">FR</country><country mxw-id="DS549916088" load-source="docdb">GB</country><country mxw-id="DS549843673" load-source="docdb">GR</country><country mxw-id="DS549843678" load-source="docdb">HR</country><country mxw-id="DS549857781" load-source="docdb">HU</country><country mxw-id="DS549763950" load-source="docdb">IE</country><country mxw-id="DS549843679" load-source="docdb">IS</country><country mxw-id="DS549774859" load-source="docdb">IT</country><country mxw-id="DS549857786" load-source="docdb">LI</country><country mxw-id="DS549916089" load-source="docdb">LT</country><country mxw-id="DS549843860" load-source="docdb">LU</country><country mxw-id="DS549916090" load-source="docdb">LV</country><country mxw-id="DS549916091" load-source="docdb">MC</country><country mxw-id="DS549843861" load-source="docdb">MK</country><country mxw-id="DS549843116" load-source="docdb">MT</country><country mxw-id="DS549763615" load-source="docdb">NL</country><country mxw-id="DS549843117" load-source="docdb">NO</country><country mxw-id="DS549763616" load-source="docdb">PL</country><country mxw-id="DS549843890" load-source="docdb">PT</country><country mxw-id="DS549763621" load-source="docdb">RO</country><country mxw-id="DS549843891" load-source="docdb">RS</country><country mxw-id="DS549763622" load-source="docdb">SE</country><country mxw-id="DS549857787" load-source="docdb">SI</country><country mxw-id="DS549843122" load-source="docdb">SK</country><country mxw-id="DS549843123" load-source="docdb">SM</country><country mxw-id="DS549774860" load-source="docdb">TR</country></ep-contracting-states></designated-states></international-convention-data><office-specific-data><eptags><ep-no-a-document-published>*</ep-no-a-document-published></eptags></office-specific-data></bibliographic-data><abstract mxw-id="PA97456276" ref-ucid="WO-2012090045-A1" lang="EN" load-source="patent-office"><p num="0000">An image providing device (1) is installed in a vehicle and provides images of vehicle surroundings to a driver. The device includes a right side camera (3) and a left side camera (4) that respectively pick up an image of a first image pickup range and an image of a second image pickup range that does not overlap the first image pickup range in the vehicle surroundings, a first display (7) that provides to the driver a right rear image picked up by the right side camera (3), a second display (8) that is provided separately from the first display (7) and provides to the driver a left rear image that is picked up by the left side camera (4), and an image display parameter correction unit (13) that corrects an image display parameter of the left rear image according to an image display parameter of the right rear image.</p></abstract><abstract mxw-id="PA97781071" ref-ucid="WO-2012090045-A1" lang="EN" source="national office" load-source="docdb"><p>An image providing device (1) is installed in a vehicle and provides images of vehicle surroundings to a driver. The device includes a right side camera (3) and a left side camera (4) that respectively pick up an image of a first image pickup range and an image of a second image pickup range that does not overlap the first image pickup range in the vehicle surroundings, a first display (7) that provides to the driver a right rear image picked up by the right side camera (3), a second display (8) that is provided separately from the first display (7) and provides to the driver a left rear image that is picked up by the left side camera (4), and an image display parameter correction unit (13) that corrects an image display parameter of the left rear image according to an image display parameter of the right rear image.</p></abstract><abstract mxw-id="PA97456277" ref-ucid="WO-2012090045-A1" lang="FR" load-source="patent-office"><p num="0000">La présente invention se rapporte à un dispositif produisant des images (1) qui est installé dans un véhicule et qui transmet à un conducteur des images des alentours du véhicule. Le dispositif comprend une caméra côté droit (3) et une caméra côté gauche (4) qui capturent respectivement une image d'une première plage de capture d'image et une image d'une seconde plage de capture d'image qui ne recouvre pas la première plage de capture d'image dans les alentours du véhicule, un premier affichage (7) qui transmet au conducteur une image arrière droite capturée par la caméra côté droit (3), un second affichage (8) distinct du premier affichage (7) et qui transmet au conducteur une image arrière gauche qui a été capturée par la caméra côté gauche (4), ainsi qu'un unité de correction de paramètre d'affichage d'image (13) qui corrige un paramètre d'affichage d'image de l'image arrière gauche en fonction d'un paramètre d'affichage d'image de l'image arrière droite.</p></abstract><abstract mxw-id="PA97781072" ref-ucid="WO-2012090045-A1" lang="FR" source="national office" load-source="docdb"><p>La présente invention se rapporte à un dispositif produisant des images (1) qui est installé dans un véhicule et qui transmet à un conducteur des images des alentours du véhicule. Le dispositif comprend une caméra côté droit (3) et une caméra côté gauche (4) qui capturent respectivement une image d'une première plage de capture d'image et une image d'une seconde plage de capture d'image qui ne recouvre pas la première plage de capture d'image dans les alentours du véhicule, un premier affichage (7) qui transmet au conducteur une image arrière droite capturée par la caméra côté droit (3), un second affichage (8) distinct du premier affichage (7) et qui transmet au conducteur une image arrière gauche qui a été capturée par la caméra côté gauche (4), ainsi qu'un unité de correction de paramètre d'affichage d'image (13) qui corrige un paramètre d'affichage d'image de l'image arrière gauche en fonction d'un paramètre d'affichage d'image de l'image arrière droite.</p></abstract><description mxw-id="PDES47616330" ref-ucid="WO-2012090045-A1" lang="EN" load-source="patent-office"><!-- EPO <DP n="2"/>--><p id="p0001" num="0001"> IMAGE PROVIDING DEVICE </p><p id="p0002" num="0002">BACKGROUND OF THE INVENTION </p><p id="p0003" num="0003">1. Field of the Invention </p><p id="p0004" num="0004"> [0001] The invention relates to an image providing device that provides an image of vehicle surroundings to a driver. </p><p id="p0005" num="0005"> 2. Description of Related Art </p><p id="p0006" num="0006"> [0002] An electronic mirror system including image pickup devices for picking up images behind a vehicle and on the sides of the vehicle and a display device that display the images picked up by the image pickup devices to a driver is described in Japanese Patent Application Publication No. 2009-83618 (JP-A-2009-83618). With such an electronic mirror system, the driver can recognize the state behind or on the sides of the vehicle, without using side mirrors. </p><p id="p0007" num="0007"> [0003] However, in the aforementioned electronic mirror system, it may be difficult for the driver to view the images when either of the left and right image pickup devices gets into shadow of a building, a significant difference in brightness or luminance is created between the left and right images. </p><p id="p0008" num="0008">SUMMARY OF THE INVENTION </p><p id="p0009" num="0009"> [0004] The invention provides an image providing device that can improve visibility of images. </p><p id="p0010" num="0010"> [0005] The image providing device according to the first aspect of the invention is installed in a vehicle and provides an image of surroundings of the vehicle to a driver. The image providing device includes a first image pickup unit having a first image pickup range positioned in the vehicle surroundings; a second image pickup unit having a second image pickup range that does not overlap the first image pickup range in the vehicle surroundings; a first image providing unit that provides to the driver a first image 
<!-- EPO <DP n="3"/>-->
 that is an image picked up by the first image pickup unit; a second image providing unit that is provided separately from the first image providing unit and provides to the driver a second image that is an image picked up by the second image pickup unit; and an image display parameter correction unit that corrects a second image display parameter of the second image provided by the second image providing unit, according to a first image display parameter of the first image provided by the first image providing unit. </p><p id="p0011" num="0011"> [0006] According to the abovementioned aspect, even when a large difference in image display parameter such as brightness or luminance occurs between the first image and the second image, for example, when either of the first and second image pickup .units gets into shadow, the difference in image display parameter can be reduced and therefore visibility of the images to the driver can be improved by correcting the second image display parameter according to the first image display parameter. </p><p id="p0012" num="0012"> [0007] The image providing device according to the second aspect of the invention is installed in a vehicle and provides an image of surroundings of the vehicle to a driver. The image providing device includes a first image pickup unit having a first image pickup range positioned in the vehicle surroundings; a second image pickup unit having a second image pickup range that does not overlap the first image pickup range in the vehicle surroundings; a first image providing unit that provides to the driver a first image that is an image picked up by the first image pickup unit; a second image providing unit that is provided separately from the first image providing unit and provides to the driver a second image that is an image picked up by the second image pickup unit; and an image display parameter correction unit that corrects at least on of a first image display parameter of the first image provided by the first image providing unit and a second image display parameter of the second image provided by the second image providing unit on the basis of comparison of the first image display parameter and the second image display parameter. </p><p id="p0013" num="0013"> [0008] According to the abovementioned second aspect, one of the image display parameters can be corrected so as to reduce the difference in image display parameter on the basis of a comparison result of the first image and second image. 
<!-- EPO <DP n="4"/>-->
 Therefore, visibility of images to the driver can be adequately improved according to the circumstances. </p><p id="p0014" num="0014"> [0009] In the abovementioned aspects, an attention object determination unit that determines whether or not an attention object to which the driver is to pay attention is present in the first image or the second image may be further provided. The image display parameter correction unit may perform correction that emphasizes the image, from the first image and the Second image, that is determined by the attention object determination unit to include the attention object. </p><p id="p0015" num="0015"> [0010] With such a configuration, when an attention object to which the driver is to pay attention is present in the image, the driver's attention can be naturally attracted to this image by performing correction that emphasizes this image, for example, by increasing the luminance, and the driver will become aware of the presence of the attention object. In addition, the emphasis is made using the image display parameters, and therefore the driver does not feel disturbed. </p><p id="p0016" num="0016"> [0011] In the abovementioned aspects, the first image pickup unit may be a right side camera that is provided on a front right side of the vehicle and picks up, as the first image, an image on a right rear side of the vehicle, and the second image pickup unit may be a left side camera that is provided on a front left side of the vehicle and picks up, as the second image, an image on a left rear side of the vehicle. </p><p id="p0017" num="0017"> [0012] With such a configuration, the correction can be performed so as to decrease the difference in image display parameter between the images picked up with the right side camera and left side camera of the vehicle. Therefore, visibility of the image of the left rear side and right rear side of the vehicle that are the blind zones for the driver can be improved. </p><p id="p0018" num="0018"> [0013] In the abovementioned aspects, the first image providing unit and the second image providing unit may be disposed side by side inside the vehicle. </p><p id="p0019" num="0019"> [0014] With such a configuration, since visibility is greatly influenced by the difference in image display parameter, the improvement in image visibility can be defined more clearly. 
<!-- EPO <DP n="5"/>-->
 [0015] In the abovementioned aspects, the image display parameter correction unit may correct both the first image display parameter and the second image display parameter. </p><p id="p0020" num="0020"> [0016] With such a configuration, the image display parameters of both images are corrected so as to reduce the difference in image display parameter. Therefore, the variation amount of image display parameter in each image can be reduced and the image display parameters can be corrected without creating a feel of discomfort for the driver. </p><p id="p0021" num="0021"> [0017] In the abovementioned aspects, an environment state detection unit that detects an environment state around the vehicle may be further provided. The environment state detection unit may correct the image display parameter on the basis of a detection result of the environment state detection unit. </p><p id="p0022" num="0022"> [0018] With such a configuration, since the correction of image display parameter is performed on the basis of environment state such as daytime and nighttime, where it is daytime, the correction can be performed with reference to a brighter image correspondingly to a state in which the image abruptly becomes dark, for example, because the image pickup unit gets into shadow, and where it is nighttime, the correction can be performed with reference to a darker image correspondingly to a state in which the image abruptly becomes bright, for example, due to illumination with headlights of the trailing vehicle. Therefore, with such an image providing device, visibility can be further improved by performing adequate correction corresponding to the environment state. </p><p id="p0023" num="0023"> [0019] An image providing method according to the third aspect of the invention is an image providing method for an image providing device including a first image pickup unit having a first image pickup range positioned in surroundings of a vehicle; a second image pickup unit having a second image pickup range that does not overlap the first image pickup range in the vehicle surroundings; a first image providing unit that provides to a driver a first image that is an image picked up by the first image pickup unit; a second image providing unit that is provided separately from the first image providing unit and provides to the driver a second image that is an image picked 
<!-- EPO <DP n="6"/>-->
 up by the second image pickup unit; a vehicle sensor that detects a running state of the vehicle; and an obstacle sensor that detects an obstacle present around the vehicle. The image providing method includes determining whether it is daytime or nighttime on the basis of an environment state around the vehicle, performing correction of causing the image with a higher luminance, from among the first image and the second image, to have a luminance identical to the luminance of the image with a lower luminance when it is daytime, and performing correction of causing the image with a lower luminance, from among the first image and the second image, to have a luminance identical to the luminance of the image with a higher luminance when it is nighttime; and determining whether or not an attention object is included in the first image or the second image, and when the attention object is included, performing correction that emphasizes the image that includes the attention object, from among the first image and the second image. </p><p id="p0024" num="0024"> [0020] The invention makes it possible to improve Visibility of images. BRIEF DESCRIPTION OF THE DRAWINGS </p><p id="p0025" num="0025"> [0021] Features, advantages, and technical and industrial significance of exemplary embodiments of the invention will be described below with reference to the accompanying drawings, in which like numerals denote like elements, and wherein: </p><p id="p0026" num="0026"> FIG. 1 is a block diagram illustrating an embodiment of the image providing device according to the invention; </p><p id="p0027" num="0027"> FIG. 2 is a plan view illustrating the case where only the pickup range of the right side camera got into shadow of a wall; </p><p id="p0028" num="0028"> FIG. 3A shows a display prior to image display parameter correction performed in the case illustrated by FIG. 2; FIG. 3B shows a display after the image display parameter correction performed in the case illustrated by FIG. 2; </p><p id="p0029" num="0029"> FIG. 4 serves to explain the sampling range in comparison of image display parameters; </p><p id="p0030" num="0030"> FIG. 5 is a plan view illustrating the stage before or after the vehicle is parked; </p><p id="p0031" num="0031"> FIG. 6 is a plan view illustrating the case in which an attention object is included in 
<!-- EPO <DP n="7"/>-->
 the image pickup range; </p><p id="p0032" num="0032"> FIG. 7A shows a display prior to image display parameter correction performed in the case illustrated by FIG. 6; FIG. 7B shows a display after the image display parameter correction performed in the case illustrated by FIG. 6; and </p><p id="p0033" num="0033"> FIG. 8 is a flowchart illustrating the operation of the image providing device. </p><p id="p0034" num="0034">DETAILED DESCRIPTION OF EMBODIMENTS </p><p id="p0035" num="0035"> [0022] The preferred embodiments of the invention will be explained below in greater detail with reference to the appended drawings. </p><p id="p0036" num="0036"> [0023] As shown in FIGS. 1 and 2, an image providing device 1 according to the present embodiment is provided in a vehicle A and provides images of the surroundings of the vehicle A to the driver. The image providing device 1 realizes the improvement in image visibility by performing correction so as to reduce the difference in image display parameter such as brightness or luminance of a plurality of images provided to the driver. </p><p id="p0037" num="0037"> [0024] The image providing unit 1 is provided with an Electronic Control Unit (ECU) 2 that controls the entire device 1. The ECU 2 is an electronic control unit constituted by a Central Processing Unit (CPU), a Read Only Memory (ROM), and a Random Access Memory (RAM). In the ECU 2, the application programs stored in the ROM are loaded into the RAM and executed by the CPU, thereby executing operational processing of various types relating to the process of providing images. </p><p id="p0038" num="0038"> [0025] The ECU 2 is connected to a right side camera 3, a left side camera 4, an obstacle sensor 5, a vehicle sensor 6, a first display 7, and a second display 8. </p><p id="p0039" num="0039"> [0026] The right side camera 3 is provided at a position of the right side mirror of the vehicle A. The right side camera 3 has an image pickup range RH extending rearward to the right of the vehicle A. The right side camera 3 picks up a right rear image that is an image within the image pickup range RH. The right side camera 3 transmits the picked-up right rear image to the ECU 2. The right side camera 3 functions as the first image pickup unit. The image pickup range RH is considered to be 
<!-- EPO <DP n="8"/>-->
 the first image pickup range, and the right rear image is considered to be the first image. </p><p id="p0040" num="0040"> [0027] Likewise, the left side camera 4 is provided at a position of the left side mirror of the vehicle A. The left side camera 4 has an image pickup range LH extending rearward to the left of the vehicle A. The left side camera 4 picks up a left rear image that is an image within the image pickup range LH. The left side camera 4 transmits the picked-up left rear image to the ECU 2. The left side camera 4 functions as the second image pickup unit. The image pickup range LH is considered to be the second image pickup range, and the left rear image is considered to be the second image. </p><p id="p0041" num="0041"> [0028] The obstacle sensor 5 detects an obstacle such as a pedestrian, another vehicle, or a building present around the vehicle A. The obstacle sensor 5 is constituted by a plurality of sensors such as laser radar sensors and image sensors. The obstacle sensor 5 transmits the obstacle detection results as obstacle information to the ECU 2. </p><p id="p0042" num="0042"> [0029] The vehicle sensor 6 is constituted by a speed sensor, a brake sensor, a shift sensor, a steering sensor, an accelerator operation amount sensor, a headlight sensor, a wiper sensor, and the like. The vehicle sensor 6 detects the running state of the vehicle A by these sensors. In addition to the steering state and speed state of the vehicle A, the running state includes the shift state of the vehicle, the on/off state. of the headlights, and the wiper drive/stop state. The vehicle sensor 6 transmits the detected running state of the vehicle A as turning state information to the ECU 2. </p><p id="p0043" num="0043"> [0030] The first display 7 and the second display 8 are small displays provided, for example, side by side on the instrument panel of the vehicle A (see FIGS. 3A and 3B). The first display 7 displays and provides to the driver the right rear image picked up by the right side camera 3. The second display 8 displays and provides to the driver the left rear image picked up by the left side camera 4. Since the first display 7 and the second display 8 are provided side by side, the driver can simultaneously recognize the state of the right rear side and left rear side of the vehicle. The first display 7 functions as the first image providing unit. The second display 8 functions as the second image providing unit. </p><p id="p0044" num="0044"> [0031] The ECU 2 has an environment state detection unit 10, an attention 
<!-- EPO <DP n="9"/>-->
 object determination unit 11, a parking state determination unit 12, and a image display parameter correction unit 13. </p><p id="p0045" num="0045"> [0032] The environment state detection unit 10 detects the environment state around the vehicle A on the basis of obstacle information obtained with the obstacle sensor 5 and running state information obtained with the vehicle sensor 6. The environment state includes an arrangement state of an obstacle such as a building or a large vehicle, a daytime or nighttime state, and a weather state. </p><p id="p0046" num="0046"> [0033] More specifically, the environment state detection unit 10 detects, the arrangement state of an obstacle from the obstacle information obtained with the obstacle sensor 5. Further, the environment state detection unit 10 detects the daytime and nighttime state from the on/off state of the headlights and detects the weather state form the wiper drive/stop state, from among the running state information obtained with the vehicle sensor 6. </p><p id="p0047" num="0047"> [0034] A method for detecting the environment state is not limited to the above-described method. For example, the environment state detection unit 10 may detect the present location of the vehicle A with a Global Positioning System (GPS) of the navigation system and then detect the arrangement state of buildings around the vehicle A from the map database. Further, the environment state detection unit 10 may detect the weather state including the position of sun by using weather information acquired by wireless communication. </p><p id="p0048" num="0048"> [0035] The attention object determination unit 11 determines an attention object to which the driver is to pay attention in the surroundings of the vehicle A on the basis of obstacle information obtained with the obstacle sensor 5. The attention object to which the driver is to pay attention, for example, corresponds to a pedestrian or another vehicle. </p><p id="p0049" num="0049"> [0036] The parking state determination unit 12 determines whether or not the vehicle A is in the state before or after parking on the basis of the running state information obtained with the vehicle sensor 6. The state before or after parking is a state in which the vehicle A is to be parked or a state in which the vehicle is started from the parked state. 
<!-- EPO <DP n="10"/>-->
 [0037] More specifically, the parking state determination unit 12 determines whether or not the vehicle A is in the state before or after parking on the basis of the vehicle speed state, vehicle steering state, and vehicle shift state, from among the vehicle state information obtained with the vehicle sensor 6. For example, the parking state determination unit 12 determines that the vehicle A is in the state before or after parking when the vehicle is in the low-speed state or the steering angle is large or when the vehicle is in the reverse shift state. </p><p id="p0050" num="0050"> [0038] The image display parameter correction unit 13 compares the image display parameter of the right rear image displayed by the first display 7 with the image display parameter of the left rear image displayed by the second display 8. </p><p id="p0051" num="0051"> [0039] More specifically, the image display parameter correction unit 13 recognizes and compares the image display parameters in sampling ranges ER, EL shown in FIG. 4. Since image display parameters are changed significantly by the effect of another vehicle displayed in the image within a range in which the other vehicle is seen, the ranges in which the road surface is mainly seen are selected as the sampling ranges ER, EL. Furthermore, in order to suppress more effectively the effect of the display of other vehicles and the like, the image display parameter correction unit 13 recognizes the image display parameters of the sampling ranges ER, EL by an appropriate method. </p><p id="p0052" num="0052"> [0040] For example, the image display parameter correction unit 13 calculates a time average of image display parameters in the sampling ranges ER, EL and recognizes the image display parameters as the calculation results. Further, the image display parameter correction unit 13 may recognize the image display parameters within a range from which another vehicle detected by Optical flow is excluded. The image display parameter correction unit 13 may also perform recognition of image display parameters from the road surface extracted by clustering. The image display parameter correction unit 13 may also perform the recognition of image display parameters by a combination of a plurality of methods. </p><p id="p0053" num="0053"> [0041] In the case where the vehicle is before or after parking in a parking space P, it is highly probable that the type of road surface (gravel, asphalt, concrete, bricks, etc) 
<!-- EPO <DP n="11"/>-->
 viewed by the right side camera 3 and left side camera 4 will be different as shown in FIG. 5, therefore the image display parameter correction unit 13 changes the sampling range and the like to a mode different from the usual mode. For example, where the image display parameter correction unit 13 stores each brightness or luminance of the same lightness in the journey to the parking space, changes in the circumstances are recognized regardless of the type of road surface, and erroneous recognition of image display parameters is avoided. </p><p id="p0054" num="0054"> [0042] The image display parameter correction unit 13 corrects the image display parameter of the right rear image or the image display parameter of the left rear image on the basis of comparison results of the image display parameter of the right rear image and the image display parameter of the left rear image. </p><p id="p0055" num="0055"> [0043] The correction of image display parameters performed by the image display parameter correction unit 13 will be explained below with reference to FIGS. 2,</p><p id="p0056" num="0056">3A, and 3B. FIG. 2 shows the case where the image pickup range RH of the right side camera 3, from among the right side camera 3 and the left side camera 4, gets into a shadow D of a wall T. FIG. 3A shows the first display 7 and the second display 8 before the image display parameter correction in the case illustrated by FIG. 2. FIG. 3B shows the first display 7 and the second display 8 after the image display parameter correction in the case illustrated by FIG. 2. Lane boundary lines CR, CL of the lane in which the vehicle A travels are shown in FIGS. 2 and 3. </p><p id="p0057" num="0057"> [0044] In the case shown in FIG. 2, the image display parameter correction unit 13 recognizes the difference in luminance caused by the shadow by comparing the image display parameter of the right rear image provided by the first display 7 and the image display parameter of the left rear image provided by the second display 8 shown in FIG. 3A. Then, as shown in FIG. 3B, the image display parameter correction unit 13 performs the correction by reducing the difference in luminance by increasing the luminance of the right rear image. </p><p id="p0058" num="0058"> [0045] The image display parameter correction unit 13 also corrects the image display parameter correspondingly to conditions on the basis of running state information 
<!-- EPO <DP n="12"/>-->
 obtained by the vehicle sensor 6, environmental conditions detected by the environment state detection unit 10, determination results obtained by the attention object determination unit 11, and determination results obtained by the parking state determination unit 12. </p><p id="p0059" num="0059"> [0046] More specifically, when the image display parameter correction unit 13 recognizes that it is daytime from the environmental conditions detected by the environment state detection unit 10, a difference in brightness or luminance often occurs when the image pickup ranges RH, LH of cameras 3, 4 get into shadow of a building or the host vehicle. Therefore, the image with a lower luminance is corrected to have a luminance identical to the luminance of the image with a higher luminance. In this case, the image display parameter correction unit 13. specifies the presence of an obstacle creating the shadow on the basis of arrangement<sup>'</sup> conditions of the obstacle or weather conditions, from among the environmental conditions. As a result, the image display parameter correction unit 13 can distinguish between the case where the luminance is reduced by the shadow and the case where image pickup object merely has a dark color, and erroneous recognition can be avoided. </p><p id="p0060" num="0060"> [0047] Further, when the image display parameter correction unit 13 recognizes that it is nighttime from the environmental conditions detected by the environment state detection unit 10, the difference in brightness or luminance is often caused by the light from headlights of the trailing vehicle. Therefore, the image with a high luminance is corrected to have a luminance identical to the luminance of the image with a lower luminance. Further, where a limit threshold is set for the luminance in the image display parameter correction unit 13, bright light such as that of headlights is prevented from being directly displayed in the image. </p><p id="p0061" num="0061"> [0048] Further, when the parking state determination unit 12 determines that the vehicle A is in the state before or after parking, it is necessary that the image display parameter correction unit 13 accurately recognize obstacles such as surrounding walls and other vehicles. Therefore, the image with a lower luminance is corrected to have a luminance identical to the luminance of the image with a higher luminance. 
<!-- EPO <DP n="13"/>-->
 [0049] The image display parameter correction unit 13 determines whether or not an attention object is included in the right rear image or left rear image on the basis of the right rear image picked up by the right side camera 3, left rear image picked up by the left side camera 4, and determination results obtained by the attention object determination unit 11. </p><p id="p0062" num="0062"> [0050] When the image display parameter correction unit 13 determines that the attention object is included in the right rear image or left rear image, the correction that emphasizes this image is performed. The emphasizing correction as referred to herein is, for example, correction that increases brightness or luminance of the image including the attention object. Further, the emphasizing correction also includes the case where the image including the attention object is relatively emphasized by decreasing the brightness or luminance of the image that does not include the attention object. </p><p id="p0063" num="0063"> [0051] FIG. 6 is a plan view illustrating the case in which a pedestrian B, which is an attention object, is included in the right rear image picked up by the right side camera 3. FIG. 7 A shows the first display 7 and the second display 8 before the image display parameter correction illustrated by FIG. 6. FIG. 7A shows the first display 7 and the second display 8 after the image display parameter correction illustrated by FIG. 6. </p><p id="p0064" num="0064"> [0052] In the case shown in FIG. 6, the image display parameter correction unit 13 determines that the pedestrian B is included in the right rear image picked up by the right side camera 3 on the basis of the right rear image picked up by the right side camera 3 shown in FIG. 7A, left rear image picked up by the left side camera 4, and determination results of the attention object determination unit 11. As shown in FIG. 7B, the image display parameter correction unit 13 performs the correction emphasizing the image by increasing the luminance with respect to the image display parameter of the right rear image that includes the pedestrian B. The image display parameter correction unit 13 also performs the correction that relatively emphasizes the right rear image by reducing the luminance of the left rear image that does not include the attention object. </p><p id="p0065" num="0065"> [0053] The operation of the above-described image providing device 1 will be described below. The correction of luminance will be explained by way of example as 
<!-- EPO <DP n="14"/>-->
 the correction of image display parameter. </p><p id="p0066" num="0066"> [0054] As shown in FIG. 8, in the image providing device 1, first, the parking state determination unit 12 determines whether the vehicle A is in the state before or after parking (SI). The parking state determination unit 12 determines whether the vehicle A is in the state before or after parking, for example, on the basis of vehicle speed state and vehicle steering state, from the running state information obtained by the vehicle sensor 6. When the parking state determination unit 12 determines that the vehicle A is in the state before or after parking, the processing advances to step S4. </p><p id="p0067" num="0067"> [0055] When the parking state determination unit 12 determines that the vehicle A is not in the state before or after parking, the image display parameter correction unit 13 determines whether or not the environment state is daylight on the basis of the environment state around the vehicle that has been detected by the environment state detection unit 10 (S2). Where the image display parameter correction unit 13 has determined that the environment state is daylight, the processing advances to step S4. </p><p id="p0068" num="0068"> [0056] Where the image display parameter correction unit 13 has determined that the environment state is not daylight, it is determined that the environment state is nighttime, and the image display parameter correction unit performs a luminance reducing correction processing of correcting the image with a lower luminance to have a luminance identical to the luminance of the image with a higher luminance, from among the right rear image picked up by the right side camera 3 and the left rear image picked i </p><p id="p0069" num="0069">up by the left side camera 4 (S3). The processing then advances to step S5. </p><p id="p0070" num="0070"> [0057] In step S4, the image display parameter correction unit 13 performs a luminance increasing correction processing of correcting the image with a higher luminance to have a luminance identical to the luminance of the image with a lower luminance from among the right rear image picked up by the right side camera 3 and the left rear image picked up by the left side camera 4. The processing then advances to step S5. The image display parameter correction unit 13 may also perform correction only in the case in which the difference in luminance between the right rear image and the left rear image is equal to or higher than a predetermined value. 
<!-- EPO <DP n="15"/>-->
 [0058] In step S5, the image display parameter correction unit 13 determines whether or not an attention object is included in the right rear image Or left rear image on the basis of the right rear image obtained with the right side camera 3, left rear image obtained with the left side camera 4, and determination results of the attention object determination unit 11. When the image display parameter correction unit 13 determines that the attention object is not included in either of the images, the processing returns to step SI and the operations are repeated. </p><p id="p0071" num="0071"> [0059] Where the image display parameter correction unit 13 determines that the attention object is included in either of the images, the emphasizing correction process that emphasizes the image including the attention object is performed (S6). In the emphasizing correction processing, the image display parameter correction unit 13 performs the correction that increases brightness or luminance of the image including the attention object. The image display parameter correction unit 13 also performs the correction that relatively emphasizes the image including the attention object by decreasing the brightness or luminance of the image that does not include the attention object. The processing then returns to step SI and the operations are repeated. </p><p id="p0072" num="0072"> [0060] With the image providing device 1 according to the present embodiment that has been explained hereinabove, even when a large difference in an image display parameter, such as brightness or luminance, occurs between the right rear image and left rear image, for example in the case where either of the right side camera 3 and the left side camera 4 gets into shadow, the image display parameter of one image can be corrected so as to decrease the difference in image display parameter on the basis of results obtained in comparing the right rear image with the left rear image. Therefore, visibility of images on the left rear side and right rear side of the vehicle that are the blind zones for the driver can be improved. </p><p id="p0073" num="0073"> [0061] Further, in the image providing device 1, the first display 7 and the second display 8 are arranged side by side. Therefore, the driver can simultaneously recognize the left rear side and right rear side of the vehicle. Further, in this state, since visibility is greatly influenced by the difference in image display parameter, the 
<!-- EPO <DP n="16"/>-->
 improvement in image visibility by the image providing device 1 can be defined more clearly. </p><p id="p0074" num="0074"> [0062] Further, with the image providing device 1, since the correction of image display parameter is performed on the basis of environment state such as daytime and nighttime, where it is daytime, the correction can be performed with reference to a brighter image correspondingly to a state in which the image abruptly becomes dark, for example, because the image pickup unit gets into shadow, and where it is nighttime, the correction can be performed with reference to a darker image correspondingly to a state in which the image abruptly becomes bright, for example, due to illumination with headlights of the trailing vehicle. Therefore, with the image providing device 1, visibility can be further improved by performing adequate correction corresponding to the environment state. </p><p id="p0075" num="0075"> [0063] Further, with the image providing device 1, when an attention object to which the driver is to pay attention is present in the image, the driver's attention can be naturally attracted to this image by performing correction that emphasizes this image, for example, by increasing the luminance, and the driver will become aware of the presence of the attention object. In addition, the emphasis is made using the image display parameters, and therefore the driver does not feel disturbed. </p><p id="p0076" num="0076"> [0064] The invention is not limited to the above-described embodiments. </p><p id="p0077" num="0077"> [0065] For example, the image display parameter correction unit 13 may also correct the image display parameter of another image with respect to the image display parameter of one image, from among the right rear image displayed by the first display 7 and the left rear image displayed by the second display 8. In this case, when a large difference in image display parameter such as brightness and luminance occurs between the right rear image and left rear image, the difference in image display parameter can be reduced by correcting the image display parameter of the left rear image according to the image display parameter of the right rear image, and visibility of the image to the driver can be improved. It is also possible to correct the image display parameter of the right rear image according to the image display parameter of the left rear image. The image 
<!-- EPO <DP n="17"/>-->
 serving as a reference for correction, from among the right rear image and left rear image, can be considered the first image and the image which is to be corrected can be considered the second image. </p><p id="p0078" num="0078"> [0066] The image display parameter correction unit 13 may also correct both image display parameters, instead of matching the image display parameter of one image with the image display parameter of the other image, when correcting the image display parameter so as to decrease the difference in image display parameter between the right rear image and left rear image. In this case, the variation amount of the image display parameter of each image can be reduced and the correction of image display parameter can be performed, without creating the feel of discomfort for the driver. Further, color shade and sharpness of the image may be also included in the image parameters and correction thereof may be performed. </p><p id="p0079" num="0079"> [0067] The invention can be effectively applied not only to the right side camera 3 and left side camera 4, but also to a back camera that picks up images behind the vehicle. Further, the number of cameras and displays is not limited to two, and three or more cameras and displays can be also used. </p><p id="p0080" num="0080"> [0068] The image providing device in accordance with the invention can also implement the correction of image display parameters of various kinds according to the circumstances. For example, since the cameras easily get into shadow when the vehicle is driven in a city street, it is possible to determine whether the vehicle is driven in a city street with a navigation system and change the correction method for image display parameters. Further, the images change significantly with time when the vehicle is driven at a high speed. Therefore, it is also possible to change the correction method for image display parameters on the basis of vehicle speed. 
</p></description><claims mxw-id="PCLM43061141" ref-ucid="WO-2012090045-A1" lang="EN" load-source="patent-office"><claim-statement><!-- EPO <DP n="18"/>--> CLAIMS: </claim-statement><claim id="clm-0001" num="1"><claim-text>1. An image providing device that is installed in a vehicle and provides an image of surroundings of the vehicle to a driver, comprising: </claim-text><claim-text> a first image pickup unit having a first image pickup range positioned in the vehicle surroundings; . . </claim-text><claim-text> a second image pickup unit having a second image pickup range that does not overlap the first image pickup range in the vehicle surroundings; </claim-text><claim-text> a first image providing unit that provides to the driver a first image that is an image picked up by the first image pickup unit; </claim-text><claim-text> a second image providing unit that is provided separately from the first image providing unit and provides to the driver a second image that is an image picked up by the second image pickup unit; and </claim-text><claim-text> an image display parameter correction unit that corrects a second image display parameter of the second image provided by the second image providing unit, according to a first image display parameter of the first image provided by the first image providing unit. </claim-text></claim><claim id="clm-0002" num="2"><claim-text>2. An image providing device that is installed in a vehicle and provides an image of surroundings of the vehicle to a driver, comprising: </claim-text><claim-text> a first image pickup unit having a first image pickup range positioned in the vehicle surroundings; </claim-text><claim-text> a second image pickup unit having a second image pickup range that does not overlap the first image pickup range in the vehicle surroundings; </claim-text><claim-text> a first image providing unit that provides to the driver a first image that is an image picked up by the first image pickup unit; </claim-text><claim-text> a second image providing unit that is provided separately from the first image providing unit and provides to the driver a second image that is an image picked up by the second image pickup unit; and </claim-text><claim-text>I <!-- EPO <DP n="19"/>--> an image display parameter correction unit that corrects at least one of a first image display parameter of the first image provided by the first image providing unit and a second image display parameter of the second image provided by the second image providing unit on the basis of comparison of the first image display parameter and the second image display parameter. </claim-text></claim><claim id="clm-0003" num="3"><claim-text>3. The image providing device according to claim 2, further comprising an attention object determination unit that determines whether or not an attention object to which the driver is to pay attention is present in the first image or the second image, wherein </claim-text><claim-text> the image display parameter correction unit performs correction that emphasizes the image, from the first image and the second image, that is determined by the attention object determination unit to include the attention object. </claim-text></claim><claim id="clm-0004" num="4"><claim-text>4. The image providing device according to claim 1 or 2, wherein the image display parameter correction unit corrects the second image display parameter so as to become closer to the first image display parameter. </claim-text></claim><claim id="clm-0005" num="5"><claim-text>5. The image providing device according to claim 1 or 2, wherein the image display parameter correction unit corrects the first image display parameter and the second image display parameter sb that a difference between the first image display parameter and the second image display parameter is reduced. </claim-text></claim><claim id="clm-0006" num="6"><claim-text>6. The image providing device according to any one of claims 1 to 5, wherein the first image pickup unit is a right side camera that is provided on a front right side of the vehicle and picks up, as the first image, an image on a right rear side of the vehicle, and the second image pickup unit is a left side camera that is provided on a front left side of the vehicle and picks up, as the second image, an image on a left rear side of the vehicle. <!-- EPO <DP n="20"/>--> </claim-text></claim><claim id="clm-0007" num="7"><claim-text>7. The image providing device according to any one of claims 1 to 6, wherein the first image providing unit and the second image providing unit are configured to be disposed side by side inside the vehicle. </claim-text></claim><claim id="clm-0008" num="8"><claim-text>8. The image providing device according to any one of claims 1 to 7, wherein the image display parameter correction unit corrects both the first image display parameter and the second image display parameter. </claim-text></claim><claim id="clm-0009" num="9"><claim-text>9. The image providing device according to any one of claims 1 to 8, further comprising an environment state detection unit that detects an environment state around the vehicle, wherein the image display parameter correction unit corrects the image display parameter on the basis of a detection result of the environment state detection unit. </claim-text></claim><claim id="clm-0010" num="10"><claim-text>10. The image providing device according to claim 9, further comprising a vehicle sensor that detects a running state of the vehicle, wherein the environment state detection unit detects the environment state around the vehicle on the basis of a detection result of the vehicle sensor. </claim-text></claim><claim id="clm-0011" num="11"><claim-text>11. The image providing device according to claim 9 or 10, further comprising an obstacle sensor that detects an obstacle present around the vehicle, wherein the environment state detection unit detects an arrangement state of the obstacle on the basis of obstacle information from the obstacle sensor. </claim-text></claim><claim id="clm-0012" num="12"><claim-text>12. The image providing device according to any one of claims 9 to 11, wherein the environment state detection unit detects a daytime or nighttime state on the basis of the turn on/off state of headlights of the vehicle and detects a weather state by a wiper operation state in the vehicle. <!-- EPO <DP n="21"/>--> </claim-text></claim><claim id="clm-0013" num="13"><claim-text>13. The image providing device according to any one of claims 1 to 12, wherein in correction of the first image display parameter and the second image display parameter, the correction of at least one of image brightness, luminance, color shade and sharpness is performed. </claim-text></claim><claim id="clm-0014" num="14"><claim-text>14. The image providing device according to any one of claims 9 to 13, further comprising a parking state determination unit that determines whether or not the vehicle is in a state before or after parking, wherein the parking state determination unit determines whether the vehicle is in the state before or after parking on the basis of the running state detected by the vehicle sensor. </claim-text></claim><claim id="clm-0015" num="15"><claim-text>15. An image providing method for an image providing device including: </claim-text><claim-text> a first image pickup unit having a first image pickup range positioned in surroundings of a vehicle; </claim-text><claim-text> a second image pickup unit having a second image pickup range that does not overlap the first image pickup range in the vehicle surroundings; </claim-text><claim-text> a first image providing unit that provides to a driver a first image that is an image picked up by the first image pickup unit; </claim-text><claim-text> a second image providing unit that is provided separately from the first image providing unit and provides to the driver a second image that is an image picked up by the second image pickup unit; </claim-text><claim-text> a vehicle sensor that detects a running state of the vehicle; and </claim-text><claim-text> an obstacle sensor that detects an obstacle present around the vehicle, </claim-text><claim-text> the image providing method comprising: </claim-text><claim-text> determining whether it is daytime or nighttime on the basis of an environment state around the vehicle, performing correction of causing the image with a higher luminance, from among the first image and the second image, to have a luminance identical to the luminance of the image with a lower luminance when it is daytime, and performing correction of causing the image with a lower luminance, from among the first image and <!-- EPO <DP n="22"/>--> the second image, to have a luminance identical to the luminance of the image with a higher luminance when it is nighttime; and </claim-text><claim-text> determining whether or not an attention object is included in the first image or the second image, and when the attention object is included, performing correction that emphasizes the image that includes the attention object, from among the first image and the second image. </claim-text></claim><claim id="clm-0016" num="16"><claim-text>16. The image providing method according to claim 15, wherein the first image pickup unit is a right side camera that is provided on a front right side of the vehicle and picks up, as the first image, an image on a right rear side of the vehicle, and the second image pickup unit is a left side camera that is provided on a front left side of the vehicle and picks up, as the second image, an image on a left rear side of the vehicle, </claim-text><claim-text> the image providing method further comprising determining whether the vehicle is in a state before or after parking on the basis of the running state of the vehicle, and determining whether it is daytime or nighttime on the basis of an environment state around the vehicle when the vehicle is in the state before or after parking. </claim-text></claim></claims><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
