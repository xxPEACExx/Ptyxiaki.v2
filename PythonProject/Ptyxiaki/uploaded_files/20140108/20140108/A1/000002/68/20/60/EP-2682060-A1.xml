<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2682060-A1" country="EP" doc-number="2682060" kind="A1" date="20140108" family-id="48463711" file-reference-id="192927" date-produced="20180822" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="146585547" ucid="EP-2682060-A1"><document-id><country>EP</country><doc-number>2682060</doc-number><kind>A1</kind><date>20140108</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-13166730-A" is-representative="YES"><document-id mxw-id="PAPP154847739" load-source="docdb" format="epo"><country>EP</country><doc-number>13166730</doc-number><kind>A</kind><date>20130507</date><lang>EN</lang></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC140549947" ucid="KR-20120062349-A" load-source="docdb"><document-id format="epo"><country>KR</country><doc-number>20120062349</doc-number><kind>A</kind><date>20120611</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL1989322495" load-source="docdb">A61B   8/00        20060101AFI20131203BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL1989623919" load-source="docdb" scheme="CPC">A61B   8/5246      20130101 LI20131214BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989624015" load-source="docdb" scheme="CPC">A61B   8/483       20130101 LI20131214BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989624365" load-source="docdb" scheme="CPC">A61B   8/14        20130101 LA20131126BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989632162" load-source="docdb" scheme="CPC">A61B   8/13        20130101 LI20131205BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989633410" load-source="docdb" scheme="CPC">A61B   8/463       20130101 FI20131214BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989649906" load-source="docdb" scheme="CPC">A61B   8/466       20130101 LI20131214BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989652394" load-source="docdb" scheme="CPC">A61B   8/469       20130101 LI20131126BHEP        </classification-cpc><classification-cpc mxw-id="PCL2049214485" load-source="docdb" scheme="CPC">A61B   8/523       20130101 LI20140304BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT132361274" lang="DE" load-source="patent-office">Verfahren und Vorrichtung zum Anzeigen dreidimensionaler und zweidimensionaler Ultraschallbilder</invention-title><invention-title mxw-id="PT132361275" lang="EN" load-source="patent-office">Method and apparatus for displaying three-dimensional ultrasonic image and two-dimensional ultrasonic image</invention-title><invention-title mxw-id="PT132361276" lang="FR" load-source="patent-office">Procédé et appareil pour afficher une image ultrasonore tridimensionnelle et une image ultrasonore bidimensionnelle</invention-title><citations><patent-citations><patcit mxw-id="PCIT242944553" load-source="docdb" ucid="US-20050096538-A1"><document-id format="epo"><country>US</country><doc-number>20050096538</doc-number><kind>A1</kind><date>20050505</date></document-id><sources><source name="SEA" category="X" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT242944554" load-source="docdb" ucid="US-20060084872-A1"><document-id format="epo"><country>US</country><doc-number>20060084872</doc-number><kind>A1</kind><date>20060420</date></document-id><sources><source name="SEA" category="A" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT242944555" load-source="docdb" ucid="US-20080077013-A1"><document-id format="epo"><country>US</country><doc-number>20080077013</doc-number><kind>A1</kind><date>20080327</date></document-id><sources><source name="SEA" category="A" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT242944556" load-source="docdb" ucid="US-20110054319-A1"><document-id format="epo"><country>US</country><doc-number>20110054319</doc-number><kind>A1</kind><date>20110303</date></document-id><sources><source name="SEA" category="A" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT242944557" load-source="docdb" ucid="US-20110245670-A1"><document-id format="epo"><country>US</country><doc-number>20110245670</doc-number><kind>A1</kind><date>20111006</date></document-id><sources><source name="SEA" category="X" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT242944558" load-source="docdb" ucid="US-20110313291-A1"><document-id format="epo"><country>US</country><doc-number>20110313291</doc-number><kind>A1</kind><date>20111222</date></document-id><sources><source name="SEA" category="A" created-by-npl="N"/></sources></patcit></patent-citations><non-patent-citations><nplcit><text>None</text><sources><source mxw-id="PNPL45211573" load-source="docdb" name="APP"/></sources></nplcit></non-patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR919531021" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>SAMSUNG MEDISON CO LTD</last-name><address><country>KR</country></address></addressbook></applicant><applicant mxw-id="PPAR919530761" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>SAMSUNG MEDISON CO., LTD.</last-name></addressbook></applicant><applicant mxw-id="PPAR919019092" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Samsung Medison Co., Ltd.</last-name><iid>101333802</iid><address><street>3366, Hanseo-ro Nam-myeon Hongcheon-gun</street><city>GANGWON-DO 250-870</city><country>KR</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR919506177" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>PARK SUNG-WOOK</last-name><address><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR919512562" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>PARK, SUNG-WOOK</last-name></addressbook></inventor><inventor mxw-id="PPAR919005712" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>PARK, SUNG-WOOK</last-name><address><street>3366, Hanseo-ro, Nam-myeon,</street><city>Hongcheon-gun, Gangwon-do</city><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR919526584" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>LEE JIN-YONG</last-name><address><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR919541368" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>LEE, JIN-YONG</last-name></addressbook></inventor><inventor mxw-id="PPAR919009622" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>LEE, JIN-YONG</last-name><address><street>3366, Hanseo-ro, Nam-myeon,</street><city>Hongcheon-gun, Gangwon-do</city><country>KR</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR919012084" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Lorenz, Markus</last-name><iid>101259170</iid><address><street>Lorenz &amp; Kollegen Patentanwälte Partnerschaftsgesellschaft Alte Ulmer Straße 2</street><city>89522 Heidenheim</city><country>DE</country></address></addressbook></agent></agents></parties><international-convention-data><designated-states><ep-contracting-states><country mxw-id="DS549910632" load-source="docdb">AL</country><country mxw-id="DS549828781" load-source="docdb">AT</country><country mxw-id="DS549910634" load-source="docdb">BE</country><country mxw-id="DS549748954" load-source="docdb">BG</country><country mxw-id="DS549750274" load-source="docdb">CH</country><country mxw-id="DS549752491" load-source="docdb">CY</country><country mxw-id="DS549828910" load-source="docdb">CZ</country><country mxw-id="DS549910635" load-source="docdb">DE</country><country mxw-id="DS549752492" load-source="docdb">DK</country><country mxw-id="DS549752501" load-source="docdb">EE</country><country mxw-id="DS549821411" load-source="docdb">ES</country><country mxw-id="DS549748955" load-source="docdb">FI</country><country mxw-id="DS549750275" load-source="docdb">FR</country><country mxw-id="DS549910636" load-source="docdb">GB</country><country mxw-id="DS549752502" load-source="docdb">GR</country><country mxw-id="DS549910637" load-source="docdb">HR</country><country mxw-id="DS549828911" load-source="docdb">HU</country><country mxw-id="DS549824664" load-source="docdb">IE</country><country mxw-id="DS549752503" load-source="docdb">IS</country><country mxw-id="DS549750276" load-source="docdb">IT</country><country mxw-id="DS549752504" load-source="docdb">LI</country><country mxw-id="DS549748956" load-source="docdb">LT</country><country mxw-id="DS549827020" load-source="docdb">LU</country><country mxw-id="DS549748969" load-source="docdb">LV</country><country mxw-id="DS549748970" load-source="docdb">MC</country><country mxw-id="DS549827021" load-source="docdb">MK</country><country mxw-id="DS549827026" load-source="docdb">MT</country><country mxw-id="DS549824665" load-source="docdb">NL</country><country mxw-id="DS549821412" load-source="docdb">NO</country><country mxw-id="DS549824670" load-source="docdb">PL</country><country mxw-id="DS549748971" load-source="docdb">PT</country><country mxw-id="DS549828912" load-source="docdb">RO</country><country mxw-id="DS549748972" load-source="docdb">RS</country><country mxw-id="DS549824671" load-source="docdb">SE</country><country mxw-id="DS549750285" load-source="docdb">SI</country><country mxw-id="DS549821413" load-source="docdb">SK</country><country mxw-id="DS549821418" load-source="docdb">SM</country><country mxw-id="DS549827027" load-source="docdb">TR</country></ep-contracting-states><ep-extended-states><ep-extended-state-data><country>BA</country></ep-extended-state-data><ep-extended-state-data><country>ME</country></ep-extended-state-data></ep-extended-states></designated-states></international-convention-data></bibliographic-data><abstract mxw-id="PA128673719" lang="EN" load-source="patent-office"><p id="pa01" num="0001">A method of displaying a 3D image and a 2D image includes the operations of acquiring the 3D image of a target object, selecting at least one cross-section of the target object based on an external input for the acquired 3D image, acquiring the 2D image by scanning the target object such as to obtain the selected at least one cross-section, and displaying the 2D image and the 3D image.
<img id="iaf01" file="imgaf001.tif" wi="83" he="101" img-content="drawing" img-format="tif"/></p></abstract><abstract mxw-id="PA128737878" lang="EN" source="EPO" load-source="docdb"><p>A method of displaying a 3D image and a 2D image includes the operations of acquiring the 3D image of a target object, selecting at least one cross-section of the target object based on an external input for the acquired 3D image, acquiring the 2D image by scanning the target object such as to obtain the selected at least one cross-section, and displaying the 2D image and the 3D image.</p></abstract><description mxw-id="PDES63959707" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><heading id="h0001"><u>CROSS-REFERENCE TO RELATED PATENT APPLICATION</u></heading><p id="p0001" num="0001">This application claims the benefit of Korean Patent Application No. <patcit id="pcit0001" dnum="KR1020120062349"><text>10-2012-0062349, filed on June 11, 2012</text></patcit>, in the Korean Intellectual Property Office, the disclosure of which is incorporated herein in its entirety by reference.</p><heading id="h0002"><u>BACKGROUND OF THE INVENTION</u></heading><heading id="h0003">1. Field of the Invention</heading><p id="p0002" num="0002">The present invention relates to a method and apparatus for displaying a three-dimensional (3D) ultrasonic image and a two-dimensional (2D) ultrasonic image, and more particularly, to a method and apparatus for acquiring a 2D ultrasonic image by scanning a target object in the direction of a cross-section selected from an acquired 3D ultrasonic image, and displaying the acquired 3D and 2D ultrasonic images.</p><heading id="h0004">2. Description of the Related Art</heading><p id="p0003" num="0003">Ultrasonic diagnosis apparatuses transmit an ultrasonic signal toward a predetermined part of the inside of a target object through the body surface of the target object and obtain an image associated with the fault or blood flow of soft tissue of the target object by using information of the ultrasonic signal reflected from tissue of the inside of the target object.</p><p id="p0004" num="0004">Such ultrasonic diagnosis apparatuses are capable of displaying an image of a target object in real time. In addition, such ultrasonic diagnosis apparatuses are very safe because there is no radiation exposure by X rays or the like, and thus are widely used together with other image diagnosis apparatuses, such as an X-ray diagnosis apparatus, a computed tomography (CT) scanner, a magnetic resonance imaging (MRI) apparatus, and a nuclear medicine diagnosis apparatus.<!-- EPO <DP n="2"> --></p><p id="p0005" num="0005">Three-dimensional (3D) ultrasonic images facilitate general and clear understanding of a target object. However, using two-dimensional (2D) ultrasonic images may be more effective than using 3D ultrasonic images, in order to observe the cross-section or the like of the inside of a target object in detail.</p><p id="p0006" num="0006">Accordingly, when a 3D ultrasonic image and a 2D ultrasonic image are displayed together, a user is able to observe a target object generally and minutely at the same time.</p><p id="p0007" num="0007">In the prior art, a 2D ultrasonic image of a target object is acquired from a 3D ultrasonic image of the target object by using a rendering technique. However, direct scanning of a target object instead of rendering may increase the frame rate of an image and may ensure high-quality images. Direct scanning of a target object may also enable real-time understanding of movement conditions and the like of a target object that moves a lot or moves fast.</p><heading id="h0005"><u>SUMMARY OF THE INVENTION</u></heading><p id="p0008" num="0008">The present invention provides a method and apparatus for displaying a three-dimensional (3D) ultrasonic image and a two-dimensional (2D) ultrasonic image.</p><p id="p0009" num="0009">According to an aspect of the present invention, there is provided an apparatus for displaying a 3D ultrasonic image and a 2D ultrasonic image, the apparatus comprising: a 3D image acquiring unit which acquires a 3D image of a target object; a cross-section selection unit which selects at least one cross-section of the target object based on an external input for the acquired 3D image; a 2D image acquiring unit which acquires a 2D image by scanning the target object such as to obtain the selected at least one cross-section; and a display unit which displays the 2D image and the 3D image.</p><p id="p0010" num="0010">The 3D image acquiring unit may acquire the 3D image of the target object by combining a plurality of pieces of image data that are acquired for each cycle of an ultrasound having a predetermined period.</p><p id="p0011" num="0011">The cross-section selection unit may comprise a window producing unit which produces at least one window which is to be located on the acquired 3D image, and a window control unit which moves the at least one window produced on the 3D image.<!-- EPO <DP n="3"> --></p><p id="p0012" num="0012">The at least one cross-section may be selected from the 3D image of the target object by the cross-section selection unit so as to correspond to the location of the at least one window moved on the 3D image.</p><p id="p0013" num="0013">The 2D image acquiring unit may acquire at least one 2D image by scanning the target object in the scan direction of the selected at least one cross-section.</p><p id="p0014" num="0014">The display unit may display the 2D image and the 3D image.</p><p id="p0015" num="0015">The cross-section selection unit may further comprise an additional cross-section selection unit which additionally selects at least another cross-section adjacent to the selected at least one cross-section.</p><p id="p0016" num="0016">The adjacent at least one cross-section may be a cross-section that is a predetermined distance separated from the at least one cross-section selected from the 3D image.</p><p id="p0017" num="0017">The 2D image acquiring unit may comprise a first image acquiring unit which acquires at least one first 2D image by scanning the target object such as to obtain the selected at least one cross-section, a second image acquiring unit which acquires at least one second 2D image by scanning the target object such as to obtain the at least another cross-section adjacent to the selected at least one cross-section, and a synthesized image acquiring unit which acquires at least one synthesized 2D image by synthesizing the at least one first 2D image and the at least one second 2D image.</p><p id="p0018" num="0018">The display unit may display the synthesized 2D image and the acquired 3D image.</p><p id="p0019" num="0019">According to another aspect of the present invention, there is provided a method of displaying a 3D ultrasonic image and a 2D ultrasonic image, the method comprising: acquiring a 3D image of a target object; selecting at least one cross-section of the target object based on an external input for the acquired 3D image; acquiring a 2D image by scanning the target object such as to obtain the selected at least one cross-section; and displaying the 2D image and the 3D image.</p><p id="p0020" num="0020">The acquiring of the 3D image may comprise acquiring the 3D image of the target object by combining a plurality of pieces of image data that are acquired for each cycle of an ultrasound having a predetermined period.</p><p id="p0021" num="0021">The selecting of the at least one cross-section may comprise producing at least one window which is to be located on the acquired 3D image, and moving the at least one window produced on the 3D image.<!-- EPO <DP n="4"> --></p><p id="p0022" num="0022">The at least one cross-section may be selected from the 3D image of the target object so as to correspond to the location of the at least one window moved on the 3D image.</p><p id="p0023" num="0023">The acquiring of the 2D image may comprise acquiring at least one 2D image by scanning the target object in the scan direction of the selected at least one cross-section.</p><p id="p0024" num="0024">The displaying may comprise displaying the 2D image and the 3D image.</p><p id="p0025" num="0025">The selecting of the at least one cross-section may further comprise additionally selecting at least another cross-section adjacent to the selected at least one cross-section.</p><p id="p0026" num="0026">The adjacent at least one cross-section may be a cross-section that is a predetermined distance separated from the at least one cross-section selected from the 3D image.</p><p id="p0027" num="0027">The acquiring of the 2D image may comprise acquiring at least one first 2D image by scanning the target object such as to obtain the selected at least one cross-section, acquiring at least one second 2D image by scanning the target object such as to obtain the at least another cross-section adjacent to the selected at least one cross-section, and acquiring at least one synthesized 2D image by synthesizing the at least one first 2D image and the at least one second 2D image.</p><p id="p0028" num="0028">The displaying may comprise displaying the synthesized 2D image and the 3D image together.</p><p id="p0029" num="0029">According to another aspect of the present invention, there is provided a computer-readable recording medium having recorded thereon a program for executing the above-described method.</p><heading id="h0006"><u>BRIEF DESCRIPTION OF THE DRAWINGS</u></heading><p id="p0030" num="0030">The above and other features and advantages of the present invention will become more apparent by describing in detail exemplary embodiments thereof with reference to the attached drawings in which:
<ul><li><figref idrefs="f0001">FIG. 1</figref> is a block diagram of an apparatus for displaying a three-dimensional (3D) ultrasonic image and a two-dimensional (2D) ultrasonic image, according to an embodiment of the present invention;</li><li><figref idrefs="f0002">FIG. 2A</figref> illustrates an example of 3D image acquisition;<!-- EPO <DP n="5"> --></li><li><figref idrefs="f0003">FIG. 2B</figref> illustrates 3D image acquisition according to an embodiment of the present invention;</li><li><figref idrefs="f0003">FIG. 3</figref> is a block diagram of a cross-section selection unit included in the apparatus illustrated in <figref idrefs="f0001">FIG. 1</figref>, according to an embodiment of the present invention;</li><li><figref idrefs="f0004">FIG. 4</figref> illustrates 2D image acquisition according to an embodiment of the present invention;</li><li><figref idrefs="f0005">FIG. 5</figref> is a block diagram of an apparatus for displaying a 3D ultrasonic image and a 2D ultrasonic image, according to another embodiment of the present invention;</li><li><figref idrefs="f0006">FIG. 6</figref> illustrates acquisition of a synthesized 2D image according to an embodiment of the present invention;</li><li><figref idrefs="f0006">FIG. 7</figref> is a flowchart of a method of displaying a 3D ultrasonic image and a 2D ultrasonic image, according to an embodiment of the present invention; and</li><li><figref idrefs="f0007">FIG. 8</figref> is a flowchart of a method of displaying a 3D ultrasonic image and a 2D ultrasonic image, according to another embodiment of the present invention.</li></ul></p><heading id="h0007"><u>DETAILED DESCRIPTION OF THE INVENTION</u></heading><p id="p0031" num="0031">Terminology used herein will now be briefly described, and the present invention will be described in detail.</p><p id="p0032" num="0032">Although general terms being widely used at present were selected as terminology used in the present invention while considering the functions of the present invention, they may vary according to intentions of one of ordinary skill in the art, judicial precedents, the advent of new technologies, and the like. Terms arbitrarily selected by the applicant of the present invention may also be used in a specific case. In this case, their meanings need to be given in the detailed description of the present invention. Hence, the terms must be defined based on the meanings of the terms and the contents of the entire specification, not by simply stating the terms themselves.</p><p id="p0033" num="0033">It will be understood that the terms "comprises" and/or "comprising" or "includes" and/or "including" when used in this specification, specify the presence of stated elements, but do not preclude the presence or addition of one or more other elements. Terms such as "... unit" and "module" stated in the specification denote units that process at least one function or operation, and they may be implemented by using hardware, software, or a combination of hardware and software.<!-- EPO <DP n="6"> --></p><p id="p0034" num="0034">In the entire specification, an "ultrasonic image" denotes an image of a target object that is acquired using ultrasounds. The target object may denote a part of a human body. For example, the target object may be an organ, such as a liver, a heart, a womb, a brain, a breast, or an abdomen, or a fetus.</p><p id="p0035" num="0035">In the entire specification, a "user" may be a medical expert, such as a doctor, a nurse, a medical technologist, or a medical image expert, but the present invention is not limited thereto.</p><p id="p0036" num="0036">The present invention will now be described more fully with reference to the accompanying drawings, in which exemplary embodiments of the invention are shown. The invention may, however, be embodied in many different forms and should not be construed as being limited to the embodiments set forth herein. In the drawings, parts irrelevant to the description are omitted for simplicity of explanation, and like numbers refer to like elements throughout.</p><p id="p0037" num="0037"><figref idrefs="f0001">FIG. 1</figref> is a block diagram of an apparatus 1000 for displaying a three-dimensional (3D) ultrasonic image and a two-dimensional (2D) ultrasonic image, according to an embodiment of the present invention.</p><p id="p0038" num="0038">Referring to <figref idrefs="f0001">FIG. 1</figref>, the apparatus 1000 may include a 3D image acquiring unit 1100, which acquires a 3D image of a target object, a cross-section selection unit 1200, which selects at least one cross-section of the target object based on an external input for the acquired 3D image, a 2D image acquiring unit 1300, which acquires a 2D image by scanning the target object such as to obtain the selected cross-section, and a display unit 1400, which displays the 2D image and the 3D image.</p><p id="p0039" num="0039"><figref idrefs="f0002">FIG. 2A</figref> illustrates an example of 3D image acquisition.</p><p id="p0040" num="0040">For example, the 3D image acquiring unit 1100 may radiate an ultrasound to the target object within a predetermined region 220 of a probe 210 and may acquire a 3D image 230 in response to an echo signal of the radiated ultrasound. Such a 3D image may include an image that voluminously expresses the whole or a part of the target object.</p><p id="p0041" num="0041"><figref idrefs="f0003">FIG. 2B</figref> illustrates acquisition of the 3D image 230 according to an embodiment of the present invention.</p><p id="p0042" num="0042">The 3D image acquiring unit 1100 may acquire the 3D image 230 of the target object by combining a plurality of pieces of image data that are acquired for each cycle of an ultrasound having a predetermined period.<!-- EPO <DP n="7"> --></p><p id="p0043" num="0043">For example, as illustrated in <figref idrefs="f0003">FIG. 2B</figref>, the 3D image 230 of the target object may be acquired by combining a plurality of pieces of image data acquired for each cycle of an ultrasonic signal having a predetermined period. For example, an ultrasonic image 231 of a first part may be acquired from an echo signal corresponding to a section of a first cycle of an ultrasonic signal transmitted toward a target object, namely, a first section ①. An ultrasonic image 232 of a second part may be acquired from an echo signal corresponding to a second section (②) of the ultrasonic signal. Similarly, an ultrasonic image 233 of a third part and an ultrasonic image 234 of a fourth part may be respectively acquired from an echo signal corresponding to a third section ③ of the ultrasonic signal and an echo signal corresponding to a fourth section ④ of the ultrasonic signal.</p><p id="p0044" num="0044">The acquired ultrasonic images 231 through 234, namely, a plurality of acquired pieces of image data, may be combined to generate a combined image, by using a conventional image matching technique or the like. The combined image may include the 3D image 230 for the whole or a part of the target object, as illustrated in <figref idrefs="f0003">FIG. 2B</figref>.</p><p id="p0045" num="0045"><figref idrefs="f0003">FIG. 3</figref> is a block diagram of the cross-section selection unit 1200 of <figref idrefs="f0001">FIG. 1</figref>, according to an embodiment of the present invention. <figref idrefs="f0004">FIG. 4</figref> illustrates 2D image acquisition according to an embodiment of the present invention.</p><p id="p0046" num="0046">Referring to <figref idrefs="f0003">FIG. 3</figref>, the cross-section selection unit 1200 may include a window producing unit 1210, which produces at least one window which is to be located on the acquired 3D image 230, and a window control unit 1220, which moves the window produced on the 3D image 230.</p><p id="p0047" num="0047">At least one cross-section may be selected from the 3D image 230 by the cross-section selection unit 1200 so as to correspond to the location of at least one window, namely, windows 410 and 420, moved on the 3D image 230.</p><p id="p0048" num="0048">For example, referring to <figref idrefs="f0004">FIG. 4</figref>, at least one cross-section may be selected using the windows 410 and 420, which are movable on the 3D image 230 captured from the target object. The at least one cross-section may include a cross-section that includes a region of the target object that a user wants to observe with interest via a 2D image. In other words, the at least one cross-section may include a cross-section for acquiring a 2D image of the target object.</p><p id="p0049" num="0049">As illustrated in <figref idrefs="f0004">FIG. 4</figref>, the windows 410 and 420 may be moved on the 3D image 230 by a control signal applied to the window control unit 1220, based on an<!-- EPO <DP n="8"> --> external input signal received from a user input unit (not shown). Then, at least one cross-section that traverses the target object may be determined by the movable windows 410 and 420, and the determined cross-sections may be selected by the cross-section selection unit 1200 to serve as cross-sections for acquiring 2D images.</p><p id="p0050" num="0050">The 2D image acquiring unit 1300 may acquire at least one 2D image by scanning the target object in the scan directions of the selected cross-sections.</p><p id="p0051" num="0051">As illustrated in <figref idrefs="f0004">FIG. 4</figref>, the 2D image acquiring unit 1300 may acquire at least one 2D image, namely, 2D images 241 and 242, by scanning the target object in scan directions P1 and P2 of the cross-sections selected by the cross-section selection unit 1200. The 3D image 230 may comprise a 3D ultrasound image, and the 2D images 241 and 242 may comprise 2D ultrasound images.</p><p id="p0052" num="0052">In other words, the 2D images 241 and 242 may be acquired by scanning the target object in radiation directions corresponding to the selected cross-sections (for example, the scan directions P1 and P2) from among directions in which an ultrasonic signal is radiated within a predetermined range by a probe 210 toward the target object. For example, the 2D image 241 may be acquired by scanning the target object in a scan direction (for example, the scan direction P1) corresponding to the cross-section determined by the windows 410. Similarly, the 2D image 242 may be acquired by scanning the target object in the scan direction P2.</p><p id="p0053" num="0053">The display unit 1400 may display the acquired 2D image and the acquired 3D image together. For example, as illustrated in <figref idrefs="f0004">FIG. 4</figref>, the 2D images 241 and 242 acquired by scanning the target object in the directions corresponding to the selected cross-sections may be displayed together with the 3D image 230, on the display unit 1400. In other words, the 2D images 241 and 242 and the 3D image 230 may be simultaneously displayed on the display unit 1400.</p><p id="p0054" num="0054"><figref idrefs="f0005">FIG. 5</figref> is a block diagram of an apparatus 1000 for displaying a 3D ultrasonic image and a 2D ultrasonic image, according to another embodiment of the present invention.</p><p id="p0055" num="0055">Referring to <figref idrefs="f0005">FIG. 5</figref>, the cross-section selection unit 1200 may further include an additional cross-section selection unit 1230, which additionally selects at least another cross-section adjacent to the selected one cross-section, in addition to the window producing unit 1210 and the window control unit 1220 of <figref idrefs="f0003">FIG. 3</figref>. The adjacent one cross-section may include a cross-section that is a predetermined distance separated from the cross-section selected from the 3D image.<!-- EPO <DP n="9"> --></p><p id="p0056" num="0056"><figref idrefs="f0006">FIG. 6</figref> illustrates acquisition of a synthesized 2D image according to an embodiment of the present invention.</p><p id="p0057" num="0057">When the cross-sections are determined and selected based on the windows 410 and 420 by the window control unit 1220, the cross-section selection unit 1200 may additionally select cross-sections adjacent to the selected at least one cross-section.</p><p id="p0058" num="0058">Referring to <figref idrefs="f0006">FIG. 6</figref>, when cross-sections based on the windows 410 and 420 are determined, at least one window, namely, windows 411 and 421, separated from the determined cross-sections by a predetermined distance may be additionally produced by the window producing unit 1210. At least one 2D image may be acquired by scanning the target object, as described above, in the scan directions corresponding to cross-sections determined by the additional windows 411 and 421.</p><p id="p0059" num="0059">Referring to <figref idrefs="f0005">FIG. 5</figref>, the 2D image acquiring unit 1300 may include a first image acquiring unit 1310, which acquires at least one first 2D image by scanning the target object such as to obtain the selected cross-section, a second image acquiring unit 1320, which acquires at least one second 2D image by scanning the target object such as to obtain at least one cross-section adjacent to the selected cross-section, and a synthesized image acquiring unit 1330, which acquires at least one synthesized 2D image by synthesizing the first 2D image and the second 2D image.</p><p id="p0060" num="0060">For example, as illustrated in <figref idrefs="f0004">FIG. 4</figref>, the first 2D images may be acquired by scanning the target object in ultrasound radiation directions, namely, the scan directions P1 and P2, corresponding to the windows 410 and 420. The second 2D images may be acquired by scanning the target object in ultrasound scan directions P1' and P2' corresponding to the additional windows 411 and 421, which are respectively adjacent to the windows 410 and 420.</p><p id="p0061" num="0061">The synthesized image acquiring unit 1330 may acquire the synthesized 2D image by synthesizing the acquired first 2D image and the acquired second 2D image by using a conventional image synthesizing technique or the like. For example, a voluminous 2D image 241 may be acquired by synthesizing the first and second 2D images which have been respectively acquired by scanning the target object in the scan directions corresponding to the windows 410 and 411. Similarly, a voluminous 2D image 242 may be acquired by synthesizing images which have been respectively acquired by scanning the target object in the scan directions corresponding to the<!-- EPO <DP n="10"> --> windows 420 and 421. The voluminous 2D images 241 and 242 may be referred to as synthesized 2D images.</p><p id="p0062" num="0062">The display unit 1400 may display such a synthesized 2D image and a 3D image together. In other words, as illustrated in <figref idrefs="f0006">FIG. 6</figref>, the voluminous 2D images 241 and 242 and the 3D image 230 may be simultaneously displayed on the display unit 1400.</p><p id="p0063" num="0063"><figref idrefs="f0006">FIG. 7</figref> is a flowchart of a method of displaying a 3D image 230 and a 2D image 241 or 242, according to an embodiment of the present invention.</p><p id="p0064" num="0064">Referring to <figref idrefs="f0006">FIG. 7</figref>, the method may include operation S100 of acquiring a 3D image of a target object, operation S200 of selecting at least one cross-section of the target object based on an external input for the acquired 3D image, operation S300 of acquiring a 2D image by scanning the target object such as to obtain the selected cross-section, and operation S400 of displaying the 2D image and the 3D image.</p><p id="p0065" num="0065">Operation S100 may include acquiring the 3D image 230 of the target object by combining a plurality of pieces of image data that are acquired for each cycle of an ultrasound having a predetermined period.</p><p id="p0066" num="0066">Operation S200 may include the operations of producing at least one window which is to be located on the acquired 3D image 230 and moving the window produced on the 3D image 230.</p><p id="p0067" num="0067">The at least one cross-section may be selected from the 3D image 230 of the target object by the cross-section selection unit 1200 so as to correspond to the location of the at least one window moved on the 3D image 230.</p><p id="p0068" num="0068">Operation S300 may include acquiring at least one 2D image by scanning the target object in the scan direction of the selected cross-section.</p><p id="p0069" num="0069">Operation S400 may include displaying the acquired 2D image and the acquired 3D image 230 together.</p><p id="p0070" num="0070">FIG. 9 is a flowchart of a method of displaying a 3D ultrasonic image and a 2D ultrasonic image, according to another embodiment of the present invention.</p><p id="p0071" num="0071">Referring to <figref idrefs="f0007">FIG. 8</figref>, operation S200 may further include operation S21 0 of additionally selecting at least one cross-section adjacent to the selected cross-section, in addition to the producing of the at least one window and the moving of the produced window of <figref idrefs="f0006">FIG. 7</figref>. The adjacent cross-section may include a cross-section that is a predetermined distance separated from the cross-section selected from the 3D image 230.<!-- EPO <DP n="11"> --></p><p id="p0072" num="0072">Operation S300 may include operation S310 of acquiring at least one first 2D image by scanning the target object such as to obtain the selected cross-section, operation S320 of acquiring at least one second 2D image by scanning the target object such as to obtain at least one cross-section adjacent to the selected cross-section, and operation S330 of acquiring at least one synthesized 2D image by synthesizing the first 2D image and the second 2D image.</p><p id="p0073" num="0073">In operation S41 0, the synthesized 2D image and the acquired 3D image are displayed together.</p><p id="p0074" num="0074">The contents of the above-described apparatuses of <figref idrefs="f0001">FIGS. 1</figref> and <figref idrefs="f0005">5</figref> may be equally applied to the methods of <figref idrefs="f0006">FIGS. 7</figref> and <figref idrefs="f0007">8</figref>. Accordingly, descriptions of the above-described apparatuses 1000 of <figref idrefs="f0001">FIGS. 1</figref> and <figref idrefs="f0005">5</figref> related to the methods of <figref idrefs="f0006">FIGS. 7</figref> and <figref idrefs="f0007">8</figref> will not be repeated here.</p><p id="p0075" num="0075">The above-described embodiments of the present invention may be written as computer programs and may be implemented in general-use digital computers that execute the programs using a computer readable recording medium.</p><p id="p0076" num="0076">Examples of the computer readable recording medium include magnetic storage media (e.g., ROM, floppy disks, hard disks, etc.), optical recording media (e.g., CD-ROMs, or DVDs), etc.</p><p id="p0077" num="0077">Up to now, the present invention has been described by referring to exemplary embodiments. While the exemplary embodiments have been particularly shown and described, it will be understood by those of ordinary skill in the art that various changes in form and details may be made therein without departing from the spirit and scope of the present invention as defined by the appended claims. Therefore, the exemplary embodiments should be considered in descriptive sense only and not for purposes of limitation. Therefore, the scope of the present invention is defined not by the detailed description of exemplary embodiments, but by the appended claims, and all differences within the scope will be construed as being included in the present invention.</p></description><claims mxw-id="PCLM56982756" lang="EN" load-source="patent-office"><!-- EPO <DP n="12"> --><claim id="c-en-0001" num="0001"><claim-text>An apparatus for displaying a three-dimensional (3D) ultrasonic image and a two-dimensional (2D) ultrasonic image, the apparatus comprising:
<claim-text>a 3D image acquiring unit which acquires a 3D image of a target object;</claim-text>
<claim-text>a cross-section selection unit which selects at least one cross-section of the target object based on an external input for the acquired 3D image;</claim-text>
<claim-text>a 2D image acquiring unit which acquires a 2D image by scanning the target object such as to obtain the selected at least one cross-section; and</claim-text>
<claim-text>a display unit which displays the 2D image and the 3D image.</claim-text></claim-text></claim><claim id="c-en-0002" num="0002"><claim-text>The apparatus of claim 1, wherein the 3D image acquiring unit acquires the 3D image of the target object by combining a plurality of pieces of image data that are acquired for each cycle of an ultrasound having a predetermined period.</claim-text></claim><claim id="c-en-0003" num="0003"><claim-text>The apparatus of claim 1, wherein<br/>
the cross-section selection unit comprises:
<claim-text>a window producing unit which produces at least one window which is to be located on the acquired 3D image; and</claim-text>
<claim-text>a window control unit which moves the at least one window produced on the 3D image, and</claim-text>
the at least one cross-section is selected from the 3D image of the target object by the cross-section selection unit so as to correspond to the location of the at least one window moved on the 3D image.</claim-text></claim><claim id="c-en-0004" num="0004"><claim-text>The apparatus of claim 1, wherein the 2D image acquiring unit acquires at least one 2D image by scanning the target object in the scan direction of the selected at least one cross-section.</claim-text></claim><claim id="c-en-0005" num="0005"><claim-text>The apparatus of claim 4, wherein the display unit displays the 2D image and the 3D image.<!-- EPO <DP n="13"> --></claim-text></claim><claim id="c-en-0006" num="0006"><claim-text>The apparatus of claim 1, wherein<br/>
the cross-section selection unit further comprises an additional cross-section selection unit which additionally selects at least another cross-section adjacent to the selected at least one cross-section, and<br/>
the adjacent at least one cross-section is a cross-section that is a predetermined distance separated from the at least one cross-section selected from the 3D image.</claim-text></claim><claim id="c-en-0007" num="0007"><claim-text>The apparatus of claim 6, wherein the 2D image acquiring unit comprises:
<claim-text>a first image acquiring unit which acquires at least one first 2D image by scanning the target object such as to obtain the selected at least one cross-section;</claim-text>
<claim-text>a second image acquiring unit which acquires at least one second 2D image by scanning the target object such as to obtain the at least another cross-section adjacent to the selected at least one cross-section; and</claim-text>
<claim-text>a synthesized image acquiring unit which acquires at least one synthesized 2D image by synthesizing the at least one first 2D image and the at least one second 2D image.</claim-text></claim-text></claim><claim id="c-en-0008" num="0008"><claim-text>The apparatus of claim 7, wherein the display unit displays the synthesized 2D image and the acquired 3D image.</claim-text></claim><claim id="c-en-0009" num="0009"><claim-text>A method of displaying a 3D ultrasonic image and a 2D ultrasonic image, the method comprising:
<claim-text>acquiring a 3D image of a target object;</claim-text>
<claim-text>selecting at least one cross-section of the target object based on an external input for the acquired 3D image;</claim-text>
<claim-text>acquiring a 2D image by scanning the target object such as to obtain the selected at least one cross-section; and</claim-text>
<claim-text>displaying the 2D image and the 3D image.</claim-text></claim-text></claim><claim id="c-en-0010" num="0010"><claim-text>The method of claim 9, wherein the acquiring of the 3D image comprises acquiring the 3D image of the target object by combining a plurality of<!-- EPO <DP n="14"> --> pieces of image data that are acquired for each cycle of an ultrasound having a predetermined period.</claim-text></claim><claim id="c-en-0011" num="0011"><claim-text>The method of claim 9, wherein<br/>
the selecting of the at least one cross-section comprises:
<claim-text>producing at least one window which is to be located on the acquired 3D image; and</claim-text>
<claim-text>moving the at least one window produced on the 3D image, and</claim-text>
the at least one cross-section is selected from the 3D image of the target object so as to correspond to the location of the at least one window moved on the 3D image.</claim-text></claim><claim id="c-en-0012" num="0012"><claim-text>The method of claim 9, wherein the acquiring of the 2D image comprises acquiring at least one 2D image by scanning the target object in the scan direction of the selected at least one cross-section.</claim-text></claim><claim id="c-en-0013" num="0013"><claim-text>The method of claim 12, wherein the displaying comprises displaying the 2D image and the 3D image.</claim-text></claim><claim id="c-en-0014" num="0014"><claim-text>The method of claim 9, wherein<br/>
the selecting of the at least one cross-section further comprises additionally selecting at least another cross-section adjacent to the selected at least one cross-section, and<br/>
the adjacent at least one cross-section is a cross-section that is a predetermined distance separated from the at least one cross-section selected from the 3D image.</claim-text></claim><claim id="c-en-0015" num="0015"><claim-text>A non-transitory computer-readable recording medium having recorded thereon a program for executing the method of any of claims 9 through 14.</claim-text></claim></claims><drawings mxw-id="PDW16671093" load-source="patent-office"><!-- EPO <DP n="15"> --><figure id="f0001" num="1"><img id="if0001" file="imgf0001.tif" wi="124" he="136" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="16"> --><figure id="f0002" num="2A"><img id="if0002" file="imgf0002.tif" wi="126" he="196" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="17"> --><figure id="f0003" num="2B,3"><img id="if0003" file="imgf0003.tif" wi="163" he="227" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="18"> --><figure id="f0004" num="4"><img id="if0004" file="imgf0004.tif" wi="163" he="227" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="19"> --><figure id="f0005" num="5"><img id="if0005" file="imgf0005.tif" wi="150" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="20"> --><figure id="f0006" num="6,7"><img id="if0006" file="imgf0006.tif" wi="143" he="227" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="21"> --><figure id="f0007" num="8"><img id="if0007" file="imgf0007.tif" wi="160" he="211" img-content="drawing" img-format="tif"/></figure></drawings><search-report-data><doc-page id="srep0001" file="srep0001.tif" wi="159" he="233" type="tif"/><doc-page id="srep0002" file="srep0002.tif" wi="165" he="232" type="tif"/></search-report-data><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
