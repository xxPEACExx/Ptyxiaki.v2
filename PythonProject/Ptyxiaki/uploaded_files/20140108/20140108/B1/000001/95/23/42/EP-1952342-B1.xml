<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-1952342-B1" country="EP" doc-number="1952342" kind="B1" date="20140108" family-id="37966456" file-reference-id="306745" date-produced="20180826" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="146588784" ucid="EP-1952342-B1"><document-id><country>EP</country><doc-number>1952342</doc-number><kind>B1</kind><date>20140108</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-06831884-A" is-representative="NO"><document-id mxw-id="PAPP154850976" load-source="docdb" format="epo"><country>EP</country><doc-number>06831884</doc-number><kind>A</kind><date>20061116</date><lang>EN</lang></document-id><document-id mxw-id="PAPP220134044" load-source="docdb" format="original"><country>EP</country><doc-number>06831884.9</doc-number><date>20061116</date></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC140552753" ucid="EP-05300934-A" load-source="docdb"><document-id format="epo"><country>EP</country><doc-number>05300934</doc-number><kind>A</kind><date>20051117</date></document-id></priority-claim><priority-claim mxw-id="PPC140557592" ucid="EP-06831884-A" load-source="docdb"><document-id format="epo"><country>EP</country><doc-number>06831884</doc-number><kind>A</kind><date>20061116</date></document-id></priority-claim><priority-claim mxw-id="PPC140551125" ucid="IB-2006054297-W" linkage-type="W" load-source="docdb"><document-id format="epo"><country>IB</country><doc-number>2006054297</doc-number><kind>W</kind><date>20061116</date></document-id></priority-claim></priority-claims><dates-of-public-availability><intention-to-grant-date><date>20130702</date></intention-to-grant-date></dates-of-public-availability><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL1989326633" load-source="docdb">G06T  15/10        20110101AFI20130604BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL1989620152" load-source="docdb" scheme="CPC">G06T  15/10        20130101 FI20130101BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT132370985" lang="DE" load-source="patent-office">VERFAHREN ZUM ANZEIGEN VON HOCHAUFLÖSENDEN BILDDATEN ZUSAMMEN MIT ZEITVERÄNDERLICHEN BILDDATEN MIT GERINGER AUFLÖSUNG</invention-title><invention-title mxw-id="PT132370986" lang="EN" load-source="patent-office">METHOD FOR DISPLAYING HIGH RESOLUTION IMAGE DATA TOGETHER WITH TIME-VARYING LOW RESOLUTION IMAGE DATA</invention-title><invention-title mxw-id="PT132370987" lang="FR" load-source="patent-office">MÉTHODE D AFFICHAGE DE DONNÉES IMAGE À HAUTE RÉSOLUTION CONJOINTEMENT AVEC DES DONNÉES IMAGE À BASSE RÉSOLUTION VARIANT DANS LE TEMPS</invention-title><citations><patent-citations><patcit mxw-id="PCIT370556486" load-source="docdb" ucid="EP-1434171-A2"><document-id format="epo"><country>EP</country><doc-number>1434171</doc-number><kind>A2</kind><date>20040630</date></document-id><sources><source name="EXA" created-by-npl="N"/></sources></patcit></patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR919525121" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>PHILIPS INTELLECTUAL PROPERTY</last-name><address><country>DE</country></address></addressbook></applicant><applicant mxw-id="PPAR919520686" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>PHILIPS INTELLECTUAL PROPERTY &amp; STANDARDS GMBH</last-name></addressbook></applicant><applicant mxw-id="PPAR919536893" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>KONINKL PHILIPS NV</last-name><address><country>NL</country></address></addressbook></applicant><applicant mxw-id="PPAR919529983" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>KONINKLIJKE PHILIPS N.V.</last-name></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR919526479" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>WEIBRECHT MARTIN</last-name><address><country>NL</country></address></addressbook></inventor><inventor mxw-id="PPAR919514529" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>WEIBRECHT, MARTIN</last-name></addressbook></inventor><inventor mxw-id="PPAR919024723" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>WEIBRECHT, MARTIN</last-name><address><street>PHILIPS IP &amp; S - NL Prof. Holstlaan 6</street><city>NL-5656AA Eindhoven</city><country>NL</country></address></addressbook></inventor><inventor mxw-id="PPAR919536451" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>ECABERT OLIVIER</last-name><address><country>NL</country></address></addressbook></inventor><inventor mxw-id="PPAR919528866" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>ECABERT, OLIVIER</last-name></addressbook></inventor><inventor mxw-id="PPAR919024725" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>ECABERT, OLIVIER</last-name><address><street>PHILIPS IP &amp; S - NL Prof. Holstlaan 6</street><city>NL-5656AA Eindhoven</city><country>NL</country></address></addressbook></inventor><inventor mxw-id="PPAR919525828" load-source="docdb" sequence="3" format="epo"><addressbook><last-name>WEESE JUERGEN</last-name><address><country>NL</country></address></addressbook></inventor><inventor mxw-id="PPAR919525273" load-source="docdb" sequence="3" format="intermediate"><addressbook><last-name>WEESE, JUERGEN</last-name></addressbook></inventor><inventor mxw-id="PPAR919024722" load-source="patent-office" sequence="3" format="original"><addressbook><last-name>WEESE, JUERGEN</last-name><address><street>PHILIPS IP &amp; S - NL Prof. Holstlaan</street><city>NL-5656 AA Eindhoven</city><country>NL</country></address></addressbook></inventor><inventor mxw-id="PPAR919522435" load-source="docdb" sequence="4" format="epo"><addressbook><last-name>KIEFER GUNDOLF</last-name><address><country>NL</country></address></addressbook></inventor><inventor mxw-id="PPAR919531009" load-source="docdb" sequence="4" format="intermediate"><addressbook><last-name>KIEFER, GUNDOLF</last-name></addressbook></inventor><inventor mxw-id="PPAR919024724" load-source="patent-office" sequence="4" format="original"><addressbook><last-name>KIEFER, GUNDOLF</last-name><address><street>PHILIPS IP &amp; S - NL Prof. Holstlaan</street><city>NL-5656AA Eindhoven</city><country>NL</country></address></addressbook></inventor></inventors><assignees><assignee mxw-id="PPAR919024726" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Philips Intellectual Property &amp; Standards GmbH</last-name><iid>100198668</iid><address><street>Steindamm 94</street><city>20099 Hamburg</city><country>DE</country></address></addressbook></assignee><assignee mxw-id="PPAR919024728" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>Koninklijke Philips N.V.</last-name><iid>101391185</iid><address><street>High Tech Campus 5</street><city>5656 AE Eindhoven</city><country>NL</country></address></addressbook></assignee></assignees><agents><agent mxw-id="PPAR919024727" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Verweij, Petronella Danielle</last-name><suffix>et al</suffix><iid>101323122</iid><address><street>Philips Intellectual Property &amp; Standards P.O. Box 220</street><city>5600 AE Eindhoven</city><country>NL</country></address></addressbook></agent></agents></parties><international-convention-data><pct-or-regional-filing-data ucid="IB-2006054297-W"><document-id><country>IB</country><doc-number>2006054297</doc-number><kind>W</kind><date>20061116</date><lang>EN</lang></document-id></pct-or-regional-filing-data><pct-or-regional-publishing-data ucid="WO-2007057855-A2"><document-id><country>WO</country><doc-number>2007057855</doc-number><kind>A2</kind><date>20070524</date><lang>EN</lang></document-id></pct-or-regional-publishing-data><designated-states><ep-contracting-states><country mxw-id="DS549788483" load-source="docdb">AT</country><country mxw-id="DS549925371" load-source="docdb">BE</country><country mxw-id="DS549896709" load-source="docdb">BG</country><country mxw-id="DS549884012" load-source="docdb">CH</country><country mxw-id="DS549925372" load-source="docdb">CY</country><country mxw-id="DS549790140" load-source="docdb">CZ</country><country mxw-id="DS549805504" load-source="docdb">DE</country><country mxw-id="DS549925373" load-source="docdb">DK</country><country mxw-id="DS549925374" load-source="docdb">EE</country><country mxw-id="DS549873362" load-source="docdb">ES</country><country mxw-id="DS549896710" load-source="docdb">FI</country><country mxw-id="DS549896711" load-source="docdb">FR</country><country mxw-id="DS549805505" load-source="docdb">GB</country><country mxw-id="DS549925375" load-source="docdb">GR</country><country mxw-id="DS549790149" load-source="docdb">HU</country><country mxw-id="DS549884013" load-source="docdb">IE</country><country mxw-id="DS549925376" load-source="docdb">IS</country><country mxw-id="DS549896712" load-source="docdb">IT</country><country mxw-id="DS549925377" load-source="docdb">LI</country><country mxw-id="DS549896717" load-source="docdb">LT</country><country mxw-id="DS549788484" load-source="docdb">LU</country><country mxw-id="DS549896718" load-source="docdb">LV</country><country mxw-id="DS549896719" load-source="docdb">MC</country><country mxw-id="DS549896720" load-source="docdb">NL</country><country mxw-id="DS549896725" load-source="docdb">PL</country><country mxw-id="DS549873363" load-source="docdb">PT</country><country mxw-id="DS549805506" load-source="docdb">RO</country><country mxw-id="DS549896726" load-source="docdb">SE</country><country mxw-id="DS549880368" load-source="docdb">SI</country><country mxw-id="DS549884026" load-source="docdb">SK</country><country mxw-id="DS549925378" load-source="docdb">TR</country></ep-contracting-states></designated-states></international-convention-data><office-specific-data><eptags><ep-no-a-document-published>*</ep-no-a-document-published></eptags></office-specific-data></bibliographic-data><description mxw-id="PDES63961202" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><p id="p0001" num="0001">The present invention relates to a method of displaying high-resolution data together with time-varying lower resolution image data. In particular, it relates to the display of high-resolution structural data together with lower resolution functional data.</p><p id="p0002" num="0002">It is known to use medical imaging techniques, for example computer tomography (CT), to provide structural or anatomical information. This anatomical information can include information about the bones, organs, etc. that are the subject of a CT scan. It is possible to obtain this anatomical image data at a high resolution.</p><p id="p0003" num="0003">It is also known to use medical imaging techniques to give functional information. This information indicates the function of the cells that make up the organs that are the subject of a scan. For example, radioisotope imaging may be used in which radiation originating from radioactive decay is used to determine the local concentration of an administered radioactive tracer in the body. Usually, the functional information is time varying, showing variations in processes over time. Unlike anatomical information, functional information is often of low resolution making it difficult to associate the functional information with a particular part of the anatomy.</p><p id="p0004" num="0004"><patcit id="pcit0001" dnum="US20040044282A1"><text>US-2004/0044282-A1</text></patcit> relates to a medical imaging system and method in which a structural and functional scan are performed in sequence. Firstly, a CT scan of the coronary artery is performed to obtain structural data of the artery. Secondly, a Positron Emission Tomography (PET) scan of the coronary artery is performed to obtain functional data of the artery. The data of the CT scan is then combined with the data of the PET scan to allow structural and functional data to be displayed in a single image. This image can be static or dynamic in nature.<!-- EPO <DP n="2"> --></p><p id="p0005" num="0005">In order to produce a useful dynamic image, it is necessary to display the dynamic data at a sufficiently high and guaranteed frame rate. With present computer hardware it is possible to render the low resolution functional data with sufficient speed to achieve a displayed frame rate of around 20 Hz. However, because of the high resolution of the anatomical scan data, the frame rate is much reduced when fused anatomical and structural data is required. Using the method of <patcit id="pcit0002" dnum="US20040044282A1"><text>US-2004/0044282-A1</text></patcit>, it is necessary to render both the anatomical and functional data for every frame before that frame is displayed. This means that the display of images cannot occur at a smooth frame rate.</p><p id="p0006" num="0006">"<nplcit id="ncit0001" npl-type="s"><text>OsiriX: An open-source software for navigating in multidimensional DICOM images", by A. Rosset et al., in Journal of Digital Imaging, Vol. 17, No. 3, 2004, pp. 205-216</text></nplcit>, discloses a DICOM viewer for multidimensional and multimodality imaging studies. Ultrafast multi-detector CT scanners can add a temporal dimension to data by sequentially acquiring images over time. The cited paper further discloses designing software to allow users to interactively navigate in five dimensions. The cited paper further discloses automatically displaying an images series on the screen in a cine loop using a "streaming" technique.</p><p id="p0007" num="0007">It is therefore an object of the present invention to improve the display of higher resolution data together with lower resolution data.</p><p id="p0008" num="0008">According to a first aspect of the present invention, there is provided a method of displaying first image data having a first resolution together with time-varying second image data having a second resolution which is lower than the first resolution, wherein the time-varying second image data comprises a plurality of second image data sets, with each second image data set representing a different point in time, the method comprising:
<ul><li>merging and rendering the first image data with a first group of second image data using rendering parameters representing a viewpoint to produce a first group of merged image data, wherein the first group of second image data comprises a plurality of second image data sets which are contiguous in time; and<!-- EPO <DP n="3"> --></li><li>displaying the first group of merged image data as a sequence of images on a display;</li><li>wherein, during the step of displaying the first group of merged image data, the step of rendering and merging is repeated with a second group of second image data, and wherein rendering and merging of the second group of functional image data is completed before the step of displaying the first batch of merged image data has completed.</li></ul><!-- EPO <DP n="4"> --></p><p id="p0009" num="0009">The first image data is preferably structural image data and the second image data is preferably functional image data.</p><p id="p0010" num="0010">In this method, the merging and rendering of the first image data with the second image data sets is carried out in groups. The group of merged data is displayed in sequence and during that time a second group of second image data is merged and rendered so that it is ready for display once display of the first group of merged data has completed. This ensures that a consistently smooth frame rate is achieved because one group of images are displayed while the next set of images is being rendered and merged.</p><p id="p0011" num="0011">Preferably the display of a group of merged image data while the next group is being processed is achieved by using a pipeline. The pipeline may be implemented in various ways. For example, the pipeline may be a First In First Out (FIFO) buffer, or may be a dedicated co-processor for used for display.</p><p id="p0012" num="0012">Advantageously, because the method of the present invention allows rendering and merging of several second image data sets in groups with the same first image data, the method can use parallel processing to improve its efficiency. The same operations are required to be carried out on each image in the functional image data group; this makes the method well suited to parallel processing.</p><p id="p0013" num="0013">Optionally, the method may also include receiving user input of a change of viewpoint. In that case, the processing of functional image data in groups allows the displayed image to maintain a constant frame rate despite the change in viewpoint. The time required to render and merge the first image data with the second image data group from the new viewpoint is known. Likewise the time remaining before the previously processed images have all been displayed is also known. A change of viewpoint is only implemented immediately if there is sufficient time for it to be processed before the previously processed images are exhausted. This allows a constant frame rate to be achieved while also allowing the viewpoint to be changed.<!-- EPO <DP n="5"> --> According to a second aspect of the present invention, there is provided a computer program comprising code means that, when executed by a data processor, instructs the data processor to perform the method of the above-described first aspect.</p><p id="p0014" num="0014">According to a third aspect of the present invention, there is provided a computer program product comprising a computer program according to the above-described second aspect embodied on a computer readable medium. Examples of suitable computer readable mediums include an optical storage medium, for example a Compact Disc, a magnetic storage medium, for example a magnetic disc, or a solid-state medium, for example flash memory.</p><p id="p0015" num="0015">According to a fourth aspect of the present invention, there is provided a medical imaging apparatus for displaying first image data having a first resolution together with time-varying second image data having a second resolution which is lower than the first resolution, wherein the time-varying second image data comprises a plurality of second image data sets, with each second image data set representing a different point in time, the apparatus comprising:
<ul><li>a storage device for storing instructions executable by a data processor and for storing first image data and a plurality of second image data sets;</li><li>a data processor which can be configured by the instructions stored in the storage device to execute the steps of:
<ul><li>merging and rendering the first image data with a first group of second image data using rendering parameters representing a viewpoint to produce a first group of merged image data, wherein the first group of second image data comprises a plurality of functional image data sets which are contiguous in time; and</li><li>displaying the first group of merged image data as a sequence of images on a display;</li><li>wherein, during the step of displaying the first group of merged image data, the step of rendering and merging is repeated with a second group of second image data, and wherein rendering and merging of the second group of second image data is completed before the step of displaying the first group of merged image data has completed.</li></ul></li></ul><!-- EPO <DP n="6"> --></p><p id="p0016" num="0016">The first image data is preferably structural image data and the second image data is preferably functional image data.</p><p id="p0017" num="0017">Embodiments of the invention will now be described by way of example with reference to the accompanying drawings, in which:
<ul><li><figref idrefs="f0001">Figure 1</figref> is a diagrammatic representation of the structure of a computer program for implementing the method of the present invention;</li><li><figref idrefs="f0002">Figure 2</figref> is a flow chart of the method of a first embodiment of the present invention;</li><li><figref idrefs="f0003">Figure 3</figref> is a flow chart of a method of handling user input of a change of viewpoint; and</li><li><figref idrefs="f0004">Figure 4</figref> is a flow chart of the method of a second embodiment of the present invention.</li></ul></p><p id="p0018" num="0018">Like reference numerals are used for like parts throughout the drawings.</p><p id="p0019" num="0019"><figref idrefs="f0001">Figure 1</figref> is a diagrammatic representation of the construction of a computer program for implementing a method according to a first embodiment of the present invention. The computer has an input of structural reference data 2 together with more than one functional data sets 4. The structural reference data 2 has a higher resolution than the functional data sets 4. Each functional data set 4 represents a particular point in time. Functional data groups 6 are generated from the functional data 4. Each group contains a number of functional data sets 4 which are contiguous in time.</p><p id="p0020" num="0020">A data fusion and rendering module 8 processes the structural reference data 2 and the functional data groups 6 to produce merged image data, i.e. image data that contains both structural and functional data. A set of rendering parameters 10 is provided to the data fusion and rendering module 8 under the control of a system controller<!-- EPO <DP n="7"> --> module 12. The data fusion and rendering module 8 uses the rendering parameters 10 to generate a series of image data for display. Each image in the series of image data includes data of one functional data set 4 and is displayed as one frame on a display.</p><p id="p0021" num="0021">In this embodiment a First In First Out (FIFO) buffer 14 is provided for storing the image data generated by the data fusion and rendering module 8, although other means may be used in alternate embodiments. The system controller module 12 can determine the status of the FIFO buffer 14 (for example, how many images remain stored) and also controls supply of image data stored in the FIFO buffer 14 to a display controller module 16.</p><p id="p0022" num="0022">The method of the present invention is depicted in <figref idrefs="f0002">Figure 2</figref>. In a first step 20, the functional data sets 4 are divided in groups, with each group comprising a predetermined number of functional image data sets 4. The images in each group are contiguous in time, i.e. the images in the group represent consecutive periods in time. In general, the number of functional image data sets 4 in each group is chosen so that the time to process all the functional image data sets 4 is approximately the same as the time to process the structural reference data 2. To give a numerical example, if the structural reference data 2 can be rendered in approximately one second, and the functional image data rendered in approximately one twentieth of a second then the number of functional images data sets in each group is twenty. It is also possible for the processing time to be split so the processing time for the structural reference data and the functional image data sets is other than the one-to-one relation described above.</p><p id="p0023" num="0023">In a second step 22, the viewpoint from which the data is to be displayed is determined and stored. This viewpoint may be a default viewpoint, which has been pre-selected, or it may alternatively be selected by user input. The viewpoint is stored as rendering parameters 10.</p><p id="p0024" num="0024">In a third step 24, the structural reference data 2 is merged and rendered with each functional image data set 4. This step is carried out by the data fusion and rendering module 8.<!-- EPO <DP n="8"> --></p><p id="p0025" num="0025">In the third step 24 of merging and rendering, the data fusion and rendering module 8 may use a variety of techniques. These can include techniques in which depth relations are taken into account and techniques in which depth relations are not taken into account. In several rendering techniques each pixel of the functional data can be attributed to specific position in the reference volume defined by the structural data. Examples of such techniques include maximum-intensity-projection and iso-surface rendering. In these techniques, the depth of each pixel is stored in data structures known as z-maps. The z-maps are used to merge and render the functional and structural projections with the correct depth relations.</p><p id="p0026" num="0026">Rendering techniques that take depth relations into account, but which do not use z-maps, may also be used. In these techniques the pixels of the projections do not refer to specific positions. An example of such a technique is volume rendering. In volume rendering a plurality of voxels along a ray is used to compose the pixel of the final projection. Therefore, the pixels do not refer to any specific depth in relation to others. In this case, it is necessary for the data fusion and rendering module 8 to merge and render the anatomical and functional data in a three-dimensional space. Preferably, this is achieved efficiently using parallel processing of the functional data sets contained in the functional data group. In that case, it is preferred to represent the functional data group by vectors that can than be processed by a vector processing unit. The elements of each vector refer to the same voxel coordinate at successive times. The complete functional data group is then represented by a three-dimensional array of vectors. This is particularly advantageous because several operations, for example ray-casting and fusion, are performed in the same way on all the functional data sets in the functional data group and thus are well suited for processing in parallel.</p><p id="p0027" num="0027">Which technique is used by the data fusion and rendering module 8 can depend on, for example, the nature of the anatomical and functional data, or on the basis of user input. The system controller 12 can adapt the frame rate at which images are displayed from the FIFO buffer 14 depending on the processing requirements of a particular rendering technique. For example, a computationally intensive rendering<!-- EPO <DP n="9"> --> technique would be displayed at a lower frame rate than a less computationally intensive rendering technique.</p><p id="p0028" num="0028">When all the functional image data sets 4 in the functional image group 6 have been merged and rendered, the merged and rendered data is buffered in the FIFO buffer 14 in step 28. No images are displayed until the data fusion and rendering module 8 has processed the first of the functional data groups 6. The buffered data can then be displayed to a user. The display of data is carried out under the control of the system controller 12 which determines how often the next image is sent from the FIFO buffer 14 to a display, and hence the frame rate of the display.</p><p id="p0029" num="0029">Once a functional data group 6 has been fully processed by the data fusion and rendering module 8 and stored in the FIFO buffer 14, the system controller 12 determines, in step 30, whether any groups remain to be processed. If there are groups remaining to be processed execution returns to step 34. If there are no groups remaining to be processed the method ends at step 32.</p><p id="p0030" num="0030">The system controller 12 can estimate the processing time from the rendering parameters and use this determine the frame rate at which images are retrieved from the FIFO buffer 14 for display. The system controller 12 can therefore ensure that the processing time for the next functional data group is less than or equal to the time taken to display all the images from the FIFO buffer. This results in a display of images at a continuous frame rate substantially free from interruptions or pauses. To give an example, it is possible to process lower resolution data faster than higher resolution data. Therefore, the system controller 12 will control the FIFO buffer 14 to supply to a display images that are rendered from lower resolution data at a higher frame rate than images rendered from higher resolution data.</p><p id="p0031" num="0031">A user is able to interact with the displayed image to alter the rendering parameters, for example to set a different viewpoint. The method by which input from a user of a change of viewpoint is processed is depicted in <figref idrefs="f0003">Figure 3</figref>. When user input of a change in rendering parameters is received in step 40, the resulting rendering<!-- EPO <DP n="10"> --> parameters are stored in step 42. The system controller may also optionally set a flag which indicates that the rendering parameters have changed.</p><p id="p0032" num="0032">In step 44 the system controller 12 checks the number of images yet to be displayed which are contained in the FIFO buffer 14. The frame rate at which the images are displayed is known and therefore the system controller 12 can calculate the time available before the FIFO buffer 14 is empty.</p><p id="p0033" num="0033">In step 46 it is then determined whether there is sufficient time for the structural image data and the functional image data group to be reprocessed with the new rendering parameters. In order to ensure a continuous display with reliable frame rate, the system controller 12 will only discard processing of the current group of images with the current rendering parameters if there is enough time to reprocess with the new rendering parameters. If there is enough time remaining execution proceeds to step 48 which resets the merging and rendering of the structural image data and the functional image data sets and returns execution to step 24 for processing with the new rendering parameters.</p><p id="p0034" num="0034">If there is not enough time for processing execution proceeds to step 50 and the new rendering parameters remain stored for use when the next functional data group is processed. It is possible that further user input of another change of parameters will be received before processing of the next functional data group has begun. In that case, the most recent user input of rendering parameters is stored. I.e. the intermediate rendering parameters are discarded without being processed.</p><p id="p0035" num="0035">In a second embodiment, which is the same as the first save as described below, the data fusion and rendering module 8 does not take depth relations into account. The method of the second embodiment is depicted in <figref idrefs="f0004">Figure 4</figref>. In this embodiment, the step of fusion and rendering comprises two steps 25 and 26. In a step 25, the structural reference data 2 is rendered using the parameters 10. The rendered structural image data is generated by calculating a two-dimensional projection of the structural reference data.<!-- EPO <DP n="11"> --></p><p id="p0036" num="0036">Once the rendered structural image has been calculated, execution proceeds to a step 26. In the step 26, the two-dimensional projection which makes up the rendered structural image is merged with projections of the functional data. Therefore, in this embodiment, the two-dimensional data fusion does not take into account depth relations.</p><p id="p0037" num="0037">If it is determined in step 30 that there are further functional data groups to process, execution proceeds to step 34. In step 34, the system controller determines whether the rendering parameters 10 have changed since the last functional data group was processed. If it is determined that the rendering parameters 10 have changed, execution returns to step 25 to render the structural image data from the new viewpoint. However, if it is determined that the rendering parameters have not changed, the structural image data does not need to be rendered again and execution proceeds to step 26 to merge the rendered structural image data with the next functional image data group.</p><p id="p0038" num="0038">In a third embodiment, which is the same as the second save as described below, step 34 is omitted. In that case processing of the next group is started from step 25 to ensure that any change in the rendering parameters is correctly dealt with.</p><p id="p0039" num="0039">In a fourth embodiment, which is the same as either the second embodiment save as described below, the rendering parameters are determined at the start of the method and cannot be changed by a user. In this embodiment it is not necessary to determine whether the rendering parameters have changed and step 34 can be omitted. When the next functional image data group is processed after step 30, execution can proceed from step 26 because there will be no change in the rendered structural image.</p><p id="p0040" num="0040">In further alternate embodiments, the data fusion and rendering module 8 may use only a single rendering technique and may offer a subset of the rendering techniques described in relation to the first embodiment.</p><p id="p0041" num="0041">The above described embodiments can all be applied to a medical imaging apparatus comprising a storage device and a data processor.<!-- EPO <DP n="12"> --></p><p id="p0042" num="0042">The present invention therefore provides a way of improving the display of anatomical and functional data. By processing and displaying merged data in groups the present invention can generate several fused images of structural and functional data with particular rendering parameters. This group can then be displayed with a predetermined and reliable frame rate. The next group is processed while a previous group is displayed ensuring that a continuous display of data is presented with a reliable frame rate.</p><p id="p0043" num="0043">The embodiments described above may be combined. Throughout this specification "comprising" is used to indicate an inclusive definition and does not preclude the presence of other items.</p></description><claims mxw-id="PCLM56986346" lang="DE" load-source="patent-office"><!-- EPO <DP n="16"> --><claim id="c-de-01-0001" num="0001"><claim-text>Verfahren zur Anzeige von medizinischen Bilddaten der Struktur (2) mit einer ersten Auflösung zusammen mit zeitlich veränderlichen medizinischen Bilddaten der Funktion mit einer zweiten Auflösung, die niedriger als die erste Auflösung ist, wobei die zeitlich veränderlichen funktionellen Bilddaten eine Vielzahl von funktionellen Bilddatensätzen (4) umfassen, wobei jeder funktionelle Bilddatensatz (4) einen anderen Zeitpunkt darstellt, wobei das Verfahren Folgendes umfasst:
<claim-text>Aufteilen der Vielzahl von funktionellen Bilddatensätzen in Gruppen, wobei jede Gruppe eine vorbestimmte Anzahl von funktionellen Bilddatensätzen umfasst, die zeitlich aufeinanderfolgen,</claim-text>
<claim-text>wobei die Anzahl der funktionellen Bilddatensätze in jeder Gruppe so gewählt ist, dass die Zeit für die Verarbeitung aller funktionellen Bilddatensätze in der genannten Gruppe ungefähr der Zeit für die Verarbeitung der medizinischen strukturellen Bilddaten entspricht,</claim-text>
<claim-text>Zusammenführen und Wiedergeben (24) der strukturellen Bilddaten mit einer ersten Gruppe von funktionellen Bilddaten unter Verwendung von Wiedergabeparametern, die einen Betrachtungspunkt darstellen, um eine erste Gruppe mit zusammengeführten Bilddaten zu erzeugen, und</claim-text>
<claim-text>Anzeigen der ersten Gruppe mit zusammengeführten Bilddaten als Bilderfolge auf einem Bildschirm,</claim-text>
<claim-text>wobei während des Schrittes des Anzeigens der ersten Gruppe mit zusammengeführten Bilddaten der Schritt des Wiedergebens und Zusammenführens (24) mit einer zweiten Gruppe mit funktionellen Bilddaten wiederholt wird, und wobei das Wiedergeben und Zusammenführen der zweiten Gruppe mit funktionellen Bilddaten abgeschlossen wird, bevor der Schritt des Anzeigens der ersten Gruppe mit zusammengeführten Bilddaten abgeschlossen wurde.</claim-text></claim-text></claim><claim id="c-de-01-0002" num="0002"><claim-text>Verfahren nach Anspruch 1, wobei in dem Schritt des Anzeigens eine Pipeline (14) verwendet wird, damit die Wiedergabe und die Zusammenführung der<!-- EPO <DP n="17"> --> zweiten Gruppe mit funktionellen Bilddaten erfolgen kann während die erste Gruppe mit zusammengeführten Bilddaten angezeigt wird.</claim-text></claim><claim id="c-de-01-0003" num="0003"><claim-text>Verfahren nach Anspruch 1, wobei der genannte Schritt des Wiedergebens und Zusammenführens (14) die parallele Verarbeitung von zwei oder mehr der funktionellen Bilddatensätze umfasst.</claim-text></claim><claim id="c-de-01-0004" num="0004"><claim-text>Verfahren nach Anspruch 2, wobei die Gruppen mit funktionellen Bilddaten als Vektoren gespeichert werden.</claim-text></claim><claim id="c-de-01-0005" num="0005"><claim-text>Verfahren nach Anspruch 1, das ferner die folgenden Schritte umfasst, wenn eine Benutzereingabe eines zweiten Betrachtungspunktes entgegengenommen wird, von dem die strukturellen Bilddaten und die funktionellen Bilddaten anzuzeigen sind:
<claim-text>Speichern (42) von zweiten Wiedergabeparametern, die den zweiten Betrachtungspunkt darstellen,</claim-text>
<claim-text>Berechnen (42) der verbleibenden Zeit bis alle der vorher verarbeiteten wiedergegebenen und zusammengeführten Bilddaten angezeigt wurden, und</claim-text>
<claim-text>Ermitteln (46), ob die verbleibende Zeit ausreicht, um den Schritt des Wiedergebens und Zusammenführens neu zu starten und in der verbleibenden Zeit abzuschließen, und in dem Fall, dass ermittelt wird, dass die verbleibende Zeit ausreicht, erneutes Starten (48) des genannten Schritts des Wiedergebens und Zusammenführens von dem zweiten Betrachtungspunkt aus.</claim-text></claim-text></claim><claim id="c-de-01-0006" num="0006"><claim-text>Verfahren nach Anspruch 1, wobei der Schritt des Zusammenführens und Wiedergebens die folgenden Schritte umfasst:
<claim-text>Wiedergeben (25) der strukturellen Bilddaten unter Verwendung der Wiedergabeparameter, die den Betrachtungspunkt darstellen, um wiedergegebene strukturelle Bilddaten zu erzeugen, und</claim-text>
<claim-text>Zusammenführen (26) einer ersten Gruppe mit funktionellen Bilddaten mit den wiedergegebenen strukturellen Bilddaten unter Verwendung der Wiedergabeparameter, um eine erste Gruppe mit zusammengeführten Bilddaten zu erzeugen.</claim-text><!-- EPO <DP n="18"> --></claim-text></claim><claim id="c-de-01-0007" num="0007"><claim-text>Computerprogramm, das Codemittel umfasst, die bei Ausführung durch einen Datenprozessor den Datenprozessor veranlassen, das Verfahren nach einem der Ansprüche 1 bis 6 auszuführen.</claim-text></claim><claim id="c-de-01-0008" num="0008"><claim-text>Computerprogrammprodukt mit einem Computerprogramm nach Anspruch 7, das sich auf einem computerlesbaren Medium befindet.</claim-text></claim><claim id="c-de-01-0009" num="0009"><claim-text>Medizinische Bildgebungsvorrichtung zur Anzeige von strukturellen Bilddaten (2) mit einer ersten Auflösung zusammen mit zeitlich veränderlichen funktionellen Bilddaten mit einer zweiten Auflösung, die niedriger als die erste Auflösung ist, wobei die zeitlich veränderlichen funktionellen Bilddaten eine Vielzahl von funktionellen Bilddatensätzen (4) umfassen, wobei jeder funktionelle Bilddatensatz (4) einen anderen Zeitpunkt darstellt, wobei die Vorrichtung Folgendes umfasst:
<claim-text>einen Speicher zum Speichern von Befehlen, die von einem Datenprozessor ausgeführt werden können und zum Speichern von strukturellen Bilddaten (2) und einer Vielzahl von funktionellen Bilddatensätzen (4),</claim-text>
<claim-text>einen Datenprozessor, der durch die in dem Speicher gespeicherten Befehle so konfiguriert werden kann, dass er die folgenden Schritte ausführt:
<claim-text>Aufteilen der Vielzahl von funktionellen Bilddatensätzen in Gruppen, wobei jede Gruppe eine vorbestimmte Anzahl von funktionellen Bilddatensätzen umfasst, die zeitlich aufeinanderfolgen,</claim-text>
<claim-text>wobei die Anzahl der funktionellen Bilddatensätze in jeder Gruppe so gewählt ist, dass die Zeit für die Verarbeitung aller funktionellen Bilddatensätze in der genannten Gruppe ungefähr der Zeit für die Verarbeitung der medizinischen strukturellen Bilddaten entspricht,</claim-text>
<claim-text>Zusammenführen und Wiedergeben (24) der strukturellen Bilddaten mit einer ersten Gruppe von funktionellen Bilddaten unter Verwendung von Wiedergabeparametern, die einen Betrachtungspunkt darstellen, um eine erste Gruppe mit zusammengeführten Bilddaten zu erzeugen, wobei die erste Gruppe mit funktionellen Bilddaten eine Vielzahl von funktionellen Bilddatensätzen umfasst, die zeitlich aufeinanderfolgen, und</claim-text>
<claim-text>Anzeigen der ersten Gruppe mit zusammengeführten Bilddaten als Bilderfolge auf einem Bildschirm,<!-- EPO <DP n="19"> --></claim-text>
<claim-text>wobei während des Schrittes des Anzeigens der ersten Gruppe mit zusammengeführten Bilddaten der Schritt des Wiedergebens und Zusammenführens (26) mit einer zweiten Gruppe mit funktionellen Bilddaten wiederholt wird, und wobei das Wiedergeben und Zusammenführen der zweiten Gruppe mit funktionellen Bilddaten abgeschlossen wird, bevor der Schritt des Anzeigens der ersten Gruppe mit zusammengeführten Bilddaten abgeschlossen wurde.</claim-text></claim-text></claim-text></claim><claim id="c-de-01-0010" num="0010"><claim-text>Medizinische Bildgebungsvorrichtung nach Anspruch 9, die ferner Folgendes umfasst:
<claim-text>ein Eingabegerät zum Entgegennehmen der Benutzereingabe eines zweiten Betrachtungspunktes, von dem die strukturellen Bilddaten und die funktionellen Bilddaten anzuzeigen sind,</claim-text>
<claim-text>wobei die Datenprozessormittel ferner durch in dem Speicher gespeicherte Befehle so konfiguriert sind, dass sie die folgenden Schritte ausführen, wenn die Benutzereingabe eines zweiten Betrachtungspunktes entgegengenommen wird:
<claim-text>Speichern (42) von zweiten Wiedergabeparametern, die den zweiten Betrachtungspunkt darstellen,</claim-text>
<claim-text>Berechnen (44) der verbleibenden Zeit bis alle der vorher verarbeiteten wiedergegebenen und zusammengeführten Bilddaten angezeigt wurden, und</claim-text>
<claim-text>Ermitteln (46), ob die verbleibende Zeit ausreicht, um den Schritt des Wiedergebens und Zusammenführens neu zu starten und in der verbleibenden Zeit abzuschließen, und in dem Fall, dass ermittelt wird, dass die verbleibende Zeit ausreicht, erneutes Starten (48) des genannten Schritts des Wiedergebens und Zusammenführens von dem zweiten Betrachtungspunkt aus.</claim-text></claim-text></claim-text></claim></claims><claims mxw-id="PCLM56986347" lang="EN" load-source="patent-office"><!-- EPO <DP n="13"> --><claim id="c-en-01-0001" num="0001"><claim-text>A method of displaying structural medical image data (2) having a first resolution together with time-varying functional medical image data having a second resolution which is lower than the first resolution, wherein the time-varying functional image data comprises a plurality of functional image data sets (4), with each functional image data set (4) representing a different point in time, the method comprising:
<claim-text>dividing the plurality of functional image data sets into groups, with each group comprising a predetermined number of functional image data sets which are contiguous in time,</claim-text>
<claim-text>wherein the number of functional image data sets in each group is chosen so that the time to process all the functional image data sets in said group is approximately the same as the time to process the structural medical image data,</claim-text>
<claim-text>merging and rendering (24) the structural image data with a first group of functional image data using rendering parameters representing a viewpoint to produce a first group of merged image data, and</claim-text>
<claim-text>displaying the first group of merged image data as a sequence of images on a display;</claim-text>
<claim-text>wherein, during the step of displaying the first group of merged image data, the step of rendering and merging (24) is repeated with a second group of functional image data, and wherein rendering and merging of the second group of functional image data is completed before the step of displaying the first group of merged image data has completed.</claim-text></claim-text></claim><claim id="c-en-01-0002" num="0002"><claim-text>A method according to claim 1, wherein a pipeline (14) is used in the step of displaying to allow rendering and merging of the second group of functional image data while the first group of merged image data is displayed.</claim-text></claim><claim id="c-en-01-0003" num="0003"><claim-text>A method according to claim 1, wherein said step of rendering and merging (14) comprises processing two or more of the functional image data sets in parallel.</claim-text></claim><claim id="c-en-01-0004" num="0004"><claim-text>A method according to claim 2, wherein the functional image data groups are stored as vectors.<!-- EPO <DP n="14"> --></claim-text></claim><claim id="c-en-01-0005" num="0005"><claim-text>A method according to claim 1, further comprising, when user input is received of a second viewpoint from which the structural image data and the functional image data is to be displayed, the following steps:
<claim-text>storing (42) second rendering parameters that represent the second viewpoint;</claim-text>
<claim-text>calculating (44) the time remaining before all the rendered and merged image data previously processed has been displayed; and</claim-text>
<claim-text>determining (46) whether the time remaining is sufficient for the step of rendering and merging to be restarted and completed in the time remaining, and, if it is determined there is sufficient time remaining, restarting (48) said step of rendering and merging from the second viewpoint.</claim-text></claim-text></claim><claim id="c-en-01-0006" num="0006"><claim-text>A method according to claim 1, wherein the step of merging and rendering comprises the following steps:
<claim-text>rendering (25) the structural image data using rendering parameters representing the viewpoint to produce rendered structural image data; and</claim-text>
<claim-text>merging (26) a first group of functional image data with the rendered structural image data using the rendering parameters to produce a first group of merged image data.</claim-text></claim-text></claim><claim id="c-en-01-0007" num="0007"><claim-text>A computer program comprising code means that, when executed by a data processor, instructs the data processor to perform the method of any one of claims 1 to 6.</claim-text></claim><claim id="c-en-01-0008" num="0008"><claim-text>A computer program product comprising a computer program according to claim 7 embodied on a computer readable medium.</claim-text></claim><claim id="c-en-01-0009" num="0009"><claim-text>A medical imaging apparatus for displaying structural image data (2) having a first resolution together with time-varying functional image data having a second resolution which is lower than the first resolution, wherein the time-varying functional image data comprises a plurality of functional image data sets (4), with each functional image data set (4) representing a different point in time, the apparatus comprising:<!-- EPO <DP n="15"> -->
<claim-text>a storage device for storing instructions executable by a data processor and for storing structural image data (2) and a plurality of functional image data sets (4);</claim-text>
<claim-text>a data processor which can be configured by the instructions stored in the storage device to execute the steps of:
<claim-text>dividing the plurality of functional image data sets into groups, with each group comprising a predetermined number of functional image data sets which are contiguous in time,</claim-text>
<claim-text>wherein the number of functional image data sets in each group is chosen so that the time to process all the functional image data sets in said group is approximately the same as the time to process the structural medical image data,</claim-text>
<claim-text>merging and rendering (24) the structural image data with a first group of functional image data using rendering parameters representing a viewpoint to produce a first group of merged image data, wherein the first group of functional image data comprises a plurality of functional image data sets which are contiguous in time; and</claim-text>
<claim-text>displaying the first group of merged image data as a sequence of images on a display;</claim-text>
<claim-text>wherein, during the step of displaying the first group of merged image data, the step of rendering and merging (26) is repeated with a second group of functional image data, and wherein rendering and merging of the second group of functional image data is completed before the step of displaying the first group of merged image data has completed.</claim-text></claim-text></claim-text></claim><claim id="c-en-01-0010" num="0010"><claim-text>A medical imaging apparatus according to claim 9, further comprising:
<claim-text>an input device for receiving user input of a second viewpoint from which the structural image data and the functional image data is to be displayed;</claim-text>
<claim-text>wherein the data processing means is further configured by instructions stored in the storage device to execute the following steps when user input of a second viewpoint is received:
<claim-text>storing (42) second rendering parameters that represent the second viewpoint;</claim-text>
<claim-text>calculating (44) the time remaining before all the merged image data previously processed has been displayed; and</claim-text>
<claim-text>determining (46) whether the time remaining is sufficient for the steps of rendering and merging to be restarted and completed in the time remaining, and, if it is determined there is sufficient time remaining, restarting (48) said steps of rendering and merging from the second viewpoint.</claim-text></claim-text></claim-text></claim></claims><claims mxw-id="PCLM56986348" lang="FR" load-source="patent-office"><!-- EPO <DP n="20"> --><claim id="c-fr-01-0001" num="0001"><claim-text>Procédé d'affichage de données d'images médicales structurelles (2) ayant une première résolution conjointement avec des données d'images médicales fonctionnelles variant dans le temps ayant une seconde résolution qui est inférieure à la première résolution, les données d'images médicales fonctionnelles variant dans le temps comprenant une pluralité d'ensembles de données d'images fonctionnelles (4), chaque ensemble de données d'images fonctionnelles (4) représentant un moment précis différent, le procédé comprenant :
<claim-text>la division de la pluralité d'ensembles de données d'images fonctionnelles en groupes, chaque groupe comprenant un nombre prédéterminé d'ensembles de données d'images fonctionnelles qui sont contiguës dans le temps,</claim-text>
<claim-text>dans lequel le nombre d'ensembles de données d'images fonctionnelles de chaque groupe est choisi de telle sorte que le temps pour traiter tous les ensembles de données d'images fonctionnelles dudit groupe soit approximativement le même que le temps pour traiter les données d'images médicales structurelles,</claim-text>
<claim-text>la fusion et le rendu (24) des données d'images structurelles avec un premier groupe de données d'images fonctionnelles en utilisant des paramètres de rendu représentant un point de vue pour produire un premier groupe de données d'images fusionnées,</claim-text>
<claim-text>l'affichage du premier groupe de données d'images fusionnées sous forme d'une séquence d'images sur un affichage ;</claim-text>
<claim-text>dans lequel, lors de l'étape d'affichage du premier groupe de données d'images fusionnées, l'étape de rendu et de fusion (24) est répétée avec un second groupe de données d'images fonctionnelles, et dans lequel le rendu et la fusion du second groupe de données d'images fonctionnelles sont terminés avant que l'étape d'affichage du premier groupe de données d'images fusionnées soit terminée.</claim-text></claim-text></claim><claim id="c-fr-01-0002" num="0002"><claim-text>Procédé selon la revendication 1, dans lequel un pipeline (14) est utilisé dans l'étape d'affichage pour permettre le rendu et la fusion du second groupe de données<!-- EPO <DP n="21"> --> d'images fonctionnelles tandis que le premier groupe de données d'images fusionnées est affiché.</claim-text></claim><claim id="c-fr-01-0003" num="0003"><claim-text>Procédé selon la revendication 1, dans lequel ladite étape de rendu et de fusion (14) comprend le traitement de deux ensembles de données d'images fonctionnelles ou plus en parallèle.</claim-text></claim><claim id="c-fr-01-0004" num="0004"><claim-text>Procédé selon la revendication 2, dans lequel les groupes de données d'images fonctionnelles sont stockés sous forme de vecteurs.</claim-text></claim><claim id="c-fr-01-0005" num="0005"><claim-text>Procédé selon la revendication 1, comprenant en outre, lorsque l'entrée de l'utilisateur est reçue d'un second point de vue depuis lequel les données d'images structurelles et les données d'images fonctionnelles doivent être affichées, les étapes suivantes :
<claim-text>le stockage (42) de seconds paramètres de rendu qui représentent le second point de vue ;</claim-text>
<claim-text>le calcul (44) du temps restant avant que toutes les données d'images rendues et fusionnées traitées précédemment aient été affichées ; et</claim-text>
<claim-text>la détermination (46) du fait que le temps restant est suffisant ou pas pour que l'étape de rendu et de fusion soit redémarrée et terminée dans le temps restant, et, si l'on détermine qu'il reste suffisamment de temps, le redémarrage (48) de ladite étape de rendu et de fusion depuis le second point de vue.</claim-text></claim-text></claim><claim id="c-fr-01-0006" num="0006"><claim-text>Procédé selon la revendication 1, dans lequel l'étape de fusion et de rendu comprend les étapes suivantes :
<claim-text>le rendu (25) des données d'images structurelles en utilisant des paramètres de rendu représentant le point de vue pour produire des données d'images structurelles rendues ; et</claim-text>
<claim-text>la fusion (26) d'un premier groupe de données d'images fonctionnelles avec les données d'images structurelles rendues en utilisant les paramètres de rendu pour produire un premier groupe de données d'images fusionnées.</claim-text><!-- EPO <DP n="22"> --></claim-text></claim><claim id="c-fr-01-0007" num="0007"><claim-text>Programme informatique comprenant des moyens de code, qui, lorsqu'ils sont exécutés par un processeur de données, donne la consigne au processeur de données de réaliser le procédé selon l'une quelconque des revendications 1 à 6.</claim-text></claim><claim id="c-fr-01-0008" num="0008"><claim-text>Produit de programme informatique comprenant un programme informatique selon la revendication 7 intégré à un support lisible par ordinateur.</claim-text></claim><claim id="c-fr-01-0009" num="0009"><claim-text>Appareil d'imagerie médicale conçu pour afficher des données d'images structurelles (2) ayant une première résolution conjointement avec des données d'images médicales fonctionnelles variant dans le temps ayant une seconde résolution qui est inférieure à la première résolution, les données d'images médicales fonctionnelles variant dans le temps comprenant une pluralité d'ensembles de données d'images fonctionnelles (4), chaque ensemble de données d'images fonctionnelles (4) représentant un moment précis différent, l'appareil comprenant :
<claim-text>un dispositif de stockage pour stocker des consignes exécutables par un processeur de données et pour stocker des données d'images structurelles (2) et une pluralité d'ensembles de données d'images fonctionnelles (4) ;</claim-text>
<claim-text>un processeur de données qui peut être configuré par les consignes stockées dans le dispositif de stockage pour exécuter les étapes suivantes :
<claim-text>la division de la pluralité d'ensembles de données d'images fonctionnelles en groupes, chaque groupe comprenant un nombre prédéterminé d'ensembles de données d'images fonctionnelles qui sont contiguës dans le temps,</claim-text>
<claim-text>dans lequel le nombre d'ensembles de données d'images fonctionnelles de chaque groupe est choisi de telle sorte que le temps pour traiter tous les ensembles de données d'images fonctionnelles dudit groupe soit approximativement le même que le temps pour traiter les données d'images médicales structurelles,</claim-text>
<claim-text>la fusion et le rendu (24) des données d'images structurelles avec un premier groupe de données d'images fonctionnelles en utilisant des paramètres de rendu représentant un point de vue pour produire un premier groupe de données d'images fusionnées, le premier groupe de données d'images fonctionnelles comprenant une pluralité d'ensembles de données d'images fonctionnelles qui sont contiguës dans le temps ; et</claim-text>
<claim-text>l'affichage du premier groupe de données d'images fusionnées sous forme d'une séquence d'images sur un affichage ;<!-- EPO <DP n="23"> --></claim-text>
<claim-text>dans lequel, lors de l'étape d'affichage du premier groupe de données d'images fusionnées, l'étape de rendu et de fusion (26) est répétée avec un second groupe de données d'images fonctionnelles, et dans lequel le rendu et la fusion du second groupe de données d'images fonctionnelles sont terminés avant que l'étape d'affichage du premier groupe de données d'images fusionnées soit terminé.</claim-text></claim-text></claim-text></claim><claim id="c-fr-01-0010" num="0010"><claim-text>Appareil d'imagerie médicale selon la revendication 9, comprenant en outre :
<claim-text>un dispositif d'entrée pour recevoir l'entrée d'utilisateur d'un second point de vue depuis lequel les données d'images structurelles et les données d'images fonctionnelles doivent être affichées ;</claim-text>
<claim-text>dans lequel les moyens de traitement de données sont en outre configurés par les consignes stockées dans le dispositif de stockage pour exécuter les étapes suivantes lorsque l'entrée d'utilisateur d'un second point de vue est reçue :
<claim-text>le stockage (42) de seconds paramètres de rendu qui représentent le second point de vue ;</claim-text>
<claim-text>le calcul (44) du temps restant avant que toutes les données d'images fusionnées traitées précédemment aient été affichées ; et</claim-text>
<claim-text>la détermination (46) du fait que le temps restant est suffisant ou non pour que les étapes de rendu et de fusion soient redémarrées et terminées dans le temps restant, et, si l'on détermine qu'il reste suffisamment de temps, le redémarrage (48) desdites étapes de rendu et de fusion depuis le second point de vue.</claim-text></claim-text></claim-text></claim></claims><drawings mxw-id="PDW16672427" load-source="patent-office"><!-- EPO <DP n="24"> --><figure id="f0001" num="1"><img id="if0001" file="imgf0001.tif" wi="126" he="180" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="25"> --><figure id="f0002" num="2"><img id="if0002" file="imgf0002.tif" wi="119" he="223" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="26"> --><figure id="f0003" num="3"><img id="if0003" file="imgf0003.tif" wi="152" he="157" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="27"> --><figure id="f0004" num="4"><img id="if0004" file="imgf0004.tif" wi="125" he="218" img-content="drawing" img-format="tif"/></figure></drawings><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
