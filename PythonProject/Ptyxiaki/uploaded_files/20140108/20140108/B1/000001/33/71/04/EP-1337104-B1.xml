<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-1337104-B1" country="EP" doc-number="1337104" kind="B1" date="20140108" family-id="27621492" file-reference-id="278427" date-produced="20180823" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="146589242" ucid="EP-1337104-B1"><document-id><country>EP</country><doc-number>1337104</doc-number><kind>B1</kind><date>20140108</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-03003607-A" is-representative="YES"><document-id mxw-id="PAPP154851434" load-source="docdb" format="epo"><country>EP</country><doc-number>03003607</doc-number><kind>A</kind><date>20030217</date><lang>EN</lang></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC140554510" ucid="JP-2002041342-A" load-source="docdb"><document-id format="epo"><country>JP</country><doc-number>2002041342</doc-number><kind>A</kind><date>20020219</date></document-id></priority-claim></priority-claims><dates-of-public-availability><intention-to-grant-date><date>20130807</date></intention-to-grant-date></dates-of-public-availability><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL1989328036" load-source="ipcr">H04N   1/56        20060101AFI20050816BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1989630489" load-source="ipcr">H04N   1/32        20060101A I20051008RMEP        </classification-ipcr><classification-ipcr mxw-id="PCL1989642380" load-source="ipcr">H04N   1/00        20060101A N20051008RMEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL1989638052" load-source="docdb" scheme="CPC">H04N   1/00132     20130101 LA20130101BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989639598" load-source="docdb" scheme="CPC">H04N   1/32128     20130101 LI20130101BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989645432" load-source="docdb" scheme="CPC">H04N   1/00167     20130101 FI20130101BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989651457" load-source="docdb" scheme="CPC">H04N2201/3242      20130101 LA20130101BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT132372359" lang="DE" load-source="patent-office">Verfahren, Vorrichtung und Programm für Bildverarbeitung</invention-title><invention-title mxw-id="PT132372360" lang="EN" load-source="patent-office">Method, apparatus, and program for image processing</invention-title><invention-title mxw-id="PT132372361" lang="FR" load-source="patent-office">Appareil, procédé et programme de traitement d'image</invention-title></technical-data><parties><applicants><applicant mxw-id="PPAR919511395" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>FUJIFILM CORP</last-name><address><country>JP</country></address></addressbook></applicant><applicant mxw-id="PPAR919543532" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>FUJIFILM CORPORATION</last-name></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR919505524" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>TERASHITA TAKAAKI</last-name><address><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR919529042" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>TERASHITA, TAKAAKI</last-name></addressbook></inventor><inventor mxw-id="PPAR919027016" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>TERASHITA, TAKAAKI</last-name><address><street>Fuji Photo Film Co.Ltd. 798 Miyanodai,Kaisei-Machi</street><city>Ashigarakami-gun, Kanagawa-ken</city><country>JP</country></address></addressbook></inventor></inventors><assignees><assignee mxw-id="PPAR919027017" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>FUJIFILM Corporation</last-name><iid>100828495</iid><address><street>26-30, Nishiazabu 2-chome</street><city>Minato-ku Tokyo</city><country>JP</country></address></addressbook></assignee></assignees><agents><agent mxw-id="PPAR919027018" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Klunker . Schmitt-Nilson . Hirsch</last-name><iid>100060668</iid><address><street>Patentanwälte Destouchesstrasse 68</street><city>80796 München</city><country>DE</country></address></addressbook></agent></agents></parties><international-convention-data><designated-states><ep-contracting-states><country mxw-id="DS549791844" load-source="docdb">DE</country><country mxw-id="DS549876197" load-source="docdb">FR</country><country mxw-id="DS549791849" load-source="docdb">GB</country></ep-contracting-states></designated-states></international-convention-data></bibliographic-data><description mxw-id="PDES63961652" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><heading id="h0001">BACKGROUND OF THE INVENTION</heading><heading id="h0002"><u>Field of the Invention</u></heading><p id="p0001" num="0001">The present invention relates to an image processing method and an image processing apparatus according to the preamble of claim 1 and claim 3, respectively. The apparatus and the method are used for carrying out image processing on image data that have already been subjected to image processing carried out by a digital camera or the like and added with image processing information regarding the image processing by the digital camera or the like. The present invention also relates to a program embodied on a computer-readable recording medium to cause a computer to execute the image processing method.</p><heading id="h0003"><u>Description of the Related Art</u></heading><p id="p0002" num="0002">In a digital still camera (hereinafter referred to as a digital camera), an image obtained by photography can be recorded as digital image data in a recording medium such as an internal memory or an IC card, and can be reproduced by a printer or a monitor based on the digital image data. In the case where an image obtained by a digital camera is reproduced, the image is expected to have as high a quality as a print generated from a negative film.</p><p id="p0003" num="0003">When a print is generated in the above manner, the quality of the print can be improved by carrying out thereon image processing such as density conversion processing, white balance processing, gradation conversion processing, saturation enhancement processing, and sharpness processing. Therefore, a method has been proposed (<patcit id="pcit0001" dnum="US6011547A"><text>U.S. Patent No. 6,011,547</text></patcit>), in order to obtain high-quality printed matter.<!-- EPO <DP n="2"> --> In this method, photography information such as information on use of flash and the type of lighting is added to image data obtained by a digital camera, and more appropriate image processing can be carried out on the image data with reference to the photography information added to the image data.</p><p id="p0004" num="0004">Meanwhile, a digital camera has also been proposed that enables output of photographed image data having been subjected to automatic or manual image processing. In such a digital camera having an image processing function, image processing is carried out so as to attain an optimal image quality according to a photographed scene and a photography condition. Furthermore, a photographer can select the type of image processing to be carried out on the image data and various functions related to the image processing according to his/her intention. For example, automatic white balance processing, white balance processing in a fixed light source mode, processing for image quality modification (regarding tones, sharpness, and chroma) and a preference regarding reproduced image (such as preference for a monochrome image, a sepia-color image, and a beautiful skin color) can be selected as the type of image processing. As the various kinds of functions regarding image processing are included selection of a photography mode (such as portrait mode, scenery/distant view mode, macro/close-up mode, night view/fireworks mode, underwater photography mode, and user exposure correction mode), an automatic bracket function, photography using an optical filter, soft focus photography, interval photography, serial photography, multiple exposure, superposition with a template, and superposition with a<!-- EPO <DP n="3"> --> frame. Optimal image processing can be carried out, reflecting an intention of the photographer according to the selected type of image processing and function.</p><p id="p0005" num="0005">In the case where image data obtained by such a digital camera having an image processing function are reproduced by a reproduction apparatus such as a printer or a monitor, further image processing is carried out on the image data. However, if the image processing is further carried out on the image data that have already been subjected to the image processing by the digital camera, a reproduced image may not have the quality intended for by the digital camera or the reproduction apparatus.</p><p id="p0006" num="0006">Meanwhile, automatic white balance processing by a digital camera refers to processing that causes white balance of an image photographed in artificial lighting to look like white balance of an image photographed in daylight. More specifically, the automatic white balance processing is to correct image data so as to cause an average of the image data (that may exclude high saturation pixels) to become a gray value having an intended color temperature (such as color temperature of daylight or tungsten light) . For this reason, when automatic white balance processing is carried out, an image photographed in a light source having a low color temperature such as a tungsten light can be reproduced to have more preferable or natural colors. If a sunset is photographed in a fixed daylight mode among fixed light source modes of a digital camera, image data processed by the automatic white balance function enables reproduction of an image reflecting a reddish color of the sunset.<!-- EPO <DP n="4"> --></p><p id="p0007" num="0007">On the other hand, in a reproduction apparatus, white balance processing is carried out for absorbing a characteristic of white balance of a digital camera. Therefore, images obtained from a reproduction apparatus have almost the same white balance, since the reproduction apparatus cannot distinguish between automatic white balance processing set in a digital camera and image processing in a fixed light source mode.</p><p id="p0008" num="0008">In accordance with the preamble of claim 1 and claim 3, respectively, <patcit id="pcit0002" dnum="EP0838939A"><text>EP-A-0 838 939</text></patcit> discloses a method and an apparatus for reproducing image data obtained by a digital camera. Along with image data, recording information is obtained in the digital camera, e. g. exposure conditions, the focal length of the lens of the camera and the like. However, it may also be that the image processing information does not include sufficient information for setting the content of the image processing out on the image data.</p><heading id="h0004">SUMMARY OF THE INVENTION</heading><p id="p0009" num="0009">The present invention has been conceived based on consideration of the above circumstances. An object of the present invention is therefore to carry out image processing on image data in consideration of image processing that has already been carried out by a digital camera or the like having a function of image processing.</p><p id="p0010" num="0010">An image processing method of the present invention is an image processing method including the steps of claim 1.</p><p id="p0011" num="0011">The "image processing information on image processing that has been carried out" refers to information representing the content of the image processing that has been carried out on the image data or information from which the content of the image processing that has been carried out on the image data can be inferred. As the information representing the content of image processing is used<!-- EPO <DP n="5"> --><!-- EPO <DP n="6"> --> information representing the type of image processing such as automatic white balance processing, white balance processing according to a light source, gradation conversion processing, density conversion processing, color correction processing, sharpness processing, monochrome processing, and sepia-color processing. The information enabling inference of the content of the image processing refers to information from which how the image processing was carried out can be inferred, although the information does not directly specify the type of the image processing. As such information can be used a photography mode set in a digital camera (such as portrait mode, scenery/distant view mode, macro/close-up mode, night view/fireworks mode, marine photograph mode, and user exposure correction mode), an automatic bracket function, photography using an optical filter, soft focus photography, interval photography, serial photography, multiple exposure, superposition with a template, and superposition with a frame. A flag prohibiting or diminishing further image processing may be used as the image processing information.</p><p id="p0012" num="0012">The image data have the format defined by JEIDA (Japan Electronic Industry Development Association). The format, Exif (Exchangeable image file format), allows description of various kinds of information in tag information thereof. Therefore, by describing the image processing information in the tag information, the image processing information can be added to the image data.</p><p id="p0013" num="0013">In the image processing method of the present invention, the content of the image processing to be carried out on the image data may be set based on a result of analysis of the image data, in addition<!-- EPO <DP n="7"> --> to the image processing information.</p><p id="p0014" num="0014">The "result of analysis of the image data" refers to the content of the image processing that was carried out on the image data, and can be obtained by judging which type of the image processing was carried out on the image data, based on colors, tones, density, and sharpness of the image data, for example.</p><p id="p0015" num="0015">The image processing method may further comprise the step of:
<ul><li>judging whether or not predetermined image processing is carried out or whether or not the predetermined image processing is to be diminished, based on the image processing information. In this case,</li><li>the step of setting the content is the step of canceling or diminishing the predetermined image processing in the case where the predetermined image processing is judged to be not carried out or to be diminished.</li></ul></p><p id="p0016" num="0016">The "predetermined image processing" refers to a specific type of processing from among a plurality of types of the image processing, if the plurality of types of the image processing is carried out on the image data. The specific type of image processing may represent all the types of the image processing. In the case where only one of the types of the image processing is carried out on the image data, the one type of the image processing refers to the predetermined image processing.</p><p id="p0017" num="0017">"Canceling the predetermined image processing" refers to not carrying out the predetermined image processing.<!-- EPO <DP n="8"> --></p><p id="p0018" num="0018">In the image processing method of the present invention, it is preferable for the image processing information to be output together with the processed image data.</p><p id="p0019" num="0019">An image processing apparatus of the present invention comprises the features of claim 3.</p><p id="p0020" num="0020">In the image processing apparatus of the present invention, the processing means may set the content of the image processing based on a result of analysis of the image data in addition to the image processing information.</p><p id="p0021" num="0021">The image processing apparatus may further comprise:
<ul><li>judgment means for judging whether or not predetermined image processing is carried out or whether or not the predetermined image processing is to be diminished, based on the image processing information. The judgment means may cancel or diminish the predetermined image processing, in the case where the predetermined image processing is judged to be not carried out or to be diminished.</li></ul></p><p id="p0022" num="0022">The image processing apparatus of the present invention may further comprise output means for outputting the image processing information together with the processed image data.<!-- EPO <DP n="9"> --></p><p id="p0023" num="0023">The image processing method of the present invention may be provided as a program that causes a computer to execute the image processing method.</p><p id="p0024" num="0024">According to the present invention, the content of the image processing to be carried out on the image data is set based on the image processing information added to the image data. Therefore, the content of the image processing to be carried out on the image data can be set so as not to influence the image processing that has already been carried out. Consequently, by carrying out the image processing according to the content that has been set, processed image data reflecting the image processing that has already been carried out can be obtained.</p><p id="p0025" num="0025">By setting the content of the image processing according to the result of analysis of the image data, the content of the image processing that has been carried out can be known with certainty. Therefore, the processed image data can securely reflect the image processing that has already been carried out on the image data.</p><heading id="h0005">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p0026" num="0026"><ul><li><figref idrefs="f0001">Figure 1</figref> is a block diagram showing a configuration of an image output system adopting an image output apparatus of an example useful for the understanding of the invention;</li><li><figref idrefs="f0002">Figure 2</figref> is a block diagram showing procedures carried out by output image processing means;</li><li><figref idrefs="f0003">Figure 3</figref> is a flow chart showing the operation in the example;</li><li><figref idrefs="f0004">Figure 4</figref> is a block diagram showing a configuration of an image<!-- EPO <DP n="10"> --> output system adopting an image output apparatus of an embodiment of the present invention;</li><li><figref idrefs="f0005">Figure 5</figref> is a flow chart showing the operation in the embodiment;</li><li><figref idrefs="f0006">Figure 6</figref> shows a manual processing input window (part 1); and</li><li><figref idrefs="f0007">Figure 7</figref> shows the manual processing input window (part 2).</li></ul></p><heading id="h0006">DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading><p id="p0027" num="0027">Hereinafter, an example useful for the understanding of the invention and an embodiment of the present invention will be explained with reference to the accompanying drawings. <figref idrefs="f0001">Figure 1</figref> is a block diagram showing a configuration of an image output system adopting an image output apparatus of an example not covered by the present invention. As shown in <figref idrefs="f0001">Figure 1</figref>, the image output system comprises a digital camera 1 and an image output apparatus 2. The image output apparatus 2 outputs as a print or prints P (hereinafter referred to as the prints P) an image data set or image data sets S1 (hereinafter referred to as the image data sets S1) obtained by the digital camera 1.</p><p id="p0028" num="0028">The digital camera 1 comprises imaging means 11 including a lens, a shutter, and CCDs, DSC image processing means 12 for obtaining the image data sets S1 by carrying out image processing on an image data set or image data sets S0 (hereinafter referred to as the image data sets S0) obtained by the imaging means 11, recording means 13 for recording the image data sets S1 in a memory card 14, and input means 15 comprising a selection dial and a setting button for variously setting the DSC image processing means 12.</p><p id="p0029" num="0029">Aphotographer can set the type of image processing to be carried<!-- EPO <DP n="11"> --> out on the image data sets S0 obtained by photography, with use of the input means 15. As the image processing can be listed automatic white balance processing, white balance processing according to a light source, gradation conversion processing, density conversion processing, color correction processing, sharpness processing, monochrome processing, and sepia-color processing. Photography modes such as port rait mode, scenery/distant view mode, macro/close-up mode, night view/fireworks mode, underwater photography mode, and user exposure correction mode are also available. The user exposure correction mode is the mode for a user to manually correct an exposure condition. Other settings such as an automatic bracket function, photography with an optical filter, soft focus photography, interval photography, serial photography, multiple exposure, superposition with a template, and superposition with a frame can also be used.</p><p id="p0030" num="0030">The DSC image processing means 12 obtains the image data sets S1 by carrying out the image processing on the image data sets S0 according to the type of the image processing set by the photographer. In the case where one of the photography modes has been set, the DSC image processing means carries out the image processing on the image data sets S0 according to the photography mode that has been set, and obtains the image data sets S1. The image data sets S1 are of Exif format, and image processing information G representing the type of image processing that has been carried out on the image data sets S1, the photography mode, and the like is described in tag information added to each of the image data sets S1.</p><p id="p0031" num="0031">The recording means 13 records the image data sets S1 added<!-- EPO <DP n="12"> --> with the image processing information G in the memory card 14.</p><p id="p0032" num="0032">In the digital camera 1 having the above components, the image data sets S0 are obtained by photography with the imaging means 11, and the DSC image processing means 12 carries out the image processing on the image data sets S1 according to the type of the image processing or the photography mode input from the input means 15. In this manner, the image data sets S1 are obtained, and the image processing information G describing the type of the image processing and the photography mode is added to the image data sets S1. The recording means 13 records the image data sets S1 added with the image processing information G in the memory card 14.</p><p id="p0033" num="0033">The image output apparatus 2 comprises reading means 21 such as a card slot for reading the image data sets S1 from the memory card 14, output image processing means 22 for obtaining a processed image data set or processed image data sets S2 (hereinafter referred to as the processed image data sets S2) by carrying out image processing on the image data sets S1, judgment means 23 for judging the type of the image processing that has been carried out on the image data sets S1 from the image processing information G, setting means 24 for setting the content of image processing to be carried out on the image data sets S1 by the output image processing means 22 according to the type of the image processing judged by the judgment means 23, and print output means 25 for outputting the processed image data sets S2 as the prints P.</p><p id="p0034" num="0034"><figref idrefs="f0002">Figure 2</figref> is a block diagram showing procedures carried out in the output image processing means 22. As shown in <figref idrefs="f0002">Figure 2</figref>, the<!-- EPO <DP n="13"> --> output image processing means 22 reduces the image data sets S1, calculates an image processing condition J based on the reduced image data sets, and carries out density correction processing, white balance processing, gradation conversion processing (that is, tone processing), color correction processing, enlargement processing for adjusting an image size, and sharpness processing, according to the image processing condition J. In this manner, processed image data sets S2 are obtained. The content of the processing carried out by the output image processing means 22 is set by the setting means 24.</p><p id="p0035" num="0035">The operation of the image output apparatus 2 will be explained next. <figref idrefs="f0003">Figure 3</figref> is a flow chart showing the operation of the image output apparatus 2. The reading means 21 reads the image data sets S1 from the memory card 14 (Step S1), and the image processing information G added to the image data sets S1 is input to the judgment means 23. The type of the image processing that has been carried out on the image data sets S1 is then judged by the judgment means 23 according to the image processing information G (Step S2). The setting means 24 sets the content of the image processing to be carried out on the image data sets S1, based on the type of the image processing (Step S3).</p><p id="p0036" num="0036">Hereinafter, how to set the content of the image processing according to the type of the past image processing will be explained in detail. In the case where the image processing information G includes information on automatic white balance processing and white balance processing for the case of a fixed light source such as daylight<!-- EPO <DP n="14"> --> or tungsten light, white balance processing by the output image processing means 22 is set to be cancelled or diminished.</p><p id="p0037" num="0037">In the case where the image processing information G does not include the information on the white balance processing, automatic white balance processing is set to be carried out. For example, an average of pixel values excluding high-saturation pixels is calculated from an image represented by any one of the image data sets S1, and a conversion table for conversion of the average into a predetermined reference value is generated for conversion of the image data sets S1. In this case, the conversion table is preferably generated based on more than one of the image data sets S1.</p><p id="p0038" num="0038">In the case where the image processing information G includes information on gradation conversion processing, gradation conversion processing is not carried out by the output image processing means 22. Alternatively, the gradation conversion processing may be carried out according to a standard gradation conversion curve for image output in standard tones.</p><p id="p0039" num="0039">Meanwhile, in the case where the image processing information G does not include the information on gradation conversion processing, the gradation conversion processing is carried out by the output image processing means 22 in accordance with a dynamic range of the image data sets S1. For example, for the image data sets S1 whose dynamic range is wide, tones are softened by decreasing data values in an intermediate density range and in a shadow range. In this manner, colors in the shadow range are prevented from being flattened. On the contrary, for the image data sets S1 whose dynamic range is small,<!-- EPO <DP n="15"> --> the image data sets as a whole and/or in a highlight range are increased to have hard tones.</p><p id="p0040" num="0040">In the case where the image processing information G includes information on saturation enhancement processing, saturation enhancement processing by the output image processing means 22 is cancelled. Since chroma is enhanced by hard tones, gradation conversion processing to harden tones is cancelled or diminished.</p><p id="p0041" num="0041">In the case where the image processing information G includes information on sharpness processing, the sharpness processing by the output image processing means 22 is cancelled or diminished. In some cases, a degree of sharpness is changed in accordance with a characteristic of the print output means 25 or a condition to view a reproduced image. Therefore, such sharpness processing for compensating the sharpness change is carried out even if the image processing information G represents the fact that the sharpness processing has already been carried out in the digital camera 1.</p><p id="p0042" num="0042">In the case where the image processing information G includes information on a photography mode, the type of image processing carried out in the photography mode is inferred, and the inferred image processing is cancelled or diminished. For example, if the image processing information G includes information on scenery/distant view mode, the image data sets S1 have already been subjected to processing for softening tones in a low frequency range, gradation conversion processing, sharpness processing, and saturation enhancement processing. Therefore, the processing of these types is cancelled or diminished.<!-- EPO <DP n="16"> --></p><p id="p0043" num="0043">In some cases, automatic bracket photography is carried out by using the digital camera 1. Automatic bracket photography is to photograph a plurality of images representing the same subject while changing an image processing condition in a plurality of steps for image processing regarding exposure, chroma, contrast, or sharpness. In this case, the image processing information G describes for which item (that is, for exposure, chroma, contrast, or sharpness) the bracket photography has been carried out. By carrying out such automatic bracket photography, the plurality of images of various exposure, chroma, contrast, or sharpness can be obtained, and one of the images having desired exposure, chroma, contrast, or sharpness can be selected therefrom. In this case, in order to reflect in the image data sets S1 the change of the image processing condition in the automatic bracket photography carried out by the digital camera 1, image processing by the output image processing means 22 is not carried out on the image data sets S1 obtained by the automatic bracket photography. Alternatively, for the items of image processing other than the item of image processing whose image processing condition was changed in the automatic bracket photography, the output image processing means 22 carries out the image processing by using the same image processing conditions.</p><p id="p0044" num="0044">If the image processing by the image output apparatus 2 is carried out on the image data sets S1 obtained by automatic bracket photography, the change in exposure, chroma, contrast, or sharpness in the automatic bracket photography cannot be reflected in the processed image data sets S2. Therefore, in the case where the image<!-- EPO <DP n="17"> --> processing information G includes information on the automatic bracket photography, the setting means 24 cancels the image processing by the output image processing means 22 or sets the image processing to be carried out according to a predetermined image processing condition for the item of image processing whose image processing condition was changed in the automatic bracket photography. More preferably, for the items of image processing other than the item of image processing whose image processing condition was changed in the automatic bracket photography, the setting means sets the output image processing means 22 to carry out the image processing by using the same image processing conditions on all the image data sets S1. In this manner, the processed image data sets S2 reflecting the effect of automatic bracket photography can be obtained.</p><p id="p0045" num="0045">In the case where the image processing information G includes information on monochrome processing or sepia-color processing, the white balance processing is set to be not carried out or to be diminished.</p><p id="p0046" num="0046">In the case where the image processing information G includes information on soft focus photography, sharpness processing is set to be not carried out or to be diminished.</p><p id="p0047" num="0047">In the case where the image processing information G includes information on interval photography, an average of an image processing parameter found from each of the image data sets S1 is used in the image processing by the output image processing means 22, in order to carry out the same image processing on all the image data sets S1 obtained by the interval photography. Alternatively, the image<!-- EPO <DP n="18"> --> processing is set to be carried out according to the same image processing parameter as the image processing parameter used for the image data set S1 that is subjected to the image processing first among all the image data sets S1.</p><p id="p0048" num="0048">In the case where the image processing information G includes information on superposition with a template, density conversion processing, white balance processing, gradation conversion processing, and color correction processing are set to be cancelled or to be diminished so as not to change colors and density of the template.</p><p id="p0049" num="0049">As shown in Table 1 below, the content of image processing on the image data sets S1 may be set according to the type of the image processing or the photography mode represented by the image processing information G. In Table 1, a circle represents cancellation or diminishing of the corresponding image processing. An X refers to usage of the predetermined condition or usage of the same image processing condition on the image data sets obtained by serial photography, multiple exposure, and superposition with a frame.
<tables id="tabl0001" num="0001"><table frame="all"><title>Table 1</title><tgroup cols="6"><colspec colnum="1" colname="col1" colwidth="28mm"/><colspec colnum="2" colname="col2" colwidth="27mm"/><colspec colnum="3" colname="col3" colwidth="27mm"/><colspec colnum="4" colname="col4" colwidth="28mm"/><colspec colnum="5" colname="col5" colwidth="29mm"/><colspec colnum="6" colname="col6" colwidth="28mm"/><thead valign="top"><row><entry>Image Processing Information</entry><entry>Color Processing</entry><entry>Chroma/Hue Processing</entry><entry>Density Conversion Processing</entry><entry>Gradation Conversion Processing</entry><entry>Sharpness Processing</entry></row></thead><tbody><row><entry>Fixed Light Source Mode</entry><entry align="center">○</entry><entry align="center">○</entry><entry/><entry/><entry/></row><row><entry>Gradation conversion Processing</entry><entry/><entry/><entry/><entry align="center">○</entry><entry/></row><row><entry>Sharpness Processing</entry><entry/><entry/><entry/><entry/><entry align="center">○</entry></row><row><entry>Saturation enhancement Processing</entry><entry/><entry align="center">○</entry><entry/><entry align="center">○</entry><entry/></row><row><entry>Portrait Mode</entry><entry/><entry align="center">○</entry><entry/><entry align="center">○</entry><entry align="center">○</entry></row><!-- EPO <DP n="19"> --><row><entry>Scenery/Distant view Mode m</entry><entry/><entry/><entry/><entry align="center">○</entry><entry align="center">○</entry></row><row><entry>Macro/Close-up Mode</entry><entry/><entry/><entry/><entry/><entry align="center">○</entry></row><row><entry>Night View/Fireworks Mode</entry><entry/><entry/><entry align="center">○</entry><entry align="center">○</entry><entry/></row><row><entry>Underwater Photography Mode</entry><entry align="center">○</entry><entry/><entry/><entry align="center">○</entry><entry/></row><row><entry>User Exposure Correction</entry><entry/><entry/><entry align="center">○</entry><entry/><entry/></row><row><entry>*Automatic Bracket Photography</entry><entry/><entry align="center">○</entry><entry align="center">○</entry><entry align="center">○</entry><entry align="center">○</entry></row><row><entry>Serial Photography</entry><entry/><entry/><entry align="center">×</entry><entry/><entry align="center">○</entry></row><row><entry>Multiple Exposure</entry><entry/><entry/><entry align="center">×</entry><entry/><entry/></row><row><entry>Superposition with Frame</entry><entry/><entry/><entry align="center">×</entry><entry/><entry/></row></tbody></tgroup><tgroup cols="6" colsep="0" rowsep="0"><colspec colnum="1" colname="col1" colwidth="28mm"/><colspec colnum="2" colname="col2" colwidth="27mm"/><colspec colnum="3" colname="col3" colwidth="27mm"/><colspec colnum="4" colname="col4" colwidth="28mm"/><colspec colnum="5" colname="col5" colwidth="29mm"/><colspec colnum="6" colname="col6" colwidth="28mm"/><tbody><row><entry namest="col1" nameend="col6" align="justify">* Select a circle, depending on the content of automatic bracket photography</entry></row></tbody></tgroup></table></tables></p><p id="p0050" num="0050">After the content of the image processing by the output image processing means has been set in the above manner, the output image processing means 22 carries out the image processing on the image data sets S1, and the processed image data sets S2 are obtained (Step S4). The processed image data sets S2 are printed by the print output means 25 as the prints P (Step S5) to end the procedures.</p><p id="p0051" num="0051">It is preferable for the image processing information G to be printed on the backside of each of the prints P. In this case, the image processing information G may be printed as characters or as illustrations that can specify the content thereof.</p><p id="p0052" num="0052">As has been described above, in the example, the content of the image processing to be carried out on the image data sets S1 is set according to the image processing information G added to the image data sets S1. Therefore, the content of the image processing on the image data sets S1 can be set so as not to influence the image<!-- EPO <DP n="20"> --> processing that has already been carried out on the image data sets S1. Consequently, by carrying out the image processing on the image data sets S1 according to the content that has been set, the processed image data sets S2 can reflect the image processing that has already been carried out on the image data sets S1.</p><p id="p0053" num="0053">By printing the image processing information G on the backside of the prints P, the photographer can easily recognize the image processing carried out on the image data sets S1 by the digital camera 1.</p><p id="p0054" num="0054">In the above example, the processed image data sets S2 may be displayed on a monitor. In this case, the image processing information G is displayed at the side of an image reproduced on the monitor.</p><p id="p0055" num="0055">An embodiment of the present invention will be explained next. <figref idrefs="f0004">Figure 4</figref> is a block diagram showing a configuration of an image output system adopting an image output apparatus of the embodiment of the present invention. In the embodiment, the same components as in the example have the same reference numbers, and detailed explanations thereof will be omitted. Differences between the example and the embodiment are as follows. Firstly, in the embodiment, a monitor 31 for displaying processed image data sets S2 as well as various kinds of information is further used together with input means 32 comprising a keyboard and a mouse for inputting the various kinds of information. In the second embodiment, judgment means 23 judges whether or not image processing information G includes a flag preventing or<!-- EPO <DP n="21"> --> diminishing image processing on image data sets S1. In the case where the flag is included, the image processing by output image processing means 22 is cancelled or diminished. At the time setting means 24 sets a degree of the image processing in the embodiment, the degree can be adjusted by a manual input from the input means 32. Furthermore, the judgment means 23 judges the content of image processing that has been carried out on the image data sets S1 by analyzing the image data sets S1.</p><p id="p0056" num="0056">The flag is included in the image processing information G by a photographer using a digital camera 1. The flag is included in the image processing information G together with information on the type of image processing and a photography mode, when the image processing is carried out on the image data sets S0 by the digital camera 1.</p><p id="p0057" num="0057">In the embodiment, the image processing information G includes the flag in addition to the information on the type of the image processing and the photography mode in the digital camera 1. However, depending on a model of the digital camera 1, the image processing information G includes only the flag, and the type of the image processing and the photography mode may not be included therein. For example, in the case where monochrome processing, sepia-color processing, photography using an optical filter, or superposition with a template is carried out, the type of image processing and the photography mode are not included in the image processing information G. Other types of image processing and photography mode may be included in the image processing information<!-- EPO <DP n="22"> --> G.</p><p id="p0058" num="0058">For this reason, in the embodiment, the judgment means 23 judges the content of the image processing that has been carried out on the image data sets S1 through analysis of the image data sets S1, in the case where the image processing information G includes the flag but the content thereof is not known.</p><p id="p0059" num="0059">The operation of the embodiment will be explained next. <figref idrefs="f0005">Figure 5</figref> is a flow chart showing the operation in the embodiment. Reading means 21 reads the image data sets S1 from a memory card 14 (Step S21). The image processing information G added to the image data sets S1 is input to the judgment means 23, and the judgment means 23 judges whether or not the flag preventing or diminishing the image processing on the image data sets S1 is included in the image processing information G (Step S22). In the case where a result at Step S22 is affirmative, the judgment means 23 further judges the type of image processing that has already been carried out on the image data sets S1, based on the image processing information G (Step S23). In this case, the type of image processing can also be judged by analyzing the image data sets S1.</p><p id="p0060" num="0060">For example, in the case where the digital camera 1 does not include in the image processing information G the content of monochrome processing carried out on the image data sets S1, the flag is included in the image processing information G but the content thereof is not included. For this reason, the judgment means 23 judges the number of channels of the image data sets S1. In the case where the image data sets S1 represent images having 1 channel, the image data sets<!-- EPO <DP n="23"> --> S1 are judged to have been subjected to monochrome processing. In the case where the number of channels is 3 but averages of RGB values are the same for entire images, the image data sets are also judged to have been subjected to monochrome processing.</p><p id="p0061" num="0061">In the case where the digital camera 1 does not include the content of sepia-color processing carried out on the image data sets S1 in the image processing information G, only the flag representing the sepia-color processing is included in the image processing information G but the content thereof is not included. For this reason, the judgment means 23 divides each of the images represented by the image data sets S1 into areas. In the case where the averages of RGB values are approximately the same in each of the areas, the image data sets S1 are judged to have been subjected to sepia-color processing.</p><p id="p0062" num="0062">In the case where the image processing information G does not include the type of the image processing and the photography mode, the judgment means 23 judges the content of the image processing on the image data sets S1 by using various methods, such as the number of channels, the averages of RGB values, and the averages in the divided areas described above.</p><p id="p0063" num="0063">Once the type of the image processing has been judged by the judgment means 23 as has been described above, the setting means 24 sets the content of the image processing to be carried out on the image data sets S1 according to the type of the image processing that has been carried out, as in the example (Step S24). In the case where the result at Step S22 is negative, the content<!-- EPO <DP n="24"> --> of the image processing to be carried out on the image data sets S1 is set at Step S24 based on the image data sets S1.</p><p id="p0064" num="0064">After the content of the image processing has been determined in the above manner, the output image processing means 22 carries out the image processing on the image data sets S1 to generate the processed image data sets S2 (Step S25). The processed image data sets S2 are displayed on the monitor 31 (Step S26), and manual processing by an operator using the input means 32 is received (Step S27).</p><p id="p0065" num="0065"><figref idrefs="f0006">Figure 6</figref> shows a manual processing input window displayed on the monitor 31. As shown in <figref idrefs="f0006">Figure 6</figref>, in the manual processing input window are displayed a processed image 41 represented by one of the processed image data sets S2, setting switch buttons 42 for switching from automatic setting to manual setting and vice versa for the image processing, a density correction button 43 for correcting density, white balance adjustment buttons 44 for adjusting white balance, tone correction buttons 45 for correcting tones, color correction buttons 46 for correcting colors, a sharpness correction button 47 for correcting sharpness, and an OK button 48 for confirming the image processing. OFF buttons are also included in the density correction button 43, the white balance adjustment buttons 44, the tone correction buttons 45, the color correction buttons 46, and the sharpness correction button 47, for cancellation of the corresponding image processing.</p><p id="p0066" num="0066">The tone correction buttons 45 include an HL button, an MD button, and an SD button representing a highlight range, an intermediate density range and a shadow range, respectively. The<!-- EPO <DP n="25"> --> color correction buttons 46 include an L button, a C button, and an H button representing lightness, chroma, and hue, respectively.</p><p id="p0067" num="0067">In the embodiment, the output image processing means 22 automatically carries out the image processing to generate the processed image data sets S2. Therefore, as shown in <figref idrefs="f0006">Figure 6</figref>, a color of an "automatic setting" button in the setting switch buttons 42 in the manual processing input window is changed so as to easily show that the automatic setting has been carried out. The color change is shown as a hatched area in <figref idrefs="f0006">Figure 6</figref>. Furthermore, in the case where white balance processing has not been carried out for example, the OFF button for the white balance adjustment button 44 is turned on so as to easily show that the white balance adjustment has not been carried out. In addition, a color of the white balance adjustment buttons 44 is also changed.</p><p id="p0068" num="0068">An operator judges whether or not the image processing is to be further carried out on the processed image data sets in the manual processing input window. In the case where the manual processing is necessary, the operator clicks a "manual setting" button in the setting switch buttons 42. In this manner, all the buttons in the window becomes usable, and the operator carries out manual processing for a desired image quality by adjusting the degree of the image processing with the buttons.</p><p id="p0069" num="0069">Whether or not the OK button 48 has been clicked is then judged (Step S28). The input for manual processing is received until a result at Step S28 becomes affirmative. When the result at Step S28 becomes affirmative, the processed image data sets S2 are output as prints<!-- EPO <DP n="26"> --> P by print output means 25 (Step S29) to end the operation.</p><p id="p0070" num="0070">As has been described above, in the embodiment, the content of the image processing to be carried out on the image data sets S1 can be set according to the image processing information G added to the image data sets S1. Therefore, the content can be set so as not to influence the image processing that has already been carried out on the image data sets S1. Furthermore, by carrying out the image processing according to the manual input, the image processing can be carried out on the image data sets S1 as the operator wishes, and the processed image data sets S2 can reflect a preference of the operator as well as the image processing that has already been carried out on the image data sets S1.</p><p id="p0071" num="0071">In the example and the embodiment described above, the image output apparatus 2 carries out the image processing on the image data sets S1 that have already been subjected to the image processing by the digital camera 1. In the case where the image data sets S1 have been subjected to image processing by a personal computer or the like and added with the image processing information G representing the content of the image processing, the content of the image processing to be carried out on the image data sets S1 may be set according to the image processing information G, as in the example and the embodiment described above.</p><p id="p0072" num="0072">In the example and the embodiment described above, the digital camera 1 includes the photography mode in the image processing information G. However, the type of image processing carried out on the image data sets S0 according to the photography mode may be<!-- EPO <DP n="27"> --> included in the image processing information G, instead of the photography mode.</p></description><claims mxw-id="PCLM56987696" lang="DE" load-source="patent-office"><!-- EPO <DP n="30"> --><claim id="c-de-01-0001" num="0001"><claim-text>Bildverarbeitungsverfahren zur Durchführung in einer Bildausgabevorrichtung zum Gewinnen verarbeiteter Bilddaten, indem eine Bildverarbeitung bezüglich Bilddaten ausgeführt wird, denen Bildverarbeitungsinformation (G) in Bezug auf eine Bildverarbeitung hinzugefügt ist, die den Inhalt der bezüglich der Bilddaten in einer Digitalkamera ausgeführten Bildverarbeitung repräsentiert oder Information repräsentiert, aus der der Inhalt der Bildverarbeitung abgeleitet werden kann, die bezüglich der Bilddaten ausgeführt wurde, <b>gekennzeichnet durch</b>:
<claim-text>Beurteilen, ob die Bildverarbeitungsinformation Information über den Typ der Bildverarbeitung, die in der Digitalkamera durchgeführt wurde, enthält, und falls der Typ der Bildverarbeitung enthalten ist:
<claim-text>Einstellen des Inhalts der Bildverarbeitung, die bezüglich der Bilddaten auszuführen ist, basierend auf der Bildverarbeitungsinformation (G); und</claim-text>
<claim-text>falls der Typ der Bildverarbeitung nicht enthalten ist:
<claim-text>Einstellen des Inhalts der Bildverarbeitung, die bezüglich der Bilddaten auszuführen ist, basierend auf einem Ergebnis einer Analyse der Bilddaten, zusätzlich zu der Bildverarbeitungsinformation.</claim-text></claim-text></claim-text></claim-text></claim><claim id="c-de-01-0002" num="0002"><claim-text>Bildverarbeitungsverfahren nach Anspruch 1, weiterhin umfassend den Schritt des Ausgebens der Bildverarbeitungsinformation zusammen mit den verarbeiteten Bilddaten.</claim-text></claim><claim id="c-de-01-0003" num="0003"><claim-text>Bildausgabevorrichtung (2), umfassend eine Verarbeitungseinrichtung zum Gewinnen verarbeiteter Bilddaten durch Ausführen einer Bildverarbeitung bezüglich Bilddaten, denen Bildverarbeitungsinformation über eine Bildverarbeitung hinzugefügt ist, welche den Inhalt der Bildverarbeitung repräsentiert, die bereits in einer Digitalkamera (1) bezüglich der Bilddaten ausgeführt wurde, oder Information, aus der sich der Inhalt der ausgeführten Bildverarbeitung der Bilddaten ableiten lässt, <b>gekennzeichnet durch</b><br/>
<!-- EPO <DP n="31"> -->weiterhin umfassend eine Beurteilungseinrichtung (23), ausgebildet zum Beurteilen, ob die Bildverarbeitungsinformation Information über den Typ der in der Digitalkamera ausgeführten Bildverarbeitung enthält,<br/>
falls die Beurteilungseinrichtung (23) beurteilt, dass der Typ der Bildverarbeitung enthalten ist, die Verarbeitungseinrichtung dazu ausgebildet ist, den Inhalt der bezüglich der Bilddaten auszuführenden Bildverarbeitung basierend auf der Bildverarbeitungsinformation (G) einzustellen; und<br/>
falls die Beurteilungseinrichtung (23) beurteilt, dass der Typ der Bildverarbeitung nicht enthalten ist:
<claim-text>die Verarbeitungseinrichtung den Inhalt der bezüglich der Bilddaten auszuführenden Bildverarbeitung basierend auf einem Ergebnis der Analyse der Bilddaten zusätzlich zu der Bildverarbeitungsinformation einstellt.</claim-text></claim-text></claim><claim id="c-de-01-0004" num="0004"><claim-text>Bildverarbeitungsvorrichtung nach Anspruch 3, weiterhin umfassend eine Ausgabeeinrichtung (25) zum Ausgeben der Bildverarbeitungsinformation zusammen mit den verarbeiteten Bilddaten.</claim-text></claim><claim id="c-de-01-0005" num="0005"><claim-text>Programm, das einen Computer veranlasst, das Bildverarbeitungsverfahren nach Anspruch 1 oder 2 auszuführen.</claim-text></claim></claims><claims mxw-id="PCLM56987697" lang="EN" load-source="patent-office"><!-- EPO <DP n="28"> --><claim id="c-en-01-0001" num="0001"><claim-text>An image processing method to be carried out in an image output apparatus for obtaining processed image data by carrying out image processing on image data added with image processing information (G) regarding image processing that represents the content of the image processing which has been carried out on the image data in a digital camera or information from which the content of the image processing that has been carried out on the image data can be inferred, <b>characterized by</b>:
<claim-text>judging, whether the image processing information includes information on the type of image processing carried out in the digital camera, in case the type of image processing is included:
<claim-text>setting the content of the image processing to be carried out on the image data based on the image processing information (G); and</claim-text>
<claim-text>in case the type of image processing is not included:
<claim-text>setting the content of the image processing to be carried out on the image data based on a result of analysis of the image data in addition to the image processing information.</claim-text></claim-text></claim-text></claim-text></claim><claim id="c-en-01-0002" num="0002"><claim-text>An image processing method as defined in claim 1, further comprising the step of outputting the image processing information together with the processed image data.</claim-text></claim><claim id="c-en-01-0003" num="0003"><claim-text>An image output apparatus (2) comprising processing means for obtaining processed image data by carrying out image processing on image data added with image processing information regarding image processing that represents the content of the image processing which has already been carried out on the image data in a digital camera (1) or information from which the content of the image processing that has been carried out on the image data can be inferred,<br/>
<b>characterized by</b><br/>
<!-- EPO <DP n="29"> -->further comprising judging means (23) adapted for judging, whether the image processing information includes information on the type of image processing carried out in the digital camera,<br/>
in case the judging means (23) judges the type of image processing is included, the processing means is adapted to set the content of the image processing to be carried out on the image data based on the image processing information (G); and<br/>
in case the judging means (23) judges that the type of image processing is not included:
<claim-text>the processing means sets the content of the image processing to be carried out on the image data based on a result of analysis of image data in addition to the image processing information.</claim-text></claim-text></claim><claim id="c-en-01-0004" num="0004"><claim-text>An image processing apparatus as defined in claim 3, the image processing apparatus further comprising output means (25) for outputting the image processing information together with the processed image data.</claim-text></claim><claim id="c-en-01-0005" num="0005"><claim-text>A program that causes a computer to execute the image processing method as defined by claim 1 or 2.</claim-text></claim></claims><claims mxw-id="PCLM56987698" lang="FR" load-source="patent-office"><!-- EPO <DP n="32"> --><claim id="c-fr-01-0001" num="0001"><claim-text>Procédé de traitement d'image destiné à être exécuté dans un dispositif de sortie d'image pour obtenir des données d'image traitée en effectuant un traitement d'image sur des données d'image auxquelles sont ajoutées des informations de traitement d'image (G) concernant le traitement d'image, représentant le contenu du traitement d'image ayant été effectué sur les données d'image dans un dispositif de prise de vue numérique ou des informations d'après lesquelles peut être déduit le contenu du traitement d'image ayant été effectué sur les données d'image, <b>caractérisé par</b> :
<claim-text>l'estimation du fait que les informations de traitement d'image comportent des informations concernant le type de traitement d'image effectué dans le dispositif de prise de vue numérique, dans le cas où le type de traitement d'image est inclus :
<claim-text>la détermination du contenu du traitement d'image à effectuer sur les données d'image en se basant sur les informations de traitement d'image (G) ; et</claim-text>
<claim-text>dans le cas où le type de traitement d'image n'est pas inclus :
<claim-text>la détermination du contenu du traitement d'image à effectuer sur les données d'image en se basant sur le résultat de l'analyse des données d'image auxquelles sont ajoutées les informations de traitement d'image.</claim-text></claim-text></claim-text></claim-text></claim><claim id="c-fr-01-0002" num="0002"><claim-text>Procédé de traitement d'image selon la revendication 1, comprenant en outre l'étape de fourniture en sortie des informations de traitement d'image avec les données de l'image traitée.</claim-text></claim><claim id="c-fr-01-0003" num="0003"><claim-text>Dispositif de sortie d'image (2) comprenant un moyen de traitement pour obtenir des données d'image traitée en effectuant un traitement d'image sur des données d'image auxquelles sont ajoutées des informations de traitement d'image concernant le traitement d'image, représentant le contenu du traitement d'image ayant déjà été effectué sur les données d'image dans un dispositif de prise de vue numérique (1) ou des informations d'après lesquelles peut être déduit le contenu du traitement d'image ayant été effectué sur les données d'image,<br/>
<!-- EPO <DP n="33"> --><b>caractérisé en ce qu'</b>il comprend en outre un moyen d'estimation (23) adapté à estimer si les informations de traitement d'image comportent des informations concernant le type de traitement d'image effectué dans le dispositif de prise de vue numérique,<br/>
dans le cas où le moyen d'estimation (23) estime que le type de traitement d'image est inclus, le moyen de traitement est adapté à déterminer le contenu du traitement d'image à effectuer sur les données d'image en se basant sur les informations de traitement d'image (G) ; et<br/>
dans le cas où le moyen d'estimation (23) estime que le type de traitement d'image n'est pas inclus :
<claim-text>le moyen de traitement détermine le contenu du traitement d'image à effectuer sur les données d'image en conséquence de l'analyse des données d'image auxquelles sont ajoutées les informations de traitement d'image.</claim-text></claim-text></claim><claim id="c-fr-01-0004" num="0004"><claim-text>Dispositif de traitement d'image selon la revendication 3, le dispositif de traitement d'image comprenant en outre un moyen de sortie (25) pour fournir en sortie les informations de traitement d'image avec les données de l'image traitée.</claim-text></claim><claim id="c-fr-01-0005" num="0005"><claim-text>Programme faisant exécuter par un ordinateur le procédé de traitement d'image selon la revendication 1 ou 2.</claim-text></claim></claims><drawings mxw-id="PDW16672824" load-source="patent-office"><!-- EPO <DP n="34"> --><figure id="f0001" num="1"><img id="if0001" file="imgf0001.tif" wi="140" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="35"> --><figure id="f0002" num="2"><img id="if0002" file="imgf0002.tif" wi="109" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="36"> --><figure id="f0003" num="3"><img id="if0003" file="imgf0003.tif" wi="103" he="168" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="37"> --><figure id="f0004" num="4"><img id="if0004" file="imgf0004.tif" wi="149" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="38"> --><figure id="f0005" num="5"><img id="if0005" file="imgf0005.tif" wi="143" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="39"> --><figure id="f0006" num="6"><img id="if0006" file="imgf0006.tif" wi="160" he="175" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="40"> --><figure id="f0007" num="7"><img id="if0007" file="imgf0007.tif" wi="160" he="175" img-content="drawing" img-format="tif"/></figure></drawings><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
