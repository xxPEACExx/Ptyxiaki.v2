<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2184637-B1" country="EP" doc-number="2184637" kind="B1" date="20140108" family-id="41508384" file-reference-id="315042" date-produced="20180826" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="146588236" ucid="EP-2184637-B1"><document-id><country>EP</country><doc-number>2184637</doc-number><kind>B1</kind><date>20140108</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-09175146-A" is-representative="YES"><document-id mxw-id="PAPP154850428" load-source="docdb" format="epo"><country>EP</country><doc-number>09175146</doc-number><kind>A</kind><date>20091105</date><lang>EN</lang></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC140549185" ucid="JP-2008284293-A" load-source="docdb"><document-id format="epo"><country>JP</country><doc-number>2008284293</doc-number><kind>A</kind><date>20081105</date></document-id></priority-claim></priority-claims><dates-of-public-availability><intention-to-grant-date><date>20130528</date></intention-to-grant-date></dates-of-public-availability><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL1989325038" load-source="docdb">G03B  13/04        20060101AFI20130412BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1989325039" load-source="docdb">G03B  13/12        20060101ALI20130412BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1989325040" load-source="docdb">G03B  17/02        20060101ALI20130412BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1989325041" load-source="docdb">G03B  19/02        20060101ALI20130412BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1989325042" load-source="docdb">H04N   5/225       20060101ALI20130412BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1989325043" load-source="docdb">H04N   5/232       20060101ALI20130412BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-2081701773" load-source="docdb" scheme="CPC">H04N   5/23245     20130101 LI20150323BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2081703702" load-source="docdb" scheme="CPC">G03B  17/02        20130101 LI20150323BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2081704142" load-source="docdb" scheme="CPC">H04N   5/23241     20130101 LI20150323BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2081705476" load-source="docdb" scheme="CPC">G03B  19/02        20130101 LI20150323BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2081711484" load-source="docdb" scheme="CPC">G03B  13/12        20130101 LI20150323BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2081712331" load-source="docdb" scheme="CPC">G03B  13/04        20130101 LI20150323BHEP        </classification-cpc><classification-cpc mxw-id="PCL2007269532" load-source="docdb" scheme="CPC">H04N   5/23293     20130101 FI20140201BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT132369341" lang="DE" load-source="patent-office">Bildgebungsvorrichtung und Anzeigesteuerungsverfahren dafür</invention-title><invention-title mxw-id="PT132369342" lang="EN" load-source="patent-office">Imaging apparatus and display control method thereof</invention-title><invention-title mxw-id="PT132369343" lang="FR" load-source="patent-office">Appareil d'imagerie et son procédé de contrôle d'affichage correspondant</invention-title></technical-data><parties><applicants><applicant mxw-id="PPAR919545202" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>SONY CORP</last-name><address><country>JP</country></address></addressbook></applicant><applicant mxw-id="PPAR919532405" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>SONY CORPORATION</last-name></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR919535881" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>AKITA MIHO</last-name><address><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR919534247" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>AKITA, MIHO</last-name></addressbook></inventor><inventor mxw-id="PPAR919022178" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>AKITA, MIHO</last-name><address><street>c/o SONY CORPORATION 1-7-1 Konan Minato-ku</street><city>Tokyo</city><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR919516209" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>MARUKAWA KAZUYUKI</last-name><address><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR919507276" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>MARUKAWA, KAZUYUKI</last-name></addressbook></inventor><inventor mxw-id="PPAR919022177" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>MARUKAWA, KAZUYUKI</last-name><address><street>c/o SONY CORPORATION 1-7-1 Konan Minato-ku</street><city>Tokyo</city><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR919520427" load-source="docdb" sequence="3" format="epo"><addressbook><last-name>TANAKA SHO</last-name><address><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR919512689" load-source="docdb" sequence="3" format="intermediate"><addressbook><last-name>TANAKA, SHO</last-name></addressbook></inventor><inventor mxw-id="PPAR919022176" load-source="patent-office" sequence="3" format="original"><addressbook><last-name>TANAKA, SHO</last-name><address><street>c/o SONY CORPORATION 1-7-1 Konan Minato-ku</street><city>Tokyo</city><country>JP</country></address></addressbook></inventor></inventors><assignees><assignee mxw-id="PPAR919022180" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Sony Corporation</last-name><iid>101016072</iid><address><street>1-7-1 Konan, Minato-ku</street><city>Tokyo</city><country>JP</country></address></addressbook></assignee></assignees><agents><agent mxw-id="PPAR919022179" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Thévenet, Jean-Bruno</last-name><suffix>et al</suffix><iid>100018552</iid><address><street>Cabinet Beau de Loménie 158, rue de l'Université</street><city>75340 Paris Cédex 07</city><country>FR</country></address></addressbook></agent></agents></parties><international-convention-data><designated-states><ep-contracting-states><country mxw-id="DS549876124" load-source="docdb">AT</country><country mxw-id="DS549871387" load-source="docdb">BE</country><country mxw-id="DS549783038" load-source="docdb">BG</country><country mxw-id="DS549923246" load-source="docdb">CH</country><country mxw-id="DS549868431" load-source="docdb">CY</country><country mxw-id="DS549876125" load-source="docdb">CZ</country><country mxw-id="DS549783953" load-source="docdb">DE</country><country mxw-id="DS549871388" load-source="docdb">DK</country><country mxw-id="DS549868432" load-source="docdb">EE</country><country mxw-id="DS549800328" load-source="docdb">ES</country><country mxw-id="DS549783039" load-source="docdb">FI</country><country mxw-id="DS549783040" load-source="docdb">FR</country><country mxw-id="DS549783954" load-source="docdb">GB</country><country mxw-id="DS549871389" load-source="docdb">GR</country><country mxw-id="DS549783955" load-source="docdb">HR</country><country mxw-id="DS549868433" load-source="docdb">HU</country><country mxw-id="DS549923247" load-source="docdb">IE</country><country mxw-id="DS549871394" load-source="docdb">IS</country><country mxw-id="DS549783045" load-source="docdb">IT</country><country mxw-id="DS549871395" load-source="docdb">LI</country><country mxw-id="DS549783956" load-source="docdb">LT</country><country mxw-id="DS549876130" load-source="docdb">LU</country><country mxw-id="DS549783961" load-source="docdb">LV</country><country mxw-id="DS549783962" load-source="docdb">MC</country><country mxw-id="DS549876131" load-source="docdb">MK</country><country mxw-id="DS549876132" load-source="docdb">MT</country><country mxw-id="DS549871396" load-source="docdb">NL</country><country mxw-id="DS549783963" load-source="docdb">NO</country><country mxw-id="DS549871397" load-source="docdb">PL</country><country mxw-id="DS549783046" load-source="docdb">PT</country><country mxw-id="DS549871402" load-source="docdb">RO</country><country mxw-id="DS549871403" load-source="docdb">SE</country><country mxw-id="DS549923248" load-source="docdb">SI</country><country mxw-id="DS549783964" load-source="docdb">SK</country><country mxw-id="DS549783969" load-source="docdb">SM</country><country mxw-id="DS549876133" load-source="docdb">TR</country></ep-contracting-states></designated-states></international-convention-data></bibliographic-data><description mxw-id="PDES63960662" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><heading id="h0001">BACKGROUND OF THE INVENTION</heading><heading id="h0002">1. Field of the Invention</heading><p id="p0001" num="0001">The present invention relates to an imaging apparatus and the display control method thereof, and specifically relates to the display operation of an imaging apparatus wherein multiple display panel units are provided on the casing thereof.</p><heading id="h0003">2. Description of the Related Art</heading><p id="p0002" num="0002">Imaging apparatuses such as digital still cameras, digital video cameras, and so forth have come into widespread use, and with many of them, a display panel made up of a liquid crystal panel or the like is formed.</p><p id="p0003" num="0003">For example, as disclosed in Japanese Unexamined Patent Application Publication No. <patcit id="pcit0001" dnum="JP2007158799A"><text>2007-158799</text></patcit>, an arrangement is made wherein a display panel is provided on a camera casing with a relatively great area, monitoring of a subject image is executed at the time of imaging, and playback display is executed at the time of playback of a captured image.</p><p id="p0004" num="0004"><patcit id="pcit0002" dnum="US2006210263A"><text>US 2006/210263</text></patcit> describes an imaging apparatus including a display screen facing the user and a second screen which is moveable between a position in which it covers the first display screen and a position in which it faces a subject being photographed. Display on the subject-facing display screen can be controlled based on an operational mode of the imaging apparatus.</p><p id="p0005" num="0005"><patcit id="pcit0003" dnum="JP2008228053A"><text>JP 2008-228053</text></patcit> describes an imaging apparatus having respective display screens that face the user and the subject. The subject-facing screen can be switched off if it is judged that a person is not present on the subject side of the imaging apparatus.</p><heading id="h0004">SUMMARY OF THE INVENTION</heading><p id="p0006" num="0006">Now, the present assignee has newly conceived an arrangement for providing two display panel units on the casing of an imaging apparatus. Specifically, similar to the related art, in addition to a display panel unit configured to execute display toward the user (the person using the imaging apparatus) direction on an imaging apparatus casing, a display panel unit configured to execute display toward a subject side is provided to the front face side (side serving as a subject side) or the like on the apparatus casing.</p><p id="p0007" num="0007">Thus, in the case that such two display panel units are provided, suitable display should be made at each display panel, i.e., display effective for a viewer, and display operation so as to avoid wasteful operations and consumption power, according to the operation state or situation relating to imaging.</p><p id="p0008" num="0008">It has been found to be desirable to realize suitable display at an imaging apparatus including two display panel units.</p><p id="p0009" num="0009">According to an embodiment of the present invention, an imaging apparatus includes: a first display panel unit configured to execute display toward a user side, disposed on an apparatus casing; a second display panel unit configured to execute display toward a subject side, disposed on the apparatus casing; an imaging processing unit configured to subject incident light from the subject side to photoelectric conversion to obtain a captured image signal; and a control unit configured to execute imaging<!-- EPO <DP n="2"> --> processing control according to the imaging mode setting, and execute display based on the captured image signal obtained by the imaging processing unit with the first display panel unit, while controlling the display operations based on the captured image signal obtained with the imaging processing unit of the second display panel unit, at least according to the imaging mode; characterized in that the control unit is configured to estimate when visibility of said second display panel unit is poor for a person on the subject side of the imaging apparatus and to control display operations of said second display panel unit dependent on the result of the poor-visibility estimation.</p><p id="p0010" num="0010">Also, the control unit may perform control to execute display based on the captured image signal obtained with the imaging processing unit on the second display panel, in the case that the imaging mode is a predetermined imaging mode determined beforehand out of multiple imaging modes.</p><p id="p0011" num="0011">Also, the control unit may perform control to turn the display of the second display panel off in the case that the imaging mode is not the predetermined imaging mode.</p><p id="p0012" num="0012">Also, the control unit may perform control to execute display based on the captured image signal obtained with the imaging processing unit on the second display panel unit in a low luminance state, in the case that the imaging mode is not the predetermined imaging mode.</p><p id="p0013" num="0013">Also, the imaging apparatus may further include: an image data reading unit configured to read image data recorded on a storage medium; wherein the control unit performs control to execute display based on image data read out by the image data reading unit on the second display panel, in the case that the imaging mode is not the predetermined imaging mode.</p><p id="p0014" num="0014">Also, the control unit may control the display operation based on the captured image signal obtained with the imaging processing unit on the second display panel unit, based on the imaging mode and a settings state according to the operations of the user relating to operations of the imaging apparatus other than the imaging mode.</p><p id="p0015" num="0015">Also, the control unit may control the display operation based on the captured image signal obtained with the imaging processing unit on the second display panel unit, based on the imaging mode and the internal detecting information of the imaging apparatus.</p><p id="p0016" num="0016">Also, the imaging apparatus may further include: an image analysis unit configured to perform image analysis of the captured image signal obtained with the imaging processing unit, wherein the control unit controls the display operation based on the captured image signal obtained with the imaging processing unit with the second display panel unit, based on the imaging mode, and image analysis information from the image analysis unit.</p><p id="p0017" num="0017">Also, the image analysis unit may detect whether or not a person exists at the<!-- EPO <DP n="3"> --> subject side from the image analysis of the captured image signal obtained with the imaging processing unit.</p><p id="p0018" num="0018">Also, the imaging apparatus may further include: an operating unit configured to select the imaging mode.</p><p id="p0019" num="0019">A display control method for the imaging apparatus with a first display panel unit configured to execute display toward a user side and a second display panel unit configured to execute display toward a subject side includes the steps of:; executing display on the first display panel based on a captured image signal obtained by subjecting incident light from the subject side to photoelectric conversion; and with a second display panel unit configured to execute display toward a subject side, disposed on the apparatus casing; and controlling display operations of said captured image signal on the second display panel according to an imaging mode selected from various types of imaging modes to perform imaging processing suitable to the imaging situation; characterized in that the controlling step is configured to estimate when visibility of said second display panel unit is poor for a person on the subject side of the imaging apparatus and to control display operations of said second display panel unit dependent on the result of the poor-visibility estimation.</p><p id="p0020" num="0020">That is to say, according to the above configuration, operations for the second display panel unit are performed according to imaging mode. An imaging mode is a mode set according to various types of imaging situations and imaging objectives. For example, these are modes that a user can select, for example, so that imaging processing suitable can be performed according to what sort of image is desired in what sort of location and situation, for example. Exposure adjusting conditions, signal processing parameters, and so forth are set for each of various types of imaging modes.</p><p id="p0021" num="0021">In the case of the above configuration, the possibility of a person existing at the subject side is determined, and display with the second display panel unit is performed.</p><p id="p0022" num="0022">Also, for example, during the monitoring period at the time of imaging of a still image (when awaiting a suitable timing for imaging of a still image), the user of the imaging apparatus (i.e., a user who attempts to perform imaging of a still image with the imaging apparatus) performs monitoring of a subject image using the first display panel unit. This monitoring image is a captured image signal to be obtained at the imaging device unit during that period, also referred to as a through image, a real time moving image of a subject scene. The user confirms the subject image thus imaged to perform a release operation (shutter operation) at a desired timing. This is the same as with a common imaging apparatus.</p><p id="p0023" num="0023">During this monitoring period, with the second display panel unit, it is suitable to<!-- EPO <DP n="4"> --> execute display based on a captured image signal, i.e., display a monitoring image serving as a through image. For example, in the case that a subject is a person, the person thereof can confirm his facial expression, pose, or the like to be imaged through the display of the second display panel unit.</p><p id="p0024" num="0024">However, this is effective only when the person is on the subject side. For example, when the user selects a scenery mode serving as an imaging mode, and attempts to image scenery where there is no person, it can be conceived that there is no person who view the display of the second display panel unit. Therefore, in such a case, there is no meaning even if a monitoring image is displayed on the second display panel unit. Consequently, it is suitable to attempt to perform power saving by turning off the second display panel unit.</p><p id="p0025" num="0025">For example, the display operations of the second display panel units are controlled suitably according to the status estimated from the imaging mode at that time, whereby useful display or more enjoyable display by the two display panel units, avoidance of increase in excessive consumption power even if the two display panel units are provided, or the like can be realized.</p><p id="p0026" num="0026">According to the above configuration, with an imaging apparatus, two display panel units are provided whereby the user side and the subject side can visually recognize their sides respectively, and each display panel can execute suitable display according to the imaging status estimated by the imaging mode.</p><p id="p0027" num="0027">Particularly, whether or not there is a person at the subject side who can view the second display panel and the display thereupon unit is assumed, and the display operation of the second display panel unit is controlled accordingly. That is to say, useful display, display with high enjoyableness, avoidance of wasteful display, or the like can be realized, and accordingly, a new and useful imaging apparatus can be provided.</p><heading id="h0005">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p0028" num="0028"><ul><li><figref idrefs="f0001">Figs. 1A and 1B</figref> are explanatory diagrams of an external view example of an imaging apparatus according to an embodiment of the present invention;</li><li><figref idrefs="f0002">Fig. 2</figref> is a block diagram of the imaging apparatus according to the embodiment;</li><li><figref idrefs="f0003">Fig. 3</figref> is an explanatory diagram of the operation transition of the imaging apparatus according to the embodiment;</li><li><figref idrefs="f0004">Figs. 4A through 4C</figref> are explanatory diagrams of an image display example of the imaging apparatus according to the embodiment;<!-- EPO <DP n="5"> --></li><li><figref idrefs="f0005">Figs. 5A through 5C</figref> are explanatory diagrams of an image display example of the imaging apparatus according to the embodiment;</li><li><figref idrefs="f0006">Fig. 6</figref> is a flowchart of a display control example of a front display panel based on the imaging mode of the embodiment;</li><li><figref idrefs="f0007">Fig. 7</figref> is a flowchart of a display control example of a front display panel based on the imaging mode of the embodiment;</li><li><figref idrefs="f0008">Fig. 8</figref> is a flowchart of a display control example with consideration for a self-imaging mode on the front display panel of the embodiment;</li><li><figref idrefs="f0009">Fig. 9</figref> is a flowchart of a display control example of the front display panel based on the imaging mode and user settings of the embodiment;</li><li><figref idrefs="f0010">Fig. 10</figref> is a flowchart of a display control example of the front display panel based on the imaging mode and camera detection information of the embodiment;</li><li><figref idrefs="f0011">Fig. 11</figref> is a flowchart of a display control example of the front display panel based on the imaging mode and image analysis results of the embodiment;</li><li><figref idrefs="f0012">Fig. 12</figref> is a flowchart of a display control example of the front display panel based on the imaging mode and image analysis results of the embodiment;</li><li><figref idrefs="f0013">Fig. 13</figref> is a flowchart of a display control example of the front display panel based on the imaging mode and image analysis results of the embodiment;</li><li><figref idrefs="f0014">Fig. 14</figref> is a flowchart of a display control example of a front display panel with consideration for a smile shutter mode of the embodiment; and</li><li><figref idrefs="f0015">Fig. 15</figref> is a flowchart of a display control example of a front display panel at time of playback of the embodiment.</li></ul></p><heading id="h0006">DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading><p id="p0029" num="0029">Description will be made below regarding an embodiment of the present invention in accordance with the following sequence.
<ol><li>1. Configuration of Imaging Apparatus</li><li>2. Operation Transition</li><li>3. Screen Display Examples of Both Display Panel Units</li><li>4. Display Control of Front Display Panel Unit When Monitoring
<ul><li>&lt;4-1: Processing Example Based on Imaging mode&gt;</li><li>&lt;4-2: Processing Example Based on Imaging mode and User Settings&gt;</li><li>&lt;4-3: Processing Example Based on Imaging mode and Internal Detecting<!-- EPO <DP n="6"> --> Information&gt;</li><li>&lt;4-4: Processing Example Based on Imaging mode and Image Analysis Information&gt;</li></ul></li><li>5. Display Control of Front Display Panel Unit During Playback</li><li>6. Modification Examples</li></ol></p><heading id="h0007">1. Configuration of Imaging Apparatus</heading><p id="p0030" num="0030">As an embodiment of the present invention, the configuration of an imaging apparatus, for example, serving as a digital camera, will be described with reference to <figref idrefs="f0001">Figs. 1A, 1B</figref>, and <figref idrefs="f0002">2</figref>.</p><p id="p0031" num="0031"><figref idrefs="f0001">Figs. 1A and 1B</figref> illustrate an external view of an imaging apparatus 1 according to the present example as viewed from the back side (user side) and front side (subject side) thereof. With the imaging apparatus 1, an imaging lens unit 20 and a flash emitting unit 15, and so forth are provided to the front side.</p><p id="p0032" num="0032">Also, operators used for user operations are formed on various portions such as the casing upper face, back side, and so forth. For example, there are provided a release operation key 5a, a dial operating portion 5b, a wide/tele operation key 5c, various types of operating keys 5d, a D-pad 5e, and so forth. The dial operating portion 5b is used for selection of an imaging mode or the like, for example. Operations such as a menu instruction, a playback instruction, an exposure correction instruction, and so forth are available through the operating keys 5d. The D-pad 5e is used for various types of operations including selection/determination of an operation menu item to be displayed on a display panel 6, for example.</p><p id="p0033" num="0033">With the imaging apparatus 1, as shown in <figref idrefs="f0001">Fig. 1A</figref>, a main display panel 6M made up of a liquid crystal panel, an organic electroluminescence (EL) panel, or the like is provided to the back side, and as shown in <figref idrefs="f0001">Fig. 1B</figref>, a front display panel 6F similarly made up of a liquid crystal panel, an organic EL panel, or the like is provided to the front side.</p><p id="p0034" num="0034">The main display panel 6M and the front display panel 6F have, for example, the same screen size, and are provided so as to occupy a relatively wide area of the casing back and the casing front respectively. With the main display panel 6M, basically, during the monitoring period (when awaiting a suitable timing in the imaging mode) display of a monitoring image (through image) where a user is a subject is executed, whereby the user can confirm a subject scenery serving as an imaging target. Also, with a playback mode, display of a playback image or thumbnail images is executed in accordance with the<!-- EPO <DP n="7"> --> operation by the user.</p><p id="p0035" num="0035">On the other hand, the front display panel 6F is directed to the subject side to execute display. With the front display panel 6F as well, an arrangement is made wherein display of a monitoring image or the like is executed, whereby a person serving as the subject side can view display content thereof, which will be described later.</p><p id="p0036" num="0036">A configuration example of such an imaging apparatus 1 will be described with reference to <figref idrefs="f0002">Fig. 2</figref>. As shown in <figref idrefs="f0002">Fig. 2</figref>, the imaging apparatus 1 includes an imaging system 2, a control system 3, a camera digital signal processor (DSP) 4, an operating unit 5, a main display panel 6M, a front display panel 6F, a display controller 7, an external interface 8, SDRAM (Synchronous Dynamic Random Access Memory) 9, and a medium interface 10.</p><p id="p0037" num="0037">The imaging system 2 is a portion to execute an imaging operation, and includes a lens mechanical unit 21, a diaphragm/ND filter mechanism 22, an imaging device unit 23, an analog signal processing unit 24, an A/D conversion unit 25, a lens driving unit 26, a lens position detecting unit 27, a timing generating circuit 28, a blurring detecting unit 13, an emission driving unit 14, a flash emitting unit 15, a lens driving driver 17, a diaphragm/ND driving driver 18, and an imaging device driver 19.</p><p id="p0038" num="0038">The incident light from a subject is guided to the imaging device unit 23 via the lens mechanical unit 21 and the diaphragm/ND filter mechanism 22. The lens mechanical unit 21 is the internal configuration of the imaging lens unit 20 in <figref idrefs="f0001">Fig. 1B</figref>, and includes multiple optical lens groups such as a cover lens, a focus lens, a zoom lens, and so forth. Also, the lens driving unit 26 is a transfer mechanism to transfer the focus lens or zoom lens in the optical axis direction. The lens driving unit 26 to which driving power is applied by the lens driving driver 17 transfers the focus lens or zoom lens. A later-described CPU (Central Processing Unit) 31 controls the lens driving driver 17, thereby executing focus control or zoom operation.</p><p id="p0039" num="0039">The diaphragm/ND filter mechanism 22 includes a diaphragm mechanism, and an ND filter mechanism to attenuate an incident light quantity by being inserted into the lens optical system, and executes optical quantity adjustment. The diaphragm/ND filter mechanism 22 executes optical quantity adjustment by opening/closing a diaphragm mechanism. Also, the diaphragm/ND driving driver 18 takes an ND filter in and out as to the optical axis of incident light, thereby adjusting an incident light quantity. The CPU 31 controls the diaphragm/ND driving driver 18 to drive the diaphragm mechanism or ND filter,<!-- EPO <DP n="8"> --> whereby incident light quantity control (exposure adjustment control) can be executed.</p><p id="p0040" num="0040">The luminous flux from the subject passes through the lens mechanical unit 21 and the diaphragm/ND filter mechanism 22, whereby a subject image is formed on the imaging device unit 23. The imaging device unit 23 subjects the formed subject image to photoelectric conversion to output the captured image signal corresponding to the subject image. The imaging device unit 23 includes a rectangular imaging region made up of multiple pixels, and sequentially outputs, to the analog signal processing unit 24, the image signal that is the analog signal corresponding to the charge accumulated in each pixel in increments of pixels. For example, a CCD (Charge Coupled Device) sensor array, a CMOS (Complementary Metal Oxide Semiconductor) sensor array, or the like is used as the imaging device unit 23.</p><p id="p0041" num="0041">The analog signal processing unit 24 internally includes a CDS (Correlation Double Sampling) circuit, an AGC (Automatic Gain Control) circuit, and so forth, and subjects the image signal input from the imaging device unit 23 to a predetermined analog process. The A/D conversion unit 25 converts the analog signal processed as the analog signal processing unit 24 into a digital signal, and supplies this to the camera DSP 4.</p><p id="p0042" num="0042">The timing generating circuit 28, which is controlled by the CPU 31, controls the timing of various operations of the imaging device unit 23, analog signal processing unit 24, and A/D conversion unit 25.</p><p id="p0043" num="0043">Specifically, the timing generating circuit 28 supplies, in order to control the imaging operation timing of the imaging device unit 23, a timing signal for exposure/charge readout, a timing signal serving as an electric shutter function, a transfer clock, a synchronizing signal according to a frame rate, and so forth to the imaging device unit 23 via the imaging device driver 19. Also, the timing generating circuit 28 also supplies the above various timing signals to the analog signal processing unit 24 so that the analog signal processing unit 24 can execute a process in sync with transfer of an image signal at the imaging device unit 23.</p><p id="p0044" num="0044">The CPU 31 executes control of each timing signal generated by the timing generating circuit 28, whereby change of the frame rate of a captured image, and electric shutter control (exposure time variable control within a frame) can be executed. Also, the CPU 31 provides a gain control signal to the analog signal processing unit 24 via the timing generating circuit 28, whereby gain variable control of a captured image signal can be executed.<!-- EPO <DP n="9"> --></p><p id="p0045" num="0045">The blurring detecting unit 13 detects a shaking quantity, and the motion amount of the imaging apparatus 1 itself. The blurring detecting unit 13 is configured of, for example, an acceleration sensor, a vibration sensor, or the like, and supplies detection information serving as a blurring quantity to the CPU 31.</p><p id="p0046" num="0046">The flash emitting unit 15 is driven by the emission driving unit 14 so as to emit flash light. The CPU 31 instructs the emission driving unit 14 to execute flash emission at a predetermined timing such as the user's operation or the like, whereby the flash emitting unit 15 can be emitted.</p><p id="p0047" num="0047">The camera DSP 4 subjects the captured image signal to be input from the A/D conversion unit 25 of the imaging system 2 to various types of digital signal processes. With the camera DSP 4, processing functions, for example as shown in the drawing, such as the image signal processing unit 41, compression/decompression processing unit 42, SDRAM controller 43, image analyzing unit 44, and so forth are realized with the internal hardware and software.</p><p id="p0048" num="0048">The image signal processing unit 41 executes a process as to an input captured image signal. For example, the image signal processing unit 41 executes an autofocus (AF) process, an auto exposure (AE) process, or the like as an operation process used for driving control of the imaging system 2 using a captured image signal, and also executes an auto white balance (AWB) process or the like as a process as to a captured image signal itself to be input.</p><p id="p0049" num="0049">For example, as the autofocus process, the image signal processing unit 41 executes contrast detection as to an input captured image signal, and transmits the detection information to the CPU 31. Various types of control methods have been used as an autofocus control methods, but with a technique referred to as "contrast AF", contrast detection is executed regarding the captured image signal at each point in time while moving the focus lens forcibly, thereby determining the position of the focus lens in the optimal contrast state. That is to say, the CPU 31 executes control to confirm the contrast detection value detected at the image signal processing unit 41 while executing the movement control of the focus lens prior to an imaging operation, and to determine a position in the optimal contrast state as a focus optimal position.</p><p id="p0050" num="0050">Also, as focus control during imaging a detection method referred to as so-called wobbling AF can be executed. The CPU 31 confirms the contrast detection value detected at the image signal processing unit 41 while moving the position of the focus lens by<!-- EPO <DP n="10"> --> swaying the focus lens minutely forward and backward all the time during an imaging operation. The optimal position of the focus lens changes depending to the state of a subject, but contrast detection is executed while changing the focus lens minutely forward and backward, whereby change in the format control direction can be determined according to change in the subject. Thus, autofocus can be executed while tracking the state of a subject.</p><p id="p0051" num="0051">Note that, with a transfer mechanism of the lens driving unit 26, an address is assigned thereto for each of transfer positions, and a lens position is distinguished with the transfer position address thereof.</p><p id="p0052" num="0052">The lens position detecting unit 27 distinguishes the address of the focus lens serving as the current lens position of the focus lens, thereby calculating distance to a subject in a focused state, and accordingly, this can be supplied to the CPU 31 as distance information. Thus, the CPU 31 can distinguish distance to a principal subject in a focused state.</p><p id="p0053" num="0053">As the auto exposure process executed by the image signal processing unit 41 of the camera DSP 4, for example, calculation of subject luminance is executed. For example, the average luminance of input captured image signals is calculated, and this is supplied to the CPU 31 as subject luminance information, i.e., exposure quantity information. As calculation of average luminance, various types of methods can be conceived, for example, such as calculation of the average value regarding the luminance signal values of all the pixels of the captured image data of one frame, calculation of the average value of luminance signal values wherein weight is provided to the center portion of an image, or the like.</p><p id="p0054" num="0054">The CPU 31 can execute automatic exposure control based on this exposure quantity information, i.e., can execute exposure adjustment in accordance with electronic shutter control at the diaphragm mechanism, ND filter, or imaging device unit 23, or gain control as to the analog signal processing unit 24.</p><p id="p0055" num="0055">The image signal processing unit 41 of the camera DSP 4 executes automatic white balance, gamma correction, an edge enhancement process, a shaking correction process, or the like as the signal process of the captured image signal itself in addition to a signal generating process used for autofocus operation or auto exposure operation.</p><p id="p0056" num="0056">The compression/decompression processing unit 42 of the camera DSP 4 executes a compression process as to the captured image signal, or a decompression process as to the<!-- EPO <DP n="11"> --> compressed image data. For example, the compression/decompression processing unit 42 executes a compression process/decompression process using a method such as JPEG (Joint Photographic Experts Group), MPEG (Moving Picture Experts Group), or the like.</p><p id="p0057" num="0057">The SDRAM controller 43 executes writing/readout as to the SDRAM 9. The SDRAM 9 is used for temporary storing of the captured image signal input from the imaging system 2, storing at the process stage at the image processing unit 41 or compression/decompression processing unit 42, ensuring of a work region, storing of information obtained at the information analyzing unit 44, or the like, and the SDRAM controller 43 executes writing/readout of such data as to the SDRAM 9.</p><p id="p0058" num="0058">The image analyzing unit 44 executes image analysis, for example, regarding the captured image data processed at the image signal processing unit 41, and executes various types of image recognition. In the case of the present example, the image analyzing unit 44 executes a recognition process of a person or face included in a subject image. Also, in the case of recognizing a person's face, the image analyzing unit 44 executes a recognition process for facial orientation, sight direction, or the like in some cases. Further, the image analyzing unit 44 detects various types of information that can be recognized by image analysis, such as the size of relative motion between the imaging apparatus 1 and a subject, or the like in some cases.</p><p id="p0059" num="0059">The control system 3 includes the CPU 31, RAM 32, flash ROM 33, and clock circuit 34. Each unit of the control system 3, camera DSP 4, and each unit of the imaging system 2, display controller 7, external interface 8, and medium interface 10 can communicate image data and control information mutually via the system bus.</p><p id="p0060" num="0060">The CPU 31 controls the whole of the imaging apparatus 1. Specifically, the CPU 31 executes various types of operation processes, and exchange of a control signal or the like as to each unit based on the program stored in the internal ROM or the like, and the user's operation by the operating unit 5, thereby causing each unit to execute a predetermined operation. Particularly, the CPU 31 executes display control at the main display panel 6M, and a control process used for display operation of a later-described front display panel 6F, or the like.</p><p id="p0061" num="0061">The RAM (Random Access Memory) 32 is used for temporary storing of the captured image signal (image data of each frame) processed at the camera DSP 4, and storing of information according to each type of process of the CPU 31.</p><p id="p0062" num="0062">The flash ROM 33 is used for storing of image data (imaged as a still image or<!-- EPO <DP n="12"> --> moving image by the user) serving as a captured image, or storing of information requested for being saved in a nonvolatile manner. The flash ROM 33 may store control software programs of the imaging apparatus 1, the setting data of the camera, and so forth.</p><p id="p0063" num="0063">The clock circuit 34 counts the current date and time information (year, month, day, hour, minute, second).</p><p id="p0064" num="0064">The operating unit 5 is configured of various types of operators (5a through 5e, etc.) shown in <figref idrefs="f0001">Figs. 1A and 1B</figref>, and a signal generating unit based on the operation thereof. The user's operation information by various types of operators is transmitted from the operating unit 5 to the CPU 31. Note that the operating unit 5 may be configured so as to allow the user to perform touch panel operations in addition to operations by the operators. For example, an arrangement may be made wherein a touch sensor is provided to the main display panel 6M, and operation input is performed by the user's touch operation as to screen display.</p><p id="p0065" num="0065">The display controller 7 controls the main display panel 6M and the front display panel 6F to execute a predetermined display operation based on the control of the CPU 31.</p><p id="p0066" num="0066">As a display operation at the main display panel 6M, monitoring display (so-called through image display), playback image display read out from the recording medium 90 or flash ROM, operation menu display, various types of icon display, point-in-time display, or the like is executed. Also, as a display operation at the front display panel 6F, monitoring display, or playback image display is executed.</p><p id="p0067" num="0067">The medium interface 10 executes readout/writing of data as to the recording medium 90 such as a memory card (card-shaped removable memory) set within the imaging apparatus 1, or the like based on the control of the CPU 31. For example, the medium interface 10 executes an operation to record still image data or moving image data serving as an imaged result in the recording medium 90. Also, the medium interface 10 executes an operation to read out image data from the recording medium 90 at the time of the playback mode.</p><p id="p0068" num="0068">Note that the portable memory card is exemplified as the recording medium 90 here, but another type of recording medium may be used as long as this medium can be used for recording image data serving as a still image or moving image to be kept as an imaged result. For example, a portable disk medium such as an optical disc or the like may be used, or an HDD (Hard Disk Drive) may be installed to record image data.</p><p id="p0069" num="0069">The external interface 8 executes transmission/reception of various types of data as<!-- EPO <DP n="13"> --> to an external apparatus via a predetermined cable in accordance with a signal standard, such as USB (Universal Serial Bus) or the like, for example. It goes without saying that an external interface according to another standard such as IEEE (Institute of Electrical and Electronics Engineers) 1394 or the like may be used regardless of the USB method.</p><p id="p0070" num="0070">Also, the external interface 8 may be configured by a wireless transmission method such as infrared transmission, short-distance wireless communication, or the like instead of a cable transmission method.</p><p id="p0071" num="0071">The imaging apparatus 1 can execute data transmission/reception as to various types of equipment such as a personal computer or the like via the external interface 8. For example, captured image data can be transferred to an external apparatus.</p><p id="p0072" num="0072">Note that a proximity sensor 50 is shown in <figref idrefs="f0002">Fig. 2</figref>. Let us say that the proximity sensor 50 is a sensor to detect whether or not there is a person in front of the imaging apparatus 1 (subject side). For example, a pyroelectric sensor or the like can be employed. As described above, in the case that person detection is executed by the image analyzing process of the image analyzing unit 44, the proximity sensor 50 may not be provided, or person detection by image analysis, and detection by the proximity sensor 50 may be used together.</p><heading id="h0008">2. Operation Transition</heading><p id="p0073" num="0073">The transition of the operation state of the imaging apparatus 1 of the present example will be described with reference to <figref idrefs="f0003">Fig. 3</figref>. The various operation states are operation states viewed particularly from the perspective of the display content of the main display panel 6M.</p><p id="p0074" num="0074">The operation state of the imaging apparatus 1 is changed to the monitoring period, recording period, preview period, and playback period according to the user's operation or the like. Note that, in reality, there are other operation states such as a period wherein communication with an external apparatus is executed, but description thereof will be omitted for the sake of simplifying explanation.</p><p id="p0075" num="0075">When the imaging apparatus 1 is, for example, powered on, the monitoring operation is started. Note that, there are cases where the imaging apparatus 1 goes to a playback operation state at the time of power-on, such as a case where the user performs a playback operation from a power-off state, or the like.</p><p id="p0076" num="0076">The monitoring period is an operation period used for executing imaging by the imaging system 2. In the case that the user commonly uses the imaging apparatus 1 to<!-- EPO <DP n="14"> --> execute imaging of a still image, first, this monitoring operation is executed.</p><p id="p0077" num="0077">With this monitoring period, a subject image (through image) is displayed on the main display panel 6M. Specifically, the CPU 31 controls the imaging system 2 and camera DSP 4 to execute an operation for imaging during the monitoring period. Subsequently, the CPU 31 stores the captured image data for each frame supplied from the camera DSP 4, for example, in the RAM 32. Subsequently, the CPU 31 transfers the captured image data for each frame to the display controller 7, and controls the main display panel 6M to execute monitoring display. At this time there is a case where the front display panel 6F is also controlled to execute monitoring display, which will be described later.</p><p id="p0078" num="0078">During this monitoring period, the user selects a subject, or awaits a suitable timing to take a picture, while viewing the display of the main display panel 6M.</p><p id="p0079" num="0079">During the monitoring period, upon the user pressing the release operation key 5a, i.e., upon the user performing a shutter operation, the operation state enters the recording period.</p><p id="p0080" num="0080">The CPU 31 executes a process to store the captured image data of one frame to be imaged at the timing of this release operation as still image data. Specifically, the CPU 31 transfers the captured image data captured at such timing to the medium interface 10 to record this in the recording medium 90.</p><p id="p0081" num="0081">Note that a recording operation according to a release operation may be executed not as to the recording medium 90 but as to the flash ROM 33. Also, an operation system may be employed wherein recording is usually executed as to the recording medium, but in the case that the recording medium 90 is not mounted, recording is executed as to the flash ROM 33. This recording period is a very short period of time immediately after a release operation as viewed from the user, and is a state wherein nothing is displayed on the main display panel 6M for example.</p><p id="p0082" num="0082">A certain period of time immediately after a recording operation according to a release operation will be referred to as the preview period. The preview period is a period wherein the image recorded in the immediately previous recording operation is displayed on the main display panel 6M, i.e., a period wherein the user is allowed to confirm the imaged still image immediately after.</p><p id="p0083" num="0083">For example, a period of two seconds to several seconds is the preview period, and during this period the CPU 31 executes control to display the recorded still image data on the main display panel 6M.<!-- EPO <DP n="15"> --></p><p id="p0084" num="0084">Upon predetermined time serving as the preview period having elapsed, the CPU 31 returns the operation state to the monitoring state, and executes operation control serving as the monitoring period. That is to say, a series of operations as imaging of a still image is executed as the monitoring period, recording period, and preview period.</p><p id="p0085" num="0085">Note that, with the imaging apparatus 1, imaging of a moving image can be executed, but in the case of a moving image, the recording period continues during a period from the start to the end of imaging of the moving image thereof. Also, in this case, no preview period is provided.</p><p id="p0086" num="0086">In the case that the user has performed an operation to instruct a playback operation, the imaging apparatus 1 proceeds to a playback operation state (playback period). During the playback period, an operation to play the image recorded in the recording medium 90 or flash ROM 33 by imaging or the like is executed.</p><p id="p0087" num="0087">The CPU 31 reads out the image recorded in the recording medium 90 or flash ROM 33 in response to the user's operation, and instructs the display controller 7 to display thumbnail images or a playback image on the main display panel 6M. Also, the playback image is displayed on the front display panel 6F in some cases.</p><heading id="h0009">3. Screen Display Examples of Both Display Panel Units</heading><p id="p0088" num="0088">Screen display examples to be displayed on the main display panel 6M and the front display panel 6F of the imaging apparatus 1 according to the present example will be described with reference to <figref idrefs="f0004 f0005">Figs. 4A through 5C</figref>.</p><p id="p0089" num="0089"><figref idrefs="f0004 f0005">Figs. 4A through 5A</figref> show examples of a screen display performed during the monitoring period.</p><p id="p0090" num="0090"><figref idrefs="f0004">Fig. 4A</figref> illustrates a state in which monitoring image (through image) is displayed on the main display panel 6M, and display is off on the front display panel 6F.</p><p id="p0091" num="0091"><figref idrefs="f0004">Fig. 4B</figref> illustrates a state in which a monitoring image is displayed on the main display panel 6M, and the same monitoring image is also displayed on the front display panel 6F.</p><p id="p0092" num="0092"><figref idrefs="f0004">Fig. 4C</figref> illustrates a state in which a monitoring image is displayed on the main display panel 6M, and a different monitoring image, a playback image for example, is displayed on the front display panel 6F. The playback image may be a playback image of an image imaged in the past and recorded in the recording medium 90 or flash ROM 33, or may be an image stored in the imaging apparatus 1 beforehand. An example of this case is a case where image data is prepared so as to be displayed when no monitoring image is<!-- EPO <DP n="16"> --> displayed on the front display panel 6F, and is stored as a preset image in the flash ROM 33 or the like beforehand, and the preset image data thereof is read out and displayed.</p><p id="p0093" num="0093">Further, the playback image is not restricted to image data serving as a so-called captured image, text data, animation data, computer graphics data, or the like is recorded in the recording medium 90 or flash ROM 33, and such data may be displayed. That is to say, the playback image includes any kind of image that can be displayed. <figref idrefs="f0005">Fig. 5A</figref> is an example wherein display is off on the main display panel 6M, and display of a monitoring image is displayed on the front display panel 6F.</p><p id="p0094" num="0094">These examples may be conceived to be display states of the main display panel 6M and front display panel 6F during the monitoring period, but what sort of display to perform is controlled by the CPU 31 according to the status of the subject, operating status of the imaging apparatus 1, and imaging mode during the monitoring period.</p><p id="p0095" num="0095"><figref idrefs="f0005">Figs. 5B and 5C</figref> show examples of the screen display performed during the playback period. <figref idrefs="f0005">Fig. 5B</figref> illustrates a state in which list display by the thumbnail images of the playback image is executed on the main display panel 6M, and on the other hand, with the front display panel 6F, a playback image under selection by a cursor K within a thumbnail image is displayed. <figref idrefs="f0005">Fig. 5C</figref> illustrates a state in which one playback image is displayed on the main display panel 6M, and the same playback image is also displayed on the front display panel 6F.</p><p id="p0096" num="0096">These examples may be conceived to be display states of the main display panel 6M and front display panel 6F during the playback period. It goes without saying that other examples may also be considered. For example, displaying the playback image on the main display panel 6M and displaying the preset image on the front display panel 6F may be considered. Also, performing a menu display of the thumbnail images on the main display panel 6M while performing sequential display (display as a slide show) of the various playback images on the front display panel 6F may also be considered.</p><p id="p0097" num="0097">Although a display example is shown in <figref idrefs="f0004 f0005">Figs. 4A through 5C</figref>, the display with the main display panel 6M which faces the user that performs imaging operations and playback operations and so forth is basically as follows.</p><p id="p0098" num="0098">First the monitoring image is displayed in the monitoring period. Also, the image that is imaged and recorded is temporarily displayed in the preview period. The thumbnail image and playback images are displayed in the playback period according to user operations and so forth. The CPU 31 controls the main display panel 6M so as to execute<!-- EPO <DP n="17"> --> these displays according to operating state and operations.</p><p id="p0099" num="0099">On the other hand, the CPU 31 performs display control of the front display panel 6F from the perspective of executing useful displays or interesting displays as to the person viewing the front display panel 6F. The various types of display control examples of the front display panel 6F will be described below.</p><heading id="h0010">[4. Display Control of Front Display Panel Unit at Time of Monitoring]</heading><heading id="h0011">&lt;4-1: Processing Example Based on Imaging mode&gt;</heading><p id="p0100" num="0100"><figref idrefs="f0006">Fig. 6A</figref> shows a display control example that the CPU 31 executes regarding the front display panel 6F during the monitoring period. As described above, the monitoring image obtained with the processing in the imaging system 2 and camera DSP 4 is displayed on the main display panel 6M. That is to say, the CPU 31 executes control to display the captured image data supplied from the camera DSP 4 on the main display panel 6M as a through image during the monitoring period.</p><p id="p0101" num="0101">At this time, in order to perform the display control of the front display panel 6F, the CPU 31 performs processing in <figref idrefs="f0006">Fig. 6A</figref> in parallel with the display control of the main display panel 6M.</p><p id="p0102" num="0102">First in step F101, the CPU 31 confirms the current imaging mode. The imaging mode will be described now.</p><p id="p0103" num="0103">The imaging mode is a mode that the user selects so as to perform imaging in a suitable state under various situations, such as a night view mode, night view and person mode, portrait mode, scenery mode, "soft snap" mode, snow mode, beach mode, high-speed shutter mode, high-sensitivity mode, smile shutter mode, and so forth.</p><p id="p0104" num="0104">With each of these imaging modes, suitable shutter speed, suitable exposure setting, suitable signal gain setting as to a captured image signal, suitable signal process settings such as edge enhancement and color process, and so forth have already been determined, and these settings can be selected by the user, for example, according to the operations of the dial operating portion 5b shown in <figref idrefs="f0001">Fig. 1A</figref>.</p><p id="p0105" num="0105">The night view mode is an imaging mode wherein imaging is executed with settings suitable for night view imaging. The night view and person mode is an imaging mode wherein imaging is executed with settings capable of imaging the night view of the back and the facial expression of a person with vivid clarity.</p><p id="p0106" num="0106">The portrait mode is an imaging mode wherein imaging is executed with settings suitable for person imaging.<!-- EPO <DP n="18"> --></p><p id="p0107" num="0107">The scenery mode is an imaging mode wherein imaging is executed with settings suitable for scenery imaging.</p><p id="p0108" num="0108">The "soft snap" mode is an imaging mode wherein imaging is executed with settings to give a viewer the impression that the texture of the skin of a person is bright and soft.</p><p id="p0109" num="0109">The high-speed shutter mode is an imaging mode wherein imaging is executed with settings suitable for a moving subject.</p><p id="p0110" num="0110">The high-sensitivity mode is an imaging mode wherein imaging is executed with natural mood using neither dark scenes nor flash.</p><p id="p0111" num="0111">The smile shutter mode is an imaging mode wherein upon a subject person becoming a smiling face, a shutter process (release) is automatically executed when the subject person smiles.</p><p id="p0112" num="0112">Though an imaging mode used for executing an imaging process suitable for such an imaging situation is selected by the user, the CPU 31 executes imaging process control according to the imaging mode settings with the stage of still image imaging from the monitoring period to the recording period. That is to say, the CPU 31 executes various types of parameter instructions as to the imaging system 2 and camera DSP 4 according to the imaging mode selected by the operation of the dial operating portion 5b. For example, an instruction is executed, such as the above shutter speed settings, exposure settings, signal process settings, or the like.</p><p id="p0113" num="0113">Step F101 in <figref idrefs="f0006">Fig. 6A</figref> is processing to branch the processing depending on currently which imaging mode is used as such an imaging mode. In the case that, of the above-mentioned various types of imaging modes, the current imaging mode is a predetermined imaging mode suitable to the display of the monitoring image on the front display panel 6F, the CPU 31 advances the processing to step F102, and executes monitoring image display on the front display panel 6F. That is to say, the display controller 7 is instructed to display the monitoring image displayed on the main display panel 6M also on the front display panel 6F. In this case, the display states of the main display panel 6M and the front display panel 6F are states such as shown in <figref idrefs="f0004">Fig. 4B</figref>.</p><p id="p0114" num="0114">On the other hand, in step F101 in the case that the current imaging mode is confirmed to not be a predetermined imaging mode suitable to the display of the monitoring image on the front display panel 6F, the CPU 31 advances the processing to step F103, and controls the display of the front display panel 6F to be turned off. In this case, the display states of the main display panel 6M and the front display panel 6F are states<!-- EPO <DP n="19"> --> such as shown in <figref idrefs="f0004">Fig. 4A</figref>.</p><p id="p0115" num="0115">The CPU 31 repeatedly executes the processing in <figref idrefs="f0006">Fig. 6A</figref> herein during the monitoring period. The monitoring period ending is, for example, in a case of release operation performed and transferring to a recording action, or in a case of playback operations performed and moving to playback action, or a case of the power off operation of the imaging apparatus 1 performed and performing power off processing. Thus, until the monitoring period is ended, the CPU 31 repeatedly executes the processing in <figref idrefs="f0006">Fig. 6A</figref>.</p><p id="p0116" num="0116">Accordingly during the monitoring period, in the case that the predetermined imaging mode is selected as the imaging mode, the monitoring image is displayed on the front display panel 6F as shown in <figref idrefs="f0004">Fig. 4B</figref>, and in the case that the predetermined imaging mode is not selected, the front display panel 6F is turned off as shown in <figref idrefs="f0004">Fig. 4A</figref>.</p><p id="p0117" num="0117">For example, of the various described imaging modes, in step F101 the CPU 31 determines the predetermined imaging mode suitable to the display of the front display panel 6F to be a night scene and person mode, portrait mode, "soft snap" mode, smile shutter mode, and so forth. That is to say, these imaging modes are determined beforehand to be applicable to the predetermined imaging mode in the processing in step F101.</p><p id="p0118" num="0118">These imaging modes are selected in the case of having the objective of imaging of a person, and accordingly, there is a high possibility that a person is included as a subject. That is to say, there is a high possibility that there is a person who can view the display of the front display panel 6F as a subject.</p><p id="p0119" num="0119">Therefore, the CPU 31 determines that if the imaging mode is one of the night view and person mode, portrait mode, "soft snap" mode, and smiling shutter mode, in step F102 the monitoring image is displayed on the front display panel 6F.</p><p id="p0120" num="0120">In the case that the imaging mode is an imaging mode other than those, i.e., the night view mode, scenery mode, high-speed shutter mode, or high-sensitivity mode, the imaging mode is assumed to be selected in the case of having no objective of imaging of a person, or the visibility of the front display panel 6F is assumed to be in a poor state.</p><p id="p0121" num="0121">For example, the night view mode and the scenery mode are intended for scenery imaging, and a situation can be assumed wherein no person is included in the subject, or even if a person is included, the person thereof has no primary role within the image. Also, in the case of the night view mode or high-sensitivity mode, even if there is a person in front, a monitoring image displayed at the time of imaging a dark scene on the front display<!-- EPO <DP n="20"> --> panel 6F would result in poor visibility from the person in front thereof.</p><p id="p0122" num="0122">Also, a subject in the high-speed mode is a subject in motion. For example, even if a person is the subject, the person is in a situation such as participating in a sporting event, is dancing, or the like, and accordingly, the person thereof is in no situation to carefully view the front display panel 6F.</p><p id="p0123" num="0123">That is to say, in the case of these imaging modes, a situation is assumed wherein there is no person in front, or even if there is a person in front, the front display panel 6F is displayed with poor visibility, or the person thereof is not in a state to view the front display panel 6F.</p><p id="p0124" num="0124">Thus the CPU 31 turns the front display panel 6F off in step F103 in the case that the imaging mode is one of a night scene mode, scenery mode, high-speed shutter mode, and high sensitivity mode.</p><p id="p0125" num="0125">Note that the above modes are examples, in addition to those, an evening view mode wherein imaging is executed with settings suitable for evening view imaging, a macro mode suitable for closeup of objects such as plants, insects, or the like, a firework mode suitable for imaging of fireworks, an underwater mode suitable for imaging under water, or the like, is provided in some cases. Also, a snow mode wherein imaging is executed with settings capable of expressing ski slopes and silvery snow of snow-covered landscapes as they appear to the human eye, a beach mode wherein imaging is executed with settings whereby the blue of the sea and sky is highlighted, or the like is provided in some cases.</p><p id="p0126" num="0126">In these cases as well, it should be set beforehand how to determine in step F101 (whether or not the imaging mode is included in the predetermined imaging modes to execute the display of the front display panel 6F) according to whether or not there is a person, the visibility of the display content of the front display panel 6F, and the situation of a person on the subject side.</p><p id="p0127" num="0127">That is to say, according to the processing example in <figref idrefs="f0006">Fig. 6A</figref>, during the monitoring, the possibility that a person exists on the front side (subject side), or the visibility of the front display panel 6F, is estimated according to the imaging mode. In the case there is a great possibility that a person who will view the monitoring image on the front display panel 6F is on the front side, and that the possibility is great of being in a state of viewing with good visibility, the monitoring image is displayed on the front display panel 6F.</p><p id="p0128" num="0128">On the other hand, in the case of a great possibility of a person to view the front display panel 6F not being on the front side, or in the case of a state estimating that even if<!-- EPO <DP n="21"> --> a person is there, visibility will not be good, the front display panel 6F is turned off.</p><p id="p0129" num="0129">For example, when a person is the subject, the user selects one of the night scene and person mode, portrait mode, "soft snap" mode, and smile shutter mode. In the case therein, the person that is the subject can view the front display panel 6F.</p><p id="p0130" num="0130">Therefore the person that is the subject can view the monitoring image that oneself is about to be imaged, and can confirm the expression, pose, and so forth of oneself. The display on the front display panel 6F can be effectively used such as confirming by oneself whether or not an expression is favorable for a photograph, for example.</p><p id="p0131" num="0131">On the other hand, in the case that the user performs imaging by selecting a night scene and person mode, portrait mode, "soft snap" mode, or smile shutter mode, the display on the front display panel 6F is turned OFF (only the front display panel 6F is in a power off state, for example), whereby power consumption can be reduced. That is to say, wasteful displays that no one is viewing, or wasteful displays having poor visibility, are not performed.</p><p id="p0132" num="0132"><figref idrefs="f0006">Fig. 6B</figref> is another processing example, and is an example of the front display panel 6F not being in the power off state, even if a person is not on the front side. Similar to <figref idrefs="f0006">Fig. 6A</figref>, in step F101 the CPU 31 branches the processing depending on the current imaging mode. In the case that a predetermined imaging mode is selected, such as night scene and person mode, portrait mode, "soft snap" mode, or smile shutter mode, the CPU 31 advances the flow to step F102A, and in the state that the display luminance of the front display panel is increased, instructs the display controller 7 to display the monitoring image.</p><p id="p0133" num="0133">Also, in the case that currently the imaging mode is other that the above-mentioned predetermined imaging modes, CPU 31 advances the flow to step F103A, and in the state that the display luminance of the front display panel 6F is decreased, instructs the display controller 7 to display the monitoring image.</p><p id="p0134" num="0134">That is to say, in the case that a person that can view the front display panel 6F exists, and estimation is made that visibility for the display is good, the display luminance of the front display panel 6F is increased so that the monitoring image can be viewed by the person. On the other hand, when assumed that there is no person in front, that visibility is too bad to view display, or the like, display luminance is decreased, and reduction in consumption power is realized. In the case that a display device made up of self emitting elements such as an organic EL panel is used as the front display panel 6F, decrease in display luminance is useful for reduction in consumption power.<!-- EPO <DP n="22"> --></p><p id="p0135" num="0135">Next, the processing example in <figref idrefs="f0007">Fig. 7</figref> will be described. Similar to <figref idrefs="f0006">Fig. 6A</figref>, in step F101 the CPU 31 branches the processing depending on the current imaging mode. In the case that a predetermined imaging mode is selected, such as night scene and person mode, portrait mode, "soft snap" mode, or smile shutter mode, the CPU 31 advances the flow to step F103, and instructs the display controller 7 to display the monitoring image on the front display panel 6F.</p><p id="p0136" num="0136">Also, in the case that the imaging mode is other than the above predetermined imaging mode, the CPU 31 advances the flow to step F104, and performs processing such as reading out image data recorded on the recording medium 90 and so forth and preset image data and so forth. For example, the CPU 31 instructs the medium interface 10 to execute the playback of image data from the recording medium 90 (captured image data and so forth). Alternatively the CPU 31 executes reading out of the preset image data and captured image data from the flash ROM 33. The CPU 31 instructs the display controller 7 to display the read out image data thereof onto the front display panel 6F. That is to say as shown in <figref idrefs="f0004">Fig. 4C</figref>, image displaying that differs from the monitoring image is executed on the front display panel 6F.</p><p id="p0137" num="0137">In this case, in the case that a person that can view the front display panel 6F exists, and estimation is made that display visibility is good, the state thereof is as shown in <figref idrefs="f0004">Fig. 4B</figref>, and the person can monitor the image of oneself about to be photographed.</p><p id="p0138" num="0138">On the other hand, when estimating a state that no person is in front, or that the display can be viewed with poor visibility, an unrelated image is displayed on the front display panel 6F such as shown in <figref idrefs="f0004">Fig. 4C</figref>. Even if the person to be the subject does not exist, many times the state is such that a person is nearby. Also, there is a case where a person is in a situation wherein the person can readily view the display of the front display panel 6F, depending on the position of the person thereof.</p><p id="p0139" num="0139">For a person who is present in those circumferences, the display on the front display panel 6F can be recognized as a part of the external view design of the imaging apparatus 1, which would be interesting.</p><p id="p0140" num="0140">Also, in such a case, the user can select an image to be displayed on the front display panel 6F, whereby the user can set the external view of his imaging apparatus 1 arbitrarily, and accordingly, the user can enjoy camera use in more ways.</p><p id="p0141" num="0141">Note that the image data to be read out and displayed from the recording medium 90 may in some cases be text data or animation data.<!-- EPO <DP n="23"> --></p><p id="p0142" num="0142">Next, yet another processing example will be shown with <figref idrefs="f0008">Fig. 8. Fig. 8</figref> is processing to correspond in the case that as one of the above-described imaging modes, a self-imaging mode can be selected. A self-imaging mode is an imaging mode in the case of the user facing the front side of the imaging apparatus 1 towards oneself.</p><p id="p0143" num="0143">In step F151 in <figref idrefs="f0008">Fig. 8</figref>, the CPU 31 confirms whether or not the current imaging mode is a self-imaging mode. In the case that the current imaging mode is a self-imaging mode, the CPU 31 advances the flow to step F152, and performs processing to turn off the display on the main display panel 6M. Control is performed to display the monitoring image on the front display panel 6F in step F153.</p><p id="p0144" num="0144">In the case that the imaging mode is other than a self-imaging mode, the CPU 31 confirms in step F154 whether or not a predetermined imaging mode is selected as the imaging mode, such as night scene and person mode, portrait mode, "soft snap" mode, or smile shutter mode.</p><p id="p0145" num="0145">In the case of a predetermined imaging mode, the flow is advanced to step F153, and the display controller 7 is instructed to display a monitoring image on the front display panel 6F.</p><p id="p0146" num="0146">Also, in the case that imaging mode is other than the above predetermined imaging modes, the CPU 31 advances the flow to step F155, and controls the display on the front display panel 6F to be turned off.</p><p id="p0147" num="0147">That is to say, in the case that the self-imaging mode is selected as the user setting, the front display panel 6F and main display panel 6M are in the state shown in <figref idrefs="f0005">Fig. 5A</figref>. in the case of not being in the self-imaging mode, the state is similar to that in <figref idrefs="f0006">Fig. 6A</figref>.</p><p id="p0148" num="0148">In the case of the self-imaging mode, the user faces the imaging apparatus toward oneself and performs imaging operations, whereby the main display panel 6M is not viewable. Accordingly, the subject can be confirmed by viewing the monitoring image on the front display panel 6F. The main display panel 6M is turned off, whereby power consumption can be reduced.</p><p id="p0149" num="0149">Note that as a modified example following the processing examples in <figref idrefs="f0008">Fig. 8</figref>, other than turning off the display of the front display panel 6F, processing examples may be considered in step F155 such as displaying in a low-luminance state such as described with <figref idrefs="f0006">Fig. 6A</figref>, or displaying a playback image or preset image as described with <figref idrefs="f0007">Fig. 7</figref>.</p><heading id="h0012">&lt;4-2: Processing Example Based on Imaging mode and User Settings&gt;</heading><p id="p0150" num="0150">In <figref idrefs="f0006 f0007 f0008">Figs. 6 through 8</figref> above, examples of controlling the display state of the front<!-- EPO <DP n="24"> --> display panel 6F according to imaging mode have been described, but here an example will be described to perform display control of the front display panel 6F with consideration for other user setting states as to the imaging device 1, in addition to the imaging mode.</p><p id="p0151" num="0151">The imaging mode is one of the user settings, but let us say that the user's setting mentioned here is a setting state according to the user's operation other than the imaging mode setting, for example, such as flash emission setting, zoom position operation, or the like.</p><p id="p0152" num="0152"><figref idrefs="f0009">Fig. 9</figref> shows a display control example that the CPU 31 executes for the front display panel 6F during the monitoring period.</p><p id="p0153" num="0153">The monitoring image obtained with the imaging system 2, camera DSP 4 is displayed on the main display panel 6M during the monitoring period. That is to say, the CPU 31 executes control to display the imaging data supplied from the camera DSP 4 on the main display panel 6M as a through image during the monitoring period. At this time, in order to perform display control for the front display panel 6F, the CPU 31 performs the processing in <figref idrefs="f0009">Fig. 9</figref> in parallel.</p><p id="p0154" num="0154">In step F201 the CPU 31 branches the processing depending on whether the current imaging mode is a predetermined imaging mode suitable to the display of the monitoring image on the front display panel 6F. That is to say, confirmation is made as to whether or not a predetermined imaging mode, such as night scene and person mode, portrait mode, "soft snap" mode, or smile shutter mode, is selected as the imaging mode.</p><p id="p0155" num="0155">In the case of a predetermined imaging mode suitable to the display of the monitoring image on the front display panel 6F, the CPU 31 advances the flow to step F202, and branches the processing depending on whether or not the user setting state other than the current imaging mode is a setting state suitable to the display of the monitoring image on the front display panel. In the case determination is made that the user setting state is a setting state suitable to the display of the monitoring image on the front display panel, the flow is advanced to step F203, and displaying of the monitoring image is executed with the front display panel 6F. That is to say, the display controller 7 is instructed to display the monitoring image displayed on the main display panel 6M also on the front display panel 6F. In this case, the display states of the main display panel 6M and the front display panel 6F are states such as shown in <figref idrefs="f0004">Fig. 4B</figref>.</p><p id="p0156" num="0156">On the other hand, in the case determination is made in step F201 that the imaging mode is not the above predetermined imaging mode, the CPU 31 advances the flow from<!-- EPO <DP n="25"> --> step F201 to F204, and controls the display of the front display panel 6F to be off. Also in the case determination is made in step F202 that the user settings other than the imaging mode is not a setting state suitable to the display of the monitoring image for the front display panel 6F, the CPU 31 advances the flow to step F204, and controls the display of the front display panel 6F to be off. In these cases, the display states of the main display panel 6M and the front display panel 6F are states such as shown in <figref idrefs="f0004">Fig. 4A</figref>.</p><p id="p0157" num="0157">The CPU 31 repeatedly executes the processing <figref idrefs="f0009">Fig. 9</figref> herein during the monitoring period. Accordingly, during the monitoring period, when the predetermined imaging mode is selected and the user setting state is a predetermined state at the point in time thereof, the monitoring image is displayed on the front display panel 6F as shown in <figref idrefs="f0004">Fig. 4B</figref>.</p><p id="p0158" num="0158">On the other hand, as a scenery mode or the like, basically when a subject scene that does not include a person is targeted, or when using a predetermined imaging mode such as portrait mode or the like but the user setting state is not a predetermined state, the front display panel 6F is turned off as shown in <figref idrefs="f0004">Fig. 4A</figref>.</p><p id="p0159" num="0159">User settings are flash emission settings, zoom position operations, and so forth for example, as mentioned above. The application of the processing in <figref idrefs="f0009">Fig. 9</figref> for each is as follows.</p><p id="p0160" num="0160">The flash emission setting of the user's settings will be considered as follows. The flash emission setting is a setting wherein the user selects whether to execute flash emission (flash-on), whether not to execute flash emission (flash-off), or whether to automatically execute flash emission on/off (flash-auto). In this case, a case where the user sets flash-on is usually a situation in which the surroundings are dark. In the case of a dark situation, a monitoring image during the monitoring period is in a low luminance state, and accordingly, the visibility of the display of the front display panel 6F can be conceived to be poor.</p><p id="p0161" num="0161">Thus, regarding the flash emission settings, in the case of "flash: on", the CPU 31 advances to step F204, and the display of the front display panel 6F is controlled to be off.</p><p id="p0162" num="0162">The zoom position operation setting of the user's settings will be considered as follows. The zoom position setting is a zoom position setting, for example, in the case of the user operating the wide/tele operating key 5c in <figref idrefs="f0001">Fig. 1A</figref> to perform a zoom operation.</p><p id="p0163" num="0163">For example, even if a person has been set as a subject, when the zoom position is at the tele side (telephoto) exceeding a predetermined position, the subject person thereof can be assumed to be positioned far away from the imaging apparatus 1. It goes without<!-- EPO <DP n="26"> --> saying that if the subject person is too far away from the imaging apparatus 1, the person thereof will have difficulty in viewing the display of the front display panel 6F suitably.</p><p id="p0164" num="0164">Thus, in the case that the zoom position by the user operation is a position in a distant state more than predetermined in step F202, the CPU 31 advances the flow to step F204, and controls the display of the front display panel 6F to be off.</p><p id="p0165" num="0165">In step F203 in <figref idrefs="f0009">Fig. 9</figref>, by the CPU 31 making determinations according to the user settings as described above, suitable display controls can be performed for the front display panel 6F. In other words, according to the processing in <figref idrefs="f0009">Fig. 9</figref>, in the case estimation is made that a person who can view the front display panel 6F exists or that the display visibility is good, the person on the subject side can monitor the image of themselves.</p><p id="p0166" num="0166">Therefore the person that is the subject can view the monitoring image that oneself is about to be imaged, and can confirm the expression, pose, and so forth of oneself. On the other hand, when estimated that a person is not in front, or that visibility is poor and the state is such that the display is not viewable, the front display panel 6F display is turned off (e.g. only the front display panel 6F is in a power off state). Thus, power consumption can be more suitable reduced.</p><p id="p0167" num="0167">Note that a flash emission setting and zoom position operation have been described above as user settings, but the determination made using both of these may be performed in step F202, or determination using only one of the user settings may be made in step F203.</p><p id="p0168" num="0168">Also, sensitivity settings, blurring correction on/off settings, specialized imaging settings and so forth can be assumed as user settings besides those described above. Each of these can also be conceived to be reflected in the determination of step S202 depending on whether or not a suitable situation is assumed regarding behavior wherein a subject person views the display of the front display panel 6F suitably.</p><p id="p0169" num="0169">Also, as a modified example according to the processing example in <figref idrefs="f0009">Fig. 9</figref>, besides turning the display off on the front display panel 6F, processing examples may be considered such as displaying in a lower luminance state as described with <figref idrefs="f0006">Fig. 6B</figref> or displaying a playback image or preset image as described in <figref idrefs="f0007">Fig. 7</figref>.</p><heading id="h0013">&lt;4-3: Processing Example Based on Imaging mode and Internal Detecting Information&gt;</heading><p id="p0170" num="0170">Next, an example to perform display control of the front display panel 6F will be described with consideration for camera detection information (internal detection<!-- EPO <DP n="27"> --> information) that the imaging apparatus 1 internally detects, in addition to imaging mode.</p><p id="p0171" num="0171">The camera detection information mentioned here is information detected by the internal sensor of the imaging apparatus 1, information that the CPU 31 can recognize in accordance with the operation control of the imaging apparatus 1, e.g., external light quantity detection information used for flash control or exposure control, zoom position information, focus information, shaking detection information, subject distance information, or the like.</p><p id="p0172" num="0172"><figref idrefs="f0010">Fig. 10</figref> shows a display control example of the CPU 31 to execute of the front display panel 6F during the monitoring period.</p><p id="p0173" num="0173">During the monitoring period, the CPU 31 executes control to display the captured image data supplied from the camera DSP 4 as a through image on the main display panel 6M, but the processing in <figref idrefs="f0010">Fig. 10</figref> for performing display control for the front display panel 6F is performed in parallel therewith.</p><p id="p0174" num="0174">In step F301, the CPU 31 branches the processing depending on whether the current imaging mode is a predetermined imaging mode suitable to the display of the monitoring image on the front display panel 6F. That is to say, the CPU 31 confirms whether or not a predetermined imaging mode such as night scene and person mode, portrait mode, "soft snap" mode, or smile shutter mode is selected.</p><p id="p0175" num="0175">In the case of confirming that currently a predetermined imaging mode is used, the CPU 31 advances the flow to step F302, confirms predetermined camera detecting information, and branches the processing depending on whether or not the state is suitable for displaying the monitoring image on the front display panel 6F.</p><p id="p0176" num="0176">In the case determination is made that the state is currently suitable for displaying the monitoring image on the front display panel 6F, the CPU 31 advances the flow to step F303, and executes the monitoring image display on the front display panel 6F. That is to say, the display controller 7 is instructed to display the monitoring image displayed on the main display panel 6M also on the front display panel 6F. In this case, the display states of the main display panel 6M and the front display panel 6F are states such as shown in <figref idrefs="f0004">Fig. 4B</figref>.</p><p id="p0177" num="0177">On the other hand, in the case the CPU 31 confirms that currently a predetermined imaging mode is not used in step F301, the CPU 31 advances the flow to step F304, and controls the display of the front display panel 6F to be turned off. Also, in step F302, also in the case determination is made that the state is not suitable for displaying the<!-- EPO <DP n="28"> --> monitoring image on the front display panel 6F, the CPU 31 advances the flow to step F304, and controls the display on the front display panel 6F to be turned off. In these cases the display states of the main display panel 6M and the front display panel 6F are states such as shown in <figref idrefs="f0004">Fig. 4A</figref>.</p><p id="p0178" num="0178">The CPU 31 repeatedly executes the processing in <figref idrefs="f0009">Fig. 9</figref> during the monitoring period. Accordingly, when the user selects a predetermined imaging mode during the monitoring period, and that the state recognized by the camera detecting information at that point in time is a predetermined state, a monitoring image is displayed on the front display panel 6F as shown in <figref idrefs="f0004">Fig. 4B</figref>.</p><p id="p0179" num="0179">On the other hand, when selecting a imaging mode other than the above-mentioned predetermined imaging modes such as scenery modes or the like, or when the state recognized by the camera detecting information is not a predetermined state even when a predetermined imaging mode has been selected, the front display panel 6F is turned off as shown in <figref idrefs="f0004">Fig. 4A</figref>.</p><p id="p0180" num="0180">The camera detecting information is external light quantity detection information, zoom position information, subject distance information, focus information, shaking detection information, or the like, for example. The determination in step F302 using the camera detecting information herein is as follows.</p><p id="p0181" num="0181">An external light quantity can be detected from the luminance average value of captured image data, a weighted luminance average value obtained by applying weighting to a portion within a screen, or the like, and these are commonly used for automatic exposure control, flash emission control in the case of the flash emission setting is auto, or the like. These luminance values are calculated, for example, at the image signal processing unit 41 of the camera DSP 4, whereby the CPU 31 can obtain the information thereof.</p><p id="p0182" num="0182">Also, though not shown in <figref idrefs="f0002">Fig. 2</figref>, an arrangement may be made wherein an external light quantity sensor or the like is provided, and external light quantity is detected directly.</p><p id="p0183" num="0183">In the case that the external light quantity detected with these techniques is low, a situation can be assumed wherein even if a monitoring image or the like is displayed on the front display panel 6F, the luminance of the screen itself is low, and accordingly, no excellent visibility can be obtained. Also, when shooting against a bright background, where the external light quantity level is too high, a situation can be assumed wherein it will be difficult to visually recognize the monitoring display of the front display panel 6F<!-- EPO <DP n="29"> --> suitably.</p><p id="p0184" num="0184">Thus, even in the case that a predetermined imaging mode is selected, in the case that the external light quantity is lower than a predetermined level or a backlighting state is determined, the CPU 31 determines the state to be not suitable to displaying the monitoring image on the front display panel 6F, the flow is advanced from step F302 to F304, and the display of the front display panel 6F is controlled to be turned off.</p><p id="p0185" num="0185">With regard to the zoom position information, the CPU 31 drives and controls the zoom lens according to the user's operation, whereby the zoom position can be detected. Even if a person has been set as a subject, when the zoom position is in the tele side (telephoto) exceeding a predetermined position, the subject person thereof can be assumed to be positioned far away from the imaging apparatus 1. That is to say, the subject person can be assumed not to be capable of viewing the display of the front display panel 6F suitably.</p><p id="p0186" num="0186">Thus in step F302, in the case that the zoom position is a position in a distant state greater than predetermined, the CPU 31 advances the flow to step F302, and controls the display of the front display panel 6F to be turned off.</p><p id="p0187" num="0187">The subject distance information is the information of distance from the imaging apparatus 1 to a subject. The CPU 31 can obtain the subject distance information using the information from the lens position detecting unit 27 as described above. For example, even if a person has been set as a subject, in the case that determination can be made that the subject person thereof is in a position far away from the imaging apparatus 1, the subject person can be assumed not to be capable of viewing the display of the front display panel 6F suitably.</p><p id="p0188" num="0188">Thus in step F302, in the case that the subject is detected to be farther than a predetermined position by the subject distance information, the CPU 31 advances the flow to step F302, and controls the display of the front display panel 6F to be turned off.</p><p id="p0189" num="0189">The focus information is the determination information of a focused state used for a process for autofocus at the image signal processing unit 41.</p><p id="p0190" num="0190">In the case of not a focused state, the CPU 31 determines that suitable monitoring image display is not executable, the flow is advanced from step F302 to F304, and controlling the display of the front display panel 6F to be turned off can be considered. That is to say, only in the case of a focused state is the monitoring display to be executed with the front display panel 6F.<!-- EPO <DP n="30"> --></p><p id="p0191" num="0191">The blurring detection information is the detection information of shaking, and the motion of the imaging apparatus 1. The CPU 31 can obtain the blurring detection information, for example, as the information from the blurring detecting unit 13.</p><p id="p0192" num="0192">In the case that shaking is great, or in the case that the user is moving the imaging apparatus 1 to follow a moving subject, or the like, the monitoring image on the front display panel 6F will not be visually recognized suitably. Thus in step F302, in the case that blurring or the movement of the imaging apparatus 1 is determined to be great by the blurring detecting information, the CPU 31 advances the flow to step F304, and controlling the display of the front display panel 6F to be turned off can be considered.</p><p id="p0193" num="0193">In step F302 in <figref idrefs="f0010">Fig. 10</figref>, suitable display control can be performed for the front display panel 6F by the CPU 31 making a determination according to all or part of the various types of camera detecting information as described above.</p><p id="p0194" num="0194">That is to say, according to the processing in <figref idrefs="f0010">Fig. 10</figref>, when a predetermined imaging mode is selected and a predetermined state suitable to the monitoring image display with the front display panel 6F from the camera detecting information, the monitoring image is displayed with the front display panel 6F.</p><p id="p0195" num="0195">Therefore the person that is the subject can view the monitoring image that oneself is about to be imaged, and can confirm the expression, pose, and so forth of oneself. However, in the case an assumption is made that the state is not suitable to displaying the monitoring image on the front display panel 6F, the front display panel 6F display is turned off. Thus, power consumption can be more suitable reduced.</p><p id="p0196" num="0196">Note that as a modified example according to the processing example in <figref idrefs="f0010">Fig. 10</figref>, in step F305, besides turning the display of the front display panel 6F off, displaying in a low luminance state as described with <figref idrefs="f0007">Fig. 7</figref>, or displaying the playback image or preset image as described with <figref idrefs="f0008">Fig. 8</figref> may be considered.</p><heading id="h0014">&lt;4-4: Processing Example Based on Imaging mode and Image Analysis Information&gt;</heading><p id="p0197" num="0197">Next, an example to perform display control of the front display panel 6F will be described with consideration for image analysis information, in addition to imaging mode. The image analysis information is information obtained by an image analyzing process that the image analyzing unit 44 executes.</p><p id="p0198" num="0198"><figref idrefs="f0011">Fig. 11</figref> shows a display control example that the CPU 31 executes for the front display panel 6F during the monitoring period.<!-- EPO <DP n="31"> --></p><p id="p0199" num="0199">As described above, in the monitoring period, a monitoring image obtained in the processing of the imaging system and camera DSP 4 is displayed on the main display panel 6M. That is to say, during the monitoring period, the CPU 31 executes control to display the captured image data supplied from the camera DSP 4 on the main display panel 6M as a through image.</p><p id="p0200" num="0200">At this time, in order to perform display control for the from display panel 6F, the CPU 31 performs the processing in <figref idrefs="f0011">Fig. 11</figref> in parallel with the display control of the main display panel 6M.</p><p id="p0201" num="0201">In step F401, the CPU 31 branches the processing depending on whether the current imaging mode is a predetermined imaging mode suitable to the display of the monitoring image of the front display panel 6F. That is to say, the CPU 31 confirms whether or not a predetermined imaging mode, such as night scene and person mode, portrait mode, "soft snap" mode, smile shutter mode, or the like is selected as the imaging mode.</p><p id="p0202" num="0202">In the case of confirming the current mode to be an above-mentioned imaging mode, the CPU 31 advances the flow to step F402, and confirms the image analysis results with the image analysis unit 44.</p><p id="p0203" num="0203">The image analyzing unit 44 executes the image analyzing process regarding the captured image data imaged at the imaging system 2 and captured in the camera DSP 4 during the monitoring period. For example, the image analyzing unit 44 executes the image analyzing process regarding the image data of each frame processed at the image signal processing unit 41, or the image data of a frame extracted intermittently from the frames processed at the image signal processing unit 41. Whether or not an image to be recognized as a person is included in the captured image data serving as an analyzing target is determined, i.e., whether or not an outline portion to be recognized as a person is included within an image is determined. Subsequently, the image analyzing unit 44 supplies the determining result thereof to the CPU 31. In step F402, the CPU 31 confirms whether or not presence of a person has been recognized as the determining result thereof.</p><p id="p0204" num="0204">In the case that the existence of a person is confirmed as an image analysis result, the CPU 31 advances the flow to step F404, and executes the monitoring image display with the front display panel 6F. That is to say, the display controller 7 is instructed to display the monitoring image displayed on the main display panel 6M also on the front display panel 6F.</p><p id="p0205" num="0205">In this case, the display states of the main display panel 6M and the front display<!-- EPO <DP n="32"> --> panel 6F are states such as shown in <figref idrefs="f0004">Fig. 4B</figref>.</p><p id="p0206" num="0206">On the other hand, in the case confirmation is made in step F401 that the current mode is not a predetermined imaging mode, the CPU 31 advances the processing to step F405, and controls the display of the front display panel 6F to be turned off. Also, in the case confirmation is made by the image analysis result confirmation in step F402 that a person does not exist, the CPU 31 advances the flow from step F403 to F405, and controls the display of the front display panel 6F to be turned off.</p><p id="p0207" num="0207">In this case, the display states of the main display panel 6M and the front display panel 6F are states such as shown in <figref idrefs="f0004">Fig. 4A</figref>.</p><p id="p0208" num="0208">The CPU 31 repeatedly executes the processing in <figref idrefs="f0009">Fig. 9</figref> during the monitoring period. Accordingly, when the user selects a predetermined imaging mode and faces the imaging apparatus 1 so that the person becomes the subject during the monitoring period, a monitoring image is displayed on the front display panel 6F.</p><p id="p0209" num="0209">Also, when selecting a imaging mode other than the predetermined imaging modes or when targeting a subject scene that does not include a person such as scenery or the like, the front display panel 6F is turned off. Note that in the case a predetermined imaging mode is selected, at the point in time that a person is to be included in the subject, the monitoring image is to be displayed on the front display panel 6F.</p><p id="p0210" num="0210">That is to say, according to the processing example herein, not only is the on/off of the display of the front display panel 6F controlled, in the case of the above predetermined imaging modes, the monitoring image is displayed on the front display panel 6F in the case that a person exists as a subject on the front side.</p><p id="p0211" num="0211">When a person becomes a subject, the person that is the subject can view the front display panel 6F. Also, since the imaging mode is a predetermined imaging mode, the visibility is assumed to be in a good state. Therefore the person that is the subject can view the monitoring image that oneself is about to be imaged, and can confirm the expression, pose, and so forth of oneself. The display on the front display panel 6F can be effectively used such as confirming by oneself whether or not an expression is favorable for a photograph, for example.</p><p id="p0212" num="0212">On the other hand, in the case that a person does not exist as the subject, determination is made that there is no one to view the front display panel 6F. Accordingly, the display on the front display panel 6F is turned off (only the front display panel 6F is in a power off state, for example), whereby power consumption can be reduced. That is to say,<!-- EPO <DP n="33"> --> wasteful displays that no one is viewing are not performed.</p><p id="p0213" num="0213">Note that in step F402, determination is made as to whether or not there is a person on the front side as a subject, by the image analysis results of the image analysis unit 44, but in step F402, processing to confirm the detection results of the approximation sensor 50 shown in <figref idrefs="f0002">Fig. 2</figref> may be performed. Also, in step F402, both of the image analysis result and the detection result of the proximity sensor 50 may be confirmed.</p><p id="p0214" num="0214">Also, determining the existence of a person on the front side by performing face detection with the image analysis has been described with the various processing examples in <figref idrefs="f0012 f0013 f0014">Figs. 12 through 14</figref>, the modified examples using the approximation sensor 50 can similarly consider the cases of <figref idrefs="f0012 f0013 f0014">Figs. 12 through 14</figref> also.</p><p id="p0215" num="0215">Now, the processing in <figref idrefs="f0011">Fig. 11</figref> performs person detection and controls the display operation of the front display panel 6F, but as person detection, detection of a "face" may be performed.</p><p id="p0216" num="0216">For example, the image analyzing unit 44 determines presence of an outline to be recognized as a face, and presence of a facial element such as the eyes, nose, mouth, or the like from captured image data, and determines whether or not a person's face serving as a subject is included in the captured image data.</p><p id="p0217" num="0217">The processing of the CPU 31 in this case is shown in <figref idrefs="f0012">Fig. 12</figref>. Note that steps F401, F402, F404, and F405 in <figref idrefs="f0012">Fig. 12</figref> are similar to <figref idrefs="f0011">Fig. 11</figref>. In step F402 the CPU 31 confirms the image analysis results of the image analysis unit 44 and determines whether or not a "face" exists. If a "face" is detected, the flow is advanced from step F403A to F404, and the monitoring image display is executed with the front display panel 6F, and on the other hand if a "face" is not detected, the flow is advanced from step F403A to F405 and the front display panel 6F is turned off. Thus, instead of determination of the whole of a person's body, the presence of a person in front may be confirmed by determination of a face.</p><p id="p0218" num="0218">Next, an example of performing display control of the front display panel 6F will be described with consideration for various analysis result information in addition to person recognition, as an image analysis result performed with the image analysis unit 44.</p><p id="p0219" num="0219">Various types of image recognition results can be obtained by other than person recognition and face recognition depending on the image analyzing process at the image analyzing unit 44. For example, the determination information of an external light quantity can be obtained. Also, the relative motion quantity between the imaging apparatus 1 and<!-- EPO <DP n="34"> --> the subject can be determined according to motion detection of frame comparison, analysis of a blurring quantity for each pixel, or the like.</p><p id="p0220" num="0220">Further, as the image recognition process in the case that a face image has been detected, the size of a face (the percentage of a facial portion occupied within the image of one frame), facial orientation, the direction in which the eyes of the subject are directed, or the like within the screen can also be obtained as analysis results.</p><p id="p0221" num="0221">Now, a case of thus using more various types of image analysis results will be described. <figref idrefs="f0013">Fig. 13</figref> shows a display control example for the CPU 31 to execute for the front display panel 6F during the monitoring period. Note that steps F401, F402, F403A, F404, and F405 are similar to <figref idrefs="f0012">Fig. 12</figref>.</p><p id="p0222" num="0222">In step F401, the CPU 31 branches the processing depending on whether the current imaging mode is a predetermined imaging mode suitable for displaying the monitoring image on the front display panel 6F. In the case that the current imaging mode is not a predetermined imaging mode suitable for displaying the monitoring image on the front display panel 6F, the display of the front display panel 6F is controlled to be turned off in step F405.</p><p id="p0223" num="0223">In the case that the current imaging mode is a predetermined imaging mode suitable for displaying the monitoring image on the front display panel 6F, the CPU 31 confirms the analysis results with the image analysis unit 44 in step F402. However with the present example, not only detection of the existence of a face, but other various types of image recognition processing is performed as described above, and the CPU 31 confirms the analysis result information thereof.</p><p id="p0224" num="0224">If a "face" of a person is detected, the flow is advanced from step F403A to F405, and control is performed to turn the display of the front display panel 6F off.</p><p id="p0225" num="0225">If a "face" of a person is detected as the analysis result by the image analysis unit 44, the CPU 31 branches the processing according to other image analysis results in step F410. That is to say, CPU 31 confirms the image analysis results other than the face, and determines whether or not the state is suitable to display the monitoring image on the front display panel 6F.</p><p id="p0226" num="0226">In the case that the CPU 31 determines from the various types of image analysis results that the state is suitable to display the monitoring image on the front display panel 6F, the flow is advanced to step F404, and the monitoring image display is executed with the front display panel 6F. That is to say, the display controller 7 is instructed to display the<!-- EPO <DP n="35"> --> monitoring image displayed on the main display panel 6M also on the front display panel 6F. In this case, the display states of the main display panel 6M and the front display panel 6F are states such as shown in <figref idrefs="f0004">Fig. 4B</figref>.</p><p id="p0227" num="0227">On the other hand, in the case determination is made from other analysis results in step F410 that the state is not suitable to display the monitoring image on the front display panel 6F, the CPU 31 controls the display of the front display panel 6F to be turned off in step F405.</p><p id="p0228" num="0228">In the event of advancing to step F405 from step F401, F403A, or F410, the display state on the main display panel 6M and front display panel 6F.</p><p id="p0229" num="0229">The CPU 31 repeatedly executes the processing in <figref idrefs="f0009">Fig. 9</figref> during the monitoring period. Accordingly, during the monitoring period when the user selects a predetermined imaging mode and faces the imaging apparatus 1 so that the face of the person is included in the subject, and the state recognized by the various types of image analysis results at the point in time thereof is a predetermined state, the monitoring image is displayed on the front display panel 6F. On the other hand, in the case that the imaging mode is not a predetermined imaging mode, or even if in a predetermined imaging mode the person (face) is not included in the subject, further, in the case of a predetermined imaging mode and the face is included in the subject but the state recognized by various types of analysis results is not a predetermined state, the front display panel 6F is turned off.</p><p id="p0230" num="0230">A processing example of step F410 according to the image analysis results other than the existence of a face is as follows. External light quantity can be determined as image analysis results. In the case the external light quantity is low, or excessively high such as when shooting into bright light or the like, the monitoring display on the front display panel 6F can be assumed not to be recognized suitably, as described above with the camera detection information.</p><p id="p0231" num="0231">Thus, even in a case that face detection is made in a predetermined imaging mode, in a case wherein determination is made that the external light quantity is lower than a predetermined level or is in a backlighting state, the CPU 31 deems the state to not be suitable for displaying the monitoring image on the front display panel 6F. That is to say, in step F405 the display of the front display panel 6F is controlled to be turned off.</p><p id="p0232" num="0232">Also, the relative motion quantity between the imaging apparatus 1 and the subject can be determined to be the image analysis result. That is to say, a case where the imaging apparatus 1 itself is blurred or moving (the user is moving the imaging apparatus<!-- EPO <DP n="36"> --> 1), or a case where the subject is moving, or a case where both are moving can be determined.</p><p id="p0233" num="0233">When the motion quantity in these cases is great, it can be conceived that even if there is a person serving as a subject, the subject person thereof will have difficulty in recognizing the front display panel 6F suitably.</p><p id="p0234" num="0234">Thus in step F410, in the case the CPU 31 determines that the relative movement of the imaging apparatus 1 and the subject is great, the flow is advanced to step F405, and the display of the front display panel 6F may be controlled to be turned off.</p><p id="p0235" num="0235">Not only simple face detection but also a face size (percentage of a facial portion within the screen) can be determined for image analysis. Though depending on the zoom position state, if a certain fixed zoom state is considered, the size of a face can serve as an index to determine the distance from the imaging apparatus 1 to the person serving as a subject. For example, in the case that even if the zoom state is a wide state, but a face is shot small, the person thereof can be assumed to be in the distance.</p><p id="p0236" num="0236">Therefore, in step F410 the CPU 31 determines the distance of a subject person based on the size of a face of the person thereof while taking the zoom position into consideration. Subsequently, in the case that the person thereof is in the distance, and has difficulty in viewing the display content of the front display panel 6F, in step F405 it can be conceived that the CPU 31 controls to the display of the front display panel 6F to be turned off.</p><p id="p0237" num="0237">Also, a facial orientation or the direction in which the eyes of the subject are directed can also be recognized for image analysis. In the case that a face is not in the front direction on a captured image, or in the case that the subject is not looking at the imaging apparatus 1, the subject person thereof can be determined not to be viewing the imaging apparatus 1, i.e., the front display panel 6F.</p><p id="p0238" num="0238">Therefore, in step F410 the CPU 31 confirms the facial orientation or the direction in which the eyes of the subject are directed. In the case determination is made that the person thereof is not looking at the display content of the front display panel 6F, the display of the front display panel 6F may be controlled to be turned off.</p><p id="p0239" num="0239">In step F410 in <figref idrefs="f0013">Fig. 13</figref>, suitable display control can be performed for the front display panel 6F, by the CPU 31 performing determinations according to the image analysis results as described above.</p><p id="p0240" num="0240">That is to say, according to the processing in <figref idrefs="f0013">Fig. 13</figref>, in a predetermined imaging<!-- EPO <DP n="37"> --> mode, when face detection is made and the predetermined state from other image analysis results, the monitoring image is displayed with the front display panel 6F. In a situation wherein this is suitable as a situation wherein a person exists on the front side of the subject and which is estimated from the imaging mode, and the person on the subject side can suitable visually confirm (or is visually confirming) the monitoring image from the image analysis results, the monitoring image is displayed on the front display panel 6F. Accordingly, the monitoring image display of the front display panel 6F is performed in a state wherein the probability that the person that is the subject will view the display on the front display panel 6F is extremely high.</p><p id="p0241" num="0241">Also, in the case that a person that is a subject does not exist, or in the case that visibility is poor or a person exists but there is no reason to perform the monitoring image display on the front display panel 6F (not viewing or not viewable), the display on the front display panel 6F is turned off. Thus, power consumption can more suitably be reduced.</p><p id="p0242" num="0242">Next <figref idrefs="f0014">Fig. 14</figref> shows a modified example of the processing example in <figref idrefs="f0013">Fig. 13</figref> which is applicable in the case of the smile shutter mode described above as one of the imaging modes. Other than F420 through F422 in <figref idrefs="f0014">Fig. 14</figref>, the flow is the same as <figref idrefs="f0013">Fig. 13</figref>. Note that in <figref idrefs="f0013">Fig. 13</figref> a release operation by the user (trigger for moving to the imaging period) is not indicated, but the processing up to the imaging period is indicated as steps F420 through F422 in <figref idrefs="f0014">Fig. 14</figref>.</p><p id="p0243" num="0243">According to the image analysis processing, in addition to face detection and the various types of detections mentioned above, expressions of the subject person can also be determined. Thus, in the event that monitoring display is performed with the front display panel 6F according to the imaging mode, existence of a subject person, and other analysis results, the CPU 31 can confirm the results of the expression determination of the subject person in step F420.</p><p id="p0244" num="0244">In the case that a smiling state is obtained from the image analysis results as the expression determination, the flow is automatically advanced to step F422, and release processing, i.e. the recording processing of the captured image data at the point in time thereof is performed. Note that in the case that the user manually has performed a release operation, the flow is advanced from step F421 to F422 and release processing is performed.</p><p id="p0245" num="0245">Thus, by combining the monitoring display on the front display panel 6F and the smile shutter mode processing, the person that is the subject can view one's own<!-- EPO <DP n="38"> --> expression on the front display panel 6F and smile, whereby the recording of the captured image can be performed.</p><p id="p0246" num="0246">Note that in the modified examples according to the processing examples in <figref idrefs="f0011 f0012 f0013 f0014">Figs. 11 through 14</figref>, in step F405, besides turning the display of the front display panel 6F off, displaying in a low luminance state as described with <figref idrefs="f0006">Fig. 6B</figref>, or displaying the playback image or preset image as described with <figref idrefs="f0007">Fig. 7</figref> may be considered.</p><p id="p0247" num="0247">Also, in the processing examples in <figref idrefs="f0012 f0013 f0014">Figs. 12 through 14</figref>, determination is made as to whether or not a person who can visually confirm the front display panel is on the front side, by the face detection by the image analysis, but a person detection (detection of a body of a person within an image) instead of face detection may be used. Also, detection results from an approximation sensor 50 may be used.</p><heading id="h0015">[5. Display Control of the Front Display Panel Unit When Playing]</heading><p id="p0248" num="0248">The various processing examples described up to this point are control processing examples of the front display panel 6F during the monitoring period, but now a display control example of the front display panel 6F during the playback period will be described.</p><p id="p0249" num="0249">As described in <figref idrefs="f0003">Fig. 3</figref>, in the case that the user has performed an operation to instruct a playback operation, the imaging apparatus 1 proceeds to a playback operation state (playback period). During the playback period, an operation to play the image recorded in the recording medium 90 or flash ROM 33 is executed.</p><p id="p0250" num="0250">The CPU 31 reads out the image recorded in the recording medium 90 or flash ROM 33 in response to the user's operation, and instructs the display controller 7 to display thumbnail images or a playback image on the main display panel 6M.</p><p id="p0251" num="0251">At this time, the CPU 31 performs the processing in <figref idrefs="f0015">Fig. 15</figref> relating to the front display panel 6F.</p><p id="p0252" num="0252">In step F501 in the playback period, the CPU 31 determines whether the display mode is a display mode to perform display on the main display panel 6M and the front display panel 6F, or a display mode to perform display only on the main display panel 6M. For example this display mode can be selected by a user operation.</p><p id="p0253" num="0253">If not a display mode to perform both screen displays, the CPU 31 advances the processing from the step F501 to F505, and executes control to turn the front display panel 6F. That is to say, the playing image display is performed only on the main display panel 6M.</p><p id="p0254" num="0254">If in a display mode to perform both screen displays, the CPU 31 advances the flow<!-- EPO <DP n="39"> --> from step F501 to F502, and branches the processing according to the playing display state of the current main display panel 6M. That is to say, currently, the CPU 31 branches the process depending on whether a thumbnail list of playback images or a single image is displayed on the main display panel 6M.</p><p id="p0255" num="0255">In the case that a single playback image is now displayed on the main display panel 6M, the CPU 31 advances the process to step F503 to instruct the display controller 7 to display the same playback image data on the front display panel 6F as well. In this case, the display states of the main display panel 6M and the front display panel 6F are states such as shown in <figref idrefs="f0005">Fig. 5C</figref>.</p><p id="p0256" num="0256">On the other hand, in the case that a thumbnail list is now displayed on the main display panel 6M, the CPU 31 advances the process to step F504. In this case, the CPU 31 instructs the display controller 7 to display on the front display panel 6F playback image data selected by the cursor K on the thumbnail list display. In this case, the display states of the main display panel 6M and the front display panel 6F are states such as shown in <figref idrefs="f0005">Fig. 5B</figref>.</p><p id="p0257" num="0257">By the CPU 31 executing such a process, a person in the front side can also view on the front display panel 6F side simultaneously. Accordingly, the user of the imaging apparatus 1, and the person in the front side can enjoy a playback image.</p><p id="p0258" num="0258">Also, as shown in <figref idrefs="f0005">Fig. 5B</figref>, in the case that a thumbnail list is displayed on the main display panel 6M, the user of the imaging apparatus 1 moves the cursor K, whereby a person in the front side can view the selected playback image on the front display panel 6F side.</p><heading id="h0016">6. Modification Examples</heading><p id="p0259" num="0259">The various types of process examples, and modifications serving as embodiments have been described so far, but further various modifications can be conceived as embodiments of the present invention.</p><p id="p0260" num="0260">For example, an arrangement may be made wherein, in the case that common monitoring image display is not executed on the front display panel 6F, an example is given wherein the display of the front display panel 6F is turned off, the display of the front display panel 6F is set to low-intensity display, or a playback image or preset image is displayed on the front display panel 6F, but the user can select which of these states to use.</p><p id="p0261" num="0261">With the present embodiment, examples for performing display control of the front display panel 6F have been described, under the assumption of whether or not the imaging<!-- EPO <DP n="40"> --> mode is a predetermined imaging mode to estimate the state suitable for displaying the front display panel 6F, and further by combining user setting state, determinations by camera detecting information (internal detecting information), and image analysis results. These may be further combined.</p><p id="p0262" num="0262">For example, an example to perform display control of the front display panel 6F with the imaging mode, user setting state, and camera detecting information may be considered.</p><p id="p0263" num="0263">Also, an example to perform display control of the front display panel 6F with the imaging mode, user setting state, and image analysis results may be considered.</p><p id="p0264" num="0264">Also, an example to perform display control of the front display panel 6F with the imaging mode, camera detecting information, and image analysis results may be considered.</p><p id="p0265" num="0265">Also, an example to perform display control of the front display panel 6F with the imaging mode, user setting state, camera detecting information, and image analysis results may be considered.</p><p id="p0266" num="0266">Also, as a shooing mode, there are cases wherein an automatic mode is prepared besides the examples described above. An automatic mode is a mode wherein the CPU 31 sets suitable imaging parameters and controls the processing of the imaging system 2 and camera DSP 4 according to external-light state, image analysis, and the like.</p><p id="p0267" num="0267">In the case that an automatic mode is prepared as an imaging mode, for example the automatic mode may be one of the predetermined imaging modes suitable to the display of the front display panel 6F. Processing such as that in <figref idrefs="f0009 f0010 f0011 f0012 f0013 f0014">Figs. 9 through 14</figref> is applied, and the display state of the front display panel 6F is controlled according to the camera detecting information, user setting information, and image analysis results.</p><p id="p0268" num="0268">With the present embodiment, description is given under the assumption of a still image shoot. However, the present example can also be applied to a moving image. In the case of a moving image, the above-mentioned monitoring period is similar to a standby period until the imaging starts. The above-mentioned recording period is the moving image recording period from recording start until recording end. Accordingly, the moving image display control of the front display panel 6F is performed during the standby period and recording period.</p><p id="p0269" num="0269">If an imaging apparatus 1 can shoot both a still image and moving image, a moving image mode is prepared as one of the imaging modes. The moving mode herein goes to one of the predetermined imaging modes applicable to the display of the front display panel 6F. In the standby period and recording period, the processing such as that in <figref idrefs="f0009 f0010 f0011 f0012 f0013 f0014">Figs. 9<!-- EPO <DP n="41"> --> through 14</figref> is applied, and the display state of the front display panel 6F is controlled according to the camera detecting information, user setting information, and image analysis results.</p><p id="p0270" num="0270">With the present example, an apparatus generally called a digital still camera has been exemplified as the imaging apparatus 1, but an embodiment of the present invention can be applied to various types of apparatuses, for example, such as video cameras, cellular phones having imaging functions, PDAs (Personal Digital Assistant), and so forth.</p><p id="p0271" num="0271">The present application contains subject matter related to that disclosed in Japanese Priority Patent Application <patcit id="pcit0004" dnum="JP2008284293A"><text>JP 2008-284293</text></patcit> filed in the Japan Patent Office on November 5, 2008.</p><p id="p0272" num="0272">It should be understood by those skilled in the art that various modifications, combinations, sub-combinations and alterations may occur depending on design requirements and other factors insofar as they are within the scope of the appended claims or the equivalents thereof.</p></description><claims mxw-id="PCLM56984723" lang="DE" load-source="patent-office"><!-- EPO <DP n="45"> --><claim id="c-de-01-0001" num="0001"><claim-text>Abbildungsvorrichtung mit:
<claim-text>einer ersten Anzeigetafeleinheit (6M), die konfiguriert ist, eine Anzeige zu einer Anwenderseite auszuführen, die an einem Vorrichtungsgehäuse angeordnet ist;</claim-text>
<claim-text>einer zweiten Anzeigetafeleinheit (6F), die konfiguriert ist, eine Anzeige zu einer Gegenstandsseite auszuführen, und am Vorrichtungsgehäuse angeordnet ist;</claim-text>
<claim-text>einer Abbildungsverarbeitungseinheit (2), die konfiguriert ist, von der Gegenstandsseite einfallendes Licht einer photoelektrischen Umwandlung zu unterziehen, um ein erfasstes Bildsignal zu erhalten; und</claim-text>
<claim-text>einer Steuereinheit (3), die konfiguriert ist, eine Abbildungsverarbeitungssteuerung gemäß einer Abbildungsart auszuführen, und eine Anzeige, die auf dem erfassten Bildsignal beruht, das durch die Abbildungsverarbeitungseinheit (2) erhalten wird, mit der ersten Anzeigetafeleinheit (6M) auszuführen, während die Anzeigeoperationen der zweiten Anzeigetafeleinheit (6F), die auf dem erfassten Bildsignal beruhen, das mit der Abbildungsverarbeitungseinheit (2) erhalten wird, mindestens gemäß der Abbildungsart gesteuert werden;</claim-text>
<claim-text><b>dadurch gekennzeichnet, dass</b> die Steuereinheit (3) konfiguriert ist, zu schätzen, ob die Sichtbarkeit der zweiten Anzeigetafeleinheit (6F) für eine Person auf der Gegenstandsseite der Abbildungsvorrichtung schlecht ist, und die Anzeigeoperationen der zweiten Anzeigetafeleinheit (6F) abhängig vom Ergebnis der Schätzung der schlechten Sichtbarkeit zu steuern.</claim-text></claim-text></claim><claim id="c-de-01-0002" num="0002"><claim-text>Abbildungsvorrichtung nach Anspruch 1, wobei die Steuereinheit (3) in dem Fall, dass die Abbildungsart eine vorgegebene Abbildungsart aus mehreren Abbildungsarten ist, eine Steuerung ausführt, eine Anzeige, die auf dem erfassten Bildsignal beruht, das mit der Abbildungsverarbeitungseinheit (2) erhalten wird, auf der zweiten Anzeigetafeleinheit (6F) auszuführen.</claim-text></claim><claim id="c-de-01-0003" num="0003"><claim-text>Abbildungsvorrichtung nach Anspruch 2, wobei die Steuereinheit (3) in dem Fall, dass die Abbildungsart nicht die vorgegebene Abbildungsart ist, eine Steuerung ausführt, die Anzeige der zweiten Anzeigetafeleinheit (6F) abzuschalten.<!-- EPO <DP n="46"> --></claim-text></claim><claim id="c-de-01-0004" num="0004"><claim-text>Abbildungsvorrichtung nach Anspruch 2, wobei die Steuereinheit (3) in dem Fall, dass die Abbildungsart nicht die vorgegebene Abbildungsart ist, eine Steuerung ausführt, eine Anzeige, die auf dem erfassten Bildsignal beruht, das mit der Abbildungsverarbeitungseinheit (2) erhalten wird, auf der zweiten Anzeigetafeleinheit (6F) in einem Zustand niedriger Helligkeit auszuführen.</claim-text></claim><claim id="c-de-01-0005" num="0005"><claim-text>Abbildungsvorrichtung nach Anspruch 2, die ferner aufweist:
<claim-text>eine Bilddatenleseeinheit (4), die konfiguriert ist, auf einem Speichermedium (90) aufgezeichnete Bilddaten zu lesen;</claim-text>
<claim-text>wobei die Steuereinheit (3) in dem Fall, dass die Abbildungsart nicht die vorgegebene Abbildungsart ist, eine Steuerung ausführt, eine Anzeige, die auf Bilddaten beruht, die durch die Bilddatenleseeinheit (4) ausgelesen werden, auf der zweiten Anzeigetafeleinheit (6F) auszuführen.</claim-text></claim-text></claim><claim id="c-de-01-0006" num="0006"><claim-text>Abbildungsvorrichtung nach Anspruch 1, wobei die Steuereinheit (3) die Anzeigeoperation, die auf dem erfassten Bildsignal beruht, das mit der Abbildungsverarbeitungseinheit (2) erhalten wird, auf der zweiten Anzeigetafeleinheit (6F) beruhend auf der Abbildungsart und einem Einstellungszustand gemäß den Operationen des Anwenders ausführt, die andere Operationen der Abbildungsvorrichtung als die Abbildungsart betreffen.</claim-text></claim><claim id="c-de-01-0007" num="0007"><claim-text>Abbildungsvorrichtung nach Anspruch 1, wobei die Steuereinheit (3) die Anzeigeoperation, die auf dem erfassten Bildsignal beruht, das mit der Abbildungsverarbeitungseinheit (2) erhalten wird, auf der zweiten Anzeigetafeleinheit (6F) beruhend auf der Abbildungsart und den internen Detektionsinformationen der Abbildungsvorrichtung ausführt.</claim-text></claim><claim id="c-de-01-0008" num="0008"><claim-text>Abbildungsvorrichtung nach Anspruch 1, die ferner aufweist:
<claim-text>eine Bildanalyseeinheit (44), die konfiguriert ist, eine Bildanalyse des erfassten Bildsignals durchzuführen, das mit der Abbildungsverarbeitungseinheit (2) erhalten wird,</claim-text>
<claim-text>wobei die Steuereinheit (3) die Anzeigeoperation, die auf dem erfassten Bildsignal beruht, das mit der Abbildungsverarbeitungseinheit (2) erhalten wird, mit der zweiten Anzeigetafeleinheit (6F) beruhend auf der Abbildungsart und Bildanalyseinformationen aus der Bildanalyseeinheit (44) steuert.</claim-text><!-- EPO <DP n="47"> --></claim-text></claim><claim id="c-de-01-0009" num="0009"><claim-text>Abbildungsvorrichtung nach Anspruch 8, wobei die Bildanalyseeinheit (44) aus der Bildanalyse des erfassten Bildsignals, das mit der Abbildungsverarbeitungseinheit (2) erhalten wird, detektiert, ob eine Person auf der Gegenstandsseite vorhanden ist oder nicht.</claim-text></claim><claim id="c-de-01-0010" num="0010"><claim-text>Abbildungsvorrichtung nach Anspruch 1, die ferner aufweist:
<claim-text>eine Bedienungseinheit (5), die konfiguriert ist, die Abbildungsart auszuwählen.</claim-text></claim-text></claim><claim id="c-de-01-0011" num="0011"><claim-text>Anzeigensteuerverfahren für eine Abbildungsvorrichtung mit einer ersten Anzeigetafeleinheit (6M), die konfiguriert ist, eine Anzeige zu einer Anwenderseite auszuführen, und einer zweiten Anzeigetafeleinheit (6F), die konfiguriert ist, eine Anzeige zu einer Gegenstandsseite auszuführen, das die folgenden Schritte aufweist:
<claim-text>Ausführen einer Anzeige auf der ersten Anzeigetafeleinheit (6M), die auf einem erfassten Bildsignal beruht, das erhalten wird, indem von der Gegenstandsseite einfallendes Licht einer photoelektrischen Umwandlung unterzogen wird; und</claim-text>
<claim-text>Steuern der Anzeigeoperationen des erfassten Bildsignals auf der zweiten Anzeigetafeleinheit (6F) gemäß einer Abbildungsart, die aus verschiedenen Typen von Abbildungsarten ausgewählt wird, um eine Abbildungsverarbeitung durchzuführen, die für die Abbildungssituation geeignet ist;</claim-text>
<claim-text><b>dadurch gekennzeichnet, dass</b> der Steuerungsschritt konfiguriert ist, abzuschätzen, ob eine Sichtbarkeit der zweiten Anzeigetafeleinheit (6F) für eine Person auf der Gegenstandsseite der Abbildungsvorrichtung schlecht ist, und Anzeigeoperationen der zweiten Anzeigetafeleinheit (6F) abhängig vom Ergebnis der Schätzung der schlechten Sichtbarkeit zu steuern.</claim-text></claim-text></claim></claims><claims mxw-id="PCLM56984724" lang="EN" load-source="patent-office"><!-- EPO <DP n="42"> --><claim id="c-en-01-0001" num="0001"><claim-text>An imaging apparatus comprising:
<claim-text>a first display panel unit (6M) configured to execute display toward a user side, disposed on an apparatus casing;</claim-text>
<claim-text>a second display panel unit (6F) configured to execute display toward a subject side, disposed on said apparatus casing;</claim-text>
<claim-text>an imaging processing unit (2) configured to subject incident light from said subject side to photoelectric conversion to obtain a captured image signal; and</claim-text>
<claim-text>a control unit (3) configured to execute imaging processing control according to imaging mode, and execute display based on the captured image signal obtained by said imaging processing unit (2) with said first display panel unit (6M), while controlling the display operations based on the captured image signal obtained with said imaging processing unit (2) of said second display panel unit (6F) at least according to said imaging mode;</claim-text>
<claim-text><b>characterized in that</b> the control unit (3) is configured to estimate when visibility of said second display panel unit (6F) is poor for a person on the subject side of the imaging apparatus and to control display operations of said second display panel unit (6F) dependent on the result of the poor-visibility estimation.</claim-text></claim-text></claim><claim id="c-en-01-0002" num="0002"><claim-text>The imaging apparatus according to Claim 1, wherein said control unit (3) performs control to execute display based on the captured image signal obtained with said imaging processing unit (2) on said second display panel (6F), in the case that said imaging mode is a predetermined imaging mode out of a plurality of imaging modes.</claim-text></claim><claim id="c-en-01-0003" num="0003"><claim-text>The imaging apparatus according to Claim 2, wherein said control unit (3) performs control to turn the display of said second display panel unit (6F) off in the case that said imaging mode is not said predetermined imaging mode.</claim-text></claim><claim id="c-en-01-0004" num="0004"><claim-text>The imaging apparatus according to Claim 2, wherein said control unit (3) performs control to execute display based on the captured image signal obtained with said imaging processing unit (2) on said second display panel unit (6F) in a low luminance state, in the case that said imaging mode is not said predetermined imaging mode.</claim-text></claim><claim id="c-en-01-0005" num="0005"><claim-text>The imaging apparatus according to Claim 2, further comprising:
<claim-text>an image data reading unit (4) configured to read image data recorded on a storage medium (90);<!-- EPO <DP n="43"> --></claim-text>
<claim-text>wherein said control unit (3) performs control to execute display based on image data read out by said image data reading unit (4) on said second display panel unit (6F), in the case that said imaging mode is not said predetermined imaging mode.</claim-text></claim-text></claim><claim id="c-en-01-0006" num="0006"><claim-text>The imaging apparatus according to Claim 1, wherein said control unit (3) controls the display operation based on the captured image signal obtained with said imaging processing unit (2) on said second display panel unit (6F), based on said imaging mode and a settings state according to the operations of the user relating to operations of the imaging apparatus other than the imaging mode.</claim-text></claim><claim id="c-en-01-0007" num="0007"><claim-text>The imaging apparatus according to Claim 1, wherein said control unit (3) controls the display operation based on the captured image signal obtained with said imaging processing unit (2) on said second display panel unit (6F), based on said imaging mode and the internal detecting information of the imaging apparatus.</claim-text></claim><claim id="c-en-01-0008" num="0008"><claim-text>The imaging apparatus according to Claim 1, further comprising:
<claim-text>an image analysis unit (44) configured to perform image analysis of the captured image signal obtained with said imaging processing unit (2),</claim-text>
<claim-text>wherein said control unit (3) controls the display operation based on the captured image signal obtained with said imaging processing unit (2) with said second display panel unit (6F), based on said imaging mode, and an image analysis information from said image analysis unit (44).</claim-text></claim-text></claim><claim id="c-en-01-0009" num="0009"><claim-text>The imaging apparatus according to Claim 8, wherein said image analysis unit (44) detects whether or not a person exists in said subject side from the image analysis of the captured image signal obtained with said imaging processing unit (2).</claim-text></claim><claim id="c-en-01-0010" num="0010"><claim-text>The imaging apparatus according to Claim 1, further comprising:
<claim-text>an operating unit (5) configured to select said imaging mode.</claim-text></claim-text></claim><claim id="c-en-01-0011" num="0011"><claim-text>A display control method for an imaging apparatus with a first display panel unit (6M) configured to execute display toward a user side and a second display panel unit (6F) configured to execute display toward a subject side comprising the steps of:<!-- EPO <DP n="44"> -->
<claim-text>executing display on the first display panel unit (6M) based on a captured image signal obtained by subjecting incident light from the subject side to photoelectric conversion; and</claim-text>
<claim-text>controlling display operations of said captured image signal on the second display panel unit (6F) according to an imaging mode selected from various types of imaging modes to perform imaging processing suitable to the imaging situation;</claim-text>
<claim-text><b>characterized in that</b> the controlling step is configured to estimate when visibility of said second display panel unit (6F) is poor for a person on the subject side of the imaging apparatus and to control display operations of said second display panel unit (6F) dependent on the result of the poor-visibility estimation.</claim-text></claim-text></claim></claims><claims mxw-id="PCLM56984725" lang="FR" load-source="patent-office"><!-- EPO <DP n="48"> --><claim id="c-fr-01-0001" num="0001"><claim-text>de formation d'image comprenant :
<claim-text>une première unité à panneau d'affichage (6M) configurée pour exécuter l'affichage vers un côté utilisateur, sur un boîtier d'appareil ;</claim-text>
<claim-text>une seconde unité à panneau d'amchage (6F) configurée pour exécuter vers un côte sujet, sur ledit boîtier d'appareil ;</claim-text>
<claim-text>une unité de traitement de formation d'image (2) configurée pour soumettre la lumière incidente provenant dudit côté sujet à une conversion photoélectrique afin d'obtenir un signal d'image acquis ; et</claim-text>
<claim-text>une unité de commande (3) configurée pour exécuter la commande de traitement de formation d'image conformément à un mode de formation d'image, et exécuter l'affichage sur la base du signal d'image acquis obtenu par ladite unité de traitement de formation d'image (2) avec ladite première unité à panneau d'affichage (6M), tout en commandant les opérations d'affichage sur la du signal d'image acquis au moyen de ladite unité de traitement de formation d'image (2) de ladite seconde unité à panneau d'affichage (6F), au moins conformément audit mode de formation d'image ;</claim-text>
<claim-text><b>caractérisé en ce que</b> l'unité de commande (3) est configurée pour estimer si la visibilité de ladite seconde unité à panneau d'affichage (6F) est faible pour une personne située du côté sujet de l'appareil de formation d'image et pour commander les opérations d'affichage de ladite seconde unité à panneau d'affichage (6F) en fonction du résultat de l'estimation de faible visibilité.</claim-text></claim-text></claim><claim id="c-fr-01-0002" num="0002"><claim-text>Appareil de formation d'image selon la revendication 1, dans lequel ladite unité de commande (3) effectue une commande pour exécuter l'affichage sur la base du signal d'image acquis obtenu au moyen de ladite unité de traitement de formation d'image (2) sur ladite seconde unité à panneau d'affichage (6F), dans le cas où ledit mode de formation d'image est un mode de formation d'image prédéterminé parmi une pluralité de modes de formation d'image.<!-- EPO <DP n="49"> --></claim-text></claim><claim id="c-fr-01-0003" num="0003"><claim-text>Appareil de formation d'image selon la revendication 2, dans lequel ladite unité de commande (3) effectue une commande pour désactiver l'affichage de ladite seconde unité à panneau d'affichage (6F) dans le cas où ledit mode de formation d'image n'est pas ledit mode de formation d'image prédéterminé.</claim-text></claim><claim id="c-fr-01-0004" num="0004"><claim-text>Appareil de formation d'image selon la revendication 2, dans lequel ladite unité de commande (3) effectue une commande pour exécuter l'affichage sur la base du signal d'image acquis obtenu au moyen de ladite unité de traitement de formation d'image (2) sur ladite seconde unité à panneau d'affichage (6F) dans un état de faible luminance, dans le cas où ledit mode de formation d'image n'est pas ledit mode de formation d'image prédéterminé.</claim-text></claim><claim id="c-fr-01-0005" num="0005"><claim-text>Appareil de formation d'image selon la revendication 2, comprenant en outre :
<claim-text>une unité de lecture de données d'image (4) configurée pour lire des données d'image enregistrées sur un support de stockage (90) ;</claim-text>
<claim-text>dans lequel ladite unité de commande (3) effectue une commande pour exécuter l'affichage sur la base de données d'image lues par ladite unité de lecture de données d'image (4) sur ladite seconde unité à panneau d'affichage (6F), dans le cas où ledit mode de formation d'image n'est pas ledit mode de formation d'image prédéterminé.</claim-text></claim-text></claim><claim id="c-fr-01-0006" num="0006"><claim-text>Appareil de formation d'image selon la revendication 1, dans lequel ladite unité de commande (3) commande l'opération d'affichage sur la base du signal d'image acquis obtenu au moyen de ladite unité de traitement de formation d'image (2) sur ladite seconde unité à panneau d'affichage (6F), sur la base dudit mode de formation d'image et d'un état de réglages conformément aux opérations de l'utilisateur qui sont liées à des opérations de l'appareil de formation d'image autres que le mode de formation d'image.</claim-text></claim><claim id="c-fr-01-0007" num="0007"><claim-text>Appareil de formation d'image selon la revendication 1, dans lequel ladite unité de commande (3) commande l'opération d'affichage sur la base du signal d'image acquis obtenu au moyen de ladite unité de traitement de formation<!-- EPO <DP n="50"> --> d'image (2) sur ladite seconde unité à panneau d'affichage (6F), sur la base dudit mode de formation d'image et des informations de détection internes de l'appareil de formation d'image.</claim-text></claim><claim id="c-fr-01-0008" num="0008"><claim-text>Appareil de formation d'image selon la revendication 1, comprenant en outre :
<claim-text>une unité d'analyse d'image (44) configurée pour effectuer une analyse d'image du signal d'image acquis obtenu au moyen de ladite unité de traitement de formation d'image (2),</claim-text>
<claim-text>dans lequel ladite unité de commande (3) commande l'opération d'affichage sur la base du signal d'image acquis obtenu au moyen de ladite unité de traitement de formation d'image (2) avec ladite seconde unité à panneau d'affichage (6F), sur la base dudit mode de formation d'image et d'une information d'analyse d'image de ladite unité d'analyse d'image (44).</claim-text></claim-text></claim><claim id="c-fr-01-0009" num="0009"><claim-text>Appareil de formation d'image selon la revendication 8, dans lequel ladite unité d'analyse d'image (44) détecte si oui ou non une personne est présente dudit côté sujet à partir de l'analyse d'image du signal d'image acquis obtenu au moyen de ladite unité de traitement de formation d'image (2).</claim-text></claim><claim id="c-fr-01-0010" num="0010"><claim-text>Appareil de formation d'image selon la revendication 1, comprenant en outre :
<claim-text>une unité de commande (5) configurée pour sélectionner ledit mode de formation d'image.</claim-text></claim-text></claim><claim id="c-fr-01-0011" num="0011"><claim-text>Procédé de commande d'affichage destiné à un appareil de formation d'image comportant une première unité à panneau d'affichage (6M) configurée pour exécuter l'affichage vers un côté utilisateur et une seconde unité à panneau d'affichage (6F) configurée pour exécuter l'affichage vers un côté sujet, comprenant les étapes consistant à :
<claim-text>exécuter l'affichage sur la première unité à panneau d'affichage (6M) sur la base d'un signal d'image acquis obtenu en soumettant la lumière incidente provenant du côté sujet à une conversion photoélectrique ; et<!-- EPO <DP n="51"> --></claim-text>
<claim-text>commander les opérations d'affichage du signal d'image acquis sur la seconde unité à panneau d'affichage (6F) conformément à un mode de formation d'image choisi parmi divers types de modes de formation d'image pour effectuer un traitement de formation d'image adapté à la situation de formation d'image ;</claim-text>
<claim-text><b>caractérisé en ce que</b> l'étape de commande est configurée pour estimer si la visibilité de ladite seconde unité à panneau d'affichage (6F) est faible pour une personne située du côté sujet de l'appareil de formation d'image et pour commander les opérations d'affichage de ladite seconde unité à panneau d'affichage (6F) en fonction du résultat de l'estimation de faible visibilité.</claim-text></claim-text></claim></claims><drawings mxw-id="PDW16671941" load-source="patent-office"><!-- EPO <DP n="52"> --><figure id="f0001" num="1A,1B"><img id="if0001" file="imgf0001.tif" wi="114" he="219" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="53"> --><figure id="f0002" num="2"><img id="if0002" file="imgf0002.tif" wi="165" he="230" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="54"> --><figure id="f0003" num="3"><img id="if0003" file="imgf0003.tif" wi="139" he="130" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="55"> --><figure id="f0004" num="4A,4B,4C"><img id="if0004" file="imgf0004.tif" wi="159" he="216" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="56"> --><figure id="f0005" num="5A,5B,5C"><img id="if0005" file="imgf0005.tif" wi="153" he="217" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="57"> --><figure id="f0006" num="6A,6B"><img id="if0006" file="imgf0006.tif" wi="165" he="202" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="58"> --><figure id="f0007" num="7"><img id="if0007" file="imgf0007.tif" wi="165" he="94" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="59"> --><figure id="f0008" num="8"><img id="if0008" file="imgf0008.tif" wi="165" he="125" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="60"> --><figure id="f0009" num="9"><img id="if0009" file="imgf0009.tif" wi="165" he="131" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="61"> --><figure id="f0010" num="10"><img id="if0010" file="imgf0010.tif" wi="165" he="129" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="62"> --><figure id="f0011" num="11"><img id="if0011" file="imgf0011.tif" wi="165" he="129" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="63"> --><figure id="f0012" num="12"><img id="if0012" file="imgf0012.tif" wi="165" he="129" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="64"> --><figure id="f0013" num="13"><img id="if0013" file="imgf0013.tif" wi="165" he="171" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="65"> --><figure id="f0014" num="14"><img id="if0014" file="imgf0014.tif" wi="165" he="224" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="66"> --><figure id="f0015" num="15"><img id="if0015" file="imgf0015.tif" wi="165" he="121" img-content="drawing" img-format="tif"/></figure></drawings><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
