<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2182421-B1" country="EP" doc-number="2182421" kind="B1" date="20140108" family-id="41478967" file-reference-id="315040" date-produced="20180826" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="146588242" ucid="EP-2182421-B1"><document-id><country>EP</country><doc-number>2182421</doc-number><kind>B1</kind><date>20140108</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-09171857-A" is-representative="YES"><document-id mxw-id="PAPP154850434" load-source="docdb" format="epo"><country>EP</country><doc-number>09171857</doc-number><kind>A</kind><date>20090930</date><lang>EN</lang></document-id><document-id mxw-id="PAPP179317197" load-source="docdb" format="original"><country>EP</country><doc-number>09171857.7</doc-number><date>20090930</date></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC140549167" ucid="KR-20080106935-A" load-source="docdb"><document-id format="epo"><country>KR</country><doc-number>20080106935</doc-number><kind>A</kind><date>20081030</date></document-id></priority-claim></priority-claims><dates-of-public-availability><intention-to-grant-date><date>20130716</date></intention-to-grant-date></dates-of-public-availability><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL-1705300781" load-source="docdb">G06F   3/038       20130101A I20130105RMEP        </classification-ipcr><classification-ipcr mxw-id="PCL1989325053" load-source="docdb">G06F   3/01        20060101AFI20100128BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1989325054" load-source="docdb">G06F   3/041       20060101ALI20100128BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1989325055" load-source="docdb">G06F   3/048       20130101ALI20100128BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1989626091" load-source="docdb">G06F   3/0488      20130101A I20130921RMEP        </classification-ipcr><classification-ipcr mxw-id="PCL1989627147" load-source="docdb">G06F   3/0481      20130101A I20130921RMEP        </classification-ipcr><classification-ipcr mxw-id="PCL1989645202" load-source="docdb">G06F   3/0486      20130101A I20130921RMEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-1875785438" load-source="docdb" scheme="CPC">G06F   3/04845     20130101 LI20161117BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1875785439" load-source="docdb" scheme="CPC">G06F   3/0482      20130101 LI20161117BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2038191952" load-source="docdb" scheme="CPC">G06F   3/0481      20130101 LI20150711BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2038191977" load-source="docdb" scheme="CPC">G06F   3/0486      20130101 LI20150711BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2038192498" load-source="docdb" scheme="CPC">G06F   3/04886     20130101 LI20150711BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2038194019" load-source="docdb" scheme="CPC">G06F   3/0414      20130101 LI20150711BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2038194067" load-source="docdb" scheme="CPC">G06F   3/0416      20130101 LI20150711BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2038197608" load-source="docdb" scheme="CPC">G06F   3/016       20130101 FI20150711BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2038198690" load-source="docdb" scheme="CPC">G06F   3/0487      20130101 LI20150710BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT132369359" lang="DE" load-source="patent-office">Objektausführungsverfahren und -vorrichtung</invention-title><invention-title mxw-id="PT132369360" lang="EN" load-source="patent-office">Object execution method and apparatus</invention-title><invention-title mxw-id="PT132369361" lang="FR" load-source="patent-office">Procédé et appareil d'exécution d'objets</invention-title><citations><patent-citations><patcit mxw-id="PCIT367053185" load-source="docdb" ucid="US-20060132456-A1"><document-id format="epo"><country>US</country><doc-number>20060132456</doc-number><kind>A1</kind><date>20060622</date></document-id><sources><source name="EXA" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT367053186" load-source="docdb" ucid="WO-2002054213-A1"><document-id format="epo"><country>WO</country><doc-number>2002054213</doc-number><kind>A1</kind><date>20020711</date></document-id><sources><source name="EXA" created-by-npl="N"/></sources></patcit></patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR919524474" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>SAMSUNG ELECTRONICS CO LTD</last-name><address><country>KR</country></address></addressbook></applicant><applicant mxw-id="PPAR919529051" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>SAMSUNG ELECTRONICS CO., LTD.</last-name></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR919529744" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>JUNG HAN CHUL</last-name><address><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR919520901" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>JUNG, HAN CHUL</last-name></addressbook></inventor><inventor mxw-id="PPAR919022204" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>JUNG, HAN CHUL</last-name><address><street>Samsung Electronics Co., Ltd 416 Maetan-dong Yeongtong-gu, Suwon-si</street><city>Gyeonggi-do</city><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR919535859" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>KWON O JAE</last-name><address><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR919540646" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>KWON, O JAE</last-name></addressbook></inventor><inventor mxw-id="PPAR919022202" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>KWON, O JAE</last-name><address><street>Samsung Electronics Co., Ltd 416 Maetan-dong Yeongtong-gu, Suwon-si</street><city>Gyeonggi-do</city><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR919518224" load-source="docdb" sequence="3" format="epo"><addressbook><last-name>SHIN CHANG BEOM</last-name><address><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR919536541" load-source="docdb" sequence="3" format="intermediate"><addressbook><last-name>SHIN, CHANG BEOM</last-name></addressbook></inventor><inventor mxw-id="PPAR919022203" load-source="patent-office" sequence="3" format="original"><addressbook><last-name>SHIN, CHANG BEOM</last-name><address><street>Samsung Electronics Co., Ltd 416 Maetan-dong Yeongtong-gu, Suwon-si</street><city>Gyeonggi-do</city><country>KR</country></address></addressbook></inventor></inventors><assignees><assignee mxw-id="PPAR919022205" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Samsung Electronics Co., Ltd.</last-name><iid>101328413</iid><address><street>129, Samsung-ro Yeongtong-gu</street><city>SUWON-SI, GYEONGGI-DO, 443-742</city><country>KR</country></address></addressbook></assignee></assignees><agents><agent mxw-id="PPAR919022206" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Birchenough, Lewis</last-name><iid>101381099</iid><address><street>Harrison Goddard Foote LLP Saviour House 9 St Saviourgate</street><city>York YO1 8NQ</city><country>GB</country></address></addressbook></agent></agents></parties><international-convention-data><designated-states><ep-contracting-states><country mxw-id="DS549800438" load-source="docdb">AT</country><country mxw-id="DS549783088" load-source="docdb">BE</country><country mxw-id="DS549868478" load-source="docdb">BG</country><country mxw-id="DS549890981" load-source="docdb">CH</country><country mxw-id="DS549784017" load-source="docdb">CY</country><country mxw-id="DS549800439" load-source="docdb">CZ</country><country mxw-id="DS549783101" load-source="docdb">DE</country><country mxw-id="DS549784018" load-source="docdb">DK</country><country mxw-id="DS549784019" load-source="docdb">EE</country><country mxw-id="DS549876191" load-source="docdb">ES</country><country mxw-id="DS549868479" load-source="docdb">FI</country><country mxw-id="DS549871452" load-source="docdb">FR</country><country mxw-id="DS549783102" load-source="docdb">GB</country><country mxw-id="DS549784020" load-source="docdb">GR</country><country mxw-id="DS549783103" load-source="docdb">HR</country><country mxw-id="DS549800440" load-source="docdb">HU</country><country mxw-id="DS549890982" load-source="docdb">IE</country><country mxw-id="DS549784025" load-source="docdb">IS</country><country mxw-id="DS549871453" load-source="docdb">IT</country><country mxw-id="DS549784026" load-source="docdb">LI</country><country mxw-id="DS549868480" load-source="docdb">LT</country><country mxw-id="DS549923269" load-source="docdb">LU</country><country mxw-id="DS549868481" load-source="docdb">LV</country><country mxw-id="DS549868486" load-source="docdb">MC</country><country mxw-id="DS549923270" load-source="docdb">MK</country><country mxw-id="DS549923271" load-source="docdb">MT</country><country mxw-id="DS549923272" load-source="docdb">NL</country><country mxw-id="DS549800461" load-source="docdb">NO</country><country mxw-id="DS549923273" load-source="docdb">PL</country><country mxw-id="DS549784027" load-source="docdb">PT</country><country mxw-id="DS549876192" load-source="docdb">RO</country><country mxw-id="DS549923274" load-source="docdb">SE</country><country mxw-id="DS549783104" load-source="docdb">SI</country><country mxw-id="DS549800462" load-source="docdb">SK</country><country mxw-id="DS549923275" load-source="docdb">SM</country><country mxw-id="DS549890983" load-source="docdb">TR</country></ep-contracting-states></designated-states></international-convention-data></bibliographic-data><description mxw-id="PDES63960668" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><heading id="h0001">BACKGROUND OF THE INVENTION</heading><heading id="h0002">FIELD OF THE INVENTION</heading><p id="p0001" num="0001">Exemplary embodiments of the present invention relate to an object execution mechanism, and to an object execution method and apparatus for executing an object based on an input pressure level with a haptic feedback indicative of an attribute of the object.</p><heading id="h0003">DESCRIPTION OF THE BACKGROUND</heading><p id="p0002" num="0002">Typically, electronic devices (e.g., personal computers and mobile communication terminals) that can execute application programs are provided with at least one input device and a display for a user to search for and execute a task while viewing visual representations of various tasks and objects. With the advancement of technology and change of users' needs, text-based visual representations have been replaced by graphical images and icons.</p><p id="p0003" num="0003">Objects (e.g., files and folders containing multimedia data including text, audio, and still and motion pictures) and icons representing the objects are stored together with attribute information providing details about the creation of the objects. For instance, the attribute information of a file can include creation time, file format, file name, and playback time. The attributes are visually provided to the user when the corresponding file, folder, or icon is selected by the user. Assuming a computing environment in which a specific application is running on a computer with a display of files related to the application, a series of commands input by the user (e.g., placing a<!-- EPO <DP n="2"> --> mouse pointer on the file and then clicking a right button of the mouse) may make the computer display the attribute information (i.e., the file size, file name, and the creation time of the file) of the selected file. If the selected file is executed, the execution command may be input by a behavior commonly adopted for all kinds of files (e.g., clicking the left button of the mouse). In such a conventional file execution method, the user may input the attribute information request command by clicking the right button of the mouse or input the execution command by clicking the left button of the mouse for executing the selected file regardless of the attribute information of the file. That is, the conventional file execution method may be limited to providing the attribute information of a selected file without visual presentation. Furthermore, since all file formats are executed using the same input behavior, the user's recognition of the attributes of the executed file may be limited. There is therefore a need to develop a method for providing the user with the attribute information of a selected object in another sensory modality (e.g., method) rather than the conventional sensory modality, and for executing the selected object with different input behaviors according to the attribute information.</p><p id="p0004" num="0004"><patcit id="pcit0001" dnum="GB2344905A"><text>GB 2,344,905</text></patcit> describes a hand held electronic device with a display on the front and a touch pad on the back. A cursor on the display indicates a position of touch on the touch pad. When the cursor is positioned over an application icon, an increase in pressure from the finger of the operator can be used to select the application.</p><p id="p0005" num="0005"><patcit id="pcit0002" dnum="EP1003188A"><text>EP 1003188</text></patcit> describes an ergonomic computer keyboard. Each key comprises an elastomeric dome for resisting downward movement of a keytop. The collapsible side walls of the domes associated with the little and ring fingers are thinner than the<!-- EPO <DP n="3"> --> side walls of the domes associated with the index and middle fingers so that less force is required to actuate the keys in groups associated with the ring and little fingers.</p><p id="p0006" num="0006"><patcit id="pcit0003" dnum="GB2381499A"><text>GB 2,381,499</text></patcit> describes a method for detecting hard and soft pushes of a manually operated keyboard key. The strength of an input (pushing) signal is compared to a first threshold. If the first threshold is exceeded, after a predetermined time the input signal is compared to a second threshold. If the second threshold is not exceeded, the input is determined to be a soft push, while if the second threshold is exceeded, the input is determined to be a hard push. Hard and soft pushes may be used to supply different types of data (e.g. upper and lower case letters) to an application running on a computer.</p><p id="p0007" num="0007"><patcit id="pcit0004" dnum="US20020140680A"><text>US 2002/0140680</text></patcit> describes a portable electronic device having a touch pad on the back and a display on the front, displaying a keyboard. When the pressure of a user's touch exceeds a first threshold, the touch position is indicated on the display.</p><p id="p0008" num="0008">When the pressure exceeds a second threshold, the key corresponding to the touched position is activated. A slide switch can be used to adjust the first threshold.</p><p id="p0009" num="0009"><patcit id="pcit0005" dnum="WO2007102092A"><text>WO 2007/102092</text></patcit> describes a mobile terminal having a programmable keypad. In one implementation, when a user exerts a pressure greater than a threshold on an area of the keypad corresponding to a key, displacement logic causes a portion of the terminal to vibrate so that the user knows the terminal has registered an input signal associated with the key.</p><p id="p0010" num="0010"><patcit id="pcit0006" dnum="US6243080B"><text>US 6,243,080</text></patcit> describes a touch sensitive panel mounted on an assembly comprising switches that are activated when sufficient pressure is applied to the panel<!-- EPO <DP n="4"> --> to cause it to displace downwards. A 'drag and drop' may be performed by maintaining sufficient pressure on the panel to keep it displaced downwards during the drag.</p><p id="p0011" num="0011"><patcit id="pcit0007" dnum="WO02054213A"><text>WO 02/054213</text></patcit> describes a three state icon for a user interface to prevent inadvertent starting of an operation associated with the icon. When the icon is in a first state, selection of the icon by a user causes the icon to change to a second state. When the icon is in the second state, selection of the icon by the user causes the icon to change to the third state and an operation associated with the icon to start.</p><p id="p0012" num="0012"><patcit id="pcit0008" dnum="US20060132456A"><text>US 2006/0132456</text></patcit> describes a technique in which tap inputs on a user interface cause different functions to execute depending on the pressure applied by the tap. A hard tap is interpreted when a user makes rapid contact with the input surface, exceeding a threshold pressure within a threshold time, possibly without exceeding a threshold distance from the initial point of contact.</p><heading id="h0004">SUMMARY OF THE INVENTION</heading><p id="p0013" num="0013">Exemplary embodiments of the present invention relate to an object execution method and apparatus to execute an object with different input behavior depending on the attribute information of the object.</p><p id="p0014" num="0014">Additional features of the invention will be set forth in the description which follows, and in part will be apparent from the description, or may be learned by practice of the invention.</p><p id="p0015" num="0015">According to the invention an object execution method is provided, comprising: displaying, by an object execution apparatus, two or more objects on a user interface; detecting, by the object execution apparatus, a selection, by a user, of one of the objects on the user interface; determining, by the<!-- EPO <DP n="5"> --></p><p id="p0016" num="0016">apparatus, a reference pressure value associated with the selected object, the reference pressure value being mapped to attribute information of the selected object; determining, by the apparatus, a pressure input by the user to execute the selected object; comparing, by the apparatus, the reference pressure value with an input pressure value corresponding to the input pressure by the user; and executing the selected object, by the apparatus, if the input pressure value is greater than the reference pressure value; characterised in that the two or more objects displayed on the user interface have different reference pressure values.</p><p id="p0017" num="0017">According to the invention an object execution apparatus is provided, comprising: a display unit to display two or more objects on a user interface; an input unit to detect a selection, by a user, of one of the objects on the user interface; a control unit to determine a reference pressure value associated with the selected object, the reference pressure value being mapped to attribute information of the selected object; and a pressure sensing unit to determine a pressure input by the user to execute the selected object; the control unit being adapted to compare the reference pressure value with an input pressure value corresponding to the input pressure by the user, and being further adapted to execute the selected object if the input pressure value is greater than the reference pressure value; characterised in that the two or more objects displayed on the user interface have different reference pressure values.</p><p id="p0018" num="0018">It is to be understood that both the foregoing general description and the following detailed description are exemplary and explanatory and are intended to provide further explanation of the invention as claimed.<!-- EPO <DP n="6"> --></p><heading id="h0005">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p0019" num="0019">The accompanying drawings, which are included to provide a further understanding of the invention and are incorporated in and constitute a part of this<!-- EPO <DP n="7"> --> specification, illustrate exemplary embodiments of the invention, and together with the description serve to explain the principles of the invention.</p><p id="p0020" num="0020"><figref idrefs="f0001">FIG. 1</figref> is an object execution apparatus according to exemplary embodiments of the present invention.</p><p id="p0021" num="0021"><figref idrefs="f0002">FIG. 2</figref> is a diagram illustrating an exemplary case in which an object is executed by interoperation of a host device and an input device according to exemplary embodiments of the present invention.</p><p id="p0022" num="0022"><figref idrefs="f0003">FIG. 3</figref> is a diagram illustrating an exemplary case in which an object is executed by interoperation of a host device and an input device according to exemplary embodiments of the present invention.</p><p id="p0023" num="0023"><figref idrefs="f0004">FIG. 4</figref> is a flowchart illustrating an object execution method according to exemplary embodiments of the present invention.</p><p id="p0024" num="0024"><figref idrefs="f0005">FIG. 5</figref> is an object execution apparatus having an integrated input device according to exemplary embodiments of the present invention.</p><p id="p0025" num="0025"><figref idrefs="f0006">FIG. 6</figref> is a diagram illustrating an exemplary case in which the object execution apparatus executes an object according to exemplary embodiments of the present invention.</p><heading id="h0006">DETAILED DESCRIPTION OF THE ILLUSTRATED EMBODIMENTS</heading><p id="p0026" num="0026">The invention is described more fully hereinafter with reference to the accompanying drawings, in which exemplary embodiments of the invention are shown. This invention may, however, be embodied in many different forms and should not be construed as limited to the exemplary embodiments set forth herein. Rather, these<!-- EPO <DP n="8"> --> exemplary embodiments are provided so that this disclosure is thorough, and will fully convey the scope of the invention to those skilled in the art. In the drawings, the size and relative sizes of layers and regions may be exaggerated for clarity. Like reference numerals in the drawings denote like elements.</p><p id="p0027" num="0027">A procedure for providing the user with representative information (e.g., pressure value information) mapped to the attribute information of objects (e.g., files and folders and/or icons linked to the files and folders) and executing an object in response to an execution command input (e.g., a pressure input) is described herein with reference to accompanying drawings. In order to simplify the explanation, it is assumed that the representative information mapped to the attribute information is pressure value information and that the pressure value information feeds back a vibration to the user.</p><p id="p0028" num="0028">Prior to explaining exemplary embodiments of the present invention, relevant terminology will be defined for the description below.</p><p id="p0029" num="0029">An "object" may refer to data, a function, a file including the data and/or function, and a folder or an icon representing one of the data, the function, the file, or the folder.</p><p id="p0030" num="0030">"Attribute" may refer to metadata that describes or is associated with the object. An attribute can be, for example, a creation time, file format, file name, or priority. An object may have attribute information. The pressure value of the object can be set according to attribute information shared in common by the objects related to a specific application.</p><p id="p0031" num="0031">An object execution apparatus according to exemplary embodiments of<!-- EPO <DP n="9"> --> the present invention can be implemented with an integrated input device or, in some cases, a separate input device. The input device may be used for inputting commands to execute objects. An object execution apparatus is described with reference to <figref idrefs="f0001">FIG. 1</figref>.</p><p id="p0032" num="0032"><figref idrefs="f0001">FIG. 1</figref> is an object execution apparatus according to exemplary embodiments of the present invention.</p><p id="p0033" num="0033">Referring to <figref idrefs="f0001">FIG. 1</figref>, the object execution apparatus may include a host device 100 having applications and executable objects, and an input device 101 for generating commands to select and execute the objects in response to a user's manipulation. The input device 101 may transmit the commands to the host device 100. The host device 100 may include a control unit 110, a display unit 120, and a storage unit 130. The input device 101 may include an input control unit 140, a pressure sensing unit 150, and a vibration generation unit 160. It should be understood that various other function blocks can be further included in the host device 100 and the input device 101 and that the host device 100 and input device 101 are not limited to the components noted above. For example, if the host device 100 and the input device 101 are connected to each other through a radio link, each of the host device 100 and the input device 101 may further include a radio communication unit. The host device 100 and the input device 101 can be a computer and a mouse, respectively, or an Internet Protocol Television (IPTV) and a remote control, respectively. The host device 100 can be a desktop computer, a laptop computer, an IPTV, a mobile terminal, a Smartphone, and, in general, any suitable device that can store and execute the objects.</p><p id="p0034" num="0034">The control unit 110 may control entire operations of the host device 100. The control unit 110 can set attribute-specific pressure values for executing objects<!-- EPO <DP n="10"> --> automatically, or, in some cases, according to user inputs. The control unit 110 may check the pressure value set for an object when an object selection command is received from the input unit 101, and may send a vibration value corresponding to the pressure value to the input device 101. The control unit 110 may also execute the selected object in response to a touch input having a pressure value that is greater than a preset pressure value.</p><p id="p0035" num="0035">The control unit 110 may include an attribute information analyzer 112 and a pressure value converter 114. The attribute information analyzer 112 may refer to the reference pressure value set for the selected object and may determine whether the input pressure value is greater than the reference pressure value. The pressure value converter 114 may determine a reference pressure value corresponding to the pressure value set for the selected object, and may convert the reference pressure value into a vibration value for generating a vibration indicative of the attribute information of the selected object.</p><p id="p0036" num="0036">The display unit 120 may display an operation status of the host device 100, application windows, and a user input status. The application windows may present visual data generated while applications are running in the host device 100. The user input status may be displayed with a pointer. The display unit 120 can be implemented with a Liquid Crystal Display (LCD) panel, or, in general, any suitable display device. The display unit 120 can include an LCD controller, a memory for buffering video data, and LCD devices.</p><p id="p0037" num="0037">The storage unit 130 can include a program memory and a data memory. The program memory may store the application programs running in the host device<!-- EPO <DP n="11"> --> 100. The data memory may buffer the data generated while applications are running, and may store data downloaded from an external device and generated by the applications. The data memory may store the object-specific attribute information, the pressure values corresponding to the attribute information, and the vibration values corresponding to the pressure values.</p><p id="p0038" num="0038">The input control unit 140 controls the operation of the input device 101, sends a signal corresponding to the pressure, which is input by the user through the input sensing unit 150, to the control unit 110 of the host device 100, and controls the generation of the vibration by vibration generation unit 160 based on the vibration value received from the control unit 110. The pressure sensing unit 150 may include a sensor such as, for example, a force sensor for sensing a pressure input by the user. The vibration generator 160 may include an actuator, such as, for example, a vibration motor to generate a feedback (e.g., vibration).</p><p id="p0039" num="0039">The operations of the host device 100 and the input device 101 for executing an object are described hereinafter with reference to <figref idrefs="f0002">FIG. 2</figref> and <figref idrefs="f0003">FIG. 3</figref>.</p><p id="p0040" num="0040"><figref idrefs="f0002">FIG. 2</figref> is a diagram illustrating an exemplary case in which an object is executed by interoperation of a host device and an input device according to exemplary embodiments of the present invention. As shown in <figref idrefs="f0002">FIG. 2</figref>, an application screen 201 may display a plurality of objects provided by means of the display unit 120. A mouse 202 may correspond to the input device 101 of <figref idrefs="f0001">FIG. 1</figref>.</p><p id="p0041" num="0041">Referring to <figref idrefs="f0002">FIG. 2</figref>, a plurality of objects 211, 212, 213, 214, and 215 are displayed in an "explorer" application screen 201. Object 211 may be a movie folder (or movie folder icon) containing movie files prioritized with a low priority. Object 211 may<!-- EPO <DP n="12"> --> be mapped to a pressure value 221 of '1' designated for indicating a low priority level of the attribute information. Pressure values 221, 222, 223, 224, and 225 corresponding to objects 211, 212, 213, 214, and 215, respectively, are displayed in <figref idrefs="f0002">FIG. 2</figref> to help explain exemplary embodiments of the present invention, but may not be displayed in the application screen 201. Object 212 may be a music folder (or music folder icon) containing music files prioritized with a low priority. Object 212 may be mapped to a low pressure value 222 of '1.' In the exemplary application screen 201, a mouse pointer 230 may be located at the music folder 212. The user can navigate the pointer 230 and select an object (e.g., music folder 212) in the application screen 201 by manipulating the mouse 202. The selected object can be displayed differently from other objects. For instance, when the music folder 212 is selected, the music folder 212 may float above the other unselected objects 211, 213, 214, and 215.</p><p id="p0042" num="0042">Object 213 may be a finance folder (or finance folder icon) containing financial data and/or files prioritized with a high priority. Object 213 may be mapped to a high pressure value 223 of '3.' Object 214 may be a schedule folder (or schedule folder icon) containing schedule data and/or files prioritized with an intermediate priority. Object 214 may be mapped to a pressure value 224 of '2.' Object 215 may be a travel folder (or travel folder icon) containing travel-related data and/or files prioritized with a low priority. Object 215 may be mapped to a pressure value 225 of '1.' The objects displayed in the "explorer" application screen 201 may have attribute information including creation time, file format, file size, content, and priority. Although objects may be classified by priority among the attributes, and the priority levels may be mapped to corresponding pressure values as described above, the objects can be classified by<!-- EPO <DP n="13"> --> various other attributes having levels mapped to the pressure values. For instance, when the object is a multimedia folder, multimedia data contained in the multimedia folder can be classified by playback time or file size. The values of playback time or file size can be mapped to corresponding pressure values. In addition, although three priority levels (i.e., low, intermediate, and high priority levels) have been described and mapped to the respective pressure values 1, 2, and 3, the priority levels can be assigned in a various ways. For example, in some cases, five or six priority levels may be used and assigned to respective pressure values. In general, any suitable number of priority levels and respective pressure values may be used. Mapping the priority levels to the pressure values assignment can be carried out automatically, or, in some cases, manually according to the user configuration.</p><p id="p0043" num="0043">As shown in <figref idrefs="f0002">FIG. 2</figref>, when the music folder 212 is selected by placing the pointer 230 on the music folder 212, the control unit 110 (more specifically, the attribute information analyzer 112 of the control unit 110) may check the pressure value designated for the music folder 212. After the attribute information analyzer 112 checks the reference pressure value, the pressure value converter 114 may convert the pressure value '1' into a 'weak vibration' value. The converted 'weak vibration' value may be sent to the input control unit 140 of the input device 101. In response to the receipt of the 'weak vibration' value, the input control unit 140 may instruct the vibration generation unit 160 to generate a weak vibration (e.g., the mouse is vibrated weakly). As noted above, vibration may be generated in three levels (e.g., weak, intermediate, and strong) to indicate the values of the attribute information. The vibration levels may be expressed in a different manner depending on the vibration motor of the input device<!-- EPO <DP n="14"> --> 101 (e.g., mouse). For instance, the weak, intermediate, and strong vibrations can be defined by respective voltages (e.g., 0.5V, 1V, and 2V) applied for a predetermined duration, for example, 0.1 second, 1 second, and 3 seconds at an identical voltage level. The weak, intermediate, and strong vibrations may thus also be defined by the duration of the vibration time. Using such haptic feedbacks based on the vibration levels, the user can acquire attribute information of the selected object.</p><p id="p0044" num="0044">In the application screen 201 of <figref idrefs="f0002">FIG. 2</figref>, the movie folder 211, music folder 212, and travel folder 215 have the pressure value '1' which is low compared to the pressure values '3' and '2' of the finance folder 213 and schedule folder 214, respectively. Accordingly, objects assigned the pressure value 1 can be executed in response to a low pressure input, but the object(s) assigned the pressure value 3 may require a relatively high pressure input to be executed. The pressure values corresponding to the pressure levels may be preset by means of the force sensor in the pressure sensing unit 150. If input commands are determined based on the pressure input duration, the target object may be executed in response to maintaining a predetermined level of pressure for a predetermined period of time. For instance, when the user attempts to move the files contained in the schedule folder 214 to the travel folder 215 with a "drag and drop" behavior, a pressure level greater than the pressure value of the schedule folder 214 must be maintained during the drag and drop process in order to successfully moves the files. If the pressure level becomes lower than the pressure value of the schedule folder 214, the file transfer from the schedule folder 214 to the travel folder 215 may be canceled.</p><p id="p0045" num="0045"><figref idrefs="f0003">FIG. 3</figref> is a diagram illustrating an exemplary case in which an object is<!-- EPO <DP n="15"> --> executed by interoperation of a host device and an input device according to exemplary embodiments of the present invention.</p><p id="p0046" num="0046">When the music folder 212 is selected, a music menu screen 301 having menu items such as, for example, 'American Pop' and 'Korean Pop' may be displayed. If the user navigates the pointer onto the 'Korean Pop' item and inputs a delete command by means of the input device 302 while the pointer is placed on the 'Korean Pop' item, the control unit 110 may instruct the display unit 120 to display a popup dialog window 310 having 'yes' and 'no' buttons 311 and 312 and a confirmation request message. In the popup dialog window 310, the object 'yes' button 311 may have a higher priority than that of the object 'no' button 312 and, as a consequence, the 'yes' button 311 may be assigned a pressure value of 3 and the 'no' button 312 may be assigned a pressure value of 1. To execute the object assigned the pressure value 3 (e.g., 'yes' button), a pressure level greater than the pressure level required for executing the object assigned the pressure value of 1 (e.g., 'no' button) must be applied onto the mouse 302. The mouse 302 can be configured such that, when the pointer is placed on the object (e.g., 'yes' button 311 or 'no' button 312), a vibration corresponding to the pressure value of the object may be generated to provide feed back of the attribute information to the user. For example, the mouse 302 may be vibrated based on the determined pressure value. If a pressure level greater than the pressure value of the selected object is input by means of the mouse 302, the control unit 110 may execute the object. The pressure levels may be set in consideration of the force sensor of the mouse 302.</p><p id="p0047" num="0047">An object execution method for providing attribute information using a<!-- EPO <DP n="16"> --> vibration, and for executing objects in response to a pressure level satisfying the pressure value indicated by the attribute information, is described hereinafter with reference to <figref idrefs="f0004">FIG. 4</figref>.</p><p id="p0048" num="0048"><figref idrefs="f0004">FIG. 4</figref> is a flowchart illustrating an object execution method according to exemplary embodiments of the present invention.</p><p id="p0049" num="0049">Referring to <figref idrefs="f0004">FIG. 4</figref>, the control unit 110 of the host device 100 of <figref idrefs="f0001">FIG. 1</figref> may execute a specific application and may display a corresponding application screen 201 having a plurality of objects on the display unit 120 (405). The application may be executed in response to a user command input by means of the input device 101. Next, the control unit 110 may monitor input of a user command by means of the input device 101 to select an object. For example, the control unit 110 may determine whether the pointer is placed on an object (410). If the pointer is placed on an object, the control unit 110 may check the reference pressure value assigned to the selected object (415). If no object is selected, the control unit 110 may return to and proceed with step 405.</p><p id="p0050" num="0050">After checking the reference pressure value assigned to the selected object at step 415, the control unit 110 may determine whether a pressure level is input by means of the input device 101 (420). The pressure sensing unit 150 senses a pressure input by the user and the control unit 110 compares the reference pressure value with an input pressure value corresponding to the pressure level input for executing the selected object. If the input pressure value corresponding to the pressure level input is greater than the reference pressure value, control unit 110 may consider that the pressure level is input, and otherwise, control unit 110 may consider that the pressure level is not input. If a pressure level is input by means of the input device 101,<!-- EPO <DP n="17"> --> the control unit 110 may proceed to step 440. If the pressure level is not input, the control unit 110 may proceed to step 425. At step 425, the pressure value converter 114 of the control unit 110 may convert the reference pressure value of the selected object into a corresponding vibration value (425) and may send the vibration value to the input device 101 such that the input device 101 may generate a vibration corresponding to the vibration value (430). Next, the control unit 110 may determine whether a navigation command for navigating the pointer is input by means of the input device 101 (435). If a navigation command is input, the control unit 110 may move the pointer according to the navigation command and the control unit 110 may return to and proceed with step 410. If a navigation command is not input, the object execution method may be terminated.</p><p id="p0051" num="0051">Returning to step 420, if a pressure level is input by means of the input device 101, the control unit 110 may check the input pressure value (440). The input pressure value may be calculated on the basis of the pressure level received from input device 101 by means of the pressure value converter 114. Next, the attribute information analyzer 112 may determine whether the input pressure value is equal to or greater than the reference pressure value of the selected object (445). If the input pressure value is equal to or greater than the reference pressure value of the selected object, the control unit 110 may execute the selected object (450). If the host device 100 is configured to execute a specific function in response to a duration-based command (e.g., a drag and drop command) requiring maintenance of a predetermined level of pressure for a predetermined period of time, the control unit 110 can further determine whether the pressure level is maintained for the predetermined duration. If<!-- EPO <DP n="18"> --> the input pressure value is less than the reference pressure value of the selected object at step 445, the process may continue with step 435.</p><p id="p0052" num="0052">An object execution apparatus implemented with an integrated input device according to exemplary embodiments of the present invention is described with reference to <figref idrefs="f0005">FIG. 5</figref>.</p><p id="p0053" num="0053"><figref idrefs="f0005">FIG. 5</figref> is an object execution apparatus having an integrated input device according to exemplary embodiments of the present invention.</p><p id="p0054" num="0054">Referring to <figref idrefs="f0005">FIG. 5</figref>, an object execution device 500 may include a touch screen 510, a control unit 520, a vibration generation unit 530, and a storage unit 540. The touchscreen 510 may include a display unit 512 and an input unit 514. The touchscreen 510 may integrate the display and input functionalities, and may generate an input signal in response to a touch on the display screen. The touchscreen 510 can detect at least one touch event occurring on the display unit 512. The display unit 512 may display an operation status of the object execution apparatus 500 and visual data generated while applications are running in the object execution device 500. The display unit 512 can be implemented with an LCD, or, in general, any suitable display device. In some cases, the display unit 512 can be provided with an LCD controller, a video memory for buffering video data, and/or LCD devices. The input unit 514 can be implemented on the display unit 512 to generate an input signal in response to the touch event on the display unit 512. The input unit 514 can include a touch sensor (not shown) and/or a signal converter (not shown). The touch sensor can sense a touch event by detecting the change of a physical quantity (e.g., resistance or capacitance). The signal converter may convert the detected change of physical quantity into a digital<!-- EPO <DP n="19"> --> signal. The signal converter may determine whether the touch sensed by the change of physical quantity is a tap event or drag event, and may calculate the coordinates of the point at which the touch event is detected. The input unit 514 may also output the pressure level input by means of the pressure sensor 516 to the control unit 520. The pressure sensor 516 can be implemented with a sensor, such as, for example, a force sensor for detecting a pressure level input by the user.</p><p id="p0055" num="0055">The control unit 520 may control entire operations of the object execution apparatus. The control unit 520 can set the attribute-specific pressure values for executing objects automatically or according to user inputs. The controller 520 may check the reference pressure value set for the object when an object selection command is input, and may send a vibration value corresponding to the reference pressure value to the vibration generation unit 530. The control unit 520 may include an attribute information analyzer 522 and a pressure value converter 524. The attribute information analyzer 522 may refer to the reference pressure value set for the selected object and may check whether the input pressure value is greater than the reference pressure value. If the input pressure value is greater than the reference pressure value, the pressure value converter 524 may determine a reference pressure value corresponding to the input pressure value and may convert the reference pressure value into a vibration value for generating a vibration indicative of the attribute information of the selected object.</p><p id="p0056" num="0056">The vibration generator 530 can be implemented with a vibration motor, such as, for example, an actuator, and can generate a vibration corresponding to the vibration value under the control of the control unit 520. The storage unit 540 can<!-- EPO <DP n="20"> --> include a program memory and a data memory. The program memory may store the application programs running in the object execution apparatus. The data memory may buffer the data generated while the applications are running, and may store data downloaded from an external device and data generated by the application programs running in the object execution apparatus. The data memory may store the object-specific attribute information, the pressure values assigned to the attribute information, and the vibration values corresponding to the pressure values.</p><p id="p0057" num="0057">Although the object execution apparatus 500 may include essential function blocks required for executing an object in <figref idrefs="f0005">FIG. 5</figref>, the object execution apparatus 500 may also include other function blocks. For example, the object execution apparatus 500 can be a communication terminal, a Personal Data Assistant (PDA), a Smartphone, and any other suitable device having an integrated input unit.</p><p id="p0058" num="0058"><figref idrefs="f0006">FIG. 6</figref> is a diagram illustrating an exemplary case in which the object execution apparatus executes an object according to exemplary embodiments of the present invention. In <figref idrefs="f0006">FIG. 6</figref>, an application screen 601 may display a plurality of objects. The application screen 601 may be provided by means of the display unit 512 of the object execution apparatus 500.</p><p id="p0059" num="0059">Referring to <figref idrefs="f0006">FIG. 6</figref>, a plurality of objects 611, 612, and 613 may be displayed in an "explorer" application screen 601. Object 611 may be a movie folder (or movie folder icon) containing movie files prioritized with a low priority. The object 611 may be mapped to a pressure value 621 of '1' designated for indicating a low priority level of the attribute information. It should be understood that although objects 611, 612, and 613 are displayed in <figref idrefs="f0006">FIG. 6</figref> together with corresponding pressure values 621,<!-- EPO <DP n="21"> --> 622, and 623, respectively, to help explain exemplary embodiments of the present invention, the pressure values 621, 622, and 623 may not be displayed on the application screen 601. Object 612 may be a music folder (or music folder icon) containing music files prioritized with a low priority. The object 612 may be mapped to a low pressure value 622 of '1.' In some cases, the user's finger may touch a part of the music folder 622 to select the music folder 622. Accordingly, an object displayed on the display unit 512 can be selected by touching a position at which the object is placed. The selected object can be displayed differently from other objects. For instance, when the music folder 612 is selected, the music folder 612 may float above other unselected objects 611 and 613. Object 613 may be a finance folder (or finance folder icon) containing financial data and/or files prioritized with a high priority. The object 613 may be mapped to a high pressure value 623 of '3.' The objects displayed with the "explorer" application have attribute information, which includes, for example, creation time, file format, file size, content, and/or priority. Although the objects may be classified by priority among the attributes, and the priority levels may be mapped to corresponding pressure values as described above, the objects can be classified by various other attributes having levels mapped to the pressure values. For instance, when the object is a multimedia folder, the multimedia data contained in the multimedia folder can be classified by playback time or file size of which values are mapped to corresponding pressure values. In addition, although three priority levels (e.g., low, intermediate, and high priority levels) have been described and mapped to the respective pressure values 1, 2, and 3, the priority levels can be assigned in various ways. For example, in some cases, five or six priority levels may be used and<!-- EPO <DP n="22"> --> assigned to respective pressure values. In general, any suitable number of priority levels and respective pressure values may be used. Mapping the priority levels to the pressure values assignment can be carried out automatically or manually according to the user configuration.</p><p id="p0060" num="0060">As shown in <figref idrefs="f0006">FIG. 6</figref>, when the music folder 612 is selected by touching the position at which the music folder 612 is placed on the touchscreen 510, the control unit 520 (more specifically, the attribute information analyzer 522) may check the reference pressure value (= 1) designated for the music folder 612. After the attribute information analyzer 522 checks the reference pressure value, the pressure value converter 524 may convert the pressure value '1' designated for the attribute of the music folder into a 'weak vibration' value. The converted 'weak vibration' value may be sent to the vibration generator 530. In response to the 'weak vibration' value, the vibration generation unit 530 may generate a weak vibration. A vibration may be generated in three different levels (e.g., weak, intermediate, and strong) corresponding to the values of the attribute information, and the vibration levels may be expressed in different manners depending on the vibration motor. For instance, the weak, intermediate, and strong vibrations can be defined by respective voltages of 0.5V, 1V, and 2V, respectively, and may be applied for a predetermined period of time (e.g., 0.1 second, 1 second, and 3 seconds) at an identical voltage level. In some cases, the weak, intermediate, and strong vibrations may be defined by the duration of the vibration time. Using such haptic feedback based on the vibration levels, the user can acquire the attribute information of the selected object.</p><p id="p0061" num="0061">In the application screen 601 of <figref idrefs="f0006">FIG. 6</figref>, the movie folder 611 and the<!-- EPO <DP n="23"> --> music folder 612 may be assigned the pressure value '1' which is low compared to the pressure value '3' of the finance folder 613. Accordingly, the objects assigned the pressure value 1 can be executed in response to a low pressure input, and the objects assigned the pressure value 3 may require a relatively high pressure input to be executed. The pressure values corresponding to the pressure levels may be preset by means of the force sensor of the pressure sensor 516. The pressure level input by the user can be measured by the pressure sensor of the input unit 514. If input commands are determined based on the pressure input duration, the target object may be executed in response to maintenance of a predetermined level of pressure for a predetermined period of time. Since the object execution operations for the object execution apparatus of <figref idrefs="f0006">FIG. 6</figref> are identical to those of <figref idrefs="f0004">FIG. 4</figref>, detailed description of the object execution method for the apparatus <figref idrefs="f0006">FIG. 6</figref> may be omitted.</p><p id="p0062" num="0062">As described above, exemplary embodiments of the present invention disclose an object execution method and apparatus to provide a user of the apparatus with an intuitive and efficient user interface using haptic and visual feedback. The object execution method and apparatus described herein may also enable the user to check the attribute information of a selected object with distinct haptic feedback without viewing the screen. The object execution method and apparatus may also provide an input/output interface operating in a novel haptic modality in which information is output in distinctive haptic feedbacks and input in distinctive physical quantities (e.g., pressure levels), thereby improving user satisfaction. Since a command input for executing an object is determined on the basis of the pressure level specific to the object, the object execution method and apparatus of the present invention may reduce the probability of<!-- EPO <DP n="24"> --> faulty execution of an object.</p></description><claims mxw-id="PCLM56984741" lang="DE" load-source="patent-office"><!-- EPO <DP n="29"> --><claim id="c-de-01-0001" num="0001"><claim-text>Objektausführungsverfahren, das Folgendes beinhaltet:
<claim-text>Anzeigen (405), durch eine Objektausführungsvorrichtung (100, 101; 500), von zwei oder mehr Objekten (211-215; 311-312; 611-613) auf einer Benutzeroberfläche (201; 301; 601);</claim-text>
<claim-text>Erkennen (410), durch die Objektausführungsvorrichtung (100, 101; 500), einer Auswahl, durch einen Benutzer, von einem der Objekte (212; 612) auf der Benutzeroberfläche (201; 301; 601);</claim-text>
<claim-text>Ermitteln (415), durch die Vorrichtung (100, 101; 500), eines Referenzdruckwertes in Verbindung mit dem gewählten Objekt (212; 612), wobei der Referenzdruckwert auf Attributinformationen des gewählten Objekts (212; 311; 612) abgebildet wird;</claim-text>
<claim-text>Ermitteln (440), durch die Vorrichtung (100, 101; 500), eines vom Benutzer eingegebenen Drucks zum Ausführen des gewählten Objekts (212; 612);</claim-text>
<claim-text>Vergleichen (445), durch die Vorrichtung (100, 101; 500), des Referenzdruckwertes mit einem Eingangsdruckwert, der dem vom Benutzer eingegebenen Druck entspricht; und</claim-text>
<claim-text>Ausführen (450) des gewählten Objekts (212; 612), durch die Vorrichtung (100, 101; 500), wenn der eingegebene Druckwert größer ist als der Referenzdruckwert;</claim-text>
<claim-text><b>dadurch gekennzeichnet, dass</b> die auf der Benutzeroberfläche (201; 301; 601) angezeigten zwei oder mehr Objekte (211-215; 311-312; 611-613) unterschiedliche Referenzdruckwerte haben.</claim-text></claim-text></claim><claim id="c-de-01-0002" num="0002"><claim-text>Verfahren nach Anspruch 1, wobei die Attributinformationen wenigstens eines aus Größe des gewählten Objekts (211-215; 311-312; 611-613), Priorität des Objekts (211-215; 311-312; 611-613), Anzahl von in dem Objekt (211-215; 311-312; 611-613) enthaltenen Dateien, Erzeugungszeit des Objekts (211-215; 311-312; 611-613), Wiedergabezeit des Objekts (211-215; 311-312; 611-613), Dateigröße des Objekts (211-215; 311-312; 611-613), Dateiformat des Objekts (211-215; 311-312; 611-613) und Dateinamen des Objekts (211-215; 311-312; 611-613) umfasst.<!-- EPO <DP n="30"> --></claim-text></claim><claim id="c-de-01-0003" num="0003"><claim-text>Objektausführungsvorrichtung (100, 101; 500), die Folgendes umfasst:
<claim-text>eine Anzeigeeinheit (120; 512) zum Anzeigen (405) von zwei oder mehr Objekten (211-215; 311-312; 611-613) auf einer Benutzeroberfläche (201; 301; 601);</claim-text>
<claim-text>eine Eingabeeinheit (101; 514) zum Erkennen (410) einer Auswahl, durch einen Benutzer, von einem der Objekte (212; 612) auf der Benutzeroberfläche (201; 301; 601);</claim-text>
<claim-text>eine Steuereinheit (110; 520) zum Ermitteln (415) eines Referenzdruckwertes in Verbindung mit dem gewählten Objekt (212; 612), wobei der Referenzdruckwert auf Attributinformationen des gewählten Objekts (212; 612) abgebildet wird; und</claim-text>
<claim-text>eine Druckerfassungseinheit (150; 516) zum Ermitteln (440) eines vom Benutzer eingegebenen Drucks zum Ausführen des gewählten Objekts (212; 612);</claim-text>
<claim-text>wobei die Steuereinheit (110; 520) zum Vergleichen (445) des Referenzdruckwertes mit einem eingegebenen Druckwert, der dem vom Benutzer eingegebenen Druck entspricht, und ferner zum Ausführen (450) des gewählten Objekts (212; 612) ausgelegt ist, wenn der eingegebene Druckwert größer ist als der Referenzdruckwert;</claim-text>
<claim-text><b>dadurch gekennzeichnet, dass</b> die auf der Benutzeroberfläche (201; 301; 601) angezeigten zwei oder mehr Objekte (211 -215; 311 -312; 611 -613) unterschiedliche Referenzdruckwerte haben.</claim-text></claim-text></claim><claim id="c-de-01-0004" num="0004"><claim-text>Vorrichtung nach Anspruch 3, wobei die Attributinformationen wenigstens eines aus Größe des Objekts (211-215; 311-312; 611-613), Priorität des Objekts (211-215; 311-312; 611-613), Anzahl von in dem Objekt (211-215;311-312; 611-613) enthaltenen Dateien, Erzeugungszeit des Objekts (211-215; 311-312; 611-613), Wiedergabezeit des Objekts (211-215; 311-312; 611-613), Dateigröße des Objekts (211-215; 311-312; 611-613), Dateiformat des Objekts (211-215; 311-312; 611-613) und Dateinamen des Objekts (211-215; 311-312; 611-613) umfasst.</claim-text></claim><claim id="c-de-01-0005" num="0005"><claim-text>Vorrichtung nach Anspruch 3, wobei die Objektausführungsvorrichtung ein Host-Gerät (100) umfasst, das die Anzeigeeinheit (120) und die Steuereinheit (110) umfasst.<!-- EPO <DP n="31"> --></claim-text></claim><claim id="c-de-01-0006" num="0006"><claim-text>Vorrichtung nach Anspruch 5, wobei das Host-Gerät (100) eines aus Fernsehen, Computer und mobilem Endgerät umfasst, das bidirektionale Kommunikationen unterstützt, und wobei die Eingabeeinheit (101) eine Maus (202; 302) oder eine Fernbedienung umfasst.</claim-text></claim><claim id="c-de-01-0007" num="0007"><claim-text>Vorrichtung nach Anspruch 3, wobei die Anzeigeeinheit (512), die Steuereinheit (520) und die Eingabeeinheit (514) in ein Endgerät (500) mit einem Touchscreen (510) integriert sind.</claim-text></claim><claim id="c-de-01-0008" num="0008"><claim-text>Vorrichtung nach Anspruch 3, wobei die Steuereinheit (110; 520) zum Überwachen von Eingaben eines Benutzerbefehls durch die Eingabeeinheit (101; 514) ausgelegt ist, um zu ermitteln (410), ob ein Zeiger (230) auf einem der zwei oder mehr Objekte (211-215; 311-312; 611-613) steht, die in der Anzeigeeinheit (120; 512) angezeigt werden, und um zu ermitteln, ob das Objekt (212; 612) auf dem der Zeiger (230) steht, gewählt ist.</claim-text></claim><claim id="c-de-01-0009" num="0009"><claim-text>Vorrichtung nach Anspruch 3, die ferner eine Speichereinheit (130; 540) zum Speichern der Attributinformationen der zwei oder mehr Objekte (211-215; 311-312; 611-613), der auf die Attributinformationen abgebildeten Referenzdruckwerte und der Referenzdruckwerten entsprechenden Vibrationswerte umfasst.</claim-text></claim></claims><claims mxw-id="PCLM56984742" lang="EN" load-source="patent-office"><!-- EPO <DP n="25"> --><claim id="c-en-01-0001" num="0001"><claim-text>An object execution method, comprising:
<claim-text>displaying (405), by an object execution apparatus (100,101; 500), two or more objects (211-215; 311-312; 611-613) on a user interface (201; 301; 601);</claim-text>
<claim-text>detecting (410), by the object execution apparatus (100, 101; 500), a selection,<br/>
by a user, of one of the objects (212; 612) on the user interface (201; 301; 601);</claim-text>
<claim-text>determining (415), by the apparatus (100, 101; 500), a reference pressure value associated with the selected object (212; 612), the reference pressure value being mapped to attribute information of the selected object (212; 311; 612);</claim-text>
<claim-text>determining (440), by the apparatus (100, 101; 500), a pressure input by the user to execute the selected object (212; 612);</claim-text>
<claim-text>comparing (445), by the apparatus (100, 101; 500), the reference pressure value with an input pressure value corresponding to the input pressure by the user; and</claim-text>
<claim-text>executing (450) the selected object (212; 612), by the apparatus (100, 101; 500), if the input pressure value is greater than the reference pressure value;</claim-text>
<claim-text><b>characterised in that</b> the two or more objects (211-215; 311-312; 611-613) displayed on the user interface (201; 301; 601) have different reference pressure values.</claim-text></claim-text></claim><claim id="c-en-01-0002" num="0002"><claim-text>The method of claim 1, wherein the attribute information comprises at least one of a size of the selected object (211-215; 311-312; 611-613), a priority of the object (211-215; 311-312; 611-613), a number of files contained in the object (211-215; 311-312; 611-613) a creation time of the object (211-215; 311-312; 611-613), a playback time of the<!-- EPO <DP n="26"> --> object (211-215; 311-312; 611-613), a file size of the object (211-215; 311-312; 611-613), a file format of the object (211-215; 311-312; 611-613), and a file name of the object (211-215; 311-312; 611-613).</claim-text></claim><claim id="c-en-01-0003" num="0003"><claim-text>An object execution apparatus (100, 101; 500), comprising:
<claim-text>a display unit (120; 512) to display (405) two or more objects (211-215; 311-312; 611-613) on a user interface (201; 301; 601);</claim-text>
<claim-text>an input unit (101; 514) to detect (410) a selection, by a user, of one of the objects (212; 612) on the user interface (201; 301; 601);</claim-text>
<claim-text>a control unit (110; 520) to determine (415) a reference pressure value associated with the selected object (212; 612), the reference pressure value being mapped to attribute information of the selected object (212; 612); and</claim-text>
<claim-text>a pressure sensing unit (150; 516) to determine (440) a pressure input by the user to execute the selected object (212; 612);</claim-text>
<claim-text>the control unit (110; 520) being adapted to compare (445) the reference pressure value with an input pressure value corresponding to the input pressure by the user, and<br/>
being further adapted to execute (450) the selected object (212; 612) if the input pressure value is greater than the reference pressure value;</claim-text>
<claim-text><b>characterised in that</b> the two or more objects (211-215; 311-312; 611-613) displayed on the user interface (201; 301; 601) have different reference pressure values.</claim-text><!-- EPO <DP n="27"> --></claim-text></claim><claim id="c-en-01-0004" num="0004"><claim-text>The apparatus of claim 3, wherein the attribute information comprises at least one of a size of the object (211-215; 311-312; 611-613), a priority of the object (211-215; 311-312; 611-613), a number of files contained in the object (211-215; 311-312; 611-613), a creation time of the object (211-215; 311-312; 611-613), a playback time of the object (211-215; 311-312; 611-613), a file size of the object (211-215; 311-312; 611-613), a file format of the object (211-215; 311-312; 611-613), and a file name of the object (211-215; 311-312; 611-613).</claim-text></claim><claim id="c-en-01-0005" num="0005"><claim-text>The apparatus of claim 3, wherein the object execution apparatus comprises a host device (100) comprising the display unit (120) and the control unit (110).</claim-text></claim><claim id="c-en-01-0006" num="0006"><claim-text>The apparatus of claim 5, wherein the host device (100) comprises one of a television, a computer, and a mobile terminal supporting bidirectional communication, and wherein the input unit (101) comprises one of a mouse (202; 302) and a remote control.</claim-text></claim><claim id="c-en-01-0007" num="0007"><claim-text>The apparatus of claim 3, wherein the display unit (512), the control unit (520), and the input unit (514) are integrated into a terminal (500) having a touchscreen (510).</claim-text></claim><claim id="c-en-01-0008" num="0008"><claim-text>The apparatus of claim 3, wherein the control unit (110; 520) is adapted to monitor input of a user command through the input unit (101; 514), to determine (410) if a pointer (230) is placed on one of the two or more objects (211-215; 311-312; 611-613)<!-- EPO <DP n="28"> --> displayed in the display unit (120; 512), and to determine that the object (212; 612) on which the pointer (230) is placed is selected.</claim-text></claim><claim id="c-en-01-0009" num="0009"><claim-text>The apparatus of claim 3, further comprises a storage unit (130; 540) to store<br/>
the attribute information of the two or more objects (211-215; 311-312; 611-613), the reference pressure values mapped to the attribute information and vibration values corresponding to the reference pressure values.</claim-text></claim></claims><claims mxw-id="PCLM56984743" lang="FR" load-source="patent-office"><!-- EPO <DP n="32"> --><claim id="c-fr-01-0001" num="0001"><claim-text>Procédé d'exécution d'objets, comprenant les opérations consistant à :
<claim-text>faire afficher (405), par un appareil d'exécution d'objets (100, 101 ; 500), deux ou plusieurs objets (211-215 ; 311-312 ; 611-613) sur une interface Utilisateur (201 ; 301 ; 601) ;</claim-text>
<claim-text>faire détecter (410), par l'appareil d'exécution d'objets (100, 101 ; 500), une sélection, faite par un utilisateur, de l'un des objets (212 ; 612) sur l'interface Utilisateur (201 ; 301 ; 601) ;</claim-text>
<claim-text>faire déterminer (415), par l'appareil (100, 101 ; 500), une valeur de pression de référence associée à l'objet sélectionné (212 ; 612), la valeur de pression de référence étant mappée à des informations d'attributs de l'objet sélectionné (212 ; 311 ; 612) ;</claim-text>
<claim-text>faire déterminer (440), par l'appareil (100, 101 ; 500), une pression introduite par l'utilisateur afin d'exécuter l'objet sélectionné (212 ; 612) ;</claim-text>
<claim-text>faire comparer (445), par l'appareil (100, 101 ; 500), la valeur de pression de référence avec une valeur de pression de saisie correspondant à la pression introduite par l'utilisateur ; et</claim-text>
<claim-text>faire exécuter (450) l'objet sélectionné (212 ; 612), par l'appareil (100, 101 ; 500), si la valeur de pression de saisie est plus grande que la valeur de pression de référence ;</claim-text>
<claim-text><b>caractérisé en ce que</b> les deux ou plusieurs objets (211-215 ; 311-312; 611-613) affichés sur l'interface Utilisateur (201 ; 301 ; 601) ont différentes valeurs de pression de référence.</claim-text></claim-text></claim><claim id="c-fr-01-0002" num="0002"><claim-text>Procédé selon la revendication 1, les informations d'attributs comprenant au moins l'un des éléments suivants, à savoir une taille de l'objet sélectionné (211-215 ; 311-312; 611-613), une priorité de l'objet (211-215; 311-312 ; 611-613), un nombre de fichiers contenus dans l'objet (211-215; 311-312; 611-613), un horaire de création de l'objet (211-215 ; 311-312; 611-613), un horaire de reproduction de l'objet (211-215 ; 311-312 ; 611-613), une taille de fichier de l'objet (211-215 ; 311-312<!-- EPO <DP n="33"> --> ; 611-613), un format de fichier de l'objet (211-215 ; 311-312 ; 611-613), et un nom de fichier de l'objet (211-215 ; 311-312 ; 611-613).</claim-text></claim><claim id="c-fr-01-0003" num="0003"><claim-text>Appareil d'exécution d'objets (100, 101 ; 500) comprenant :
<claim-text>une unité d'affichage (120 ; 512) pour afficher (405) deux ou plusieurs objets (211-215 ; 311-312 ; 611-613) sur une interface Utilisateur (201 ; 301 ; 601) ;</claim-text>
<claim-text>une unité de saisie (101 ; 514) pour détecter (410) une sélection, faite par un utilisateur, de l'un des objets (212 ; 612) sur l'interface Utilisateur (201 ; 301 ; 601) ;</claim-text>
<claim-text>une unité de commande (110 ; 520) pour déterminer (415) une valeur de pression de référence associée à l'objet sélectionné (212 ; 612), la valeur de pression de référence étant mappée vers des informations d'attributs de l'objet sélectionné (212 ; 612) ; et</claim-text>
<claim-text>une unité de captage de pression (150 ; 516) pour déterminer (440) une pression introduite par l'utilisateur afin d'exécuter l'objet sélectionné (212 ; 612) ;</claim-text>
<claim-text>l'unité de commande (110 ; 520) étant conçue pour comparer (445) la valeur de pression de référence avec une valeur de pression de saisie correspondant à la pression introduite par l'utilisateur, et étant conçue en outre pour exécuter (450) l'objet sélectionné (212 ; 612) si la valeur de pression de saisie est plus grande que la valeur de pression de référence ;</claim-text>
<claim-text><b>caractérisé en ce que</b> les deux ou plusieurs objets (211-215 ; 311-312; 611-613) affichés sur l'interface Utilisateur (201 ; 301 ; 601) ont différentes valeurs de pression de référence.</claim-text></claim-text></claim><claim id="c-fr-01-0004" num="0004"><claim-text>Appareil selon la revendication 3, les informations d'attributs comprenant au moins l'un des éléments suivants, à savoir une taille de l'objet (211-215 ; 311-312 ; 611-613), une priorité de l'objet (211-215; 311-312; 611-613), un nombre de fichiers contenus dans l'objet (211-215 ; 311-312 ; 611-613), un horaire de création de l'objet (211-215 ; 311-312 ; 611-613), un horaire de reproduction de l'objet (211-215 ; 311-312 ; 611-613), une taille de fichier de l'objet (211-215 ; 311-312 ; 611-613), un format de fichier de l'objet (211-215 ; 311-312 ; 611-613), et un nom de fichier de l'objet (211-215 ; 311-312 ; 611-613).<!-- EPO <DP n="34"> --></claim-text></claim><claim id="c-fr-01-0005" num="0005"><claim-text>Appareil selon la revendication 3, l'appareil d'exécution d'objets comprenant un dispositif hôte (100) comportant l'unité d'affichage (120) et l'unité de commande (110).</claim-text></claim><claim id="c-fr-01-0006" num="0006"><claim-text>Appareil selon la revendication 5, le dispositif hôte (100) comprenant l'un des postes suivants, à savoir un téléviseur, un ordinateur, et un terminal mobile prenant en charge des communications bidirectionnelles, et cas dans lequel l'unité de saisie (101) comporte l'un des postes suivants, à savoir une souris (202 ; 302) et une télécommande.</claim-text></claim><claim id="c-fr-01-0007" num="0007"><claim-text>Appareil selon la revendication 3, l'unité d'affichage (512), l'unité de commande (520), et l'unité de saisie (514) étant intégrées en un terminal (500) possédant un écran tactile (510).</claim-text></claim><claim id="c-fr-01-0008" num="0008"><claim-text>Appareil selon la revendication 3, l'unité de commande (110 ; 520) étant conçue pour surveiller la saisie d'une instruction d'utilisateur par l'intermédiaire de l'unité de saisie (101 ; 514), afin de déterminer (410) si un pointeur (230) est placé sur l'un des deux ou plusieurs objets (211-215 ; 311-312; 611-613) affichés sur l'unité d'affichage (120 ; 512), et de déterminer que l'objet (212 ; 612) sur lequel le pointeur (230) est placé est sélectionné.</claim-text></claim><claim id="c-fr-01-0009" num="0009"><claim-text>Appareil selon la revendication 3, comprenant en outre une unité de stockage (130 ; 540) pour stocker les informations d'attributs des deux ou plusieurs objets (211-215 ; 311-312 ; 611-613), les valeurs de pression de référence étant mappées vers les informations d'attributs et les valeurs de vibration correspondant aux valeurs de pression de référence.</claim-text></claim></claims><drawings mxw-id="PDW16671947" load-source="patent-office"><!-- EPO <DP n="35"> --><figure id="f0001" num="1"><img id="if0001" file="imgf0001.tif" wi="143" he="222" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="36"> --><figure id="f0002" num="2"><img id="if0002" file="imgf0002.tif" wi="145" he="187" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="37"> --><figure id="f0003" num="3"><img id="if0003" file="imgf0003.tif" wi="141" he="185" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="38"> --><figure id="f0004" num="4"><img id="if0004" file="imgf0004.tif" wi="165" he="216" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="39"> --><figure id="f0005" num="5"><img id="if0005" file="imgf0005.tif" wi="165" he="149" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="40"> --><figure id="f0006" num="6"><img id="if0006" file="imgf0006.tif" wi="142" he="144" img-content="drawing" img-format="tif"/></figure></drawings><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
