<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2556714-B1" country="EP" doc-number="2556714" kind="B1" date="20140108" family-id="43127136" file-reference-id="318277" date-produced="20180825" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="146588101" ucid="EP-2556714-B1"><document-id><country>EP</country><doc-number>2556714</doc-number><kind>B1</kind><date>20140108</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-10715685-A" is-representative="NO"><document-id mxw-id="PAPP154850293" load-source="docdb" format="epo"><country>EP</country><doc-number>10715685</doc-number><kind>A</kind><date>20100406</date><lang>EN</lang></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC140550797" ucid="EP-2010002160-W" load-source="docdb"><document-id format="epo"><country>EP</country><doc-number>2010002160</doc-number><kind>W</kind><date>20100406</date></document-id></priority-claim></priority-claims><dates-of-public-availability><intention-to-grant-date><date>20130827</date></intention-to-grant-date></dates-of-public-availability><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL1989324719" load-source="ipcr">H04L  12/801       20130101ALI20130814BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1989324720" load-source="ipcr">H04W  72/12        20090101AFI20130814BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL1989622693" load-source="docdb" scheme="CPC">H04L  47/30        20130101 LI20130101BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989627356" load-source="docdb" scheme="CPC">H04L  47/35        20130101 LI20130101BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989642907" load-source="docdb" scheme="CPC">H04W  72/1284      20130101 LA20130101BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989643733" load-source="docdb" scheme="CPC">H04L  47/25        20130101 LI20130101BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989647873" load-source="docdb" scheme="CPC">H04W  72/1252      20130101 LI20130101BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989649557" load-source="docdb" scheme="CPC">H04L  47/14        20130101 FI20130101BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT132368936" lang="DE" load-source="patent-office">Verfahren und Knoten zur Handhabung von Warteschlangen in Kommunikationsnetzen und entsprechendes Computerprogrammprodukt</invention-title><invention-title mxw-id="PT132368937" lang="EN" load-source="patent-office">Method and node for handling queues in communication networks, and corresponding computer program product</invention-title><invention-title mxw-id="PT132368938" lang="FR" load-source="patent-office">Procédé et noeud pour la gestion de files d'attente dans des réseaux de communication, et produit programme d'ordinateur correspondant</invention-title></technical-data><parties><applicants><applicant mxw-id="PPAR919524039" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>TELECOM ITALIA SPA</last-name><address><country>IT</country></address></addressbook></applicant><applicant mxw-id="PPAR919518841" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>TELECOM ITALIA S.P.A.</last-name></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR919514951" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>ANDREOZZI MATTEO MARIA</last-name><address><country>IT</country></address></addressbook></inventor><inventor mxw-id="PPAR919519929" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>ANDREOZZI, MATTEO, MARIA</last-name></addressbook></inventor><inventor mxw-id="PPAR919021527" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>ANDREOZZI, MATTEO, MARIA</last-name><address><street>Universita di Pisa - Dipartimento di lngegneria dell'lnformazione Via Diotisalvi 2</street><city>1-56126 Pisa</city><country>IT</country></address></addressbook></inventor><inventor mxw-id="PPAR919531624" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>CARETTI MARCO</last-name><address><country>IT</country></address></addressbook></inventor><inventor mxw-id="PPAR919506491" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>CARETTI, MARCO</last-name></addressbook></inventor><inventor mxw-id="PPAR919021523" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>CARETTI, MARCO</last-name><address><street>Telecom Italia S.p.A. Via G. Reiss Romoli 274</street><city>I-10148 Torino</city><country>IT</country></address></addressbook></inventor><inventor mxw-id="PPAR919536443" load-source="docdb" sequence="3" format="epo"><addressbook><last-name>FRANCESCHINI DANIELE</last-name><address><country>IT</country></address></addressbook></inventor><inventor mxw-id="PPAR919540807" load-source="docdb" sequence="3" format="intermediate"><addressbook><last-name>FRANCESCHINI, DANIELE</last-name></addressbook></inventor><inventor mxw-id="PPAR919021520" load-source="patent-office" sequence="3" format="original"><addressbook><last-name>FRANCESCHINI, DANIELE</last-name><address><street>Telecom Italia S.p.A. Via G. Reiss Romoli 274</street><city>I-10148 Torino</city><country>IT</country></address></addressbook></inventor><inventor mxw-id="PPAR919535124" load-source="docdb" sequence="4" format="epo"><addressbook><last-name>ROSSI ROBERTO</last-name><address><country>IT</country></address></addressbook></inventor><inventor mxw-id="PPAR919533764" load-source="docdb" sequence="4" format="intermediate"><addressbook><last-name>ROSSI, ROBERTO</last-name></addressbook></inventor><inventor mxw-id="PPAR919021521" load-source="patent-office" sequence="4" format="original"><addressbook><last-name>ROSSI, ROBERTO</last-name><address><street>Telecom Italia S.p.A. Via G. Reiss Romoli 274</street><city>I-10148 Torino</city><country>IT</country></address></addressbook></inventor><inventor mxw-id="PPAR919512803" load-source="docdb" sequence="5" format="epo"><addressbook><last-name>SABELLA DARIO</last-name><address><country>IT</country></address></addressbook></inventor><inventor mxw-id="PPAR919534608" load-source="docdb" sequence="5" format="intermediate"><addressbook><last-name>SABELLA, DARIO</last-name></addressbook></inventor><inventor mxw-id="PPAR919021524" load-source="patent-office" sequence="5" format="original"><addressbook><last-name>SABELLA, DARIO</last-name><address><street>Telecom Italia S.p.A. Via G. Reiss Romoli 274</street><city>I-10148 Torino</city><country>IT</country></address></addressbook></inventor><inventor mxw-id="PPAR919513100" load-source="docdb" sequence="6" format="epo"><addressbook><last-name>STEA GIOVANNI</last-name><address><country>IT</country></address></addressbook></inventor><inventor mxw-id="PPAR919503892" load-source="docdb" sequence="6" format="intermediate"><addressbook><last-name>STEA, GIOVANNI</last-name></addressbook></inventor><inventor mxw-id="PPAR919021522" load-source="patent-office" sequence="6" format="original"><addressbook><last-name>STEA, GIOVANNI</last-name><address><street>Università di Pisa - Dipartimento di lngegneria dell'lnformazione Via Diotisalvi 2</street><city>I-56126 Pisa</city><country>IT</country></address></addressbook></inventor></inventors><assignees><assignee mxw-id="PPAR919021526" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Telecom Italia S.p.A.</last-name><iid>100234051</iid><address><street>Piazza degli Affari 2</street><city>20123 Milano</city><country>IT</country></address></addressbook></assignee></assignees><agents><agent mxw-id="PPAR919021525" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Maccalli, Marco</last-name><suffix>et al</suffix><iid>100044218</iid><address><street>Maccalli &amp; Pezzoli S.r.l., Via Settembrini, 40</street><city>20124 Milano</city><country>IT</country></address></addressbook></agent></agents></parties><international-convention-data><pct-or-regional-filing-data ucid="EP-2010002160-W"><document-id><country>EP</country><doc-number>2010002160</doc-number><kind>W</kind><date>20100406</date><lang>EN</lang></document-id></pct-or-regional-filing-data><pct-or-regional-publishing-data ucid="WO-2011124235-A1"><document-id><country>WO</country><doc-number>2011124235</doc-number><kind>A1</kind><date>20111013</date><lang>EN</lang></document-id></pct-or-regional-publishing-data><designated-states><ep-contracting-states><country mxw-id="DS549781383" load-source="docdb">AT</country><country mxw-id="DS549798172" load-source="docdb">BE</country><country mxw-id="DS549873744" load-source="docdb">BG</country><country mxw-id="DS549889082" load-source="docdb">CH</country><country mxw-id="DS549782514" load-source="docdb">CY</country><country mxw-id="DS549781384" load-source="docdb">CZ</country><country mxw-id="DS549798185" load-source="docdb">DE</country><country mxw-id="DS549782515" load-source="docdb">DK</country><country mxw-id="DS549782516" load-source="docdb">EE</country><country mxw-id="DS549869554" load-source="docdb">ES</country><country mxw-id="DS549873745" load-source="docdb">FI</country><country mxw-id="DS549873758" load-source="docdb">FR</country><country mxw-id="DS549798186" load-source="docdb">GB</country><country mxw-id="DS549782525" load-source="docdb">GR</country><country mxw-id="DS549798187" load-source="docdb">HR</country><country mxw-id="DS549781389" load-source="docdb">HU</country><country mxw-id="DS549889083" load-source="docdb">IE</country><country mxw-id="DS549798188" load-source="docdb">IS</country><country mxw-id="DS549873759" load-source="docdb">IT</country><country mxw-id="DS549782526" load-source="docdb">LI</country><country mxw-id="DS549922665" load-source="docdb">LT</country><country mxw-id="DS549781390" load-source="docdb">LU</country><country mxw-id="DS549922666" load-source="docdb">LV</country><country mxw-id="DS549922667" load-source="docdb">MC</country><country mxw-id="DS549867119" load-source="docdb">MK</country><country mxw-id="DS549867120" load-source="docdb">MT</country><country mxw-id="DS549869555" load-source="docdb">NL</country><country mxw-id="DS549873760" load-source="docdb">NO</country><country mxw-id="DS549867121" load-source="docdb">PL</country><country mxw-id="DS549889084" load-source="docdb">PT</country><country mxw-id="DS549869556" load-source="docdb">RO</country><country mxw-id="DS549867126" load-source="docdb">SE</country><country mxw-id="DS549889085" load-source="docdb">SI</country><country mxw-id="DS549873761" load-source="docdb">SK</country><country mxw-id="DS549867127" load-source="docdb">SM</country><country mxw-id="DS549782527" load-source="docdb">TR</country></ep-contracting-states></designated-states></international-convention-data><office-specific-data><eptags><ep-no-a-document-published>*</ep-no-a-document-published></eptags></office-specific-data></bibliographic-data><description mxw-id="PDES63960529" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><heading id="h0001"><u>Field of the Invention</u></heading><p id="p0001" num="0001">The disclosure relates to techniques for handling queues in communication networks.</p><p id="p0002" num="0002">The disclosure was devised with attention paid to its possible application in scheduling real-time flows in uplink packet access cellular networks, such as UMTS High-Speed Uplink Packet Access (HSUPA) and Long Term Evolution (LTE).</p><heading id="h0002"><u>Description of the related art</u></heading><p id="p0003" num="0003">Cellular communication networks, e.g. 3G+ cellular networks, such as HSUPA and LTE (Long Term Evolution of UMTS), are and will be exploited to provide diverse services to users, including real-time services such as voice and video calls, live video streaming, and the like. Real-time services have a bounded end-to-end delay requirement, which, to be properly enforced, leads to the delay at each scheduling hop to be bounded as well. The end-to-end path of each packet includes two end (access) segments and one core network. Core networks are generally overprovisioned and/or make use of standardized QoS-enabling architectures, such as Differentiated Services (DiffServ) and/or MultiProtocol Label Switching-based Traffic Engineering (MPLS-TE), which are well-tuned and normally effective in providing QoS assurance; in that context, access segments plays a key role in enabling reliable real-time services.</p><p id="p0004" num="0004">Document <patcit id="pcit0001" dnum="EP1885090A"><text>EP-A-1 885 090</text></patcit> discloses a scheduling procedure to be implemented in MAC for IEEE 802.16d/e (WiMAX) or similar PMP (Point to MultiPoint)<!-- EPO <DP n="2"> --> telecommunications networks. The procedure involves processing at every radio frame only the connections previously planned to be serviced in that frame and in determining for every serviced connection the most suitable frame for next scheduling. An array of tables is used to store the connection identifiers of the connections to be serviced at the current and next radio frames up to a planned time horizon. At every radio frame, the connections inserted in the current frame tables are processed, the bandwidth is allocated in variable length blocks, and the frame of next servicing is evaluated according to the executed allocation and to the traffic rate parameters. The bandwidth allocation as well as the calculation of the next scheduling frame is performed based on the scheduling type of every service connection. Referring to the uplink scheduler, an estimation is performed of the input queue length of a Terminal Station (TS). This is updated at the reception of every bandwidth request by adding the value of incremental requests or by setting the new value in case of aggregate requests; at the reception of an uplink PDU the TS queue estimate is decremented by the number of bytes actually used, and the queue estimate is reset when a burst completely filled in by padding is received, as a burst not used for traffic nor for management data is interpreted as an aggregate request set to 0.</p><p id="p0005" num="0005">Additionally, documents such as <nplcit id="ncit0001" npl-type="b"><text>B. Wang, et al.. "Performance of VOIP on HSDPA", Proc. of IEEE VTC Spring '05, June 2005</text></nplcit>, or <nplcit id="ncit0002" npl-type="s"><text>M. Andreozzi, et al., "Flexible Scheduling for Real-Time Services in High-Speed Packet Access Cellular Networks", European Wireless 2009, Aalborg (DK) 17-20 May 2009</text></nplcit>, disclose arrangements where queues are physically placed at the NodeB.<!-- EPO <DP n="3"> --></p><heading id="h0003"><u>Object and summary of the invention</u></heading><p id="p0006" num="0006">The scheduling procedure for telecommunications networks discussed in the foregoing exploits a queue estimation framework to perform uplink scheduling by resorting to a scheduling procedure that processes for every radio frame only the connections previously planned to be serviced in that frame.</p><p id="p0007" num="0007">The inventors have noted that this inevitably results in an unrefined queue estimation. Also, the inventors have noted that, in the context considered, the possibility to proactively schedule the data to be transmitted without waiting for the uplink signaling request would be a desirable feature.</p><p id="p0008" num="0008">The object of the invention is thus to provide an improved solution enabling i.a. a more refined queue estimation, with the possibility of proactive scheduling.</p><p id="p0009" num="0009">According to the present invention, that object is achieved by means of a method having the features set forth in claim 1. The invention also relates to a corresponding node in network and to corresponding computer program product, loadable in the memory of at least one computer and including software code portions for performing the steps of the method of the invention when the product is run on a computer, as set forth in the corresponding independent claims that follow. As used herein, reference to such a computer program product is intended to be equivalent to reference to a computer-readable medium containing instructions for controlling a computer system to coordinate the performance of the method of the invention. Reference to "at least one computer" is evidently intended to highlight the possibility for the present invention to be implemented in a distributed/ modular fashion.</p><p id="p0010" num="0010">The claims are an integral part of the disclosure of<!-- EPO <DP n="4"> --> the invention provided herein.</p><p id="p0011" num="0011">Various embodiments provide a queue estimation procedure that can be exploited as a framework by the uplink scheduler in order to fully exploit the channel conditions experienced by the user.</p><p id="p0012" num="0012">Various embodiments provide for estimating both the size of the queue and the PDU generation time, and not merely the queue length. In various embodiments, the resulting output is a complete data structure, and not just a number.</p><p id="p0013" num="0013">Various embodiments are based on reconstructing the queues of each UE at the NodeB, so as to know the size and generation time of their packets and enable a scheduler to use such information. While various embodiments are amenable to all types of traffic, various embodiments are adapted for handling periodic traffic (e.g., VoIP).</p><p id="p0014" num="0014">Also, while certain embodiments are applicable in HSUPA, various embodiments can be readily applied to other similar access technologies (e.g., LTE) via minor modifications.</p><p id="p0015" num="0015">Various embodiments consider the uplink access segment of a cellular network, such as e.g. HSUPA. In such a network, scheduling is coordinated by a centralized entity, called NodeB.</p><p id="p0016" num="0016">User Equipments (UEs, e.g. mobile phones or handheld devices) in a cell send their traffic to the NodeB. At every scheduling period, called Transmission Time Interval (TTI), the NodeB computes Serving Grants (SG) for each UE, which determine - either directly or indirectly - a reference value for the amount of bits that a UE can transmit over its Enhanced Dedicated Channel (E-DCH).</p><p id="p0017" num="0017">The SGs may be computed according to several performance criteria, e.g. so as to limit the received<!-- EPO <DP n="5"> --> power at the NodeB, so that the latter is able to decode simultaneous transmissions from several UEs. Data Packets, which may be referred to as Protocol Data Units (PDUs), are buffered in the UE queues length and are transmitted across the radio interface.</p><p id="p0018" num="0018">Higher layer data packets, which are long, may thus be segmented into a number of PDUs, and padding can be added to fill up the last PDU. The NodeB obtains the backlog state of the UE queues from the Scheduling Information (SI), which are either piggybacked in the PDUs sent by the UE (if any) or in a stand-alone transmission (otherwise), whereby the SI are quantized according to a table, so that, as already noted in the foregoing, reconstructing therefrom the exact backlog state may not be always possible.</p><p id="p0019" num="0019">In various embodiments a "clever" scheduling solution computes the SG based on the SI reported by the UEs, thus dispensing with the risk of issuing overlength SGs and undesirably wasting resources and reducing the number of UEs that can be served in a TTI. Various embodiments take into account the fact that, when real-time traffic is considered, in addition to knowing how many PDUs are included in each queue and the relevant size, it may also be interesting to know the deadline for transmitting each of them, which cannot be inferred from the SI alone. In various embodiments, using simple computations, a NodeB can reconstruct a sufficiently accurate estimate of the backlog state of UE queues taking the SI as an input, thus providing a reconstructed estimate (which may be termed a Virtual Queue or VQ), which is represented by a list of couples {[lo,hi], d}, where lo, hi are the lower and upper bounds for the number of PDUs in the UE queue generated by time d. Various embodiments may co-operate with any scheduling procedure that takes into account the above<!-- EPO <DP n="6"> --> information (e.g., those used for real-time scheduling in the downlink direction, where queues are physically placed at the NodeB to be adapted for working with HSUPA via minor modifications).</p><p id="p0020" num="0020">In various embodiments, the Virtual Queue or VQ procedure does not make assumptions as to the actual traffic generation profile, thus being amenable to any kind of traffic, including non real-time traffic (e.g., HTTP), where a scheduler may harvest a smaller benefit by knowing the size and generation time of all the queued packets.</p><p id="p0021" num="0021">In so far as real-time traffic is concerned, periodic traffic may play a relevant role. For instance, voice flows have a periodic packet generation behavior: they alternate "on" periods (talkspurts), when they generate fixed-length packets with a constant interarrival time (e.g., 20s for the AMR codec), and - if they have Voice Activity Detection (VAD), as it normally happens - "off" or silence periods, when they either do not generate packets at all, or generate smaller packets.</p><p id="p0022" num="0022">Usually, the voice codec is made known at the RNC at the setup of a VoIP flow, for example in the Source Statistic Descriptor field of the RAB Assignment message sent to the RNC (Radio Network Controller) when the PDP Context is activated.</p><p id="p0023" num="0023">In various embodiments, the RNC can therefore provide the NodeB with the above information, and the latter can be used to identify the flow characteristics (i.e., the flow period and packet size, whether it has VAD or not, whether it generates packets during off periods, etc.). The VQ procedure can thus be refined to better match the flow characteristics, resulting in a reduced error in the reconstructed VQ.</p><p id="p0024" num="0024">Moreover, in the presence of periodic traffic, the<!-- EPO <DP n="7"> --> possibility exists of predicting the arrival of PDUs in the near future (i.e., the next 1-2 TTIs); this may be of interest since issuing SGs reactively, i.e. based on the SI reported by the UEs, undergoes a non negligible signaling delay equal to (at least) 2 TTIs, i.e. 20ms in a 10ms TTI deployment.</p><p id="p0025" num="0025">In various embodiments, such signaling delay can be avoided by predicting the backlog status of the UE queue at the time a possible SG will actually be used, i.e. in the subsequent TTI. In that way, SG can be issued proactively, i.e. based on the predicted status of the UE queue, before the SI is actually conveyed to the NodeB. This is achieved by computing the SG on a projection of the state of the VQ at the time when the SG will actually be exploited by the related UE.</p><p id="p0026" num="0026">In various embodiments, proactive scheduling can coexist with standard (reactive) scheduling of non-periodic or poorly predictable uplink flows, and can be turned on and off at will on the same flow, depending on whether a reliable estimate of the packet generation instants is available or not.</p><p id="p0027" num="0027">In various embodiments, Virtual Queue techniques can also be applied to other technologies. In fact, the Long Term Evolution of UMTS (LTE) is another potential area of application.</p><p id="p0028" num="0028">In LTE, scheduling of uplink resources is done by eNodeB. The latter assigns certain time/frequency resources to the UEs and informs UEs about the transmission formats to use. As in HSUPA, scheduling decisions may be based on QoS parameters, UE buffer status, uplink channel quality measurements. As in HSPA, the UE buffer status reported to the eNodeB is a coarsened version of the real UE buffer occupancy, and a quantization table, similar to the one<!-- EPO <DP n="8"> --> employed in HSPA, is used for encoding the UE buffers occupancies.</p><p id="p0029" num="0029">Moreover in LTE, like in HSPA, there is no way to acquire direct knowledge of uplink traffic deadlines. Therefore, in various embodiments the possibility of reconstructing the UEs buffers status at the NodeB level in HSPA, can be easily ported, with minor adjustments, into the LTE eNodeB MAC layer, in order to enable deadline-based scheduler to be executed also in the uplink side of the LTE architecture.</p><p id="p0030" num="0030">In various embodiments, virtual queueing can be applied to any technology that satisfies the following requirements:
<ul><li>packets are segmented into a number of fixed-length PDUs, whose length is known at both the sender and the receiver. That length need not be the same for all senders;</li><li>the status of uplink buffers is reported by conveying to the NodeB either an exact or an approximate buffer length, measured in number of PDUs. Reporting can be either periodical or non periodical;</li><li>the receiver (of buffer status reports) decides scheduling grants for the senders.</li></ul></p><p id="p0031" num="0031">In various embodiments, an improved estimate of the queue length may be obtained by periodically increasing the queue length by a fixed amount and subtracting the number of detected information units transmitted from the second point (e.g. the User Equipment or UE) to the first point (e.g. the base station), in case the arrival process for the information units at the second point is known to be periodic; the estimated queue length is compared to the quantized queue length information reported by the second point (e.g. the UE), and any mismatch in the above comparison is used to infer the onset and the termination<!-- EPO <DP n="9"> --> of periodic packet generation at the second point.</p><heading id="h0004"><u>Brief description of the annexed representations</u></heading><p id="p0032" num="0032">The invention will now be described, by way of example only, with reference to the enclosed representations, wherein:
<ul><li><figref idrefs="f0001">Figure 1</figref> is representative of SI and SG timing in an embodiment;</li><li><figref idrefs="f0001">Figure 2</figref> is a block diagram illustrative of the scheduling framework in an embodiment;</li><li><figref idrefs="f0002">Figure 3</figref> is illustrative of possible sequences of packets depending on the initial offset in an embodiment;</li><li><figref idrefs="f0003">Figure 4</figref> is illustrative of a High-level example of proactive scheduling in an embodiment; and</li><li><figref idrefs="f0003">Figure 5</figref> represents certain possible relevant quantities in proactive scheduling in an embodiment.</li></ul></p><heading id="h0005"><u>Detailed description of embodiments</u></heading><p id="p0033" num="0033">In the following description, numerous specific details are given to provide a thorough understanding of embodiments. The embodiments can be practiced without one or more of the specific details, or with other methods, components, materials, etc. In other instances, well-known structures, materials, or operations are not shown or described in detail to avoid obscuring aspects of the embodiments. Reference throughout this specification to "one embodiment" or "an embodiment" means that a particular feature, structure, or characteristic described in connection with the embodiment is included in at least one embodiment. Thus, the appearances of the phrases "in one embodiment" or "in an embodiment" in various places throughout this specification are not necessarily all referring to the same embodiment. Furthermore, the<!-- EPO <DP n="10"> --> particular features, structures, or characteristics may be combined in any suitable manner in one or more embodiments.</p><p id="p0034" num="0034">The headings provided herein are for convenience only and do not interpret the scope or meaning of the embodiments.</p><p id="p0035" num="0035">By way of introduction, some basic concepts of HSUPA technology will be summarized, with emphasis placed on the SI reporting and SG signaling mechanisms; the unscheduled mechanism for HSUPA, which can be used in conjunction with voice traffic, will then be recapitulated together with voice codecs and their characteristics.</p><p id="p0036" num="0036">As regards HSUPA, the UMTS radio access network (UTRAN) includes three major network elements: the Radio Network Controller (RNC), the Base Station (NodeB) and the User Equipment (UE). A RNC controls one or more NodeBs, the latter being in charge of a single cell where UEs roam.</p><p id="p0037" num="0037">In HSUPA the NodeB coordinates scheduling decisions using TTIs of 2 or 10ms. The Protocol Data Units or PDUs are physically stored at the UEs. However, the NodeB obtains the backlog state of the UE queues from the Scheduling Information (SI), which includes the total backlog on the UE and the percentage of the latter accounted to the highest priority flow (i.e., the one which will be selected by the internal UE scheduler). Both are quantized, using five and four bit indexes respectively, according to two non-linear tables (see the 3<sup>rd</sup> Generation Partnership Project website already captioned in the foregoing) so that reconstructing the exact backlog state may not be possible. The UE always reports an overestimated backlog to the NodeB.</p><p id="p0038" num="0038">The NodeB allocates data transmission power to the various UEs by assigning them scheduling grants (SGs). Depending on the received SG, the UE selects the<!-- EPO <DP n="11"> --> appropriate coding, which also determines the employed TBS. The mapping between SGs and TBSs (Transport Block Sizes or Sets) is pre-configured in the E-DCH Transport Format Combination (ETFC) table, which is known to both the NodeB and the UEs. A null SG, called the zero grant, prevents the UE from transmitting any data.</p><p id="p0039" num="0039">In considering SI reporting and SG signaling, one may first focus on a generic User Equipment or UE, say i. One may assume that i has one real-time flow, which is internally scheduled at the highest priority. The QoS class of the flow is known to the NodeB from the setup negotiation. Some other information, hereinafter called flow information, is normally available at least at the RNC (which can, in turn, communicate them to the NodeB). For exemplary purposes, this information may be assumed to include the voice codec employed, one out of a finite choice of known possibilities (which is what normally happens).<br/>
A standard SI quantization table (Table 1) is reported below, both in bytes (left) and in 40-byte PDUs (right). In Table 1 herein, those SI values which cannot be reported in this case are shown in grey.<!-- EPO <DP n="12"> -->
<tables id="tabl0001" num="0001"><img id="ib0001" file="imgb0001.tif" wi="151" he="81" img-content="table" img-format="tif"/></tables></p><p id="p0040" num="0040">The table reports in its left hand side a dimension in bytes, whereas the queues actually contain a number of fixed-length PDUs, whose length is selected by the NodeB. The PDU length can be set arbitrarily. A common value is 40 bytes, which is such that a voice packet is entirely contained into a PDU.</p><p id="p0041" num="0041">The number of 40-byte PDUs associated to each SI value is shown on the right side of Table 1. For instance, the UE reports a value of 18 if the queue is buffering 24 to 31 PDUs. For a given PDU size, the quantization table is divided in two zones: a non ambiguous zone, consisting in the set of SI that allows one to infer an exact backlog at the UE (i.e., 0≤<i>SI</i>≤12 for 40-byte PDUs) and an ambiguous one, where the quantization intervals are larger than the PDU size. Furthermore, it will be appreciated that - in the non ambiguous region - not all the SI values are actually possible. The width of the ambiguous region depends on the PDU size. The larger the PDU size, the smaller the ambiguous region, and, within the latter, the width of each quantization interval.</p><p id="p0042" num="0042">In the following, whenever referring to SI<!-- EPO <DP n="13"> --> quantization, the PDUs will be assumed to be 40 bytes long. This may be regarded as a "pejorative" assumption in terms of quantization. However, various embodiments do not rely on the PDU size, although their performance - and effectiveness - may be related thereto.</p><p id="p0043" num="0043">A UE application generates packets, so that, at some time instants, a number of PDUs is inserted in the (FIFO) UE queue. When the UE receives a SG from the NodeB, it transmits one MAC-E PDU, which includes zero or more PDUs and/or SI, in a single TTI. Those PDUs may belong to different packets, as original packets are reassembled at the NodeB. This means that the scheduling module in the latter may be made aware of packet boundaries when it receives a set of PDUs. However, no such assumption is made here.</p><p id="p0044" num="0044">Packets queued at the UE can be removed either by scheduling decisions taken at the NodeB, or dropped by the UE after a known dropping timeout. Without loss of generality, one may assume that one packet is generated in a TTI. In fact, the UE is not required to transmit packets atomically, and it can mix PDU of several packets (however maintaining the FIFO ordering) in the same transmission. Furthermore, it may not be possible to pin down events with a smaller resolution than the TTI, from a real-time scheduling point of view packets of a flow generated in the same TTI would have the same deadline nonetheless.</p><p id="p0045" num="0045">In the following, purely for ease of exposition, times will be normalized to the TTI length, so that the sequence of TTIs is a sequence of natural numbers. The SI issued at a given TTI T at the UE reports the state of its queue up to T. However, this SI arrives at the NodeB at time T+1. Assuming that the NodeB is able to compute a scheduling decision in zero time, the NodeB might be able to keep into<!-- EPO <DP n="14"> --> account that SI when issuing the subsequent SG. The latter in turn arrives at the UE at time T+2. Therefore, in the very best case, the signaling delay will equal 2 TTI.</p><p id="p0046" num="0046"><figref idrefs="f0001">Figure 1</figref> herein is exemplary of SI and SG timing in communication between a NodeB and a User Equipment or UE. In a 10ms TTI deployment, such a signaling delay is indeed attainable, since the SG is actually 2ms long, and they are repeated five times in the 10ms period. It is thus foreseeable that the NodeB might take, e.g., 2ms for computing the SGs for the UEs in the cell, leave the first 2ms instance blank, and actually repeat the correct SG four times. The UEs would therefore be able to decode the correct SG simply by skipping the first instance. In a 2ms TTI deployment, instead, there seems to be no other way than wasting at least another TTI for allowing the NodeB to make scheduling decisions, which brings the signaling delay to 3 TTI.</p><p id="p0047" num="0047">Every item of information received at the NodeB at T will inevitably refer to quantities generated before T-1. In the following the NodeB will be taken as a reference, since decisions are taken by the latter. Therefore, reference will be had to - say - SI at time T to define SI received at that time (hence generated at time T-1 at the UE). Finally, for the same reason, a packet will have a minimum delay lying between one and two TTIs, depending on its arrival time with respect to the TTI boundary.</p><p id="p0048" num="0048">In HSUPA, non-scheduled transmissions are allowed by standards. Specifically<nplcit id="ncit0003" npl-type="b"><text> 3GPP TS 25.309 V6.6.0 (2006-03), Chapter 10</text></nplcit> indicates that when non-scheduled transmission is configured by the SRNC, the UE is allowed to send E-DCH data at any time, up to a configured number of bits, without receiving any scheduling command from the Node B. Thus, signalling overhead and scheduling delay are<!-- EPO <DP n="15"> --> minimized.</p><p id="p0049" num="0049">This means that a share of the resources is reserved at every TTI for such kind of transmissions. These resources are not handled by the scheduler. The LTE system allows a similar mechanism, with enhanced flexibility. The RRC (Radio Resource Control) may configure some H-ARQ processes to be reserved for periodic resource assignment, in both the downlink and the uplink direction. This is called semi-persistent scheduling. By using the latter, some OFDMA resources (and, accordingly, data resources), are pre-reserved. In LTE, the non-scheduled mode can be used to serve a MAC-d flow of a UE. In this case, the latter is served periodically (for up to a configurable maximum number of periods), and is given a fixed grant on a given set of TTIs within a period.</p><p id="p0050" num="0050">In both HSUPA and LTE the SI is not taken into account for the flow for non-scheduled services. Furthermore, signaling delay and overhead are reduced, since SG need not be transmitted. Moreover, in HSUPA (where a non-scheduled UE has an implicit SG at every TTI), near-zero uplink latency is also achievable. However, this comes with a drastic reduction in efficiency, as these services completely bypass the NodeB scheduler (hence their name). Broadly speaking, non-scheduled transmissions subtract a number of resources from the control of the scheduler. Under this regime, a non-scheduled flow can transmit up to a pre-defined number of bits, whether its queue is empty or not, whether the related PDUs are urgent or not, whether the channel conditions for the UE are optimal or largely suboptimal. Furthermore, queue length and delays are not taken into account, as SI are not considered. This makes such a mechanism inefficient when used on a large scale (i.e., for many users simultaneously), or for mobile users<!-- EPO <DP n="16"> --> with varying channels. In HSUPA, additional mechanisms would also be required to keep the intra-cell interference generated by non-scheduled users under control.</p><p id="p0051" num="0051">On the other hand, VQ (in all its versions, included those specialized for CBR (Constant Bit Rate) service) is meant to work at the scheduling level, enabling a scheduler to know the current (and, in case of CBR sources, predict the future) state of a UE queue, specifically how many packets are in there and (most of all) when they were queued. This allows a scheduler (which is an external element in this framework) to use the above information for whatever suitable purpose. For instance, it could set up a purely deadline-based service (which cannot be done, for instance, using semi-persistent scheduling), or a hybrid, semi-opportunistic scheduling, where packet deadlines and channel conditions are combined to form scheduling and resource allocation criteria. While, for instance, efficient solutions which capitalize on statistical multiplexing among different connections, adaptive channel exploitation, etc., can be designed using a VQ framework, this cannot be achieved by using a non-scheduled mode.</p><p id="p0052" num="0052">Turning now to voice codecs, VoIP applications represent an important class of real-time traffic in today's HSPA systems. As already anticipated, a specialized VQ procedure will be presented for periodic traffic.</p><p id="p0053" num="0053">The traffic profiles of VoIP applications can be classified into four categories:
<ul><li>CBR (Constant Bit Rate): applications that generate constant-size packets at constant intervals;</li><li>CBR on/off: these applications have Voice Activity Detection (VAD). They generate constant size packets at constant intervals during talkspurts, and they do not generate information during silence periods;<!-- EPO <DP n="17"> --></li><li>Quasi-CBR: constant packet generation interval (during both talkspurts and silence periods), different packet size for talkspurts and silence periods;</li><li>VBR (Variable Bit Rate): packets of variable lengths generated at fixed intervals.</li></ul></p><p id="p0054" num="0054">This exemplary disclosure describes specialized VQ procedures for the first two categories; extensions for the third one are straightforward, especially if the scenario is limited to a communication where the Quasi-CBR has constant size packets at constant intervals, behaving basically like a CBR on/off.</p><p id="p0055" num="0055">Some common characteristics for all the voice codecs can be abstracted as follows: packet generation periods are normally larger than the TTI (whichever the version, 2ms or 10ms). For instance, voice streams using the AMR codec are CBR (with on/off alternation due to Voice Activity Detection), with frame generation periods of 20ms (i.e. 2 or 10 TTI, depending on the HSUPA version). The periods considered are not necessarily integer multiples of a TTI. Furthermore, for VAD-enabled codecs, single "on" and "off" periods are normally much larger than the inter packet generation time (and, consequently, of the TTI). The average length of these periods is in the order of 100-1000 TTIs, whatever the voice model adopted and the TTI length.</p><p id="p0056" num="0056">Also, quasi-CBR sources may appear to the scheduler as CBR sources, if the length of the packets during talkspurts and silence periods amounts to the same number of PDUs. For instance, the GSM AMR codec generates 32 bytes of payload during talkspurts, and either 0 or 5 bytes of payload during silence periods. If the PDU length is above 72 bytes, then the SI reports just one PDU in all cases.</p><p id="p0057" num="0057">An exemplary scheduling framework is shown in <figref idrefs="f0001">figure 2</figref>. The Virtual Queuing block collects the sequence of SI<!-- EPO <DP n="18"> --> and transmitted PDUs from the UE, and uses this information to reconstruct the state of the UE queue in the most accurate possible way, using affordable computations. A basic procedure, which does not make any assumption on the traffic profile, will be described in the following. In some cases, we might know more about the flow, and exploit this knowledge to improve the VQ estimate. A "flow profile" may be defined as a set of information items such as: whether the traffic is periodic, and whether the generated packets have a constant length. The above information can be collected at flow setup, through means that are known to the person skilled in the art and do not need not be described here. One may assume that the NodeB is configured with a table which associates codecs with the following information: i) a flow type (e.g., CBR, or CBR on/off, etc.), ii) a flow period, and iii) a packet length. If a flow is known to be CBR or CBR on/off, this information can be used both to specialize the VQ procedure and to enable proactive SG assignment. As for the first issue, knowing its packet length and period allows one to overcome the uncertainties in the VQ estimate that arise due to the SI quantization. Furthermore, as it allows one to predict the size and generation instant of packets, it enables the NodeB to assign suitably large SGs proactively to periodic flows.</p><p id="p0058" num="0058"><figref idrefs="f0001">Figure 2</figref> is representative of an exemplary scheduling framework including a Virtual Queuing arrangement VQ having SI plus TX'd PDUs as inputs together with information as to flow type, period, size(s), and so on developed by a flow profile module FP starting from flow information as provided e.g. by a codec.</p><p id="p0059" num="0059">The following description relates to the basic Virtual Queueing (VQ) procedure and how to populate and manage the<!-- EPO <DP n="19"> --> VQ observing the sequence of SI reported by the UE and the sequence of PDUs transmitted by the UE.</p><p id="p0060" num="0060">Various embodiments pursue the goal of enabling the NodeB to reconstruct the exact backlog state on the UE, which may not be always possible due to the quantized nature of the SI. The estimation process depends on the PDU length, and, in general, the shorter the PDU size, the more difficult the accurate estimations of their number (see Table 1).</p><p id="p0061" num="0061">Although an exact packet length for every generated packet cannot be inferred from the SI in general, by considering the sequence of reported SI and transmitted PDUs the accuracy of the VQ estimate can be increased, thus considerably reducing the impact of the SI quantization.</p><p id="p0062" num="0062">A general procedure will be considered first, while subsequently showing a possible refinement step for the case when flow profile information is available.</p><p id="p0063" num="0063">A VQ is a FIFO queue of items {[lo, hi], d}, where d is an estimated packet generation time, and lo, hi are the lower and upper bounds for the overall VQ backlog including all packets generated until time d. How those time instants d are computed will be described in the following.</p><p id="p0064" num="0064"><figref idrefs="f0001">Figure 2</figref> illustrates a possible "snapshot" of a VQ: 1 to 3 PDUs that are still sitting in the UE queue were generated at time 1, whereas 5 to 7 PDU were generated up to time 3 (which implies that 5-3=2 to 7-1=6 PDUs were generated at time 3) and so on. While one can easily infer lower and upper bounds for each packet in the VQ from the above information, one may prefer to store the queue length at time t in the VQ, since the above information is more precise than the length of single packets. In fact, for the latter the uncertainty in the estimation of the queue length for two consecutive packets is summed up. This means<!-- EPO <DP n="20"> --> that one may estimate the length of single packets from the cumulative lengths if need be, while the converse may not be true without allowing for further errors.</p><p id="p0065" num="0065">Furthermore, the length associated to the head of the VQ still describes the head-of-line packet, which in fact enables deadline-based scheduling.</p><p id="p0066" num="0066">Let <i>S<sub>i</sub>,D<sub>i</sub>,q<sub>i</sub></i> be the SI, the number of transmitted PDUs and the queue length at time i, and let <i>L</i>(·),<i>H</i>(·) be the functions that report the lower and upper bounds on the UE queue length from the SI given as a parameter, as specified in the quantization table.</p><p id="p0067" num="0067">For instance, with reference to Table 1, one may have <i>L</i>(15)=11,<i>H</i>(15)=13. According to the standard, when a UE sends both PDUs and SI, the backlog reported by the latter does not take into account the PDUs just transmitted.</p><p id="p0068" num="0068">At a high level, the VQ estimation works as follows.</p><p id="p0069" num="0069">Every time a set of k PDUs is transmitted by the UE to the NodeB, the number k is subtracted from the upper and lower bounds of every entry in the VQ, and when the upper bound of the head-of-line entry reaches zero the latter is removed from the front.</p><p id="p0070" num="0070">Every time a new SI arrives at the NodeB, the new information is used to either improve the length estimate for the tail of the VQ, or to detect the generation of a new packet at the UE.</p><p id="p0071" num="0071">When a new packet generation is detected at time <i>t</i>, a new entry {[<i>L</i>(<i>S<sub>t</sub></i>),<i>H</i>(<i>S<sub>t</sub></i>)],<i>t</i>} is added to the tail of the VQ.</p><p id="p0072" num="0072">In order to explain the procedure in detail, one may start with describing what happens with an initially empty queue, assuming that one packet is generated at time 0. The general case will then be described.<!-- EPO <DP n="21"> --></p><p id="p0073" num="0073">At every subsequent time instant i, the following relationships hold: <maths id="math0001" num=""><math display="block"><mo>∀</mo><mi>i</mi><mo>≥</mo><mn>0</mn><mo>,</mo><mspace width="1em"/><mi>L</mi><mfenced><msub><mi>S</mi><mi>i</mi></msub></mfenced><mo>≤</mo><msub><mi>q</mi><mi>i</mi></msub><mo>≤</mo><mi>H</mi><mfenced><msub><mi>S</mi><mi>i</mi></msub></mfenced></math><img id="ib0002" file="imgb0002.tif" wi="50" he="6" img-content="math" img-format="tif"/></maths></p><p id="p0074" num="0074">No other packet is assumed to be generated at the UE after time 0 for a while, i being a generic instant.</p><p id="p0075" num="0075">Then, for any time j between 0 and i: <maths id="math0002" num="(1)"><math display="block"><mo>∀</mo><mi>i</mi><mo>≥</mo><mn>0</mn><mo>,</mo><mo>∀</mo><mi>j</mi><mo>:</mo><mn>0</mn><mo>≤</mo><mi>j</mi><mo>≤</mo><mi>i</mi><mo>,</mo><mspace width="1em"/><msub><mi>q</mi><mi>i</mi></msub><mo>=</mo><msub><mi>q</mi><mi>j</mi></msub><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>x</mi><mo>=</mo><mi>j</mi><mo>+</mo><mn>1</mn></mrow><mi>i</mi></munderover></mstyle><msub><mi>D</mi><mi>x</mi></msub><mn>.</mn></math><img id="ib0003" file="imgb0003.tif" wi="87" he="15" img-content="math" img-format="tif"/></maths></p><p id="p0076" num="0076">This means that the queue is not growing. In fact, some PDU might be transmitted from the UE. If this happens, then the SI at time j will reflect the new state of the queue, which will generally be smaller than it was at time 0 (assuming that no packets are generated after time 0).</p><p id="p0077" num="0077">From (1), the following can be derived: <maths id="math0003" num="(2)"><math display="block"><mo>∀</mo><mi>i</mi><mo>≥</mo><mn>0</mn><mo>,</mo><mspace width="1em"/><msubsup><mi>Q</mi><mi>i</mi><mi>L</mi></msubsup><mo>=</mo><munder><mi>max</mi><mrow><mn>0</mn><mo>≤</mo><mi>j</mi><mo>≤</mo><mi>i</mi></mrow></munder><mfenced open="{" close="}" separators=""><mi>L</mi><mfenced><msub><mi>S</mi><mi>j</mi></msub></mfenced><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>x</mi><mo>=</mo><mi>j</mi><mo>+</mo><mn>1</mn></mrow><mi>i</mi></munderover></mstyle><msub><mi>D</mi><mi>x</mi></msub></mfenced><mo>≤</mo><msub><mi>q</mi><mi>i</mi></msub><mo>≤</mo><munder><mi>min</mi><mrow><mn>0</mn><mo>≤</mo><mi>j</mi><mo>≤</mo><mi>i</mi></mrow></munder><mfenced open="{" close="}" separators=""><mi>H</mi><mfenced><msub><mi>S</mi><mi>j</mi></msub></mfenced><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>x</mi><mo>=</mo><mi>j</mi><mo>+</mo><mn>1</mn></mrow><mi>i</mi></munderover></mstyle><msub><mi>D</mi><mi>x</mi></msub></mfenced><mo>=</mo><msubsup><mi>Q</mi><mi>i</mi><mi>H</mi></msubsup></math><img id="ib0004" file="imgb0004.tif" wi="128" he="19" img-content="math" img-format="tif"/></maths> <maths id="math0004" num=""><math display="inline"><msubsup><mi>Q</mi><mi>i</mi><mi>L</mi></msubsup><mo>,</mo><msubsup><mi>Q</mi><mi>i</mi><mi>H</mi></msubsup></math><img id="ib0005" file="imgb0005.tif" wi="14" he="7" img-content="math" img-format="tif" inline="yes"/></maths> are the most accurate bounds on the length of the queue available at time <i>i</i> given the above information.</p><p id="p0078" num="0078">Now, in the absence of a new packet arrival, <maths id="math0005" num=""><math display="inline"><msubsup><mi>Q</mi><mi>i</mi><mi>L</mi></msubsup><mo>,</mo><msubsup><mi>Q</mi><mi>i</mi><mi>H</mi></msubsup></math><img id="ib0006" file="imgb0006.tif" wi="15" he="7" img-content="math" img-format="tif" inline="yes"/></maths> are increasing and decreasing respectively, thus narrowing down the uncertainty for <i>q<sub>i</sub>.</i></p><p id="p0079" num="0079">Therefore, in order to provide the scheduler with a consistent view at every TTI, both <maths id="math0006" num=""><math display="inline"><msubsup><mi>Q</mi><mi>i</mi><mi>L</mi></msubsup><mo>,</mo><msubsup><mi>Q</mi><mi>i</mi><mi>H</mi></msubsup></math><img id="ib0007" file="imgb0007.tif" wi="14" he="7" img-content="math" img-format="tif" inline="yes"/></maths> should be recomputed and the corresponding VQ entry updated. However, if another packet is generated at the UE at some time <i>k</i>, then <maths id="math0007" num=""><math display="inline"><msubsup><mi>Q</mi><mi>i</mi><mi>L</mi></msubsup><mo>&gt;</mo><msubsup><mi>Q</mi><mi>i</mi><mi>H</mi></msubsup></math><img id="ib0008" file="imgb0008.tif" wi="17" he="7" img-content="math" img-format="tif" inline="yes"/></maths> might possibly take place for some <i>h</i>≥<i>k</i>,<!-- EPO <DP n="22"> --> because <i>L</i>(·) may increase.</p><p id="p0080" num="0080">A simple example is the following.</p><p id="p0081" num="0081">Assume that at time 0 a 20-PDU packet arrives. Then we have <i>S</i><sub>0</sub>=17, <i>L</i>(<i>S</i><sub>0</sub>)=18, <i>H</i>(<i>S</i><sub>0</sub>)=23. Thus, an entry is inserted in the VQ, {[18,23],0}. At time 1, no PDUs are transmitted and <i>S</i><sub>1</sub>=17. At time 2, the UE transmits four PDUs, and sends <i>S</i><sub>2</sub>=17 again. According to (2): <maths id="math0008" num=""><math display="block"><msubsup><mi>Q</mi><mn>2</mn><mi>L</mi></msubsup><mo>=</mo><mi>max</mi><mfenced open="{" close="}" separators=""><mi>L</mi><mfenced><msub><mi>S</mi><mn>0</mn></msub></mfenced><mo>-</mo><mn>4</mn><mo>,</mo><mi>L</mi><mfenced><msub><mi>S</mi><mn>1</mn></msub></mfenced><mo>-</mo><mn>4</mn><mo>,</mo><mi>L</mi><mfenced><msub><mi>S</mi><mn>2</mn></msub></mfenced></mfenced><mo>≤</mo><msub><mi>q</mi><mn>2</mn></msub><mo>≤</mo><mi>min</mi><mfenced open="{" close="}" separators=""><mi>H</mi><mfenced><msub><mi>S</mi><mn>0</mn></msub></mfenced><mo>-</mo><mn>4</mn><mo>,</mo><mi>H</mi><mfenced><msub><mi>S</mi><mn>1</mn></msub></mfenced><mo>-</mo><mn>4</mn><mo>,</mo><mi>H</mi><mfenced><msub><mi>S</mi><mn>2</mn></msub></mfenced></mfenced><mo>=</mo><msubsup><mi>Q</mi><mn>2</mn><mi>H</mi></msubsup></math><img id="ib0009" file="imgb0009.tif" wi="151" he="8" img-content="math" img-format="tif"/></maths><br/>
which, after few manipulations, becomes <maths id="math0009" num=""><math display="inline"><msubsup><mi>Q</mi><mn>2</mn><mi>L</mi></msubsup><mo>=</mo><mn>18</mn><mo>,</mo><mspace width="1em"/><msubsup><mi>Q</mi><mn>2</mn><mi>H</mi></msubsup><mo>=</mo><mn>19.</mn></math><img id="ib0010" file="imgb0010.tif" wi="35" he="8" img-content="math" img-format="tif" inline="yes"/></maths></p><p id="p0082" num="0082">This means that the number of PDUs in the queue at time 0 was at least <i>q</i><sub>0</sub>≥18+4=22, and <i>q</i><sub>0</sub>≤23. Note that the initial uncertainty on the number of PDU included was 23-18=5 PDUs at time 0, and it is now 19-18=1 PDU, i.e. it narrows down with time.</p><p id="p0083" num="0083">Suppose now that, at time 3, two more PDUs are received at the NodeB, and the UE still reports <i>S</i><sub>3</sub>=17. Clearly, this implies that another packet must have arrived: if it had not, then the UE queue would be between 16 and 17 PDUs, and the reported SI would be <i>S</i><sub>3</sub>=16.</p><p id="p0084" num="0084">If (2) is instantiated again at time 3, one gets: <maths id="math0010" num=""><math display="block"><msubsup><mi>Q</mi><mn>3</mn><mi>L</mi></msubsup><mo>=</mo><mi>max</mi><mfenced open="{" close="}" separators=""><mi>L</mi><mfenced><msub><mi>S</mi><mn>0</mn></msub></mfenced><mo>-</mo><mn>6</mn><mo>,</mo><mi>L</mi><mfenced><msub><mi>S</mi><mn>1</mn></msub></mfenced><mo>-</mo><mn>6</mn><mo>,</mo><mi>L</mi><mfenced><msub><mi>S</mi><mn>2</mn></msub></mfenced><mo>-</mo><mn>2</mn><mo>,</mo><mi>L</mi><mfenced><msub><mi>S</mi><mn>3</mn></msub></mfenced></mfenced><mo>=</mo><mi>max</mi><mfenced open="{" close="}"><mn>14</mn><mn>14</mn><mn>16</mn><mn>18</mn></mfenced><mo>=</mo><mn>18</mn></math><img id="ib0011" file="imgb0011.tif" wi="130" he="8" img-content="math" img-format="tif"/></maths> <maths id="math0011" num=""><math display="block"><msubsup><mi>Q</mi><mn>3</mn><mi>H</mi></msubsup><mo>=</mo><mi>min</mi><mfenced open="{" close="}" separators=""><mi>H</mi><mfenced><msub><mi>S</mi><mn>0</mn></msub></mfenced><mo>-</mo><mn>6</mn><mo>,</mo><mi>H</mi><mfenced><msub><mi>S</mi><mn>1</mn></msub></mfenced><mo>-</mo><mn>6</mn><mo>,</mo><mi>H</mi><mfenced><msub><mi>S</mi><mn>2</mn></msub></mfenced><mo>-</mo><mn>2</mn><mo>,</mo><mi>H</mi><mfenced><msub><mi>S</mi><mn>3</mn></msub></mfenced></mfenced><mo>=</mo><mi>min</mi><mfenced open="{" close="}"><mn>17</mn><mn>17</mn><mn>19</mn><mn>23</mn></mfenced><mo>=</mo><mn>17</mn></math><img id="ib0012" file="imgb0012.tif" wi="135" he="9" img-content="math" img-format="tif"/></maths></p><p id="p0085" num="0085">In this case, the inconsistency is revealed by the fact that <maths id="math0012" num=""><math display="inline"><msubsup><mi>Q</mi><mn>3</mn><mi>L</mi></msubsup><mo>&gt;</mo><msubsup><mi>Q</mi><mn>3</mn><mi>H</mi></msubsup><mn>.</mn></math><img id="ib0013" file="imgb0013.tif" wi="20" he="8" img-content="math" img-format="tif" inline="yes"/></maths> When this happens, the most accurate estimate for the length of the first entry in the VQ is<!-- EPO <DP n="23"> --> <maths id="math0013" num=""><math display="inline"><mfenced open="[" close="]"><msubsup><mi>Q</mi><mrow><mi>h</mi><mo>-</mo><mn>1</mn></mrow><mi>L</mi></msubsup><msubsup><mi>Q</mi><mrow><mi>h</mi><mo>-</mo><mn>1</mn></mrow><mi>H</mi></msubsup></mfenced><mo>,</mo></math><img id="ib0014" file="imgb0014.tif" wi="24" he="10" img-content="math" img-format="tif" inline="yes"/></maths> and a new entry {[<i>L</i>(<i>S<sub>h</sub></i>),<i>H</i>(<i>S<sub>h</sub></i>)],<i>h</i>} is added to the tail of the VQ. From then on, the estimate for the previous entry (i.e., the last-but-one) is frozen, and every subsequent information can only be used to improve the last entry in the VQ.</p><p id="p0086" num="0086">At TTI <i>h</i>, the computation of <maths id="math0014" num=""><math display="inline"><msubsup><mi>Q</mi><mi>i</mi><mi>L</mi></msubsup><mo>,</mo><msubsup><mi>Q</mi><mi>i</mi><mi>H</mi></msubsup></math><img id="ib0015" file="imgb0015.tif" wi="14" he="7" img-content="math" img-format="tif" inline="yes"/></maths> is restarted, i.e., we rewrite (2) substituting the index of the most recent packet arrival for 0: <maths id="math0015" num="(3)"><math display="block"><mo>∀</mo><mi>i</mi><mo>≥</mo><mi>h</mi><mo>,</mo><mspace width="1em"/><msubsup><mi>Q</mi><mi>i</mi><mi>L</mi></msubsup><mo>=</mo><munder><mi>max</mi><mrow><mi>h</mi><mo>≤</mo><mi>j</mi><mo>≤</mo><mi>i</mi></mrow></munder><mfenced open="{" close="}" separators=""><mi>L</mi><mfenced><msub><mi>S</mi><mi>j</mi></msub></mfenced><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>x</mi><mo>=</mo><mi>j</mi><mo>+</mo><mn>1</mn></mrow><mi>i</mi></munderover></mstyle><msub><mi>D</mi><mi>x</mi></msub></mfenced><mo>≤</mo><msub><mi>q</mi><mi>i</mi></msub><mo>≤</mo><munder><mi>min</mi><mrow><mi>h</mi><mo>≤</mo><mi>j</mi><mo>≤</mo><mi>i</mi></mrow></munder><mfenced open="{" close="}" separators=""><mi>H</mi><mfenced><msub><mi>S</mi><mi>j</mi></msub></mfenced><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>x</mi><mo>=</mo><mi>j</mi><mo>+</mo><mn>1</mn></mrow><mi>i</mi></munderover></mstyle><msub><mi>D</mi><mi>x</mi></msub></mfenced><mo>=</mo><msubsup><mi>Q</mi><mi>i</mi><mi>H</mi></msubsup></math><img id="ib0016" file="imgb0016.tif" wi="138" he="17" img-content="math" img-format="tif"/></maths></p><p id="p0087" num="0087">Note that <maths id="math0016" num=""><math display="inline"><msubsup><mi>Q</mi><mi>i</mi><mi>L</mi></msubsup><mo>,</mo><msubsup><mi>Q</mi><mi>i</mi><mi>H</mi></msubsup></math><img id="ib0017" file="imgb0017.tif" wi="14" he="8" img-content="math" img-format="tif" inline="yes"/></maths> can be computed in constant time, as (3) boils down to: <maths id="math0017" num="(4)"><math display="block"><msubsup><mi>Q</mi><mi>i</mi><mi>L</mi></msubsup><mo>=</mo><mi>max</mi><mfenced open="{" close="}" separators=""><mi>L</mi><mfenced><msub><mi>S</mi><mi>i</mi></msub></mfenced><mo>,</mo><msubsup><mi>Q</mi><mi>i</mi><mi>L</mi></msubsup><mo>-</mo><msub><mi>D</mi><mi>i</mi></msub></mfenced><mo>,</mo><mspace width="1em"/><msubsup><mi>Q</mi><mi>i</mi><mi>H</mi></msubsup><mo>=</mo><mi>min</mi><mfenced open="{" close="}" separators=""><mi>H</mi><mfenced><msub><mi>S</mi><mi>i</mi></msub></mfenced><mo>,</mo><msubsup><mi>Q</mi><mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow><mi>H</mi></msubsup><mo>-</mo><msub><mi>D</mi><mi>i</mi></msub></mfenced></math><img id="ib0018" file="imgb0018.tif" wi="113" he="11" img-content="math" img-format="tif"/></maths></p><p id="p0088" num="0088">While it may not always be possible to identify the exact TTI when the new packet has been generated (unless additional information on the packet generation process is available), one may decide to acknowledge that a packet is generated when the information provided by (4) becomes inconsistent.</p><p id="p0089" num="0089">Assume now that the VQ includes <i>N</i> entries {[<i>m<sup>i</sup></i>,<i>n<sup>i</sup></i>],<i>t<sup>i</sup></i>} (a superscript is used for the entries in the VQ and a subscript for time instants): every time a set of <i>k</i> PDUs are transmitted from the UE to the NodeB, the following actions take place: <maths id="math0018" num="(5)"><math display="block"><mo>∀</mo><mi>i</mi><mo>,</mo><mn>1</mn><mo>≤</mo><mi>i</mi><mo>≤</mo><mi>N</mi><mo>-</mo><mn>1</mn><mo>,</mo><mspace width="1em"/><msup><mi>m</mi><mi>i</mi></msup><mo>=</mo><mi>max</mi><mfenced open="{" close="}" separators=""><mn>0</mn><mo>,</mo><msup><mi>m</mi><mi>i</mi></msup><mo>-</mo><mi>k</mi></mfenced><mo>,</mo><msup><mi>n</mi><mi>i</mi></msup><mo>=</mo><msup><mi>n</mi><mi>i</mi></msup><mo>-</mo><mi>k</mi></math><img id="ib0019" file="imgb0019.tif" wi="118" he="10" img-content="math" img-format="tif"/></maths></p><p id="p0090" num="0090">Furthermore, if <i>n</i><sup>1</sup>≤0 the head-of-line entry has to be removed. This implies that one may be considering more PDUs than necessary as being generated at a given time instant,<!-- EPO <DP n="24"> --> which may be avoided by using additional information. If, e.g., the NodeB sees packet boundaries and one can be reasonably sure that only one packet is generated at a TTI, this last part of the procedure can be refined according to known methods.</p><p id="p0091" num="0091">The last entry in the VQ (i.e., the <i>N</i> <sup>th</sup>), is instead updated through (3). If updating each entry of the VQ at every transmission is too costly, a tradeoff between accuracy and speed can be achieved as follows:
<ul><li>when PDUs are transmitted by the UE, (4) is computed for the last entry and the transmitted PDUs are subtracted from the head-of-line entry alone;</li><li>each VQ entry is augmented with a counter <i>q<sup>x</sup></i>. The latter is set to <i>n</i><sup><i>x</i>-1</sup>, , i.e. the upper bound on the estimate of the previous entry, when the <i>x</i><sup>th</sup> entry is frozen;</li><li>once the upper bound for the head-of-line entry becomes negative, the latter is removed, and for the new head-of-line entry we subtract <i>q<sup>x</sup></i> from both the lower and upper bounds, as well as any reminder from the previous transmission.</li></ul></p><p id="p0092" num="0092">This makes it possible to update the VQ in constant time, without worsening the length estimate of both the head-of-line packet and the whole queue, which are normally the most important information taken into account at the scheduler. For instance, the HY-CART scheduler needs only the first one in order to make its decisions. However, one may not be able to correctly assess the length of the queue up to the <i>x</i><sup>th</sup> packet, 1&lt;<i>x</i>&lt;<i>N</i>, at least not without tolerating Θ(<i>N</i>) operations.</p><p id="p0093" num="0093">As already anticipated, in various embodiments, in case the arrival process for the information units at the<!-- EPO <DP n="25"> --> UE is known to be periodic, an improved estimate of the queue length may be obtained by periodically increasing the queue length by a fixed amount and subtracting the number of detected information units transmitted from the UE to the base station. The estimated queue length may be compared to the quantized queue length information reported by the UE, and any mismatch in the above comparison is used to infer the onset and the termination of periodic packet generation at the UE.</p><p id="p0094" num="0094">In the presence of flow profile information, the VQ procedure described in the foregoing can however be employed with any kind of traffic, as it does not rely on additional information on the flow profile (e.g., whether the traffic is periodic or not). However, in the presence of flow profile information, the VQ procedure can be specialized.</p><p id="p0095" num="0095">The following is a description of how flow profile information (whether provided as an input or inferred from the VQ procedure) can be used to specialize the VQ procedure, and to design a specialized VQ procedure version for CBR on/off flows. CBR flows can be considered as a subcase of CBR on/off flows, with an arbitrarily long "on" period. Moreover, the quasi-CBR case can be readily derived through straightforward modifications starting from the CBR on/off case.</p><p id="p0096" num="0096">For CBR on/off, the size of a packet is constant, on and off periods are one order of magnitude larger than the packet generation period. Under these hypotheses, the VQ procedure can be specialized as follows.</p><p id="p0097" num="0097">Assume for the sake of discussion that the packet period is equal to x TTI, where x is an integer (this hypothesis is made solely for the sake of simplicity, and is in no way mandatory). Then:<!-- EPO <DP n="26"> -->
<ul><li>within a talkspurt, every x TTI insert a constant length packet in the VQ;</li><li>whenever the SI, computed on the VQ, is larger than the reported SI, assume that a silence period has begun, stop generating packets and remove the exceeding entries from the tail of the VQ.</li></ul></p><p id="p0098" num="0098">The TTI when a packet is generated, from which all the packet generation instants can be estimated, can be detected, for instance, if one receives two consecutive SI which reveal a packet generation. For instance, assuming a 2 TTI period for 1-PDU packets, if <i>SI</i>(<i>i</i>)=4, <i>SI</i>(<i>i</i>+1)=5, then packets are generated at time i = 5+2·<i>k</i>, <i>k</i>≥0.</p><p id="p0099" num="0099">If, as it happens with some voice codecs, packets have a non-integer period (e.g., 33.3ms, i.e. 10/3 of a 10ms TTI), then the computations - although conceptually simple - may be slightly more involved, but otherwise practicable with conventional means. In fact, in this case, knowing the period and the TTI of the first packet of a talkspurt may not be sufficient to determine the TTIs when packets are generated: the offset with respect to the TTI boundary, i.e. whether 0≤0<i>o</i>&lt;1/3, 1/3≤<i>o</i>&lt;2/3, 2/3≤<i>o</i>&lt;1 in this case, can be determined as schematically shown in <figref idrefs="f0002">Figure 3</figref>, which shows illustrative sequences of packets depending on the initial offset, with an exemplary period equal to 10/3 TTI.</p><p id="p0100" num="0100">A condition used to detect the generation of a packet may be an increase in the reported SI. This means that one may implicitly assume that, during a silence period, the UE queue can be drained sufficiently, so that there is no ambiguity in the detection of the first packet. Such assumptions are reasonable, since the duration of a silence period is considerably larger than the packet period and the ambiguous region starts when there are several (e.g.,<!-- EPO <DP n="27"> --> more than 5) packets in the queue. Similarly, the onset of a silence period is detected through mismatch between the SI and the VQ length. Again, this condition might be detected with some delay if the UE queue is in the ambiguous region when this happens. However, late detection of a silence period is not particularly harmful, since the VQ is rapidly reset to the correct length, and virtual packets entered by mistake have little, if any, chance of being seen by the scheduler.</p><p id="p0101" num="0101">As already shown previously, the signaling delay associated to SI reporting and SG scheduling amounts to at least two TTIs, assuming that at time <i>T</i><sub><i>k</i>+1</sub> the NodeB can issue a SG which takes into account the SI sent by the UE at time <i>T<sub>k</sub></i>. The latter is unavoidable if reactive SG scheduling is used, even if an UE queue is always emptied right after each non-zero SI report. As the TTI duration in HSUPA can be as high as 10ms, 20ms of added delay in the uplink direction are not negligible, especially with voice applications.</p><p id="p0102" num="0102">However, such a delay can be removed by employing a proactive SG assignment scheme, by exploiting the VQ procedure and the prediction of the time instants at which packets are generated. In fact, if the packet length and generation instants are known, SG can be scheduled based on the presumed backlog state of the UE at the time when the SG will actually be used. For instance, if the NodeB knows that voice packets are generated each 20 ms (i.e., every other TTI) starting from time 0, it can schedule a SG large enough to hold two packets at time 2, and periodically schedule another SG for one packet, as shown in <figref idrefs="f0003">Figure 4</figref>, which is representative of a high level example of proactive scheduling.<!-- EPO <DP n="28"> --></p><p id="p0103" num="0103">It will be appreciated that the figure slightly abuses the notation for the sake of conciseness, assuming that SG(2p) means an SG large enough to transmit two packets of length p. Furthermore, non interesting quantities (e.g., the SI generated at the UE at time 2) are not shown for ease of reading.</p><p id="p0104" num="0104">In this way the delay of each packet (under ideal channel conditions) is reduced to 1.5 TTI on average, which is actually the lower bound. The VQ procedure can then be run at <i>T<sub>k</sub></i>, by predicting the SI that the UE is going to send at <i>T</i><sub><i>k</i>+1</sub> (when in fact it will use the grant that the NodeB is computing), to assign SG based on the estimated state of the VQ at time <i>T</i><sub><i>k</i>+1</sub>.</p><p id="p0105" num="0105">In this example, assuming a CBR on/off flow, proactive scheduling would yield a benefit in terms of delay for each packet in a talkspurt except the first one. In fact, the beginning of a talkspurt can only be detected by looking at the SI (i.e., reactively), so that the first packet actually has a higher delay (3.5 TTI on average) than the rest. Likewise, since the onset of a silence period can only be detected reactively, i.e. through a mismatch between the VQ and the SI, an SG will be wasted at the end of each talkspurt (unless the UE has lower priority traffic to send). Given that the average number of voice packets in a talkspurt is rather large, and that the SG required for servicing a voice packet is normally small, this results in a negligible waste of cell capacity. Obviously, channel conditions may be taken into account for scheduling decisions. In that case, being proactive increases by two (i.e., the number of TTIs in the signaling delay) the number of scheduling opportunities for a packet, thus possibly allowing for a better exploitation of the variable<!-- EPO <DP n="29"> --> channel characteristics.</p><p id="p0106" num="0106">Proactive scheduling may be enforced once the packet generation pattern of the flow is known. For that reason, each flow may be associated to a proactive Boolean variable, which is initially false and is set to true whenever the NodeB has achieved enough information on the packet generation pattern. It may then become false again if packet generation becomes too jittery (possibly because of operating system overhead at the sending application or due to clock skews) or unknown (e.g., at the beginning of a silence period for a CBR on/off voice flow). Thus, proactive and reactive grant scheduling can be mixed for the various flows at a given time.</p><p id="p0107" num="0107">This point can be investigated more in detail with reference of <figref idrefs="f0003">figure 5</figref>, which is representative of relevant quantities in proactive scheduling again between a UE and a NodeB.</p><p id="p0108" num="0108">One may assume that scheduling decision is made at time <i>t</i>. At that time, one has <i>SI</i>(<i>t</i>), which was generated at time <i>t</i>-1 at the UE. On the other hand, the SG being computed will be used at time <i>t</i>+1 at the UE.</p><p id="p0109" num="0109">Therefore, one takes into account:
<ul><li>the packets generated between <i>t</i>-1 and <i>t</i>+1 at the UE;</li><li>the PDUs transmitted by the UE at time <i>t</i>, according to the SG that was sent at time <i>t</i>-1.</li></ul></p><p id="p0110" num="0110">Therefore, at time <i>t</i> the NodeB will:
<ul><li>update the VQ including <i>SI</i>(<i>t</i>)</li><li>compute the predicted state of VQ at time <i>t</i><sup>-</sup>, <i>VQ</i>|<i><sub>t</sub></i>-(which would be known at <i>t</i>+1), by predicting the arrivals in [<i>t</i>-1,<i>t</i>) according to the flow profile<!-- EPO <DP n="30"> --></li><li>starting from <i>VQ</i>|<i><sub>t</sub></i>-, compute the amount of PDUs that the UE will transmit at time <i>t</i> as the minimum between those allowed by the SG issued at time <i>t</i>-1 and those in <i>VQ</i>|<i><sub>t</sub></i>-<i>.</i> Those PDUs will not need be reported any more once they have been sent to the H-ARQ process for transmission (even if they need retransmitting). This allows one to compute <i>VQ</i>|<i><sub>t<sub2>+</sub2></sub></i></li><li>compute the predicted state of VQ at time (<i>t</i>+1)<sup>-</sup>, VQ|<sub>(<i>t</i>+1)</sub>- (which would be known at <i>t</i>+2), by predicting the arrivals in (<i>t</i>, <i>t</i>+1) according to the flow profile.</li></ul></p><p id="p0111" num="0111">It may happen that, at some time, the UE is not eligible for transmitting new PDUs, since a retransmitting H-ARQ process has its turn. In that case, the NodeB will simply skips the UE for allocating grants.</p><p id="p0112" num="0112">Proactive scheduling can be employed with CBR and CBR on/off flows, provided that the correct VQ procedure is used for each flow.</p><p id="p0113" num="0113">Various embodiments enable a scheduler to perform scheduling of real-time uplink flows by reconstructing, through a Virtual Queueing technique, the status of the uplink buffers. The outcome of such a technique is that the scheduler possesses a virtualized version of the uplink flow buffer, where virtual packets are associated to their estimated size and generation time.</p><p id="p0114" num="0114">Various embodiments will thus enable a scheduler to make real-time decisions (e.g., schedule PDUs by deadline), which could not be possible otherwise.</p><p id="p0115" num="0115">Various embodiments of Virtual Queueing techniques considered herein can be applied to any system (e.g., cellular ones) where, e.g.:<!-- EPO <DP n="31"> -->
<ul><li>packets are segmented into a number of fixed-length PDUs, whose length is known at both the sender and the receiver, such a length not having to be the same for all senders;</li><li>the status of uplink buffers is reported under the form of a number of PDUs, in either a coarsened and an exact version, either periodically or non periodically;</li><li>the receiver (of buffer status reports) decides scheduling grants for the senders;</li><li>both the High Speed Uplink Packet Access (HSUPA) and the Long Term Evolution (LTE) of the UMTS verify all three conditions.</li></ul></p><p id="p0116" num="0116">Various embodiments concern a standard Virtual Queueing technique, which does not make any assumptions on the packet generation process, thus being suitable for any kind of real-time traffic (whether CBR or not).</p><p id="p0117" num="0117">Various embodiments concern a specialized VQ version for CBR (or CBR on/off, or Quasi-CBR) traffic, which capitalizes on knowing the packet size and period of a connection.</p><p id="p0118" num="0118">In the latter case, a proactive version of the scheduling process can be adopted at the scheduler. In this, the scheduler computes its scheduling grants based not only on the (state) information arrived at previous reporting intervals, but on the predicted state of the queue at the moment the grant will be actually used.</p><p id="p0119" num="0119">A main benefit of using VQ techniques lies in that a number of schedulers which could not be used in an uplink context (i.e., those that need to know the packet arrival time in order to make a decision) can now be employed in conjunction with VQ.</p><p id="p0120" num="0120">This disclosure demonstrates the effectiveness of various embodiments of VQ used in conjunction with e.g. a<!-- EPO <DP n="32"> --> HY-CART scheduler, originally designed for HSDPA connections.</p><p id="p0121" num="0121">Performance evaluations performed by the applicants show significant benefits in using the three techniques.</p><p id="p0122" num="0122">Without prejudice to the underlying principles of the invention, the details and the embodiments may vary, even appreciably, with respect to what has been described by way of example only, without departing from the scope of the invention as defined by the annexed claims.</p></description><claims mxw-id="PCLM56984324" lang="DE" load-source="patent-office"><!-- EPO <DP n="36"> --><claim id="c-de-01-0001" num="0001"><claim-text>Verfahren zum Abschätzen, an einem ersten Punkt (NodeB) eines Kommunikationsnetzwerkes, der Länge einer Warteschlange von Informationseinheiten, die an den ersten Punkt (NodeB) von einem zweiten Punkt (UE) in dem Netzwerk zu übertragen sind, wobei das Verfahren umfasst, dass der erste Punkt (NodeB) von dem zweiten Punkt (UE) quantisierte Warteschlangenlängeninformationen empfängt, wobei die quantisierten Warteschlangenlängeninformationen eine untere Grenze und eine obere Grenze der Warteschlangenlänge anzeigen, wobei das Verfahren Folgendes umfasst:
<claim-text>- Detektieren, an dem ersten Punkt (NodeB), einer Übertragung von Informationseinheiten von dem zweiten Punkt (UE) zu dem ersten Punkt (NodeB), und</claim-text>
<claim-text>- Erzeugen einer verbesserten Abschätzung der Warteschlangenlänge durch ein Korrigieren der unteren Grenze und der oberen Grenze durch eine Subtraktion der Anzahl von detektierten Informationseinheiten, die von dem zweiten Punkt (UE) zu dem ersten Punkt (NodeB) übertragen wurden, <b>dadurch gekennzeichnet, dass</b> Folgendes umfasst ist:</claim-text>
<claim-text>- Detektieren, dass die verbesserte Abschätzung der Warteschlangenlänge inkonsistent wird, da die entsprechende untere Grenze höher wird als die entsprechende obere Grenze,</claim-text>
<claim-text>- erneutes Starten der Berechnung der verbesserten Abschätzung der Warteschlangenlänge durch ein erneutes Starten des Korrigierens der unteren Grenze und der oberen Grenze durch Subtraktion der Anzahl von delektierten Informationseinheiten, die von dem zweiten Punkt (UE) zu dem ersten Punkt (NodeB) übertragen wurden.</claim-text></claim-text></claim><claim id="c-de-01-0002" num="0002"><claim-text>Verfahren nach Anspruch 1, welches ein Berechnen einer verbesserten Abschätzung der Warteschlangenlänge zu einer Zeit i durch ein Berechnen der unteren Grenze beziehungsweise der oberen Grenze der Waueschlangenlänge als das Maximum beziehungsweise des Minimums der Differenz zwischen der unteren beziehungsweise der oberen Grenze der quantisieren Warteschlangenlängeninformation,<!-- EPO <DP n="37"> --> wie sie durch den zweiten Punkt (UE) zu einer früheren Zeit j bereitgestellt wurden, und der Gesamtzahl der detektierten Informationseinheiten, die von dem zweiten Punkt (UE) zu dem ersten Punkt (NodeB) über das Intervall zwischen dem früheren Zeitpunkt j und der Zeit i übertragen wurden.</claim-text></claim><claim id="c-de-01-0003" num="0003"><claim-text>Verfahren nach Anspruch 1, weiter umfassend das Nehmen der verbesserten Abschätzung, die inkonsistent wird, als eine Darstellung von zumindest einer neuen Informationseinheit, die zur Warteschlange hinzugekommen ist.</claim-text></claim><claim id="c-de-01-0004" num="0004"><claim-text>Verfahren nach einem der Ansprüche 1 bis 3, welches weiter umfasst, dass der erste Punkt (NodeB) an den ersten Punkt (UE) Planungsinformationen für das Übertragen der Informationseinheiten von dem zweiten Punkt (UE) zu dem ersten Punkt (NodeB) überträgt, wobei die Planungsinformation als eine Funktion der verbesserten Abschätzung der Warteschlangenlänge erzeugt wird.</claim-text></claim><claim id="c-de-01-0005" num="0005"><claim-text>Verfahren nach einem der vorhergehenden Ansprüche, welches weiter ein Empfangen der Informationseinheiten an dem ersten Punkt (NodeB) als ein Aufwärtsstrecken-Pakettrafik in dem Kommunikationsnetzwerk umfasst.</claim-text></claim><claim id="c-de-01-0006" num="0006"><claim-text>Verfahren nach Anspruch 4, welches weiter ein Auswählen eines NodeB in HSUPA oder LTE als den ersten Punkt umfasst.</claim-text></claim><claim id="c-de-01-0007" num="0007"><claim-text>Knoten in einem Kommunikationsnetzwerk, wobei der Knoten (NodeB) von einem Nutzer (UE) in dem Netzwerk Informationen über die Länge einer Warteschlange von Informationseinheiten, die zu dem Knoten (NodeB) von dem Nutzer (UE) zu übertragen sind, empfangen kann, wobei die Informationen in Form von quantisierten Längeninformationen vorliegen, die eine untere Grenze und eine obere Grenze der Warteschlangenlängen anzeigen, wobei der Knoten ausgebildet ist, um das Verfahren nach einem der Ansprüche 1 bis 6 auszuführen.<!-- EPO <DP n="38"> --></claim-text></claim><claim id="c-de-01-0008" num="0008"><claim-text>Computerprogrammprodukt, welches in einem Speicher von zumindest einem Computer ladbar ist, und Softwarecodeteile umfasst, um die Schritte des Verfahrens nach einem der Ansprüche 1 bis 6 auszuführen.</claim-text></claim></claims><claims mxw-id="PCLM56984325" lang="EN" load-source="patent-office"><!-- EPO <DP n="33"> --><claim id="c-en-01-0001" num="0001"><claim-text>A method of estimating, at a first point (NodeB) of a communication network, the length of a queue of information units to be transmitted to said first point (NodeB) from a second point (UE) in said network, the method including said first point (NodeB) receiving from said second point (UE) quantized queue length information, said quantized queue length information being indicative of a lower bound and an upper bound for said queue length, the method including:
<claim-text>- detecting at said first point (NodeB) transmission of information units from said second point (UE) to said first point (NodeB), and</claim-text>
<claim-text>- producing an improved estimate of said queue length by correcting said lower bound and said upper bound via subtraction of the number of the detected information units transmitted from said second point (UE) to said first point (NodeB), <b>characterized by</b> further including:</claim-text>
<claim-text>- detecting said improved estimate of said queue length becoming inconsistent due to the respective lower bound becoming higher than the respective upper bound,</claim-text>
<claim-text>- restarting computing said improved estimate of said queue length by restarting correcting said lower bound and said upper bound by subtraction of the number of the detected information units transmitted from said second point (UE) to said first point (NodeB).</claim-text></claim-text></claim><claim id="c-en-01-0002" num="0002"><claim-text>The method of claim 1, including computing an improved estimate on said queue length at a time i by computing said lower, respectively upper bound of the queue length as the maximum, respectively the minimum, of the difference between the lower, respectively the upper, bound<!-- EPO <DP n="34"> --> for said quantized queue length information as provided by said second point (UE) at an earlier time j and the total number of the detected information units transmitted from said second point (UE) to said first point (NodeB) over the interval between said earlier time j and said time i.</claim-text></claim><claim id="c-en-01-0003" num="0003"><claim-text>The method of claim 1, including taking said improved estimate becoming inconsistent as representative of at least one new information unit having joined said queue.</claim-text></claim><claim id="c-en-01-0004" num="0004"><claim-text>The method of any of claims 1 to 3, including said first point (NodeB) sending to said second point (UE) scheduling information for transmitting said information units from said second point (UE) to said first point (NodeB), said scheduling information being generated as a function of said improved estimate on said queue length.</claim-text></claim><claim id="c-en-01-0005" num="0005"><claim-text>The method of any of the previous claims, including receiving said information units at said first point (NodeB) as uplink packet traffic in said communication network.</claim-text></claim><claim id="c-en-01-0006" num="0006"><claim-text>The method of claim 4, including selecting as said first point a NodeB in HSUPA or LTE.</claim-text></claim><claim id="c-en-01-0007" num="0007"><claim-text>A node in a communication network, said node (NodeB) to receive from a user (UE) in said network information on the length of a queue of information units to be transmitted to said node (NodeB) from said user (UE) said information being in the form of quantized queue length information indicative of a lower bound and an upper bound for said queue length, the node configured for<!-- EPO <DP n="35"> --> performing the method of any of claims 1 to 6.</claim-text></claim><claim id="c-en-01-0008" num="0008"><claim-text>A computer program product, loadable in the memory of at least one computer and including software code portions for performing the steps of the method of any of claims 1 to 6.</claim-text></claim></claims><claims mxw-id="PCLM56984326" lang="FR" load-source="patent-office"><!-- EPO <DP n="39"> --><claim id="c-fr-01-0001" num="0001"><claim-text>Procédé d'estimation, au niveau d'un premier point (NodeB) d'un réseau de communication, de la longueur d'une file d'attente d'unités d'informations à transmettre audit premier point (NodeB) depuis un second point (UE) dans ledit réseau, le procédé comprenant la réception par ledit premier point (NoeudB) en provenance dudit second point (UE) d'informations de longueur de file d'attente quantifiées, lesdites informations de longueur de file d'attente quantifiées étant indicatives d'une limite inférieure et d'une limite supérieure pour ladite longueur de file d'attente, le procédé comprenant :
<claim-text>- la détection au niveau dudit premier point (NodeB) d'une transmission d'unités d'informations depuis ledit second point (UE) audit premier point (NodeB), et</claim-text>
<claim-text>- la production d'une estimation améliorée de ladite longueur de file d'attente en corrigeant ladite limite inférieure et ladite limite supérieure via une soustraction du nombre des unités d'informations détectées transmises depuis ledit second point (UE) audit premier point (NodeB), <b>caractérisé en ce qu'</b>il comprend en outre :</claim-text>
<claim-text>- la détection de ladite estimation améliorée de ladite longueur de file d'attente deviennant incohérente en raison du fait que la limite inférieure respective devienne plus élevée que la limite supérieure respective,<!-- EPO <DP n="40"> --></claim-text>
<claim-text>- le redémarrage d'un calcul de ladite estimation améliorée de ladite longueur de file d'attente en redémarrant une correction de ladite limite inférieure et de ladite limite supérieure par soustraction du nombre des unités d'informations détectées transmises depuis ledit second point (UE) audit premier point (NodeB).</claim-text></claim-text></claim><claim id="c-fr-01-0002" num="0002"><claim-text>Procédé selon la revendication 1, comprenant le calcul d'une estimation améliorée sur ladite longueur de file d'attente à un instant i en calculant ladite limite inférieure, respectivement la limite supérieure de la longueur de file d'attente comme le maximum, respectivement le minimum, de la différence entre la limite inférieure, respectivement la limite supérieure, pour lesdites informations de longueur de file d'attente quantifiées telles qu'elles sont fournies par ledit second point (UE) à un temps antérieur j et du nombre total des unités d'informations détectées transmises depuis ledit second point (UE) audit premier point (NodeB) sur l'intervalle entre ledit temps antérieur j et ledit temps i.</claim-text></claim><claim id="c-fr-01-0003" num="0003"><claim-text>Procédé selon la revendication 1, comprenant le fait de prendre le fait que ladite estimation améliorée deviennant incohérente comme représentatif du fait qu'au moins une nouvelle unité d'informations ait rejoint ladite file d'attente.</claim-text></claim><claim id="c-fr-01-0004" num="0004"><claim-text>Procédé selon l'une quelconque des revendications 1 à 3, comprenant l'envoi par ledit premier point (NodeB) audit second point (UE) d'informations d'ordonnancement pour transmettre lesdites unités d'informations depuis ledit second<!-- EPO <DP n="41"> --> point (UE) audit premier point (NodeB), lesdites informations d'ordonnancement étant générées en fonction de ladite estimation améliorée sur ladite longueur de file d'attente.</claim-text></claim><claim id="c-fr-01-0005" num="0005"><claim-text>Procédé selon l'une quelconque des revendications précédentes, comprenant la réception desdites unités d'informations au niveau dudit premier point (NoeudB) en tant que trafic de paquets en liaison montante dans ledit réseau de communication.</claim-text></claim><claim id="c-fr-01-0006" num="0006"><claim-text>Procédé selon la revendication 4, comprenant la sélection en tant que dit premier point d'un noeudB en HSUPA ou LTE.</claim-text></claim><claim id="c-fr-01-0007" num="0007"><claim-text>Noeud dans un réseau de communication, ledit noeud (NodeB) permettant de recevoir depuis un utilisateur (EU) dans ledit réseau des informations sur la longueur d'une file d'attente d'unités d'informations à transmettre audit noeud (NodeB) depuis ledit utilisateur (UE), lesdites informations étant sous forme d'informations de longueur de file d'attente quantifiées indicatives d'une limite inférieure et d'une limite supérieure pour ladite longueur de file d'attente, le noeud étant configuré pour réaliser le procédé selon l'une quelconque des revendications 1 à 6.</claim-text></claim><claim id="c-fr-01-0008" num="0008"><claim-text>Produit de programme informatique, pouvant être chargé dans la mémoire d'au moins un ordinateur et comprenant des portions de code logiciel pour réaliser les étapes du procédé selon l'une quelconque des revendications 1 à 6.</claim-text></claim></claims><drawings mxw-id="PDW16671821" load-source="patent-office"><!-- EPO <DP n="42"> --><figure id="f0001" num="1,2"><img id="if0001" file="imgf0001.tif" wi="148" he="195" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="43"> --><figure id="f0002" num="3"><img id="if0002" file="imgf0002.tif" wi="96" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="44"> --><figure id="f0003" num="4,5"><img id="if0003" file="imgf0003.tif" wi="111" he="209" img-content="drawing" img-format="tif"/></figure></drawings><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
