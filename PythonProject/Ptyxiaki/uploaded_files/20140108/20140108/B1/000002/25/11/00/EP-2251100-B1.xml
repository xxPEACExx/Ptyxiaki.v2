<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2251100-B1" country="EP" doc-number="2251100" kind="B1" date="20140108" family-id="39796858" file-reference-id="315025" date-produced="20180825" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="146587986" ucid="EP-2251100-B1"><document-id><country>EP</country><doc-number>2251100</doc-number><kind>B1</kind><date>20140108</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-08718455-A" is-representative="YES"><document-id mxw-id="PAPP154850178" load-source="docdb" format="epo"><country>EP</country><doc-number>08718455</doc-number><kind>A</kind><date>20080117</date><lang>ES</lang></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC140552727" ucid="ES-2008070007-W" load-source="docdb"><document-id format="epo"><country>ES</country><doc-number>2008070007</doc-number><kind>W</kind><date>20080117</date></document-id></priority-claim></priority-claims><dates-of-public-availability><intention-to-grant-date><date>20130807</date></intention-to-grant-date></dates-of-public-availability><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL1989324426" load-source="ipcr">B07C   5/34        20060101AFI20090812BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL1989632202" load-source="docdb" scheme="CPC">B07C   5/38        20130101 LI20130917BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989641096" load-source="docdb" scheme="CPC">B07C2501/0081      20130101 LA20130719BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989641663" load-source="docdb" scheme="CPC">B07C   5/342       20130101 LI20130917BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989648151" load-source="docdb" scheme="CPC">B07C2501/0063      20130101 LA20130719BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989650069" load-source="docdb" scheme="CPC">B07C   5/34        20130101 FI20130917BHEP        </classification-cpc><classification-cpc mxw-id="PCL1989651556" load-source="docdb" scheme="CPC">Y10S 209/905       20130101 LA20130518BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT132368591" lang="DE" load-source="patent-office">AUTOMATISCHES SYSTEM UND VERFAHREN ZUR BESTIMMUNG UND EINTEILUNG VON NAHRUNGSMITTELN</invention-title><invention-title mxw-id="PT132368592" lang="EN" load-source="patent-office">AUTOMATIC FOOD DETERMINATION AND GRADING SYSTEM AND METHOD</invention-title><invention-title mxw-id="PT132368593" lang="FR" load-source="patent-office">PROCÉDÉ ET SYSTÈME AUTOMATIQUE DE DÉTERMINATION ET DE CLASSIFICATION D'ALIMENTS</invention-title></technical-data><parties><applicants><applicant mxw-id="PPAR919513586" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>FUNDACION AZTI AZTI FUNDAZIOA</last-name><address><country>ES</country></address></addressbook></applicant><applicant mxw-id="PPAR919526315" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>FUNDACION AZTI-AZTI FUNDAZIOA</last-name></addressbook></applicant><applicant mxw-id="PPAR919533133" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>FUNDACION FATRONIK</last-name><address><country>ES</country></address></addressbook></applicant><applicant mxw-id="PPAR919505995" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>FUNDACION FATRONIK</last-name></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR919510269" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>MARTINEZ DE MARANON IBABE INIGO</last-name><address><country>ES</country></address></addressbook></inventor><inventor mxw-id="PPAR919538859" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>MARTINEZ DE MARANON IBABE, INIGO</last-name></addressbook></inventor><inventor mxw-id="PPAR919020991" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>MARTINEZ DE MARAÑÓN IBABE, Iñigo</last-name><address><street>Txatxarramendi Ugartea z/g</street><city>E-48395 Sukarrieta</city><country>ES</country></address></addressbook></inventor><inventor mxw-id="PPAR919517351" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>RODRIGUEZ FERNANDEZ RAQUEL</last-name><address><country>ES</country></address></addressbook></inventor><inventor mxw-id="PPAR919514675" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>RODRIGUEZ FERNANDEZ, RAQUEL</last-name></addressbook></inventor><inventor mxw-id="PPAR919020992" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>RODRIGUEZ FERNÁNDEZ, Raquel</last-name><address><street>Txatxarramendi Ugartea z/g</street><city>E-48395 Sukarrieta</city><country>ES</country></address></addressbook></inventor><inventor mxw-id="PPAR919514994" load-source="docdb" sequence="3" format="epo"><addressbook><last-name>LASA MORAN AITOR</last-name><address><country>ES</country></address></addressbook></inventor><inventor mxw-id="PPAR919535401" load-source="docdb" sequence="3" format="intermediate"><addressbook><last-name>LASA MORAN, AITOR</last-name></addressbook></inventor><inventor mxw-id="PPAR919020996" load-source="patent-office" sequence="3" format="original"><addressbook><last-name>LASA MORÁN, Aitor</last-name><address><street>Paseo Mikeletegi 7 Parque Tecnológico</street><city>E-20009 Donostia-San Sebastian</city><country>ES</country></address></addressbook></inventor></inventors><assignees><assignee mxw-id="PPAR919020994" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Fundacion Azti-azti Fundazioa</last-name><iid>101126410</iid><address><street>Txatxarramendi Ugartea, z/g</street><city>48395 Sukarrieta</city><country>ES</country></address></addressbook></assignee><assignee mxw-id="PPAR919020995" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>FUNDACION FATRONIK</last-name><iid>101126411</iid><address><street>Paseo Mikeletegi, 7 Parque Tecnologico</street><city>20009 Donostia-San Sebastian</city><country>ES</country></address></addressbook></assignee></assignees><agents><agent mxw-id="PPAR919020993" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Ezcurra Zufia, Maria Antonia</last-name><iid>101194631</iid><address><street>C/ Iparraguirre, 15 - 2° a</street><city>48009 Bilbao</city><country>ES</country></address></addressbook></agent></agents></parties><international-convention-data><pct-or-regional-filing-data ucid="ES-2008070007-W"><document-id><country>ES</country><doc-number>2008070007</doc-number><kind>W</kind><date>20080117</date><lang>ES</lang></document-id></pct-or-regional-filing-data><pct-or-regional-publishing-data ucid="WO-2009090279-A1"><document-id><country>WO</country><doc-number>2009090279</doc-number><kind>A1</kind><date>20090723</date><lang>ES</lang></document-id></pct-or-regional-publishing-data><designated-states><ep-contracting-states><country mxw-id="DS549780084" load-source="docdb">AT</country><country mxw-id="DS549868340" load-source="docdb">BE</country><country mxw-id="DS549870315" load-source="docdb">BG</country><country mxw-id="DS549922160" load-source="docdb">CH</country><country mxw-id="DS549868341" load-source="docdb">CY</country><country mxw-id="DS549865903" load-source="docdb">CZ</country><country mxw-id="DS549887601" load-source="docdb">DE</country><country mxw-id="DS549868346" load-source="docdb">DK</country><country mxw-id="DS549868347" load-source="docdb">EE</country><country mxw-id="DS549796367" load-source="docdb">ES</country><country mxw-id="DS549870316" load-source="docdb">FI</country><country mxw-id="DS549870317" load-source="docdb">FR</country><country mxw-id="DS549887606" load-source="docdb">GB</country><country mxw-id="DS549868348" load-source="docdb">GR</country><country mxw-id="DS549887607" load-source="docdb">HR</country><country mxw-id="DS549865904" load-source="docdb">HU</country><country mxw-id="DS549922161" load-source="docdb">IE</country><country mxw-id="DS549868349" load-source="docdb">IS</country><country mxw-id="DS549870318" load-source="docdb">IT</country><country mxw-id="DS549868362" load-source="docdb">LI</country><country mxw-id="DS549870319" load-source="docdb">LT</country><country mxw-id="DS549780093" load-source="docdb">LU</country><country mxw-id="DS549870320" load-source="docdb">LV</country><country mxw-id="DS549870321" load-source="docdb">MC</country><country mxw-id="DS549780094" load-source="docdb">MT</country><country mxw-id="DS549868363" load-source="docdb">NL</country><country mxw-id="DS549887608" load-source="docdb">NO</country><country mxw-id="DS549868364" load-source="docdb">PL</country><country mxw-id="DS549870338" load-source="docdb">PT</country><country mxw-id="DS549865905" load-source="docdb">RO</country><country mxw-id="DS549868365" load-source="docdb">SE</country><country mxw-id="DS549922162" load-source="docdb">SI</country><country mxw-id="DS549887609" load-source="docdb">SK</country><country mxw-id="DS549780095" load-source="docdb">TR</country></ep-contracting-states></designated-states></international-convention-data></bibliographic-data><description mxw-id="PDES63960416" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><heading id="h0001"><b><u>OBJECT OF THE INVENTION</u></b></heading><p id="p0001" num="0001">The present invention relates to an automatic system and method for the determination and classification of foods.</p><p id="p0002" num="0002">The invention is based on a high-speed manipulation robot assisted by a localization system, which is capable of detecting foods which come along a conveyor belt in a random fashion and without contact with one another, and classifying them according to own characteristics. The robot incorporates a robotized manipulation grip wherein at least one sensor which permits the classification of food is housed.</p><heading id="h0002"><b><u>BACKGROUND OF THE INVENTION</u></b></heading><p id="p0003" num="0003">There are automatic methods for the classification of foods such as patent document <patcit id="pcit0001" dnum="US4884696A"><text>US4884696</text></patcit>. This document discloses an automatic method of classifying objects of different shapes.</p><p id="p0004" num="0004">In this invention, different sensors are found throughout the path that the object to classify will make. A wheel with grips rotates the products so that all it sides can be seen.</p><p id="p0005" num="0005">It Is known in the state of the art a weighing and portioning technique as the one disclosed in <patcit id="pcit0002" dnum="WO0122043A"><text>WO 0122043</text></patcit> wherein said technique is based on a so called grader technique, where a number of items which are to be portioned out, namely natural foodstuff items with varying weight, are subjected to an weighing-in and are thereafter selectively fed together in a computer-controlled manner to receiving stations for the building-up of weight-determined portion in these stations.</p><p id="p0006" num="0006">Another document related with the object of the present invention, is <patcit id="pcit0003" dnum="WO2007083327A"><text>WO2007/083327</text></patcit>, where is disclosed an apparatus for grading articles based on at least one characteristics of the articles.</p><p id="p0007" num="0007">The present invention discloses an automatic system method for the classification of different foods, wherein the foods enter through a transport system and their presence is detected by a localization system, without having to move or rotate the food, and once the food and its position on the conveyor belt have been recognized by said system, a robotized grip which has at least one sensor, classifies the food.</p><heading id="h0003"><b><u>DESCRIPTION OF THE INVENTION</u></b></heading><!-- EPO <DP n="2"> --><p id="p0008" num="0008">The present invention aims to resolve the problem of determining and classifying, in an automatic fashion, foods.</p><p id="p0009" num="0009">The solution is to develop an automatic system which is capable of determining characteristics typical of each food and classifying them in accordance with them.</p><p id="p0010" num="0010">In a first aspect of the invention, it relates to an automatic method for the determination and classification of foods, which comprises, at least, the following stages:
<ul><li>feeding of the food to be classified into a transport system along which the food moves,</li><li>determination using a localization system of the position, orientation, geometry and size of the food,</li><li>positioning of a robotized grip on the food, thanks to the information obtained by the localization system,</li><li>data collection using a sensor present in the robotized grip and classification of the food in accordance with the data obtained by the sensor,</li><li>separation of the food classified.</li></ul></p><p id="p0011" num="0011">In a second aspect of the invention, it relates to an automatic system for the determination and classification of foods which comprises at least:
<ul><li>a transport system along which the food moves,</li><li>a localization system of the position, orientation, geometry and size of the food, a robotized grip which is positioned on the food, thanks to the information obtained by the localization system,</li><li>at least one sensor present in the robotized grip for the classification of the food.</li></ul></p><p id="p0012" num="0012">When the present invention speaks of transport system this may be both manual and automatic, such as for example a conveyor belt.</p><p id="p0013" num="0013">When the present specification refers to a localization system, this may be an artificial vision system which functions using microwaves, ultrasounds, infrared, ultraviolet, X-rays or a mechanical system such as, for example, conveyor buckets, etc.</p><p id="p0014" num="0014">The manipulation grip of the foods present en the robot, may act via vacuum, pneumatic, hydraulic or electromechanical actuators or passive methods, among others, so that on the one hand it adapts to the geometry and physical characteristics of the product for its correct manipulation and, on the other hand, to the integrated sensor system, integrated sensor.</p><p id="p0015" num="0015">The sensor collects the data from the outer part of the food or by introducing itself therein.<!-- EPO <DP n="3"> --></p><heading id="h0004"><b><u>PREFERRED EMBODIMENT OF THE INVENTION</u></b></heading><p id="p0016" num="0016">In an example of embodiment of the invention, the food which is going to be classified is fish, and in particular mackerel.</p><p id="p0017" num="0017">The mackerel is introduced via a conveyor belt.</p><p id="p0018" num="0018">This fish is detected by a vision system which permits that the robotized grip is subsequently placed on the mackerel, to collect the data necessary for its classification.</p><p id="p0019" num="0019">In this example of embodiment, the aim is to classify mackerels into male and female.</p><p id="p0020" num="0020">The measurement is made in this example of embodiment by the insertion of a sensor in the food, in particular on or in the fish's gonads. The sensor is present in the robot grip and thanks to the information recovered by the vision system, the sensor will be inserted in a suitable place for the correct determination of the sex.</p><p id="p0021" num="0021">The vision system detects the fish as they move along the conveyor belt and correctly identifies their position and orientation. After detection, the vision system, which has previously been calibrated with respect to the robot and the conveyor belt, performs the transformation of the reference system to send the coordinates of the point where the sensor should be inserted to the robot with the grip.</p><p id="p0022" num="0022">The vision system is composed of three main parts: the illumination system, optics and the software that analyses the images.</p><p id="p0023" num="0023">The illumination system pursues different objectives maintaining a constant illumination in the working area to eliminate variations which hinder or even prevent the work of the analysis software, eliminating the shadows projected by the objects, removing glare and reflections on objects and the belt, maximizing the contrast between the objects to analyse and the background, the conveyor belt.</p><p id="p0024" num="0024">To achieve that the illumination intensity is constant, an enclosure is constructed which isolates the working area from external illumination.</p><p id="p0025" num="0025">The vision system in this example of embodiment has two sources of high-intensity linear illumination. The sources function at a sufficiently high frequency to avoid flashing and fluctuations in intensity.</p><p id="p0026" num="0026">The sources are placed on both sides of the conveyor belt, and at a suitable height thereon. They are place opposite one another, so that the light indirectly hits the conveyor belt, in this way avoiding shadows and glare.</p><p id="p0027" num="0027">To select the suitable optics of the vision system, it is necessary to basically bear in mind the size of the camera sensor, the distance to the<!-- EPO <DP n="4"> --> working plane and the size of the objects that should be detected.</p><p id="p0028" num="0028">For the detection system of the vision system initially, a statistical modelling of the background is made, i.e. the conveyor belt without any fish.</p><p id="p0029" num="0029">In this model each pixel of the image is stored as the sum of several Gaussian functions.</p><p id="p0030" num="0030">The number of Gaussians whereby the model is approximated depends on how flexible and adaptable it is needed to be: between three and five seems a suitable number in the tests.</p><p id="p0031" num="0031">This model is updated during the execution of the algorithm, so that the model is flexible to changes, both progressive and sudden, needing an adaptation time in both cases. To adapt the model and adjust the data obtained to the Gaussians, the Expectation Maximization (EM) algorithm is used. The pixel modelling enables differentiated areas both in colour/material and in illumination in the working area and the adaptation permits flexibility as regards the constancy of the illumination, provided that no saturation occurs in the sensor and the dynamic range is sufficient, and with regard to the colour of the belt, which may vary with time due to wear or dirt.</p><p id="p0032" num="0032">Using the previous statistical model the segmentation is made of the objects placed in the working space. A fixed limit is defined in accordance with the typical deviation of each Gaussian, and it is decided that a specific pixel belongs to an object if its value in the scale of greys is not within the bell defined by any of the Gaussians.</p><p id="p0033" num="0033">Next, an iterative growth algorithm is used of regions in two runs to identify the blobs or connected regions which are then going to be analysed. At this point, a simple filtering will also be performed in accordance with the area, the length and the length/width ratio to discard the most evident regions. Using the moments of inertia of first and second order, the mass centre of the object and its major and minor semi-axes are calculated, which permits identifying the orientation of the fish.</p><p id="p0034" num="0034">To correctly define the piercing area, two different measurements are taken. Initially a longitudinal division is made of the object and the intensity measurement calculated in both halves is compared using the mask obtained in the segmentation. In this way the position of the loin is distinguished with regard to the stomach. Finally, two transversal measurements are taken at a certain distance from the ends to differentiate the head area from the tail. The piercing area can now be calculated with this analysis.</p><p id="p0035" num="0035">The robotized manipulation grip of the fish present in the robot operates via vacuum, in this example of embodiment.<!-- EPO <DP n="5"> --></p><p id="p0036" num="0036">The grip shows a vacuum suction system and a set of air outlets, at least one is necessary, to grip the fish. These are of bellows type so that they easily adapt to the curvature of the different fish.</p><p id="p0037" num="0037">This system is complemented with at least one prod which permits avoiding the shear stresses on the air outlets, since as the fish and the water environment are very slipup, when the fish is moved laterally at high speed and subjected to high speed rotations and high acceleration, the inertias and the shear stresses are not withstood by the air outlets which mainly work by traction. It is necessary to insert the prods in the fish to avoid shear stresses.</p><p id="p0038" num="0038">To release or leave the fish quickly, not only does it break the vacuum in the system, but additionally blows air through the air outlets, which accelerates the process and also contributes to cleaning the internal areas of the air outlets.</p><p id="p0039" num="0039">Some of the prods, those positioned in the ventral area of the fish have the probe of the sensor which is introduced until the gonads in a protected manner.</p><p id="p0040" num="0040">The sensor is inserted on the fish gonads and analyses the spectrum obtained after the impact of electromagnetic radiation on the gonad, the spectrums of the male and the female being different.</p><p id="p0041" num="0041">Once the decision is made on the sex of the fish, the robotized grip deposits the fish on the correct conveyor belt.</p><p id="p0042" num="0042">Variations in materials, shape, size and arrangement of the component elements, described in non-limitative manner, do not alter the essential characteristics of this invention, it being sufficient to be reproduced by a person skilled in the art.</p></description><claims mxw-id="PCLM56983985" lang="DE" load-source="patent-office"><!-- EPO <DP n="8"> --><claim id="c-de-01-0001" num="0001"><claim-text>Automatische Methode zur Ermittlung und Klassifizierung von Nahrungsmitteln, die mindestens folgende Stufen umfasst:
<claim-text>- Beschickung eines Fördersystems, entlang dessen sich die Nahrungsmittel bewegen, mit den zu klassifizierenden Nahrungsmitteln,</claim-text>
<claim-text>- Ermittlung der Position, Ausrichtung, Geometrie und Größe der Nahrungsmittel mittels eines Lokalisierungssystems,</claim-text>
<claim-text>- daslokalisierungssystem transformiert das Referenzsystem zur Sendung der Koordinaten des Punktes an den Roboter, wo ein Robotergreifer zu positionieren ist,</claim-text>
<claim-text>- Positionierung des Robotergreifers auf die Nahrungsmittel dank der vom Lokalisierungssystem erzielten Information,</claim-text>
<claim-text>- Datenerhebung durch Positionierung eines am Robotergreifer vorhandenen Sensors auf die Nahrungsmittel und Klassifizierung mit den vom Sensor erzielten Daten,</claim-text>
<claim-text>- Trennung der klassifizierten Nahrungsmittel.</claim-text></claim-text></claim><claim id="c-de-01-0002" num="0002"><claim-text>Automatische Methode gemäß Patentanspruch 1, <b>dadurch gekennzeichnet, dass</b> die Trennung der klassifizierten Nahrungsmittel mittels des Robotergreifers erfolgt.</claim-text></claim><claim id="c-de-01-0003" num="0003"><claim-text>Methode gemäß Patentanspruch 1, <b>dadurch gekennzeichnet, dass</b> die Daten vom Sensor durch dessen Einführung in die Nahrungsmittel erhoben werden.</claim-text></claim><claim id="c-de-01-0004" num="0004"><claim-text>Methode gemäß Patentanspruch 1, <b>dadurch gekennzeichnet, dass</b> das klassifizierte Nahrungsmittel Fisch ist.</claim-text></claim><claim id="c-de-01-0005" num="0005"><claim-text>Methode gemäß Patentanspruch 1, <b>dadurch gekennzeichnet, dass</b> die Datenerhebung an den Nahrungsmittelgonaden erfolgt.</claim-text></claim><claim id="c-de-01-0006" num="0006"><claim-text>Automatisches System zur Bestimmung und Klassifizierung von Nahrungsmitteln, das mindestens umfasst:
<claim-text>- Ein Fördersystem, entlang dessen sich die Nahrungsmittel bewegen,</claim-text>
<claim-text>- Ein Lokalisierungssystem der Position, Ausrichtung, Geometrie und Größe der Nahrungsmittel,</claim-text>
<claim-text>- Einen Roboterarm, der dank der vom Lokalisierungssystem erzielten Information auf die Nahrungsmittel positioniert wird,</claim-text>
<claim-text>- Mindestens einen am Roboterarm vorhandenen Sensor für die Klassifizierung der Nahrungsmittel.</claim-text></claim-text></claim><claim id="c-de-01-0007" num="0007"><claim-text>Automatisches System gemäß Patentanspruch 6, <b>dadurch gekennzeichnet, dass</b> das Lokalisierungssystem ein Visionssystem ist.</claim-text></claim></claims><claims mxw-id="PCLM56983986" lang="EN" load-source="patent-office"><!-- EPO <DP n="6"> --><claim id="c-en-01-0001" num="0001"><claim-text>Automatic method for the determination and classification of foods which comprises at least the following stages:
<claim-text>- feeding of the food to be classified into a transport system along which the food moves,</claim-text>
<claim-text>- determination using a localization system of the position, orientation, geometry and size of the food,</claim-text>
<claim-text>- the localization system transforms the reference system to send the coordinates of the point to the robot where a robot grip has to be positioned,</claim-text>
<claim-text>- positioning of the robotized grip on the food, thanks to the information obtained by the localization system,</claim-text>
<claim-text>- data collection using positioning on the food a sensor present in the robotized grip and classification of the food in accordance with the data obtained by the sensor,</claim-text>
<claim-text>- separation of the food classified.</claim-text></claim-text></claim><claim id="c-en-01-0002" num="0002"><claim-text>Automatic method according to claim 1, <b>characterized in that</b> the separation of the food classified is performed using the robotized grip.</claim-text></claim><claim id="c-en-01-0003" num="0003"><claim-text>Method according to claim 1, <b>characterized in that</b> the data is collected by the sensor by introducing it in the food.</claim-text></claim><claim id="c-en-01-0004" num="0004"><claim-text>Method according to claim 1, <b>characterized in that</b> the food classified is fish.</claim-text></claim><claim id="c-en-01-0005" num="0005"><claim-text>Method according to claim 1, <b>characterized in that</b> the data collection is made on the food gonads.</claim-text></claim><claim id="c-en-01-0006" num="0006"><claim-text>Automatic system for the determination and classification of foods which comprises at least:
<claim-text>- a transport system along which the food moves,</claim-text>
<claim-text>- a localization system of the position, orientation, geometry and size of the food,<!-- EPO <DP n="7"> --></claim-text>
<claim-text>- a robotized grip which is positioned on the food, thanks to the information obtained by the localization system,</claim-text>
<claim-text>- at least one sensor present in the robotized grip for the classification of the food</claim-text></claim-text></claim><claim id="c-en-01-0007" num="0007"><claim-text>Automatic system according to claim 6, <b>characterized in that</b> the localization system is a vision system.</claim-text></claim></claims><claims mxw-id="PCLM56983987" lang="FR" load-source="patent-office"><!-- EPO <DP n="9"> --><claim id="c-fr-01-0001" num="0001"><claim-text>Procédé automatique pour la détermination et la classification de la nourriture qui comprend au moins les étapes suivantes:
<claim-text>- alimentation de la nourriture que doit être classée dans un système de transport le long duquel la nourriture se déplace,</claim-text>
<claim-text>- détermination utilisant un système de localisation de la position, l'orientation, la géométrie et la taille de la nourriture,</claim-text>
<claim-text>- le système de localisation transforme le système de référence pour envoyer les coordonnées du point au robot, où une poignée de robot doit être positionné,</claim-text>
<claim-text>- Positionnement de la poignée robotisée sur la nourriture, grâce à l'information obtenue par le système de localisation,</claim-text>
<claim-text>- la collecte de données utilisant le positionnement sur la nourriture d'un capteur présent dans la poignée robotisée et la classification de la nourriture, conformément aux données obtenues par le capteur,</claim-text>
<claim-text>- séparation de la nourriture classée.</claim-text></claim-text></claim><claim id="c-fr-01-0002" num="0002"><claim-text>Procédé automatique selon la revendication 1, <b>caractérisé en ce que</b> la séparation de la nourriture classée est effectuée en utilisant la poignée robotisée.</claim-text></claim><claim id="c-fr-01-0003" num="0003"><claim-text>Procédé selon la revendication 1, <b>caractérisé en ce que</b> les données sont recueillies par le capteur en l'introduisant dans la nourriture.</claim-text></claim><claim id="c-fr-01-0004" num="0004"><claim-text>Procédé selon la revendication 1, <b>caractérisé en ce que</b> la nourriture classée est poisson.</claim-text></claim><claim id="c-fr-01-0005" num="0005"><claim-text>Procédé selon la revendication 1, <b>caractérisé en ce que</b> la collecte de données est effectuée sur les gonades alimentaires.</claim-text></claim><claim id="c-fr-01-0006" num="0006"><claim-text>Système automatique pour la détermination et la classification de la nourriture qui comprend au moins:
<claim-text>- Système de transport le long duquel la nourriture se déplace,</claim-text>
<claim-text>- Un système de localisation de la position, l'orientation, la géométrie et la taille de la nourriture</claim-text>
<claim-text>- Une poignée robotisée qui est positionnée sur la nourriture, grâce à l'information obtenue par le système de localisation,</claim-text>
<claim-text>- Au moins un capteur présent dans la poignée robotisée pour la classification de la nourriture.</claim-text></claim-text></claim><claim id="c-fr-01-0007" num="0007"><claim-text>Système automatique selon la revendication 6, <b>caractérisé en ce que</b> le système de localisation est un système de vision.</claim-text></claim></claims><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
