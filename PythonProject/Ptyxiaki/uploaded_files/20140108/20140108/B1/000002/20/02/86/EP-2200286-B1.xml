<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2200286-B1" country="EP" doc-number="2200286" kind="B1" date="20140108" family-id="37683235" file-reference-id="318244" date-produced="20180826" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="146588207" ucid="EP-2200286-B1"><document-id><country>EP</country><doc-number>2200286</doc-number><kind>B1</kind><date>20140108</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-10158752-A" is-representative="NO"><document-id mxw-id="PAPP154850399" load-source="docdb" format="epo"><country>EP</country><doc-number>10158752</doc-number><kind>A</kind><date>20060719</date><lang>EN</lang></document-id><document-id mxw-id="PAPP246855744" load-source="docdb" format="original"><country>EP</country><doc-number>10158752.5</doc-number><date>20060719</date></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC140553527" ucid="EP-06768290-A" linkage-type="3" load-source="docdb"><document-id format="epo"><country>EP</country><doc-number>06768290</doc-number><kind>A</kind><date>20060719</date></document-id></priority-claim><priority-claim mxw-id="PPC140552504" ucid="JP-2005218064-A" load-source="docdb"><document-id format="epo"><country>JP</country><doc-number>2005218064</doc-number><kind>A</kind><date>20050727</date></document-id></priority-claim></priority-claims><dates-of-public-availability><intention-to-grant-date><date>20130724</date></intention-to-grant-date></dates-of-public-availability><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL1989324964" load-source="docdb">H04N   5/45        20110101AFI20130709BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1989324965" load-source="docdb">H04N   7/173       20110101ALI20130709BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1989324966" load-source="docdb">H04N  21/43        20110101ALI20130709BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1989324967" load-source="docdb">H04N  21/431       20110101ALI20130709BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1989324968" load-source="docdb">H04N  21/84        20110101ALI20130709BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1989621393" load-source="docdb">G09G   5/14        20060101ALI20101217RHJP        </classification-ipcr><classification-ipcr mxw-id="PCL1989639407" load-source="docdb">G09G   5/38        20060101ALI20101217RHJP        </classification-ipcr><classification-ipcr mxw-id="PCL1989650105" load-source="docdb">G09G   5/00        20060101ALI20101217RHJP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL2114867859" load-source="docdb" scheme="CPC">H04N   5/45        20130101 FI20140917BHEP        </classification-cpc><classification-cpc mxw-id="PCL2114871068" load-source="docdb" scheme="CPC">H04N  21/4307      20130101 LI20140917BHEP        </classification-cpc><classification-cpc mxw-id="PCL2114871483" load-source="docdb" scheme="CPC">H04N  21/4316      20130101 LI20140917BHEP        </classification-cpc><classification-cpc mxw-id="PCL2114877621" load-source="docdb" scheme="CPC">H04N  21/84        20130101 LI20140917BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT132369254" lang="DE" load-source="patent-office">Aufzeichnungsmedium zur Wiedergabe durch ein Videosynthesegerät, Datenerzeugungsgerät und Programm</invention-title><invention-title mxw-id="PT132369255" lang="EN" load-source="patent-office">Recording medium to be reproduced by a video synthesizing apparatus, data generating apparatus and program</invention-title><invention-title mxw-id="PT132369256" lang="FR" load-source="patent-office">Support d'enregistrement pour la reproduction au moyen d'un appareil de synthétisation vidéo, appareil de génération de données et programme</invention-title></technical-data><related-documents><relation type="division"><child-doc ucid="EP-10158752-A"><document-id load-source="patent-office" format="epo"><country>EP</country><doc-number>10158752</doc-number><kind>A</kind><date>20060719</date></document-id></child-doc><parent-doc ucid="EP-06768290.6"><document-id load-source="patent-office" format="epo"><country>EP</country><doc-number>06768290.6</doc-number><date>20060719</date></document-id></parent-doc></relation></related-documents><parties><applicants><applicant mxw-id="PPAR919513430" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>SHARP KK</last-name><address><country>JP</country></address></addressbook></applicant><applicant mxw-id="PPAR919537857" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>SHARP KABUSHIKI KAISHA</last-name></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR919539667" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>WATANABE SHUICHI</last-name><address><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR919527297" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>WATANABE, SHUICHI</last-name></addressbook></inventor><inventor mxw-id="PPAR919022034" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>WATANABE, SHUICHI</last-name><address><street>Rapport Honda C-106 2-24-7 Honda-cho Midori-ku Chiba-shi</street><city>Chiba 266-0005</city><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR919541653" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>KIYAMA JIRO</last-name><address><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR919505471" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>KIYAMA, JIRO</last-name></addressbook></inventor><inventor mxw-id="PPAR919022036" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>KIYAMA, JIRO</last-name><address><street>2-31-21-206, Maebaranishi Funabashi-shi Chiba</street><city>Chiba 274-0825</city><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR919511101" load-source="docdb" sequence="3" format="epo"><addressbook><last-name>YAMAGUCHI TAKAYOSHI</last-name><address><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR919515324" load-source="docdb" sequence="3" format="intermediate"><addressbook><last-name>YAMAGUCHI, TAKAYOSHI</last-name></addressbook></inventor><inventor mxw-id="PPAR919022035" load-source="patent-office" sequence="3" format="original"><addressbook><last-name>YAMAGUCHI, TAKAYOSHI</last-name><address><street>6-824 Nishihatsuishi Nagareyama-shi</street><city>Chiba 270-0121</city><country>JP</country></address></addressbook></inventor></inventors><assignees><assignee mxw-id="PPAR919022037" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Sharp Kabushiki Kaisha</last-name><iid>100219336</iid><address><street>22-22, Nagaike-cho Abeno-ku</street><city>Osaka-shi, Osaka 545-8522</city><country>JP</country></address></addressbook></assignee></assignees><agents><agent mxw-id="PPAR919022038" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Treeby, Philip David William</last-name><iid>100057962</iid><address><street>R.G.C. Jenkins &amp; Co 26 Caxton Street</street><city>London SW1H 0RJ</city><country>GB</country></address></addressbook></agent></agents></parties><international-convention-data><designated-states><ep-contracting-states><country mxw-id="DS549875792" load-source="docdb">DE</country><country mxw-id="DS549923129" load-source="docdb">ES</country><country mxw-id="DS549890358" load-source="docdb">FR</country><country mxw-id="DS549875793" load-source="docdb">GB</country><country mxw-id="DS549890359" load-source="docdb">IT</country><country mxw-id="DS549783712" load-source="docdb">NL</country></ep-contracting-states></designated-states></international-convention-data></bibliographic-data><description mxw-id="PDES63960633" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><heading id="h0001">Technical Field</heading><p id="p0001" num="0001">The present invention relates to a video synthesizing apparatus and program which, when first and second videos are input, displays a synthesized video by combining the second video with the first video.</p><heading id="h0002">Background Art</heading><p id="p0002" num="0002">With the development of high-speed network infrastructure and with the development of large capacity recording media, the absolute quantity of video data that can be handled at a time by the user or by user video equipment has markedly increased. With this trend, various functions that are achieved using a plurality of sets of video data and high-performance applications based on such functions have been emerging. As one of such functions, there is a function called "picture in picture".</p><p id="p0003" num="0003">"Picture in picture" is a function for displaying two videos at the same time by superimposing a small child frame<!-- EPO <DP n="2"> --> over the screen (parent frame). This function is used for, for example "multi-angle representation" for displaying, in the child frame, a video taken from a different angle of view from that of the video for the parent frame or for "commentary display" for displaying additional information in a commentary style as to the video of the parent frame (for example, displaying in the child frame a director's commentary video or the like recorded with untold stories during shooting the movie).</p><p id="p0004" num="0004">Picture in picture is realized for example by decoding two sets of video data over two different layers and superimposing these decoded videos, as shown in <figref idrefs="f0017">FIG. 17</figref>. In this case, the video for the child frame is adjusted in its display size and displayed position in order to be laid over the parent frame. Also, the child frame at the time of picture in picture may have a video of an arbitrary shape, other than the rectangular video shown in <figref idrefs="f0017">FIG. 17</figref>. The picture-in-picture function and the method of realizing it are described in for example patent document 1.<br/>
Patent document 1: Japanese Patent Application Laid-open <patcit id="pcit0001" dnum="JP2005123775A"><text>2005-123775</text></patcit></p><p id="p0005" num="0005"><patcit id="pcit0002" dnum="WO2005015899A"><text>WO 2005/015899</text></patcit> discloses a photographing system comprising a photographing section for acquiring a photographed image, a synthesizing/reproducing section for reading out stored data to constitute a scenario video image, a section storing information for synthesizing photographed images into the scenario video image, a synthesis/reproduction control section for synthesizing the scenario video image read out at the synthesizing/reproducing section and the photographed image acquired at the photographing section (18) according to the synthesis information stored at the scenario storage section, and a section for displaying a synthesized video image obtained from the synthesis/reproduction control section.</p><heading id="h0003"><u>Disclosure of Invention</u></heading><heading id="h0004">Problems to be Solved by the Invention</heading><!-- EPO <DP n="3"> --><p id="p0006" num="0006">In the conventional picture in picture, the displayed position of the child frame would have been determined beforehand, and the child frame was displayed at that position.</p><p id="p0007" num="0007">In picture in picture, the video in the child frame is overlapped and displayed over the video in the parent frame, therefore, part of the parent frame video will be hidden by the child-frame video when the child frame is displayed. For this reason, it is preferred that the displayed position of the child frame in the parent frame can be switched in accordance with the changing content of the parent frame video.</p><p id="p0008" num="0008">Further, as one application of using picture in picture, there is a possible configuration in which the child-frame video is given so as to be able to be started to play, paused and restarted, freely at arbitrary points of time within a particular period. The child frame is displayed only when the video is playing. This configuration is utilized when, for example, the child-frame video is one that is added as a privilege video to the parent-frame video and hence it is not necessary for the child-frame video to be exactly synchronized with the parent frame but the child-frame video (privilege video) should be permitted to be played for a particular duration alone in the parent-frame video. Also<!-- EPO <DP n="4"> --> in this case, it is preferred that the displayed position in which the child frame should be displayed on the parent frame is appropriately given in accordance with the content of the parent-frame video every time the child frame is displayed.</p><p id="p0009" num="0009">However, despite such demand there has been no conventional method for giving a changeable displayed position for the child frame in accordance with the change of the parent-frame video as described above. It has been hence impossible to make the above-described application feasible.</p><p id="p0010" num="0010">The present invention has been devised in view of the above problem, it therefore an object to provide data for display that specifies the displayable period, the area to be displayed or displayable area at every moment, as to the displayed position of the child frame during picture-in-picture playback. It is also an object to provide a video synthesizing apparatus and program, which, based on the data for display, can provide the appropriate displayed position of the child frame even when the playback time and stopped time of the child-frame video are freely changed as described above.</p><heading id="h0005">Means for Solving the Problems</heading><!-- EPO <DP n="5"> --><p id="p0011" num="0011">In order to solve the above problem, a recording medium as set out in claim 1 is provided.</p><p id="p0012" num="0012">Also in order to solve the above problem, a data generating apparatus as set out in claim 7 is provided.</p><p id="p0013" num="0013">In addition, a program, for solving the above problem, as set out in claim 13 is provided.</p><p id="p0014" num="0014">Furthermore, a video synthesizing apparatus is provided to solve the above problem, as set out in claim 19.</p><p id="p0015" num="0015">Preferred features are set out in the dependent claims.</p><heading id="h0006">Advantage of the Invention</heading><p id="p0016" num="0016">The invention provides data for display on the displayed position of a child frame during picture-in-picture playback, giving displayable time and the displayed area or displayable area. This data for display either may be included in the video data of the child-frame video or parent-frame video, or may be stored in management data that is independent of the video data and handled with the video data during video transmission or distribution. In the video displaying apparatus and method, the data for display is used to determine the displayed position of the child frame in correspondence with the playback time of the parent (child)-frame video every time it is readout. These configurations, when a child-frame video is synthesized for its display on the parent-frame video in picture in picture, enable the child-frame video to be displayed for playback by displaying it in the suitable<!-- EPO <DP n="6"> --> displayed pos tion. As a result, the child-frame video can be switched freely between display and non-display within the range of the displayable time. Further, every time the child-frame video is switched freely between display and non-display, the child-frame video can be synthesized for its display at an appropriate position. Accordingly, it is possible to perform playback during picture-in-picture in the way the distributor intended.</p><heading id="h0007">Brief Description of Drawings</heading><p id="p0017" num="0017"><ul><li>[<figref idrefs="f0001">FIG. 1] FIG. 1</figref> is a functional block diagram showing a schemat c configuration of a video display apparatus according to the first, second and third embodiments of the present invention.</li><li>[<figref idrefs="f0002">FIG. 2] FIG. 2</figref> is a diagram showing an example of data for display used in the video display apparatus according to the first embodiment of the present invention.</li><li>[<figref idrefs="f0003">FIG. 3] FIG. 3</figref> is a diagram showing another example of data for display used in the video display apparatus according to the first embodiment of the present invention.</li><li>[<figref idrefs="f0004">FIG. 4] FIG. 4</figref> is a diagram showing a variation of data for display used in the video display apparatus according to the first embodiment of the present invention.</li><li>[<figref idrefs="f0005">FIG. 5] FIG. 5</figref> is a diagram showing still another example<!-- EPO <DP n="7"> --> of data for display used in the video display apparatus according to the first embodiment of the present invention.</li><li>[<figref idrefs="f0006">FIG. 6] FIG. 6</figref> is a flow chart showing the processing when a video is displayed on the video display apparatus according to the first, second or third embodiment of the present invention.</li><li>[<figref idrefs="f0007">FIG. 7] FIG. 7</figref> is an illustrative diagram showing a first displaying state when a video is displayed on the video display apparatus according to the first embodiment of the present invention.</li><li>[<figref idrefs="f0008">FIG. 8] FIG. 8</figref> is an illustrative diagram showing a second displaying state when a video is displayed on the video display apparatus according to the first embodiment of the present invention.</li><li>[<figref idrefs="f0009">FIG. 9] FIG. 9</figref> is an illustrative diagram showing a third displaying state when a video is displayed on the video display apparatus according to the first embodiment of the present invention.</li><li>[<figref idrefs="f0010">FIG. 10] FIG. 10</figref> is an illustrative diagram showing a fourth displaying state when a video is displayedon the video display apparatus according to the first embodiment of the present invention.</li><li>[<figref idrefs="f0011">FIG. 11] FIG. 11</figref> is a diagram showing an example of data for display used in the video display apparatus according to the second embodiment of the present invention.<!-- EPO <DP n="8"> --></li><li>[<figref idrefs="f0012">FIG. 12] FIG. 12</figref> is an illustrative diagram showing a first displaying state when a video is displayedon the video display apparatus according to the second embodiment of the present invention.</li><li>[<figref idrefs="f0013">FIG. 13] FIG. 13</figref> is an illustrative diagram showing a second displaying state when a video is displayed on the video display apparatus according to the second embodiment of the present invention.</li><li>[<figref idrefs="f0014">FIG. 14] FIG. 14</figref> is an illustrative diagram showing a third displaying state when a video is displayed on the video display apparatus according to the second embodiment of the present invention.</li><li>[<figref idrefs="f0015">FIG. 15] FIG. 15</figref> is an illustrative diagram showing a fourth displaying state when a video is displayed on the video display apparatus according to the second embodiment of the present invention.</li><li>[<figref idrefs="f0016">FIG. 16] FIG. 16</figref> is a diagram showing a process when a video is displayed on the video display apparatus according to the third embodiment of the present invention.</li><li>[<figref idrefs="f0017">FIG. 17] FIG. 17</figref> is an illustrative diagram showing a method of realizing a conventional picture-in-picture function.</li></ul></p><heading id="h0008">Description of Reference Numerals</heading><p id="p0018" num="0018"><dl id="dl0001" compact="compact"><dt>1, 2, 3,</dt><dd>video display apparatuses<!-- EPO <DP n="9"> --></dd><dt>101, 103</dt><dd>decoders</dd><dt>102, 104</dt><dd>buffering units</dd><dt>105</dt><dd>synthesizer</dd><dt>106</dt><dd>adjuster</dd><dt>107</dt><dd>display unit</dd><dt>108</dt><dd>input unit</dd><dt>109</dt><dd>processing controller</dd><dt>110, 210, 310</dt><dd>position designator</dd></dl></p><heading id="h0009">Best Mode for Carrying Out the Invention</heading><p id="p0019" num="0019">Next, referring to the drawings a video synthesizing apparatus according to the present invention will described in detail when it is applied to a video display apparatus that displays a synthesized video.</p><heading id="h0010">(The first embodiment)</heading><p id="p0020" num="0020">The video display apparatus, method and data for display according to the first embodiment of the present invention will be described with reference to <figref idrefs="f0001 f0002 f0003 f0004 f0005 f0006 f0007 f0008 f0009 f0010">FIGS. 1 to 10</figref>.</p><p id="p0021" num="0021"><figref idrefs="f0001">FIG. 1</figref> is the functional block diagram showing a schematic configuration of a video display apparatus 1 according to the first embodiment of the present invention. Video display apparatus 1 receives two sets of video data (encoded video streams), decodes and combines these to display in a so-called<!-- EPO <DP n="10"> --> "picture-in-picture representation" state. In this specification hereinbelow, the video displayed in the parent frame and the video displayed in the child frame in the picture-in-picture representation will be called "main video" and "sub video", respectively, in distinction from each other.</p><p id="p0022" num="0022">Video display apparatus 1 includes: a decoder 101 and buffering unit 102 for decoding the video data of main video and controlling the output thereof; a decoder 103 and buffering unit 104 for decoding the video data of sub video and controlling the output thereof; a synthesizer 105 with an adjuster 106 incorporated therein for combining the sub video with the main video; and a display unit 107 for displaying the output video. In addition, the apparatus further includes: an input unit 108 for receiving a user's switching instruction for display/non-display of the sub video (child frame) ; a process controller 109 for controlling the processing of decoder 103 and/or buffering unit 104 in accordance with the switching; and a position designator 110 for designating the displayed position of the sub video (child frame) from the data for display and time information during playback as to the sub video, which are separately input. In this specification, this data for display to be used for designating the displayed position of the sub video (child frame) is called "metadata" in contrast to video data.<!-- EPO <DP n="11"> --></p><p id="p0023" num="0023">Here, video display apparatus 1 was described to include decoders 101 and 103, but this is not essential. For example, if the input video data is video data that has not been encoded, video display apparatus 1 does not need to include decoders 101 and 103. Also, video display apparatus 1 in <figref idrefs="f0001">FIG. 1</figref> is constructed of functional blocks regarding the processing of video data (data having to do with video signals) only. However, practical video data includes, other the data involving video signals, audio data and management data (information necessary for decoding encoded data such as encoding system etc., and information necessary for playing video, such as a play list for designating video clipping and joining, and the like), and the actual video display apparatus is constructed further including the functional blocks for processing these. In this case, the configuration in <figref idrefs="f0001">FIG. 1</figref> is installed as an internal structure of the actual video display apparatus.</p><p id="p0024" num="0024">To begin with, description will be made of the processing in video display apparatus 1 when no sub video (child frame) is displayed. In this occasion, no video data of sub video is input or though it is input, the video data is subjected to a non-display process.<!-- EPO <DP n="12"> --></p><p id="p0025" num="0025">The input video data of main video is decoded by decoder 101, and the decoded video is adj usted as to timing by buffering unit 102 and output. Since no sub video is displayed, the decoded video output from buffering unit 102 passes through synthesizer 105 without being processed therein and is supplied to display unit 107. So, the main video is displayed as it is.</p><p id="p0026" num="0026">Next, description will be made of the processing in video display apparatus 1 when a sub video (child frame) is displayed.<br/>
The video data of the input sub video is decoded at decoder 103, and the decoded video is adj usted as to timing by buffering unit 104 and output. This decoded picture of sub video is input to adjuster 106 inside synthesizer 105.</p><p id="p0027" num="0027">Adjuster 106, as a pre-process for synthesizing the sub video with the main video, converts and adjusts the image size, and the displayed position on the screen, of the decoded picture of the sub video. On this occasion, the sub video (child frame) is adjusted so as to be synthesized in the displayed position that is designated by position designator 110 described later, within the main video (parent frame). Thereafter, the sub video after the adjustment is synthesized with the decoded picture of the input main video, so that the synthesized video is output and displayed through display<!-- EPO <DP n="13"> --> unit 107. Further, it is also possible to make the main video be seen through the synthesized sub video by setting a transmittance when they are synthesized.</p><p id="p0028" num="0028">Video display apparatus 1 includes input unit 108, which receives a switching instruction for display/non-display of the sub video (child frame) from the user. Then, input unit 108, based on the input switching instruction, generates a display status information that indicates whether the sub video (child frame) should be displayed or non-displayed at the current point of time and transfers it to processing controller 109 and position designator 110.</p><p id="p0029" num="0029">Processing controller 109 receives the display status information from input unit 108 and controls the processing of decoder 103 and/or buffering unit 104 based on it. For example, when the display status information has come to "non-displayed state", the controller stops the decoding process at decoder 103 and/or output from buffering unit 104 and restarts these processes when the display status information comes to "displayed state", to thereby pause the sub video during the non-displaying period.</p><p id="p0030" num="0030">Position designator 110 receives the display status information from input unit 108, and when the sub video (child<!-- EPO <DP n="14"> --> frame) is in the displayed state, it determines the displayed position of the sub video (child frame) to be displayed in the main video (parent frame) using the aftermentioned metadata and notifies adjuster 106 of the result.</p><p id="p0031" num="0031">As the main video is changing temporally, the displayed position in the main video, at which the sub video is wanted to be displayed or may be displayed changes temporally with the change of the main video. Accordingly, if playback and display of the sub video is restarted some time after the sub video was stopped in its display and set into pause, by processing controller 109 and decoder 103 and/or buffering unit 104 that are controlled by processing controller 109 as stated above, it is not always desirable that the sub video is displayed at the same position as before when it was stopped in its display. The data for display for sub video given in the present invention, namely metadata is the data which is given with information on where the sub video should or can be displayed in the main video with every time position in the main video. Position designator 110, using the metadata that is input with the video data of the sub video, outputs the displayed position of the sub video (child frame) corresponding to the time position indicated by the time information during playback.<!-- EPO <DP n="15"> --></p><p id="p0032" num="0032">Referring to <figref idrefs="f0002 f0003 f0004 f0005">FIGS. 2 to 5</figref>, the metadata for video display, handled in the present embodiment will be described in further detail.</p><p id="p0033" num="0033"><figref idrefs="f0002">FIGS. 2</figref> and <figref idrefs="f0003">3</figref> show specific examples of metadata according to the sub video display given in the present invention. The video stream (sub video stream) contained in the video data is composed of a header portion and a video data portion. The header portion includes various kinds of information regarding the stream, and this header portion includes the metadata.</p><p id="p0034" num="0034"><figref idrefs="f0002">FIGS. 2</figref> and <figref idrefs="f0003">3</figref> each show a specific structure of metadata (<figref idrefs="f0002">FIG. 2(a)</figref>, <figref idrefs="f0003">FIG. 3(a)</figref>) and a diagram showing the displayed area or displayable area, designated by the metadata (<figref idrefs="f0002">FIG. 2(b)</figref>, <figref idrefs="f0003">FIG. 3(b)</figref>). Also, a diagram (<figref idrefs="f0002">FIG. 2(c)</figref>, <figref idrefs="f0003">FIG. 3(c)</figref>) schematically showing the displayed area or displayable area in one dimension is added in order to allow an easy understanding of the temporal variation of the displayed area or displayable area. That is, the vertical axis in <figref idrefs="f0002">FIGS. 2(c)</figref> and <figref idrefs="f0003">3(c)</figref> represents spatial two-dimensional position on the screen and the vertical width of the illustrated band corresponds to the size of the displayed area or displayable area.</p><p id="p0035" num="0035"><figref idrefs="f0002">FIG. 2 (a)</figref> shows an example of a metadata structure. The<!-- EPO <DP n="16"> --> metadata is comprised of: total play time 200 of a sub video; displayable time information 201 that represents the time range of the main video that allows the sub video to be displayed, based on the playback time in the main video (the playback time based on "00:00:00", the playback starting position); and displayed area information 202 that shows the position in the main video in which the sub video s displayed at each moment in the displayable time range. Here, displayed area information 202 in <figref idrefs="f0002">FIG. 2</figref> gives the upper left vertex of the child frame on the assumption that the sub video (child frame) has a predetermined fixed display size. For example, the sub video is displayed from time "00:00:10" with its upper left vertex positioned at (x1, y1). It should, of course, be understood that the coordinates of the vertex are not limited to the coordinates of the upper left point, but the coordinates of the center of the sub video, for example can be used.</p><p id="p0036" num="0036"><figref idrefs="f0002">FIG. 2 (b)</figref> shows a two-dimensional representation of the displayed area where the sub video is displayed at individual points of time of the main video. For example, from time "00:00:15" to time "00:00:30", the sub video is synthesized and displayed in the area in the main video with its upper left vertex set at coordinates (x2, y2).</p><p id="p0037" num="0037"><figref idrefs="f0002">FIG. 2 (c)</figref> shows a one-dimensional representation of the<!-- EPO <DP n="17"> --> displayed area where the sub video is displayed. The vertical direction shows the spatial position (area) in the main video and the horizontal direction shows time (time position of the main video). For example, the upper left vertex of the sub video shifts from coordinates (x1, y1) to (x2, y2) at the time of "00:00:15". In <figref idrefs="f0002">FIG. 2(c)</figref>, the displayed area of the sub video in the main video is given by a band region that changes its position at times "00:00:15" and "00:00:30".</p><p id="p0038" num="0038"><figref idrefs="f0003">FIG. 3 (a)</figref> also shows an example of a metadata structure. The metadata shown in <figref idrefs="f0003">FIG. 3(a)</figref> is comprised of: total play time 300 of a sub video; displayable time information 301 that represents the time range of the main video that allows the sub video to be displayed, based on the playback time in the main video; and displayable area information 302 that shows the area in the main video in which the sub video can be displayed (display is permitted) at each moment in the displayable time range. Here, displayable area information 302 shown in <figref idrefs="f0003">FIG. 3</figref> gives coordinates of two points, upper left and lower right vertexes for the area in which the child frame can be displayed. For example, referring to <figref idrefs="f0003">FIG. 3(b)</figref>, it is shown that from time "00:00:10" the sub video (child frame) can be displayed in a rectangular area having an upper left vertex at coordinates (x1, y1) and a lower right vertex at coordinates (x1', y1'). If the sub video (child frame)<!-- EPO <DP n="18"> --> has a predetermined fixed display size and when the displayable area designated by displayable area information 302 in <figref idrefs="f0003">FIG. 3</figref> is greater than the display size of the child frame, the sub video will be able to be displayed at an arbitrary position within the displayable area when it is displayed. Further, the sub video (child frame) being displayed may be moved or enlarged within the range of the displayable area. For example, in <figref idrefs="f0003">FIG. 3(c)</figref>, the area in which the sub video can be displayed in the main video is specified by a band region that changes its position and widths at times "00:00:15" and "00:00:30".</p><p id="p0039" num="0039">Though in the two examples shown in <figref idrefs="f0002">FIGS. 2</figref> and <figref idrefs="f0003">3</figref>, the displayed (displayable) area specified by the metadata was described on the assumption that the sub video (child frame) has a fixed size, the sub video size is not limited to this; the displayed area information is adapted to give the sub video's display size itself. That is, similarly to <figref idrefs="f0003">FIG. 3</figref> the displayed area is specified by the coordinates of two points, upper left and lower right vertexes, and the sub video may be displayed so that the sub video is enlarged or reduced to meet the size of the displayed area.</p><p id="p0040" num="0040">A table in <figref idrefs="f0004">FIG. 4</figref> shows variations for setting up the time ranges in which the displayed (displayable) area is specified and of the descriptive format of the displayed<!-- EPO <DP n="19"> --> (displayable) area, with regard to the metadata given by the present invention. Here, <figref idrefs="f0004">FIG. 4</figref> shows the cases where the displayed (displayable) areas are limited to rectangular shapes.</p><p id="p0041" num="0041">There are different ways of setting up the time ranges; one way is to specify arbitrary sections and another way is to give a display (displayable) area to every section of a fixed unit. Here, when arbitrary sections are specified, if it is assumed that there is no time gap or overlap within a continuous duration, one of the starting and ending times of a section may be omitted. Further, in the table of <figref idrefs="f0004">FIG. 4</figref>, a generally used time notation, "hour: minute: second" is used as an example. However, the time notation is not limited this; for example, the total time can be given in a "second" or "millisecond" format. On the other hand, when a displayed (displayable) area is given to every section of a fixed unit, one displayed (displayable) area is given to every unit of an arbitrary time, for example, every second, every 250 milliseconds, every minute or the like, other than every five seconds which is exemplified in <figref idrefs="f0004">FIG. 4</figref>. Further, it is also possible to use a unit during video encoding other than time such as a frame unit and a GOP (Group Of Picture) unit. The length of a unit section is set appropriately depending on the properties of the stored video.<!-- EPO <DP n="20"> --></p><p id="p0042" num="0042">The descriptive formats of the displayed (displayable) area may be specified in several ways, including a single set of coordinates, two sets of coordinates, and a set of coordinates with a s ze. Of these, the case where the area can be determined with a single set of coordinates is one where the display size of the sub video has been previously determined. When the area is specified with two sets of coordinates or a set of coordinates with a given size, there are two possible cases where the display s ze of the sub video is smaller than the specified area or a so-called displayable area is specified, and where the sub video is resized (enlarged or reduced in size) into the specified area or the displayed area. As a displayable area it is also possible to designate a band-like area ranging from top to bottom or from left to right in the main video (e.g., an area ranging the upper half or lower half of the screen). Though in <figref idrefs="f0004">FIG. 4</figref> the examples of the displayed (displayable) area are specified as rectangular areas, other than this, the displayed (displayable) area may be given as a shape other than a rectangle, such as a polygon and oval, or may be formed in an arbitrary shape. An area of an arbitrary shape can be formed for example by using a masking image of the shape. Here, description of a specific descriptive format for an arbitrary shape is omitted.<!-- EPO <DP n="21"> --></p><p id="p0043" num="0043">Further, it is also possible to specify a displayed (displayable) area that moves continuously with time as shown in <figref idrefs="f0005">FIG. 5</figref> instead of the cases shown in <figref idrefs="f0002">FIGS. 2</figref> and <figref idrefs="f0003">3</figref> in which the position of the displayed (displayable) area changes discretely at certain points of time. In this case, a displayed (displayable) area information 502 included in the metadata (<figref idrefs="f0005">FIG. 5 (a)</figref>) can be given, for example by a combination of a time section, a position of the displayed (displayable) area at the starting time position of the time section, and a position of the displayed (displayable) area at the ending time position of the time section, as shown in <figref idrefs="f0005">FIG. 5</figref>. As an example, <figref idrefs="f0005">FIG. 5 (b)</figref> shows a displayed area of a child frame. Here, at time "00:00:10", a child frame is displayed in a displayed area having its upper left point at coordinates (x1, y1). Then the displayed area is continuously shifted so that the child frame is displayed at time "00:00:20" in the displayed area having its upper left point at (x2, y2). Further, the displayed area is continuously shifted so that the child frame is displayed at time "00: 00: 40" in the displayed area having its upper left point at (x3, y3). <figref idrefs="f0005">FIG. 5 (c)</figref> shows the above case in a schematic manner, where the displayed area or displayable area is represented in one dimension.</p><p id="p0044" num="0044">It should be noted that the method for specifying an<!-- EPO <DP n="22"> --> area that continuously changes is not limited to this. It is also possible to specify a displayed (displayable) area by giving its position at the starting time position together with a unit variation (movement vector).</p><p id="p0045" num="0045">Further, in the present invention an area specified by the metadata is handled as a displayed area (an area in which display is made) or displayable area (an area in which display is permitted). On the contrary, this can be also understood as that areas other than the above are specified as the display prohibited areas (areas in which display is not permitted). That is, the present invention can be similarly applied to the metadata that specifies displayable time and display prohibited areas.</p><p id="p0046" num="0046">Referring next to <figref idrefs="f0006 f0007 f0008 f0009 f0010">FIGS. 6 to 10</figref>, description will be made of the specific operation when the sub video which is synthesized with the main video is played back and displayed using the metadata for display described heretofore.</p><p id="p0047" num="0047"><figref idrefs="f0006">FIG. 6</figref> is a flow chart showing a process when a sub video is displayed, including the switching of display/non-display of the sub video (child frame). This flow chart mainly shows the operations of position designator 110, processing controller 109 and synthesizer 105 of the apparatus components<!-- EPO <DP n="23"> --> of video display apparatus 1, shown in <figref idrefs="f0001">FIG. 1</figref>. <figref idrefs="f0007 f0008 f0009 f0010">FIGS. 7 to 10</figref> show an example of an operation result when a sub video is synthes zed and displayed on video display apparatus 1 of <figref idrefs="f0001">FIG. 1</figref>, in accordance with the flow chart of <figref idrefs="f0006">FIG. 6</figref>. In <figref idrefs="f0007 f0008 f0009 f0010">FIGS. 7 to 10</figref>, a solid black portion indicates the time during which the sub video is displayed and the displayed position at that time.</p><p id="p0048" num="0048">In the description hereinbelow, playback and display processing will be described taking an example of the metadata shown in <figref idrefs="f0002">FIG. 2</figref>, in which the size of the displayed area is equal to the display size of the sub video. However, even though use is made of metadata that describes a so-called displayable area, namely a case that the size of the displayed area is hence greater than the display size of the sub video, the basic operation is unchanged except in that an appropriate displayed position is selected from the displayable area by designator 110 and output.</p><p id="p0049" num="0049">Position designator 110 reads metadata (Step S1), then determines whether the current playback time of the main video falls within the displayable time based on the displayable time information (201 in <figref idrefs="f0002">FIG. 2</figref>) included in the metadata (Steps S2 and S3). If it is before the starting time of the displayable time, no sub video is displayed and the start<!-- EPO <DP n="24"> --> of the displayable time is waited for (Step S2; No).</p><p id="p0050" num="0050">If the current playback time in the main video is within the displayable time (Step S2; Yes -&gt; Step S3; No), position designator 110 takes up a switching instruction between sub video displayed and non-displayed statuses from input unit 108. Here, when the instruction for displaying the sub video is received so that the sub video is in the displayed status (Step S4; Yes), a decoding process of the sub video is implemented so as to output a decoded picture (Step S5). Further, position designator 110 acquires the time information regarding the current playback time position in the main video (Step S6) and determines the displayed position of the sub video corresponding to the current playback time position, based on the metadata (Step S7). Then, synthesizer 105 synthesizes and displays the sub video at the displayed position designated in the main video (Step S8). When the data of the sub video is not completed (Step S9; No), the operation goes to Step S3 for continuation of the process.</p><p id="p0051" num="0051">On the other hand, when the sub video is instructed to set into the non-displayed status by the user using the switching instruction between sub-video displayed and non-displayed statuses (S4; No), decoding and output processing of the sub video are stopped (Step S10) to make<!-- EPO <DP n="25"> --> the display of the sub video itself temporarily halting.<br/>
When the playback of the sub video is completed (S9; Yes), or when the playback time of the main video has passed the end time of the sub video displayable time (S3; Yes), the sub video display processing is ended.</p><p id="p0052" num="0052"><figref idrefs="f0007 f0008 f0009 f0010">FIGS. 7 to 10</figref> are diagrams schematically showing the positional relationships between the main video and sub video. The vertical direction shows the spatial position in the main video and the horizontal direction shows time. Now, the main video starts to be output at time "00:00:00". The drawings also show the displayed status of the sub video when the metadata structure shown in <figref idrefs="f0002">FIG. 2(a)</figref> is used.</p><p id="p0053" num="0053">First, <figref idrefs="f0007">FIG. 7</figref> is a diagram showing the situation up to time "00:00:13". Referring to the metadata structure in <figref idrefs="f0002">FIG. 2(a)</figref>, the sub video-displayable time starts from time "00:00:10". Then, as a control for displaying the sub video is made by the user at time "00:00:13" (Step S2; Yes &gt; Step S3; No -&gt; Step S4; Yes in <figref idrefs="f0006">FIG. 6</figref>), the sub video is decoded (Step S5). This sub video is synthesized with the main video, and display of the sub video at the displayed position corresponding to time "00:00:13", designated by the metadata is started (the black solid portion in <figref idrefs="f0007">FIG. 7</figref>).<!-- EPO <DP n="26"> --></p><p id="p0054" num="0054">Secondly, <figref idrefs="f0008">FIG. 8</figref> is a diagram showing the situation up to time "00:00:20". Referring to the metadata structure in <figref idrefs="f0002">FIG. 2 (a)</figref>, the process of changing the displayed area of the sub video at time "00:00:15" is described. Accordingly, position designator 110 changes the displayed position of the sub video in accordance with displayed area information 202 in the metadata (Step S7). Then, when a signal for setting the sub video status into the non-displayed state is input through input unit 108 at time "00:00:20" (Step S4; No), a signal for stopping the sub video output is output fromposition designator 110 to synthesizer 105. As a result, synthesizer 105 stops the sub video output (Step S10).</p><p id="p0055" num="0055">Next, <figref idrefs="f0009">FIG. 9</figref> is a diagram showing the situation up to time "00:00:28", in which the display has been switched into the sub video (child frame)-displayed state once again. On this occasion, the sub video is returned to the playback state from the pausing state, and the continuat on of the sub video that was played at time "00:00:20" is played. The sub video (child frame) at that time is displayed at a displayed position corresponding to time "00:00:28" designated by the metadata.</p><p id="p0056" num="0056">Next, <figref idrefs="f0010">FIG. 10</figref> is a diagram showing the situation up to time "00:00:36", in which playback of the sub video having a total playback time of "15 seconds" has been completed.<!-- EPO <DP n="27"> --> Referring first to the metadata described in <figref idrefs="f0002">FIG. 2(a)</figref>, the displayed area of the sub video is changed at time "00:00:30" (Step S7). Then at time "00: 00: 36" at which the total playback time "15 seconds" has elapsed, the output of the sub video stops (Step S9; Yes).</p><p id="p0057" num="0057">As has been described heretofore, in video display apparatus 1 according to the first embodiment of the present invention, when a sub video is synthesized and displayed with the main video by use of the metadata that gives the sub video-displayed area or displayable area, the displayed position of the sub video inside the main video in correspondence to the display time can be appropriately designated. As a result, the sub video can be freely switched between the displayed and non-displayed states within the range of displayable time. Further, even if switching between the displayed and non-displayed states is freely done, it is possible to avoid the sub video being synthesized and displayed at a position unfavorable to the main video.</p><p id="p0058" num="0058">In <figref idrefs="f0001">FIG. 1</figref> of the present embodiment, the above-described metadata is illustrated so as to be input independently of each set of video data. For example, when management data for managing video data (information such as an encoding system and the like, required to decode encoded data and information<!-- EPO <DP n="28"> --> required for playing the video such as a play list that specifies video clipping and joining) is given as a stream separate from video data, the metadata can be stored into the management data so as to be given to video display apparatus 1. Alternatively, as already illustrated in <figref idrefs="f0002">FIG. 2(a)</figref> or <figref idrefs="f0003">FIG. 3(a)</figref>, the above-described metadata may be supplied by being stored in the video stream that includes the video data of sub video. In this case, it is necessary to provide a process of separating the metadata from the video stream of the sub video before the stream is input to video display apparatus 1.</p><p id="p0059" num="0059">Further, since the aforementioned metadata is consumed as the sub video is played back, it is generally considered that the metadata is given in one-to-one correspondence with sub video. However, for example, it is also possible to consider a using method such that the main video has a set of metadata, which is commonly applied to a plurality of sets of sub videos. In this case, the metadata may be stored in the video data (video data stream) of the main video. Further, though in <figref idrefs="f0002">FIGS. 2(a)</figref> and <figref idrefs="f0003">3(a)</figref> the aforementioned metadata is stored in the header position of the video stream, the storage position is not limited to this. For example, when video data is transmitted by dividing it into a plurality of packets, the metadata may be embedded as a new packet between<!-- EPO <DP n="29"> --> one video packet and the next, or stored into the packet header of each video packet.</p><p id="p0060" num="0060">The video distributor is able to display a sub video in picture-in-picture mode at a displayed position that is intended by the distributor by supplying metadata together with video data in the way described above.</p><p id="p0061" num="0061">Further, though synthesizer 105 of video display apparatus 1 shown in <figref idrefs="f0001">FIG. 1</figref> adjusts the sub video only and makes no adjustment for the main video (that is, the main video is displayed in the full screen), it is possible to use a synthesizer 105a which also includes an adjuster 106a (as an additional adjuster separate from adjuster 106 for sub video) on the input side of the decoded video of the main video so as to produce an output by adjusting both the main and sub videos (synthesizer 105a and adjuster 106a are not particularly illustrated). In this case, however, since the metadata represents the displayed (displayable) area on the main video onto which the sub video is synthesized and displayed, when the main video is adj usted by the aforementioned adj uster 106a, it is necessary to adjust the sub video-displayed (displayable) area that is given by the metadata, in conformity with the above adjustment. Illustratively, for example, if the main video is reduced, for display, to half both vertically<!-- EPO <DP n="30"> --> and horizontally, the sub video-displayed (displayable) area that is synthesized and displayed with the main video is also compressed by half vertically and horizontally. Though this reference will not be particularly mentioned in the other embodiments, this matter should be quite similarly applied to the other embodiments.</p><heading id="h0011">(The second embodiment)</heading><p id="p0062" num="0062">Next, a video display apparatus, method and data for display according to the second embodiment of the present invention will be described using <figref idrefs="f0001">FIGS. 1</figref>, <figref idrefs="f0006">6</figref> and <figref idrefs="f0011">11</figref> through 15.</p><p id="p0063" num="0063">The schematic configuration of video display apparatus 2 according to the second embodiment of the present invention can be given by the functional block diagram of <figref idrefs="f0001">FIG. 1</figref>, similarly to the first embodiment. However, in the second embodiment, the metadata handled here is different from that of the first embodiment. As for the operation of the display apparatus, only the operation of the position designator is different between video display apparatus 1 (position designator 110) and video display apparatus 2 (position designator 210) . So, hereinbelow, the metadata used in video display apparatus 2 of the second embodiment and the specific operation during playback using this metadata will be described mainly focusing<!-- EPO <DP n="31"> --> on the difference from the first embodiment.</p><p id="p0064" num="0064"><figref idrefs="f0011">FIG. 11</figref> shows an example of metadata handled in the second embodiment. The metadata (<figref idrefs="f0002">FIGS. 2</figref> and <figref idrefs="f0003">3</figref>) exemplified in the first embodiment is to give a displayed area of a sub video (child frame) in the main video that is favorable to the main video when a sub video is displayed within the displayable time. Therefore, in the metadata shown in <figref idrefs="f0002">FIG. 2</figref> and <figref idrefs="f0003">FIG. 3</figref>, the displayed area of the sub video is given so as to be in correspondence with each point of playback time of the main video based on the playback time axis with regard to the main video. In contrast, the metadata according to the second embodiment shown in <figref idrefs="f0011">FIG. 11</figref> is to give a preferable displayed area in which, when a sub video is displayed, the sub-video itself can be displayed in a preferable manner depending on the content of the sub video and creative intention. Accordingly, in the metadata according to the second embodiment, the sub video-displayed area is given so as to be in correspondence with each point of playback time in the sub video based on the playback time axis with regard to the sub video.</p><p id="p0065" num="0065">Here, the preferable displayed position depending on the content of the sub video is applied to a usage case in which, when, for example a 10-second sub video is composed<!-- EPO <DP n="32"> --> of a scene of a person A facing rightward in the first ive seconds and another scene of a person B facing leftward in the remaining five seconds, a sub-video picture is displayed on the left-hand side on the screen in the first five seconds and a sub-video picture is displayed on the right-hand side on the screen in the remaining five seconds so that both the persons A and B face the center of the screen. Of course, this is a mere example, and it is not always desirable for both persons to face the center, but the positions where sub-video pictures are displayed depends on the directive intention of the video director. In sum, the metadata according to the second embodiment as shown in <figref idrefs="f0011">FIG. 11</figref> is understood to be additional information for indicating the creative intention of the sub-video' s director in the playback of the sub video itself.</p><p id="p0066" num="0066">Similarly to <figref idrefs="f0002">FIG. 2</figref> for the first embodiment, <figref idrefs="f0011">FIG. 11(a)</figref> shows a specific metadata structure, <figref idrefs="f0011">FIG. 11(b)</figref> shows the displayed area designated by the metadata, and <figref idrefs="f0011">FIG. 11(c)</figref> schematically shows temporal change of the displayed area in a one-dimensional representation for easy understanding. As described above, the horizontal axes in <figref idrefs="f0011">FIGS. 11(b) and 11(c)</figref> represent the playback time position of the sub video. The vertical axis in <figref idrefs="f0011">FIG. 11(c)</figref>represent the spatial two-dimensional position on the screen and the vertical width<!-- EPO <DP n="33"> --> of the illustrated band corresponds to the size of the displayed area.</p><p id="p0067" num="0067">The metadata shown in <figref idrefs="f0011">FIG. 11(a)</figref> is comprised of: displayable time information 1101 that represents the time range of the main video that allows the sub video to be displayed; and displayed area information 1102 that shows the position in the main video in which the sub video should be displayed at each playback time point of the sub video, based on the sub v deo's playback time axis. However, displayable time information 1101 is not essential and can be omitted. If omitted, the whole part of the main video is understood as the displayable time of the sub video.</p><p id="p0068" num="0068">In <figref idrefs="f0011">FIG. 11</figref>, the case in which the displayed area is specified simply with the coordinates of the upper left vertex of the child frame (or center of the child frame) was described as an example of displayed area information 1102 on the assumption that the display size of the sub video (child frame) has a predetermined fixed size. However, the displayed area information is not limited to this. Similarly to the first embodiment, two sets of coordinates may be given to designate a displayable area (see <figref idrefs="f0003">FIG. 3</figref>) or two sets of coordinates may be given to designate a displayed area in which the sub video is displayed with enlargement or reduction. In <figref idrefs="f0011">FIG.<!-- EPO <DP n="34"> --> 11(c)</figref>, the displayed area in which the sub video should be displayed is represented as a band-like area that changes its position at the sub video-playback time "00: 00: 05" (i.e., in total, five seconds after the start of playback of the sub video) and at "00:00:10" (i.e., in total, ten seconds after the start of playback of the sub video).</p><p id="p0069" num="0069">Referring next to <figref idrefs="f0006">FIGS. 6</figref>, <figref idrefs="f0012 f0013 f0014 f0015">12 to 15</figref>, description will bemade of a specific operation when the sub video is synthesized with the main video, played back and displayed using the metadata shown in <figref idrefs="f0011">FIG. 11</figref>.</p><p id="p0070" num="0070">Similarly to the first embodiment, the process when video display apparatus 2 according to the present embodiment performs sub video display including the switching of display/non-display of the sub video (child frame) is shown by the flow chart in <figref idrefs="f0006">FIG. 6</figref>. This flow chart shows the operations of position designator 210, processing controller 109 and synthesizer 105 of the apparatus components of video display apparatus 2 shown in <figref idrefs="f0001">FIG. 1</figref>.</p><p id="p0071" num="0071">Similarly to the description in the first embodiment, in the description hereinbelow, playback and display processing using metadata that gives displayed area will be described. However, even though use is made of metadata that<!-- EPO <DP n="35"> --> describes displayable area, the basic operation is unchanged except in that an appropriate displayed position is selected from the displayable area by position designator 210 to be output.</p><p id="p0072" num="0072">Position designator 210 reads input metadata (Step S1), and then based on displayable time information 1101 included in the metadata, determines whether the current playback time in the main video falls within the displayable time (Steps S2 and S3). If the current playback time is before the starting time of the displayable time, no sub video is displayed and the start of the displayable time is waited for (Step S2; No).</p><p id="p0073" num="0073">If the current playback time in the main video is within the displayable time (Step S2; Yes -&gt; Step S3; No), position designator 210 takes up a switching instruction between sub video displayed and non-displayed statuses from input unit 108. Here, when the instruction for displaying a sub video is received and the sub video is in the displayed status (Step S4; Yes), a decoding process of the sub video is implemented so as to output a decoded picture (Step S5). Further, position designator 210 acquires the time information regarding the current playback time position in the sub video (Step S6) and determines the displayed position corresponding to the<!-- EPO <DP n="36"> --> current playback time position in the sub video, based on the metadata (Step S7). Then, synthesizer 105 synthesizes and displays the sub video in the displayed position designated in the main video (Step S8). In the above way, there are two different points from the first embodiment: at Step S6 the total playback time position of the sub video itself is acquired as the time information; and at Step S7 the displayed position corresponding to the playback time position of the sub video is determined using the metadata.</p><p id="p0074" num="0074"><figref idrefs="f0012 f0013 f0014 f0015">FIGS. 12 to 15</figref> are diagrams schematically showing an example of the operational result when a sub video is synthesized and displayed on video display apparatus 2. Here, in video display apparatus 2 of this embodiment, the metadata is controlled based on the sub video-playback time that represents the position at which the sub video has been reproduced and displayed, separately from the playback time of the main video, so each of <figref idrefs="f0012 f0013 f0014 f0015">FIGS. 12 to 15</figref>, (a) shows how the displayed area is designated by the metadata based on the sub video-playback time and (b) shows how the sub video is synthesized and displayed with the main video based on the main video-playback time. In the drawings (b) of <figref idrefs="f0012 f0013 f0014 f0015">FIGS. 12 to 15</figref>, the solid black portion indicates a period during which the sub video is displayed and the displayed position at that time.<!-- EPO <DP n="37"> --></p><p id="p0075" num="0075">First, <figref idrefs="f0012">FIG. 12</figref> is a diagram showing the situation up to time "00:00:13". Referring to the metadata structure in <figref idrefs="f0011">FIG. 11(a)</figref>, the sub video-displayable time starts from time "00:00:10". Then, as a control for displaying the sub video is made by the user at time "00:00:13" (Step S2; Yes -&gt; Step S3; No -&gt; Step S4; Yes in <figref idrefs="f0006">FIG. 6</figref>), the sub video is decoded (Step S5). This sub video is synthesized with the main video, and display of the sub video at the displayed position corresponding to time "00:00:13", designated by the metadata is started. Here, <figref idrefs="f0012">FIG. 12 (a)</figref> shows the state when the video starts to be output from "00: 00: 00" in the sub video-playback time. <figref idrefs="f0012">FIG. 12(b)</figref> shows the state when the sub v deo starts to be output when the main video-playback time is "00:00:13".</p><p id="p0076" num="0076">Secondly, <figref idrefs="f0013">FIG. 13</figref> is a diagram showing the situation up to time "00:00:20". Referring to displayed area information 1102 of the metadata structure in <figref idrefs="f0011">FIG. 11(a)</figref>, the displayed area of the sub video is changed at "00:00:05" in the sub video-playback time. Accordingly, as shown in <figref idrefs="f0013">FIG. 13(a)</figref> the displayed area changes at "00:00:05" in the sub video-playback time. As a result, on the synthesized video, the displayed position is changed at time "00:0018", which corresponds to a point of time five seconds after the playback (display) of the sub video started, as shown in <figref idrefs="f0013">FIG. 13(b)</figref>.<!-- EPO <DP n="38"> --> Then, when the sub video is set into the non-displayed state at "00:00:20" in the main video-playback time, the display of the sub video in the main video stops. At this condition, the sub video has been played up to "00:00:07".</p><p id="p0077" num="0077">Next, <figref idrefs="f0014">FIG. 14</figref> is a diagram showing the situation up to time "00:00:28", in which the display has been switched into the sub video (child frame)-displayed state once again. On this occasion, the sub video is returned to the playback state from the pausing state, and the continuation of the sub video that was played at "00: 00: 20" in the main video time, in other words, the sub video is started to be played from the time position "00:00:07" in the sub video time (the time position corresponding to the total playback time of 7 seconds). The displayed position of the sub video (child rame) is given by the metadata so that the sub video is displayed at a displayed pos tion corresponding to "00:00:07" in the sub video time position (the time position corresponding to the total playback time of 7 seconds).</p><p id="p0078" num="0078">Next, <figref idrefs="f0015">FIG. 15</figref> is a diagram showing the situation up to "00:00:36" in the main video time, in which playback of the sub video having a total playback time of "15 seconds" has been completed. Referring to displayed area information 1102 included in the metadata described in <figref idrefs="f0011">FIG. 11 (a)</figref>, the displayed<!-- EPO <DP n="39"> --> posi on of the sub video is changed at "00:00:10" in the sub video time (at time position corresponding to the total playback time of 10 seconds). Accordingly, at "00:00:10" in the sub video time, or at "00:00:31" in the main video time, the displayed position of the sub video is changed.</p><p id="p0079" num="0079">As has been described heretofore, in video display apparatus 2 according to the present embodiment, when a sub video is synthesized and displayed with the main video by use of the metadata that gives the sub video-displayed area (or displayable area), it is possible to synthesize and display the sub video with the main video by specifying the position where the sub video should be displayed, which is previously determined depending on the content of the sub video and/or creative intention. As a result, the sub video can be freely switched between the displayed and non-displayed states. Also, if switching between the displayed and non-displayed states is freely done, it is possible to synthesize and display the sub video in the displayed position in conformity with the content of the sub video and/or creative intention.</p><p id="p0080" num="0080">Also with regard to the metadata of the present embodiment, the metadata can be supplied in a form, either by storing it similarly to the first embodiment, in, for example the data stream of management data that is independent of the<!-- EPO <DP n="40"> --> video data, or by storing it in the video stream including the video data of the sub video as shown in <figref idrefs="f0011">FIG. 11 (a)</figref>. When stored in the video stream, it is necessary to provide a process of separating the metadata from the video stream of the sub video before its input to video display apparatus 2. It should be noted that since the metadata according to the second embodiment is given in one-to-one correspondence with sub video, the metadata is normally added to the video data of the sub video or to the management data regarding to the sub video. Further, though in <figref idrefs="f0011">FIG. 11 (a)</figref> the metadata is stored in the header position of the video stream, the storage position is not limited to this. For example, when video data is transmitted by dividing it into a plurality of packets, the metadata may be embedded as a new packet between one video packet and the next, or stored into the packet header of each video packet.</p><heading id="h0012">(The third embodiment)</heading><p id="p0081" num="0081">Next, a video display apparatus, method and data for display according to the third embodiment of the present invention will be described using <figref idrefs="f0001">FIGS. 1</figref>, <figref idrefs="f0006">6</figref> and <figref idrefs="f0016">16</figref>.</p><p id="p0082" num="0082">The schematic configuration of a video display apparatus 3 according to the third embodiment of the present invention can be given by the functional block diagram of <figref idrefs="f0001">FIG. 1</figref>, similarly<!-- EPO <DP n="41"> --> to the first and second embodiments. However, since the operation of position designator 110 alone is different, in the present embodiment the position designator is designated at 310. The process of performing sub video display on the video display apparatus 3 according to the third embodiment is also given by the flow chart shown in <figref idrefs="f0006">FIG. 6</figref>, similarly to the first and second embodiments. Hereinbelow, the operation of video display apparatus 3 according to the third embodiment will be described focusing on the difference from the video display apparatus 1 of the first embodiment.</p><p id="p0083" num="0083">In video display apparatus 3 in the present embodiment, two kinds of metadata described in the first and second embodiments are input as the metadata for displaying a sub video, so that the displayed area of the sub video is determined based on the combination of these two sets of metadata. Accordingly, position designator 310 of video display apparatus 3 receives two kinds of metadata and two sets of time information (main video's playback time positional information and sub video's playback time positional information) (Step S6 in the flow chart) and determines an appropriate display area for the sub video (Step S7 in the flow chart).</p><p id="p0084" num="0084"><figref idrefs="f0016">FIG. 16</figref> is a diagram schematically showing the states<!-- EPO <DP n="42"> --> of main and sub videos. <figref idrefs="f0016">FIG. 16(a)</figref> shows the sub video-displayable area designated in relation to the main video, given by the metadata described in the first embodiment while <figref idrefs="f0016">FIG. 16(b)</figref> shows the displayed area designated in relation to the sub video itself, given by the metadata described in the second embodiment. <figref idrefs="f0016">FIG. 16 (c)</figref> is a diagram showing how the displayed area of the sub video during playback is designated by the metadata of <figref idrefs="f0016">FIG. 16(b). FIG. 16(d)</figref> is a diagram showing a situation in which the main video and sub video are synthesized and displayed by the metadata of <figref idrefs="f0016">FIGS. 16(a) and 16(b)</figref>.</p><p id="p0085" num="0085"><figref idrefs="f0016">FIGS. 16(c) and 16(d)</figref>, similarly to the first and second embodiments, show the displayed position of a sub video using the aforementioned two kinds of metadata when the sub video is started to display at time "00:00:13", stopped to display at time "00:00:20", restarted to display at time "00:00:28" and ended to display at time "00:00:36". Further, in <figref idrefs="f0016">FIG. 16(c)</figref> a displayed area 16B corresponding to the sub video shown in (b) is given and in <figref idrefs="f0016">FIG. 16(d)</figref> a displayable area 16A of the sub video in the main video shown in (a) is shown. The hatched areas or black solid areas in <figref idrefs="f0016">FIG. 16(d)</figref> show the periods in which the sub video is displayed and the displayed positions in those periods.<!-- EPO <DP n="43"> --></p><p id="p0086" num="0086">It is usual that a sub video is given to the main video as a value-added extra content. Therefore, it is generally desirable that its playback is performed while the main video is kept from destruction as far as possible. Accordingly, when the aforementioned two kinds of metadata are given, the displayed area is determined by giving priority to the sub video-displayable area 16A that is given in relation to the main video over the displayed area 16B that is given in relation to the sub video itself.</p><p id="p0087" num="0087">In <figref idrefs="f0016">FIG. 16(d)</figref>, in a time range 1601 ("00:00:13" to "00:00:15"), displayable area 16A and displayed area 16B exactly overlap each other, so that the displayed area of the sub video is determined based on both sets of metadata.</p><p id="p0088" num="0088">In a time range 1602 ("00:00:15" to "00:00:20" and "00:00:28" to "00:00:30") displayed area 16B is completely included in displayable area 16A. Accordingly, in range 1602 the sub video is displayed in the displayed area that is given to the sub video itself based on the metadata similar to that shown n the second embodiment.</p><p id="p0089" num="0089">In a time range 1603 ("00:00:30" to "00:00:36"), sub video-displayable area 16A given to the main video and sub video-displayed area 16B designated in conformity with the<!-- EPO <DP n="44"> --> sub video content itself are separated in different regions. In this case, sub video-displayable area 16A that is given to the main video is given priority. That is, in time range 1603, the sub video is displayed in the sub video-displayable area that is given to the main video based on the metadata similar to that shown in the first embodiment.</p><p id="p0090" num="0090">Though not illustrated, when the displayable area shown in <figref idrefs="f0016">FIG. 16(a)</figref> and the displayed area shown in <figref idrefs="f0016">FIG. 16(b)</figref> to specify the displayed position of the sub video are located in different areas and when the displayable area shown in <figref idrefs="f0016">FIG. 16 (a)</figref> is greater than the display size of the sub video (child frame), a process of setting up a sub video-displayed area by determining an area that is included in the displayable area of <figref idrefs="f0016">FIG. 16 (a)</figref> and becomes closest to the displayed area of <figref idrefs="f0016">FIG. 16(b)</figref> may be added. Of course, if, conversely, the creative intention of the sub video is markedly important, it is possible to set the displayed position of the sub video by force based on the displayed area of <figref idrefs="f0016">FIG. 16 (b)</figref> by giving the displayed area of <figref idrefs="f0016">FIG. 16(b)</figref> a high priority.</p><p id="p0091" num="0091">Here, in each of the above-described embodiments of the present invention, the video data (and management data) and metadata input to the video display apparatus either may be supplied through transmission paths such as broadcasting<!-- EPO <DP n="45"> --> and/or communication, or may have been recorded beforehand on a recording medium so that the video data (and management data) and metadata recorded on the recording medium is sequentially read out to play it back for display. The situation is the same for the case in which the data is recorded once on a recording medium through a transmission path and then the recorded video data (and management data) with the metadata is read out for its playback. That is, the video display apparatus, method and data for display of the present invention can be applied as one component of a broadcast video receiver, video communication receiver and recording and reproducing apparatus having a recording medium and also can be applied to a recording medium on which the metadata described in each embodiment has been recorded.</p><p id="p0092" num="0092">It is also possible to control the metadata shown in each embodiment of the present invention separately from the video data (and management). Fromthis feature, whenmetadata is generated on the reproduction side, it is also possible to use the generated metadata on the reproduct on side in combination w th the video data that is separately input through broadcasting, communication or a recording medium when the video is played back in picture in picture. In this case, for example, the metadata can be formed with such processing as user preference settings for the areas which<!-- EPO <DP n="46"> --> the user does not care to be hidden and which are not wanted to be hidden in the main video during displaying a sub video. The generation of the metadata on the reproduction side is carried out when the video data (and management data) input through a transmission path such as broadcasting, communication etc., is recorded in the recording medium or directly before the video data (and management data) is played back after reading them out from the recording medium. This generating process may be done by user's direct input or may be done dynamically using a program such as Java (registered trademark) or the like. That is, the present invention can be applied to a video display apparatus and method that uses the metadata described in each embodiment no matter where the metadata was finally set up.</p><p id="p0093" num="0093">Here, the embodiments disclosed herein are, in all respects, ustrative and not restrictive. The scope of the present invention is defined by the scope of claims rather than the foregoing description, and all changes that fall within the meaning and scope equivalent to the scope of claims are intended to be embraced by the claims.</p></description><claims mxw-id="PCLM56984636" lang="DE" load-source="patent-office"><!-- EPO <DP n="55"> --><claim id="c-de-01-0001" num="0001"><claim-text>Aufzeichnungsmedium, welches mit einem ersten Video, mit einem zweiten Video und mit Daten für eine Anzeige zum Anzeigen des ersten Videos und des zweiten Videos durch Überlagern des zweiten Videos über dem ersten Video in einem Bild-in-Bild-Format aufgezeichnet ist,<br/>
wobei das zweite Video derart bereitgestellt ist, dass eine Anzeige/Nicht-Anzeige des zweiten Videos zu einem beliebigen Zeitpunkt innerhalb eines anzeigbaren Zeitraums (201, 301, 501) schaltbar ist, welcher im ersten Video bestimmt ist, wobei der anzeigbare Zeitraum (201, 301, 501) eine Zeitspanne des ersten Videos repräsentiert, welcher eine Anzeige des zweiten Videos ermöglicht,<br/>
wobei die Daten für eine Anzeige Daten sind mit:
<claim-text>Zeitrauminformation, welche den anzeigbaren Zeitraum repräsentiert,</claim-text>
<claim-text>Zeitinformation, welche mindestens einen Zeitbereich im zweiten Video repräsentiert, welcher unterschiedlich ist zur Zeit im ersten Video, und</claim-text>
<claim-text>Information (1102) über den angezeigten Bereich, welcher eine Position im ersten Video repräsentiert, an welcher das zweite Video angezeigt wird, wenn das zweite Video zum Anzeigen geschaltet wird, vermittelt in Korrespondenz mit dem mindestens einen Zeitbereich im zweiten Video,</claim-text>
wobei die Daten für eine Anzeige derart bereitgestellt werden, dass die Anzeige/Nicht-Anzeige des zweiten Videos zu einem beliebigen Zeitpunkt innerhalb des anzeigbaren Zeitraums, der im ersten Video bestimmt ist, schaltbar ist,<br/>
wobei das Aufzeichnungsmedium betreibbar ist, um durch eine Videosynthetisierungsvorrichtung wiedergegeben zu werden, welche ausgebildet ist, das erste Video, das zweite Video und die Daten für eine Anzeige auszulesen und das zweite Video über der angezeigten<!-- EPO <DP n="56"> --> Position innerhalb des ersten Videos, welche bestimmt wird durch die Daten für die Anzeige, zu synthetisieren und<br/>
wobei die Information über den angezeigten Bereich im anzeigbaren Zeitraum eine räumliche Position im ersten Video repräsentiert, welche sich als Funktion der Zeitinformation derart ändert, dass die räumliche Position innerhalb des anzeigbaren Zeitraums nicht konstant ist.</claim-text></claim><claim id="c-de-01-0002" num="0002"><claim-text>Aufzeichnungsmedium nach Anspruch 1,<br/>
wobei das Aufzeichnungsmedium des Weiteren mit einem Programm aufgezeichnet ist, wobei die Daten für eine Anzeige und das Programm verwendet werden zum Anzeigen des ersten Videos und des zweiten Videos durch Überlagern des zweiten Videos über dem ersten Video im Bild-in-Bild-Format und<br/>
wobei das Programm das erste Video, das zweite Video und die Daten für eine Anzeige ausliest, eine angezeigte Position innerhalb des ersten Videos auf der Grundlage der Daten für eine Anzeige bestimmt, wenn das zweite Video zu einem beliebigen Zeitpunkt angezeigt wird, und das zweite Video über der angezeigten Position synthetisiert.</claim-text></claim><claim id="c-de-01-0003" num="0003"><claim-text>Aufzeichnungsmedium nach Anspruch 1 oder 2,<br/>
wobei die Information über den angezeigten Bereich einen Satz von Koordinaten eines oberen linken Vertex und eines rechteckigen Bereichs zur Anzeige des zweiten Videos aufweist.</claim-text></claim><claim id="c-de-01-0004" num="0004"><claim-text>Aufzeichnungsmedium nach Anspruch 1,<br/>
wobei die Information (1102) des angezeigten Bereichs Information über den anzeigbaren Bereich ist, welche eine Position im ersten Video repräsentiert, an welcher das zweite Video anzeigbar ist, wenn das zweite Video zum Anzeigen geschaltet wird, und zwar vermittelt in Korrespondenz mit dem mindestens einen Zeitbereich im zweiten Video.</claim-text></claim><claim id="c-de-01-0005" num="0005"><claim-text>Aufzeichnungsmedium nach Anspruch 1,<br/>
wobei das Aufzeichnungsmedium des Weiteren mit einem Programm aufgezeichnet ist, wobei Daten für eine Anzeige und das Programm verwendet werden zum Anzeigen des ersten Videos und des zweiten Videos durch Überlagern des zweiten Videos über dem ersten Video im Bild-in-Bild-Format und<br/>
<!-- EPO <DP n="57"> -->wobei das Programm das erste Video, das zweite Video und die Daten für eine Anzeige ausliest, eine angezeigte Position innerhalb des ersten Videos auf der Grundlage der Daten für eine Anzeige bestimmt, wenn das zweite Video zu einem beliebigen Zeitpunkt angezeigt wird, und das zweite Video über der angezeigten Position synthetisiert.</claim-text></claim><claim id="c-de-01-0006" num="0006"><claim-text>Aufzeichnungsmedium nach Anspruch 4 oder 5,<br/>
wobei die Information über den anzeigbaren Bereich einen Satz von Koordinaten eines oberen linken Vertex und eines anzeigbaren rechteckigen Bereichs für das zweite Video enthält.</claim-text></claim><claim id="c-de-01-0007" num="0007"><claim-text>Datenerzeugungsvorrichtung,<br/>
welche Daten für eine Anzeige generiert, die verwendet werden zum Setzen und Synthetisieren eines zweiten Videos über einem ersten Video und zum Ausgeben eines Videos in einem Bild-in-Bild-Format,<br/>
wobei das zweite Video derart bereitgestellt wird, dass eine Anzeige/Nicht-Anzeige des zweiten Videos zu einem beliebigen Zeitpunkt innerhalb eines anzeigbaren Zeitraums (201, 301, 501) schaltbar ist, welcher im ersten Video bestimmt ist, wobei der anzeigbare Zeitraum (201, 301, 501) einen Zeitbereich des ersten Videos repräsentiert, der die Anzeige des zweiten Videos erlaubt,<br/>
wobei die Datenerzeugungsvorrichtung aufweist:
<claim-text>eine Bestimmungseinrichtung zum Bestimmen des anzeigbaren Zeitraums,</claim-text>
<claim-text>eine Bestimmungseinrichtung zum Bestimmen von Zeitinformation, welche mindestens einen Zeitbereich im zweiten Video bestimmt,</claim-text>
<claim-text>eine Bestimmungseinrichtung zum Bestimmen von Information (1102) über den angezeigten Bereich, welche eine Position im ersten Video repräsentiert, an welcher das zweite Video angezeigt wird, wenn das zweite Video zum Anzeigen zu dem mindestens einen Zeitbereich geschaltet wird, und</claim-text>
<claim-text>eine Erzeugungseinrichtung zum Erzeugen der Daten für eine Anzeige mit Zeitrauminformation und der Zeitinformation und der Information über den angezeigten Bereich, wobei die Zeitrauminformation den anzeigbaren Zeitraum repräsentiert und die Daten für einer Anzeige derart bereitgestellt werden, dass eine Anzeige/Nicht-Anzeige des zweiten Videos zu einem beliebigen Zeitpunkt innerhalb des anzeigbaren<!-- EPO <DP n="58"> --> Zeitraums schaltbar ist, der im ersten Video bestimmt ist, und</claim-text>
wobei die Information über den angezeigten Bereich im anzeigbaren Zeitraum eine räumliche Position im ersten Video repräsentiert, die sich als Funktion der Zeitinformation derart ändert, dass sie im anzeigbaren Zeitraum nicht konstant ist.</claim-text></claim><claim id="c-de-01-0008" num="0008"><claim-text>Datenerzeugungsvorrichtung nach Anspruch 7,<br/>
welche des Weiteren eine Schreibeinrichtung zum Schreiben der erzeugten Daten für eine Anzeige auf einem Aufzeichnungsmedium aufweist.</claim-text></claim><claim id="c-de-01-0009" num="0009"><claim-text>Datenerzeugungsvorrichtung nach Anspruch 7 oder 8,<br/>
wobei die Information über den angezeigten Bereich einen Satz von Koordinaten eines oberen linken Vertex und eines rechteckigen Bereichs für ein Anzeigen des Videos aufweist.</claim-text></claim><claim id="c-de-01-0010" num="0010"><claim-text>Datenerzeugungsvorrichtung nach Anspruch 7,<br/>
wobei die Information (1102) über den angezeigten Bereich Information über den angezeigten Bereich ist, welche eine Position im ersten Video repräsentiert, an welcher das zweite Video anzeigbar ist, wenn das zweite Video zur Anzeige zu dem mindestens einen Zeitbereich geschaltet wird.</claim-text></claim><claim id="c-de-01-0011" num="0011"><claim-text>Datenerzeugungsvorrichtung nach Anspruch 10,<br/>
welche des Weiteren eine Schreibeinrichtung zum Schreiben der erzeugten Daten für eine Anzeige auf einem Aufzeichnungsmedium aufweist.</claim-text></claim><claim id="c-de-01-0012" num="0012"><claim-text>Datenerzeugungsvorrichtung nach Anspruch 10 oder 11,<br/>
wobei die Information über den anzeigbaren Bereich einen Satz von Koordinaten eines oberen linken Vertex und eines anzeigbaren rechteckigen Bereichs für das zweite Video enthält.</claim-text></claim><claim id="c-de-01-0013" num="0013"><claim-text>Programm, welches bewirkt, dass ein Computer, wobei der Computer ein erstes Video und ein zweites Video empfängt und das erste Video, das mit dem zweiten Video synthetisiert ist, ausgibt, wobei das zweite Video derart bereitgestellt wird, dass eine Anzeige/Nicht-Anzeige des zweiten Videos zu einem beliebigen Zeitpunkt innerhalb<!-- EPO <DP n="59"> --> eines anzeigbaren Zeitraums (201, 301, 501), welcher im ersten Video bestimmt ist, schaltbar ist, wobei der anzeigbare Zeitraum (201, 301, 501) einen Zeitbereich des ersten Videos repräsentiert, welcher die Anzeige des zweiten Videos erlaubt, ausführt:
<claim-text>eine Bestimmungsfunktion, welche
<claim-text>Daten für eine Anzeige empfängt, mit:
<claim-text>Zeitrauminformation, welche den anzeigbaren Zeitraum repräsentiert,</claim-text>
<claim-text>Zeitinformation, welche mindestens einen Zeitbereich im zweiten Video repräsentiert, der sich von einer Zeit im ersten Video unterscheidet, und</claim-text>
<claim-text>Information (1102) über den angezeigten Bereich, welche eine Position im ersten Video repräsentiert, an welcher das zweite Video angezeigt wird, wenn das zweite Video zum Anzeigen geschaltet ist, und zwar vermittelt in Korrespondenz mit dem mindestens einen Zeitbereich im zweiten Video, und</claim-text></claim-text>
<claim-text>eine Steuerung ausführt zum Bestimmen einer angezeigten Position innerhalb des ersten Videos zu der Zeit, wenn das zweite Video zu einem beliebigen Zeitpunkt angezeigt wird, und zwar auf der Grundlage der Daten für eine Anzeige, und</claim-text></claim-text>
<claim-text>eine Synthetisierungsfunktion, welche eine Steuerung ausführt zum Setzen und Synthetisieren des zweiten Videos über der angezeigten Position innerhalb des ersten Videos, welche durch die Bestimmungsfunktion bestimmt ist,</claim-text>
<claim-text>wobei die Daten für eine Anzeige derart bereitgestellt werden, dass eine Anzeige/Nicht-Anzeige des zweiten Videos zu einem beliebigen Zeitpunkt innerhalb eines anzeigbaren Zeitraums schaltbar ist, der im ersten Video bestimmt ist, und</claim-text>
<claim-text>wobei die Information über den angezeigten Bereich im anzeigbaren Zeitraum eine räumliche Position im ersten Video repräsentiert, welche sich als Funktion der Zeitinformation derart ändert, dass die räumliche Position im anzeigbaren Zeitraum nicht konstant ist.</claim-text></claim-text></claim><claim id="c-de-01-0014" num="0014"><claim-text>Programm nach Anspruch 13,<br/>
welches des Weiteren bewirkt, dass der Computer eine Schreibfunktion zum Schreiben der erzeugten Daten für eine Anzeige auf einem Aufzeichnungsmedium ausführt.</claim-text></claim><claim id="c-de-01-0015" num="0015"><claim-text>Programm nach Anspruch 13 oder 14,<br/>
<!-- EPO <DP n="60"> -->wobei die Information über den angezeigten Bereich einen Satz von Koordinaten eines oberen linken Vertex und eines rechteckigen Bereichs für ein Anzeigen des Videos aufweist.</claim-text></claim><claim id="c-de-01-0016" num="0016"><claim-text>Programm nach Anspruch 13,<br/>
wobei die Information (1102) über den angezeigten Bereich Information über den angezeigten Bereich ist, welche eine Position im ersten Video repräsentiert, an welcher das zweite Video angezeigt wird, wenn das zweite Video zum Anzeigen geschaltet wird, vermittelt in Korrespondenz mit dem mindestens einen Zeitbereich im zweiten Video.</claim-text></claim><claim id="c-de-01-0017" num="0017"><claim-text>Programm nach Anspruch 16,<br/>
welches des Weiteren bewirkt, dass der Computer eine Schreibfunktion zum Schreiben der erzeugten Daten für eine Anzeige auf einem Aufzeichnungsmedium ausführt.</claim-text></claim><claim id="c-de-01-0018" num="0018"><claim-text>Programm nach Anspruch 16 oder 17,<br/>
wobei die Information über den anzeigbaren Bereich einen Satz von Koordinaten eines oberen linken Vertex und eines anzeigbaren rechteckigen Bereichs für das zweite Video enthält.</claim-text></claim><claim id="c-de-01-0019" num="0019"><claim-text>Videosynthetisierungsvorrichtung, welche ein erstes Video und ein zweites Video empfängt und das erste Video synthetisiert mit dem zweiten Video ausgibt,<br/>
wobei das zweite Video derart bereitgestellt ist, dass eine Anzeige/Nicht-Anzeige des zweiten Videos zu einem beliebigen Zeitpunkt innerhalb eines anzeigbaren Zeitraums (201, 301, 501) schaltbar ist, welcher im ersten Video bestimmt ist, wobei der anzeigbare Zeitraum (201, 301, 501) eine Zeitspanne des ersten Videos repräsentiert, welcher eine Anzeige des zweiten Videos ermöglicht,<br/>
wobei die Videosynthetisierungsvorrichtung aufweist:
<claim-text>eine Bestimmungseinrichtung,
<claim-text>welche Daten für eine Anzeige empfängt mit:
<claim-text>Zeitrauminformation, welche den anzeigbaren Zeitraum repräsentiert,</claim-text>
<claim-text>Zeitinformation, welche mindestens einen Zeitbereich im zweiten Video repräsentiert, welcher unterschiedlich ist zur Zeit im ersten Video, und<!-- EPO <DP n="61"> --></claim-text>
<claim-text>Information (1102) über den anzeigbaren Bereich, welcher eine Position im ersten Video repräsentiert, an welcher das zweite Video angezeigt wird, wenn das zweite Video zum Anzeigen geschaltet wird vermittelt in Korrespondenz mit dem mindestens einen Zeitbereich im zweiten Video, und</claim-text></claim-text>
<claim-text>welche eine Position innerhalb des ersten Videos bestimmt, wenn das zweite Video auf der Grundlage der Daten für eine Anzeige angezeigt wird, und</claim-text></claim-text>
<claim-text>eine Synthetisierungseinrichtung zum Setzen und Synthetisieren des zweiten Videos über der angezeigten Position innerhalb des ersten Videos, welche durch die Bestimmungseinrichtung bestimmt wird,</claim-text>
wobei die Daten für eine Anzeige derart bereitgestellt werden, dass eine Anzeige/Nicht-Anzeige des zweiten Videos zu einem beliebigen Zeitpunkt innerhalb eines anzeigbaren Zeitraums schaltbar ist, der im ersten Video bestimmt ist, und<br/>
wobei die Information über den angezeigten Bereich im anzeigbaren Zeitraum eine räumliche Position im ersten Video repräsentiert, welche sich als Funktion der Zeitinformation derart ändert, dass die räumliche Position im anzeigbaren Zeitraum nicht konstant ist.</claim-text></claim><claim id="c-de-01-0020" num="0020"><claim-text>Videosynthetisierungsvorrichtung nach Anspruch 19,<br/>
wobei die Information (1102) des angezeigten Bereichs Information über den anzeigbaren Bereich ist, welche eine Position im ersten Video repräsentiert, an welcher das zweite Video anzeigbar ist, wenn das zweite Video zum Anzeigen geschaltet wird, und zwar vermittelt in Korrespondenz mit dem mindestens einen Zeitbereich im zweiten Video,</claim-text></claim></claims><claims mxw-id="PCLM56984637" lang="EN" load-source="patent-office"><!-- EPO <DP n="47"> --><claim id="c-en-01-0001" num="0001"><claim-text>A recording medium recorded with a first video, a second video, and data for display for displaying the first video and the second video by superimposing the second video over the first video in a picture-in-picture format,<br/>
wherein<br/>
the second video is provided in such a manner that display/non-display of the second video is switchable at an arbitrary point of time within a displayable period (201, 301, 501) designated in the first video, the displayable period (201, 301, 501) representing a time range of the first video that allows for display of the second video,<br/>
the data for display is data that includes:
<claim-text>period information representing the displayable period;</claim-text>
<claim-text>time information representing at least one section of time in the second video differing from time in the first video, and</claim-text>
<claim-text>displayed area information (1102) that represents a position in the first video in which the second video is displayed when the second video is switched to displaying, imparted in correspondence with the at least one section of time in the second video,</claim-text>
the data for display being provided such that display/non-display of the second video is switchable at an arbitrary point of time within the displayable period being designated in the first video,<br/>
the recording medium is operable to be reproduced by a video synthesizing apparatus configured to read out the first video, the second video and the data for display, and synthesize the second video over the displayed position inside the first video designated based on the data for display, and<br/>
<!-- EPO <DP n="48"> -->the displayed area information represents, in the displayable period, a spatial position in the first video that changes as a function of the time information, such that the spatial position is not constant in the displayable period.</claim-text></claim><claim id="c-en-01-0002" num="0002"><claim-text>The recording medium according to claim 1, wherein the recording medium is further recorded with a program, the data for display and the programme are used for displaying the first video and the second video by superimposing the second video over the first video in the picture-in-picture format, and the program reads out the first video, the second video and the data for display, designates a displayed position inside the first video based on the data for display when the second video is displayed at an arbitrary point of time, and synthesizes the second video over the displayed position.</claim-text></claim><claim id="c-en-01-0003" num="0003"><claim-text>The recording medium according to Claim 1 or 2, wherein the displayed area information includes a set of coordinates of an upper left vertex of a rectangular area for displaying the second video.</claim-text></claim><claim id="c-en-01-0004" num="0004"><claim-text>The recording medium according to claim 1, wherein the displayed area information (1102) is displayable area information that represents a position in the first video in which the second video is displayable when the second video is switched to displaying, imparted in correspondence with the at least one section of time in the second video.</claim-text></claim><claim id="c-en-01-0005" num="0005"><claim-text>The recording medium according to claim 1, wherein the recording medium is further recorded with a program, the data for display and the program are used for displaying the first video and the second video by superimposing the second video over the first video in the picture-in-picture format, and the program reads out the first video, the second video and the data for display, designates a displayed position<!-- EPO <DP n="49"> --> inside the first video based on the data for display when the second video is displayed at an arbitrary point of time, and synthesizes the second video over the displayed position.</claim-text></claim><claim id="c-en-01-0006" num="0006"><claim-text>The recording medium according to Claim 4 or 5, wherein the displayable area information includes a set of coordinates of an upper left vertex of a displayable rectangular area for the second video.</claim-text></claim><claim id="c-en-01-0007" num="0007"><claim-text>A data generating apparatus which generates data for display that is used for laying and synthesizing a second video over a first video and outputting a video in the picture-in-picture format,<br/>
wherein<br/>
the second video is provided in such a manner that display/non-display of the second video is switchable at an arbitrary point of time within a displayable period (201, 301, 501) designated in the first video, the displayable period (201, 301, 501) representing a time range of the first video that allows the display of the second video,<br/>
the data generating apparatus includes:
<claim-text>a designating means for designating the displayable period,</claim-text>
<claim-text>a designating means for designating time information representing at least one section of time in the second video;</claim-text>
<claim-text>a designating means for designating displayed area information (1120) that represents a position in the first video in which the second video is displayed when the second video is switched to displaying at the at least one section of time, and</claim-text>
<claim-text>a generating means for generating the data for display including period information and the time information and displayed<!-- EPO <DP n="50"> --> area information, the period information representing the displayable period, and the data for display being provided such that display/non-display of the second video is switchable at an arbitrary point of time within the displayable period being designated in the first video, and</claim-text>
<claim-text>the displayed area information represents, in the displayable period, a spatial position in the first video that changes as a function of the time information, such that the spatial position is not constant in the displayable period.</claim-text></claim-text></claim><claim id="c-en-01-0008" num="0008"><claim-text>The data generating apparatus according to claim 7, further comprising a writing means for writing the generated data for display onto a recording medium.</claim-text></claim><claim id="c-en-01-0009" num="0009"><claim-text>The data generating apparatus according to claim 7 or 8, wherein the displayed area information includes a set of coordinates of an upper left vertex of a rectangular area for displaying the second video.</claim-text></claim><claim id="c-en-01-0010" num="0010"><claim-text>The data generating apparatus according to claim 7, wherein the displayed area information (1102) is displayable area information that represents a position in the first video in which the second video is displayable when the second video is switched to displaying at the at least one section of time.</claim-text></claim><claim id="c-en-01-0011" num="0011"><claim-text>The data generating apparatus according to claim 10, further comprising a writing means for writing the generated data for display onto a recording medium.</claim-text></claim><claim id="c-en-01-0012" num="0012"><claim-text>The data generating apparatus according to claim 10 or 11, wherein the displayable area information includes a set of coordinates of an upper left vertex of a displayable rectangular area for the second video.<!-- EPO <DP n="51"> --></claim-text></claim><claim id="c-en-01-0013" num="0013"><claim-text>A program which makes a computer, said computer receiving a first video and a second video and outputting the first video synthesized with the second video, wherein the second video is provided in such a manner that display/non-display of the second video is switchable at an arbitrary point of time within a displayable period (201, 301, 501) designated in the first video, the displayable period (201, 301, 501) representing a time range of the first video that allows the display of the second video, perform:
<claim-text>a designating function which
<claim-text>receives data for display which includes:
<claim-text>period information representing the displayable period;</claim-text>
<claim-text>time information representing at least one section of time in the second video differing from time in the first video; and</claim-text>
<claim-text>displayed area information (1102) that represents a position in the first video in which the second video is displayed when the second video is switched to displaying, imparted in correspondence with the at least one section of time in the second video, and</claim-text>
<claim-text>performs a control for designating a displayed position inside the first video at the time when the second video is displayed at an arbitrary point of time, based on the data for display, and</claim-text></claim-text></claim-text>
<claim-text>a synthesizing function which performs a control for laying and synthesizing the second video over the displayed position inside the first video, designated by the designating function, wherein</claim-text>
<claim-text>the data for display is provided such that display/non-display of the second video is switchable at an arbitrary point of time within the displayable period being designated in the first video, and<!-- EPO <DP n="52"> --></claim-text>
<claim-text>the displayed area information represents, in the displayable period, a spatial position in the first video that changes as a function of the time information, such that the spatial position is not constant in the displayable period.</claim-text></claim-text></claim><claim id="c-en-01-0014" num="0014"><claim-text>The program according to claim 13, further making the computer perform a writing function for writing the generated data for display onto a recording medium.</claim-text></claim><claim id="c-en-01-0015" num="0015"><claim-text>The program according to claim 13 or 14, wherein the displayed area information includes a set of coordinates of an upper left vertex of a rectangular area for displaying the second video.</claim-text></claim><claim id="c-en-01-0016" num="0016"><claim-text>The program according to claim 13, wherein the displayed area information (1102) is displayable area information that represents a position in the first video in which the second video is displayed when the second video is switched to displaying, imparted in correspondence with the at least one section of time in the second video.</claim-text></claim><claim id="c-en-01-0017" num="0017"><claim-text>The program according to claim 16, further making the computer perform a writing function for writing the generated data for display onto a recording medium.</claim-text></claim><claim id="c-en-01-0018" num="0018"><claim-text>The program according to claim 16 or 17, wherein the displayable area information includes a set of coordinates of an upper left vertex of a displayable rectangular area for the second video.</claim-text></claim><claim id="c-en-01-0019" num="0019"><claim-text>A video synthesizing apparatus which receives a first video and a second video and outputs the first video synthesized with the second video,<br/>
wherein<br/>
<!-- EPO <DP n="53"> -->the second video is provided in such a manner that display/non-display of the second video is switchable at an arbitrary point of time within a displayable period (201, 301, 501) designated in the first video, the displayable period (201, 301, 501) representing a time range of the first video that allows the display of the second video,<br/>
the video synthesizing apparatus includes:
<claim-text>a designating means which receives data for display including:
<claim-text>period information representing the displayable period;</claim-text>
<claim-text>time information representing at least one section of time in the second video differing from time in the first video; and</claim-text>
<claim-text>displayed area information (1102) representing a position in the first video in which the second video is displayed when the second video is switched to displaying at the at least one section of time, imparted in correspondence with the at least one section of time in the second video, and</claim-text>
<claim-text>designates a displayed position inside the first video when the second video is displayed based on the data for display; and</claim-text>
<claim-text>a synthesizing means for laying and synthesizing the second video over the displayed position inside the first video, designated by the designating means,</claim-text></claim-text>
<claim-text>wherein</claim-text>
<claim-text>the data for display is provided such that display/non-display of the second video is switchable at an arbitrary point of time within the displayable period being designated in the first video, and<!-- EPO <DP n="54"> --></claim-text>
<claim-text>the displayed area information represents, in the displayable period, a spatial position in the first video that changes as a function of the time information, such that the spatial position is not constant in the displayable period.</claim-text></claim-text></claim><claim id="c-en-01-0020" num="0020"><claim-text>The video synthesizing apparatus according to claim 19, wherein the displayed area information (1102) is displayable area information representing a position in the first video in which the second video is displayable when the second video is switched to displaying, imparted in correspondence with the at least one section of time in the second video.</claim-text></claim></claims><claims mxw-id="PCLM56984638" lang="FR" load-source="patent-office"><!-- EPO <DP n="62"> --><claim id="c-fr-01-0001" num="0001"><claim-text>Support d'enregistrement enregistré avec une première vidéo, une deuxième vidéo et des données pour l'affichage pour afficher la première vidéo et la deuxième vidéo en superposant la deuxième vidéo sur la première dans un format d'incrustation d'image,<br/>
étant précisé<br/>
que la deuxième vidéo est prévue de telle sorte que son affichage/non affichage soit commutable à un moment arbitraire à l'intérieur d'une période affichable (201, 301, 501) désignée dans la première vidéo, la période affichable (201, 301, 501) représentant un intervalle de temps de la première vidéo qui permet l'affichage de la deuxième vidéo,<br/>
que les données pour l'affichage sont des données qui contiennent :
<claim-text>des informations de période représentant la période affichable ;</claim-text>
<claim-text>des informations de temps représentant au moins une section de temps dans la deuxième vidéo différente du temps dans la première vidéo, et</claim-text>
<claim-text>des informations de zone affichée (1102) qui représentent une position dans la première vidéo où la deuxième vidéo est affichée quand la deuxième vidéo est commutée pour l'affichage, attribuée en correspondance avec ladite section de temps dans la deuxième vidéo,</claim-text>
les données pour l'affichage étant fournies de telle sorte que l'affichage/non affichage de la deuxième vidéo soit commutable à un moment arbitraire à l'intérieur de la période affichable, désignée dans la première vidéo,<br/>
que le support d'enregistrement est apte à être reproduit par un synthétiseur vidéo conçu pour lire la première vidéo, la deuxième vidéo et les données pour l'affichage, et pour synthétiser la deuxième vidéo sur la position affichée à l'intérieur de la première vidéo, désignée sur la base des données pour l'affichage, et<br/>
<!-- EPO <DP n="63"> -->que les informations de zone affichée représentent, dans la période affichable, une position spatiale dans la première vidéo, qui change en fonction des informations de temps, de telle sorte que la position spatiale n'est pas constante dans la période affichable.</claim-text></claim><claim id="c-fr-01-0002" num="0002"><claim-text>Support d'enregistrement selon la revendication 1, étant précisé que le support d'enregistrement est également enregistré avec un programme, que les données pour l'affichage et le programme sont utilisés pour afficher la première vidéo et la deuxième vidéo en superposant la deuxième vidéo sur la première dans le format d'incrustation, et que le programme lit la première vidéo, la deuxième vidéo et les données pour l'affichage, désigne une position affichée à l'intérieur de la première vidéo sur la base des données pour l'affichage quand la deuxième vidéo est affichée à un moment arbitraire, et synthétise la deuxième vidéo sur l'endroit affiché.</claim-text></claim><claim id="c-fr-01-0003" num="0003"><claim-text>Support d'enregistrement selon la revendication 1 ou 2, étant précisé que les informations de zone affichée contiennent une série de coordonnées d'un sommet gauche supérieur d'une zone rectangulaire pour afficher la deuxième vidéo.</claim-text></claim><claim id="c-fr-01-0004" num="0004"><claim-text>Support d'enregistrement selon la revendication 1, étant précisé que les informations de zone affichée (1102) sont des informations de zone affichable qui représentent une position, dans la première vidéo, où la deuxième vidéo est affichable quand la deuxième vidéo est commutée pour l'affichage, attribuée en correspondance avec ladite section de temps dans la deuxième vidéo.</claim-text></claim><claim id="c-fr-01-0005" num="0005"><claim-text>Support d'enregistrement selon la revendication 1, étant précisé que le support d'enregistrement est également enregistré avec un programme, que les données pour l'affichage et le programme sont utilisés pour afficher la première vidéo et la deuxième vidéo en superposant la deuxième vidéo sur la première dans le format d'incrustation d'image, et que le programme lit la première vidéo, la deuxième vidéo et les données pour<!-- EPO <DP n="64"> --> l'affichage, désigne une position affichée à l'intérieur de la première vidéo sur la base des données pour l'affichage quand la deuxième vidéo est affichée à un moment arbitraire, et synthétise la deuxième vidéo sur la position affichée.</claim-text></claim><claim id="c-fr-01-0006" num="0006"><claim-text>Support d'enregistrement selon la revendication 4 ou 5, étant précisé que les informations de zone affichable contiennent une série de coordonnées d'un sommet gauche supérieur d'une zone rectangulaire affichable pour la deuxième vidéo.</claim-text></claim><claim id="c-fr-01-0007" num="0007"><claim-text>Appareil générateur de données qui génère des données pour l'affichage, qui est utilisé pour placer et synthétiser une deuxième vidéo sur une première vidéo et pour sortir une vidéo dans le format d'incrustation d'image,<br/>
étant précisé<br/>
que la deuxième vidéo est prévue de telle sorte que son affichage/non affichage soit commutable à un moment arbitraire à l'intérieur d'une période affichable (201, 301, 501) désignée dans la première vidéo, la période affichable (201, 301, 501) représentant un intervalle de temps de la première vidéo qui permet l'affichage de la deuxième vidéo,<br/>
que l'appareil générateur de données contient :
<claim-text>des moyens de désignation pour désigner la période affichable,</claim-text>
<claim-text>des moyens de désignation pour désigner des informations de temps représentant au moins une section de temps dans la deuxième vidéo ;</claim-text>
<claim-text>des moyens de désignation pour désigner des informations de zone affichée (1120) qui représentent une position dans la première vidéo où la deuxième vidéo est affichée quand la deuxième vidéo est commutée pour l'affichage au niveau de ladite section de temps, et</claim-text>
des moyens générateurs pour générer les données pour l'affichage, contenant des informations de période, les<!-- EPO <DP n="65"> --> informations de temps et des informations de zone affichée, les informations de période représentant la période affichable, et les données pour l'affichage étant fournies de telle sorte que l'affichage/non affichage de la deuxième vidéo soit commutable à un moment arbitraire à l'intérieur de la période affichable désignée dans la première vidéo, et<br/>
que les informations de zone affichée représentent, dans la période affichable, une position spatiale dans la première vidéo qui change en fonction des informations de temps, de telle sorte que la position spatiale n'est pas constante dans la période affichable.</claim-text></claim><claim id="c-fr-01-0008" num="0008"><claim-text>Appareil générateur de données selon la revendication 7, comprenant également des moyens d'écriture pour écrire les données générées, pour un affichage sur un support d'enregistrement.</claim-text></claim><claim id="c-fr-01-0009" num="0009"><claim-text>Appareil générateur de données selon la revendication 7 ou 8, étant précisé que les informations de zone affichée contiennent une série de coordonnées d'un sommet supérieur gauche d'une zone rectangulaire pour afficher la deuxième vidéo.</claim-text></claim><claim id="c-fr-01-0010" num="0010"><claim-text>Appareil générateur de données selon la revendication 7, étant précisé que les informations de zone affichée (1102) sont des informations de zone affichable qui représentent une position, dans la première vidéo, où la deuxième vidéo est affichable quand la deuxième vidéo est commutée pour l'affichage au niveau de ladite section de temps.</claim-text></claim><claim id="c-fr-01-0011" num="0011"><claim-text>Appareil générateur de données selon la revendication 10, comprenant également des moyens d'écriture pour écrire les données générées, pour un affichage sur un support d'enregistrement.</claim-text></claim><claim id="c-fr-01-0012" num="0012"><claim-text>Appareil générateur de données selon la revendication 10 ou 11, étant précisé que les informations de zone affichable contiennent une série de coordonnées d'un sommet supérieur gauche d'une zone rectangulaire affichable pour la deuxième vidéo.<!-- EPO <DP n="66"> --></claim-text></claim><claim id="c-fr-01-0013" num="0013"><claim-text>Programme qui fait exécuter à un ordinateur - ledit ordinateur recevant une première vidéo et une deuxième vidéo et sortant la première vidéo synthétisée avec la deuxième vidéo, étant précisé que la deuxième vidéo est prévue de telle sorte que son affichage/non affichage soit commutable à un moment arbitraire à l'intérieur d'une période affichable (201, 301, 501) désignée dans la première vidéo, la période affichable (201, 301, 501) représentant un intervalle de temps de la première vidéo qui permet l'affichage de la deuxième vidéo -<br/>
une fonction de désignation qui
<claim-text>reçoit des données pour l'affichage, qui contiennent :
<claim-text>des informations de période représentant la période affichable ;</claim-text>
<claim-text>des informations de temps représentant au moins une section de temps dans la deuxième vidéo différente du temps dans la première vidéo, et</claim-text>
<claim-text>des informations de zone affichée (1102) qui représentent une position dans la première vidéo où la deuxième vidéo est affichée quand la deuxième vidéo est commutée pour l'affichage, attribuée en correspondance avec ladite section de temps dans la deuxième vidéo, et</claim-text>
<claim-text>exécute une commande pour désigner une position affichée à l'intérieur de la première vidéo au moment ou la deuxième vidéo est affichée à un moment arbitraire, sur la base des données pour l'affichage, et</claim-text>
une fonction de synthèse qui exécute une commande pour placer et synthétiser la deuxième vidéo sur la position affichée à l'intérieur de la première vidéo et désignée par la fonction de désignation, étant précisé<br/>
que les données pour l'affichage sont fournies de telle sorte que l'affichage/non affichage de la deuxième vidéo soit commutable à un moment arbitraire à l'intérieur<!-- EPO <DP n="67"> --> de la période affichable, désignée dans la première vidéo, et<br/>
que les informations de zone affichée représentent, dans la période affichable, une position spatiale dans la première vidéo, qui change en fonction des informations de temps, de telle sorte que la position spatiale n'est pas constante dans la période affichable.</claim-text></claim-text></claim><claim id="c-fr-01-0014" num="0014"><claim-text>Programme selon la revendication 13, qui fait également exécuter à l'ordinateur une fonction d'écriture pour écrire les données générées, pour un affichage sur un support d'enregistrement.</claim-text></claim><claim id="c-fr-01-0015" num="0015"><claim-text>Programme selon la revendication 13 ou 14, étant précisé que les informations de zone affichée contiennent une série de coordonnées d'un sommet supérieur gauche d'une zone rectangulaire pour afficher la deuxième vidéo.</claim-text></claim><claim id="c-fr-01-0016" num="0016"><claim-text>Programme selon la revendication 13, étant précisé que les informations de zone affichée (1102) sont des informations de zone affichable qui représentent une position, dans la première vidéo, où la deuxième vidéo est affichée quand la deuxième vidéo est commutée pour l'affichage, et qui est attribuée en correspondance avec ladite section de temps dans la deuxième vidéo.</claim-text></claim><claim id="c-fr-01-0017" num="0017"><claim-text>Programme selon la revendication 16, qui fait également exécuter à l'ordinateur une fonction d'écriture pour écrire les données générées, pour un affichage sur un support d'enregistrement.</claim-text></claim><claim id="c-fr-01-0018" num="0018"><claim-text>Programme selon la revendication 16 ou 17, étant précisé que les informations de zone affichable contiennent une série de coordonnées d'un sommet supérieur gauche d'une zone rectangulaire affichable pour la deuxième vidéo.</claim-text></claim><claim id="c-fr-01-0019" num="0019"><claim-text>Appareil de synthèse vidéo qui reçoit une première vidéo et une deuxième vidéo et sort la première vidéo synthétisée avec la deuxième vidéo,<br/>
étant précisé<br/>
que la deuxième vidéo est prévue de telle sorte que son affichage/non affichage soit commutable à un moment arbitraire à l'intérieur d'une période affichable (201,<!-- EPO <DP n="68"> --> 301, 501) désignée dans la première vidéo, la période affichable (201, 301, 501) représentant un intervalle de temps de la première vidéo qui permet l'affichage de la deuxième vidéo,<br/>
le synthétiseur vidéo comprenant :
<claim-text>des moyens de désignation qui reçoivent des données pour un affichage, contenant :
<claim-text>des informations de période représentant la période affichable ;</claim-text>
<claim-text>des informations de temps représentant au moins une section de temps dans la deuxième vidéo différente du temps dans la première vidéo ; et</claim-text>
<claim-text>des informations de zone affichée (1102) représentant une position dans la première vidéo où la deuxième vidéo est affichée quand la deuxième vidéo est commutée pour l'affichage au niveau de ladite section de temps, attribuée en correspondance avec ladite section de temps dans la deuxième vidéo, et</claim-text>
<claim-text>qui désignent une position affichée à l'intérieur de la première vidéo quand la deuxième vidéo est affichée sur la base des données pour l'affichage ;</claim-text>
<claim-text>et</claim-text>
<claim-text>des moyens de synthèse pour placer et synthétiser la deuxième vidéo sur la position affichée, à l'intérieur de la première vidéo, désignée par les moyens de désignation,</claim-text></claim-text>
étant précisé<br/>
que les données pour l'affichage sont fournies de telle sorte que l'affichage/non affichage de la deuxième vidéo soit commutable à un moment arbitraire à l'intérieur de la période affichable, désignée dans la première vidéo, et<br/>
que les informations de zone affichée représentent, dans la période affichable, une position spatiale dans la première vidéo, qui change en fonction des informations de<!-- EPO <DP n="69"> --> temps, de telle sorte que la position spatiale n'est pas constante dans la période affichable.</claim-text></claim><claim id="c-fr-01-0020" num="0020"><claim-text>Appareil de synthèse vidéo selon la revendication 19, étant précisé que les informations de zone affichée (1102) sont des informations de zone affichable représentant une position, dans la première vidéo, où la deuxième vidéo est affichable quand la deuxième vidéo est commutée pour l'affichage, attribuée en correspondance avec ladite section de temps dans la deuxième vidéo.</claim-text></claim></claims><drawings mxw-id="PDW16671916" load-source="patent-office"><!-- EPO <DP n="70"> --><figure id="f0001" num="1"><img id="if0001" file="imgf0001.tif" wi="165" he="232" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="71"> --><figure id="f0002" num="2(a),2(b),2(c)"><img id="if0002" file="imgf0002.tif" wi="165" he="229" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="72"> --><figure id="f0003" num="3(a),3(b),3(c)"><img id="if0003" file="imgf0003.tif" wi="165" he="231" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="73"> --><figure id="f0004" num="4"><img id="if0004" file="imgf0004.tif" wi="153" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="74"> --><figure id="f0005" num="5(a),5(b),5(c)"><img id="if0005" file="imgf0005.tif" wi="165" he="229" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="75"> --><figure id="f0006" num="6"><img id="if0006" file="imgf0006.tif" wi="164" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="76"> --><figure id="f0007" num="7"><img id="if0007" file="imgf0007.tif" wi="107" he="231" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="77"> --><figure id="f0008" num="8"><img id="if0008" file="imgf0008.tif" wi="116" he="229" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="78"> --><figure id="f0009" num="9"><img id="if0009" file="imgf0009.tif" wi="117" he="229" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="79"> --><figure id="f0010" num="10"><img id="if0010" file="imgf0010.tif" wi="119" he="228" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="80"> --><figure id="f0011" num="11(a),11(b),11(c)"><img id="if0011" file="imgf0011.tif" wi="165" he="215" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="81"> --><figure id="f0012" num="12(a),12(b)"><img id="if0012" file="imgf0012.tif" wi="151" he="201" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="82"> --><figure id="f0013" num="13(a),13(b)"><img id="if0013" file="imgf0013.tif" wi="153" he="202" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="83"> --><figure id="f0014" num="14(a),14(b)"><img id="if0014" file="imgf0014.tif" wi="147" he="201" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="84"> --><figure id="f0015" num="15(a),15(b)"><img id="if0015" file="imgf0015.tif" wi="158" he="214" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="85"> --><figure id="f0016" num="16(a),16(b),16(c),16(d)"><img id="if0016" file="imgf0016.tif" wi="162" he="216" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="86"> --><figure id="f0017" num="17"><img id="if0017" file="imgf0017.tif" wi="148" he="226" img-content="drawing" img-format="tif"/></figure></drawings><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
