<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2678860-A1" country="EP" doc-number="2678860" kind="A1" date="20140101" family-id="43975437" file-reference-id="317082" date-produced="20180823" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="146550663" ucid="EP-2678860-A1"><document-id><country>EP</country><doc-number>2678860</doc-number><kind>A1</kind><date>20140101</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-12703169-A" is-representative="NO"><document-id mxw-id="PAPP154824586" load-source="docdb" format="epo"><country>EP</country><doc-number>12703169</doc-number><kind>A</kind><date>20120125</date><lang>IT</lang></document-id><document-id mxw-id="PAPP220438210" load-source="docdb" format="original"><country>EP</country><doc-number>12703169.8</doc-number><date>20120125</date></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC140446236" ucid="IB-2012050346-W" linkage-type="W" load-source="docdb"><document-id format="epo"><country>IB</country><doc-number>2012050346</doc-number><kind>W</kind><date>20120125</date></document-id></priority-claim><priority-claim mxw-id="PPC140449184" ucid="IT-MI20110103-A" load-source="docdb"><document-id format="epo"><country>IT</country><doc-number>MI20110103</doc-number><kind>A</kind><date>20110128</date></document-id></priority-claim></priority-claims><technical-data><classification-ipc><edition>7</edition><main-classification>G10L  11/00</main-classification></classification-ipc><classifications-ipcr><classification-ipcr mxw-id="PCL1988105577" load-source="docdb">G10L  19/02        20130101ALI20120815BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1988117873" load-source="docdb">G10L  25/48        20130101A I20130921RMEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-2128530886" load-source="docdb" scheme="CPC">G10L  25/48        20130101 FI20141203BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2128532126" load-source="docdb" scheme="CPC">G10L  19/0204      20130101 LA20141203BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT132184473" lang="DE" load-source="patent-office">VERFAHREN UND VORRICHTUNG ZUM SCANNEN UND/ODER SYNCHRONISIEREN VON AUDIO/VIDEO-EREIGNISSEN</invention-title><invention-title mxw-id="PT132184474" lang="EN" load-source="patent-office">PROCESS AND MEANS FOR SCANNING AND/OR SYNCHRONIZING AUDIO/VIDEO EVENTS</invention-title><invention-title mxw-id="PT132184475" lang="FR" load-source="patent-office">PROCÉDÉ ET MOYEN PERMETTANT DE NUMÉRISER ET/OU DE SYNCHRONISER DES ÉVÉNEMENTS AUDIO/VIDÉO</invention-title></technical-data><parties><applicants><applicant mxw-id="PPAR918135585" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>UNIVERSAL MULTIMEDIA ACCESS S R L</last-name><address><country>IT</country></address></addressbook></applicant><applicant mxw-id="PPAR918146599" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>UNIVERSAL MULTIMEDIA ACCESS S.R.L.</last-name></addressbook></applicant><applicant mxw-id="PPAR918988421" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Universal Multimedia Access S.r.L.</last-name><iid>101328667</iid><address><street>Viale Lombardia 32</street><city>20131 Milano (MI)</city><country>IT</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR918163204" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>CAFARELLA CARLO GUIDO</last-name><address><country>IT</country></address></addressbook></inventor><inventor mxw-id="PPAR918143464" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>CAFARELLA, Carlo Guido</last-name></addressbook></inventor><inventor mxw-id="PPAR918985723" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>CAFARELLA, Carlo Guido</last-name><address><street>Via Leopardi 13</street><city>I-20093 Cologno Monzese (MI)</city><country>IT</country></address></addressbook></inventor><inventor mxw-id="PPAR918166580" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>OLGENI GIACOMO</last-name><address><country>IT</country></address></addressbook></inventor><inventor mxw-id="PPAR918143088" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>OLGENI, GIACOMO</last-name></addressbook></inventor><inventor mxw-id="PPAR918980727" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>OLGENI, GIACOMO</last-name><address><street>Viale Abruzzi 41</street><city>I-20131 Milano (MI)</city><country>IT</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR918984579" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Pizzoli, Antonio</last-name><suffix>et al</suffix><iid>100043592</iid><address><street>Società Italiana Brevetti S.p.A Via Carducci 8</street><city>20123 Milano</city><country>IT</country></address></addressbook></agent></agents></parties><international-convention-data><pct-or-regional-filing-data ucid="IB-2012050346-W"><document-id><country>IB</country><doc-number>2012050346</doc-number><kind>W</kind><date>20120125</date><lang>EN</lang></document-id></pct-or-regional-filing-data><pct-or-regional-publishing-data ucid="WO-2012101586-A1"><document-id><country>WO</country><doc-number>2012101586</doc-number><kind>A1</kind><date>20120802</date><lang>EN</lang></document-id></pct-or-regional-publishing-data><designated-states><ep-contracting-states><country mxw-id="DS548911677" load-source="docdb">AL</country><country mxw-id="DS548860525" load-source="docdb">AT</country><country mxw-id="DS548895459" load-source="docdb">BE</country><country mxw-id="DS548921861" load-source="docdb">BG</country><country mxw-id="DS548914831" load-source="docdb">CH</country><country mxw-id="DS548895460" load-source="docdb">CY</country><country mxw-id="DS548812853" load-source="docdb">CZ</country><country mxw-id="DS548911682" load-source="docdb">DE</country><country mxw-id="DS548895461" load-source="docdb">DK</country><country mxw-id="DS548895466" load-source="docdb">EE</country><country mxw-id="DS548833406" load-source="docdb">ES</country><country mxw-id="DS548921866" load-source="docdb">FI</country><country mxw-id="DS548921867" load-source="docdb">FR</country><country mxw-id="DS548911683" load-source="docdb">GB</country><country mxw-id="DS548895467" load-source="docdb">GR</country><country mxw-id="DS548911684" load-source="docdb">HR</country><country mxw-id="DS548812854" load-source="docdb">HU</country><country mxw-id="DS548914832" load-source="docdb">IE</country><country mxw-id="DS548895468" load-source="docdb">IS</country><country mxw-id="DS548921868" load-source="docdb">IT</country><country mxw-id="DS548895469" load-source="docdb">LI</country><country mxw-id="DS548921869" load-source="docdb">LT</country><country mxw-id="DS548860526" load-source="docdb">LU</country><country mxw-id="DS548921874" load-source="docdb">LV</country><country mxw-id="DS548921875" load-source="docdb">MC</country><country mxw-id="DS548860527" load-source="docdb">MK</country><country mxw-id="DS548860528" load-source="docdb">MT</country><country mxw-id="DS548860529" load-source="docdb">NL</country><country mxw-id="DS548914833" load-source="docdb">NO</country><country mxw-id="DS548860530" load-source="docdb">PL</country><country mxw-id="DS548833407" load-source="docdb">PT</country><country mxw-id="DS548914871" load-source="docdb">RO</country><country mxw-id="DS548833408" load-source="docdb">RS</country><country mxw-id="DS548860531" load-source="docdb">SE</country><country mxw-id="DS548911685" load-source="docdb">SI</country><country mxw-id="DS548914954" load-source="docdb">SK</country><country mxw-id="DS548914955" load-source="docdb">SM</country><country mxw-id="DS548895478" load-source="docdb">TR</country></ep-contracting-states></designated-states></international-convention-data><office-specific-data><eptags><ep-no-a-document-published>*</ep-no-a-document-published></eptags></office-specific-data></bibliographic-data><abstract mxw-id="PA98583548" ref-ucid="WO-2012101586-A1" lang="EN" load-source="patent-office"><p num="0000">Process for scanning and/or synchronizing audio/video events that comprises the following operating steps: - at least one audio processor (AP1; AP2) acquires at least one signal (RS; SS) of the audio of an audio/video event; the audio processor (AP1; AP2) divides said signal (RS; SS) into a plurality (j) of segments (RSx) corresponding to different moments (tx) of the signal (RS; SS); the audio processor (AP1; AP2) generates a spectrogram (SG) comprising a plurality (n) of frequency bands (By) in each segment (RSx) of the signal (RS; SS); the audio processor (AP1; AP2) locates in the spectrogram (SG), among the bands (By) of each segment (RSx) of the signal (RS; SS), one or more peaks (Pxz) in which the magnitude (Mxy') of the corresponding band (By') is greater than the magnitudes (Mxy) of the other bands (By); - the audio processor (AP1; AP2) locates among said peaks (Pxz) of the spectrogram (SG) the transition peaks (P'xz) which at a given moment (tx') have a band (By') differing from the bands (By) of the peaks (Pxz) at a previous moment (tx'-l); the audio processor (AP1; AP2) combines in at least one or more transitions (TRw, TRw') the moment (tx') and the band (By') of a transition peak (P'x'z), with the moment (tx") and the band (By") of one or more subsequent transition peaks (P'x"z); the audio processor (API; AP2) associates one or more hashes (Hq) corresponding to one or more transitions (TRw, TRw') with the moment (tx') or the moments (tx', tx'") at which these transitions (TRw, TRw') occur in the signal (RS; SS). The present invention also relates to means (AP1; AP2, IF, DS) for scanning and/or synchronizing audio/video events.</p></abstract><abstract mxw-id="PA98951923" ref-ucid="WO-2012101586-A1" lang="EN" source="national office" load-source="docdb"><p>Process for scanning and/or synchronizing audio/video events that comprises the following operating steps: - at least one audio processor (AP1; AP2) acquires at least one signal (RS; SS) of the audio of an audio/video event; the audio processor (AP1; AP2) divides said signal (RS; SS) into a plurality (j) of segments (RSx) corresponding to different moments (tx) of the signal (RS; SS); the audio processor (AP1; AP2) generates a spectrogram (SG) comprising a plurality (n) of frequency bands (By) in each segment (RSx) of the signal (RS; SS); the audio processor (AP1; AP2) locates in the spectrogram (SG), among the bands (By) of each segment (RSx) of the signal (RS; SS), one or more peaks (Pxz) in which the magnitude (Mxy') of the corresponding band (By') is greater than the magnitudes (Mxy) of the other bands (By); - the audio processor (AP1; AP2) locates among said peaks (Pxz) of the spectrogram (SG) the transition peaks (P'xz) which at a given moment (tx') have a band (By') differing from the bands (By) of the peaks (Pxz) at a previous moment (tx'-l); the audio processor (AP1; AP2) combines in at least one or more transitions (TRw, TRw') the moment (tx') and the band (By') of a transition peak (P'x'z), with the moment (tx") and the band (By") of one or more subsequent transition peaks (P'x"z); the audio processor (API; AP2) associates one or more hashes (Hq) corresponding to one or more transitions (TRw, TRw') with the moment (tx') or the moments (tx', tx'") at which these transitions (TRw, TRw') occur in the signal (RS; SS). The present invention also relates to means (AP1; AP2, IF, DS) for scanning and/or synchronizing audio/video events.</p></abstract><abstract mxw-id="PA98583549" ref-ucid="WO-2012101586-A1" lang="FR" load-source="patent-office"><p num="0000">L'invention concerne un procédé permettant de numériser et/ou de synchroniser des événements audio/vidéo, ledit procédé comprenant les étapes suivantes : - au moins un processeur audio (AP1 ; AP2) acquiert au moins un signal (RS ; SS) de l'audio d'un événement audio/vidéo ; le processeur audio (AP1 ; AP2) divise ledit signal (RS ; SS) en une pluralité (j) de segments (RSx) correspondant à différents moments (tx) du signal (RS ; SS) ; le processeur audio (AP1 ; AP2) génère un spectrogramme (SG) comprenant une pluralité (n) de bandes de fréquence (By) dans chaque segment (RSx) du signal (RS ; SS) ; le processeur audio (AP1 ; AP2) localise dans le spectrogramme (SG), parmi les bandes (By) de chaque segment (RSx) du signal (RS ; SS), une ou plusieurs crêtes (Pxz) dans lesquelles la magnitude (Mxy') de la bande correspondante (By') est supérieure aux magnitudes (Mxy) des autres bandes (By) ; - le processeur audio (AP1 ; AP2) localise, parmi lesdites crêtes (Pxz) du spectrogramme (SG), les crêtes de transition (P'xz) qui, à un moment donné (tx'), ont une bande (By') qui diffère des bandes (By) des crêtes (Pxz) à un moment précédent (tx'-l) ; le processeur audio (AP1 ; AP2) combine, dans au moins une ou plusieurs transitions (TRw, TRw'), le moment (tx') et la bande (By') d'une crête de transition (P'x'z), avec le moment (tx") et la bande (By") d'une ou plusieurs crêtes de transition ultérieures (P'x"z) ; le processeur audio (AP1 ; AP2) associe un ou plusieurs hachages (Hq) correspondant à une ou plusieurs transitions (TRw, TRw') avec le moment (tx') ou les moments (tx', tx'") auxquels ces transitions (TRw, TRw') surviennent dans le signal (RS ; SS). L'invention concerne également des moyens (AP1 ; AP2, IF, DS) permettant de numériser et/ou de synchroniser des événements audio/vidéo.</p></abstract><abstract mxw-id="PA98951924" ref-ucid="WO-2012101586-A1" lang="FR" source="national office" load-source="docdb"><p>L'invention concerne un procédé permettant de numériser et/ou de synchroniser des événements audio/vidéo, ledit procédé comprenant les étapes suivantes : - au moins un processeur audio (AP1 ; AP2) acquiert au moins un signal (RS ; SS) de l'audio d'un événement audio/vidéo ; le processeur audio (AP1 ; AP2) divise ledit signal (RS ; SS) en une pluralité (j) de segments (RSx) correspondant à différents moments (tx) du signal (RS ; SS) ; le processeur audio (AP1 ; AP2) génère un spectrogramme (SG) comprenant une pluralité (n) de bandes de fréquence (By) dans chaque segment (RSx) du signal (RS ; SS) ; le processeur audio (AP1 ; AP2) localise dans le spectrogramme (SG), parmi les bandes (By) de chaque segment (RSx) du signal (RS ; SS), une ou plusieurs crêtes (Pxz) dans lesquelles la magnitude (Mxy') de la bande correspondante (By') est supérieure aux magnitudes (Mxy) des autres bandes (By) ; - le processeur audio (AP1 ; AP2) localise, parmi lesdites crêtes (Pxz) du spectrogramme (SG), les crêtes de transition (P'xz) qui, à un moment donné (tx'), ont une bande (By') qui diffère des bandes (By) des crêtes (Pxz) à un moment précédent (tx'-l) ; le processeur audio (AP1 ; AP2) combine, dans au moins une ou plusieurs transitions (TRw, TRw'), le moment (tx') et la bande (By') d'une crête de transition (P'x'z), avec le moment (tx") et la bande (By") d'une ou plusieurs crêtes de transition ultérieures (P'x"z) ; le processeur audio (AP1 ; AP2) associe un ou plusieurs hachages (Hq) correspondant à une ou plusieurs transitions (TRw, TRw') avec le moment (tx') ou les moments (tx', tx'") auxquels ces transitions (TRw, TRw') surviennent dans le signal (RS ; SS). L'invention concerne également des moyens (AP1 ; AP2, IF, DS) permettant de numériser et/ou de synchroniser des événements audio/vidéo.</p></abstract><description mxw-id="PDES49466449" ref-ucid="WO-2012101586-A1" lang="EN" load-source="patent-office"><!-- EPO <DP n="2"/>--><p id="p0001" num="0001"> PROCESS AND MEANS FOR SCANNING AND/OR SYNCHRONIZING </p><p id="p0002" num="0002"> AUDIO/VIDEO EVENTS </p><p id="p0003" num="0003">The present invention relates to a process and means for scanning and/or synchronizing audio/video events, in particular a process that can be implemented by at least an audio processor for scanning and/or synchronizing respectively reference or environmental audio signals of an audio or video event. </p><p id="p0004" num="0004"> GB 2213613 discloses a phoneme recognition system and WO 97/16820 discloses a method and a system for compressing a speech signal. </p><p id="p0005" num="0005"> A user attending an audio/video event may need a help allowing him/her to better understand that event. For example, if the audio/video event is a movie, the user may need subtitles or a spoken description of the event, a visual description of the event in the sign language or other audio/video information related to the event. The user can load into a portable electronic device provided with a display and/or a speaker, e.g. a mobile phone or smartphone, at least one audio/video file corresponding to said help, however this may be difficult to synchronize with the event, especially if the event includes pauses or cuts, or if the audio/video file is read after the event has started. </p><p id="p0006" num="0006"> Therefore the object of the present invention is to provide a help which is free from the above-mentioned drawbacks. This object is achieved by means of a process, a program, an audio processor and other means whose main characteristics are respectively recited in claims 1, 28, 29, 30 and 32 while other features are recited in the remaining claims. </p><p id="p0007" num="0007"> Thanks to the peculiar steps of analysis of the audio signal of the audio/video event, the process according to the present invention allows to scan this signal in a simple and effective way, so as to generate a relatively compact index file that can be easily distributed through the Internet to be loaded and run also in an audio processor with comparatively limited resources, e.g. a mobile phone or smartphone. </p><p id="p0008" num="0008"> The process according to the present invention itself can therefore be implemented in the audio processor for scanning in real time the environmental audio signal of the event and synchronizing with this event in a fast and reliable manner, even in the presence of disturbances or background noise, an audio/video file corresponding to the 
<!-- EPO <DP n="3"/>-->
 required help, that can be read by the same audio processor. </p><p id="p0009" num="0009"> Further advantages and characteristics of the process and means according to the present invention will be clear to those skilled in the art from the following detailed and non-limiting description of an embodiment thereof, with reference to the annexed drawings wherein: </p><p id="p0010" num="0010"> figure 1 shows a block diagram of a first audio processor; </p><p id="p0011" num="0011"> figure 2 shows the diagram of a reference signal scanned by the audio processor of figure 1 ; </p><p id="p0012" num="0012"> figure 3 shows different steps of the scanning process of the signal of figure 2; figure 4 shows a spectrogram of the signal of figure 2; </p><p id="p0013" num="0013"> figure 5 shows a first processing step of the spectrogram of figure 4; </p><p id="p0014" num="0014"> figure 6 shows a second processing step of the spectrogram of figure 4; </p><p id="p0015" num="0015"> figure 7 shows a scheme of an index file generated by the audio processor of figure 1; </p><p id="p0016" num="0016"> figure 8 shows a block diagram of a second audio processor; and </p><p id="p0017" num="0017"> figure 9 shows a time table generated by the audio processor of figure 1. </p><p id="p0018" num="0018"> With reference to figure 1 , there is seen that in the scanning process according to the present invention at least a first audio processor API acquires a reference signal RS of the audio of an event, e.g. a movie, a show, a TV broadcast, a music, a song, a speech or another kind of audio/video event. The reference signal RS is generally a digital audio signal contained in at least an audio or video file suitable to be loaded into the memory of a first audio processor API, that in turn is an electronic device, e.g. a computer or other digital processor, even of known type, which is provided with at least one microprocessor and a digital memory to load and run at least one program that implements the process according to the present invention. The reference signal RS can also be obtained by directly sampling through a sampling device an analog audio signal of the event acquired through a microphone. </p><p id="p0019" num="0019"> Referring also to figure 2, there is seen that the first audio processor API divides the reference signal RS into a plurality j of segments RSx, with x between 1 and j, which have a length L, for instance 512 samples, and overlap by an overlapping factor OF, in particular between L/2 and L (excluding L), for instance 384 samples. Segments 
<!-- EPO <DP n="4"/>-->
 RSx are arranged consecutively for the whole duration of the reference signal RS, i.e. each segment RSx corresponds to a moment tx of the reference signal RS, which moment tx is proportional to the time t elapsed since the beginning of the reference signal RS and is inversely proportional to the sampling frequency sf of the reference signal RS and to the difference between length L and the overlapping factor OF of segments RSx. Therefore, if sf=l l kHz, L=512 and OF=384, then tx=t/(sf*(L- OF))=85.93 t, i.e. a second of the reference signal RS includes almost 86 segments RSx. </p><p id="p0020" num="0020"> Referring also to figure 3, there is seen that the first audio processor API processes each segment RSx through a window function WF, in particular implemented with a squared cosine, that attenuates the signal at the ends of segment RSx, so as to obtain an attenuated segment RS'x, whereafter the first audio processor API performs a conversion of the attenuated segment RS'x in the frequency domain, in particular with a Fourier transform, e.g. of the DFT type (Direct Fourier Transform) that is implemented in turn through a FFT algorithm (Fast Fourier Transform), so as to obtain a group Gx of n complex numbers Cxy, with y between 1 and n, as well as with n preferably between 100 and 300. Therefore, calculating the quadratic average of the modules of the complex numbers Cxy, the first audio processor API determines the magnitude Mxy of each of the n frequency bands By in the signal of segment RSx. Bands By may have for instance a constant width sf/2n or variable widths, e.g. with a logarithmic or exponential increase of the frequencies in each band By. </p><p id="p0021" num="0021"> Referring also to figure 4, there is seen that the first audio processor API generates, in particular with a STFT algorithm (Short-Time Fourier Transform), a spectrogram SG of the reference signal RS, which spectrogram includes a plurality j of groups Gx that in turn include a plurality n of magnitudes Mxy in bands By in each segment RSx of the reference signal RS. </p><p id="p0022" num="0022"> The first audio processor API then locates in spectrogram SG, among bands By of each segment RSx of the reference signal RS, one or more peaks Pxz, in particular a plurality k of peaks Pxz, with z between 1 and k, in which the magnitude Mxy' of the corresponding band By' is greater than the magnitude Maxy of the other bands By. In particular, if k=2 the first audio processor API locates in each segment RSx the two peaks Pxl, Px2 of the bands By' and By" having the two greater magnitudes Mxy' and 
<!-- EPO <DP n="5"/>-->
 Mxy" with respect to the other magnitudes Mxy in the other bands By of segment RSx. In a graphical representation of spectrogram SG, peaks Pxz appear as points with coordinates [tx, By], in which each segment RSx or moment tx of the reference signal RS is associated with a plurality k of bands By. </p><p id="p0023" num="0023"> Referring also to figures 5 and 6, there is seen that the first audio processor API, after having located peaks Pxz during the analysis of spectrogram SG, locates in turn among these peaks Pxz the transition peaks P'xz, i.e. the peaks Pxz whose band By' at moment tx' is different from bands By of peaks Pxz at a previous moment tx'-l . For example, with k=2, if peaks PI 1, P21, P31 and peaks PI 2, P22, P32 are respectively in the same bands Bl, B2, then peak P41 is still in band Bl whereas peak P42 is in band B4, then peaks P51, P52 are respectively in bands B2, B3 and peaks P61, P62 are respectively in bands B3 and B5, the first audio processor API will then select the transition peaks P' l l, ΡΊ2, P'42, P'51, P'52 and P'62, discarding the remaining peaks of spectrogram SG, as shown in figure 6. </p><p id="p0024" num="0024"> The first audio processor API, after having located the transition peaks P'xz in spectrogram SG, combines moment tx' and band By' of a transition peak P'x'z with moment tx" and band By" of one or more subsequent transition peaks P'x"z into a plurality of transitions TRw. In particular, the first audio processor API locates all transition peaks P'xz comprised in a temporal window that includes a plurality m of subsequent moments tx in which there is present at least one transition peak P'xz, with m preferably between 5 and 15. In the example of figures 5 and 6, e.g. if m=2 (low value selected for simplicity) transitions TRw include the following transitions: </p><p id="p0025" num="0025"> TR1 : based on values tl, Bl of transition peak P' l l and on values t4, B4 of transition peak P'42; </p><p id="p0026" num="0026"> TR2: based on values tl, Bl of transition peak P' l l and on values t5, B2 of transition peak P ' 51 ; </p><p id="p0027" num="0027"> TR3: based on values tl, Bl of transition peak P' l l and on values t5, B3 of transition peak P'52; </p><p id="p0028" num="0028"> TR4: based on values tl, B2 of transition peak ΡΊ2 and on values t4, B4 of transition peak P'42; </p><p id="p0029" num="0029"> TR5: based on values tl, B2 of transition peak ΡΊ2 and on values t5, B2 of 
<!-- EPO <DP n="6"/>-->
 transition peak P ' 51 ; </p><p id="p0030" num="0030"> TR6: based on values tl, B2 of transition peak ΡΊ2 and on values t5, B3 of transition peak P'52; </p><p id="p0031" num="0031"> TR7: based on values t4, B4 of transition peak P'42 and on values t5, B3 of transition peak P'52; </p><p id="p0032" num="0032"> TR8: based on values t4, B4 of transition peak P'42 and on values t6, B5 of transition peak P'62; </p><p id="p0033" num="0033"> TR7: based on values t5, B2 of transition peak P'51 and on values t6, B5 of transition peak P'62, and so on. </p><p id="p0034" num="0034"> Referring to figure 7, there is seen that the first audio processor API can combine moments tx', tx" and bands By', By" of the two transition peaks P'x'z and P'x"z of a transition TRw in different ways. Preferably, the first audio processor API associates a transition TRw with a 32-bit hash Hq in at least one index file IF, with q between 1 and c, in which 8 bits correspond to band By' of the first transition peak P'x'z of transition TRw, 8 bits correspond to band By" of the second transition peak P'x"z of transition TRw and 16 bits correspond to the difference Δΐχ between moments tx" and tx' at which these two transition peaks P'x'z, P'x"z appear in the reference signal RS, i.e. the duration Δΐχ of transition TRw. The first audio processor API then associates in index file IF said hash Hq with each moment tx, in particular with moment tx' of the first transition peak P'x'z, of each same transition TRw that occurs in the reference signal RS. The index file IF therefore includes a plurality c of hashes Hq corresponding to all possible transitions TRw with different duration Δΐχ and/or band By' and/or band By", that are present one or more times in the reference signal RS. Therefore, if a transition TRw' having the same duration Δΐχ and the same bands By', By" of a previous transition TRw is repeated at a subsequent moment tx" in the reference signal RS, the first audio processor API does not create a new hash in the way described above but associates also moment tx" of the subsequent transition TRw' with hash Hq in the index file IF. </p><p id="p0035" num="0035"> Therefore the index file IF contains a series of hashes Hq, each of which corresponds to a possible different transition TRw in the reference signal RS and is associated with all moments tx at which this transition TRw occurs in the reference 
<!-- EPO <DP n="7"/>-->
 signal RS. The index file IF suitably contains at least one hash index HI and at least one time index TI, which however can also be included in several separate index files IF. The hash index HI includes a first series of 32-bit values, in particular the overall number c of hashes Hq obtained from the reference signal RS, as well as the hashes Hq and the corresponding hash addresses Haq pointing to one or more occurrences lists Lq contained in the time index TI. Each occurrences list Lq of the time index TI includes a first series of 32-bit values, in particular the number of occurrences aq in which one or more transitions TRw, TRw' corresponding to a hash Hq occur in the reference signal RS and the moments tqb, with b between 1 and aq, corresponding to the moment or moments at which this transition TRw or these transitions TRw, TRw' occur in the reference signal RS. In other embodiments, one or more occurrences lists Lq may be contained in separate files, i.e. the time index TI includes more files containing one or more occurrences lists Lq. </p><p id="p0036" num="0036"> Therefore, in the scanning process the first audio processor API scans a reference signal RS to generate at least one index file IF containing one or more hashes Hq corresponding to the different possible transitions TRw between peaks Pxz of a spectrogram SG of the reference signal RS, in particular between peaks P'xz in different bands By', By" and between two subsequent moments tx' and tx". The index file IF contains also a list of the moment or moments in the reference signal RS at which each of these different transitions TRw occurs. </p><p id="p0037" num="0037"> Referring to figure 8, there is seen that in the synchronizing process according to the present invention at least a second audio processor AP2, that may also coincide with the first audio processor API, acquires a samples signal SS of the audio/video event at issue. The samples signal SS is generally a digital audio signal, e.g. 16-bit at 11 kHz, obtained by directly sampling the audio of the audio/video event with a sampling device, in particular acquired through a microphone connected to the second audio processor AP2, which in turn is an electronic device preferably portable, e.g. a mobile phone, a reader for audio/video files (for instance mp3 or mp4), a smartphone, a tablet PC, a portable PC or other electronic processor provided with at least a microprocessor and a memory to load and run at least a program implementing the process according to the present invention. The sampled signal SS can be filtered through a gate, so as to 
<!-- EPO <DP n="8"/>-->
 remove background noise when the audio/video event does not produce a signal or produces a very low signal. </p><p id="p0038" num="0038"> The second audio processor AP2 processes a spectrogram SG of the sampled signal SS and, within said spectrogram SG, locates peaks Pxz, transition peaks P'xz and transitions TRw through the same steps, or equivalent steps, of the above-mentioned scanning process so as to obtain a sequence of hashes hq from the sampled signal SS. In the synchronizing process, the second audio processor AP2 can limit the number of bands By of spectrogram SG with respect to the scanning process depending on the quality of the sampled signal SS, that can be lower than the quality of the reference signal RS due to environmental noise and/or quality of the microphone acquiring the audio of the event to be synchronized. In practice, the bands By in which the reference signal RS and the sampled signal SS are divided are the same, but the second audio processor AP2 can exclude some bands By, e.g. those with lower and/or higher frequencies, thus considering a number n' of bands By smaller than the number n of bands By of the scanning process, i.e. n'&lt;n. Moreover, always due to environmental noise and/or quality of the microphone acquiring the audio of the event to be synchronized, in the synchronizing process the second audio processor AP2 can locate in spectrogram SG of the sampled signal SS a number k' of peaks P'xz greater than in the scanning process, in particular k'=3, with z between 1 and k', in which the magnitude Mxy' of the corresponding band By' is greater than the magnitudes Mxy of the other bands By. </p><p id="p0039" num="0039"> The second audio processor AP2 also processes at least one hash index HI associated with a reference signal RS of the vent of the sampled signal SS. This hash index HI is not obtained from the hashes Hq of the sampled signal SS but is contained in an index file IF that is obtained from a reference signal RS, in particular through the above-described scanning process, and is loaded through a mass memory and/or a data connection DC. For instance, the index file IF is transmitted on demand from a data server DS through the Internet or the cellular network to be loaded into a memory of the second audio processor AP2 by a user that knows the audio/video event corresponding to the reference signal RS, i.e. to the index file IF and/or the sampled signal SS. In practice, prior to acquiring the sampled signal SS, a user loads into a memory, in 
<!-- EPO <DP n="9"/>-->
 particular a non-volatile memory, of the second audio processor AP2 at least one index file IF associated with the audio/video event. When the program implementing the synchronization process is started, the second audio processor AP2 loads into a volatile memory the hash index HI of the index file IF. The user cam also select and load into a memory of the second audio processor AP2 one or more audio/video files AV, e.g. files containing subtitles, texts, images, audio and/or video passages, to be synchronized with the audio/video event through the index file IF loaded into the memory of the second audio processor AP2. The data server DS can transmit on demand through the Internet or the cellular network also the audio/video files AV associated with the index file IF. </p><p id="p0040" num="0040"> For each hash Hq obtained from the sampled signal SS, the second audio processor AP2 locates the hash address Haq in the hash index HI of the index file IF and loads into a memory, in particular a volatile memory, the occurrences list Lq pointed at by the hash address Haq of the index file IF. Alternatively, if the resources are sufficient, the second audio processor AP2 can load in a volatile memory all the occurrences lists Lq of the time index TI upon starting the program. The second audio processor AP2 thus modifies a time table TT according to the moment tql or the moments tqb contained in the occurrences list Lq pointed at by the hash address Haq and to the time ta elapsed from the moment when the second audio processor AP2 started acquiring the sampled signal SS. The elapsed time ta may be measured by a clock of the second audio processor AP2. </p><p id="p0041" num="0041"> Referring to figure 9, there is seen that the time table TT preferably includes a plurality r of time counters TCs, with s between 1 and r, which are associated with time slots of the reference signal RS or of the sampled signal SS. For instance, if the maximum duration Tmax of the reference signal RS is 3 hours (an audio/video event usually does not exceed this duration) and r=65536, then the duration of each time slot is equal to Tmax/r, i.e. about 0.16 seconds. When the second audio processor AP2 obtains a hash Hq from the sampled signal SS, it modifies, in particular it increases, in the time table TT the value of each counter TCs associated with the time slot corresponding to the difference between the value of each moment tqb in the occurrences list Lq associated with hash Hq and the time ta elapsed from the moment when the second audio processor AP2 started acquiring the sampled signal SS, i.e. TCs 
<!-- EPO <DP n="10"/>-->
 = TCs + 1 with s = tqb - ta. The second audio processor AP2 can modify the time table TT also according to the processing time tb required by the second audio processor AP2 to obtain hash Hq or the corresponding occurrences list Lq, in particular by adding said processing time tb to the elapsed time ta, i.e. TCs = TCs + 1 with s = tqb - (ta + tb). Through such a trick, the counter TCs associated with the time slot comprising the starting time ts of the acquisition of the sampled signal SS, after the second audio processor AP2 has obtained a significant plurality of hashes Hq, is increased statistically more than the other counters TCs, since most of the hashes Hq should be associated with the starting time ts. The second audio processor AP2 adds the starting time ts to the elapsed time ta and, if desired, also to the processing time tb to obtain the real time RT of the event, i.e. RT = ts + ta or RT = ts +ta +tb. </p><p id="p0042" num="0042"> Therefore, after an elapsed time ta or a certain number of hashes Hq obtained from the sampled signal SS or after that a counter TCs is greater, e.g. double or triple, than the other counters TCs or after that a counter TCs has reached a given threshold value TV or after that a user has sent a command through an input device, the second audio processor AP2 determines in the above-described manner the real time RT of the sampled signal SS, which therefore can be used to synchronize the audio/video file AV with the sampled signal SS. The second audio processor AP2 or another electronic device can therefore process the audio/video file AV to generate an audio/video output, e.g. subtitles ST shown on the video display VD and/or an audio content AC commenting or translating the event, broadcast through a loudspeaker LS, which audio/video output is synchronized with the sampled signal SS of the audio/video event. </p><p id="p0043" num="0043"> The second audio processor AP2 can repeat one or more times, manually or automatically, in particular periodically, the synchronizing process to check whether the sampled signal SS is actually synchronized with the reference signal RS. The second audio processor AP2 can calculate the difference between the real time RT1 obtained when the process was first performed and the real time RT2 when the process was performed a second time, as well as the difference given by the clock of the second audio processor AP2 between the starting times tsl and ts2 of the two processes. The second audio processor AP2 can therefore calculate a correction factor CF proportional to the ratio between said differences, i.e. CF = (RT2 - RTl)/(ts2 - tsl), which correction 
<!-- EPO <DP n="11"/>-->
 factor CF can be multiplied by the real time RT2 determined by the second audio processor AP2 during the second synchronizing process, so as to make up for a possible slowing down or acceleration of the sampled signal SS with respect to the reference signal RS and thus obtain a new corrected real time R , i.e. R = (ts2 + ta) * CF or R = (ts2 + ta +tb) * CF, which again can be used to synchronize the audio/video file AV. However, if the module of the correction factor CF is greater than a given threshold value, the sampled signal SS should not have slowed down or accelerated with respect to the reference signal RS, but rather a pause or a jump in the sampled signal SS should have occurred, whereby the second audio processor AP2 does not use the correction factor CF to correct the real time RT. </p><p id="p0044" num="0044"> Possible additions and/or modifications may be made by those skilled in the art to the above-described embodiment of the invention, yet without departing from the scope of the appended claims. 
</p></description><claims mxw-id="PCLM43969019" ref-ucid="WO-2012101586-A1" lang="EN" load-source="patent-office"><claim-statement><!-- EPO <DP n="12"/>-->CLAIMS </claim-statement><claim id="clm-0001" num="1"><claim-text>1. Process for scanning and/or synchronizing audio/video events, characterized in that it comprises the following operating steps: </claim-text><claim-text> at least one audio processor (API; AP2) acquires at least one signal (RS; SS) of the audio of an audio/video event; </claim-text><claim-text> the audio processor (API; AP2) divides said signal (RS; SS) into a plurality (j) of segments (RSx) corresponding to different moments (tx) of the signal (RS; SS); </claim-text><claim-text> the audio processor (API; AP2) generates a spectrogram (SG) comprising a plurality (n) of frequency bands (By) in each segment (RSx) of the signal (RS; SS); the audio processor (API ; AP2) locates in the spectrogram (SG), among the bands (By) of each segment (RSx) of the signal (RS; SS), one or more peaks (Pxz) in which the magnitude (Mxy') of the corresponding band (By') is greater than the magnitudes (Mxy) of the other bands (By); </claim-text><claim-text> the audio processor (API; AP2) locates among said peaks (Pxz) of the spectrogram (SG) the transition peaks (P'xz) which at a given moment (tx') have a band (By') differing from the bands (By) of the peaks (Pxz) at a previous moment (tx'-l); the audio processor (API; AP2) combines in at least one or more transitions (TRw, TRw') the moment (tx') and the band (By') of a transition peak (P'x'z), with the moment (tx") and the band (By") of one or more subsequent transition peaks (P'x"z); the audio processor (API; AP2) associates one or more hashes (Hq) corresponding to one or more transitions (TRw, TRw') with the moment (tx') or the moments (tx', tx'") at which these transitions (TRw, TRw') occur in the signal (RS; SS). </claim-text></claim><claim id="clm-0002" num="2"><claim-text> 2. Process according to the previous claim, characterized in that said hashes (Hq) comprise the band (By') of the first transition peak (P'x'z) of a transition (TRw), the band (By") of the second transition peak (P'x"z) of the same transition (TRw) and the difference (Atx) between the moments (tx", tx') at which these two transition peaks (P'x'z, P'x"z) occur in the signal (RS; SS). </claim-text></claim><claim id="clm-0003" num="3"><claim-text> 3. Process according to one of the previous claims, characterized in that said hashes (Hq) are associated in at least one index file (IF) with said moments (tx', tx'") at <!-- EPO <DP n="13"/>--> which said transitions (TRw, TRw') occur in the signal (RS). </claim-text></claim><claim id="clm-0004" num="4"><claim-text> 4. Process according to the previous claim, characterized in that the index file (IF) comprises said hashes (Hq) and corresponding hash addresses (HAq) which point at one or more occurrences lists (Lq). </claim-text></claim><claim id="clm-0005" num="5"><claim-text> 5. Process according to the previous claim, characterized in that said occurrences lists (Lq) comprise the number of occurrences (aq) of the moments at which one or more transitions (TRw, TRw') corresponding to a hash (Hq) occur in the signal (RS). </claim-text></claim><claim id="clm-0006" num="6"><claim-text> 6. Process according to claim 4 o 5, characterized in that said occurrences lists (Lq) comprise the moments (tqb) at which one or more transitions (TRw, TRw') corresponding to a hash (Hq) occur in the signal (RS). </claim-text></claim><claim id="clm-0007" num="7"><claim-text> 7. Process according to one of the previous claims, characterized in that the audio processor (API; AP2) locates the transition peaks (P'xz) included in a time window which comprises a plurality (m) of subsequent moments at which at least one transition peak (P'xz) is present. </claim-text></claim><claim id="clm-0008" num="8"><claim-text> 8. Process according to the previous claim, characterized in that said plurality (m) of subsequent moments is comprised between 5 and 15. </claim-text></claim><claim id="clm-0009" num="9"><claim-text> 9. Process according to one of the previous claims, characterized in that said spectrogram (SG) comprises a plurality (n) of bands (By) comprised between 100 and 300. </claim-text></claim><claim id="clm-0010" num="10"><claim-text> 10. Process according to one of the previous claims, characterized in that the audio processor (API; AP2) locates in the spectrogram (SG), among the bands (By) of each segment (RSx) of the signal (RS; SS), two or three peaks (Pxz) in which the magnitude (Mxy') of the corresponding bands (By') is greater than the magnitudes (Mxy) of the other bands (By). </claim-text></claim><claim id="clm-0011" num="11"><claim-text> 11. Process according to one of the previous claims, characterized in that said signal (RS; SS) is a sampled signal (SS) of the audio of an audio/video event. </claim-text></claim><claim id="clm-0012" num="12"><claim-text> 12. Process according to the previous claim, characterized in that the audio processor (AP2) loads into at least one memory at least one index file (IF) associated with said sampled signal (SS). </claim-text></claim><claim id="clm-0013" num="13"><claim-text> 13. Process according to the previous claim, characterized in that the audio <!-- EPO <DP n="14"/>--> processor (AP2) locates in the index file (IF) at least one hash address (HAq) associated with a hash (Hq) obtained from the sampled signal (SS). </claim-text></claim><claim id="clm-0014" num="14"><claim-text> 14. Process according to the previous claim, characterized in that the audio processor (AP2) loads into at least one memory at least one occurrences list (Lq) pointed at by said hash address (HAq). </claim-text></claim><claim id="clm-0015" num="15"><claim-text> 15. Process according to one of claims 12 to 14, characterized in that the audio processor (AP2) modifies a time table (TT) according to the moment (tql) or the moments (tqb) associated in the index file (IF) with a hash (Hq) obtained from the sampled signal (SS). </claim-text></claim><claim id="clm-0016" num="16"><claim-text> 16. Process according to the previous claim, characterized in that said moment (tql) or moments (tqb) associated with the hash (Hq) in the index file (IF) are contained in the occurrences list (Lq) pointed at by the hash address (HAq) associated with the same hash (Hq). </claim-text></claim><claim id="clm-0017" num="17"><claim-text> 17. Process according to claim 15 o 16, characterized in that the audio processor (AP2) modifies the time table (TT) also according to the time (ta) elapsed from the moment at which the audio processor (AP2) started to obtain the sampled signal (SS). </claim-text></claim><claim id="clm-0018" num="18"><claim-text> 18. Process according to one of claims 15 to 17, characterized in that the audio processor (AP2) modifies the time table (TT) also according to the processing time (tb) used to obtain the hash (Hq) or the corresponding occurrences list (Lq). </claim-text></claim><claim id="clm-0019" num="19"><claim-text> 19. Process according to one of claims 15 to 18, characterized in that the time table (TT) comprises a plurality (r) of time counters (TCs) associated with time slots of the sampled signal (SS). </claim-text></claim><claim id="clm-0020" num="20"><claim-text> 20. Process according to the previous claim, characterized in that when the audio processor (AP2) obtains a hash (Hq) from the sampled signal (SS), it modifies in the time table (TT) the value of each counter (TCs) associated with the time slot corresponding to the difference between the value of each moment (tqb) in the occurrences list (Lq) corresponding to the hash (Hq) and the time (ta) elapsed from the moment at which the audio processor (AP2) started to obtain the sampled signal (SS). </claim-text></claim><claim id="clm-0021" num="21"><claim-text> 21. Process according to the previous claim, characterized in that the audio processor (AP2) determines the real time (RT) of the sampled signal (SS) by adding the value (ts) of a counter (TCs) in the time table (TT) to the time (ta) elapsed from the <!-- EPO <DP n="15"/>--> moment at which the audio processor (AP2) started to obtain the sampled signal (SS).</claim-text></claim><claim id="clm-0022" num="22"><claim-text>22. Process according to the previous claim, characterized in that said value (ts) of said counter (TC's) in the time table (TT) is greater than the values of all the other counters (TCs) in the time table (TT). </claim-text></claim><claim id="clm-0023" num="23"><claim-text> 23. Process according to one of claims 11 to 22, characterized in that the audio processor (AP2) repeats the same process for determining a correction factor (CF) to make up for slowing downs or accelerations, if any, of the sampled signal (SS). </claim-text></claim><claim id="clm-0024" num="24"><claim-text> 24. Process according to the previous claim, characterized in that said correction factor (CF) is proportional to the difference between the real time (RT1) obtained when the process was performed a first time and the real time (RT2) obtained when the process was performed a second time, and is inversely proportional to the difference between the starting times (tsl, ts2) of the two processes. </claim-text></claim><claim id="clm-0025" num="25"><claim-text> 25. Process according to the previous claim, characterized in that if the module of the correction factor (CF) is greater than a given threshold value, it is not used to correct the real time (RT) of the sampled signal (SS). </claim-text></claim><claim id="clm-0026" num="26"><claim-text> 26. Process according to one of claims 21 to 25, characterized in that the audio processor (AP2) uses said real time (RT) for synchronizing at least one audio/video file (AV) with the sampled signal (SS). </claim-text></claim><claim id="clm-0027" num="27"><claim-text> 27. Process according to one of claims 1 to 10, characterized in that said signal (RS; SS) is a reference signal (RS) of the audio of an audio/video event. </claim-text></claim><claim id="clm-0028" num="28"><claim-text> 28. Program suitable for being run by audio processors (API, AP2), characterized in that it implements the process according to one of the previous claims. </claim-text></claim><claim id="clm-0029" num="29"><claim-text> 29. Audio processor (API, AP2), characterized in that it comprises the program according to the previous claim. </claim-text></claim><claim id="clm-0030" num="30"><claim-text> 30. Index file (IF), characterized in that it comprises one or more hashes (Hq) corresponding to one or more transitions (TRw, TRw') between peaks (P'xz) of a spectrogram (SG) of a signal (RS) corresponding to the audio of an audio/video event. </claim-text></claim><claim id="clm-0031" num="31"><claim-text> 31. Index file (IF) according to the previous claim, characterized in that said hashes (Hq) are associated in the index file (IF) with the moment (tx') or the moments (tx', tx'") at which said transitions (TRw, TRw') occur in said signal (RS). </claim-text></claim><claim id="clm-0032" num="32"><claim-text> 32. Data server (DS), characterized in that it transmits on demand through a <!-- EPO <DP n="16"/>--> data connection (DC) an index file (IF) according to claim 30 or 31. </claim-text></claim><claim id="clm-0033" num="33"><claim-text> 33. Data server (DS) according to the previous claim, characterized in that it transmits on demand through a data connection (DC) also an audio/video file (AV) associated with said index file (IF). </claim-text></claim></claims><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
