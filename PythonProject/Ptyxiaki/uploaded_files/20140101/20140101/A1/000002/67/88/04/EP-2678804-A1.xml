<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2678804-A1" country="EP" doc-number="2678804" kind="A1" date="20140101" family-id="45815508" file-reference-id="317082" date-produced="20180826" status="corrected" lang="FR"><bibliographic-data><publication-reference fvid="146551265" ucid="EP-2678804-A1"><document-id><country>EP</country><doc-number>2678804</doc-number><kind>A1</kind><date>20140101</date><lang>FR</lang></document-id></publication-reference><application-reference ucid="EP-12708270-A" is-representative="NO"><document-id mxw-id="PAPP154825188" load-source="docdb" format="epo"><country>EP</country><doc-number>12708270</doc-number><kind>A</kind><date>20120221</date><lang>FR</lang></document-id><document-id mxw-id="PAPP186997018" load-source="docdb" format="original"><country>EP</country><doc-number>12708270.9</doc-number><date>20120221</date></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC140451639" ucid="EP-2012052958-W" linkage-type="W" load-source="docdb"><document-id format="epo"><country>EP</country><doc-number>2012052958</doc-number><kind>W</kind><date>20120221</date></document-id></priority-claim><priority-claim mxw-id="PPC140455274" ucid="FR-1151424-A" load-source="docdb"><document-id format="epo"><country>FR</country><doc-number>1151424</doc-number><kind>A</kind><date>20110222</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL1988107076" load-source="docdb">G06K   9/00        20060101AFI20120913BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-2012764701" load-source="docdb" scheme="CPC">G06K   9/00248     20130101 LI20151020BHEP        </classification-cpc><classification-cpc mxw-id="PCL1991312222" load-source="docdb" scheme="CPC">G06K   9/6232      20130101 FI20140102BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT132186279" lang="DE" load-source="patent-office">VERFAHREN ZUR ERKENNUNG EINER VORGEGEBENEN MENGE CHARAKTERISCHER PUNKTE EINES GESICHTS</invention-title><invention-title mxw-id="PT132186280" lang="EN" load-source="patent-office">METHOD FOR DETECTING A PREDEFINED SET OF CHARACTERISTIC POINTS OF A FACE</invention-title><invention-title mxw-id="PT132186281" lang="FR" load-source="patent-office">PROCÉDÉ DE DÉTECTION D'UN ENSEMBLE PRÉDÉFINI DE POINTS CARACTÉRISTIQUES D'UN VISAGE</invention-title></technical-data><parties><applicants><applicant mxw-id="PPAR918167893" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>FITTINGBOX</last-name><address><country>FR</country></address></addressbook></applicant><applicant mxw-id="PPAR918154860" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>FITTINGBOX</last-name></addressbook></applicant><applicant mxw-id="PPAR918982937" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Fittingbox</last-name><iid>101322539</iid><address><street>644 Voi l'Occitane Immeuble Arizona-Bâtiment A</street><city>31670 Labege</city><country>FR</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR918167971" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>CHOUKROUN ARIEL</last-name><address><country>FR</country></address></addressbook></inventor><inventor mxw-id="PPAR918159099" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>CHOUKROUN, ARIEL</last-name></addressbook></inventor><inventor mxw-id="PPAR918993712" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>CHOUKROUN, ARIEL</last-name><address><street>15 Rue des Pénitents Blancs</street><city>F-31000 Toulouse</city><country>FR</country></address></addressbook></inventor><inventor mxw-id="PPAR918170925" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>LE GALLOU SYLVAIN</last-name><address><country>FR</country></address></addressbook></inventor><inventor mxw-id="PPAR918166700" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>LE GALLOU, SYLVAIN</last-name></addressbook></inventor><inventor mxw-id="PPAR918981122" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>LE GALLOU, SYLVAIN</last-name><address><street>19 Les Castillanes</street><city>F-31450 Baziege</city><country>FR</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR918981165" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Cornuejols, Christophe</last-name><iid>101284624</iid><address><street>Schmit-Chretien Parc de Basso Cambo 4 rue Paul Mesplé</street><city>31100 Toulouse</city><country>FR</country></address></addressbook></agent></agents></parties><international-convention-data><pct-or-regional-filing-data ucid="EP-2012052958-W"><document-id><country>EP</country><doc-number>2012052958</doc-number><kind>W</kind><date>20120221</date><lang>FR</lang></document-id></pct-or-regional-filing-data><pct-or-regional-publishing-data ucid="WO-2012113805-A1"><document-id><country>WO</country><doc-number>2012113805</doc-number><kind>A1</kind><date>20120830</date><lang>FR</lang></document-id></pct-or-regional-publishing-data><designated-states><ep-contracting-states><country mxw-id="DS548929160" load-source="docdb">AL</country><country mxw-id="DS548816037" load-source="docdb">AT</country><country mxw-id="DS548913888" load-source="docdb">BE</country><country mxw-id="DS548865554" load-source="docdb">BG</country><country mxw-id="DS548929927" load-source="docdb">CH</country><country mxw-id="DS548913889" load-source="docdb">CY</country><country mxw-id="DS548816038" load-source="docdb">CZ</country><country mxw-id="DS548929161" load-source="docdb">DE</country><country mxw-id="DS548913890" load-source="docdb">DK</country><country mxw-id="DS548913891" load-source="docdb">EE</country><country mxw-id="DS548837057" load-source="docdb">ES</country><country mxw-id="DS548865555" load-source="docdb">FI</country><country mxw-id="DS548929928" load-source="docdb">FR</country><country mxw-id="DS548929162" load-source="docdb">GB</country><country mxw-id="DS548913892" load-source="docdb">GR</country><country mxw-id="DS548929163" load-source="docdb">HR</country><country mxw-id="DS548816039" load-source="docdb">HU</country><country mxw-id="DS548929929" load-source="docdb">IE</country><country mxw-id="DS548913893" load-source="docdb">IS</country><country mxw-id="DS548865556" load-source="docdb">IT</country><country mxw-id="DS548913894" load-source="docdb">LI</country><country mxw-id="DS548865557" load-source="docdb">LT</country><country mxw-id="DS548934618" load-source="docdb">LU</country><country mxw-id="DS548865558" load-source="docdb">LV</country><country mxw-id="DS548865559" load-source="docdb">MC</country><country mxw-id="DS548934619" load-source="docdb">MK</country><country mxw-id="DS548934620" load-source="docdb">MT</country><country mxw-id="DS548934621" load-source="docdb">NL</country><country mxw-id="DS548929938" load-source="docdb">NO</country><country mxw-id="DS548934622" load-source="docdb">PL</country><country mxw-id="DS548837058" load-source="docdb">PT</country><country mxw-id="DS548926910" load-source="docdb">RO</country><country mxw-id="DS548837059" load-source="docdb">RS</country><country mxw-id="DS548934623" load-source="docdb">SE</country><country mxw-id="DS548929164" load-source="docdb">SI</country><country mxw-id="DS548929939" load-source="docdb">SK</country><country mxw-id="DS548929940" load-source="docdb">SM</country><country mxw-id="DS548913895" load-source="docdb">TR</country></ep-contracting-states></designated-states></international-convention-data><office-specific-data><eptags><ep-no-a-document-published>*</ep-no-a-document-published></eptags></office-specific-data></bibliographic-data><abstract mxw-id="PA99625627" ref-ucid="WO-2012113805-A1" lang="EN" load-source="patent-office"><p num="0000">The invention relates to a method for detecting a predefined set of characteristic points of a face from an image of said face. The method comprises a step of causing the shape and/or the texture of a hierarchy of statistical models of portions of a face to converge on the real data supplied by the image of the face.</p></abstract><abstract mxw-id="PA99824146" ref-ucid="WO-2012113805-A1" lang="EN" source="national office" load-source="docdb"><p>The invention relates to a method for detecting a predefined set of characteristic points of a face from an image of said face. The method comprises a step of causing the shape and/or the texture of a hierarchy of statistical models of portions of a face to converge on the real data supplied by the image of the face.</p></abstract><abstract mxw-id="PA99625628" ref-ucid="WO-2012113805-A1" lang="FR" load-source="patent-office"><p num="0000">L'invention concerne un procédé de détection d'un ensemble prédéfini de points caractéristiques d'un visage à partir d'une image de ce visage Le procédé comporte une étape qui consiste à faire converger la forme et/ou la texture d'une hiérarchie de modèles statistiques de parties de visage sur les données réelles fournies par l'image du visage.</p></abstract><abstract mxw-id="PA99824147" ref-ucid="WO-2012113805-A1" lang="FR" source="national office" load-source="docdb"><p>L'invention concerne un procédé de détection d'un ensemble prédéfini de points caractéristiques d'un visage à partir d'une image de ce visage Le procédé comporte une étape qui consiste à faire converger la forme et/ou la texture d'une hiérarchie de modèles statistiques de parties de visage sur les données réelles fournies par l'image du visage.</p></abstract><description mxw-id="PDES50931329" ref-ucid="WO-2012113805-A1" lang="FR" load-source="patent-office"><!-- EPO <DP n="2"/>--><p id="p0001" num="0001"> Procédé de détection d'un ensemble prédéfini de points caractéristiques d'un visage </p><p id="p0002" num="0002">La présente invention est relative au domaine du traitement d'image. Elle concerne plus particulièrement la détection et le suivi de points caractéristiques d'un visage. Contexte de l'invention et problèmes posés </p><p id="p0003" num="0003"> L'identification de points caractéristiques d'un visage dans une image présente de nombreuses applications, qui couvrent notamment la sécurité ou la réalité augmentée. </p><p id="p0004" num="0004"> Dans ce dernier domaine, on peut par exemple citer l'essayage virtuel de lunettes entièrement automatique, c'est à dire la superposition sur un écran d'une image réelle d'un visage d'un utilisateur et d'une image virtuelle d'une paire de lunettes dont des paramètres caractéristiques, tels que la forme et la texture, ont été préalablement mémorisés. </p><p id="p0005" num="0005"> Il est alors important de pouvoir détecter les points caractéristiques d'un visage à partir d'une simple image d'un utilisateur. Ce procédé est appelé alignement du visage. </p><p id="p0006" num="0006"> Parmi les méthodes d'alignement, on peut citer les méthodes par modélisation statistique. Celles-ci comportent classiquement deux phases : </p><p id="p0007" num="0007"> - une phase d'apprentissage qui consiste à créer le modèle statistique et - une phase de détection qui consiste à faire converger la forme et/ou la texture du modèle statistique sur une donnée réelle. </p><p id="p0008" num="0008"> Les trois principaux algorithmes utilisant des modèles statistiques sont les modèles à forme active ASM (Active Shape Models), les modèles à apparence active AAM (Active Appearance Models) et les modèles locaux contraints CLM (Constrained Local Models). </p><p id="p0009" num="0009"> Dans la phase d'apprentissage, les ASM ne modélisent que la forme (ensemble de points reliés entre eux) d'un objet, les AAM modélisent la forme et la texture (pixels contenus à l'intérieur de l'enveloppe convexe de la forme), et les CLM modélisent la forme et des patchs de textures (pixels contenus dans une zone de voisinage en chaque point de la forme). 
<!-- EPO <DP n="3"/>-->
 Dans la phase de détection, les ASM comme les CLM font converger la forme de l'objet en fonction de surfaces de réponse (qui sont unidimensionnelles pour les ASM et bidimensionnelles pour les CLM), la texture du modèle statistique CLM est statique ou bien mise à jour par prédictions. Tandis que pour les AAM, la convergence se fait conjointement sur la texture et la forme (avec des méthodes de descente de gradient), la texture du modèle cherche à approximer au mieux la texture de l'image sur laquelle se déroule la détection. </p><p id="p0010" num="0010"> Les CLM ont l'avantage d'être plus robustes aux occultations et aux changements d'apparence, mais sont plus sensibles aux minima locaux. Les AAM sont plus robustes face aux minima locaux, mais la convergence de la texture est problématique dans les méthodes de descente de gradient (problème de triangulation de la forme dont la fonction de déformation du maillage doit toujours créer un maillage uni), et les AAM s'adaptent moins à la variabilité des visages. </p><p id="p0011" num="0011"> Ces divers algorithmes ne sont donc pas totalement satisfaisants. </p><p id="p0012" num="0012">Exposé de l'invention </p><p id="p0013" num="0013"> La présente invention vise selon un premier aspect un procédé de détection d'un ensemble prédéfini de points caractéristiques d'un visage à partir d'une image de ce visage. </p><p id="p0014" num="0014"> Le procédé comporte un groupe d'étapes 300-400 qui consiste à faire converger la forme et/ou la texture d'une hiérarchie de modèles statistiques de parties de visage sur les données réelles fournies par l'image du visage. </p><p id="p0015" num="0015"> On appelle également dans la littérature reconstruction de visage ce procédé de détection ou d'identification de points caractéristiques, en ce qu'il permet ensuite de reconstruire la forme tridimensionnelle et la position du visage, et donc d'y calculer si besoin diverses dimensions, par exemple dans le cadre d'essayage de paires de lunettes virtuelles. </p><p id="p0016" num="0016">Préférentiellement, les modèles statistiques utilisés sont de type Modèles à Apparence Active par Patchs (PAAM). Ceux-ci sont avantageusement créés à partir de mêmes données d'apprentissage (textures et formes), seuls des 
<!-- EPO <DP n="4"/>-->
 sous-ensembles différents de points définissant les formes étant utilisés. </p><p id="p0017" num="0017"> Il s'agit donc d'un algorithme de reconstruction de visage, nommé dans la suite de la description Hiérarchie de Modèles à Apparence Active par Patchs (en anglais "Hierarchical Patches Active Appearance Models" ou HPAAM). </p><p id="p0018" num="0018">Selon une mise en œuvre préférée, le procédé comporte l'utilisation d'une hiérarchie de modèles statistiques de parties de visage (HPAAM) pour la détection de points caractérisant de visages simplifiés ou de parties de visage (comme par exemple les yeux et la bouche) (étape 300) puis d'une hiérarchie de modèles statistiques de visage pour la détection finale (étape 400). </p><p id="p0019" num="0019"> Préférentiellement, le groupe d'étapes 300-400 utilise une méthode d'alignement par modélisation comportant deux phases : </p><p id="p0020" num="0020"> - une phase d'apprentissage qui consiste à créer un modèle statistique et</p><p id="p0021" num="0021">- une phase de détection qui consiste à faire converger la forme et/ou la texture du modèle statistique sur une donnée réelle. </p><p id="p0022" num="0022">Selon une mise en œuvre préférée, la construction d'un modèle statistique de forme et de texture est réalisée en alignant et en normalisant toutes les formes et les textures puis en appliquant une analyse en composante principale sur les formes alignées et sur les textures alignées. </p><p id="p0023" num="0023">Le procédé de détection utilise, dans un cas particulier, une étape de minimisation par un algorithme inverse compositionnel (ICA) pour la reconstruction du visage en faisant converger des paramètres de forme p, de pose q, et de texture λ de chaque modèle statistique de partie de visage. </p><p id="p0024" num="0024"> Dans cette phase de détection utilisant une approche de type Gauss Newton via l'algorithme ICA, la texture, la forme et la pose du modèle PAAM sont optimisées de sorte que la texture de chacun des patchs converge vers la texture de l'image utilisée pour la détection. </p><p id="p0025" num="0025"> Selon un mode de mise en œuvre avantageux, le modèle hiérarchique est un ensemble composé d'un modèle statistique de parties du visage (MSV1 ), et d'un modèle statistique du visage (MSV2). 
<!-- EPO <DP n="5"/>-->
 Selon diverses mises en œuvre éventuellement utilisées conjointement : - le procédé comporte une étape 100 de prétraitement de l'image afin de s'affranchir au mieux des conditions d'éclairage de la prise de vue, ce prétraitement comportant une égalisation d'histogramme. </p><p id="p0026" num="0026"> - le procédé comporte une étape 200 de détection du visage dans l'image, réalisée grâce à un algorithme du type de celui de Viola et Jones </p><p id="p0027" num="0027">Présentation des figures </p><p id="p0028" num="0028"> Les caractéristiques et avantages de l'invention seront mieux appréciés grâce à la description qui suit, description qui expose les caractéristiques de l'invention au travers d'un exemple non limitatif d'application. </p><p id="p0029" num="0029"> La description s'appuie sur les figures annexées qui représentent : </p><p id="p0030" num="0030"> Figure 1 : un organigramme du procédé tel que décrit ici </p><p id="p0031" num="0031"> Figure 2 : un exemple de modèle statistique de visage. </p><p id="p0032" num="0032">Description détaillée d'un mode de réalisation de l'invention </p><p id="p0033" num="0033"> Dans le cadre de l'exemple décrit ici, le procédé selon l'invention (illustré figure 1 ) est destiné à être mis en œuvre sous forme logicielle, par exemple par un micro-ordinateur du marché; connu en soi. </p><p id="p0034" num="0034"> Le procédé travaille sur des données d'entrée représentatives d'une image du visage d'un individu. </p><p id="p0035" num="0035"> Le procédé et le dispositif d'acquisition de l'image du visage sortent en tant que tels du cadre de la présente invention et ne sont donc pas détaillés plus avant ici. </p><p id="p0036" num="0036">Mode de fonctionnement </p><p id="p0037" num="0037"> L'algorithme de la solution d'alignement de visage proposée comporte en quatre étapes : </p><p id="p0038" num="0038"> Etape 100 : Prétraitement de l'image afin de s'affranchir au mieux des conditions d'éclairage de la prise de vue. Le prétraitement de l'image utilisé est une égalisation d'histogramme 
<!-- EPO <DP n="6"/>-->
 Etape 200 : Détection du visage dans l'image. La détection de visage est réalisé grâce à un algorithme connu en soi, du type de celui de Viola et Jones </p><p id="p0039" num="0039">Etape 300 : Détection de parties du visage (comme par exemple les yeux et la bouche) dans la zone du visage détectée à l'étape 200 précédente. La détection de parties du visage consiste à faire converger un modèle statistique de visage simplifié (MSV1 ) de type modèle à apparence active par patchs (noté PAAM par simplification). </p><p id="p0040" num="0040"> Il est à noter que cette étape 300 peut contenir des sous-étapes intermédiaires qui ne sont pas indispensables, mais qui rendent la reconstruction (c'est-à-dire la détection des points caractéristiques du visage, permettant de le reconstituer sous n'importe quel angle) plus robuste. Cela consiste à faire converger en chaque sous-étape un modèle statistique de type PAAM de plus en plus riche ou complexe en nombre de points et/ou en taille de patchs. La dernière sous-étape étant la convergence du modèle statistique de visage simplifié le plus complexe. </p><p id="p0041" num="0041"> Le but de chaque sous étape est de faire converger un algorithme de type ICA (algorithme inverse compositionnel), connu en soi, sur un modèle statistique avant un autre modèle statistique plus complexe. </p><p id="p0042" num="0042"> Cet algorithme ICA, permet de trouver de manière itérative les paramètres de forme (p), de pose (q) et de texture (λ) qui correspondent au mieux à l'image traitée. </p><p id="p0043" num="0043"> En effet, ceci permet, notamment d'améliorer l'estimation du paramètre de pose q, qui est assez imprécise en utilisant la détection du visage de Viola et Jones. </p><p id="p0044" num="0044"> Il est à noter également que, dans une variante de mise en œuvre, une initialisation plus complexe des modèles PAAM peut être envisagée. Plusieurs instances ou initialisations du modèle statistique PAAM (du visage simplifié MSV1 ou d'une sous-étape) peuvent par exemple être initiées à l'intérieur de la zone du visage trouvé à l'étape 200. Les points des parties du visage détectés seront alors ceux donnés par la meilleure instance en termes de corrélation ou d'erreur de convergence. 
<!-- EPO <DP n="7"/>-->
 Etape 400 : Détection des points caractéristiques du visage. La détection des points caractéristiques du visage consiste à faire converger un modèle statistique de visage (MSV2) de type PAAM. La figure 2 illustre un exemple de modèle statistique de visage. </p><p id="p0045" num="0045">Les modèles statistiques MSV1 et MSV2 peuvent être créés à partir de la même base d'apprentissage, il existe alors des facteurs multiplicatifs permettant de faire correspondre des paramètres régissant les formes correspondant aux modèles statistiques MSV1 et MSV2. Par exemple, le paramètre modifiant la forme d'un mouvement de gauche à droite du visage pour le modèle statistique MSV1 est -1 fois celui du modèle statistique MSV2. </p><p id="p0046" num="0046"> L'initialisation de l'étape 400, peut donc éventuellement se faire à l'aide de ces facteurs multiplicatifs appliqués aux paramètres trouvés à l'étape 300. Les autres paramètres ne trouvant pas de correspondance peuvent être instanciés en plusieurs positions (-0.5, 0 et 0.5 par exemple), seule la convergence donnant l'erreur la plus petite. Des tests ont montré qu'il était préférable de considérer l'erreur donnée par la corrélation de la texture du modèle et de la texture de l'image (ZNCC) au lieu de la différence au carré de ces textures (SSD). </p><p id="p0047" num="0047"> Le paramètre de pose (q) est initialisé grâce à l'étape 300 </p><p id="p0048" num="0048"> Il est à noter que cette étape 400 peut contenir aussi des sous-étapes intermédiaires qui ne sont pas indispensables, mais qui rendent la reconstruction plus robuste. Cela consiste à faire converger en chaque sous- étape un modèle statistique de visage type PAAM de plus en plus complexe en termes de taille de patchs ou de résolution. La dernière sous-étape étant la convergence du modèle statistique de visage le plus complexe. </p><p id="p0049" num="0049"> Il est à noter également que les paramètres d'initialisation des sous- étapes peuvent être déduits de la sous étape précédente grâce au fait que les modèles statistiques de visages peuvent être créés à partir de la même base d'apprentissage. </p><p id="p0050" num="0050"> En ce qui concerne les modèles statistiques PAAM (utilisés dans les étapes 300 et 400), la méthode d'alignement par modélisation statistique comporte deux phases : 
<!-- EPO <DP n="8"/>-->
 - une phase d'apprentissage qui consiste à créer le modèle statistique et</p><p id="p0051" num="0051">- une phase de détection qui consiste à faire converger la forme et/ou la texture du modèle statistique sur une donnée réelle. La phase d'apprentissage du modèle statistique PAAM par patchs à apparence active (Patches Active Appearance Models), proposé dans le présent exemple de mise en œuvre de l'invention, diffère d'un algorithme de modèles locaux contraints CLM sur le fait qu'une texture est maintenant apprise et sur la manière d'effectuer l'alignement des données. </p><p id="p0052" num="0052"> La phase de détection du modèle PAAM se fait de façon similaire aux</p><p id="p0053" num="0053">AAM. On utilise une minimisation de Gauss Newton conjointement sur la texture, la forme et la pose du modèle, de sorte que la texture de chacun des patchs converge vers la texture de l'image utilisée pour la détection. Une différence très significative provient de la manière de modifier la forme (la manière d'implémenter les fonctions de déformation ou fonctions 'Warp'). En effet, les méthodes de convergence des AAM font appel à la composition de fonctions de déformation de maillage. Mais dans le cas de maillages, la composition en chaque triangle fait perdre la connexité du maillage. Un maillage étant un ensemble de points reliés par triangulation. </p><p id="p0054" num="0054"> L'avantage de cette approche PAAM est que la résolution de la minimisation ne nécessite pas d'approximation due aux fonctions de déformations (ou 'Warp') puisqu'il n'y a plus de notion de connexité de maillage et que l'on peut formaliser la solution problème de façon matricielle. Dans une mise en œuvre préférée, on utilise dans le présent procédé d'alignement du visage un modèle hiérarchique (noté HPAAM par simplification dans la suite de la description) qui est la composition de modèles statistiques PAAM, ces modèles pouvant être créés à partir des mêmes données d'apprentissage (textures et formes). </p><p id="p0055" num="0055"> Un modèle hiérarchique est défini comme la composition de modèles statistiques lorsque ces modèles statistiques sont créés à partir des mêmes données d'apprentissage (textures et formes). Seuls des sous-ensembles différents de points définissant les formes sont utilisés. 
<!-- EPO <DP n="9"/>-->
 On l'appelle hiérarchique parce que la définition (en nombre de points) et donc le contenu sémantique des modèles impliqués va progressivement croissante. </p><p id="p0056" num="0056"> La construction d'un modèle statistique de forme et de texture est, quant à lui, réalisé en alignant et en normalisant toutes les formes et les textures puis en appliquant une analyse en composante principale (notée par simplification ACP dans la suite de la description) sur les formes alignées et sur les textures alignées. Des algorithmes d'analyse en composante principale sont bien connus de l'homme du métier et ne sont donc pas détaillés ici. </p><p id="p0057" num="0057"> Les formes (S) sont alors paramétrées de la façon suivante :</p><p id="p0058" num="0058">S = - S 4- i&gt;sbs<sub>&gt;</sub> dans lequel S désigne la forme moyenne et b<sub>s</sub> les vecteurs propres donnés par l'analyse en composante principale. De façon similaire, pour les textures : Γ = J + ë<sub>T</sub>b<sub>T</sub> </p><p id="p0059" num="0059"> Les modèles statistiques présentés sont, dans le présent exemple, créés à partir d'une centaine de textures et formes de visages. </p><p id="p0060" num="0060"> Une texture est la concaténation de patchs rectangulaires centrés sur chaque point de la forme. </p><p id="p0061" num="0061"> Le modèle hiérarchique proposé est un ensemble composé d'un modèle statistique de parties visage (MSV1 ) et d'un modèle statistique du visage (MSV2). </p><p id="p0062" num="0062"> On effectue alors un alignement des formes par une analyse de Procruste, selon une méthode connue en soi. </p><p id="p0063" num="0063"> La forme du modèle statistique du visage MSV2 est, dans le présent exemple de mise en œuvre, constituée de cinquante et un points. Il est cependant clair que des modèles utilisant des nombres de points plus ou moins grands sont utilisables. </p><p id="p0064" num="0064"> Ici encore, on effectue un alignement des formes par une analyse de Procruste, selon une méthode connue en soi. La texture est la concaténation des 51 patchs rectangulaires </p><p id="p0065" num="0065">Dans la solution d'alignement de visage présentée ici à titre d'exemple nullement limitatif, on utilise un HPAAM pour la détection des parties de visage 
<!-- EPO <DP n="10"/>-->
 (étape 300) puis un HPAAM pour le visage pour la détection finale (étape 400). </p><p id="p0066" num="0066"> Un modèle statistique PAAM utilise deux paramètres normalisés à estimer : un premier paramètre p définissant la forme et un second paramètre λ définissant la texture. Pour la variabilité en pose des visages dans l'image (rotation, homothétie, translation) un troisième paramètre q (paramètre de pose) est à estimer. </p><p id="p0067" num="0067"> Pour la partie HPAAM des parties de visage (étape 300), les paramètres p et λ du modèle statistique PAAM MSV1 sont initialisés à 0, tandis que le paramètre de pose q est estimé grâce à la détection du visage. </p><p id="p0068" num="0068"> De la même façon, dans le cas ou des sous-étapes intermédiaires sont utilisées, les paramètres p et λ des modèles statistiques PAAM suivants (modèles plus complexes) sont initialisés à 0. </p><p id="p0069" num="0069"> Il est à noter que dans une réalisation non privilégiée car moins robuste, l'étape 300 de convergence d'un modèle statistique PAAM de visage simplifié MSV1 peut être supprimée. Dans ce cas, plusieurs instances ou initialisations du paramètre de forme de l'étape 400 sont alors initiées. Les points du visage détectés seront alors ceux donnés par meilleure instance en termes de corrélation ou d'erreur de convergence. </p><p id="p0070" num="0070"> Le paramètre λ de texture est quant à lui initialisé à 0 puisque les textures des deux étages (correspondant aux deux niveaux de résolution) ne sont pas liées. Enfin, le paramètre de pose q peut être directement repris de l'étage PAAM précédent. La présente invention vise selon un second aspect un procédé de suivi d'un ensemble prédéfini de points caractéristiques d'un visage dans une vidéo. En effet, le procédé d'alignement de visage décrit précédemment permet de détecter des points caractéristiques d'un visage se trouvant dans la première image composant une vidéo. Cette étape permet notamment de trouver les paramètres de pose, de texture et de forme expliquant le visage détecté. Pour les images suivantes qui composent la vidéo, une telle détection n'est pas nécessaire puisqu'il s'agit toujours de la même identité et les variations de forme et de pose entre 2 images consécutives sont minimes. Le suivi consiste 
<!-- EPO <DP n="11"/>-->
 donc à faire converger un modèle statistique de visage (MSV2) de type PAAM successivement pour chaque image. Les paramètres étant simplement initialisés grâce aux paramètres trouvés pour l'image précédente. </p><p id="p0071" num="0071"> Pour chaque point associé au patch, il est possible d'établir des mises en correspondances directes entre les images, et ainsi de permettre la reconstruction 3D éparse du modèle de visage ainsi que son suivi 3D au long de la séquence vidéo selon des techniques classiques d'ajustement de faisceau connues de l'homme du métier. </p><p id="p0072" num="0072">Avantages de réalisation </p><p id="p0073" num="0073"> Un algorithme d'alignement de visage HPAAM permet de détecter les points caractéristiques d'un visage en s'affranchissant le plus possible des conditions de prises de vues de l'image (induites par le système d'acquisition ou par l'illumination de la scène) et des variations propres au visage (identité, pose, expression). </p><p id="p0074" num="0074"> Il est à noter que le choix d'un modèle déformable par patch a pour avantage de créer moins de dépendances à l'illumination, moins de dépendances aux expressions du visage, et d'éviter le problème de connectivité du maillage par rapport à un modèle déformable complet. </p><p id="p0075" num="0075"> La reconstruction par patch proposée a montré son efficacité sur des bases de données de visages contenant une grande variabilité en identités, poses et illuminations. Variantes de réalisation </p><p id="p0076" num="0076"> La portée de la présente invention ne se limite pas aux détails des formes de réalisation ci-dessus considérées à titre d'exemple, mais s'étend au contraire aux modifications à la portée de l'homme de l'art. 
</p></description><claims mxw-id="PCLM44727283" ref-ucid="WO-2012113805-A1" lang="FR" load-source="patent-office"><claim-statement><!-- EPO <DP n="12"/>--> REVENDICATIONS </claim-statement><claim id="clm-0001" num="1"><claim-text>1 . Procédé de détection d'un ensemble prédéfini de points caractéristiques d'un visage à partir d'une image de ce visage, </claim-text><claim-text> caractérisé en ce que les points caractéristiques sont obtenus en faisant converger la forme et/ou la texture d'une hiérarchie de modèles statistiques de parties de visage sur les données réelles fournies par l'image du visage, les modèles statistiques utilisés étant de type Modèles à Apparence Active par Patchs (PAAM). </claim-text></claim><claim id="clm-0002" num="2"><claim-text>2. Procédé selon la revendication 1 , caractérisé en ce qu'il comporte l'utilisation d'une hiérarchie de modèles statistiques de visages simplifiés</claim-text><claim-text>(HPAAM) pour la détection de parties de visage (étape 300) puis d'une hiérarchie de modèles statistiques de visage pour la détection finale (étape 400). </claim-text></claim><claim id="clm-0003" num="3"><claim-text>3. Procédé selon l'une quelconque des revendications précédentes, caractérisé en ce que le groupe d'étapes 300-400 utilise une méthode d'alignement par modélisation comportant deux phases : </claim-text><claim-text> - une phase d'apprentissage qui consiste à créer un modèle statistique et</claim-text><claim-text>- une phase de détection qui consiste à faire converger la forme et/ou la texture du modèle statistique sur une donnée réelle. </claim-text></claim><claim id="clm-0004" num="4"><claim-text>4. Procédé selon la revendication 3, caractérisé en ce que la construction d'un modèle statistique de forme et de texture est réalisée en alignant et en normalisant toutes les formes et les textures puis en appliquant une analyse en composante principale sur les formes alignées et sur les textures alignées. </claim-text></claim><claim id="clm-0005" num="5"><claim-text>5. Procédé selon la revendication 2, caractérisé en ce que les modèles statistiques sont créés à partir de mêmes données d'apprentissage (textures et formes), seuls des sous-ensembles différents de points définissant les formes étant utilisés. <!-- EPO <DP n="13"/>--> </claim-text></claim><claim id="clm-0006" num="6"><claim-text>6. Procédé selon l'une quelconque des revendications précédentes, caractérisé en ce qu'il comporte une étape de minimisation par un algorithme inverse compositionnel (ICA) pour la détection de points caractéristiques du visage en faisant converger des paramètres de forme p, de pose q et de texture λ de chaque modèle statistique de partie de visage. </claim-text></claim><claim id="clm-0007" num="7"><claim-text>7. Procédé selon l'une quelconque des revendications 3 à 5, caractérisé en ce que dans la phase de détection du modèle PAAM, on utilise une minimisation de Gauss Newton conjointement sur la texture, la forme et la pose du modèle, de sorte que la texture de chacun des patchs converge vers la texture de l'image utilisée pour la détection. </claim-text></claim><claim id="clm-0008" num="8"><claim-text>8. Procédé selon l'une quelconque des revendications précédentes, caractérisé en ce que le modèle hiérarchique est un ensemble composé d'un modèle statistique de visage simplifié (MSV1 ), et d'un modèle statistique du visage (MSV2). </claim-text></claim><claim id="clm-0009" num="9"><claim-text>9. Procédé selon l'une quelconque des revendications précédentes, caractérisé en ce qu'il comporte une étape 100 de prétraitement de l'image afin de s'affranchir au mieux des conditions d'éclairage de la prise de vue, ce prétraitement comportant une égalisation d'histogramme. </claim-text></claim><claim id="clm-0010" num="10"><claim-text>10. Procédé selon l'une quelconque des revendications précédentes, caractérisé en ce qu'il comporte une étape 200 de détection du visage dans l'image, réalisée grâce à un algorithme du type de celui de Viola et Jones </claim-text></claim><claim id="clm-0011" num="11"><claim-text>1 1 . Procédé de suivi d'un ensemble prédéfini de points caractéristiques d'un visage dans une vidéo, </claim-text><claim-text> caractérisé en ce que le procédé comporte une détection de points caractéristiques du visage pour la première image composant la vidéo, et qui consiste à faire converger la forme et/ou la texture d'un modèle statistique de parties de visage sur les données réelles fournies par les images suivantes composant la vidéo, le modèle statistique utilisé étant de type Modèle à Apparence Active par Patchs (PAAM). </claim-text></claim></claims><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
