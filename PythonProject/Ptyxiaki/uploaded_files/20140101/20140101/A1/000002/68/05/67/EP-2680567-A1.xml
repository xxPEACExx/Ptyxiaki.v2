<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2680567-A1" country="EP" doc-number="2680567" kind="A1" date="20140101" family-id="46317274" file-reference-id="257599" date-produced="20180824" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="146549121" ucid="EP-2680567-A1"><document-id><country>EP</country><doc-number>2680567</doc-number><kind>A1</kind><date>20140101</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-12173448-A" is-representative="YES"><document-id mxw-id="PAPP154823044" load-source="docdb" format="epo"><country>EP</country><doc-number>12173448</doc-number><kind>A</kind><date>20120625</date><lang>EN</lang></document-id><document-id mxw-id="PAPP226229713" load-source="docdb" format="original"><country>EP</country><doc-number>12173448.7</doc-number><date>20120625</date></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC140450294" ucid="EP-12173448-A" load-source="docdb"><document-id format="epo"><country>EP</country><doc-number>12173448</doc-number><kind>A</kind><date>20120625</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL1988105054" load-source="docdb">H04N   5/357       20110101ALI20121130BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1988112526" load-source="docdb">H04N   5/217       20110101AFI20121130BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1988117221" load-source="docdb">G06T   5/00        20060101ALI20121130BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1988120805" load-source="docdb">H04N   5/232       20060101ALI20121130BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL1988918825" load-source="docdb" scheme="CPC">G06T   5/002       20130101 FI20140103BHEP        </classification-cpc><classification-cpc mxw-id="PCL1988919821" load-source="docdb" scheme="CPC">H04N   5/144       20130101 LA20140103BHEP        </classification-cpc><classification-cpc mxw-id="PCL2066399213" load-source="docdb" scheme="CPC">G06T   5/50        20130101 LI20140403BHEP        </classification-cpc><classification-cpc mxw-id="PCL2066399214" load-source="docdb" scheme="CPC">G06T2207/10016     20130101 LA20140403BHEP        </classification-cpc><classification-cpc mxw-id="PCL2066399215" load-source="docdb" scheme="CPC">G06T2207/20182     20130101 LA20140403BHEP        </classification-cpc><classification-cpc mxw-id="PCL2066399216" load-source="docdb" scheme="CPC">G06T2207/30232     20130101 LA20140403BHEP        </classification-cpc><classification-cpc mxw-id="PCL2102369868" load-source="docdb" scheme="CPC">H04N   5/23254     20130101 LI20140730BHEP        </classification-cpc><classification-cpc mxw-id="PCL2102370248" load-source="docdb" scheme="CPC">H04N   5/2173      20130101 LI20140730BHEP        </classification-cpc><classification-cpc mxw-id="PCL2102371022" load-source="docdb" scheme="CPC">H04N   5/361       20130101 LI20140730BHEP        </classification-cpc><classification-cpc mxw-id="PCL2102379026" load-source="docdb" scheme="CPC">H04N   5/23267     20130101 LI20140730BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT132179847" lang="DE" load-source="patent-office">Videorauschunterdrückung</invention-title><invention-title mxw-id="PT132179848" lang="EN" load-source="patent-office">Video noise reduction</invention-title><invention-title mxw-id="PT132179849" lang="FR" load-source="patent-office">Réduction du bruit vidéo</invention-title><citations><patent-citations><patcit mxw-id="PCIT242651887" load-source="docdb" ucid="EP-1995948-A2"><document-id format="epo"><country>EP</country><doc-number>1995948</doc-number><kind>A2</kind><date>20081126</date></document-id><sources><source name="SEA" category="I" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT242651886" load-source="docdb" ucid="US-20070070250-A1"><document-id format="epo"><country>US</country><doc-number>20070070250</doc-number><kind>A1</kind><date>20070329</date></document-id><sources><source name="APP" created-by-npl="N"/><source name="SEA" category="YD" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT377888983" load-source="docdb" ucid="US-20100165122-A1"><document-id format="epo"><country>US</country><doc-number>20100165122</doc-number><kind>A1</kind><date>20100701</date></document-id><sources><source name="SEA" category="IY" created-by-npl="N"/></sources></patcit></patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR918162255" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>AXIS AB</last-name><address><country>SE</country></address></addressbook></applicant><applicant mxw-id="PPAR918144391" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>AXIS AB</last-name></addressbook></applicant><applicant mxw-id="PPAR918993525" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Axis AB</last-name><iid>100082004</iid><address><street>Emdalavägen 14</street><city>223 69 Lund</city><country>SE</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR918163885" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>OESTLUND PETTER</last-name><address><country>SE</country></address></addressbook></inventor><inventor mxw-id="PPAR918149859" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>OESTLUND, PETTER</last-name></addressbook></inventor><inventor mxw-id="PPAR918986062" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>ÖSTLUND, Petter</last-name><address><street>Banergränden 33</street><city>226 48 Lund</city><country>SE</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR918988226" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Johansson, Magnus</last-name><iid>100822718</iid><address><street>Awapatent AB Box 1066</street><city>251 10 Helsingborg</city><country>SE</country></address></addressbook></agent></agents></parties><international-convention-data><designated-states><ep-contracting-states><country mxw-id="DS548802252" load-source="docdb">AL</country><country mxw-id="DS548845090" load-source="docdb">AT</country><country mxw-id="DS548802253" load-source="docdb">BE</country><country mxw-id="DS548843797" load-source="docdb">BG</country><country mxw-id="DS548835874" load-source="docdb">CH</country><country mxw-id="DS548802254" load-source="docdb">CY</country><country mxw-id="DS548846121" load-source="docdb">CZ</country><country mxw-id="DS548842794" load-source="docdb">DE</country><country mxw-id="DS548802255" load-source="docdb">DK</country><country mxw-id="DS548802256" load-source="docdb">EE</country><country mxw-id="DS548847781" load-source="docdb">ES</country><country mxw-id="DS548843802" load-source="docdb">FI</country><country mxw-id="DS548843803" load-source="docdb">FR</country><country mxw-id="DS548842795" load-source="docdb">GB</country><country mxw-id="DS548802257" load-source="docdb">GR</country><country mxw-id="DS548842796" load-source="docdb">HR</country><country mxw-id="DS548846126" load-source="docdb">HU</country><country mxw-id="DS548835875" load-source="docdb">IE</country><country mxw-id="DS548802262" load-source="docdb">IS</country><country mxw-id="DS548843804" load-source="docdb">IT</country><country mxw-id="DS548802263" load-source="docdb">LI</country><country mxw-id="DS548842797" load-source="docdb">LT</country><country mxw-id="DS548845091" load-source="docdb">LU</country><country mxw-id="DS548843805" load-source="docdb">LV</country><country mxw-id="DS548842798" load-source="docdb">MC</country><country mxw-id="DS548845092" load-source="docdb">MK</country><country mxw-id="DS548845093" load-source="docdb">MT</country><country mxw-id="DS548847782" load-source="docdb">NL</country><country mxw-id="DS548801439" load-source="docdb">NO</country><country mxw-id="DS548847783" load-source="docdb">PL</country><country mxw-id="DS548844158" load-source="docdb">PT</country><country mxw-id="DS548846127" load-source="docdb">RO</country><country mxw-id="DS548844159" load-source="docdb">RS</country><country mxw-id="DS548847784" load-source="docdb">SE</country><country mxw-id="DS548835876" load-source="docdb">SI</country><country mxw-id="DS548801440" load-source="docdb">SK</country><country mxw-id="DS548801441" load-source="docdb">SM</country><country mxw-id="DS548846150" load-source="docdb">TR</country></ep-contracting-states><ep-extended-states><ep-extended-state-data><country>BA</country></ep-extended-state-data><ep-extended-state-data><country>ME</country></ep-extended-state-data></ep-extended-states></designated-states></international-convention-data></bibliographic-data><abstract mxw-id="PA128669791" lang="EN" load-source="patent-office"><p id="pa01" num="0001">Noise is reduced in video frames captured by an image sensor (103) of a monitoring camera (100) by using image data representing a captured video frame (302) and image data representing a previously captured video frame (304) at least partially overlapping the captured video frame (302), as well as motion data representing global motion vectors for the captured video frame (302) in relation to the previously captured video frame (304). The captured video frame (302) and the previously captured video frame (304) are spatially aligned using the global motion vectors to provide a set of spatially aligned video frames, and temporal noise reduction is performed on the captured video frame using the spatially aligned set of video frames to provide a temporally noise reduced captured video frame.
<img id="iaf01" file="imgaf001.tif" wi="73" he="100" img-content="drawing" img-format="tif"/></p></abstract><abstract mxw-id="PA128499164" lang="EN" source="EPO" load-source="docdb"><p>Noise is reduced in video frames captured by an image sensor (103) of a monitoring camera (100) by using image data representing a captured video frame (302) and image data representing a previously captured video frame (304) at least partially overlapping the captured video frame (302), as well as motion data representing global motion vectors for the captured video frame (302) in relation to the previously captured video frame (304). The captured video frame (302) and the previously captured video frame (304) are spatially aligned using the global motion vectors to provide a set of spatially aligned video frames, and temporal noise reduction is performed on the captured video frame using the spatially aligned set of video frames to provide a temporally noise reduced captured video frame.</p></abstract><description mxw-id="PDES63955221" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><heading id="h0001"><u>Technical field</u></heading><p id="p0001" num="0001">The present invention relates to methods and devices for noise reduction of video frames.</p><heading id="h0002"><u>Background</u></heading><p id="p0002" num="0002">Surveillance cameras are currently used in many different applications, for monitoring environments both indoors and outdoors. To give a useful picture of the monitored environment also in difficult imaging situations, different types of noise reduction may be used to enhance and improve the image data. One example of such noise reduction is temporal noise reduction.</p><p id="p0003" num="0003"><patcit id="pcit0001" dnum="US20070070250A"><text>US 2007/0070250</text></patcit> discloses a temporal noise reduction method where the overall gain of the temporal filtering is adjusted based on global motion.</p><p id="p0004" num="0004">As noise reduction is an important factor in improving the usefulness of image data from surveillance cameras, improvements in this area are always of interest.</p><heading id="h0003"><u>Summary</u></heading><p id="p0005" num="0005">An object of the present invention is to improve the quality of images captured by a monitoring camera.</p><p id="p0006" num="0006">This and further objects are achieved by a method of reducing noise in video frames captured by a monitoring camera according to claim 1, by means of a video noise reducer according to claim 6, and by means of a monitoring camera according to claim 10. Further embodiments of the invention are presented in the dependent claims.</p><p id="p0007" num="0007">In particular, according to a first aspect of the invention, a method of reducing noise in video frames captured by an image sensor of a monitoring camera, comprises the steps of:
<ul><li>accessing image data representing a captured video frame,</li><li>accessing image data representing a previously captured video frame at least partially overlapping the captured video frame,</li><li>accessing motion data representing global motion vectors for the captured video frame in relation to the previously captured video frame,<!-- EPO <DP n="2"> --></li><li>spatially aligning the captured video frame and the previously captured video frame using the global motion vectors to provide a set of spatially aligned video frames, and</li><li>performing temporal noise reduction on the captured video frame using the spatially aligned set of video frames to provide a temporally noise reduced captured video frame.</li></ul></p><p id="p0008" num="0008">In this way temporal noise reduction may be used also in a case where relative movement occurs between the camera and large parts of a scene. Thereby the image quality is enhanced and the usefulness of the video is improved.</p><p id="p0009" num="0009">The method may further include the step of performing image stabilization of the captured video frame, wherein the global motion vectors are established as part of the image stabilization step. In this case these global motion vectors may serve a dual purpose, being used both for image stabilization and to improve the temporal noise reduction.</p><p id="p0010" num="0010">The step of performing temporal noise reduction may comprise accessing data representing local motion information for the captured video frame in relation to the previously captured video frame, and excluding areas of the captured video frame from the temporal noise reduction where the local motion information indicates a moving object. In this case pixels or image elements which represent an object moving across the scene may be excluded from the temporal noise reduction, which further improves the functioning of the temporal noise reduction.</p><p id="p0011" num="0011">The step of performing temporal noise reduction further may comprise providing the temporally noise reduced video frame by calculating an average of the set of spatially aligned video frames. In this way random noise varying over time may be cancelled out or at least reduced.</p><p id="p0012" num="0012">The step of spatially aligning the captured video frame and the previously captured video frame may comprise accessing image data from an image sensor border area provided for image stabilization purposes. In this way the temporal noise reduction may be performed on a larger part of the captured video frame, possibly even the entire video frame.</p><p id="p0013" num="0013">According to a second aspect of the invention, a video noise reducer for reducing noise in video frames captured by an image sensor of a monitoring camera, comprises<!-- EPO <DP n="3"> -->
<ul><li>an image data input arranged to receive information representing a captured video frame and a previously captured video frame at least partially overlapping the captured video frame,</li><li>a motion data input arranged to receive information representing global motion vectors for the captured video frame in relation to the previously captured video frame,</li><li>a spatial aligner arranged to spatially align the captured video frame and the previously captured video frame using the global motion vectors to provide a set of spatially aligned video frames, and</li><li>a temporal noise reducer arranged to perform temporal noise reduction on the captured video frame using the spatially aligned set of video frames to provide a temporally noise reduced captured video frame.</li></ul></p><p id="p0014" num="0014">The motion data input may further be arranged to receive data representing local motion information for the captured video frame in relation to the previously captured video frame, and the temporal noise reducer may further be arranged to exclude areas of the captured video frame from the temporal noise reduction where the local motion information indicates a moving object. In this way the temporal noise reduction is improved by taking into account the occurrence of moving objects in the scene.</p><p id="p0015" num="0015">The temporal noise reducer may be arranged to provide the temporally noise reduced captured video frame by calculating an average of the set of spatially aligned video frames. This gives the possibility to cancel out or at least reduce random noise varying over time.</p><p id="p0016" num="0016">The image data input may further be arranged to receive image data captured by an image sensor border area, and the spatial aligner may further be arranged to use image data from the image sensor border area. As mentioned above, in this way the temporal noise reduction may be performed on a larger part of the captured video frame, possibly even the entire video frame.</p><p id="p0017" num="0017">According to some embodiment of the invention a monitoring camera comprises an image sensor and a video noise reducer described above.</p><p id="p0018" num="0018">The monitoring camera may further comprise an image stabilizer arranged to perform image stabilization of the captured video frame and to establish the global motion vectors as part of the image stabilization. These global motion vectors may then be used both for the image stabilization and for the temporal noise reduction<!-- EPO <DP n="4"> --> according to embodiments of the present invention. In other words, less additional hardware and/or software is needed.</p><p id="p0019" num="0019">The image sensor may comprise a border area for image stabilization purposes. This border area makes it possible to use information outside the overlapping parts of the video frames when spatially aligning the video frames. The border area is also used for image stabilization purposes, and, thus, serves a dual purpose, or, in other words, less additional hardware and/or software need to be provided.</p><p id="p0020" num="0020">A further scope of applicability of the present invention will become apparent from the detailed description given below. However, it should be understood that the detailed description and specific examples, while indicating preferred embodiments of the invention, are given by way of illustration only, since various changes and modifications within the scope of the invention will become apparent to those skilled in the art from this detailed description. Hence, it is to be understood that this invention is not limited to the particular component parts of the device described or steps of the methods described as such device and method may vary. It is also to be understood that the terminology used herein is for purpose of describing particular embodiments only, and is not intended to be limiting. It must be noted that, as used in the specification and the appended claim, the articles "a," "an," "the," and "said" are intended to mean that there are one or more of the elements unless the context clearly dictates otherwise. Thus, for example, reference to "a sensor" or "the sensor" may include several sensors, and the like. Furthermore, the word "comprising" does not exclude other elements or steps.</p><heading id="h0004"><u>Brief description of the drawings</u></heading><p id="p0021" num="0021">Other features and advantages of the present invention will become apparent from the following detailed description of presently preferred embodiments, with reference to the accompanying drawings, in which:
<ul><li><figref idrefs="f0001">Fig 1</figref> schematically illustrates a monitoring camera.</li><li><figref idrefs="f0001">Fig. 2</figref> illustrates a method according to embodiments of the invention.</li><li><figref idrefs="f0001">Fig. 3</figref> illustrates an image sensor.</li></ul></p><heading id="h0005"><u>Detailed description of embodiments of the invention</u></heading><p id="p0022" num="0022">Embodiments of the present invention may be implemented in an imaging device capturing video of a scene, e.g. a mechanically or digitally pan- and tiltable<!-- EPO <DP n="5"> --> monitoring camera 100, parts of which are shown in <figref idrefs="f0001">Fig 1</figref>. Alternatively, embodiments of the invention may be implemented in any device implementing functions reducing noise in video frames, e.g. in a video encoding device, a video server, a video processing device, etc. Further, it should be noted that the different parts of the video noise reducer may be implemented either in software or in hardware, or in a combination thereof.</p><p id="p0023" num="0023">The camera 100 includes an image capturing unit 102 arranged to capture images, in the form of sequences of video frames, of a scene. The image capturing means 102 comprises an image sensor 103 for registering image data, and may further comprise a number of conventional components not illustrated in the figures, such as a lens, an image processor for processing image data registered by the image sensor 103, and a memory of any suitable type such as a RAM (Random Access Memory), a hard disc drive or a flash memory etc, for storing processed image data.</p><p id="p0024" num="0024">Image data, or, more precisely, information representing captured video frames, is fed to a video noise reducer 104 via an image data input 106. More in detail, in the embodiments presented herein, a captured video frame and a previously captured video frame are fed to the video noise reducer 104.</p><p id="p0025" num="0025">The video noise reducer 104 comprises a temporal noise reducer 114 which may be arranged to improve the quality of images by averaging image elements, e.g. pixels, over at least two video frames to remove temporal noise, i.e. noise which changes over time and which appear randomly in different image elements.</p><p id="p0026" num="0026">In temporal noise reduction, local motion vectors may be produced which describe motion between two consecutive video frames. These local motion vectors could e.g. indicate that a bird flying across the monitored scene has moved between two frames. The pixels of a frame which are associated with such local motion vectors may then be excluded from the averaging in the temporal noise reduction. Alternatively, any other temporal noise reduction method may be used.</p><p id="p0027" num="0027">In the monitoring camera discussed herein, motion data, or, more precisely, information representing global motion vectors for the captured video frame in relation to the previously captured video frame, is also fed to the video noise reducer 104 via a motion data input 108.</p><p id="p0028" num="0028">The motion data may be produced by an image stabilizer 110, which is shown in dashed lines to indicate that this is an optional feature of the monitoring camera. The image stabilizer 110 may perform stabilizing of images in conventional manner,<!-- EPO <DP n="6"> --> and the global motion vectors for the video frames may be established as part of the image stabilizing functionality. As an alternative the global motion vectors may also be established or calculated separately from image stabilization, e.g. in a case where image stabilizing functionality is not implemented in the monitoring camera. The global motion vectors may be established via some sort of image processing. One example is by using local motion vectors of sub-images which in turn are obtained by techniques such as block matching or edge pattern matching. Another option is to use an iterative, multi-resolution motion estimation scheme, e.g. using multi-resolution pyramids. Yet another option is to use mechanical motion detection, e.g. with an electronic micro chip-packed gyroscope, such as a micro-electromechanical system, MEMS. The global motion vectors may also be established using methods similar to those used in the H.264 and MPEG standards for video compression.</p><p id="p0029" num="0029">The global motion vectors describe the amount of global motion that has taken place in the time between the capture of two video frames. This motion may e.g. be caused by the camera being placed on a moving vehicle or on a post swaying in the wind, or when a large part of the scene moves. In other words, global motion vectors indicate the movement of an entire frame, or at least a main part thereof, indicating that the entire scene has moved in relation to the camera, or vice versa, since the last video frame was captured.</p><p id="p0030" num="0030">In the video noise reducer 104, the global motion vectors are now used to spatially align the captured video frame and the previously captured video frame to provide a set of spatially aligned video frames. This step is performed by a spatial aligner 112. The set of spatially aligned video frames are then fed to the temporal noise reducer 114 which performs temporal noise reduction on the spatially aligned video frames in order to produce a temporally noise reduced video frame, corresponding to the captured video frame. In this way, the image quality is improved.</p><p id="p0031" num="0031">In comparison to a method where global motion vectors are not used in the temporal noise reduction, this method has the advantage of being able to perform temporal noise reduction also in a case where the entire video frame has moved between two frames. Were the global motion vectors not used, the entire frame would likely be excluded from the temporal noise reduction as the local motion vectors would indicate movement in all pixels of the frame.</p><p id="p0032" num="0032">It may be noted that the temporal noise reduction may still calculate local motion vectors for the set of spatially aligned video frames, as it still would be<!-- EPO <DP n="7"> --> advantageous to exclude pixels with local motion between frames. To illustrate this, one might picture the situation where the camera is placed on a pole which sways slightly in the wind, and a ball is thrown across the scene monitored by the camera. The global motion vectors will indicate that the entire video frame moves, but the pixels which represent the ball will still be associated with local motion vectors, and, hence, can be excluded from the temporal noise reduction.</p><p id="p0033" num="0033"><figref idrefs="f0001">Fig. 3</figref> illustrates a captured video frame 302 and a partially overlapping, previously captured video frame 304 in a situation where global movement has occurred. In <figref idrefs="f0001">Fig. 3</figref> both of the video frames 302 and 304 are captured within the same image sensor 103. The image sensor 103 in this case includes a border area 306 which may be seen as a buffert zone surrounding the captured frame. The buffert zone allows the image to move between two frames but still be captured in its entirety. When performing the spatial aligning, image data representing not only the previously captured frame 304 but also representing an area outside the previously captured frame 304 may be used, so that temporal noise reduction may be performed for the entire captured video frame, not only for those parts that actually overlap the previously captured video frame. Such a border area 306 or buffert zone may also be utilized for image stabilization purposes.</p><p id="p0034" num="0034">In <figref idrefs="f0001">Fig. 2</figref>, a method 200 of reducing noise in video frames captured by an image sensor of a monitoring camera is illustrated. In a first step 202, image data representing a captured video frame, and a previously captured video frame at least partially overlapping the captured video frame, is accessed. In step 204, motion data representing global motion vectors for the captured video frame in relation to the previously captured video frame is accessed. It may be noted that steps 202 and 204 may take place in any order, or even concurrently.</p><p id="p0035" num="0035">In step 206 the captured video frame and the previously captured video frame are spatially aligned to provide a set of spatially aligned video frames. This may either take place by the previously captured frame being spatially aligned to the captured video frame or the other way around. As a third option both frames may be affected by the aligning. The alignment may take place by shifting the affected frame/s in the x- and/or y-direction and the alignment may also include rotation of the affected frame/s. In case an image sensor border area is present, this may be used to provide a full overlap between the frames after the spatial aligning. In case such a border area is not available, only the overlapping parts of the frames will be included in the set of the spatially aligned video frames.<!-- EPO <DP n="8"> --></p><p id="p0036" num="0036">Finally, in step 208, temporal noise reduction is performed on the captured video frame using the spatially aligned set of video frames to provide a temporally noise reduced captured video frame. This temporally noise reduced video frame may then be fed to possible further image processing, such as object detection, or it may be shown to an operator.</p><p id="p0037" num="0037">In case the border area was not available for the temporal noise reduction, the temporally noise reduced video frame will obviously contain some parts where the temporal noise is not reduced according to the method presented herein, i.e. those parts for which it was not possible to perform the temporal noise reduction due to the lack of overlap. In other words, the image data in such parts of the video frame are those provided in the captured video frame, before the temporal noise reduction took place.</p><p id="p0038" num="0038">Obviously, the temporal noise reduction may be performed repeatedly on several video frames, where the captured video frame then will assume the role of a previously captured video frame. For sake of simplicity, only the process of performing the temporal noise reduction on one frame is described.</p><p id="p0039" num="0039">It may also be noted that the extension to using several previously captured video frames, or even future frames, in the temporal noise reduction presented herein, is straight forward. In case future video frames are to be used, a slight delay in producing the temporally noise reduced captured video frame will obviously occur as one or more of such future video frames first have to be captured.</p><p id="p0040" num="0040">To summarize, noise is reduced in video frames captured by an image sensor 103 of a monitoring camera 100, by using image data representing a captured video frame 302 and image data representing a previously captured video frame 304 at least partially overlapping the captured video frame 302, as well as motion data representing global motion vectors for the captured video frame 302 in relation to the previously captured video frame 304. The captured video frame 302 and the previously captured video frame 304 are spatially aligned using the global motion vectors to provide a set of spatially aligned video frames, and temporal noise reduction is performed on the captured video frame using the spatially aligned set of video frames to provide a temporally noise reduced captured video frame.</p></description><claims mxw-id="PCLM56976134" lang="EN" load-source="patent-office"><!-- EPO <DP n="9"> --><claim id="c-en-0001" num="0001"><claim-text>A method of reducing noise in video frames captured by an image sensor of a monitoring camera, comprising the steps of:
<claim-text>accessing (202) image data representing a captured video frame,</claim-text>
<claim-text>accessing (202) image data representing a previously captured video frame at least partially overlapping the captured video frame,</claim-text>
<claim-text>accessing (204) motion data representing global motion vectors for the captured video frame in relation to the previously captured video frame,</claim-text>
<claim-text>spatially aligning (206) the captured video frame and the previously captured video frame using the global motion vectors to provide a set of spatially aligned video frames, and</claim-text>
<claim-text>performing (208) temporal noise reduction on the captured video frame using the spatially aligned set of video frames to provide a temporally noise reduced captured video frame.</claim-text></claim-text></claim><claim id="c-en-0002" num="0002"><claim-text>The method of claim 1, further comprising the step of performing image stabilization of the captured video frame, wherein the global motion vectors are established as part of the image stabilization step.</claim-text></claim><claim id="c-en-0003" num="0003"><claim-text>The method of any of the above claims, wherein the step of performing temporal noise reduction comprises<br/>
accessing data representing local motion information for the captured video frame in relation to the previously captured video frame, and<br/>
excluding areas of the captured video frame from the temporal noise reduction where the local motion information indicates a moving object.</claim-text></claim><claim id="c-en-0004" num="0004"><claim-text>The method of any of the above claims, wherein the step of performing temporal noise reduction further comprises<br/>
providing the temporally noise reduced video frame by calculating an average of the set of spatially aligned video frames.</claim-text></claim><claim id="c-en-0005" num="0005"><claim-text>The method of any of the above claims, wherein the step of spatially aligning the captured video frame and the previously captured video frame comprises accessing image data from an image sensor border area provided for image stabilization purposes.<!-- EPO <DP n="10"> --></claim-text></claim><claim id="c-en-0006" num="0006"><claim-text>A video noise reducer for reducing noise in video frames captured by an image sensor of a monitoring camera, comprising<br/>
an image data input (106) arranged to receive information representing a captured video frame (302) and a previously captured video frame (304) at least partially overlapping the captured video frame (302),<br/>
a motion data input (108) arranged to receive information representing global motion vectors for the captured video frame (302) in relation to the previously captured video frame (304),<br/>
a spatial aligner (112) arranged to spatially align the captured video frame (302) and the previously captured video frame (304) using the global motion vectors to provide a set of spatially aligned video frames, and<br/>
a temporal noise reducer (114) arranged to perform temporal noise reduction on the captured video frame (302) using the spatially aligned set of video frames to provide a temporally noise reduced captured video frame.</claim-text></claim><claim id="c-en-0007" num="0007"><claim-text>The video noise reducer of claim 6, wherein<br/>
the motion data input (108) is further arranged to receive data representing local motion information for the captured video frame in relation to the previously captured video frame, and<br/>
the temporal noise reducer (114) is further arranged to exclude areas of the captured video frame from the temporal noise reduction where the local motion information indicates a moving object.</claim-text></claim><claim id="c-en-0008" num="0008"><claim-text>The video noise reducer of claim 6 or 7, wherein<br/>
the temporal noise reducer (114) is arranged to provide the temporally noise reduced captured video frame by calculating an average of the set of spatially aligned video frames.</claim-text></claim><claim id="c-en-0009" num="0009"><claim-text>The video noise reducer of any of claims 6-8, wherein<br/>
the image data input (106) is further arranged to receive image data captured by an image sensor border area (308), and<br/>
the spatial aligner (112) is further arranged to use image data from the image sensor border area (308).<!-- EPO <DP n="11"> --></claim-text></claim><claim id="c-en-0010" num="0010"><claim-text>A monitoring camera comprising<br/>
an image sensor (103), and<br/>
a video noise reducer (104) according to any of claims 7-9.</claim-text></claim><claim id="c-en-0011" num="0011"><claim-text>The monitoring camera of claim 10, further comprising<br/>
an image stabilizer (110) arranged to perform image stabilization of the captured video frame (302), and to establish the global motion vectors as part of the image stabilization.</claim-text></claim><claim id="c-en-0012" num="0012"><claim-text>The monitoring camera of claim 10 or 11, wherein the image sensor (103) comprises a border area (306) provided for image stabilization purposes.</claim-text></claim></claims><drawings mxw-id="PDW16666919" load-source="patent-office"><!-- EPO <DP n="12"> --><figure id="f0001" num="1,2,3"><img id="if0001" file="imgf0001.tif" wi="165" he="199" img-content="drawing" img-format="tif"/></figure></drawings><search-report-data><doc-page id="srep0001" file="srep0001.tif" wi="159" he="233" type="tif"/><doc-page id="srep0002" file="srep0002.tif" wi="158" he="233" type="tif"/></search-report-data><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
