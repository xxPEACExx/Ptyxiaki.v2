<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2680221-A1" country="EP" doc-number="2680221" kind="A1" date="20140101" family-id="48670570" file-reference-id="318307" date-produced="20180824" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="146549383" ucid="EP-2680221-A1"><document-id><country>EP</country><doc-number>2680221</doc-number><kind>A1</kind><date>20140101</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-12305768-A" is-representative="YES"><document-id mxw-id="PAPP154823306" load-source="docdb" format="epo"><country>EP</country><doc-number>12305768</doc-number><kind>A</kind><date>20120628</date><lang>EN</lang></document-id><document-id mxw-id="PAPP168045543" load-source="docdb" format="original"><country>EP</country><doc-number>12305768.9</doc-number><date>20120628</date><lang>EN</lang></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC140452339" ucid="EP-12305768-A" load-source="docdb"><document-id format="epo"><country>EP</country><doc-number>12305768</doc-number><kind>A</kind><date>20120628</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL1988132208" load-source="docdb">G06T   3/40        20060101AFI20130107BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-1999876008" load-source="docdb" scheme="CPC">G06T   3/4053      20130101 FI20151114BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1999879817" load-source="docdb" scheme="CPC">G06T   3/4038      20130101 LI20151113BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT132180633" lang="DE" load-source="patent-office">Verfahren und System zur Erzeugung eines Video-Streams mit hoher Auflösung</invention-title><invention-title mxw-id="PT132180634" lang="EN" load-source="patent-office">Method and system for generating a high-resolution video stream</invention-title><invention-title mxw-id="PT132180635" lang="FR" load-source="patent-office">Procédé et système de génération d'un flux vidéo haute résolution</invention-title><citations><patent-citations><patcit mxw-id="PCIT242652372" load-source="docdb" ucid="US-20060003328-A1"><document-id format="epo"><country>US</country><doc-number>20060003328</doc-number><kind>A1</kind><date>20060105</date></document-id><sources><source name="SEA" category="A" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT242652373" load-source="docdb" ucid="WO-2002093916-A2"><document-id format="epo"><country>WO</country><doc-number>2002093916</doc-number><kind>A2</kind><date>20021121</date></document-id><sources><source name="SEA" category="A" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT242652374" load-source="docdb" ucid="WO-2011092696-A1"><document-id format="epo"><country>WO</country><doc-number>2011092696</doc-number><kind>A1</kind><date>20110804</date></document-id><sources><source name="SEA" category="A" created-by-npl="N"/></sources></patcit></patent-citations><non-patent-citations><nplcit><text>BISHOP C M ET AL: "Super-resolution Enhancement of Video", INTERNATIONAL WORKSHOP ON ARTIFICIAL INTELLIGENCE AND STATISTICS.(AISTATS 2003), no. 9TH, 3 January 2003 (2003-01-03), pages 1 - 8, XP002631362</text><sources><source mxw-id="PNPL53546060" load-source="docdb" name="SEA" category="XA"/></sources></nplcit><nplcit><text>FREEMAN W.T. ET AL.: "Learning Low-Level Vision", INTERNATIONAL JOURNAL OF COMPUTER VISION, vol. 40, no. 1, 2000 - 2000, pages 25 - 47, XP002687991</text><sources><source mxw-id="PNPL53546061" load-source="docdb" name="SEA" category="A"/></sources></nplcit><nplcit><text>None</text><sources><source mxw-id="PNPL67455038" load-source="docdb" name="APP"/></sources></nplcit><nplcit><text>STEPHANE PELLETIER ET AL: "High-Resolution Video Synthesis from Mixed-Resolution Video Based on the Estimate-and-Correct Method", 2005 SEVENTH IEEE WORKSHOPS ON APPLICATIONS OF COMPUTER VISION (WACV/MOTION'05) - 5-7 JAN. 2005 - BRECKENRIDGE, CO, USA, IEEE, LOS ALAMITOS, CALIF., USA, 1 January 2005 (2005-01-01), pages 172 - 177, XP031059086</text><sources><source mxw-id="PNPL53546062" load-source="docdb" name="SEA" category="A"/></sources></nplcit><nplcit><text>VINCENT CHEUNG ET AL: "Video Epitomes", INTERNATIONAL JOURNAL OF COMPUTER VISION, KLUWER ACADEMIC PUBLISHERS, BO, vol. 76, no. 2, 23 December 2006 (2006-12-23), pages 141 - 152, XP019581846</text><sources><source mxw-id="PNPL53546063" load-source="docdb" name="SEA" category="A"/></sources></nplcit></non-patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR918152818" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>ALCATEL LUCENT</last-name><address><country>FR</country></address></addressbook></applicant><applicant mxw-id="PPAR918161978" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>ALCATEL LUCENT</last-name></addressbook></applicant><applicant mxw-id="PPAR918988717" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Alcatel-Lucent</last-name><iid>101311164</iid><address><street>3, Avenue Octave Gréard</street><city>75007 Paris</city><country>FR</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR1098371615" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>NAMBOODIRI VINAY</last-name><address><country>IN</country></address></addressbook></inventor><inventor mxw-id="PPAR918132611" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>NAMBOODIRI, Vinay</last-name></addressbook></inventor><inventor mxw-id="PPAR918986331" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>NAMBOODIRI, Vinay</last-name><address><street>Paul Lebrunstraat 26 bus 201</street><city>3000 Leuven</city><country>BE</country></address></addressbook></inventor><inventor mxw-id="PPAR1098371616" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>MACQ JEAN-FRANÇOIS</last-name><address><country>BE</country></address></addressbook></inventor><inventor mxw-id="PPAR1098371614" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>Macq, Jean-François</last-name></addressbook></inventor><inventor mxw-id="PPAR918989720" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>Macq, Jean-François</last-name><address><street>Drève du Château 32</street><city>1083 Ganshoren</city><country>BE</country></address></addressbook></inventor><inventor mxw-id="PPAR918139472" load-source="docdb" sequence="3" format="epo"><addressbook><last-name>RONDAO ALFACE PATRICE</last-name><address><country>BE</country></address></addressbook></inventor><inventor mxw-id="PPAR918171727" load-source="docdb" sequence="3" format="intermediate"><addressbook><last-name>Rondao Alface, Patrice</last-name></addressbook></inventor><inventor mxw-id="PPAR918984919" load-source="patent-office" sequence="3" format="original"><addressbook><last-name>Rondao Alface, Patrice</last-name><address><street>Rue Sainte Barbe 110/1</street><city>1400 Nivelles</city><country>BE</country></address></addressbook></inventor><inventor mxw-id="PPAR918135963" load-source="docdb" sequence="4" format="epo"><addressbook><last-name>VERZIJP NICO</last-name><address><country>BE</country></address></addressbook></inventor><inventor mxw-id="PPAR918146165" load-source="docdb" sequence="4" format="intermediate"><addressbook><last-name>Verzijp, Nico</last-name></addressbook></inventor><inventor mxw-id="PPAR918990952" load-source="patent-office" sequence="4" format="original"><addressbook><last-name>Verzijp, Nico</last-name><address><street>Rembrandtstraat 20 / 4</street><city>2018 Antwerpen</city><country>BE</country></address></addressbook></inventor><inventor mxw-id="PPAR918157077" load-source="docdb" sequence="5" format="epo"><addressbook><last-name>SIX ERWIN</last-name><address><country>BE</country></address></addressbook></inventor><inventor mxw-id="PPAR918142128" load-source="docdb" sequence="5" format="intermediate"><addressbook><last-name>SIX, ERWIN</last-name></addressbook></inventor><inventor mxw-id="PPAR918989953" load-source="patent-office" sequence="5" format="original"><addressbook><last-name>SIX, ERWIN</last-name><address><street>Centrumwijk 47</street><city>9270 Kalken</city><country>BE</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR918985353" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Prins, Hendrik Willem</last-name><iid>100780471</iid><address><street>Arnold &amp; Siedsma Sweelinckplein 1</street><city>2517 GK The Hague</city><country>NL</country></address></addressbook></agent></agents></parties><international-convention-data><designated-states><ep-contracting-states><country mxw-id="DS548840820" load-source="docdb">AL</country><country mxw-id="DS548803549" load-source="docdb">AT</country><country mxw-id="DS548840822" load-source="docdb">BE</country><country mxw-id="DS548860702" load-source="docdb">BG</country><country mxw-id="DS548864925" load-source="docdb">CH</country><country mxw-id="DS548858326" load-source="docdb">CY</country><country mxw-id="DS548803550" load-source="docdb">CZ</country><country mxw-id="DS548804627" load-source="docdb">DE</country><country mxw-id="DS548858327" load-source="docdb">DK</country><country mxw-id="DS548858328" load-source="docdb">EE</country><country mxw-id="DS548890146" load-source="docdb">ES</country><country mxw-id="DS548860703" load-source="docdb">FI</country><country mxw-id="DS548860704" load-source="docdb">FR</country><country mxw-id="DS548840823" load-source="docdb">GB</country><country mxw-id="DS548858329" load-source="docdb">GR</country><country mxw-id="DS548840824" load-source="docdb">HR</country><country mxw-id="DS548803551" load-source="docdb">HU</country><country mxw-id="DS548864926" load-source="docdb">IE</country><country mxw-id="DS548840825" load-source="docdb">IS</country><country mxw-id="DS548860705" load-source="docdb">IT</country><country mxw-id="DS548858330" load-source="docdb">LI</country><country mxw-id="DS548804628" load-source="docdb">LT</country><country mxw-id="DS548803552" load-source="docdb">LU</country><country mxw-id="DS548804629" load-source="docdb">LV</country><country mxw-id="DS548804630" load-source="docdb">MC</country><country mxw-id="DS548878066" load-source="docdb">MK</country><country mxw-id="DS548878067" load-source="docdb">MT</country><country mxw-id="DS548803553" load-source="docdb">NL</country><country mxw-id="DS548890147" load-source="docdb">NO</country><country mxw-id="DS548803558" load-source="docdb">PL</country><country mxw-id="DS548804632" load-source="docdb">PT</country><country mxw-id="DS548803559" load-source="docdb">RO</country><country mxw-id="DS548804633" load-source="docdb">RS</country><country mxw-id="DS548803560" load-source="docdb">SE</country><country mxw-id="DS548804634" load-source="docdb">SI</country><country mxw-id="DS548864927" load-source="docdb">SK</country><country mxw-id="DS548864928" load-source="docdb">SM</country><country mxw-id="DS548878068" load-source="docdb">TR</country></ep-contracting-states><ep-extended-states><ep-extended-state-data><country>BA</country></ep-extended-state-data><ep-extended-state-data><country>ME</country></ep-extended-state-data></ep-extended-states></designated-states></international-convention-data></bibliographic-data><abstract mxw-id="PA128670053" lang="EN" load-source="patent-office"><p id="pa01" num="0001">A process for generating a high-resolution video stream, the process comprising: receiving (310) a low-resolution video stream; receiving (320) at least one high-resolution video stream; selecting (331) first image patches from said at least one high-resolution video stream; generating (332) respective first low-resolution counterparts of said first high-resolution image patches; storing (333) said first high-resolution image patches indexed by said first low-resolution counterparts in a first data storage; and improving (350) said low-resolution video stream by substituting (351) portions of said low-resolution video stream that are similar to one or more of said first low-resolution counterparts with first high-resolution patches obtained from said first data storage in accordance with said indexing; wherein said low-resolution video stream and said at least one high-resolution video stream are substantially synchronized video streams.
<img id="iaf01" file="imgaf001.tif" wi="117" he="91" img-content="drawing" img-format="tif"/></p></abstract><abstract mxw-id="PA128499426" lang="EN" source="EPO" load-source="docdb"><p>A process for generating a high-resolution video stream, the process comprising: receiving (310) a low-resolution video stream; receiving (320) at least one high-resolution video stream; selecting (331) first image patches from said at least one high-resolution video stream; generating (332) respective first low-resolution counterparts of said first high-resolution image patches; storing (333) said first high-resolution image patches indexed by said first low-resolution counterparts in a first data storage; and improving (350) said low-resolution video stream by substituting (351) portions of said low-resolution video stream that are similar to one or more of said first low-resolution counterparts with first high-resolution patches obtained from said first data storage in accordance with said indexing; wherein said low-resolution video stream and said at least one high-resolution video stream are substantially synchronized video streams.</p></abstract><description mxw-id="PDES63955483" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><heading id="h0001"><b>Field of the Invention</b></heading><p id="p0001" num="0001">The present invention relates to the field of video image processing, and in particular to the field of super-resolution techniques, i.e. the problem of generating a high-resolution image from one or more low-resolution images.</p><heading id="h0002"><b>Background</b></heading><p id="p0002" num="0002">The problem of generating a high-resolution panorama from several images has been approached in various ways.</p><p id="p0003" num="0003">A first option for improved high quality panoramas is to use higher quality panoramic cameras. Usually based on (almost) zero-parallax arrangements of multiple video sensors, these can capture panoramas that cover 360 degree views. However, there are limitations to the sensors currently and there is a limit to their abilities to sense the scene due to limited resolution of the camera device sensors. Also, including more sensors increases the cost of the device and in particular the cost of the real-time stitching.</p><p id="p0004" num="0004">Another option is to improve the image quality of broadcast using registration of an image from one camera onto other. These images can be stitched together to provide panoramic views. However, this approach suffers from parallax issues (different perspective deformations due to the difference in point of view and direction of view) and color differences. Moreover the dynamic registration of moving cameras is<!-- EPO <DP n="2"> --> difficult. Another problem is that while some part of the image may be available in other cameras, there will always exist some regions of the scene that is not covered by any camera. In this case, the user will have a very uneven experience while watching an event.</p><heading id="h0003"><b>Summary</b></heading><p id="p0005" num="0005">It is therefore an object of embodiments of the present invention to overcome, at least partially, one or more of the above stated problems.</p><p id="p0006" num="0006">According to an aspect of the invention, there is provided a process for generating a high-resolution video stream, the process comprising: receiving a low-resolution video stream; receiving at least one high-resolution video stream; selecting first image patches from the at least one high-resolution video stream; generating respective first low-resolution counterparts of the first high-resolution image patches; storing the first high-resolution image patches indexed by the first low-resolution counterparts in a first data storage; and improving the low-resolution video stream by substituting portions of the low-resolution video stream that are similar to one or more of the first low-resolution counterparts with first high-resolution patches obtained from the first data storage in accordance with the indexing; wherein the low-resolution video stream and the at least one high-resolution video stream are substantially synchronized video streams.</p><p id="p0007" num="0007">The term "low-resolution video" is used herein to denote an overview image, preferably a panoramic image, which provides relatively little detail. The term "high-resolution video"<!-- EPO <DP n="3"> --> is used herein to denote a video stream that provides more detail for a smaller portion of the scenery covered by the "low-resolution video". It is not necessary that the high-resolution video covers an area of the scenery that is wholly comprised within the scope of the low-resolution video. As will be explained below, a full overlap is preferred, but a partial overlap is also effective. Even a complete lack of overlap will not render the invention ineffective, provided that it is not permanent; i.e. there should be some link between the content of the low-resolution image and the high-resolution image.</p><p id="p0008" num="0008">A "patch" will be understood to be a small region of the video image. The patch is preferably rectangular, in a particular preference it is a square. It may have dimensions in the order of several pixels; preferably from 3×3 pixels up to 16×16 pixels.</p><p id="p0009" num="0009">It is an advantage of the present invention that parallax and perspective mismatch problems are avoided, because the process according to the invention does not attempt to paste entire morphologically recognizable features into the low-resolution image; on the contrary, very small patterns, which appear abstract to the human eye but which are nevertheless characteristic of the type of scenery that is being visualized, are substituted.</p><p id="p0010" num="0010">Thanks to the live nature of the process according to the invention, i.e. the use of high-resolution streams that are substantially synchronous to the low-resolution stream and that cover the same general scenery, the process according to the invention will outperform systems that are purely based on a static dictionary.<!-- EPO <DP n="4"> --></p><p id="p0011" num="0011">In an embodiment, the process according to the present invention is applied in conjunction with a second data storage comprising pre-stored second high-resolution image patches indexed by second low-resolution counterparts, and the process further comprises substituting portions of the low-resolution video stream that are similar to one or more of the second low-resolution counterparts with second high-resolution patches obtained from the second data storage in accordance with its indexing.</p><p id="p0012" num="0012">This embodiment combines the effectiveness of the dynamic creation of a patch dictionary with the efficiency of the use of a proven static dictionary.</p><p id="p0013" num="0013">In an embodiment of the process according to the present invention, the storing of the first high-resolution image patches comprises according an expiration time to the high-resolution image patches, the process further comprising deactivating the first high-resolution image patches in accordance with the expiration time.</p><p id="p0014" num="0014">In this embodiment, the dynamic dictionary is permanently updated, while avoiding an infinite increase in size of the stored data.</p><p id="p0015" num="0015">In an embodiment of the process according to the present invention, the improving of the low-resolution video stream comprises determining a similarity with the one or more of the first low-resolution counterparts by applying a "nearest neighbor" criterion, and wherein the substituting with first high-resolution patches comprises substituting with a weighted sum of the respective first high-resolution patches<!-- EPO <DP n="5"> --> corresponding to the low-resolution counterparts that meet the "nearest neighbor" criterion.</p><p id="p0016" num="0016">It is an advantage of this embodiment that resolution can be improved for certain patches of imagery despite the absence of an exact match in the dynamic dictionary.</p><p id="p0017" num="0017">In an embodiment of the process according to the present invention, the similarity is determined on the basis of intensity gradients.</p><p id="p0018" num="0018">This simplification has proven to be computationally efficient, while leading to excellent results.</p><p id="p0019" num="0019">According to an aspect of the present invention, there is provided a computer program comprising software means configured to perform, when executed, the method as described above.</p><p id="p0020" num="0020">According to an aspect of the present invention, there is provided a system for generating a high-resolution video stream, the system comprising: a first video interface for receiving a low-resolution video stream; a second video interface for receiving at least one high-resolution video stream; a registration processor, operatively connected to the second video interface and to a first data storage, the registration processor being configured to select first high-resolution image patches from the at least one high-resolution video stream, to generate respective first low-resolution counterparts of the first high-resolution image patches, and to store the first high-resolution image patches indexed by the first low-resolution counterparts in the data storage); and an image improvement processor,<!-- EPO <DP n="6"> --> operatively connected to the first video interface and to the first data storage, the image improvement processor being configured to substitute portions of the low-resolution video stream that are similar to one or more of the first low-resolution counterparts with first high-resolution patches obtained from the first data storage in accordance with the indexing; wherein the low-resolution video stream and the at least one high-resolution video stream are substantially synchronized.</p><p id="p0021" num="0021">In an embodiment, the system according to the present invention further comprises a second data storage, the second data storage comprising pre-stored second high-resolution image patches indexed by second low-resolution counterparts, and the image improvement processor is further configured to substitute portions of the low-resolution video stream that are similar to one or more of the second low-resolution counterparts with second high-resolution patches obtained from the second data storage in accordance with its indexing.</p><p id="p0022" num="0022">In an embodiment, the system according to the present invention further comprises a timer, operatively connected to the registration processor, and the registration processor is further configured to accord an expiration time to the first high-resolution image patches, and to deactivate the first high-resolution image patches in accordance with the expiration time in conjunction with the timer.</p><p id="p0023" num="0023">In an embodiment of the system according to the present invention, the image improvement processor is further configured to determine a similarity with the one or more of<!-- EPO <DP n="7"> --> the first low-resolution counterparts by applying a "nearest neighbor" criterion, and to substitute the portions with a weighted sum of the respective first high-resolution patches corresponding to the low-resolution counterparts that meet the "nearest neighbor" criterion.</p><p id="p0024" num="0024">In an embodiment of the system according to the present invention, the image improvement processor is further configured to determine the similarity on the basis of intensity gradients.</p><p id="p0025" num="0025">The technical effects and advantages of the program and system according to embodiments of the present invention correspond, <i>mutatis mutandis,</i> to those mentioned above for the corresponding embodiments of the process according to the present invention.</p><heading id="h0004"><b>Brief Description of the Figures</b></heading><p id="p0026" num="0026">Some embodiments of apparatus and/or methods in accordance with embodiments of the present invention are now described, by way of example only, and with reference to the accompanying drawings, in which:
<ul><li><figref idrefs="f0001">Figure 1</figref> provides an overview of a system and method according to an embodiment of the present invention;</li><li><figref idrefs="f0002">Figure 2</figref> provides an overview of a system and method according to another embodiment of the present invention;</li><li><figref idrefs="f0002">Figure 3</figref> provides a flow chart of a method according to an embodiment of the present invention; and<!-- EPO <DP n="8"> --></li><li><figref idrefs="f0003">Figure 4</figref> provides a block diagram of a system according to an embodiment of the present invention.</li></ul></p><heading id="h0005"><b>Description of Embodiments</b></heading><p id="p0027" num="0027">The focus of the present invention is on generating a high-resolution image from a single low-resolution image, with the help of a set of training images. The low-resolution image is typically a panoramic or wide-angle view of a scene, while the various training images provide high-resolution scenery. According to the invention, detailed (zoomed-in) images of the same general scenery are used as training images. These training images are processed in real time, to form a permanently updated dictionary of high-resolution image patches that can be blended into the panoramic video feed at locations where a low-resolution counterpart of such a patch is identified.</p><p id="p0028" num="0028">Embodiments of the present invention may advantageously be used in situations where multiple cameras, possibly including high definition (HD) cameras, are available to broadcast an event, but not everything is captured in one camera. When there is also an overview camera (omnicam or panoramic camera) available that captures the whole scene, this invention allows output of the overview cameras to be improved using the data from HD cameras. This enables broadcast of wider views with higher quality. A typical application is a television broadcast of a sports event, where a single overview camera may be used to capture a (low-resolution) overview of the entire playing field, or even the entire stadium, while multiple other cameras follow the movements of the players and/or the reactions of the audience.<!-- EPO <DP n="9"> --></p><p id="p0029" num="0029">In the process according to the invention, "patches" of high-resolution imagery taken from the detail images are substituted into the low-resolution base image. The individual "patches" of high-resolution imagery to be substituted into the low-resolution base image are preferably identified on the basis of their pattern of intensity gradients, ignoring the hue information. This approach has proven to give excellent results, while being more computationally efficient than a full-color pattern selection.</p><p id="p0030" num="0030">In the present application, the term "dictionary" denotes a database that associates a high-resolution intensity pattern (target) with a given number of low-resolution intensity pattern (key) .</p><p id="p0031" num="0031">The dictionary does not have to be complete. In fact, for practical reasons (in particular, the required amount of storage), it is recommended that the dictionary does not comprise entries for every single possible combination of pixel values that could make up a patch - except for tiny patches, such a dictionary would quickly become huge. One way of identifying the most appropriate high-resolution substitute for a low-resolution patch that does not appear in the dictionary as such, is based on locally linear embedding. That method comprises identifying the nearest neighbors of the low-resolution patch in the dictionary, calculating weights for those nearest neighbors that allow reconstruction of the low-resolution patch with minimal error, and applying the same weights to the high-resolution counterparts of the identified nearest neighbors. The<!-- EPO <DP n="10"> --> reconstructed high-resolution patch is then used as a substitute for the original low-resolution patch.</p><p id="p0032" num="0032">The present invention is based <i>inter alia</i> on the insight of the inventors that the use of a static dictionary does not always provide acceptable high-resolution panoramas.</p><p id="p0033" num="0033">While static dictionaries are believed to work adequately for natural images, other types of imagery (notably sports programs) are more specific and dynamic in nature. Using a generic database does not serve well in super-resolving the images of specific people and specific sports. This is because, in sports it is necessary to ensure the specific player and scene characteristics. A generic solution does not take this into account. For instance, in football, it is necessary to ensure that a specific player on super-resolution does not resemble another one. Additionally, specific objects such as the ball and lines on the playing field are crucial and a generic super-resolution method could modify the details in an unacceptable way during the super-resolution procedure.</p><p id="p0034" num="0034">Hence, according to the invention, the dictionary is populated in real-time with key-target pairs that are registered from the actual image material to which the super-resolution technique is being applied.</p><p id="p0035" num="0035">The process of identifying image patches that can serve as dictionary entries is referred to as registration. It includes the selection of a patch from a high-resolution image, downsampling of that patch to obtain a low-resolution counterpart, and storing the original high-resolution patch<!-- EPO <DP n="11"> --> along with its low-resolution counterpart as a key-target pair.</p><p id="p0036" num="0036">The present invention circumvents the above problems by adopting super-resolution by especially taking into account the specific scene-related information in the super-resolution procedure. The result is a system that may use live high definition (HD) cameras to improve a low resolution panorama by using super-resolution and coarse registration techniques.</p><p id="p0037" num="0037">Accordingly, a system is proposed which obtains online coarse scale related information from the HD cameras and the wide-angle panoramic view. A coupled high-resolution and low-resolution (HR-LR) dictionary is obtained by learning, and used for the super-resolution technique. No explicit overlap is needed. This is because a dictionary is populated with entries that piecewise maps the low-resolution panoramic view to the high-resolution view, without requiring that the individual pieces (patches) originate from the same field of view. This dictionary is based on statistics of the scene and is preferably operated in the gradient/edge domain (such that it is unaffected by color). The learning is done locally using patches. Note that it is not necessary for HD views to be present for all of the panoramic view.</p><p id="p0038" num="0038">The output of the overview panoramic camera is super-resolved using the learned dictionary through a projection step.</p><p id="p0039" num="0039">A first embodiment of the process according to the present invention will now be described in connection with <figref idrefs="f0001">Figure 1</figref>.<!-- EPO <DP n="12"> --></p><p id="p0040" num="0040">In the first embodiment, the relevant scene related information is obtained from the set of HD cameras <b>110.</b> There are various ways of doing this. An example of obtaining the related scene information is to perform a rough registration and alignment procedure <b>130.</b> The outcome of the registration process is the scaling ratio between the HD view and the corresponding area in the (lower resolution) panorama. The HD view is then downscaled according to that scaling ratio. The resulting view and its original HD copy are used in an online dictionary learning step.</p><p id="p0041" num="0041">An online dictionary <b>150</b> is then derived from this scene-related information. This is done by first preprocessing the input frames by performing gradient operation in the high resolution (HR) domain and mid-band filters in the corresponding down-sampled low-resolution (LR) domain. From the image frames we extract local corresponding HR and LR patches <b>140.</b> These are then quantized with a clustering algorithm resulting in a coupled dictionary of HR and LR visual vocabulary <b>120.</b> Once the online dictionary is learnt, we then do a projection <b>160</b> of the low-resolution patches from the panorama <b>100</b> onto the dictionary. This allows us to obtain the corresponding high resolution gradient patch information that is used for reconstructing the scene. This high-resolution gradient information is coupled with the color information to result in a high resolution output panoramic image <b>170.</b></p><p id="p0042" num="0042">Preferably, the patch substitution process is performed in a dense manner, i.e. by substituting overlapping portions of the original low-resolution image by high-resolution counterparts. Most preferably, the pixel values of the<!-- EPO <DP n="13"> --> overlapping parts of the high-resolution portions are combined (for instance by means of averaging or weighted averaging), so as to avoid boundary artifacts. Preferably, the image portions to be substituted are spaced apart by 3 pixels (center-to-center), and the patches are slightly greater than 3×3 pixels, thus forming an overlapping grid.</p><p id="p0043" num="0043">A second embodiment of the process according to the present invention will now be described in connection with <figref idrefs="f0002">Figure 2</figref>.</p><p id="p0044" num="0044">In the second embodiment, the online approach of the invention, as explained in connection with <figref idrefs="f0001">Figure 1</figref>, is combined with an offline approach. The same reference signs are used to denote the same features; these will not be explicitly repeated here. Thus, a previously populated (static) dictionary <b>210/250</b> is used in addition to the dynamic dictionary. The dynamic dictionary is adapted to the current scene by learning from the current HR frames. A simple example of an adaptation is by learning a more exhaustive dictionary of K features in the offline phase and a smaller dictionary of M features in the online learning phase. The combined dictionary <b>260</b> of K+M features can then be used in the super-resolution projection step <b>160.</b> This results also in a wide angle high resolution panorama <b>170</b> being generated and combines the strengths of the online and offline methods.</p><p id="p0045" num="0045">The video resulting from the process according to the invention will provide a much better user-experience, as having a high resolution panoramic view of the whole scene available would enable the user to choose and focus on what exactly he wants to see and at what level in much higher detail than was previously possible. It allows for better<!-- EPO <DP n="14"> --> resolution in areas where no broadcast camera is available. In areas where broadcast cameras are available, the pure broadcast view will still offer higher resolution. However, solving parallax issues is complex and computationally expensive, so the invention offers an advantageous alternative for that case as well.</p><p id="p0046" num="0046"><figref idrefs="f0002">Figure 3</figref> provides an exemplary flow chart of a method according to an embodiment of the present invention.</p><p id="p0047" num="0047">In a first step <b>310,</b> a low-resolution video stream is received. Preferably simultaneously, one or more high-resolution video streams are received <b>320.</b> The low-resolution video stream and the high-resolution video stream(s) are substantially synchronized video streams, representing the same general scenery.</p><p id="p0048" num="0048">Image patches are selected <b>331</b> from these high-resolution video streams, which may be scaled and/or transformed (as explained above, not shown in the Figure) to match the corresponding area in the low-resolution video. Low-resolution counterparts are generated <b>332</b> for the selected high-resolution image patches. Next, pairs of low-resolution counterparts and the high-resolution patches from which they are derived are stored <b>333</b> as an indexed dictionary in an appropriate data storage means.</p><p id="p0049" num="0049">The actual improving <b>350</b> of the low-resolution video stream is performed by substituting <b>351</b> portions of the low-resolution video stream that are sufficiently similar to one or more of the stored low-resolution patches with corresponding high-resolution patches obtained from the first data storage.<!-- EPO <DP n="15"> --></p><p id="p0050" num="0050">The process may further comprise substituting <b>352</b> portions of the low-resolution video stream with high-resolution patches obtained from a second, static data storage.</p><p id="p0051" num="0051">The storage of low-resolution/high-resolution pairs in the dynamic dictionary is preferably subjected to an expiration time, such that the process may comprise deactivating <b>360</b> patch pairs in accordance with said expiration time. This ensures that the size of the dynamic dictionary does not grow indefinitely, and that is contents represent the current (or at least most recent) statistics of the visualized scenery. The expiration time may be expressed as a number of frames (i.e., video frames), or as an absolute amount of time. Adequate results can be achieved with an expiration time of 3 video frames, or approximately 100-120 ms. Preferably, the expiration time is set between 3 and 1000 video frames.</p><p id="p0052" num="0052">The substitution of image portions by high-resolution patches is not necessarily one-to-one. The process may determine the similarity between an image portion and the patches in the dictionary by applying a "nearest neighbor" criterion. Accordingly, the substitution step would include synthesizing a high-resolution patch from the various high-resolution patches that correspond to the respective nearest neighbors in of the target portion in the low-resolution domain.</p><p id="p0053" num="0053">Hereinabove, the steps of the exemplary process have been describe in a particular order for clarity reasons only. In general, the steps of the methods according to the invention may performed in a different order, parallelized, or<!-- EPO <DP n="16"> --> serialized, unless it is clear from the context that a particular step cannot occur unless preceded or followed by a particular other step.</p><p id="p0054" num="0054"><figref idrefs="f0003">Figure 4</figref> provides a block diagram of a system according to an embodiment of the present invention.</p><p id="p0055" num="0055">The illustrated system <b>400</b> includes a first video interface <b>410</b> for receiving a low-resolution video stream and a second video interface <b>420</b> for receiving at least one high-resolution video stream. The low-resolution video stream and the at least one high-resolution video stream are substantially synchronized.</p><p id="p0056" num="0056">The term "interface" designates the necessary hardware and software required to establish data communication connectivity across the various layers of the protocol stack, as is well known to a person skilled in the art. Preferably, standardized protocols are used. An access interface may for instance include an interface for an xDSL, xPON, WMAN, or 3G link. A LAN interface may for instance include an interface for one or more of an IEEE 802.3 "Ethernet" link, an IEEE 802.11 "Wireless LAN" link. A PAN interface may for instance include a USB interface or a Bluetooth interface.</p><p id="p0057" num="0057">The system further includes a registration processor <b>430,</b> operatively connected to the second video interface <b>420</b> and to a first data storage <b>440.</b> The registration processor <b>430</b> is configured to select first high-resolution image patches from the high-resolution video stream(s), to generate respective low-resolution counterparts of the high-resolution image patches, and to store the high-resolution<!-- EPO <DP n="17"> --> image patches indexed by the first low-resolution counterparts in the data storage <b>440.</b> In order to properly scale and/or transform the high-resolution patches, the area to which they belong may be matched on a feature basis with the corresponding area of the low-resolution video stream. To this end, the registration processor <b>430</b> would be further operatively connected to the first video interface <b>410.</b></p><p id="p0058" num="0058">The system further includes an image improvement processor <b>450,</b> operatively connected to the first video interface <b>410</b> and to the first data storage <b>440.</b> The image improvement processor <b>450</b> is configured to substitute portions of the low-resolution video stream that are similar to one or more stored low-resolution counterparts with high-resolution patches obtained from the first data storage <b>440</b> in accordance with the indexing.</p><p id="p0059" num="0059">A second data storage <b>450</b> may be present in the system <b>400.</b> This second data storage <b>450</b> comprises a static dictionary, consisting of pre-stored high-resolution image patches indexed by their low-resolution counterparts. In this case, the image improvement processor <b>450</b> is further configured to substitute portions of the low-resolution video stream that are similar to one or more of said second low-resolution counterparts with high-resolution patches obtained from the second data storage <b>440</b> in accordance with its indexing.</p><p id="p0060" num="0060">The system <b>400</b> may include a timer <b>460,</b> in order to impose an expiration policy upon the entries stored in the dynamic dictionary at the first data storage <b>440.</b> The timer <b>460</b> is operatively connected to the registration processor <b>430,</b> which is further configured to accord an expiration time to the high-resolution image patches, and to deactivate these<!-- EPO <DP n="18"> --> high-resolution image patches (preferably by deleting them from the storage <b>440)</b> in accordance with the expiration time, using the timing input from the timer <b>460.</b></p><p id="p0061" num="0061">Although methods and apparatus have been described hereinabove as separate embodiments, this is done for clarity purposes only, and it should be noted that features described only in connection with method embodiments may be applied in the apparatus according to the present invention to obtain the same technical effects and advantages, and vice versa.</p><p id="p0062" num="0062">The functions of the various elements shown in the figures, including any functional blocks labeled as "processors", may be provided through the use of dedicated hardware as well as hardware capable of executing software in association with appropriate software. When provided by a processor, the functions may be provided by a single dedicated processor, by a single shared processor, or by a plurality of individual processors, some of which may be shared. Moreover, explicit use of the term "processor" or "controller" should not be construed to refer exclusively to hardware capable of executing software, and may implicitly include, without limitation, digital signal processor (DSP) hardware, network processor, application specific integrated circuit (ASIC), field programmable gate array (FPGA), read only memory (ROM) for storing software, random access memory (RAM), and non volatile storage. Other hardware, conventional and/or custom, may also be included. Similarly, any switches shown in the FIGS. are conceptual only. Their function may be carried out through the operation of program logic, through dedicated logic, through the interaction of program control and dedicated logic, or even manually, the<!-- EPO <DP n="19"> --> particular technique being selectable by the implementer as more specifically understood from the context.</p><p id="p0063" num="0063">A person of skill in the art would readily recognize that steps of various above-described methods can be performed by programmed computers. Herein, some embodiments are also intended to cover program storage devices, e.g., digital data storage media, which are machine or computer readable and encode machine-executable or computer-executable programs of instructions, wherein said instructions perform some or all of the steps of said above-described methods. The program storage devices may be, e.g., digital memories, magnetic storage media such as a magnetic disks and magnetic tapes, hard drives, or optically readable digital data storage media. The embodiments are also intended to cover computers programmed to perform said steps of the above-described methods.</p></description><claims mxw-id="PCLM56976400" lang="EN" load-source="patent-office"><!-- EPO <DP n="20"> --><claim id="c-en-0001" num="0001"><claim-text>A process for generating a high-resolution video stream, the process comprising:
<claim-text>- receiving (310) a low-resolution video stream;</claim-text>
<claim-text>- receiving (320) at least one high-resolution video stream;</claim-text>
<claim-text>- selecting (331) first image patches from said at least one high-resolution video stream;</claim-text>
<claim-text>- generating (332) respective first low-resolution counterparts of said first high-resolution image patches;</claim-text>
<claim-text>- storing (333) said first high-resolution image patches indexed by said first low-resolution counterparts in a first data storage; and</claim-text>
<claim-text>- improving (350) said low-resolution video stream by substituting (351) portions of said low-resolution video stream that are similar to one or more of said first low-resolution counterparts with first high-resolution patches obtained from said first data storage in accordance with said indexing;<br/>
wherein said low-resolution video stream and said at least one high-resolution video stream are substantially synchronized video streams.</claim-text></claim-text></claim><claim id="c-en-0002" num="0002"><claim-text>The process according to claim 1, applied in conjunction with a second data storage comprising pre-stored second high-resolution image patches indexed by second low-resolution counterparts, the process further comprising substituting (352) portions of said low-resolution video stream that are similar to one or more of said second low-resolution counterparts with second high-resolution patches obtained from said second data storage in accordance with its indexing.<!-- EPO <DP n="21"> --></claim-text></claim><claim id="c-en-0003" num="0003"><claim-text>The process according to any of the preceding claims, wherein said storing (333) of said first high-resolution image patches comprises according an expiration time to said high-resolution image patches, the process further comprising deactivating (360) said first high-resolution image patches in accordance with said expiration time.</claim-text></claim><claim id="c-en-0004" num="0004"><claim-text>The process according to any of the preceding claims, wherein said improving (350) of said low-resolution video stream comprises determining a similarity with said one or more of said first low-resolution counterparts by applying a "nearest neighbor" criterion, and wherein said substituting with first high-resolution patches comprises substituting with a weighted sum of the respective first high-resolution patches corresponding to the low-resolution counterparts that meet said "nearest neighbor" criterion.</claim-text></claim><claim id="c-en-0005" num="0005"><claim-text>The process according to any of the preceding claims, wherein said similarity is determined on the basis of intensity gradients.</claim-text></claim><claim id="c-en-0006" num="0006"><claim-text>A computer program comprising software means configured to perform, when executed the method of any of the preceding claims.</claim-text></claim><claim id="c-en-0007" num="0007"><claim-text>A system (400) for generating a high-resolution video stream, the system (400) comprising:
<claim-text>- a first video interface (410) for receiving a low-resolution video stream;</claim-text>
<claim-text>- a second video interface (420) for receiving at least one high-resolution video stream;</claim-text>
<claim-text>- a registration processor (430), operatively connected to said second video interface (420) and to a first data<!-- EPO <DP n="22"> --> storage (440), said registration processor (430) being configured to select first high-resolution image patches from said at least one high-resolution video stream, to generate respective first low-resolution counterparts of said first high-resolution image patches, and to store said first high-resolution image patches indexed by said first low-resolution counterparts in said data storage (440); and</claim-text>
<claim-text>- an image improvement processor (450), operatively connected to said first video interface (410) and to said first data storage (440), said image improvement processor (450) being configured to substitute portions of said low-resolution video stream that are similar to one or more of said first low-resolution counterparts with first high-resolution patches obtained from said first data storage (440) in accordance with said indexing;<br/>
wherein said low-resolution video stream and said at least one high-resolution video stream are substantially synchronized.</claim-text></claim-text></claim><claim id="c-en-0008" num="0008"><claim-text>The system (400) according to claim 6, further comprising a second data storage (450), said second data storage (450) comprising pre-stored second high-resolution image patches indexed by second low-resolution counterparts, wherein said image improvement processor (450) is further configured to substitute portions of said low-resolution video stream that are similar to one or more of said second low-resolution counterparts with second high-resolution patches obtained from said second data storage (440) in accordance with its indexing.</claim-text></claim><claim id="c-en-0009" num="0009"><claim-text>The system (400) according to any of claims 7-8, further comprising a timer (460), operatively connected to said registration processor (430), wherein said registration<!-- EPO <DP n="23"> --> processor (430) is further configured to accord an expiration time to said first high-resolution image patches, and to deactivate said first high-resolution image patches in accordance with said expiration time in conjunction with said timer.</claim-text></claim><claim id="c-en-0010" num="0010"><claim-text>The system (400) according to any of claims 7-9, wherein said image improvement processor (450) is further configured to determine a similarity with said one or more of said first low-resolution counterparts by applying a "nearest neighbor" criterion, and to substitute said portions with a weighted sum of the respective first high-resolution patches corresponding to the low-resolution counterparts that meet said "nearest neighbor" criterion.</claim-text></claim><claim id="c-en-0011" num="0011"><claim-text>The system (400) according to any of claims 7-10, wherein said image improvement processor (450) is further configured to determine said similarity on the basis of intensity gradients.</claim-text></claim></claims><drawings mxw-id="PDW16667181" load-source="patent-office"><!-- EPO <DP n="24"> --><figure id="f0001" num="1"><img id="if0001" file="imgf0001.tif" wi="165" he="130" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="25"> --><figure id="f0002" num="2,3"><img id="if0002" file="imgf0002.tif" wi="165" he="220" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="26"> --><figure id="f0003" num="4"><img id="if0003" file="imgf0003.tif" wi="165" he="147" img-content="drawing" img-format="tif"/></figure></drawings><search-report-data><doc-page id="srep0001" file="srep0001.tif" wi="157" he="233" type="tif"/><doc-page id="srep0002" file="srep0002.tif" wi="158" he="233" type="tif"/><doc-page id="srep0003" file="srep0003.tif" wi="156" he="233" type="tif"/></search-report-data><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
