<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2680217-A1" country="EP" doc-number="2680217" kind="A1" date="20140101" family-id="46720293" file-reference-id="252638" date-produced="20180824" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="146549387" ucid="EP-2680217-A1"><document-id><country>EP</country><doc-number>2680217</doc-number><kind>A1</kind><date>20140101</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-11859180-A" is-representative="NO"><document-id mxw-id="PAPP154823310" load-source="docdb" format="epo"><country>EP</country><doc-number>11859180</doc-number><kind>A</kind><date>20110223</date><lang>JA</lang></document-id><document-id mxw-id="PAPP220439689" load-source="docdb" format="original"><country>EP</country><doc-number>11859180.9</doc-number><date>20110223</date></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC140450690" ucid="JP-2011053979-W" linkage-type="A" load-source="docdb"><document-id format="epo"><country>JP</country><doc-number>2011053979</doc-number><kind>W</kind><date>20110223</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL1988115576" load-source="docdb">G06T   1/00        20060101AFI20120910BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL1988104026" load-source="docdb" scheme="CPC">G06K   9/00033     20130101 LI20131011BHEP        </classification-cpc><classification-cpc mxw-id="PCL1988106563" load-source="docdb" scheme="CPC">G06K   9/00013     20130101 FI20131031BHEP        </classification-cpc><classification-cpc mxw-id="PCL1988124616" load-source="docdb" scheme="CPC">G06K2009/00932     20130101 LA20131011BHEP        </classification-cpc><classification-cpc mxw-id="PCL1988129955" load-source="docdb" scheme="CPC">G06K   9/00919     20130101 LI20131011BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT132180645" lang="DE" load-source="patent-office">VORRICHTUNG ZUR ERFASSUNG BIOLOGISCHER INFORMATIONEN UND VERFAHREN ZUR ERFASSUNG BIOLOGISCHER INFORMATIONEN</invention-title><invention-title mxw-id="PT132180646" lang="EN" load-source="patent-office">BIOLOGICAL INFORMATION ACQUISITION DEVICE AND BIOLOGICAL INFORMATION ACQUISITION METHOD</invention-title><invention-title mxw-id="PT132180647" lang="FR" load-source="patent-office">DISPOSITIF D'ACQUISITION D'INFORMATIONS BIOLOGIQUES ET PROCÉDÉ D'ACQUISITION D'INFORMATIONS BIOLOGIQUES</invention-title><citations><non-patent-citations><nplcit><text>See references of WO 2012114474A1</text><sources><source mxw-id="PNPL67455039" load-source="docdb" name="SEA"/></sources></nplcit></non-patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR918148458" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>FUJITSU FRONTECH LTD</last-name><address><country>JP</country></address></addressbook></applicant><applicant mxw-id="PPAR918160632" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>FUJITSU FRONTECH LIMITED</last-name></addressbook></applicant><applicant mxw-id="PPAR918979584" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Fujitsu Frontech Limited</last-name><iid>101065923</iid><address><street>1776, Yanokuchi</street><city>Inagi-shi Tokyo 206-8555</city><country>JP</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR918151990" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>KAMATA HIDEO</last-name><address><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR918140711" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>KAMATA, HIDEO</last-name></addressbook></inventor><inventor mxw-id="PPAR918989514" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>KAMATA, HIDEO</last-name><address><street>c/o Fujitsu Frontech Limited 1776 Yanokuchi</street><city>Inagi-shi Tokyo 206-8555</city><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR918145140" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>MINAGAWA AKITAKA</last-name><address><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR918173140" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>MINAGAWA, AKITAKA</last-name></addressbook></inventor><inventor mxw-id="PPAR918989889" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>MINAGAWA, AKITAKA</last-name><address><street>c/o Fujitsu Frontech Limited 1776 Yanokuchi</street><city>Inagi-shi Tokyo 206-8555</city><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR918149750" load-source="docdb" sequence="3" format="epo"><addressbook><last-name>HIGASHIURA YASUYUKI</last-name><address><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR918158520" load-source="docdb" sequence="3" format="intermediate"><addressbook><last-name>HIGASHIURA, YASUYUKI</last-name></addressbook></inventor><inventor mxw-id="PPAR918983428" load-source="patent-office" sequence="3" format="original"><addressbook><last-name>HIGASHIURA, YASUYUKI</last-name><address><street>c/o Fujitsu Frontech Limited 1776 Yanokuchi</street><city>Inagi-shi Tokyo 206-8555</city><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR918145979" load-source="docdb" sequence="4" format="epo"><addressbook><last-name>KASUGAI KENTAROU</last-name><address><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR918140518" load-source="docdb" sequence="4" format="intermediate"><addressbook><last-name>KASUGAI, KENTAROU</last-name></addressbook></inventor><inventor mxw-id="PPAR918990588" load-source="patent-office" sequence="4" format="original"><addressbook><last-name>KASUGAI, KENTAROU</last-name><address><street>c/o Fujitsu Frontech Limited 1776 Yanokuchi</street><city>Inagi-shi Tokyo 206-8555</city><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR918169584" load-source="docdb" sequence="5" format="epo"><addressbook><last-name>IDE KATSUMI</last-name><address><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR918140300" load-source="docdb" sequence="5" format="intermediate"><addressbook><last-name>IDE, KATSUMI</last-name></addressbook></inventor><inventor mxw-id="PPAR918986432" load-source="patent-office" sequence="5" format="original"><addressbook><last-name>IDE, KATSUMI</last-name><address><street>c/o Fujitsu Frontech Limited 1776 Yanokuchi</street><city>Inagi-shi Tokyo 206-8555</city><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR918138021" load-source="docdb" sequence="6" format="epo"><addressbook><last-name>TANAKA HIROYUKI</last-name><address><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR918132923" load-source="docdb" sequence="6" format="intermediate"><addressbook><last-name>TANAKA, HIROYUKI</last-name></addressbook></inventor><inventor mxw-id="PPAR918991454" load-source="patent-office" sequence="6" format="original"><addressbook><last-name>TANAKA, HIROYUKI</last-name><address><street>c/o Fujitsu Frontech Limited 1776 Yanokuchi</street><city>Inagi-shi Tokyo 206-8555</city><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR918152604" load-source="docdb" sequence="7" format="epo"><addressbook><last-name>YOSHIDA TAKASHI</last-name><address><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR918161945" load-source="docdb" sequence="7" format="intermediate"><addressbook><last-name>YOSHIDA, TAKASHI</last-name></addressbook></inventor><inventor mxw-id="PPAR918993165" load-source="patent-office" sequence="7" format="original"><addressbook><last-name>YOSHIDA, TAKASHI</last-name><address><street>c/o Fujitsu Frontech Limited 1776 Yanokuchi</street><city>Inagi-shi Tokyo 206-8555</city><country>JP</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR918987256" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>HOFFMANN EITLE</last-name><iid>100061036</iid><address><street>Patent- und Rechtsanwälte Arabellastrasse 4</street><city>81925 München</city><country>DE</country></address></addressbook></agent></agents></parties><international-convention-data><pct-or-regional-filing-data ucid="JP-2011053979-W"><document-id><country>JP</country><doc-number>2011053979</doc-number><kind>W</kind><date>20110223</date><lang>JA</lang></document-id></pct-or-regional-filing-data><pct-or-regional-publishing-data ucid="WO-2012114474-A1"><document-id><country>WO</country><doc-number>2012114474</doc-number><kind>A1</kind><date>20120830</date><lang>JA</lang></document-id></pct-or-regional-publishing-data><designated-states><ep-contracting-states><country mxw-id="DS548804646" load-source="docdb">AL</country><country mxw-id="DS548858346" load-source="docdb">AT</country><country mxw-id="DS548804647" load-source="docdb">BE</country><country mxw-id="DS548864939" load-source="docdb">BG</country><country mxw-id="DS548890499" load-source="docdb">CH</country><country mxw-id="DS548840840" load-source="docdb">CY</country><country mxw-id="DS548858347" load-source="docdb">CZ</country><country mxw-id="DS548804648" load-source="docdb">DE</country><country mxw-id="DS548840841" load-source="docdb">DK</country><country mxw-id="DS548840842" load-source="docdb">EE</country><country mxw-id="DS548878084" load-source="docdb">ES</country><country mxw-id="DS548864940" load-source="docdb">FI</country><country mxw-id="DS548864941" load-source="docdb">FR</country><country mxw-id="DS548804649" load-source="docdb">GB</country><country mxw-id="DS548840843" load-source="docdb">GR</country><country mxw-id="DS548804650" load-source="docdb">HR</country><country mxw-id="DS548858348" load-source="docdb">HU</country><country mxw-id="DS548890500" load-source="docdb">IE</country><country mxw-id="DS548804651" load-source="docdb">IS</country><country mxw-id="DS548864942" load-source="docdb">IT</country><country mxw-id="DS548840844" load-source="docdb">LI</country><country mxw-id="DS548860717" load-source="docdb">LT</country><country mxw-id="DS548858349" load-source="docdb">LU</country><country mxw-id="DS548860718" load-source="docdb">LV</country><country mxw-id="DS548860719" load-source="docdb">MC</country><country mxw-id="DS548803632" load-source="docdb">MK</country><country mxw-id="DS548803633" load-source="docdb">MT</country><country mxw-id="DS548878085" load-source="docdb">NL</country><country mxw-id="DS548864943" load-source="docdb">NO</country><country mxw-id="DS548878086" load-source="docdb">PL</country><country mxw-id="DS548890501" load-source="docdb">PT</country><country mxw-id="DS548878087" load-source="docdb">RO</country><country mxw-id="DS548890502" load-source="docdb">RS</country><country mxw-id="DS548878092" load-source="docdb">SE</country><country mxw-id="DS548890503" load-source="docdb">SI</country><country mxw-id="DS548803654" load-source="docdb">SK</country><country mxw-id="DS548803655" load-source="docdb">SM</country><country mxw-id="DS548840845" load-source="docdb">TR</country></ep-contracting-states></designated-states></international-convention-data></bibliographic-data><abstract mxw-id="PA128670057" lang="EN" load-source="patent-office"><p id="pa01" num="0001">To adequately acquire biometric information even when a feature amount of the biometric information may vary by a variety of factors.</p><p id="pa02" num="0002">A biometric information acquisition apparatus (1) acquires biometric information to be used for verification. The biometric information acquisition apparatus (1) includes a blood flow increasing unit (2a), a biometric information acquiring unit (2b), a feature amount evaluating unit (2c), and a reacquisition determining unit (2d). The blood flow increasing unit (2a) increases blood flow of an object person. The biometric information acquiring unit (2b) acquires the biometric information from the object person. The feature amount evaluating unit (2c) evaluates the feature amount of the acquired biometric information. The reacquisition determining unit (2d) determines whether to cause the blood flow increasing unit (2a) to operate and then cause the biometric information acquiring unit (2b) to reacquire the biometric information when the evaluated feature amount does not reach a predetermined threshold.<img id="iaf01" file="imgaf001.tif" wi="165" he="94" img-content="drawing" img-format="tif"/></p></abstract><abstract mxw-id="PA128499430" lang="EN" source="EPO" load-source="docdb"><p>To adequately acquire biometric information even when a feature amount of the biometric information may vary by a variety of factors.  A biometric information acquisition apparatus (1) acquires biometric information to be used for verification. The biometric information acquisition apparatus (1) includes a blood flow increasing unit (2a), a biometric information acquiring unit (2b), a feature amount evaluating unit (2c), and a reacquisition determining unit (2d). The blood flow increasing unit (2a) increases blood flow of an object person. The biometric information acquiring unit (2b) acquires the biometric information from the object person. The feature amount evaluating unit (2c) evaluates the feature amount of the acquired biometric information. The reacquisition determining unit (2d) determines whether to cause the blood flow increasing unit (2a) to operate and then cause the biometric information acquiring unit (2b) to reacquire the biometric information when the evaluated feature amount does not reach a predetermined threshold.</p></abstract><description mxw-id="PDES63955487" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><heading id="h0001">Technical Field</heading><p id="p0001" num="0001">The embodiments discussed herein are related to biometric information acquisition apparatus and method for acquiring biometric information.</p><heading id="h0002">Background Art</heading><p id="p0002" num="0002">The human body has biometric information allowing an individual person to be positively identified. Some of this information is used to identify and authenticate individuals. Known biometrics for person authentication include those based on, for example, fingerprints, eye retina and iris patterns, facial characteristics, blood vessel patterns, and DNA (deoxyribonucleic acid).</p><p id="p0003" num="0003">Led by the development of biometric authentication technology in recent years, a great variety of apparatuses for recognizing body features of such human body parts and authenticating individuals have been offered. Biometric authentication is achieved by comparing biometric information collected upon registration (also referred to as a registered template) against biometric information newly acquired during the authentication.</p><p id="p0004" num="0004">In order to improve accuracy of biometric<!-- EPO <DP n="2"> --> authentication using such biometric information, it is preferable to acquire biometric information with a certain degree of accuracy in each authentication attempt. However, a user which is an authentication object does not always assume a proper posture in the authentication process. In view of this, there is proposed a biometric information matching apparatus capable of evaluating a feature amount of biometric information and, then, prompting a user for re-entry to acquire biometric information of good quality if the feature amount is evaluated to be insufficient (see, for example, Patent Literature 1).</p><heading id="h0003">Citation List</heading><heading id="h0004">Patent Literature</heading><p id="p0005" num="0005"><ul><li>PTL1: Japanese Laid-open Patent Publication No. <patcit id="pcit0001" dnum="JP2007172022A"><text>2007-172022</text></patcit></li></ul></p><heading id="h0005">Summary of Invention</heading><heading id="h0006">Technical Problem</heading><p id="p0006" num="0006">However, the feature amount included in the acquired biometric information varies among different individuals, and re-entry prompt does not always improve the feature amount immediately. In addition, reacquisition of biometric information does not lead to an improvement of the feature amount to be captured once a user has familiarized himself or herself, to a certain extent, with the procedure involved in the authentication process.<!-- EPO <DP n="3"> --> Repeating re-entry prompt in spite of such a situation would deny a posture recognized by the user to be proper.</p><p id="p0007" num="0007">Especially, the aforementioned problem becomes much more pronounced in the case where the feature amount of biometric information to be acquired may vary by a variety of factors, such as a surrounding environment and a physical condition of the user.</p><p id="p0008" num="0008">In view of the above-described problem, the embodiments aim at providing biometric information acquisition apparatus and method capable of adequately acquiring biometric information even when the feature amount of the biometric information may vary by a variety of factors.</p><heading id="h0007">Solution to Problem</heading><p id="p0009" num="0009">In order to solve the above-described problem, there is provided a biometric information acquisition apparatus including a blood flow increasing unit, a biometric information acquiring unit, a feature amount evaluating unit, and a reacquisition determining unit. The blood flow increasing unit increases an amount of blood flow of an object person. The biometric information acquiring unit acquires, from the object person, biometric information whose feature amount is to be increased due to an increase in the amount of blood flow. The feature amount evaluating unit evaluates the feature amount of the biometric information acquired by the biometric information<!-- EPO <DP n="4"> --> acquiring unit. The reacquisition determining unit determines whether to cause the blood flow increasing unit to operate and then cause the biometric information acquiring unit to reacquire the biometric information when the feature amount evaluated by the feature amount evaluating unit does not reach a predetermined threshold.</p><p id="p0010" num="0010">In order to solve the above-described problem, there is also provided a biometric information acquisition method including acquiring, from an object person, biometric information whose feature amount is to be increased due to an increase in an amount of blood flow of the object person; evaluating the feature amount of the acquired biometric information; and increasing the amount of blood flow in a biometric information acquisition region from which the biometric information of the object person is acquired and reacquiring the biometric information from the biometric information acquisition region when the evaluated feature amount does not reach a predetermined threshold.</p><heading id="h0008">Advantageous Effects of Invention</heading><p id="p0011" num="0011">The aforementioned biometric information acquisition apparatus and method enable adequate acquisition of biometric information even when the feature amount of the biometric information may vary by a variety of factors.</p><p id="p0012" num="0012">These and other objects, features and advantages<!-- EPO <DP n="5"> --> of the present invention become apparent from the following detailed description of illustrative embodiments thereof, which is to be read in connection with the accompanying drawings.</p><heading id="h0009">Brief Description of Drawings</heading><p id="p0013" num="0013"><ul><li>[<figref idrefs="f0001">FIG. 1] FIG. 1</figref> illustrates a configuration of a biometric information acquisition apparatus according to a first embodiment.</li><li>[<figref idrefs="f0002">FIG. 2] FIG. 2</figref> illustrates a configuration of an authentication system according to a second embodiment.</li><li>[<figref idrefs="f0003">FIG. 3] FIG. 3</figref> illustrates a configuration of a registration apparatus according to the second embodiment.</li><li>[<figref idrefs="f0004">FIG. 4] FIG. 4</figref> illustrates a hardware configuration example of the registration apparatus according to the second embodiment.</li><li>[<figref idrefs="f0005">FIG. 5] FIG. 5</figref> illustrates an overview of a sensor unit according to the second embodiment.</li><li>[<figref idrefs="f0006">FIG. 6] FIG. 6</figref> illustrates a configuration of the sensor unit according to the second embodiment.</li><li>[<figref idrefs="f0007">FIG. 7] FIG. 7</figref> illustrates observed examples of palmar surface temperature distribution according to the second embodiment.</li><li>[<figref idrefs="f0008">FIG. 8] FIG. 8</figref> illustrates a flowchart of a biometric information acquiring process according to the second embodiment.</li><li>[<figref idrefs="f0009">FIG. 9] FIG. 9</figref> illustrates a flowchart of a<!-- EPO <DP n="6"> --> feature amount evaluating process according to the second embodiment.</li><li>[<figref idrefs="f0010">FIG. 10] FIG. 10</figref> illustrates a flowchart of a blood flow increasing process according to the second embodiment.</li><li>[<figref idrefs="f0011">FIG. 11] FIG. 11</figref> illustrates examples of vein images each having a different feature amount according to the second embodiment.</li><li>[<figref idrefs="f0012">FIG. 12] FIG. 12</figref> illustrates examples of feature data sets extracted from the corresponding vein images according to the second embodiment.</li><li>[<figref idrefs="f0013">FIG. 13] FIG. 13</figref> illustrates an example of feature amount evaluation results according to the second embodiment.</li><li>[<figref idrefs="f0014">FIG. 14] FIG. 14</figref> illustrates examples of registered templates according to the second embodiment.</li><li>[<figref idrefs="f0015">FIG. 15] FIG. 15</figref> illustrates an overview of an automated teller machine according to the second embodiment.</li><li>[<figref idrefs="f0016">FIG. 16] FIG. 16</figref> illustrates a configuration of an authentication system according to a third embodiment.</li><li>[<figref idrefs="f0017">FIG. 17] FIG. 17</figref> illustrates an overview of a sensor unit according to a fourth embodiment.</li><li>[<figref idrefs="f0018">FIG. 18] FIG. 18</figref> illustrates an example of registered templates according to a fifth embodiment.</li></ul></p><heading id="h0010">Description of Embodiments</heading><p id="p0014" num="0014">Several embodiments will be described below with<!-- EPO <DP n="7"> --> reference to the accompanying drawings.</p><heading id="h0011">First Embodiment</heading><p id="p0015" num="0015">A biometric information acquisition apparatus according to a first embodiment is described first with reference to <figref idrefs="f0001">FIG. 1. FIG. 1</figref> illustrates a configuration of a biometric information acquisition apparatus according to the first embodiment.</p><p id="p0016" num="0016">A biometric information acquisition apparatus 1 is configured to acquire, from a living body, biometric information whose feature amount (i.e., amount of feature information) is altered by a change in blood flow. Examples of such biometrics include those based on vein patterns near the body surface, such as a palm vein pattern and a finger vein pattern. In addition, the temperature of the body surface and the amount of perspiration are also examples of such biometric information.</p><p id="p0017" num="0017">The biometric information acquisition apparatus 1 may be configured as a stand-alone apparatus separate from an authentication apparatus for identity authentication using biometric information and a registration apparatus for registering biometric information (templates) used by the authentication apparatus for matching purposes, or may be configured as part of these apparatuses.</p><p id="p0018" num="0018">The biometric information acquisition apparatus 1 includes a blood flow increasing unit 2a, a biometric information acquiring unit 2b, a feature amount evaluating unit 2c, and a reacquisition determining unit 2d. The<!-- EPO <DP n="8"> --> blood flow increasing unit 2a increases the blood flow of an object person. For example, in the case where biometric information to be acquired is a palm vein pattern, the blood flow increasing unit 2a warms a palm of the object person to increase blood flow. The biometric information acquiring unit 2b acquires, from the object person, biometric information whose feature amount is to be increased due to an increase in the blood flow. The feature amount evaluating unit 2c evaluates the feature amount of the biometric information acquired by the biometric information acquiring unit 2b. The reacquisition determining unit 2d determines whether to cause the blood flow increasing unit 2a to operate and then cause the biometric information acquiring unit 2b to reacquire the biometric information in the case where the feature amount evaluated by the feature amount evaluating unit 2c does not reach a predetermined threshold.</p><p id="p0019" num="0019">The term "feature amount" as used herein means the amount of significant information (feature information) allowing, among records of biometric information, identification determination (matching) of biometric information records extracted from the same person. In the case of, for example, a palm vein pattern, the feature information may be minutiae points in the vein pattern (ending points and bifurcation points of veins), the number of veins intersected by a straight line drawn between a minutiae point and an adjacent minutiae point, or a small<!-- EPO <DP n="9"> --> partial image around a minutiae point.</p><p id="p0020" num="0020">The amount of such feature information varies from person to person, and some people present a high amount of feature information while others present a low amount of feature information. A person with a high amount of feature information tends to maintain high authentication accuracy, but a person with a low amount of feature information tends to be troubled by unstable authentication accuracy. In addition, the feature amount extracted from the same individual may be affected and vary by changes in the environment. The blood flow increasing unit 2a increases blood flow of the object person to thereby increase the amount of feature information to be acquired.</p><p id="p0021" num="0021">For example, a vein pattern acquired from a user (object person) with reduced blood flow caused by blood vessel constriction on a cold day includes a very low feature amount. In such a case, the blood flow increasing unit 2a warms a palm of the object person, for example, by a hot-air heater, which increases blood flow of the object person, in turn increasing the feature amount to be included in the vein pattern. The biometric information having the increased feature amount due to the increase in blood flow is acquired by the biometric information acquiring unit 2b from the object person.</p><p id="p0022" num="0022">As described above, even when the feature amount to be acquired may vary by a variety of factors, the biometric information acquisition apparatus 1 increases<!-- EPO <DP n="10"> --> blood flow of an object person if biometric information including a very low feature amount has been acquired from the object person, to thereby acquire the biometric information with an increase feature amount. In addition, the biometric information acquisition apparatus 1 reduces incidence of repeatedly imposing re-entry of the biometric information on the user as a result of a verification failure, contributing to controlling a reduction in the level of convenience for the user. An authentication process using the biometric information acquired in this manner is expected to achieve stably high authentication accuracy.</p><p id="p0023" num="0023">Next, a detailed description is given using a second embodiment.</p><heading id="h0012">Second Embodiment</heading><p id="p0024" num="0024"><figref idrefs="f0002">FIG. 2</figref> illustrates a configuration of an authentication system according to a second embodiment. The second embodiment represents an authentication system 5 using veins in a palm for authentication, however, the embodiment is also applicable to a system utilizing a body feature other than palm veins for authentication as long as the feature amount of the body feature is altered by a change in the amount of blood flow.</p><p id="p0025" num="0025">The authentication system 5 is a type of system for recognizing features of a living body to thereby identify and authenticate an individual, and is used, for example, for client authentication in a banking system.<!-- EPO <DP n="11"> --> The authentication system 5 includes a registration apparatus 20, multiple automated teller machines (ATM) 30, an authentication server 6, and a network 9.</p><p id="p0026" num="0026">The authentication server 6 stores, in association with each other, identification information for identifying each individual and verification information (template) registered in advance prior to biometric authentication. The identification information is a unique identification (ID) assigned directly (e.g., a user number) or indirectly (e.g., an account number) to a user. The verification information is, for example, feature information extracted from image information in relation to features by a predetermined feature extraction algorithm, or encoded information generated by encoding the image information or the feature information.</p><p id="p0027" num="0027">One or more automated teller machines 30 are installed in an ATM area 7 located inside a financial institution and an ATM booth 8. The automated teller machines 30 are authentication apparatuses used for biometric authentication to authenticate a user prior to a financial transaction. Each of the automated teller machines 30 includes an integrated circuit (IC) card reader/writer 31 and a sensor unit 50. The sensor unit 50 includes an image pickup device to take an image of palm veins of the user. The automated teller machine 30 authenticates the user based on verification information and biometric information of the user. The verification<!-- EPO <DP n="12"> --> information is identified from identification information read by the IC card reader/writer 31 from an IC card (for example, a cash card having an IC chip mounted thereon) of the user. The biometric information of the user is acquired from the sensor unit 50. The sensor unit 50 is a biometric information acquisition apparatus for acquiring biometric information, and the automated teller machine 30 is an authentication apparatus including the biometric information acquisition apparatus.</p><p id="p0028" num="0028">The registration apparatus 20 is installed at a bank counter or the like, and used for registering a template of each user according to instructions or operations of a bank teller. The registration apparatus 20 includes a processor 21, a display 22, and the sensor unit 50, and may further include a keyboard 23, a mouse 24, and an IC card reader/writer 25 if needed. The sensor unit 50 includes a built-in image pickup device to capture an image of a palm of the user, which image is output to the processor 21. The IC card reader/writer 25 reads and writes information from and to an IC card 26 of the user. The keyboard 23 and the mouse 24 individually accept input operations.</p><p id="p0029" num="0029">Next described is template registration (registration of verification information) using the registration apparatus 20. A user calling for template registration enters identification information for identifying the user (for example, a user identification)<!-- EPO <DP n="13"> --> using the keyboard 23, the mouse 24, or the IC card reader/writer 25. The registration apparatus 20 introduces the user to template registration procedures using a screen of the display 22 and prompts the user to enter biometric information for the template registration. The user enters biometric information by laying a hand over the sensor unit 50. The registration apparatus 20 into which an image of palm veins has been entered as biometric information creates verification information from the entered information and stores the verification information in at least one of a storage section of the processor 21, a storage section of the authentication server 6, and a storage section on the IC card 26 of the user. To carry out biometric authentication, the automated teller machine 30 makes an inquiry to the storage section of the authentication server 6 or the IC card 26 for a corresponding template and compares the entered biometric information against the template.</p><p id="p0030" num="0030">Next described is a configuration of the registration apparatus 20 of the second embodiment for achieving the template registration process, with reference to <figref idrefs="f0003">FIG. 3. FIG. 3</figref> illustrates a configuration of a registration apparatus according to the second embodiment. The registration apparatus 20 includes a control unit 200, a storage unit 201, an informing unit 202, and a communicating unit 203. In addition, the registration apparatus 20 further includes an image inputting unit 204,<!-- EPO <DP n="14"> --> a blood flow increasing unit 205, a blood flow amount evaluating unit 206, a feature amount evaluating unit 207, a reacquisition determining unit 208, and a template registration unit 209.</p><p id="p0031" num="0031">The control unit 200 exerts overall control over individual processing units to authenticate a user. The storage unit 201 stores and holds therein image information acquired from the sensor unit 50 and various databases. The informing unit 202 generates display messages needed, for example, to provide the user with guidance for the action of laying a hand over the sensor unit 50 and to inform the user of the temperature of the palm, the success or failure of the verification and the like, and then presents such a message on the display 22. The informing unit 202 also generates a needed audio message and audio-outputs the message using speakers (not illustrated). The communicating unit 203 communicates individually with the sensor unit 50, an IC chip built in the IC card reader/writer 25, and a computer connected to the network 9.</p><p id="p0032" num="0032">The image inputting unit 204 inputs a captured image of a living body part from the sensor unit 50. More specifically, upon inputting therein the captured image, the image inputting unit 204 extracts an object by deleting the background from the image and, then, determines whether the extracted object is a palm. If determining that the object is not a palm, the image inputting unit 204 inputs a captured image of a living body part once again from the<!-- EPO <DP n="15"> --> sensor unit 50. On the other hand, if determining that the object is a palm, the image inputting unit 204 crops the palm (fingers and wrist may be included) from the captured image, and provides position correction of the cropped palm in terms of the position (position correction in the front-back and left-right directions), the size (height correction in the up-down direction), and the orientation (rotation correction).</p><p id="p0033" num="0033">The blood flow increasing unit 205 increases blood flow in a region from which biometric information is acquired (i.e., a palm of the user). For example, the blood flow increasing unit 205 includes a warming unit which warms the palm to thereby improve the flow of blood, in turn increasing blood flow. In addition, the blood flow increasing unit 205 includes a posture changing unit which changes the posture of the palm to thereby improve the flow of blood, in turn increasing blood flow. Further, the blood flow increasing unit 205 includes a vibrating unit which applies a stimulus to the palm to thereby improve the flow of blood, in turn increasing blood flow. The blood flow increasing unit 205 increases blood flow in the palm using one of the warming unit, the posture changing unit, and the vibrating unit, or any combination of these units. Note that the blood flow increasing unit 205 may be configured to trigger the user's vision, hearing or other senses rather than the above-mentioned somatic senses as long as the sense has a causal connection with an increase<!-- EPO <DP n="16"> --> in blood flow. In this case, the blood flow increasing unit 205 increases blood flow, for example, by presenting a predetermined image on the display 22 to stimulate vision of the user or by outputting predetermined audio content from speakers to stimulate his or her hearing. Because a blood flow increasing effect is generally a vasodilatory effect, the blood flow increasing unit 205 may stimulate the user's parasympathetic nervous system that has a vasodilatory effect.</p><p id="p0034" num="0034">The blood flow amount evaluating unit 206 evaluates the amount of blood flow in the region from which biometric information is acquired (i.e., a palm of the user). For example, the blood flow amount evaluating unit 206 includes a temperature measuring unit which evaluates the amount of blood flow based on the temperature of the palm. More specifically, the blood flow amount evaluating unit 206 detects a rise in body temperature, based on which an increase in blood flow in the region for the biometric information acquisition is evaluated.</p><p id="p0035" num="0035">The feature amount evaluating unit 207 evaluates a feature amount included in the biometric information based on the captured image. More specifically, the feature amount evaluating unit 207 evaluates a vein pattern in the palm image or the amount of feature information included in the vein pattern. The feature information may be minutiae points in the vein pattern (ending points and bifurcation points of veins), the number of veins intersected by a line<!-- EPO <DP n="17"> --> drawn between a minutiae point and an adjacent minutiae point, or a small partial image around a minutiae point. The amount of feature information is a quantified representation of the number or quality of the feature information obtained by a predetermined evaluation algorithm. A higher amount of feature information results in authentication with stable accuracy while a lower amount of feature information leads to authentication with less stable accuracy. A simplified example of the amount of feature information is the sum of the count of minutiae points and the number of veins intersected by a line drawn between a minutiae point and an adjacent minutiae point. Note that the evaluation of the feature amount by the feature amount evaluating unit 207 may be represented by an evaluation value (for example, a numerical value such as 100 and 200), or a score on an evaluation scale denoting the quantity of the feature amount based on predetermined thresholds (for example, a score on a scale of "high", "moderate", and "low").</p><p id="p0036" num="0036">The reacquisition determining unit 208 determines need of reacquiring the biometric information based on the evaluation of the feature amount. If the feature amount of the acquired biometric information is evaluated to be insufficient, the reacquisition determining unit 208 determines reacquisition of the biometric information, that is, re-entry of an image.</p><p id="p0037" num="0037">The template registration unit 209 processes the<!-- EPO <DP n="18"> --> extracted image information to be a registration template, and records (registers) the registration template in the storage section of the processor 21, the storage section of the authentication server 6, or the storage section on the IC card 26 of the user.</p><p id="p0038" num="0038">Note that the registration apparatus 20 increases blood flow in the region for the biometric information acquisition for the purpose of increasing the feature amount included in the biometric information of the template registration target. On the other hand, an authentication apparatus does the same for the purpose of increasing the feature amount included in biometric information of a verification target. Therefore, the authentication apparatus may have the same configuration as the registration apparatus, except for the template registration unit 209 which is replaced with a verifying unit. The verifying unit carries out biometric verification by comparing biometric information extracted from a captured image input by the image inputting unit 204 against a registration template registered in advance.</p><p id="p0039" num="0039">Next described is a hardware configuration example of the registration apparatus 20 according to the second embodiment, with reference to <figref idrefs="f0004">FIG. 4. FIG. 4</figref> illustrates a hardware configuration example of a registration apparatus according to the second embodiment.</p><p id="p0040" num="0040">The registration apparatus 20 includes the processor 21, the display 22, the keyboard 23, the mouse 24,<!-- EPO <DP n="19"> --> the sensor unit 50, and the IC card reader/writer 25.</p><p id="p0041" num="0041">The whole processor 21 is controlled by a central processing unit (CPU) 101. To the CPU 101, the following devices are connected via a bus 107: a random access memory (RAM) 102; a hard disk drive (HDD) 103; a communication interface 104; a graphic processor 105; and an input/output interface 106.</p><p id="p0042" num="0042">The RAM 102 temporarily stores therein at least part of an operating system program and application programs to be executed by the CPU 101. The RAM 102 also stores various types of data needed by the CPU 101 for its processing. The HDD 103 stores the operating system program and the application programs.</p><p id="p0043" num="0043">To the graphic processor 105, the display 22 is connected. The graphic processor 105 causes the display 22 to present an image on its screen according to an instruction of the CPU 101.</p><p id="p0044" num="0044">To the input/output interface 106, the keyboard 23, the mouse 24, the sensor unit 50, and the IC card reader/write 25 are connected. In addition, the input/output interface 106 is configured to be connected to a portable recording medium interface allowing information to be written and read to and from a portable recording medium 110. The input/output interface 106 transmits signals individually sent from the keyboard 23, the mouse 24, the sensor unit 50, the IC card reader/writer 25, the portable recording medium interface to the CPU 101 via the<!-- EPO <DP n="20"> --> bus 107.</p><p id="p0045" num="0045">The communication interface 104 is connected to the network 9. The communication interface 104 transmits and receives data to and from another computer (for example, the authentication server 6).</p><p id="p0046" num="0046">The hardware configuration described above achieves the processing functions of this embodiment. Note that the authentication server 6 and the automated teller machine 30 may individually have the same hardware configuration.</p><p id="p0047" num="0047">Note that the processor 21 may include modules each composed of a field programmable gate array (FPGA), a digital signal processer (DSP) or the like, and may not include the CPU 101. In such a case, the processor 21 includes a nonvolatile memory (for example, an electrically erasable and programmable read-only memory (EEPROM), a flash memory, or a flash memory card), in which firmware of the modules is stored. The firmware may be written to the nonvolatile memory via the portable recording medium 110 or the communication interface 104. Thus, the processor 21 is able to update firmware by rewriting the firmware stored in the nonvolatile memory.</p><p id="p0048" num="0048">Next is described an overview of the sensor unit 50 according to the second embodiment, with reference to <figref idrefs="f0005">FIG. 5. FIG. 5</figref> illustrates an overview of a sensor unit according to the second embodiment. The sensor unit 50 has a form in which a boxy case 58 with an open top is<!-- EPO <DP n="21"> --> supported by a case supporting part 59 functioning as a base. The case 58 includes a wrist supporting part 60 for supporting a wrist of the user, a finger supporting part 63 for supporting fingers, and thumb/little-finger hill supporting parts 61 and 65 for supporting a thumb hill or a little finger hill. The wrist supporting part 60, the finger supporting part 63, the thumb/little-finger hill supporting parts 61 and 65 form four sides of the open top of the case 58 to provide good support for a palm of the user. In addition, the wrist supporting part 60 has a substantially U-shape configuration to support the wrist of the user in a correct posture. The finger supporting part 63 has a wave shape with two crests to support the index, third, and fourth fingers individually in their correct positions. Each of the thumb/little-finger hill supporting parts 61 and 65 has a concave shape with a curved surface to support the thumb hill or the little finger hill. With these supporting parts, the sensor unit 50 supports the palm in a correct position.</p><p id="p0049" num="0049">The boxy case 58 has a sensing part 68 and a warm air outlet part 67 on its bottom surface. The sensing part 68 includes a first image sensor (for example, a complementary metal-oxide semiconductor (CMOS) sensor, or a charge-coupled device (CCD) sensor) for capturing an image of a living body part, a condenser lens, multiple near-infrared light emitting devices (light emitting diodes (LED)) irradiating an object, and a second image sensor for<!-- EPO <DP n="22"> --> capturing an image of temperature distribution of the living body part. The near-infrared light emitting devices emit near-infrared light in the direction of the object (i.e., the upper direction).</p><p id="p0050" num="0050">The warm air outlet part 67 includes a heater and a fan and blows out warm air toward the open top. As the heater, a nichrome wire coil, for example, is used. Alternatively, heaters may be provided in the parts with which the hand comes in contact, that is, the wrist supporting part 60, the finger supporting part 63, and the thumb/little-finger hill supporting parts 61 and 65, to thereby warm the contact areas of the hand. Further, a heater may be provided on the internal wall surface forming an interior recess 64 to warm the inside of the interior recess. The internal warm air is prevented by the interior recess 64 from diffusing and efficiently warms the palm of the user.</p><p id="p0051" num="0051">Next described are functions provided for the sensor unit 50 according to the second embodiment, with reference to <figref idrefs="f0006">FIGS. 6</figref> and <figref idrefs="f0007">7</figref>. <figref idrefs="f0006">FIG. 6</figref> illustrates a configuration of a sensor unit according to the second embodiment. <figref idrefs="f0007">FIG. 7</figref> illustrates observed examples of palmar surface temperature distribution according to the second embodiment.</p><p id="p0052" num="0052">The sensor unit 50 includes a control unit 51, a near-infrared image capturing unit 52, an infrared image capturing unit 53, a driving unit 54, a ranging unit 55, a<!-- EPO <DP n="23"> --> storing unit 56, and a communicating unit 57.</p><p id="p0053" num="0053">The control unit 51 exerts overall control over individual processing units. The near-infrared image capturing unit (the first image sensor) 52 acquires image information from an object, that is a targeted living body part. The near-infrared image capturing unit 52 is able to continuously shoot the object, achieving continuous shooting of, for example, 15 frames per second. Note that the setting of the shooting speed may be changed. Alternatively, the shooting timing may be determined not according to time, but according to distance from the object obtained based on an output of the ranging unit 55. Note that the near-infrared image capturing unit 52 is configured suitable to capture an image of palm veins, and in the case of capturing an image of a tip of a finger or a different living body part, a configuration suitable for the object may be adopted.</p><p id="p0054" num="0054">The near-infrared image capturing unit 52 captures near-infrared light reflected from the object, i.e., the living body part (palm), to form an image. Since hemoglobin in red blood cells flowing through veins has lost oxygen, the hemoglobin (reduced hemoglobin) has the property of absorbing light in a near-infrared range of around 700 nm to around 1000 nm. Therefore, when near-infrared light hits a palm, less reflection is observed in areas where veins are located, and thus, it is possible to recognize the location of veins based on the intensity of<!-- EPO <DP n="24"> --> the reflected near-infrared light. Images captured by the near-infrared image capturing unit 52 are achromatic, and the use of a specific light sauce facilitates extraction of characteristic information.</p><p id="p0055" num="0055">The infrared image capturing unit 53 captures an image of temperature distribution of the palm at an infrared wavelength (in general, in the range of 7.5 µm to 13 µm). Therefore, the infrared image capturing unit 53 has a function of measuring the temperature of the region from which biometric information is acquired. The temperature distribution of a palm captured in the image is not only used to evaluate the amount of blood flow, but also presented on the display 22. For example, the display 22 presents temperature distribution of the palm using thermograph screens starting with a thermograph screen 90 (refer to <figref idrefs="f0007">FIG. 7(1)</figref>) and ending with a thermograph screen 91 (<figref idrefs="f0007">FIG. 7(2)</figref>). Such temperature distribution enables understanding of whether the temperature of the palm is sufficient or not. In addition, the temperature transition enables understanding of whether the temperature of the palm has been increased and, correspondingly, blood flow has been increased.</p><p id="p0056" num="0056">The driving unit 54 powers up the heater and drives the fan. That is, the driving unit 54 functions as a warming unit to warm a palm by delivering warm air to the palm.</p><p id="p0057" num="0057">The ranging unit 55 measures the distance from a<!-- EPO <DP n="25"> --> living body part being the object. The measured distance is used to determine shooting timing. The storing unit 56 stores therein image information acquired by the near-infrared image capturing unit 52. The communication unit 57 is connected to the communicating unit 203 of the registration apparatus 20 to thereby receive an instruction from the registration apparatus 20 and transmit image information and the like to the registration apparatus 20.</p><p id="p0058" num="0058">In the above-described manner, the sensor unit 50 warms a region from which biometric information is acquired, i.e., a palm of a user, to cause palm veins to dilate and increase blood flow. As a result, the near-infrared image capturing unit 52 captures an image of veins with the increased blood flow and, subsequently, the sensor unit 50 outputs a captured image with an increased feature amount.</p><p id="p0059" num="0059">In addition, the sensor unit 50 being provided with the infrared image capturing unit 53 allows the registration apparatus 20 to present temperature distribution of the palm on the display 22. The display of transition of the palm temperature distribution gives a justified reason to the user for waiting until the temperature of the palm has increased. Displaying model palm temperature distribution together with the palm temperature distribution of the user is likely to further reduce the user's frustration with the waiting time.</p><p id="p0060" num="0060">Note that the degree of warmth of a palm, that is, the degree of the increase in blood flow may be determined<!-- EPO <DP n="26"> --> to be sufficient if the temperature distribution satisfies a predetermined criterion (for example, 36 degrees Celsius or more over 80% or more of the surface area of the palm). In addition, the predetermined criterion may be a temperature rise from the start of the warming up, a temperature rise range, the rate of the temperature rise, or some combination of the above.</p><p id="p0061" num="0061">A biometric information acquiring process implemented by the processor 21 according to the second embodiment is next described in detail with reference to <figref idrefs="f0008">FIG. 8. FIG. 8</figref> illustrates a flowchart of a biometric information acquiring process according to the second embodiment. In template registration, the processor 21 acquires biometric information to be registered as a template. At this point, the processor 21 implements the biometric information acquiring process to thereby acquire biometric information.</p><p id="p0062" num="0062">[Step S11] The processor 21 (the image inputting unit 204) makes a request to the sensor unit 50 for an image, in which palm veins are captured (captured image), to be used for template registration. The sensor unit 50 responds to the processor 21 with a captured image of a palm. The processor 21 acquires the captured image from the sensor unit 50.</p><p id="p0063" num="0063">[Step S12] The processor 21 (the feature amount evaluating unit 207) extracts vein data from the captured image by predetermined image processing.<!-- EPO <DP n="27"> --></p><p id="p0064" num="0064">[Step S13] The processor 21 (the feature amount evaluating unit 207) generates feature data from the extracted vein data.</p><p id="p0065" num="0065">[Step S14] The processor 21 (the feature amount evaluating unit 207) implements a feature amount evaluating process for evaluating a feature amount included in the generated feature data. The details of the feature amount evaluating process are described later with reference to <figref idrefs="f0009">FIG. 9</figref>.</p><p id="p0066" num="0066">[Step S15] The processor 21 (the reacquisition determining unit 208) determines whether the feature amount included in the feature data is sufficient. The determination is made by comparing the feature amount with one or more predetermined thresholds. The processor 21 (the reacquisition determining unit 208) proceeds to step S16 if the feature amount is insufficient, and ends the biometric information acquiring process if the feature amount is sufficient.</p><p id="p0067" num="0067">[Step S16] The processor 21 (the informing unit 202) informs a user of a retake of a palm vein image. The processor 21 (the informing unit 202) also informs the user of a palm warming treatment to be provided. Further, the processor 21 (the informing unit 202) informs the user of the current status of the palm temperature distribution.</p><p id="p0068" num="0068">[Step S17] The processor 21 (the blood flow increasing unit 205) implements a blood flow increasing process for increasing blood flow in the palm (the region<!-- EPO <DP n="28"> --> from which biometric information is acquired) and, subsequently, returns to step S11 after the end of the process implementation in order to take a palm vein image once again. The details of the blood flow increasing process are described later with reference to <figref idrefs="f0010">FIG. 10</figref>.</p><p id="p0069" num="0069">In this manner, the registration apparatus 20 acquires biometric information having a predetermined feature amount, which improves quality of the registration template and contributes to an improvement in authentication accuracy. Although the above description is directed to the case where, in template registration, the registration apparatus 20 acquires biometric information to be registered as a template, the same process may be used by an authentication apparatus (for example, the automated teller machine 30) to acquire biometric information in each authentication attempt.</p><p id="p0070" num="0070">The feature amount evaluating process implemented by the feature amount evaluating unit 207 according to the second embodiment is next described in detail with reference to <figref idrefs="f0009">FIG. 9. FIG. 9</figref> illustrates a flowchart of a feature amount evaluating process according to the second embodiment. The feature amount evaluating process is carried out in step S14 of the biometric information acquiring process.</p><p id="p0071" num="0071">[Step S21] The feature amount evaluating unit 207 obtains a feature amount included in the feature data by quantifying the number or quality of feature information<!-- EPO <DP n="29"> --> using a predetermined evaluation algorithm.</p><p id="p0072" num="0072">[Step S22] The feature amount evaluating unit 207 determines whether the calculated feature amount is equal to or more than a first threshold. The feature amount evaluating unit 207 proceeds to step S24 if the feature amount is equal to or more than the first threshold, and proceeds to step S23 if not.</p><p id="p0073" num="0073">[Step S23] The feature amount evaluating unit 207 evaluates that the calculated feature amount is "too low". Since the biometric information whose feature amount is evaluated as being "too low" is not able to guarantee a predetermined authentication accuracy, the feature amount is determined to be insufficient in step S15 of the biometric information acquiring process.</p><p id="p0074" num="0074">[Step S24] The feature amount evaluating unit 207 determines whether the calculated feature amount is equal to or more than a second threshold. The feature amount evaluating unit 207 proceeds to step S26 if the feature amount is equal to or more than the second threshold, and proceeds to step S25 if not.</p><p id="p0075" num="0075">[Step S25] The feature amount evaluating unit 207 evaluates that the calculated feature amount is "low". Since the biometric information whose feature amount is evaluated as being "low" may not be able to guarantee the predetermined authentication accuracy, the feature amount is determined to be insufficient in step S15 of the biometric information acquiring process. Note that the<!-- EPO <DP n="30"> --> biometric information whose feature amount is evaluated as being "low" may be accepted from the aspect of convenience after no improvement is observed in reacquisition of biometric information. That is, even when determined to be insufficient once in step S15 of the biometric information acquiring process, the calculated feature amount is not determined to be insufficient in succession.</p><p id="p0076" num="0076">[Step S26] The feature mount evaluating unit 207 determines whether the calculated feature amount is equal to or more than a third threshold. The feature amount evaluating unit 207 proceeds to step S28 if the feature amount is equal to or more than the third threshold, and proceeds to step S27 if not.</p><p id="p0077" num="0077">[Step S27] The feature amount evaluating unit 207 evaluates that the calculated feature amount is "moderate" and, then, ends the feature amount evaluating process. Since the biometric information whose feature amount is evaluated as being "moderate" is able to guarantee the predetermined authentication accuracy, the feature amount is determined to be not insufficient in step S15 of the biometric information acquiring process.</p><p id="p0078" num="0078">[Step S28] The feature amount evaluating unit 207 evaluates that the calculated feature amount is "high" and, then, ends the feature amount evaluating process. Since the biometric information whose feature amount is evaluated as being "high" is able to sufficiently guarantee the predetermined authentication accuracy, the feature amount<!-- EPO <DP n="31"> --> is determined to be not insufficient in step S15 of the biometric information acquiring process.</p><p id="p0079" num="0079">Thus, in the feature amount evaluating process, a feature amount is evaluated in multiple steps according to the magnitude of the feature amount. Note that the feature amount may be evaluated using a two-point scale of "suitable (high)" and "unsuitable (low)", a three-point scale of "optimal (high)", "suitable (moderate)", and "unsuitable (low)", or a scale with still more points.</p><p id="p0080" num="0080">The blood flow increasing process implemented by the blood flow increasing unit 205 according to the second embodiment is next described in detail with reference to <figref idrefs="f0010">FIG. 10. FIG. 10</figref> illustrates a flowchart of a blood flow increasing process according to the second embodiment. The blood flow increasing process is carried out in step S17 of the biometric information acquiring process.</p><p id="p0081" num="0081">[Step S31] The blood flow increasing unit 205 turns on the heater and fan of the warm air outlet part 67.</p><p id="p0082" num="0082">[Step S32] The blood flow increasing unit 205 monitors the palmar surface temperature based on the palm temperature distribution obtained by the infrared image capturing unit 53.</p><p id="p0083" num="0083">[Step S33] The blood flow increasing unit 205 determines whether a temperature rise with the temperature distribution satisfying a predetermined criterion (for example, 36 degrees Celsius or more over 80% or more of the surface area of the palm) is observed. The blood flow<!-- EPO <DP n="32"> --> increasing unit 205 proceeds to step S34 if a temperature rise satisfying the predetermined criterion is observed, and returns to step S32 if not and continues monitoring the palmar surface temperature.</p><p id="p0084" num="0084">[Step S34] The blood flow increasing unit 205 turns off the heater and fan of the warm air outlet part 67 and ends the blood flow increasing process.</p><p id="p0085" num="0085">In this manner, the blood flow increasing unit 205 warms a palm to increase the temperature of the palm, improving the flow of blood in the palm, that is, increasing blood flow in palm veins.</p><p id="p0086" num="0086">Next described are examples of acquired palm vein images and registered templates generated based on the palm vein images according to the second embodiment, with reference to <figref idrefs="f0011 f0012 f0013 f0014">FIGS. 11 to 14</figref>. <figref idrefs="f0011">FIG. 11</figref> illustrates examples of vein images each having a different feature amount according to the second embodiment. <figref idrefs="f0012">FIG. 12</figref> illustrates examples of feature data sets extracted from the corresponding vein images according to the second embodiment. <figref idrefs="f0013">FIG. 13</figref> illustrates an example of feature amount evaluation results according to the second embodiment. <figref idrefs="f0014">FIG. 14</figref> illustrates examples of registered templates according to the second embodiment.</p><p id="p0087" num="0087">The feature amount of a palm vein image (vein pattern) varies among different individuals and also varies according to the environment. A vein image 80 (see <figref idrefs="f0011">FIG. 11(1)</figref>) exhibits a relatively complex vein pattern including<!-- EPO <DP n="33"> --> many bifurcation points of veins and having a large amount of veins per unit area. Such a vein image 80 is evaluated as having a high feature amount. A vein image 81 (see <figref idrefs="f0011">FIG. 11(2)</figref>) exhibits a vein pattern with average complexity, including a moderate number of bifurcation points of veins and having a moderate amount of veins per unit area. Such a vein image 81 is evaluated as having a moderate feature amount. A vein image 82 (see <figref idrefs="f0011">FIG. 11(3)</figref>) exhibits a relatively simple vein pattern including a small number of bifurcation points of veins and having a small amount of veins per unit area. Such a vein image 82 is evaluated as having a low feature amount.</p><p id="p0088" num="0088">The vein image 80 evaluated as having a high feature amount is said to be less subject to environmental influences, providing sufficient authentication accuracy even under environmental changes such as seasonal variation in temperature and variation in the ambient temperature. In addition, such a vein image 80 is also said to be less subject to variation in the posture of the user, providing sufficient authentication accuracy even when there are postural changes such as a standing or seated position, a position of the arm, and a wrist angle relative to the heart.</p><p id="p0089" num="0089">On the other hand, the vein image 82 evaluated as having a low feature amount is said to be susceptible to environmental influences, providing poor authentication accuracy under subtle environmental changes. In addition,<!-- EPO <DP n="34"> --> such a vein image 82 is also said to be susceptible to variation in the posture of the user, providing poor authentication accuracy if there is a slight change in the posture.</p><p id="p0090" num="0090">The blood flow increasing unit 205 improves the vein image 82 evaluated as having a low feature amount to be one like the vein image 81 evaluated as having a moderate feature amount or the vein image 80 evaluated as having a high feature amount.</p><p id="p0091" num="0091">Each of the vein images 80, 81, and 82 is, for example, processed to generate a feature data set by binarizing corresponding image information with a 256-level gray scale, ranging from 0 to 255, into 0 and 255. A feature data set 83 (see <figref idrefs="f0012">FIG. 12(1)</figref>) is an example of feature data generated for a part of the vein image 80. A feature data set 84 (see <figref idrefs="f0012">FIG. 12(2)</figref>) is an example of feature data generated for a part of the vein image 81. A feature data set 85 (see <figref idrefs="f0012">FIG. 12(3)</figref>) is an example of feature data generated for a part of the vein image 82. The feature data sets 83, 84, and 85 are individually evaluated in terms of the feature amount, which results are presented as feature amount evaluation results 86 (see <figref idrefs="f0013">FIG. 13</figref>). The feature amount evaluation results 86 include the following entry items: the count of "0" included in each feature data set; a column component feature amount which is the count of sections with successive 0s in the column direction; a row component feature amount which is the<!-- EPO <DP n="35"> --> count of sections with two or more successive 0s in the row direction; and a total feature amount which is the sum of the column and row component feature amounts. In addition, the feature amount evaluation results 86 also include an entry item of evaluation which is a categorized result obtained by classifying a corresponding total feature amount into one of categories of "low", "moderate", and "high" based on predetermined thresholds (see the first to third thresholds in <figref idrefs="f0009">FIG. 9</figref>).</p><p id="p0092" num="0092">According to the feature amount evaluation results 86 of <figref idrefs="f0013">FIG. 13</figref>, as for evaluation example 1 representing an evaluation result of the feature data set 83, the count of "0" is "13", the column component feature amount is "4", the row component feature amount is "3", and the total feature amount is "7". Assuming here that the total feature amount "7" is equal to or more than the third threshold, the feature data set 83 is evaluated as having a "high" feature amount. As for evaluation example 2 representing an evaluation result of the feature data set 84, the count of "0" is "10", the column component feature amount is "2", the row component feature amount is "3", and the total feature amount is "5". Assuming here that the total feature amount "5" is equal to or more than the second threshold but less than the third threshold, the feature data set 84 is evaluated as having a "moderate" feature amount. As for evaluation example 3 representing an evaluation result of the feature data set 85, the count<!-- EPO <DP n="36"> --> of "0" is "8", the column component feature amount is "2", the row component feature amount is "1", and the total feature amount is "3". Assuming here that the total feature amount "3" is equal to or more than the first threshold but less than the second threshold, the feature data set 85 is evaluated as having a "low" feature amount.</p><p id="p0093" num="0093">Each of the feature data sets evaluated in this manner is associated with both a user identification for uniquely identifying a user and a feature amount evaluation, and registered as a template as illustrated in registered templates 87 (see <figref idrefs="f0014">FIG. 14</figref>). For example, a user with a user identification ID001 is associated with an evaluation result "moderate" and a feature data set DATA0012.</p><p id="p0094" num="0094">In addition, not only one but also multiple feature data sets may be associated with a single user identification. For example, a user with a user identification ID002 is associated with an evaluation result "high" and a feature data set DATA0021 as well as with an evaluation result "moderate" and a feature data set DATA0022.</p><p id="p0095" num="0095">Thus, in the case where multiple feature data sets each having a different evaluation result have been registered as templates, a template (feature data set) for verification may be selected according to surrounding environmental conditions causing changes in the amount of blood flow, such as seasons and temperature variations. Next is described an overview of the automated<!-- EPO <DP n="37"> --> teller machine 30 according to the second embodiment, with reference to <figref idrefs="f0015">FIG. 15. FIG. 15</figref> illustrates an overview of an automated teller machine according to the second embodiment.</p><p id="p0096" num="0096">The automated teller machine 30 includes the IC card reader/writer 31, a bankbook insertion port 32, a coin deposit and withdrawal port 33, a display and operation unit 34, a banknote deposit and withdrawal port 35, and the sensor unit 50. The IC card reader/writer 31 receives a cache card (IC card) and reads and writes information stored in the IC card. The bankbook insertion port 32 receives a bank book. The coin deposit and withdrawal port 33 is a deposit and withdrawal port for coins. The banknote deposit and withdrawal port 35 is a deposit and withdrawal port for banknotes. The display and operation unit 34 is an image display device with a touch panel function, serving as a display output unit as well as an operation input unit. The sensor unit 50 has a function as a biometric information acquiring unit for capturing biometric information of a user as well as a function as a blood flow increasing unit for increasing blood flow of the user.</p><p id="p0097" num="0097">The automated teller machine 30 is installed in the ATM area 7 or the ATM booth 8, and in many cases, a user visits the ATM area 7 or the ATM booth 8 from outdoors. Therefore, a palm of the user having been exposed to the outside air, for example, on a cold day may be experiencing<!-- EPO <DP n="38"> --> bad blood circulation. Even in such a case, the automated teller machine 30 ensures stable authentication using good biometric information having an increased feature amount because the biometric information of the user is captured after his or her blood flow has been increased. Such an automated teller machine 30 contributes to improving convenience for users and, also, offers improved operational efficiency by preventing repeated authentication failures. In addition, the automated teller machine 30 reduces the waiting time of the users.</p><heading id="h0013">Third Embodiment</heading><p id="p0098" num="0098">Next described is an authentication system according to a third embodiment. The authentication system according to the third embodiment is used to manage entrance and exit to and from a room. <figref idrefs="f0016">FIG. 16</figref> illustrates a configuration of an authentication system according to the third embodiment. The third embodiment represents an authentication system 10 using veins in a palm for authentication, however, the embodiment is also applicable to a system utilizing a body feature other than palm veins for authentication as long as the feature amount of the body feature is altered by a change in the amount of blood flow.</p><p id="p0099" num="0099">The authentication system 10 is a system configured to recognize features of a living body to thereby identify and authenticate an individual, and is used, for example, in an entrance and exit management<!-- EPO <DP n="39"> --> system to authenticate individuals entering and leaving a room. The authentication system 10 includes entrance and exit management apparatuses 120 and 130, an authentication server 11, and a network 12.</p><p id="p0100" num="0100">The authentication server 11 stores, in association with each other, identification information for identifying an individual and verification information (template) registered in advance prior to biometric authentication. The identification information is a unique identification assigned directly (e.g., a user number) or indirectly (e.g., a card number) to a user. The verification information is, for example, feature information extracted from image information in relation to features by a predetermined feature extraction algorithm, or encoded information generated by encoding the image information or the feature information.</p><p id="p0101" num="0101">The entrance and exit management apparatus 120 includes an authentication apparatus 121 and a door 125. The authentication apparatus 121 includes a numeric keypad 122, an IC card reader/writer 123, and a sensor unit 124. The numeric keypad 122 is used to enter a personal identification number in the case of concurrently using personal identification number authentication. The IC card reader/writer 123 reads and writes information from and to an IC card (not illustrated) of a user. The sensor unit 124 includes an image pickup device to capture an image of a palm of the user. The authentication apparatus 121<!-- EPO <DP n="40"> --> authenticates the user using a registered template stored in the IC card and the captured image and controls opening and closing of the door 125.</p><p id="p0102" num="0102">The sensor unit 124 is housed in an interior recess 124a. The interior recess 124a includes a built-in heater 124c. The heater 124c warms a space inside the interior recess 124a and a supporting part 124b for supporting a palm. When the user lays a hand over the sensor unit 124, the palm of the hand is warmed by warm air in the interior recess 124a and by the supporting part 124b. In this manner, the palm of the user is warmed, increasing blood flow in the palm.</p><p id="p0103" num="0103">The entrance and exit management apparatus 130 includes a flapper 132 and a sensor unit 131 for each gate. The sensor unit 131 includes an image pickup device to capture an image of a palm of the user. The entrance and exit management apparatus 130 authenticates the user using a registered template stored in the IC card and the captured image and controls opening and closing of the flapper 132.</p><p id="p0104" num="0104">The sensor unit 131 is provided on a height adjusting unit 133 for allowing the height of the sensor unit 131 to be adjusted. The sensor unit 131 is able to capture an image of a palm as changing the position in height of the palm. This changes the height of the palm of the user relative to his or her heart. Blood flow in the palm of the user reduces when the palm is at a higher<!-- EPO <DP n="41"> --> position relative to the heart and increases when it is at a lower position. Therefore, the height adjusting unit 133 lowers the height position of the sensor unit 131 and, in this manner, functions as a posture changing unit for changing the posture of the user to thereby increase blood flow in the palm of the user.</p><p id="p0105" num="0105">Note that the entrance and exit management apparatus 130 may be equipped with multiple gates for each of which the sensor unit 131 is installed at a different height, and guide a user whose blood flow is desired to be increased to a gate with the sensor unit 131 installed at a lower height.</p><p id="p0106" num="0106">Alternatively, the entrance and exit management apparatus 130 may be equipped with a single gate on which multiple sensor units 131 are installed at different heights, and guide a user whose blood flow is desired to be increased to use the sensor unit 131 installed at a lower height.</p><heading id="h0014">Fourth Embodiment</heading><p id="p0107" num="0107">Next is described an overview of a sensor unit according to a fourth embodiment. <figref idrefs="f0017">FIG. 17</figref> illustrates an overview of a sensor unit according to the fourth embodiment. The sensor unit of the fourth embodiment differs from that of the second embodiment in changing the angle of supporting a palm.</p><p id="p0108" num="0108">A sensor unit 140 includes a sensing unit 141, a sensing unit supporting part 142, a wrist supporting part<!-- EPO <DP n="42"> --> 143, a finger supporting part 144, and an angle adjusting part 145. The sensing unit 141 includes a first image sensor for capturing an image of a living body part, a condenser lens, multiple near-infrared light emitting devices irradiating an object, and a second image sensor for capturing an image of temperature distribution of the living body part. The near-infrared light emitting devices emit near-infrared light in the direction of the object (i.e., the upper direction). The sensing unit supporting part 142 supports the sensing unit 141. The wrist supporting part 143 has a substantially U-shape configuration to support the wrist of the user in a correct posture. The finger supporting part 144 has a wave shape with two crests to support the index, third, and fourth fingers individually in their correct positions. The angle adjusting part 145 changes the tilt of the sensing unit supporting part 142, the wrist supporting part 143, and the finger supporting part 144. The angle adjusting part 145 changes the angle, for example, to -15, 0, and 15 degrees to thereby enable a palm of a user to be tilted backward, kept in a horizontal position, and tilted forward, respectively.</p><p id="p0109" num="0109">Note that the angle adjusting part 145 changes the posture of the palm by changing the tilt of the sensing unit supporting part 142, the wrist supporting part 143, and the finger supporting part 144. However, the angle adjusting part 145 may achieve the same effect by adjusting<!-- EPO <DP n="43"> --> the heights of the wrist supporting part 143 and the finger supporting part 144 instead.</p><p id="p0110" num="0110">In this manner, the sensor unit 140 increases blood flow in the palm of a user by changing the posture of the palm. In addition, such a sensor unit 140 is highly suitable for use in a situation where the user takes a seated position. In the case of being used for template registration, the sensor unit 140 may position the palm of the user in a posture corresponding to a palm posture to be taken in an authentication process. For example, if a palm angle is to be 15 degrees during the image capturing process in an authentication apparatus used by the user, a palm angle for the template registration is also set to 15 degrees. In this case, the sensor unit 140 may additionally include a heater or other blood flow increasing means.</p><p id="p0111" num="0111">Note that the sensor unit 140 may increase blood flow in the palm of a user by repetition of operation for changing the palm posture or by a massage given by vibrating means such as an eccentric motor and an ultrasonic vibrator. Thus, the sensor unit 140 is able to increase blood flow in the palm of a user also by applying a stimulus thereto. Furthermore, the sensor unit 140 may additionally include a heater and achieve an increase in blood flow in a composite manner.</p><heading id="h0015">Fifth Embodiment</heading><p id="p0112" num="0112">Next described are registered templates according<!-- EPO <DP n="44"> --> to a fifth embodiment. <figref idrefs="f0018">FIG. 18</figref> illustrates an example of registered templates according to a fifth embodiment. The registered templates of the fifth embodiment differ from those of the second embodiment in registering a posture taken when biometric information is acquired for each template registration.</p><p id="p0113" num="0113">A posture taken in each template registration is associated with both a user identification for uniquely identifying a user and a feature data set, and registered as a template as illustrated in registered templates 88. For example, the user with the user identification ID001 is associated with a feature data set DATA0013 and a posture "standard (horizontal)". The user with the user identification ID002 is associated with a feature data set DATA0023 and a posture "tilted forward". A user with a user identification ID003 is associated with a feature data set DATA0033 and a posture "tilted backward".</p><p id="p0114" num="0114">Thus, a posture taken in each template registration is also registered in a corresponding template, which allows the authentication apparatus to immediately select a posture enabling an increase in blood flow to acquire biometric information.</p><p id="p0115" num="0115">Note that an authentication apparatus (for example, the automated teller machine 30) may acquire surrounding environmental conditions causing changes in the amount of blood flow, such as seasons and temperature variations, and then cause the blood flow increasing unit 205 to operate if<!-- EPO <DP n="45"> --> predetermined conditions representing a high likelihood of a reduction in blood flow having taken place are satisfied, for example, when the outside air temperature is equal to or less than a predetermined value.</p><p id="p0116" num="0116">Note that the blood flow increasing unit 205 is applicable not only for increasing blood flow but also reducing (i.e., increasing in the negative direction) blood flow. In this case, for example, the blood flow increasing unit 205 blows cool air to the palm of a user or positions the palm high. In this manner, the authentication apparatus is able to also match a feature amount of authentication biometric information to a feature amount of template-registered biometric information.</p><p id="p0117" num="0117">In addition, the above-described processing functions may be achieved by a computer. In this case, a program is provided in which processing contents of functions that each apparatus needs to have are described. By executing the program on the computer, the above-described processing functions are achieved on the computer. The program in which processing contents are described may be recorded in computer-readable recording media (including portable recording media). Such computer-readable recording media include a magnetic-storage device, an optical disk, a magneto-optical recording medium, and a semiconductor memory. Examples of the magnetic-storage device are a hard disk drive (HDD), a flexible disk (FD), and a magnetic tape. Examples of the optical disk are a<!-- EPO <DP n="46"> --> digital versatile disk (DVD), a DVD random access memory (DVD-RAM), a compact disc read-only memory (CD-ROM), a CD recordable (CD-R), and a CD rewritable (CD-RW). An example of the magneto-optical recording medium is a magneto-optical disk (MO).</p><p id="p0118" num="0118">In the case of distributing the program, portable recording media, such as DVDs and CD-ROMs, in which the program is recorded are sold. In addition, the program may be stored in a memory device of a server computer and then transferred from the server computer to another computer via a network.</p><p id="p0119" num="0119">A computer for executing the program stores the program, which is originally recorded in a portable recording medium or transferred from the server computer, in its own memory device. Subsequently, the computer reads the program from its own memory device and performs processing according to the program. Note that the computer is able to read the program directly from the portable recording medium and perform processing according to the program. In addition, the computer is able to sequentially perform processing according to a received program each time such a program is transferred from the server computer.</p><p id="p0120" num="0120">Note that various modifications are possible to the above-described embodiments without departing from the scope of the embodiments.</p><p id="p0121" num="0121">The foregoing is merely illustrative of the<!-- EPO <DP n="47"> --> principles of the present invention. Further, numerous modifications and changes will readily occur to those skilled in the art, and therefore, it is not desired to limit the disclosed technology to the exact construction and applications illustrated and described above. Accordingly, all suitable modifications and equivalents may be resorted to, falling within the scope of the present invention determined by appended claims and their equivalents.</p><heading id="h0016">Reference Signs List</heading><p id="p0122" num="0122"><dl id="dl0001" compact="compact"><dt>1</dt><dd>biometric information acquisition apparatus</dd><dt>2a</dt><dd>blood flow increasing unit</dd><dt>2b</dt><dd>biometric information acquiring unit</dd><dt>2c</dt><dd>feature amount evaluating unit</dd><dt>2d</dt><dd>reacquisition determining unit</dd></dl></p></description><claims mxw-id="PCLM56976405" lang="EN" load-source="patent-office"><!-- EPO <DP n="48"> --><claim id="c-en-0001" num="0001"><claim-text>A biometric information acquisition apparatus comprising:
<claim-text>a blood flow increasing unit configured to increase an amount of blood flow of an object person;</claim-text>
<claim-text>a biometric information acquiring unit configured to acquire, from the object person, biometric information whose feature amount is to be increased due to an increase in the amount of blood flow;</claim-text>
<claim-text>a feature amount evaluating unit configured to evaluate the feature amount of the biometric information acquired by the biometric information acquiring unit; and</claim-text>
<claim-text>a reacquisition determining unit configured to determine whether to cause the blood flow increasing unit to operate and then cause the biometric information acquiring unit to reacquire the biometric information when the feature amount evaluated by the feature amount evaluating unit does not reach a predetermined threshold.</claim-text></claim-text></claim><claim id="c-en-0002" num="0002"><claim-text>The biometric information acquisition apparatus according to claim 1, wherein the blood flow increasing unit includes a posture changing unit for changing a posture of a biometric information acquisition region from which the biometric information of the object person is acquired.<!-- EPO <DP n="49"> --></claim-text></claim><claim id="c-en-0003" num="0003"><claim-text>The biometric information acquisition apparatus according to claim 2, wherein the posture changing unit changes a tilt of a supporting part that supports the biometric information acquisition region.</claim-text></claim><claim id="c-en-0004" num="0004"><claim-text>The biometric information acquisition apparatus according to claim 2, wherein the posture changing unit changes height of a supporting part that supports the biometric information acquisition region.</claim-text></claim><claim id="c-en-0005" num="0005"><claim-text>The biometric information acquisition apparatus according to claim 2, wherein the posture changing unit changes a position of the biometric information acquisition region.</claim-text></claim><claim id="c-en-0006" num="0006"><claim-text>The biometric information acquisition apparatus according to claim 2, wherein the blood flow increasing unit includes a vibrating unit for applying a vibration to the biometric information acquisition region.</claim-text></claim><claim id="c-en-0007" num="0007"><claim-text>The biometric information acquisition apparatus according to claim 1,<br/>
wherein the biometric information acquiring unit includes an image capturing device for acquiring the biometric information, the image capturing device being disposed in an interior recess of the biometric information acquiring unit, and<br/>
<!-- EPO <DP n="50"> -->the blood flow increasing unit includes a warming unit for warming inside the interior recess.</claim-text></claim><claim id="c-en-0008" num="0008"><claim-text>The biometric information acquisition apparatus according to claim 7,<br/>
wherein the reacquisition determining unit includes a temperature measuring unit for measuring temperature of the biometric information acquisition region, and<br/>
the reacquisition determining unit determines a timing of reacquiring the biometric information, based on a result of the temperature measurement of the biometric information acquisition region.</claim-text></claim><claim id="c-en-0009" num="0009"><claim-text>The biometric information acquisition apparatus according to claim 1, further comprising a verification information registering unit configured to register verification information based on the biometric information acquired by the biometric information acquiring unit.</claim-text></claim><claim id="c-en-0010" num="0010"><claim-text>The biometric information acquisition apparatus according to claim 9, wherein the verification information includes an evaluation made for the biometric information by the feature amount evaluating unit.</claim-text></claim><claim id="c-en-0011" num="0011"><claim-text>The biometric information acquisition<!-- EPO <DP n="51"> --> apparatus according to claim 9, wherein the verification information includes information on an operation effected by the blood flow increasing unit.</claim-text></claim><claim id="c-en-0012" num="0012"><claim-text>The biometric information acquisition apparatus according to claim 9, wherein the blood flow increasing unit increases the amount of blood flow of the object person based on the verification information.</claim-text></claim><claim id="c-en-0013" num="0013"><claim-text>The biometric information acquisition apparatus according to claim 1, further comprising a verifying unit configured to verify the biometric information acquired by the biometric information acquiring unit against verification information registered in advance.</claim-text></claim><claim id="c-en-0014" num="0014"><claim-text>A biometric information acquisition method comprising:
<claim-text>acquiring, from an object person, biometric information whose feature amount is to be increased due to an increase in an amount of blood flow of the object person;</claim-text>
<claim-text>evaluating the feature amount of the acquired biometric information; and</claim-text>
<claim-text>increasing the amount of blood flow in a biometric information acquisition region from which the biometric information of the object person is acquired and reacquiring the biometric information from the biometric<!-- EPO <DP n="52"> --> information acquisition region when the evaluated feature amount does not reach a predetermined threshold.</claim-text></claim-text></claim></claims><drawings mxw-id="PDW16667185" load-source="patent-office"><!-- EPO <DP n="53"> --><figure id="f0001" num="1"><img id="if0001" file="imgf0001.tif" wi="130" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="54"> --><figure id="f0002" num="2"><img id="if0002" file="imgf0002.tif" wi="154" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="55"> --><figure id="f0003" num="3"><img id="if0003" file="imgf0003.tif" wi="144" he="163" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="56"> --><figure id="f0004" num="4"><img id="if0004" file="imgf0004.tif" wi="162" he="201" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="57"> --><figure id="f0005" num="5"><img id="if0005" file="imgf0005.tif" wi="161" he="164" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="58"> --><figure id="f0006" num="6"><img id="if0006" file="imgf0006.tif" wi="147" he="179" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="59"> --><figure id="f0007" num="7(1),7(2)"><img id="if0007" file="imgf0007.tif" wi="161" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="60"> --><figure id="f0008" num="8"><img id="if0008" file="imgf0008.tif" wi="130" he="196" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="61"> --><figure id="f0009" num="9"><img id="if0009" file="imgf0009.tif" wi="147" he="198" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="62"> --><figure id="f0010" num="10"><img id="if0010" file="imgf0010.tif" wi="109" he="168" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="63"> --><figure id="f0011" num="11(1),11(2),11(3)"><img id="if0011" file="imgf0011.tif" wi="147" he="230" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="64"> --><figure id="f0012" num="12(1),12(2),12(3)"><img id="if0012" file="imgf0012.tif" wi="144" he="221" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="65"> --><figure id="f0013" num="13"><img id="if0013" file="imgf0013.tif" wi="140" he="118" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="66"> --><figure id="f0014" num="14"><img id="if0014" file="imgf0014.tif" wi="145" he="107" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="67"> --><figure id="f0015" num="15"><img id="if0015" file="imgf0015.tif" wi="139" he="170" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="68"> --><figure id="f0016" num="16"><img id="if0016" file="imgf0016.tif" wi="154" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="69"> --><figure id="f0017" num="17"><img id="if0017" file="imgf0017.tif" wi="163" he="177" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="70"> --><figure id="f0018" num="18"><img id="if0018" file="imgf0018.tif" wi="146" he="114" img-content="drawing" img-format="tif"/></figure></drawings><search-report-data><doc-page id="srep0001" file="srep0001.tif" wi="165" he="230" type="tif"/><doc-page id="srep0002" file="srep0002.tif" wi="165" he="233" type="tif"/></search-report-data><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
