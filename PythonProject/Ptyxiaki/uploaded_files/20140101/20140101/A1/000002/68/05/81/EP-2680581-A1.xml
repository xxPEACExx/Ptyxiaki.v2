<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2680581-A1" country="EP" doc-number="2680581" kind="A1" date="20140101" family-id="48670569" file-reference-id="252638" date-produced="20180824" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="146549107" ucid="EP-2680581-A1"><document-id><country>EP</country><doc-number>2680581</doc-number><kind>A1</kind><date>20140101</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-12305758-A" is-representative="YES"><document-id mxw-id="PAPP154823030" load-source="docdb" format="epo"><country>EP</country><doc-number>12305758</doc-number><kind>A</kind><date>20120628</date><lang>EN</lang></document-id><document-id mxw-id="PAPP179320828" load-source="docdb" format="original"><country>EP</country><doc-number>12305758.0</doc-number><date>20120628</date></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC140453011" ucid="EP-12305758-A" load-source="docdb"><document-id format="epo"><country>EP</country><doc-number>12305758</doc-number><kind>A</kind><date>20120628</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL1988101306" load-source="docdb">H04N   7/26        20060101AFI20121116BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1988124160" load-source="docdb">H04N   7/50        20060101ALI20121116BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-2036690015" load-source="docdb" scheme="CPC">H04N  19/176       20130101 LI20150723BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2036694175" load-source="docdb" scheme="CPC">H04N  19/167       20141101 LI20150723BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2036696151" load-source="docdb" scheme="CPC">H04N  19/137       20141101 LI20150724BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2036696676" load-source="docdb" scheme="CPC">H04N  19/196       20141101 LI20150724BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2036698818" load-source="docdb" scheme="CPC">H04N  19/124       20141101 FI20150724BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2036699494" load-source="docdb" scheme="CPC">H04N  19/172       20130101 LI20150723BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2137520859" load-source="docdb" scheme="CPC">H04N  19/17        20141101 LI20141108BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2137521959" load-source="docdb" scheme="CPC">H04N  19/107       20141101 LI20141108BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2137523623" load-source="docdb" scheme="CPC">H04N  19/61        20141101 LI20141108BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2137523859" load-source="docdb" scheme="CPC">H04N  19/162       20141101 LI20141108BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2137525251" load-source="docdb" scheme="CPC">H04N  19/117       20141101 LI20141108BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2137528300" load-source="docdb" scheme="CPC">H04N  19/463       20141101 LI20141108BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2137528949" load-source="docdb" scheme="CPC">H04N  19/86        20141101 LI20141108BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2137530235" load-source="docdb" scheme="CPC">H04N  19/46        20130101 LI20141108BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2137532534" load-source="docdb" scheme="CPC">H04N  19/51        20130101 LI20141108BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT132179805" lang="DE" load-source="patent-office">Verfahren und Vorrichtung zur dynamischen Anpassung der Parameter eines Videocodierers</invention-title><invention-title mxw-id="PT132179806" lang="EN" load-source="patent-office">Method and apparatus for dynamic adaptation of video encoder parameters</invention-title><invention-title mxw-id="PT132179807" lang="FR" load-source="patent-office">Procédé et appareil d'adaptation dynamique de paramètres de codage vidéo</invention-title><citations><patent-citations><patcit mxw-id="PCIT242651868" load-source="docdb" ucid="US-20040151390-A1"><document-id format="epo"><country>US</country><doc-number>20040151390</doc-number><kind>A1</kind><date>20040805</date></document-id><sources><source name="SEA" category="Y" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT242651870" load-source="docdb" ucid="US-20080159385-A1"><document-id format="epo"><country>US</country><doc-number>20080159385</doc-number><kind>A1</kind><date>20080703</date></document-id><sources><source name="SEA" category="I" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT242651871" load-source="docdb" ucid="US-20090263032-A1"><document-id format="epo"><country>US</country><doc-number>20090263032</doc-number><kind>A1</kind><date>20091022</date></document-id><sources><source name="SEA" category="Y" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT242651867" load-source="docdb" ucid="US-6834080-B1"><document-id format="epo"><country>US</country><doc-number>6834080</doc-number><kind>B1</kind><date>20041221</date></document-id><sources><source name="SEA" category="A" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT371081244" load-source="docdb" ucid="WO-1999059344-A1"><document-id format="epo"><country>WO</country><doc-number>1999059344</doc-number><kind>A1</kind><date>19991118</date></document-id><sources><source name="SEA" category="XY" created-by-npl="N"/></sources></patcit></patent-citations><non-patent-citations><nplcit><text>CHANGCAI LAI ET AL: "Efficient intra mode selection using motion affected region tracking", VISUAL COMMUNICATIONS AND IMAGE PROCESSING; 11-7-2010 - 14-7-2010; HUANG SHAN, AN HUI, CHINA,, 11 July 2010 (2010-07-11), XP030082239</text><sources><source mxw-id="PNPL55258374" load-source="docdb" name="SEA" category="Y"/></sources></nplcit><nplcit><text>None</text><sources><source mxw-id="PNPL67455008" load-source="docdb" name="APP"/></sources></nplcit></non-patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR918162379" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>ALCATEL LUCENT</last-name><address><country>FR</country></address></addressbook></applicant><applicant mxw-id="PPAR918148347" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>ALCATEL LUCENT</last-name></addressbook></applicant><applicant mxw-id="PPAR918982201" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Alcatel-Lucent</last-name><iid>101311164</iid><address><street>3, Avenue Octave Gréard</street><city>75007 Paris</city><country>FR</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR918165420" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>VERZIJP NICO</last-name><address><country>BE</country></address></addressbook></inventor><inventor mxw-id="PPAR918153495" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>Verzijp, Nico</last-name></addressbook></inventor><inventor mxw-id="PPAR918988822" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Verzijp, Nico</last-name><address><street>Rembrandtstraat 20 B4</street><city>2018 Antwerpen</city><country>BE</country></address></addressbook></inventor><inventor mxw-id="PPAR918133603" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>Macq Jean-Francois</last-name><address><country>BE</country></address></addressbook></inventor><inventor mxw-id="PPAR918136477" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>MACQ, JEAN-FRANCOIS</last-name></addressbook></inventor><inventor mxw-id="PPAR918992003" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>Macq, Jean-François</last-name><address><street>Drève du Château 32</street><city>1083 Ganshoren</city><country>BE</country></address></addressbook></inventor><inventor mxw-id="PPAR918172189" load-source="docdb" sequence="3" format="epo"><addressbook><last-name>RONDAO ALFACE PATRICE</last-name><address><country>BE</country></address></addressbook></inventor><inventor mxw-id="PPAR918141657" load-source="docdb" sequence="3" format="intermediate"><addressbook><last-name>Rondao Alface, Patrice</last-name></addressbook></inventor><inventor mxw-id="PPAR918988731" load-source="patent-office" sequence="3" format="original"><addressbook><last-name>Rondao Alface, Patrice</last-name><address><street>Rue Sainte Barbe 110 Bte 1</street><city>Nivelles 1400</city><country>BE</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR918984231" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>ALU Antw Patent Attorneys</last-name><iid>101179751</iid><address><street>Intellectual Property and Standards Copernicuslaan 50</street><city>2018 Antwerp</city><country>BE</country></address></addressbook></agent></agents></parties><international-convention-data><designated-states><ep-contracting-states><country mxw-id="DS548801320" load-source="docdb">AL</country><country mxw-id="DS548843633" load-source="docdb">AT</country><country mxw-id="DS548801326" load-source="docdb">BE</country><country mxw-id="DS548834956" load-source="docdb">BG</country><country mxw-id="DS548802190" load-source="docdb">CH</country><country mxw-id="DS548846096" load-source="docdb">CY</country><country mxw-id="DS548845066" load-source="docdb">CZ</country><country mxw-id="DS548801327" load-source="docdb">DE</country><country mxw-id="DS548846097" load-source="docdb">DK</country><country mxw-id="DS548846098" load-source="docdb">EE</country><country mxw-id="DS548842462" load-source="docdb">ES</country><country mxw-id="DS548834957" load-source="docdb">FI</country><country mxw-id="DS548835726" load-source="docdb">FR</country><country mxw-id="DS548801328" load-source="docdb">GB</country><country mxw-id="DS548846099" load-source="docdb">GR</country><country mxw-id="DS548801329" load-source="docdb">HR</country><country mxw-id="DS548845067" load-source="docdb">HU</country><country mxw-id="DS548802191" load-source="docdb">IE</country><country mxw-id="DS548801334" load-source="docdb">IS</country><country mxw-id="DS548835727" load-source="docdb">IT</country><country mxw-id="DS548846100" load-source="docdb">LI</country><country mxw-id="DS548843054" load-source="docdb">LT</country><country mxw-id="DS548845068" load-source="docdb">LU</country><country mxw-id="DS548843055" load-source="docdb">LV</country><country mxw-id="DS548843056" load-source="docdb">MC</country><country mxw-id="DS548842629" load-source="docdb">MK</country><country mxw-id="DS548842962" load-source="docdb">MT</country><country mxw-id="DS548845069" load-source="docdb">NL</country><country mxw-id="DS548842463" load-source="docdb">NO</country><country mxw-id="DS548802192" load-source="docdb">PL</country><country mxw-id="DS548843058" load-source="docdb">PT</country><country mxw-id="DS548845074" load-source="docdb">RO</country><country mxw-id="DS548843059" load-source="docdb">RS</country><country mxw-id="DS548845075" load-source="docdb">SE</country><country mxw-id="DS548843060" load-source="docdb">SI</country><country mxw-id="DS548842464" load-source="docdb">SK</country><country mxw-id="DS548802193" load-source="docdb">SM</country><country mxw-id="DS548842963" load-source="docdb">TR</country></ep-contracting-states><ep-extended-states><ep-extended-state-data><country>BA</country></ep-extended-state-data><ep-extended-state-data><country>ME</country></ep-extended-state-data></ep-extended-states></designated-states></international-convention-data></bibliographic-data><abstract mxw-id="PA128669778" lang="EN" load-source="patent-office"><p id="pa01" num="0001">A method for adapting at least one video encoding parameter to be used for encoding of a video for being transmitted from a server to a client, comprises a step of determining whether the movement speed of a region of interest over successive ones of previously encoded and transmitted frames of said video exceeds a predetermined threshold value, and a step of adapting said at least one video encoding parameter if said predetermined threshold value is exceeded.
<img id="iaf01" file="imgaf001.tif" wi="145" he="107" img-content="drawing" img-format="tif"/></p></abstract><abstract mxw-id="PA128499151" lang="EN" source="EPO" load-source="docdb"><p>A method for adapting at least one video encoding parameter to be used for encoding of a video for being transmitted from a server to a client, comprises a step of determining whether the movement speed of a region of interest over successive ones of previously encoded and transmitted frames of said video exceeds a predetermined threshold value, and a step of adapting said at least one video encoding parameter if said predetermined threshold value is exceeded.</p></abstract><description mxw-id="PDES63955208" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><p id="p0001" num="0001">The present invention relates to a method and apparatus for adapting video encoder parameters.</p><p id="p0002" num="0002">High spatial-resolution video, also referred to as Ultra High Definition video, is becoming more and more common. This type of content ranges from High Definition, hereafter abbreviated with HD, video with 1920×1080 pixels per frame to higher resolution video either directly acquired with advanced optics and image sensors or obtained from stitched views from multiple cameras. Direct delivery of this type of content in its entirety to end-user-devices is often not possible due to bandwidth constraints.</p><p id="p0003" num="0003">A possible solution is to down sample the complete content before transmission but this results in a low-quality image, which is not desirable.</p><p id="p0004" num="0004">In another solution the end-user will first operate a Region of Interest, hereafter abbreviated by ROI throughout the remainder of this document. This ROI is typically a lot smaller compared to the UHD input video and may fit to the user device's native display resolution. In response to an end-user command, the image will be cropped at the server side to the desired ROI before encoding and transmission. This solution offers better image quality at the cost of a per-user encoding. Such system may however not scale to a very large number of users, but it is very well suited for e.g. surveillance applications. To improve scalability, the system can be distributed over multiple proxy servers, each responsible to serve a pre-defined number of neighboring users.</p><p id="p0005" num="0005">Problems with such an interactive ROI encoding arise in case the end-user starts navigating, e.g. by interactively displacing, his/her ROI into the whole available spatial content on his/her display. Depending on the encoder configuration, two observations can be made with respect to prior art solutions for this:<!-- EPO <DP n="2"> -->
<ol><li>a/ Constant quality encoding (fixed quantization) results in a dramatic bandwidth increase.</li><li>b/ Contant bitrate encoding keeps the bandwidth under control but the quality will suffer, even in the case of a static ROI.</li></ol></p><p id="p0006" num="0006">It is therefore an object of embodiments of the present invention to present a method of the known type but which does not show the aforementioned disadvantages.</p><p id="p0007" num="0007">According to embodiments of the present invention this object is achieved by a method for adapting at least one video encoding parameter to be used for encoding of a video for being transmitted from a server to a client, said method comprising a step of determining whether the movement speed of a region of interest over successive ones of previously encoded and transmitted frames of said video exceeds a predetermined threshold value, and a step of adapting said at least one video encoding parameter if said predetermined threshold value is exceeded.</p><p id="p0008" num="0008">In this way, by adapting the encoder parameters based on the speed of the ROI movement itself, bandwidth peaks are prevented in case fast ROI motion is detected. In addition the impact on the video quality can be reduced.</p><p id="p0009" num="0009">In an embodiment said movement speed of said region of interest is determined by monitoring commands issued by said client on said region of interest.</p><p id="p0010" num="0010">This allows to use direct input from user navigation commands.</p><p id="p0011" num="0011">In another embodiment said movement speed of said region of interest is determined by monitoring previously determined encoding decisions used during encoding of previous frames.</p><p id="p0012" num="0012">In this case the ROI motion is determined indirectly based on some statistics of previously encoding decisions made by the encoder.<!-- EPO <DP n="3"> --></p><p id="p0013" num="0013">The at least one encoding parameter to be adapted can be a quantization parameter which can be adapted such as to increase with increasing movement speed of said region of interest.</p><p id="p0014" num="0014">Alternatively said at least one encoding parameter may relate to a changing from inter to intra-coding, such that in case said movement speed of said region of interest exceeds said predetermined threshold value, intra-coding of macroblocks will be enforced.</p><p id="p0015" num="0015">In yet another variant the at least one encoding parameter may relate to the use of a deblocking filter which is enforced in case said movement speed of said region of interest exceeds said predetermined threshold value.</p><p id="p0016" num="0016">The present invention relates as well to embodiments of a video server for performing the above mentioned method.</p><p id="p0017" num="0017">The present invention relates as well to a computer program product comprising software adapted to perform the method steps in accordance to any of the claims 1 to 6, when executed on a data-processing apparatus.</p><p id="p0018" num="0018">It is to be noticed that the term 'coupled', used in the claims, should not be interpreted as being limitative to direct connections only. Thus, the scope of the expression 'a device A coupled to a device B' should not be limited to devices or systems wherein an output of device A is directly connected to an input of device B. It means that there exists a path between an output of A and an input of B which may be a path including other devices or means.</p><p id="p0019" num="0019">It is to be noticed that the term 'comprising', used in the claims, should not be interpreted as being limitative to the means listed thereafter. Thus, the scope of the expression 'a device comprising means A and B' should not be limited to devices consisting only of components A and B. It means that with respect to the present invention, the only relevant components of the device are A and B.<!-- EPO <DP n="4"> --></p><p id="p0020" num="0020">The above and other objects and features of the invention will become more apparent and the invention itself will be best understood by referring to the following description of an embodiment taken in conjunction with the accompanying drawings wherein:
<ul><li><figref idrefs="f0001 f0002">Figs. 1a-b</figref> schematically show typical prior art configurations of a client/server system,</li><li><figref idrefs="f0003">Fig. 2</figref> explains a possibility to measure the ROI movement speed,</li><li><figref idrefs="f0004 f0005">Figs. 3a-b</figref> show embodiments of a client/server configuration according to the invention,</li><li><figref idrefs="f0006">Fig. 4</figref> shows an embodiment of the method.</li></ul></p><p id="p0021" num="0021">It should be appreciated by those skilled in the art that any block diagrams herein represent conceptual views of illustrative circuitry embodying the principles of the invention. Similarly, it will be appreciated that any flow charts, flow diagrams, state transition diagrams, pseudo code, and the like represent various processes which may be substantially represented in computer readable medium and so executed by a computer or processor, whether or not such computer or processor is explicitly shown.</p><p id="p0022" num="0022"><figref idrefs="f0001 f0002">Figs. 1a-b</figref> depict prior art systems, which can e.g. be based on a H.264 encoder with Variable Bit Rate (VBR) output. In a typical configuration such as depicted in <figref idrefs="f0001">Fig. 1a</figref> a video storage device VS, wherein a large number of video files can be stored, is part of a server S for providing these video files to a client device C. In an alternative embodiment this video storage device can be a separate entity coupled to the server S. In view of the storage capabilities of the storage device, which can be made of any type of memory, e.g. a hard disk drive, an electronically erasable or non-volatile memory, or any other type of memory capable to store digital data, the video files are generally stored in a<!-- EPO <DP n="5"> --> compressed form. In these situations, a decoder DS may be put between the video storage and the server, or can be part of the server itself, such as depicted in <figref idrefs="f0001">Fig. 1a</figref>, to uncompress the stored compressed video files to restore them to their original uncompressed format. Alternatively, such as depicted in <figref idrefs="f0002">fig. 1b</figref>, the server can also be coupled to an acquisition system AS comprising one or more cameras which may output the video uncompressed, and directly to a ROI cropping device CR of the server.</p><p id="p0023" num="0023">In both configurations the original video files are thus received by such a ROI cropping device CR, which is further adapted to receive from the client device C instructions with respect to this cropping. The client device itself generally comprises a display (not shown on <figref idrefs="f0001 f0002">figs. 1a-b</figref>) for showing the video transmitted from the server to the client and a user interface for receiving cropping instructions from the user. These instructions may be input by a user U, via any type of user interface (not shown on <figref idrefs="f0001 f0002">Figs. 1a-b</figref>) which can e.g. comprise a touch interface, a keyboard, a mouse, or any other type of gesture detection interface etc, for receiving information as to the location of the ROI or to which size the user wants to crop the displayed image. These are generally denoted ROI navigation commands such as pan/tilt commands, which generally assume that the size of the ROI is initially equal to the resolution of the end-users' device. Also zoom commands that allow to change the size of the ROI can be input. This user interface is coupled to a user command processor UCP which is adapted to translate these received instructions from the user interface into suitable commands understandable by the ROI cropping device CR in the server.</p><p id="p0024" num="0024">In another configuration the cropping instructions are provided by the user command processor autonomously, thus without any input from a human user, taking into account the size restriction of the display of the client device. For instance, if the original size of an image in the server comprises 8000x4000 pixels, and the display of the client is only suited to show 1880 by 800 pixels, the<!-- EPO <DP n="6"> --> user command processor may autonomously generate a cropping command to the ROI cropping device to select a region of interest of 1880x800 pixels (e.g. of the upper left corner of the image or centred on the 8Kx4K image).</p><p id="p0025" num="0025">Upon receipt of these cropping instructions, the ROI cropping device will thus crop the large image, thus cut out an indicated (selected or predefined) region out of the large image, to the desired reduced size, and provide this to an encoder for encoding the selected ROI for then transmission of this encoded ROI to the client. Upon receipt thereof by the client, a decoder device DC of the client will then decode the received cropped image, and provide this to a display device (not shown on <figref idrefs="f0001 f0002">Figs. 1a-b</figref>) for being viewed by the user U. The selected cropped parts of the original image are called ROI images. The server encoder E thus receives the cropped ROI images as in <figref idrefs="f0001 f0002">Figures 1a-b</figref>.</p><p id="p0026" num="0026">When a user starts ROI navigation e.g. by providing pan/tilt input instructions via the client user interface, the user command processor UCP will translate them into commands understandable to the ROI cropping device. As earlier mentioned, problems may arise in case the end-user starts navigating (i.e. interactively displacing) his/her ROI into the whole available spatial content. Depending on the encoder configuration, two observations can be made with respect to prior art solutions for this:
<ol><li>a/ Constant quality encoding (fixed quantization) results in a dramatic bandwidth increase. Indeed, for fast ROI movement, there is very little or even no motion compensation possible (reference frames do not sufficiently overlap with the current ROI position), effectively resulting in a bandwidth comparable to intra only encoding. Experiments have shown that bandwidth can increase with a factor of 6 or more. For a 1Mbps stream (on average), bandwidth increases to 6Mbps and even more have been observed.</li><li>b/ Contant bitrate encoding keeps the bandwidth under control but the quality will suffer, even in the case of a static ROI.</li></ol><!-- EPO <DP n="7"> --></p><p id="p0027" num="0027">In order to solve these prior art problems, the server S includes an additional functionality, for dynamically adapting the encoder parameters based on the speed of the ROI movements input by the user. When a ROI motion is detected, which exceeds a predetermined threshold value, the encoding parameters are updated such as to prevent bandwidth peaks and/or too strong impact on the video quality.</p><p id="p0028" num="0028">This threshold value can be expressed in absolute number of pixels shift per frame, e.g. 32 pixels per frame. It may also be expressed in an absolute number of macroblocks shift per frame, e.g. 2 macroblocks (which for H.264 coding corresponds to 32 pixels as 1 macroblock corresponds to 16 by 16 pixels). In another embodiment the threshold can vary, and be based on statistical measurements of the encoder performance itself. These and other examples will be explained more into detail in a further paragraph of this document.</p><p id="p0029" num="0029">In an embodiment, the motion detection and determination of how the encoder parameters are to be updated, is performed in a separate module of the server. This is shown in <figref idrefs="f0004 f0005">Figs. 3a-b</figref>, wherein the server is equipped with a rate controller module RCM. In order not to overload the drawings, the video storage, decoder, acquisition system and user are no longer shown in <figref idrefs="f0004 f0005">Figs. 3a-b</figref> as they are no real contributing elements to the invention.</p><p id="p0030" num="0030">It is also to be remarked that in other embodiments the server does not need to contain a separate module RCM for incorporating this extra functionality, and all server functions can as well be performed by means of one processor device, which can receive its instructions from one or more computer programs, either encoded on a carrier such as a compact disk, or stored on another type of fixed or mobile memory attachable or incorporated within the<!-- EPO <DP n="8"> --> server, or even downloadable from a storage server towards the video server under consideration.</p><p id="p0031" num="0031">In an embodiment, wherein the speed of the ROI movement is detected based on the user input commands, the functionality of the rate controller module RCM will then imply that the user navigation commands with respect to the ROI or in general the displayed images, are also to be received and analyzed. This is shown in <figref idrefs="f0004">Fig. 3a</figref> by means of arrow 1a, indicating the interception and receipt of the user commands cmd by this rate controller block. Furthermore the rate controller functionality implies a recalculation of the encoding parameters to be used by the server encoder E, and the provision of these possibly adapted parameters to the encoders. This is shown by means of arrow 2. The encoding parameters which can be influenced are e.g. the quantization parameter QP, etc. that it has to use.</p><p id="p0032" num="0032">In an alternative embodiment, depicted in <figref idrefs="f0005">Fig. 3b</figref>, the movement of the ROI is detected indirectly by monitoring the server encoder motion estimation performances. This monitoring is depicted by means of arrow 2a, from the server encoder E to the rate controller module RCM.</p><p id="p0033" num="0033">Both embodiments will now be explained more into detail. For the further explanation it is assumed that frames are encoded in the same order as the display order using simple sequences of I and P frames. In case the display and encoding order become different, the encoder can also instruct the rate controller on the coding frame ordering. This allows the rate controller to measure ROI motion with respect to the reference frame to be used for coding the current frame (which may be different from the previous frame in display order).</p><p id="p0034" num="0034">In the embodiment depicted in <figref idrefs="f0004">Fig. 3a</figref> direct input from user navigation commands is provided to the rate controller. In a variant, successive ones of such user navigation commands can be intercepted by the rate<!-- EPO <DP n="9"> --> controller, which is adapted to analyze them, and to derive from them a 2D translation vector between two consecutive frames, expressed in pixels. Based on this information, the rate controller can easily derive a ROI speed expressed as the length of the translation vector in pixels/frame.</p><p id="p0035" num="0035">The ROI motion is then compared against a predetermined threshold and can thus be considered fast when the computed speed is above this given threshold e.g. above 5 pixels/frame. In some embodiments optimal threshold values can be determined empirically beforehand.</p><p id="p0036" num="0036">In another embodiment other metrics can be calculated for the determination of the ROI motion. An example can be by computing the percentage of overlapping area between the current ROI and available reference frames which are used for encoding of the current ROI. This is illustrated on <figref idrefs="f0003">Figure 2</figref>, showing the current frame f, depicted in full line, as well as two reference frames f<sub>1</sub><sup>ref</sup> and f<sub>2</sub><sup>ref</sup> used for the encoding of the current frame f. If the union of overlapping regions A, used for the encoding of the ROI under consideration is smaller than a threshold T, the ROI motion is considered to be fast and exceeding the threshold, such as to enable the adaptation of encoding parameters. If this area is smaller than the predetermined threshold, the ROI motion is still considered as slow, and live motion estimation prediction is still used, meaning that the encoding parameters are not to be adapted. In this example, the threshold may be given by the total area of the ROI minus two columns times two rows of macroblocks. This enables to cover any 2D ROI motion with respect to the chosen number of reference frames used by the encoder.</p><p id="p0037" num="0037">In other variant embodiments user navigation's input could also be expressed in other forms, depending on the type of interactivity modes: e.g. as zooming factors, 3D rotation matrix, etc. Metrics can also be derived from such data, and be compared against predetermined thresholds for these metrics.<!-- EPO <DP n="10"> --></p><p id="p0038" num="0038">In the embodiment depicted in <figref idrefs="f0005">Fig. 3b</figref>, ROI motion can also be detected by getting feedback on how the encoder E is performing with respect to motion estimation. The ROI motion is therefore indirectly detected based on some statistics on the coding decisions made by the encoder, for instance:
<ul><li>If the amount of intra-coded macro blocks in inter-predicted frames gets above a predetermined threshold</li><li>If the average energy in the residual signal gets above a certain threshold</li><li>If the resulting bit rate peaks above a predefined target bit rate and margin</li></ul></p><p id="p0039" num="0039">Such measurement can be used on-the-fly by the rate controller RCM to update the encoding parameters or can be used in an offline manner to learn how to define the best threshold for the cases of the embodiments according to <figref idrefs="f0004">Fig. 3a</figref> described in the previous paragraphs.</p><p id="p0040" num="0040">For all embodiments described with respect to <figref idrefs="f0004 f0005">Figs. 3a-b</figref>, it is the objective to instruct the encoder with suitable adapted encoding parameters in case high ROI motion is detected. This will enable to avoid bitrate peaks, prevent visible artifacts and reduce processing complexity.</p><p id="p0041" num="0041">In an embodiment the encoding parameters are modified so as to prevent bitrate peaks as the inability of the encoder to do a proper motion estimation usually leads to a lot of intra-frame coded information. The basic lever to decrease the bitrate is to modify the quantization parameter QP, from the information on ROI motion. The way the rate controller RCM uses this information to vary the QP for the encoder can be as follows : in case the ROI speed is lower than the threshold, the rate controller outputs a low QP (resulting in a high quality image) . In an embodiment a QP value equal or less than 16 can e.g. be selected. When the ROI speed increases, the output QP is increased as well. In general, the rate controller implements a function QP=f(ROI-speed),<!-- EPO <DP n="11"> --> where this function can be linear, step-wise etc. The best matching function can be determined using experiments. A very simple step-wise function could for instance be the following
<ul><li>default for low motion: QP=16</li><li>high motion: QP=32</li></ul></p><p id="p0042" num="0042">In another embodiment the encoding parameters can be adapted with the aim to limit the user-perceived impact on quality. By nature, when the ROI motion is high, the user will be less sensitive to pixel accuracy. However at high QP, a static macroblock-grid may become apparent (blocking artefacts). In this case, the in-loop deblocking filter of the encoder can be enabled or strengthened. In the H.264 standard, an in-loop deblocking filter is defined. Its parameters can either be inferred from other coding parameters in the bitstream (in particular from the quantization parameters) or explicitly signalled in the slice header when the flag <i>deblocking_filter_control_present_flag</i> is set to 1. The encoder can then signal a forced use of the deblocking filter by setting the disable_deblocking_filter to 0 and control how the strength of the deblocking filter is influenced by the QP with the parameters s/tce_o/pho_c0_offsef_dtv2 and <i>slice_beta_offset_div2.</i> The higher the values of both parameters are, the more often the deblocking filter will be applied across block boundaries (for a given QP value).</p><p id="p0043" num="0043">The way the rate controller uses the ROI speed to control these parameters can be as follows. The filter can be forced when fast ROI motion is detected as described above, possibly with a threshold value optimized for filtering control to be determined experimentally. In that case, the <i>slice_alpha_cO_offset_div2</i> and <i>slice_beta_offset_div2</i> are defined as an increasing function of the ROI speed. Functions that yield the most pleasing visual effect can be determined empirically.<!-- EPO <DP n="12"> --></p><p id="p0044" num="0044">In a third embodiment, when high ROI motion is detected, the encoder may decide to code macroblocks in intra mode. In order to save some computational cycles, the rate controller can therefore enforce intra-coding of macroblocks, when fast ROI motion is detected as described above (possibly with a threshold value optimized for processing complexity control). This allows the encoder to skip the processing steps for motion estimation.</p><p id="p0045" num="0045">It is evident that the above mentioned adaptations of encoding parameters can be combined in whichever order, in other embodiments. <figref idrefs="f0006">Fig. 4</figref> illustrates this by giving an embodiment of a flowchart illustrating the different steps of the method. In a first step, 100, the ROI motion is to be detected, e.g. by means of the methods previously described. This ROI motion, expressed by means of a suitable metric, which can vary from embodiment to embodiment, is to be compared against a predetermined suitable threshold in step 200. When this threshold is exceeded, one or more encoding parameters may be adapted. A list of three adaptations are mentioned in respective steps 310 to 330, but they may be combined in whichever order, or selected separately for being implemented in just one selected adaptation of one encoding parameter, under item 300. When the threshold is not exceeded, the encoding is not changed, and normal encoding is used, as step 400 indicates.</p><p id="p0046" num="0046">While the principles of the invention have been described above in connection with specific apparatus, it is to be clearly understood that this description is made only by way of example and not as a limitation on the scope of the invention, as defined in the appended claims. In the claims hereof any element expressed as a means for performing a specified function is intended to encompass any way of performing that function. This may include, for example, a combination of electrical or mechanical elements which performs that function or software in any form, including, therefore, firmware, microcode or the like, combined with appropriate circuitry for executing that software to perform the<!-- EPO <DP n="13"> --> function, as well as mechanical elements coupled to software controlled circuitry, if any. The invention as defined by such claims resides in the fact that the functionalities provided by the various recited means are combined and brought together in the manner which the claims call for, and unless otherwise specifically so defined, any physical structure is of little or no importance to the novelty of the claimed invention. Applicant thus regards any means which can provide those functionalities as equivalent as those shown herein.</p></description><claims mxw-id="PCLM56976121" lang="EN" load-source="patent-office"><!-- EPO <DP n="14"> --><claim id="c-en-0001" num="0001"><claim-text>A method for adapting at least one video encoding parameter to be used for encoding of a video for being transmitted from a server (S) to a client (C) , said method comprising a step of determining whether the movement speed of a region of interest over successive ones of previously encoded and transmitted frames of said video exceeds a predetermined threshold value, and a step of adapting said at least one video encoding parameter if said predetermined threshold value is exceeded.</claim-text></claim><claim id="c-en-0002" num="0002"><claim-text>Method according to claim 1, wherein said movement speed of said region of interest is determined by monitoring commands issued by said client on said region of interest.</claim-text></claim><claim id="c-en-0003" num="0003"><claim-text>Method according to claim 1 wherein said movement speed of said region of interest is determined by monitoring previously determined encoding decisions used during encoding of previous frames .</claim-text></claim><claim id="c-en-0004" num="0004"><claim-text>Method according to any of the previous claims 1-3 wherein said at least one parameter is a quantization parameter and wherein said quantization parameter is adapted such as to increase with increasing movement speed of said region of interest.</claim-text></claim><claim id="c-en-0005" num="0005"><claim-text>Method according to any of the previous claims 1-4, wherein said at least one encoding parameter relates to a changing from inter to intra-coding, such that in case said movement speed of said region of interest exceeds said predetermined threshold value, intra-coding of macroblocks will be enforced.<!-- EPO <DP n="15"> --></claim-text></claim><claim id="c-en-0006" num="0006"><claim-text>Method according to any of the previous claims 1-5, wherein said at least one encoding parameter relates to the use of a deblocking filter which is enforced in case said movement speed of said region of interest exceeds said predetermined threshold value.</claim-text></claim><claim id="c-en-0007" num="0007"><claim-text>Video server (S) for encoding a video for subsequent transmission towards a client (C) coupled to said video server (S) , said video server (S) being adapted to determine whether the movement speed of a region of interest over successive ones of previously encoded and transmitted frames of said video exceeds a predetermined threshold value, and to adapt at least one video encoding parameter if said predetermined threshold value is exceeded.</claim-text></claim><claim id="c-en-0008" num="0008"><claim-text>Video server (S) according to claim 7 further being adapted to determine said movement speed of said region of interest is by monitoring commands issued by said client on said region of interest.</claim-text></claim><claim id="c-en-0009" num="0009"><claim-text>Video server (S) according to claim 7 further being adapted to determine said movement speed of said region of interest by monitoring previously determined encoding decisions used during encoding of previous frames .</claim-text></claim><claim id="c-en-0010" num="0010"><claim-text>Video server (S) according to any of the previous claim 7-9, wherein said at least one parameter is a quantization parameter and wherein said video server is able to adapt said quantization parameter such as to increase with increasing movement speed of said region of interest.</claim-text></claim><claim id="c-en-0011" num="0011"><claim-text>Video server (S) according to any of the previous claims 7-10, wherein said at least one encoding parameter relates to a changing from inter to<!-- EPO <DP n="16"> --> intra-coding, such that in case said movement speed of said region of interest exceeds said predetermined threshold value, intra-coding of macroblocks will be enforced.</claim-text></claim><claim id="c-en-0012" num="0012"><claim-text>Video server (S) according to any of the previous claims 7-11, wherein said at least one encoding parameter relates to the use of a deblocking filter which is enforced in case said movement speed of said region of interest exceeds said predetermined threshold value.</claim-text></claim><claim id="c-en-0013" num="0013"><claim-text>A computer program product comprising software adapted to perform the method steps in accordance to any of the claims 1 to 6, when executed on a data-processing apparatus.</claim-text></claim></claims><drawings mxw-id="PDW16666906" load-source="patent-office"><!-- EPO <DP n="17"> --><figure id="f0001" num="1a"><img id="if0001" file="imgf0001.tif" wi="165" he="88" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="18"> --><figure id="f0002" num="1b"><img id="if0002" file="imgf0002.tif" wi="165" he="113" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="19"> --><figure id="f0003" num="2"><img id="if0003" file="imgf0003.tif" wi="118" he="107" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="20"> --><figure id="f0004" num="3a"><img id="if0004" file="imgf0004.tif" wi="165" he="98" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="21"> --><figure id="f0005" num="3b"><img id="if0005" file="imgf0005.tif" wi="165" he="98" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="22"> --><figure id="f0006" num="4"><img id="if0006" file="imgf0006.tif" wi="165" he="127" img-content="drawing" img-format="tif"/></figure></drawings><search-report-data><doc-page id="srep0001" file="srep0001.tif" wi="158" he="233" type="tif"/><doc-page id="srep0002" file="srep0002.tif" wi="158" he="233" type="tif"/></search-report-data><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
