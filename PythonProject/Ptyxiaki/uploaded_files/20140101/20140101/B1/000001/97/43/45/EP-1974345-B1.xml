<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-1974345-B1" country="EP" doc-number="1974345" kind="B1" date="20140101" family-id="38287846" file-reference-id="311113" date-produced="20180826" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="146553521" ucid="EP-1974345-B1"><document-id><country>EP</country><doc-number>1974345</doc-number><kind>B1</kind><date>20140101</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-07701036-A" is-representative="NO"><document-id mxw-id="PAPP154827444" load-source="docdb" format="epo"><country>EP</country><doc-number>07701036</doc-number><kind>A</kind><date>20070119</date><lang>EN</lang></document-id><document-id mxw-id="PAPP220146701" load-source="docdb" format="original"><country>EP</country><doc-number>07701036.1</doc-number><date>20070119</date></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC140451376" ucid="KR-2007000349-W" linkage-type="W" load-source="docdb"><document-id format="epo"><country>KR</country><doc-number>2007000349</doc-number><kind>W</kind><date>20070119</date></document-id></priority-claim><priority-claim mxw-id="PPC140446514" ucid="US-75998006-P" load-source="docdb"><document-id format="epo"><country>US</country><doc-number>75998006</doc-number><kind>P</kind><date>20060119</date></document-id></priority-claim><priority-claim mxw-id="PPC140452410" ucid="US-77672406-P" load-source="docdb"><document-id format="epo"><country>US</country><doc-number>77672406</doc-number><kind>P</kind><date>20060227</date></document-id></priority-claim><priority-claim mxw-id="PPC140451207" ucid="US-77941706-P" load-source="docdb"><document-id format="epo"><country>US</country><doc-number>77941706</doc-number><kind>P</kind><date>20060307</date></document-id></priority-claim><priority-claim mxw-id="PPC140450268" ucid="US-77944106-P" load-source="docdb"><document-id format="epo"><country>US</country><doc-number>77944106</doc-number><kind>P</kind><date>20060307</date></document-id></priority-claim><priority-claim mxw-id="PPC140451051" ucid="US-77944206-P" load-source="docdb"><document-id format="epo"><country>US</country><doc-number>77944206</doc-number><kind>P</kind><date>20060307</date></document-id></priority-claim><priority-claim mxw-id="PPC140452065" ucid="US-78717206-P" load-source="docdb"><document-id format="epo"><country>US</country><doc-number>78717206</doc-number><kind>P</kind><date>20060330</date></document-id></priority-claim><priority-claim mxw-id="PPC140454741" ucid="US-78751606-P" load-source="docdb"><document-id format="epo"><country>US</country><doc-number>78751606</doc-number><kind>P</kind><date>20060331</date></document-id></priority-claim></priority-claims><dates-of-public-availability><intention-to-grant-date><date>20130723</date></intention-to-grant-date><search-report-dispatch-date><date>20111227</date></search-report-dispatch-date></dates-of-public-availability><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL1988118907" load-source="docdb">G10L  19/008       20130101AFI20130613BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1988137485" load-source="docdb">H04S   3/02        20060101ALI20130613BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL1988104748" load-source="docdb" scheme="CPC">H04S2420/01        20130101 LA20130922BHEP        </classification-cpc><classification-cpc mxw-id="PCL1988109677" load-source="docdb" scheme="CPC">G10L  19/008       20130101 LI20130922BHEP        </classification-cpc><classification-cpc mxw-id="PCL1988112005" load-source="docdb" scheme="CPC">H04S   3/02        20130101 FI20130922BHEP        </classification-cpc><classification-cpc mxw-id="PCL1988118619" load-source="docdb" scheme="CPC">H04S2400/15        20130101 LA20130922BHEP        </classification-cpc><classification-cpc mxw-id="PCL1988122497" load-source="docdb" scheme="CPC">H04S   1/007       20130101 LI20130101BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT132193047" lang="DE" load-source="patent-office">VERFAHREN UND VORRICHTUNG ZUR VERARBEITUNG EINES MEDIENSIGNALS</invention-title><invention-title mxw-id="PT132193048" lang="EN" load-source="patent-office">METHOD AND APPARATUS FOR PROCESSING A MEDIA SIGNAL</invention-title><invention-title mxw-id="PT132193049" lang="FR" load-source="patent-office">PROCÉDÉ ET APPAREIL POUR TRAITER UN SIGNAL MÉDIA</invention-title><citations><non-patent-citations><nplcit><text>"WD 2 for MPEG Surround", 73. MPEG MEETING;25-07-2005 - 29-07-2005; POZNAN; (MOTION PICTUREEXPERT GROUP OR ISO/IEC JTC1/SC29/WG11),, no. N7387, 29 July 2005 (2005-07-29), XP030013965, ISSN: 0000-0345</text><sources><source mxw-id="PNPL66918909" load-source="docdb" name="EXA"/></sources></nplcit><nplcit><text>J. BREEBAART, J. HERRE, C. FALLER, J. RÖDÉN, F. MYBURG, S. DISCH, H. PURNHAGEN, G. HOTHO, M. NEUSINGER, K. KJÖRLING, W.OOMEN: "MPEG Spatial Audio Coding / MPEG Surround:Overview and Current Status", AES, 119TH CONVENTION, 7 October 2005 (2005-10-07), XP040372928</text><sources><source mxw-id="PNPL66918910" load-source="docdb" name="EXA"/></sources></nplcit></non-patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR918173107" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>LG ELECTRONICS INC</last-name><address><country>KR</country></address></addressbook></applicant><applicant mxw-id="PPAR918138002" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>LG ELECTRONICS INC.</last-name></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR918158343" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>OH HYEN O</last-name><address><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR918150388" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>OH, HYEN O</last-name></addressbook></inventor><inventor mxw-id="PPAR918997088" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>OH, HYEN O</last-name><address><street>306-403, Hansin Apt., Gangseon-maeul 3-Danji Juyeop 1-dong, Ilsan-gu, Goyang-si</street><city>Gyeonggi-do 411-744</city><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR918147910" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>PANG HEE SUCK</last-name><address><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR918170005" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>PANG, HEE SUCK</last-name></addressbook></inventor><inventor mxw-id="PPAR918997090" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>PANG, HEE SUCK</last-name><address><street>Department of Electronics Engineering Sejong University Gunja-dong</street><city>Gwangjin-gu, Seoul 143-839</city><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR918171231" load-source="docdb" sequence="3" format="epo"><addressbook><last-name>KIM DONG SOO</last-name><address><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR918144818" load-source="docdb" sequence="3" format="intermediate"><addressbook><last-name>KIM, DONG SOO</last-name></addressbook></inventor><inventor mxw-id="PPAR918997086" load-source="patent-office" sequence="3" format="original"><addressbook><last-name>KIM, DONG SOO</last-name><address><street>502, Woolim Villa, 602-265 Namhyeon-dong, Gwanak-gu</street><city>Seoul 151-801</city><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR918149218" load-source="docdb" sequence="4" format="epo"><addressbook><last-name>LIM JAE HYUN</last-name><address><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR918156261" load-source="docdb" sequence="4" format="intermediate"><addressbook><last-name>LIM, JAE HYUN</last-name></addressbook></inventor><inventor mxw-id="PPAR918997089" load-source="patent-office" sequence="4" format="original"><addressbook><last-name>LIM, JAE HYUN</last-name><address><street>609, Parkville officetel, 1062-20 Namhyeon-dong, Gwanak-gu</street><city>Seoul 151-801</city><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR918160384" load-source="docdb" sequence="5" format="epo"><addressbook><last-name>JUNG YANG WON</last-name><address><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR918132914" load-source="docdb" sequence="5" format="intermediate"><addressbook><last-name>JUNG, YANG WON</last-name></addressbook></inventor><inventor mxw-id="PPAR918997087" load-source="patent-office" sequence="5" format="original"><addressbook><last-name>JUNG, YANG WON</last-name><address><street>2-803, Yeoksam Hanshin Apt. Dogok-dong, Gangnam-gu</street><city>Seoul 135-270</city><country>KR</country></address></addressbook></inventor></inventors><assignees><assignee mxw-id="PPAR918997092" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>LG Electronics Inc.</last-name><iid>100808671</iid><address><street>20 Yoido-dong</street><city>Youngdungpo-ku Seoul 150-721</city><country>KR</country></address></addressbook></assignee></assignees><agents><agent mxw-id="PPAR918997091" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Katérle, Axel</last-name><iid>100767217</iid><address><street>Wuesthoff &amp; Wuesthoff Patent- und Rechtsanwälte Schweigerstrasse 2</street><city>81541 München</city><country>DE</country></address></addressbook></agent></agents></parties><international-convention-data><pct-or-regional-filing-data ucid="KR-2007000349-W"><document-id><country>KR</country><doc-number>2007000349</doc-number><kind>W</kind><date>20070119</date><lang>EN</lang></document-id></pct-or-regional-filing-data><pct-or-regional-publishing-data ucid="WO-2007083959-A1"><document-id><country>WO</country><doc-number>2007083959</doc-number><kind>A1</kind><date>20070726</date><lang>EN</lang></document-id></pct-or-regional-publishing-data><designated-states><ep-contracting-states><country mxw-id="DS548978491" load-source="docdb">AT</country><country mxw-id="DS548863054" load-source="docdb">BE</country><country mxw-id="DS548975996" load-source="docdb">BG</country><country mxw-id="DS548829009" load-source="docdb">CH</country><country mxw-id="DS548863055" load-source="docdb">CY</country><country mxw-id="DS548978492" load-source="docdb">CZ</country><country mxw-id="DS548977893" load-source="docdb">DE</country><country mxw-id="DS548863056" load-source="docdb">DK</country><country mxw-id="DS548863057" load-source="docdb">EE</country><country mxw-id="DS548973330" load-source="docdb">ES</country><country mxw-id="DS548975997" load-source="docdb">FI</country><country mxw-id="DS548829010" load-source="docdb">FR</country><country mxw-id="DS548977898" load-source="docdb">GB</country><country mxw-id="DS548863058" load-source="docdb">GR</country><country mxw-id="DS548978493" load-source="docdb">HU</country><country mxw-id="DS548829011" load-source="docdb">IE</country><country mxw-id="DS548863059" load-source="docdb">IS</country><country mxw-id="DS548976002" load-source="docdb">IT</country><country mxw-id="DS548863060" load-source="docdb">LI</country><country mxw-id="DS548976003" load-source="docdb">LT</country><country mxw-id="DS548883996" load-source="docdb">LU</country><country mxw-id="DS548976004" load-source="docdb">LV</country><country mxw-id="DS548976005" load-source="docdb">MC</country><country mxw-id="DS548883997" load-source="docdb">NL</country><country mxw-id="DS548883998" load-source="docdb">PL</country><country mxw-id="DS548973331" load-source="docdb">PT</country><country mxw-id="DS548987680" load-source="docdb">RO</country><country mxw-id="DS548883999" load-source="docdb">SE</country><country mxw-id="DS548977899" load-source="docdb">SI</country><country mxw-id="DS548829012" load-source="docdb">SK</country><country mxw-id="DS548863061" load-source="docdb">TR</country></ep-contracting-states></designated-states></international-convention-data><office-specific-data><eptags><ep-no-a-document-published>*</ep-no-a-document-published></eptags></office-specific-data></bibliographic-data><description mxw-id="PDES63957249" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><heading id="h0001"><b>Technical Field</b></heading><p id="p0001" num="0001">The present invention relates to an apparatus for processing a media signal and method thereof, and more particularly to an apparatus for generating a surround signal by using spatial information of the media signal and method thereof.</p><heading id="h0002"><b>Background Art</b></heading><p id="p0002" num="0002">Generally, various kinds of apparatuses and methods have been widely used to generate a multi-channel media signal by using spatial information for the multi-channel media signal and a downmix signal, in which the downmix signal is generated by downmixing the multi-channel media signal into mono or stereo signal.</p><p id="p0003" num="0003">However, the above methods and apparatuses are not usable in environments unsuitable for generating a multi-channel signal. For instance, they are not usable for a device capable of generating only a stereo signal. In other words, there exists no method or apparatus for generating a surround signal, in which the surround signal has multi-channel features in the environment incapable of generating a multi-channel signal by using spatial information of the multi-channel signal.</p><p id="p0004" num="0004">Document <nplcit id="ncit0001" npl-type="s"><text>PASI OJALA: "New use cases for spatial audio coding", ITU STUDY GROUP 16 - VIDEO CODING EXPERTS GROUP -ISO/JEC MPEG &amp; ITU-T VCEG (ISO/IEC JTC1/SC29/WG11 AND ITU-T SG16 Q6)</text></nplcit> concerns a generic description of a SAC decoder. An input signal consisting of either one or two downmixed audio channels is first transformed into QMF domain after which the spatial parameters are applied to reconstruct a multi-channel audio which is further transformed into time domain using QMF synthesis.</p><p id="p0005" num="0005">Document <patcit id="pcit0001" dnum="WO2004028204A2"><text>WO 2004/028204 A2</text></patcit> concerns a method and a media system for generating at least one output signal from at least one input signal from a second set of sound signals having a related second set of Head Related Transfer Functions.</p><p id="p0006" num="0006">So, since there exists no method or apparatus for generating a surround signal in a device capable of generating only a mono or stereo signal, it is difficult to process the media signal efficiently.</p><heading id="h0003"><b>Disclosure of Invention</b></heading><heading id="h0004"><b>Technical Problem</b></heading><p id="p0007" num="0007">Accordingly, the present invention is directed to an apparatus for processing an audio signal and method as claimed in claims 1 and 6 thereof as claimed in claims 1 and 6 that substantially obviate one or more of the problems due to limitations and disadvantages of the related art.</p><p id="p0008" num="0008">An object of the present invention is to provide an apparatus for processing a media signal and method thereof, by which the media signal can be converted to a surround signal by using spatial information for the media signal.</p><p id="p0009" num="0009">Additional features and advantages of the invention will be set forth in a description which follows, and in part will be apparent from the description, or may be learned by practice of the invention. The objectives and other advantages of the invention will be realized and attained by the structure particularly pointed out in the written description and claims thereof as well as the appended drawings.</p><heading id="h0005"><b>Technical Solution</b></heading><p id="p0010" num="0010">To achieve these and other advantages and in accordance with the purpose of the<!-- EPO <DP n="2"> --><!-- EPO <DP n="3"> --> present invention, a method of processing a signal according to the present invention includes of: generating source mapping information corresponding to each source of multi-sources by using spatial information indicating features between the multi-sources; generating sub-rendering information by applying filter information giving a surround effect to the source mapping information per the source; generating rendering information for generating a surround signal by integrating at least one of the sub-rendering information; and generating the surround signal by applying the rendering information to a downmix signal generated by downmixing the multi-sources.</p><p id="p0011" num="0011">To further achieve these and other advantages and in accordance with the purpose of the present invention, an apparatus for processing a signal includes a source map ping unit generating source mapping information corresponding to each source of multi-sources by using spatial information indicating features between the multi-sources; a sub-rendering information generating unit generating sub-rendering information by applying filter information having a surround effect to the source mapping information per the source; an integrating unit generating rendering information for generating a surround signal by integrating the at least one of the sub-rendering information; and a rendering unit generating the surround signal by applying the rendering information to a downmix signal generated by downmixing the multi-sources.</p><p id="p0012" num="0012">It is to be understood that both the foregoing general description and the following detailed description are exemplary and explanatory and are intended to provide further explanation of the invention as claimed.</p><heading id="h0006"><b>Advantageous Effects</b></heading><p id="p0013" num="0013">A signal processing apparatus and method according to the present invention enable a decoder, which receives a bitstream including a downmix signal generated by downmixing a multi-channel signal and spatial information of the multi-channel signal, to generate a signal having a surround effect in environments in incapable of recovering the multi-channel signal.</p><heading id="h0007"><b>Brief Description of the Drawings</b></heading><p id="p0014" num="0014">The accompanying drawings, which are included to provide a further understanding of the invention and are incorporated in and constitute a part of this specification, illustrate embodiments of the invention and together with the description serve to explain the principles of the invention.</p><p id="p0015" num="0015">In the drawings:</p><p id="p0016" num="0016"><figref idrefs="f0001">FIG. 1</figref> is a block diagram of an audio signal encoding apparatus and an audio signal decoding apparatus according to one embodiment of the present invention;</p><p id="p0017" num="0017"><figref idrefs="f0001">FIG. 2</figref> is a structural diagram of a bitstream of an audio signal according to one<!-- EPO <DP n="4"> --> embodiment of the present invention;</p><p id="p0018" num="0018"><figref idrefs="f0002">FIG. 3</figref> is a detailed block diagram of a spatial information converting unit according to one embodiment of the present invention;</p><p id="p0019" num="0019"><figref idrefs="f0002">FIG. 4</figref> and <figref idrefs="f0003">FIG. 5</figref> are block diagrams of channel configurations used for source mapping process according to one embodiment of the present invention;</p><p id="p0020" num="0020"><figref idrefs="f0003">FIG. 6 and FIG. 7</figref> are detailed block diagrams of a rendering unit for a stereo downmix signal according to one embodiment of the present invention;</p><p id="p0021" num="0021"><figref idrefs="f0004">FIG. 8 and FIG. 9</figref> are detailed block diagrams of a rendering unit for a mono downmix signal according to one embodiment of the present invention;</p><p id="p0022" num="0022"><figref idrefs="f0004">FIG. 10 and FIG. 11</figref> are block diagrams of a smoothing unit and an expanding unit according to one embodiment of the present invention;</p><p id="p0023" num="0023"><figref idrefs="f0005">FIG. 12</figref> is a graph to explain a first smoothing method according to one embodiment of the present invention;</p><p id="p0024" num="0024"><figref idrefs="f0005">FIG. 13</figref> is a graph to explain a second smoothing method according to one embodiment of the present invention;</p><p id="p0025" num="0025"><figref idrefs="f0005">FIG. 14</figref> is a graph to explain a third smoothing method according to one embodiment of the present invention;</p><p id="p0026" num="0026"><figref idrefs="f0005">FIG. 15</figref> is a graph to explain a fourth smoothing method according to one embodiment of the present invention;</p><p id="p0027" num="0027"><figref idrefs="f0006">FIG. 16</figref> is a graph to explain a fifth smoothing method according to one embodiment of the present invention;</p><p id="p0028" num="0028"><figref idrefs="f0006">FIG. 17</figref> is a diagram to explain prototype filter information corresponding to each channel;</p><p id="p0029" num="0029"><figref idrefs="f0007">FIG. 18</figref> is a block diagram for a first method of generating rendering filter information in a spatial information converting unit according to one embodiment of the present invention;</p><p id="p0030" num="0030"><figref idrefs="f0008">FIG. 19</figref> is a block diagram for a second method of generating rendering filter information in a spatial information converting unit according to one embodiment of the present invention;</p><p id="p0031" num="0031"><figref idrefs="f0009">FIG. 20</figref> is a block diagram for a third method of generating rendering filter information in a spatial information converting unit according to one embodiment of the present invention;</p><p id="p0032" num="0032"><figref idrefs="f0010">FIG. 21</figref> is a diagram to explain a method of generating a surround signal in a rendering unit according to one embodiment of the present invention;</p><p id="p0033" num="0033"><figref idrefs="f0010">FIG. 22</figref> is a diagram for a first interpolating method according to one embodiment of the present invention;</p><p id="p0034" num="0034"><figref idrefs="f0011">FIG. 23</figref> is a diagram for a second interpolating method according to one embodiment of the present invention;<!-- EPO <DP n="5"> --></p><p id="p0035" num="0035"><figref idrefs="f0011">FIG. 24</figref> is a diagram for a block switching method according to one embodiment of the present invention;</p><p id="p0036" num="0036"><figref idrefs="f0012">FIG. 25</figref> is a block diagram for a position to which a window length decided by a window length deciding unit is applied according to one embodiment of the present invention;</p><p id="p0037" num="0037"><figref idrefs="f0012">FIG. 26</figref> is a diagram for filters having various lengths used in processing an audio signal according to one embodiment of the present invention;</p><p id="p0038" num="0038"><figref idrefs="f0013">FIG. 27</figref> is a diagram for a method of processing an audio signal dividedly by using a plurality of subfilters according to one embodiment of the present invention;</p><p id="p0039" num="0039"><figref idrefs="f0013">FIG. 28</figref> is a block diagram for a method of rendering partition rendering information generated by a plurality of subfilters to a mono downmix signal according to one embodiment of the present invention;</p><p id="p0040" num="0040"><figref idrefs="f0014">FIG. 29</figref> is a block diagram for a method of rendering partition rendering information generated by a plurality of subfilters to a stereo downmix signal according to one embodiment of the present invention;</p><p id="p0041" num="0041"><figref idrefs="f0014">FIG. 30</figref> is a block diagram for a first domain converting method of a downmix signal according to one embodiment of the present invention; and</p><p id="p0042" num="0042"><figref idrefs="f0015">FIG. 31</figref> is a block diagram for a second domain converting method of a downmix signal according to one embodiment of the present invention.</p><heading id="h0008"><b>Best Mode for Carrying Out the Invention</b></heading><p id="p0043" num="0043">Reference will now be made in detail to the preferred embodiments of the present invention, examples of which are illustrated in the accompanying drawings.</p><p id="p0044" num="0044"><figref idrefs="f0001">FIG. 1</figref> is a block diagram of an audio signal encoding apparatus and an audio signal decoding apparatus according to one embodiment of the present invention.</p><p id="p0045" num="0045">Referring to <figref idrefs="f0001">FIG. 1</figref>, an encoding apparatus 10 includes a downmixing unit 100, a spatial information generating unit 200, a downmix signal encoding unit 300, a spatial information encoding unit 400, and a multiplexing unit 500.</p><p id="p0046" num="0046">If multi-source(X1, X2, ..., Xn) audio signal is inputted to the downmixing unit 100, the downmixing unit 100 downmixes the inputted signal into a downmix signal. In this case, the downmix signal includes mono, stereo and multi-source audio signal.</p><p id="p0047" num="0047">The source includes a channel and ,in convenience, is represented as a channel in the following description. In the present specification, the mono or stereo downmix signal is referred to as a reference. Yet, the present invention is not limited to the mono or stereo downmix signal.</p><p id="p0048" num="0048">The encoding apparatus 10 is able to optionally use an arbitrary downmix signal directly provided from an external environment.</p><p id="p0049" num="0049">The spatial information generating unit 200 generates spatial information from a<!-- EPO <DP n="6"> --> multi-channel audio signal. The spatial information can be generated in the course of a downmixing process. The generated downmix signal and spatial information are encoded by the downmix signal encoding unit 300 and the spatial information encoding unit 400, respectively and are then transferred to the multiplexing unit 500.</p><p id="p0050" num="0050">In the present invention, 'spatial information' means information necessary to generate a multi-channel signal from upmixing a downmix signal by a decoding apparatus, in which the downmix signal is generated by downmixing the multi-channel signal by an encoding apparatus and transferred to the decoding apparatus. The spatial information includes spatial parameters. The spatial parameters include CLD(channel level difference) indicating an energy difference between channels, ICC(inter-channel coherences) indicating a correlation between channels, CPC(channel prediction coefficients) used in generating three channels from two channels, etc.</p><p id="p0051" num="0051">In the present invention, 'downmix signal encoding unit' or 'downmix signal decoding unit' means a codec that encodes or decodes an audio signal instead of spatial information. In the present specification, a downmix audio signal is taken as an example of the audio signal instead of the spatial information. And, the downmix signal encoding or decoding unit may include MP3, AC-3, DTS, or AAC. Moreover, the downmix signal encoding or decoding unit may include a codec of the future as well as the previously developed codec.</p><p id="p0052" num="0052">The multiplexing unit 500 generates a bitstream by multiplexing the downmix signal and the spatial information and then transfers the generated bitstream to the decoding apparatus 20. Besides, the structure of the bitstream will be explained in <figref idrefs="f0001">FIG. 2</figref> later.</p><p id="p0053" num="0053">A decoding apparatus 20 includes a demultiplexing unit 600, a downmix signal decoding unit 700, a spatial information decoding unit 800, a rendering unit 900, and a spatial information converting unit 1000.</p><p id="p0054" num="0054">The demultiplexing unit 600 receives a bitstream and then separates an encoded downmix signal and an encoded spatial information from the bitstream. Subsequently, the downmix signal decoding unit 700 decodes the encoded downmix signal and the spatial information decoding unit 800 decodes the encoded spatial information.</p><p id="p0055" num="0055">The spatial information converting unit 1000 generates rendering information applicable to a downmix signal using the decoded spatial information and filter information. In this case, the rendering information is applied to the downmix signal to generate a surround signal.</p><p id="p0056" num="0056">For instance, the surround signal is generated in the following manner. First of all, a process for generating a downmix signal from a multi-channel audio signal by the encoding apparatus 10 can include several steps using an OTT (one-to-two) or TTT (three-to-three) box. In this case, spatial information can be generated from each of the<!-- EPO <DP n="7"> --> steps. The spatial information is transferred to the decoding apparatus 20. The decoding apparatus 20 then generates a surround signal by converting the spatial information and then rendering the converted spatial information with a downmix signal. Instead of generating a multi-channel signal by upmixing a downmix signal, the present invention relates to a rendering method including the steps of extracting spatial information for each upmixing step and performing a rendering by using the extracted spatial information. For example, HRTF (head-related transfer functions) filtering is usable in the rendering method.</p><p id="p0057" num="0057">In this case, the spatial information is a value applicable to a hybrid domain as well. So, the rendering can be classified into the following types according to a domain.</p><p id="p0058" num="0058">The first type is that the rendering is executed on a hybrid domain by having a downmix signal pass through a hybrid filterbank. In this case, a conversion of domain for spatial information is unnecessary.</p><p id="p0059" num="0059">The second type is that the rendering is executed on a time domain. In this case, the second type uses a fact that a HRTF filter is modeled as a FIR (finite inverse response) filter or an IIR (infinite inverse response) filter on a time domain. So, a process for converting spatial information to a filter coefficient of time domain is needed.</p><p id="p0060" num="0060">The third type is that the rendering is executed on a different frequency domain. For instance, the rendering is executed on a DFT (discrete Fourier transform) domain. In this case, a process for transforming spatial information into a corresponding domain is necessary. In particular, the third type enables a fast operation by replacing a filtering on a time domain into an operation on a frequency domain.</p><p id="p0061" num="0061">In the present invention, filter information is the information for a filter necessary for processing an audio signal and includes a filter coefficient provided to a specific filter. Examples of the filter information are explained as follows. First of all, prototype filter information is original filter information of a specific filter and can be represented as GL_L or the like. Converted filter information indicates a filter coefficient after the prototype filter information has been converted and can be represented as GL_L or the like. Sub-rendering information means the filter information resulting from spatializing the prototype filter information to generate a surround signal and can be represented as FL_L1 or the like. Rendering information means the filter information necessary for executing rendering and can be represented as HL_L or the like. Interpolated/smoothed rendering information means the filter information resulting from interpolation/smoothing the rendering information and can be represented as HL_L or the like. In the present specification, the above filter informations are referred to. Yet, the present invention is not restricted by the names of the filter informations. In particular, HRTF is taken as an example of the filter information. Yet, the present invention is not limited to the HRTF.<!-- EPO <DP n="8"> --></p><p id="p0062" num="0062">The rendering unit 900 receives the decoded downmix signal and the rendering information and then generates a surround signal using the decoded downmix signal and the rendering information. The surround signal may be the signal for providing a surround effect to an audio system capable of generating only a stereo signal. Besides, the present invention can be applied to various systems as well as the audio system capable of generating only the stereo signal.</p><p id="p0063" num="0063"><figref idrefs="f0001">FIG. 2</figref> is a structural diagram for a bitstream of an audio signal according to one embodiment of the present invention, in which the bitstream includes an encoded downmix signal and encoded spatial information.</p><p id="p0064" num="0064">Referring to <figref idrefs="f0001">FIG. 2</figref>, a 1-frame audio payload includes a downmix signal field and an ancillary data field. Encoded spatial information can be stored in the ancillary data field. For instance, if an audio payload is 48∼128kbps, spatial information can have a range of 5-32kbps. Yet, no limitations are put on the ranges of the audio payload and spatial information.</p><p id="p0065" num="0065"><figref idrefs="f0002">FIG. 3</figref> is a detailed block diagram of a spatial information converting unit according to one embodiment of the present invention.</p><p id="p0066" num="0066">Referring to <figref idrefs="f0002">FIG. 3</figref>, a spatial information converting unit 1000 includes a source mapping unit 1010, a sub-rendering information generating unit 1020, an integrating unit 1030, a processing unit 1040, and a domain converting unit 1050.</p><p id="p0067" num="0067">The source mapping unit 101 generates source mapping information corresponding to each source of an audio signal by executing source mapping using spatial information. In this case, the source mapping information means per-source information generated to correspond to each source of an audio signal by using spatial information and the like. The source includes a channel and, in this case, the source mapping information corresponding to each channel is generated. The source mapping information can be represented as a coefficient. And, the source mapping process will be explained in detail later with reference to <figref idrefs="f0002">FIG. 4</figref> and <figref idrefs="f0003">FIG. 5</figref>.</p><p id="p0068" num="0068">The sub-rendering information generating unit 1020 generates sub-rendering information corresponding to each source by using the source mapping information and the filter information. For instance, if the rendering unit 900 is the HRTF filter, the sub-rendering information generating unit 1020 is able to generate sub-rendering information by using HRTF filter information.</p><p id="p0069" num="0069">The integrating unit 1030 generates rendering information by integrating the sub-rendering information to correspond to each source of a downmix signal. The rendering information, which is generated by using the spatial information and the filter information, means the information to generate a surround signal by being applied to the downmix signal. And, the rendering information includes a filter coefficient type. The integration can be omitted to reduce an operation quantity of the<!-- EPO <DP n="9"> --> rendering process. Subsequently, the rendering information is transferred to the processing unit 1042.</p><p id="p0070" num="0070">The processing unit 1042 includes an interpolating unit 1041 and/or a smoothing unit 1042. The rendering information is interpolated by the interpolating unit 1041 and/or smoothed by the smoothing unit 1042.</p><p id="p0071" num="0071">The domain converting unit 1050 converts a domain of the rendering information to a domain of the downmix signal used by the rendering unit 900. And, the domain converting unit 1050 can be provided to one of various positions including the position shown in <figref idrefs="f0002">FIG. 3</figref>. So, if the rendering information is generated on the same domain of the rendering unit 900, it is able to omit the domain converting unit 1050. The domain-converted rendering information is then transferred to the rendering unit 900.</p><p id="p0072" num="0072">The spatial information converting unit 1000 can include a filter information converting unit 1060. In <figref idrefs="f0002">FIG. 3</figref>, the filter information converting unit 1060 is provided within the spatial information converting unit 100. Alternatively, the filter information converting unit 1060 can be provided outside the spatial information converting unit 100. The filter information converting unit 1060 is converted to be suitable for generating sub-rendering information or rendering information from random filter information, e.g., HRTF. The converting process of the filter information can include the following steps.</p><p id="p0073" num="0073">First of all, a step of matching a domain to be applicable is included. If a domain of filter information does not match a domain for executing rendering, the domain matching step is required. For instance, a step of converting time domain HRTF to DFT, QMF or hybrid domain for generating rendering information is necessary.</p><p id="p0074" num="0074">Secondly, a coefficient reducing step can be included. In this case, it is easy to save the domain-converted HRTF and apply the domain-converted HRTF to spatial information. For instance, if a prototype filter coefficient has a response of a long tap number (length), a corresponding coefficient has to be stored in a memory corresponding to a response amounting to a corresponding length of total 10 in case of 5.1 channels. This increases a load of the memory and an operational quantity. To prevent this problem, a method of reducing a filter coefficient to be stored while maintaining filter characteristics in the domain converting process can be used. For instance, the HRTF response can be converted to a few parameter value. In this case, a parameter generating process and a parameter value can differ according to an applied domain.</p><p id="p0075" num="0075">The downmix signal passes through a domain converting unit 1110 and/or a decorrelating unit 1200 before being rendered with the rendering information. In case that a domain of the rendering information is different from that of the downmix signal, the domain converting unit 1110 converts the domain of the downmix signal in order to match the two domains together.<!-- EPO <DP n="10"> --></p><p id="p0076" num="0076">The decorrelating unit 1200 is applied to the domain-converted downmix signal. This may have an operational quantity relatively higher than that of a method of applying a decorrelator to the rendering information. Yet, it is able to prevent distortions from occurring in the process of generating rendering information. The decorrelating unit 1200 can include a plurality of decorrelators differing from each other in characteristics if an operational quantity is allowable. If the downmix signal is a stereo signal, the decorrelating unit 1200 may not be used. In <figref idrefs="f0002">FIG. 3</figref>, in case that a domain-converted mono downmix signal, i.e., a mono downmix signal on a frequency, hybrid, QMF or DFT domain is used in the rendering process, a decorrelator is used on the corresponding domain. And, the present invention includes a decorrelator used on a time domain as well. In this case, a mono downmix signal before the domain converting unit 1100 is directly inputted to the decorrelating unit 1200. A first order or higher IIR filter (or FIR filter) is usable as the decorrelator.</p><p id="p0077" num="0077">Subsequently, the rendering unit 900 generates a surround signal using the downmix signal, the decorrelated downmix signal, and the rendering information. If the downmix signal is a stereo signal, the decorrelated downmix signal may not be used. Details of the rendering process will be described later with reference to <figref idrefs="f0003 f0004">FIGs. 6 to 9</figref>.</p><p id="p0078" num="0078">The surround signal is converted to a time domain by an inverse domain converting unit 1300 and then outputted. If so, a user is able to listen to a sound having a multi-channel effect though stereophonic earphones or the like.</p><p id="p0079" num="0079"><figref idrefs="f0002">FIG. 4</figref> and <figref idrefs="f0003">FIG. 5</figref> are block diagrams of channel configurations used for source mapping process according to one embodiment of the present invention. A source mapping process is a process for generating source mapping information corresponding to each source of an audio signal by using spatial information. As mentioned in the foregoing description, the source includes a channel and source mapping information can be generated to correspond to the channels shown in <figref idrefs="f0002">FIG. 4</figref> and <figref idrefs="f0003">FIG. 5</figref>. The source mapping information is generated in a type suitable for a rendering process.</p><p id="p0080" num="0080">For instance, if a downmix signal is a mono signal, it is able to generate source mapping information using spatial information such as CLD1∼CLD5, ICC1~ICC5, and the like.</p><p id="p0081" num="0081">The source mapping information can be represented as such a value as D_L (=D<sub>L</sub>), D_R (=D<sub>R</sub>), D_C (=D<sub>C</sub>), D_LFE (=D<sub>LFE</sub>), D_Ls (=D<sub>Ls</sub>), D_Rs (=D<sub>Rs</sub>), and the like. In this case, the process for generating the source mapping information is variable according to a tree structure corresponding to spatial information, a range of spatial information to be used, and the like. In the present specification, the downmix signal is a mono signal for example, which does not put limitation of the present invention.<!-- EPO <DP n="11"> --></p><p id="p0082" num="0082">Right and left channel outputs outputted from the rendering unit 900 can be expressed as Math <figref idrefs="f0001">Figure 1</figref>.</p><p id="p0083" num="0083"><maths id="math0001" num="MathFigure 1"><math display="block"><mtable><mtr><mtd><mi>Lo</mi><mo>=</mo><mi mathvariant="normal">L</mi><mo>*</mo><mi mathvariant="normal">GL_Lʹ</mi><mo>+</mo><mi mathvariant="normal">C</mi><mo>*</mo><mi mathvariant="normal">GC_Lʹ</mi><mo>+</mo><mi mathvariant="normal">R</mi><mo>*</mo><mi mathvariant="normal">GR_Lʹ</mi><mo>+</mo><mi>Ls</mi><mo>*</mo><mi mathvariant="normal">GLs_Lʹ</mi><mo>+</mo><mi>Rs</mi><mo>*</mo><mi mathvariant="normal">GRs_Lʹ</mi></mtd></mtr><mtr><mtd><mi>Ro</mi><mo>=</mo><mi mathvariant="normal">L</mi><mo>*</mo><mi mathvariant="normal">GL_Rʹ</mi><mo>+</mo><mi mathvariant="normal">C</mi><mo>*</mo><mi mathvariant="normal">GC_Rʹ</mi><mo>+</mo><mi mathvariant="normal">R</mi><mo>*</mo><mi mathvariant="normal">GR_Rʹ</mi><mo>+</mo><mi>Ls</mi><mo>*</mo><mi mathvariant="normal">GLs_Rʹ</mi><mo>+</mo><mi>Rs</mi><mo>*</mo><mi mathvariant="normal">GRs_Rʹ</mi></mtd></mtr></mtable></math><img id="ib0001" file="imgb0001.tif" wi="128" he="26" img-content="math" img-format="tif"/></maths></p><p id="p0084" num="0084">In this case, the operator '*' indicates a product on a DFT domain and can be replaced by a convolution on a QMF or time domain.</p><p id="p0085" num="0085">The present invention includes a method of generating the L, C, R, Ls and Rs by source mapping information using spatial information or by source mapping information using spatial information and filter information. For instance, source mapping information can be generated using CLD of spatial information only or CLD and ICC of spatial information. The method of generating source mapping information using the CLD only is explained as follows.</p><p id="p0086" num="0086">In case that the tree structure has a structure shown in <figref idrefs="f0002">FIG. 4</figref>, a first method of obtaining source mapping information using CLD only can be expressed as Math <figref idrefs="f0001">Figure 2</figref>.</p><p id="p0087" num="0087"><maths id="math0002" num="MathFigure 2"><math display="block"><mfenced open="[" close="]"><mtable><mtr><mtd><mi>L</mi></mtd></mtr><mtr><mtd><mi>R</mi></mtd></mtr><mtr><mtd><mi>C</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">LFE</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">Ls</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">Rs</mi></mtd></mtr></mtable></mfenced><mo>=</mo><mfenced open="[" close="]"><mtable><mtr><mtd><msub><mi>D</mi><mi>L</mi></msub></mtd></mtr><mtr><mtd><msub><mi>D</mi><mi>R</mi></msub></mtd></mtr><mtr><mtd><msub><mi>D</mi><mi>C</mi></msub></mtd></mtr><mtr><mtd><msub><mi>D</mi><mi mathvariant="italic">LFE</mi></msub></mtd></mtr><mtr><mtd><msub><mi>D</mi><mi mathvariant="italic">Ls</mi></msub></mtd></mtr><mtr><mtd><msub><mi>D</mi><mi mathvariant="italic">Rs</mi></msub></mtd></mtr></mtable></mfenced><mo>⁢</mo><mi>m</mi><mo>=</mo><mfenced open="[" close="]"><mtable><mtr><mtd><msub><mi>c</mi><mrow><mn>1</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>3</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>1</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>1</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>0</mn></mrow></msub></mtd></mtr><mtr><mtd><msub><mi>c</mi><mrow><mn>2</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>3</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>1</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>1</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>0</mn></mrow></msub></mtd></mtr><mtr><mtd><msub><mi>c</mi><mrow><mn>1</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>4</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>2</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>1</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>0</mn></mrow></msub></mtd></mtr><mtr><mtd><msub><mi>c</mi><mrow><mn>2</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>4</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>2</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>1</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>0</mn></mrow></msub></mtd></mtr><mtr><mtd><msub><mi>c</mi><mrow><mn>1</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>2</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>2</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>0</mn></mrow></msub></mtd></mtr><mtr><mtd><msub><mi>c</mi><mrow><mn>2</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>2</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>2</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>0</mn></mrow></msub></mtd></mtr></mtable></mfenced><mo>⁢</mo><mi>m</mi></math><img id="ib0002" file="imgb0002.tif" wi="103" he="65" img-content="math" img-format="tif"/></maths></p><p id="p0088" num="0088">In this case, <maths id="math0003" num=""><math display="block"><msubsup><mi>c</mi><mrow><mn>1</mn><mo>,</mo><msub><mi mathvariant="italic">OTT</mi><mi>X</mi></msub></mrow><mrow><mi>l</mi><mo>,</mo><mi>m</mi></mrow></msubsup><mo>=</mo><msqrt><mfrac><msup><mn>10</mn><mfrac><msubsup><mi mathvariant="italic">CLD</mi><mi>X</mi><mrow><mi>l</mi><mo>,</mo><mi>m</mi></mrow></msubsup><mn>10</mn></mfrac></msup><mrow><mn>1</mn><mo>+</mo><msup><mn>10</mn><mfrac><msubsup><mi mathvariant="italic">CLD</mi><mi>X</mi><mrow><mi>l</mi><mo>,</mo><mi>m</mi></mrow></msubsup><mn>10</mn></mfrac></msup></mrow></mfrac></msqrt></math><img id="ib0003" file="imgb0003.tif" wi="53" he="41" img-content="math" img-format="tif"/></maths><!-- EPO <DP n="12"> --> <maths id="math0004" num=""><math display="block"><msubsup><mi>c</mi><mrow><mn>2</mn><mo>,</mo><msub><mi mathvariant="italic">OTT</mi><mi>X</mi></msub></mrow><mrow><mi>l</mi><mo>,</mo><mi>m</mi></mrow></msubsup><mo>=</mo><msqrt><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mn>10</mn><mfrac><msubsup><mi mathvariant="italic">CLD</mi><mi>X</mi><mrow><mi>l</mi><mo>,</mo><mi>m</mi></mrow></msubsup><mn>10</mn></mfrac></msup></mrow></mfrac></msqrt></math><img id="ib0004" file="imgb0004.tif" wi="62" he="30" img-content="math" img-format="tif"/></maths><br/>
and 'm' indicates a mono downmix signal.</p><p id="p0089" num="0089">In case that the tree structure has a structure shown in <figref idrefs="f0003">FIG. 5</figref>, a second method of obtaining source mapping information using CLD only can be expressed as Math <figref idrefs="f0002">Figure 3</figref>.</p><p id="p0090" num="0090"><maths id="math0005" num="MathFigure 3"><math display="block"><mfenced open="[" close="]"><mtable><mtr><mtd><mi>L</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">Ls</mi></mtd></mtr><mtr><mtd><mi>R</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">Rs</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">C</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">LFE</mi></mtd></mtr></mtable></mfenced><mo>=</mo><mfenced open="[" close="]"><mtable><mtr><mtd><msub><mi>D</mi><mi>L</mi></msub></mtd></mtr><mtr><mtd><msub><mi>D</mi><mi mathvariant="italic">Ls</mi></msub></mtd></mtr><mtr><mtd><msub><mi>D</mi><mi>R</mi></msub></mtd></mtr><mtr><mtd><msub><mi>D</mi><mi mathvariant="italic">Rs</mi></msub></mtd></mtr><mtr><mtd><msub><mi>D</mi><mi mathvariant="italic">C</mi></msub></mtd></mtr><mtr><mtd><msub><mi>D</mi><mi mathvariant="italic">LFE</mi></msub></mtd></mtr></mtable></mfenced><mo>⁢</mo><mi>m</mi><mo>=</mo><mfenced open="[" close="]"><mtable><mtr><mtd><msub><mi>c</mi><mrow><mn>1</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>3</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>1</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>1</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>0</mn></mrow></msub></mtd></mtr><mtr><mtd><msub><mi>c</mi><mrow><mn>2</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>3</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>1</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>1</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>0</mn></mrow></msub></mtd></mtr><mtr><mtd><msub><mi>c</mi><mrow><mn>1</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>4</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>2</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>1</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>0</mn></mrow></msub></mtd></mtr><mtr><mtd><msub><mi>c</mi><mrow><mn>2</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>4</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>2</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>1</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>0</mn></mrow></msub></mtd></mtr><mtr><mtd><msub><mi>c</mi><mrow><mn>1</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>2</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>2</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>0</mn></mrow></msub></mtd></mtr><mtr><mtd><msub><mi>c</mi><mrow><mn>2</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>2</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>2</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>0</mn></mrow></msub></mtd></mtr></mtable></mfenced><mo>⁢</mo><mi>m</mi></math><img id="ib0005" file="imgb0005.tif" wi="105" he="68" img-content="math" img-format="tif"/></maths></p><p id="p0091" num="0091">If source mapping information is generated using CLD only, a 3-dimensional effect may be reduced. So, it is able to generate source mapping information using ICC and/ or decorrelator. And, a multi-channel signal generated by using a decorrelator output signal dx(m) can be expresses as Math <figref idrefs="f0002">Figure 4</figref>.</p><p id="p0092" num="0092"><maths id="math0006" num="MathFigure 4"><math display="block"><mfenced open="[" close="]"><mtable><mtr><mtd><mi>L</mi></mtd></mtr><mtr><mtd><mi>R</mi></mtd></mtr><mtr><mtd><mi>C</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">LFE</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">Ls</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">Rs</mi></mtd></mtr></mtable></mfenced><mo>=</mo><mfenced open="[" close="]"><mtable><mtr><mtd><msub><mi>A</mi><mrow><mi>L</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><mi>m</mi><mo>+</mo><msub><mi>B</mi><mrow><mi>L</mi><mo>⁢</mo><mn>0</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>0</mn></msub><mfenced><mi>m</mi></mfenced><mo>+</mo><msub><mi>B</mi><mrow><mi>L</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>1</mn></msub><mfenced separators=""><msub><mi>C</mi><mrow><mi>L</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><mi>m</mi></mfenced><mo>+</mo><msub><mi>B</mi><mrow><mi>L</mi><mo>⁢</mo><mn>3</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>3</mn></msub><mfenced separators=""><msub><mi>C</mi><mrow><mi>L</mi><mo>⁢</mo><mn>3</mn></mrow></msub><mo>⁢</mo><mi>m</mi></mfenced></mtd></mtr><mtr><mtd><msub><mi>A</mi><mrow><mi>R</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><mi>m</mi><mo>+</mo><msub><mi>B</mi><mrow><mi>R</mi><mo>⁢</mo><mn>0</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>0</mn></msub><mfenced><mi>m</mi></mfenced><mo>+</mo><msub><mi>B</mi><mrow><mi>R</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>1</mn></msub><mfenced separators=""><msub><mi>C</mi><mrow><mi>R</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><mi>m</mi></mfenced><mo>+</mo><msub><mi>B</mi><mrow><mi>R</mi><mo>⁢</mo><mn>3</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>3</mn></msub><mfenced separators=""><msub><mi>C</mi><mrow><mi>R</mi><mo>⁢</mo><mn>3</mn></mrow></msub><mo>⁢</mo><mi>m</mi></mfenced></mtd></mtr><mtr><mtd><msub><mi>A</mi><mrow><mi>C</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><mi>m</mi><mo>+</mo><msub><mi>B</mi><mrow><mi>C</mi><mo>⁢</mo><mn>0</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>0</mn></msub><mfenced><mi>m</mi></mfenced><mo>+</mo><msub><mi>B</mi><mrow><mi>C</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>1</mn></msub><mfenced separators=""><msub><mi>C</mi><mrow><mi>C</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><mi>m</mi></mfenced></mtd></mtr><mtr><mtd><msub><mi>c</mi><mrow><mn>2</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>4</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>2</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>1</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>0</mn></mrow></msub><mo>⁢</mo><mi>m</mi></mtd></mtr><mtr><mtd><msub><mi>A</mi><mrow><mi mathvariant="italic">LS</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><mi>m</mi><mo>+</mo><msub><mi>B</mi><mrow><mi mathvariant="italic">LS</mi><mo>⁢</mo><mn>0</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>0</mn></msub><mfenced><mi>m</mi></mfenced><mo>+</mo><msub><mi>B</mi><mrow><mi mathvariant="italic">LS</mi><mo>⁢</mo><mn>2</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>2</mn></msub><mfenced separators=""><msub><mi>C</mi><mrow><mi mathvariant="italic">LS</mi><mo>⁢</mo><mn>2</mn></mrow></msub><mo>⁢</mo><mi>m</mi></mfenced></mtd></mtr><mtr><mtd><msub><mi>A</mi><mrow><mi mathvariant="italic">RS</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><mi>m</mi><mo>+</mo><msub><mi>B</mi><mrow><mi mathvariant="italic">RS</mi><mo>⁢</mo><mn>0</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>0</mn></msub><mfenced><mi>m</mi></mfenced><mo>+</mo><msub><mi>B</mi><mrow><mi mathvariant="italic">RS</mi><mo>⁢</mo><mn>2</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>2</mn></msub><mfenced separators=""><msub><mi>C</mi><mrow><mi mathvariant="italic">RS</mi><mo>⁢</mo><mn>2</mn></mrow></msub><mo>⁢</mo><mi>m</mi></mfenced></mtd></mtr></mtable></mfenced></math><img id="ib0006" file="imgb0006.tif" wi="105" he="51" img-content="math" img-format="tif"/></maths></p><p id="p0093" num="0093">In this case, 'A', 'B' and 'C' are values that can be represented by using CLD and ICC. 'd ' to 'd ' indicate decorrelators. And, 'm' indicates a mono downmix signal. Yet, this method is unable to generate source mapping information such as D_L, D_R, and the like.</p><p id="p0094" num="0094">Hence, the first method of generating the source mapping information using the<!-- EPO <DP n="13"> --> CLD, ICC and/or decorrelators for the downmix signal regards dx(m) (x=0, 1, 2) as an independent input. In this case, the 'dx' is usable for a process for generating sub-rendering filter information according to Math <figref idrefs="f0003">Figure 5</figref>.</p><p id="p0095" num="0095"><maths id="math0007" num="MathFigure 5"><math display="block"><mtable columnalign="left"><mtr><mtd><mi>FL_L_M</mi><mo>=</mo><mi>d_L_M</mi><mo>*</mo><mi>GL_Lʹ</mi><mspace width="1em"/><mfenced separators=""><mi>Mono input</mi><mo>→</mo><mi>Left output</mi></mfenced></mtd></mtr><mtr><mtd><mi>FL_R_M</mi><mo>=</mo><mi>d_L_M</mi><mo>*</mo><mi>GL_Rʹ</mi><mspace width="1em"/><mfenced separators=""><mi>Mono input</mi><mo>→</mo><mi>Right output</mi></mfenced></mtd></mtr><mtr><mtd><mi>FL_L_Dx</mi><mo>=</mo><mi>d_L_Dx</mi><mo>*</mo><mi>GL_Lʹ</mi><mspace width="1em"/><mfenced separators=""><mi>Dx output</mi><mo>→</mo><mi>Left output</mi></mfenced></mtd></mtr><mtr><mtd><mi>FL_R_Dx</mi><mo>=</mo><mi>d_L_Dx</mi><mo>*</mo><mi>GL_Rʹ</mi><mspace width="1em"/><mfenced separators=""><mi>Dx output</mi><mo>→</mo><mi>Right output</mi></mfenced></mtd></mtr></mtable></math><img id="ib0007" file="imgb0007.tif" wi="110" he="48" img-content="math" img-format="tif"/></maths></p><p id="p0096" num="0096">And, rendering information can be generated according to Math <figref idrefs="f0003">Figure 6</figref> using a result of Math <figref idrefs="f0003">Figure 5</figref>.</p><p id="p0097" num="0097">MathFigure 6 <maths id="math0008" num="MathFigure 6"><math display="block"><mtable columnalign="left"><mtr><mtd><mi>HM_L</mi><mo>=</mo><mi>FL_L_M</mi><mo>+</mo><mi>FR_L_M</mi><mo>+</mo><mi>FC_L_M</mi><mo>+</mo><mi>FLS_L_M</mi><mo>+</mo><mi>FRS_L_M</mi><mo>+</mo><mi>FLFE_L_M</mi></mtd></mtr><mtr><mtd><mi>HM_R</mi><mo>=</mo><mi>FL_R_M</mi><mo>+</mo><mi>FR_R_M</mi><mo>+</mo><mi>FC_R_M</mi><mo>+</mo><mi>FLS_R_M</mi><mo>+</mo><mi>FRS_R_M</mi><mo>+</mo><mi>FLFE_R_M</mi></mtd></mtr><mtr><mtd><mi>HDx_L</mi><mo>=</mo><mi>FL_L_Dx</mi><mo>+</mo><mi>FR_L_Dx</mi><mo>+</mo><mi>FC_L_Dx</mi><mo>+</mo><mi>FLS_L_Dx</mi><mo>+</mo><mi>FRS_L_Dx</mi><mo>+</mo><mi>FLFE_L_Dx</mi></mtd></mtr><mtr><mtd><mi>HDx_R</mi><mo>=</mo><mi>FL_R_Dx</mi><mo>+</mo><mi>FR_R_Dx</mi><mo>+</mo><mi>FC_R_Dx</mi><mo>+</mo><mi>FLS_R_Dx</mi><mo>+</mo><mi>FRS_R_Dx</mi><mo>+</mo><mi>FLFE_R_Dx</mi></mtd></mtr></mtable></math><img id="ib0008" file="imgb0008.tif" wi="149" he="34" img-content="math" img-format="tif"/></maths></p><p id="p0098" num="0098">Details of the rendering information generating process are explained later. The first method of generating the source mapping information using the CLD, ICC and/or decorrelators handles a dx output value, i.e., 'dx(m)' as an independent input, which may increase an operational quantity.</p><p id="p0099" num="0099">A second method of generating source mapping information using CLD, ICC and/ or decorrelators employs decorrelators applied on a frequency domain. In this case, the source mapping information can be expresses as Math <figref idrefs="f0003">Figure 7</figref>.</p><p id="p0100" num="0100"><!-- EPO <DP n="14"> --><maths id="math0009" num="MathFigure 7"><math display="block"><mtable columnalign="left"><mtr><mtd><mfenced open="[" close="]"><mtable><mtr><mtd><mi>L</mi></mtd></mtr><mtr><mtd><mi>R</mi></mtd></mtr><mtr><mtd><mi>C</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">LFE</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">Ls</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">Rs</mi></mtd></mtr></mtable></mfenced></mtd><mtd><mo>=</mo><mfenced open="[" close="]"><mtable><mtr><mtd><msub><mi>A</mi><mrow><mi>L</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><mi>m</mi><mo>+</mo><msub><mi>B</mi><mrow><mi>L</mi><mo>⁢</mo><mn>0</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>0</mn></msub><mo>⁢</mo><mi>m</mi><mo>+</mo><msub><mi>B</mi><mrow><mi>L</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>1</mn></msub><mo>⁢</mo><msub><mi>C</mi><mrow><mi>L</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><mi>m</mi><mo>+</mo><msub><mi>B</mi><mrow><mi>L</mi><mo>⁢</mo><mn>3</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>3</mn></msub><mo>⁢</mo><msub><mi>C</mi><mrow><mi>L</mi><mo>⁢</mo><mn>3</mn></mrow></msub><mo>⁢</mo><mi>m</mi></mtd></mtr><mtr><mtd><msub><mi>A</mi><mrow><mi>R</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><mi>m</mi><mo>+</mo><msub><mi>B</mi><mrow><mi>R</mi><mo>⁢</mo><mn>0</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>0</mn></msub><mo>⁢</mo><mi>m</mi><mo>+</mo><msub><mi>B</mi><mrow><mi>R</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>1</mn></msub><mo>⁢</mo><msub><mi>C</mi><mrow><mi>R</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><mi>m</mi><mo>+</mo><msub><mi>B</mi><mrow><mi>R</mi><mo>⁢</mo><mn>3</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>3</mn></msub><mo>⁢</mo><msub><mi>C</mi><mrow><mi>R</mi><mo>⁢</mo><mn>3</mn></mrow></msub><mo>⁢</mo><mi>m</mi></mtd></mtr><mtr><mtd><msub><mi>A</mi><mrow><mi>C</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><mi>m</mi><mo>+</mo><msub><mi>B</mi><mrow><mi>C</mi><mo>⁢</mo><mn>0</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>0</mn></msub><mo>⁢</mo><mi>m</mi><mo>+</mo><msub><mi>B</mi><mrow><mi>C</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>1</mn></msub><mo>⁢</mo><msub><mi>C</mi><mrow><mi>C</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><mi>m</mi></mtd></mtr><mtr><mtd><msub><mi>c</mi><mrow><mn>2</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>4</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>2</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>1</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>0</mn></mrow></msub><mo>⁢</mo><mi>m</mi></mtd></mtr><mtr><mtd><msub><mi>A</mi><mrow><mi mathvariant="italic">LS</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><mi>m</mi><mo>+</mo><msub><mi>B</mi><mrow><mi mathvariant="italic">LS</mi><mo>⁢</mo><mn>0</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>0</mn></msub><mo>⁢</mo><mi>m</mi><mo>+</mo><msub><mi>B</mi><mrow><mi mathvariant="italic">LS</mi><mo>⁢</mo><mn>2</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>2</mn></msub><mo>⁢</mo><msub><mi>C</mi><mrow><mi mathvariant="italic">LS</mi><mo>⁢</mo><mn>2</mn></mrow></msub><mo>⁢</mo><mi>m</mi></mtd></mtr><mtr><mtd><msub><mi>A</mi><mrow><mi mathvariant="italic">RS</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><mi>m</mi><mo>+</mo><msub><mi>B</mi><mrow><mi mathvariant="italic">RS</mi><mo>⁢</mo><mn>0</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>0</mn></msub><mo>⁢</mo><mi>m</mi><mo>+</mo><msub><mi>B</mi><mrow><mi mathvariant="italic">RS</mi><mo>⁢</mo><mn>2</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>2</mn></msub><mo>⁢</mo><msub><mi>C</mi><mrow><mi mathvariant="italic">RS</mi><mo>⁢</mo><mn>2</mn></mrow></msub><mo>⁢</mo><mi>m</mi></mtd></mtr></mtable></mfenced></mtd></mtr><mtr><mtd><mspace width="1em"/></mtd><mtd><mo>=</mo><mfenced open="[" close="]"><mtable><mtr><mtd><msub><mi>A</mi><mrow><mi>L</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>B</mi><mrow><mi>L</mi><mo>⁢</mo><mn>0</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>0</mn></msub><mo>+</mo><msub><mi>B</mi><mrow><mi>L</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>1</mn></msub><mo>⁢</mo><msub><mi>C</mi><mrow><mi>L</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>B</mi><mrow><mi>L</mi><mo>⁢</mo><mn>3</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>3</mn></msub><mo>⁢</mo><msub><mi>C</mi><mrow><mi>L</mi><mo>⁢</mo><mn>3</mn></mrow></msub></mtd></mtr><mtr><mtd><msub><mi>A</mi><mrow><mi>R</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>B</mi><mrow><mi>R</mi><mo>⁢</mo><mn>0</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>0</mn></msub><mo>+</mo><msub><mi>B</mi><mrow><mi>R</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>1</mn></msub><mo>⁢</mo><msub><mi>C</mi><mrow><mi>R</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>B</mi><mrow><mi>R</mi><mo>⁢</mo><mn>3</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>3</mn></msub><mo>⁢</mo><msub><mi>C</mi><mrow><mi>R</mi><mo>⁢</mo><mn>3</mn></mrow></msub></mtd></mtr><mtr><mtd><msub><mi>A</mi><mrow><mi>C</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>B</mi><mrow><mi>C</mi><mo>⁢</mo><mn>0</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>0</mn></msub><mo>+</mo><msub><mi>B</mi><mrow><mi>C</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>1</mn></msub><mo>⁢</mo><msub><mi>C</mi><mrow><mi>C</mi><mo>⁢</mo><mn>1</mn></mrow></msub></mtd></mtr><mtr><mtd><msub><mi>c</mi><mrow><mn>2</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>4</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>2</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>1</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>0</mn></mrow></msub></mtd></mtr><mtr><mtd><msub><mi>A</mi><mrow><mi mathvariant="italic">LS</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>B</mi><mrow><mi mathvariant="italic">LS</mi><mo>⁢</mo><mn>0</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>0</mn></msub><mo>+</mo><msub><mi>B</mi><mrow><mi mathvariant="italic">LS</mi><mo>⁢</mo><mn>2</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mn>2</mn></msub><mo>⁢</mo><msub><mi>C</mi><mrow><mi mathvariant="italic">LS</mi><mo>⁢</mo><mn>2</mn></mrow></msub></mtd></mtr><mtr><mtd><msub><mi>A</mi><mrow><mi mathvariant="italic">RS</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>B</mi><mrow><mi mathvariant="italic">RS</mi><mo>⁢</mo><mn>0</mn></mrow></msub><mo>⁢</mo><msub><mi>D</mi><mn>0</mn></msub><mo>+</mo><msub><mi>B</mi><mrow><mi mathvariant="italic">RS</mi><mo>⁢</mo><mn>2</mn></mrow></msub><mo>⁢</mo><msub><mi>D</mi><mn>2</mn></msub><mo>⁢</mo><msub><mi>C</mi><mrow><mi mathvariant="italic">RS</mi><mo>⁢</mo><mn>2</mn></mrow></msub></mtd></mtr></mtable></mfenced></mtd></mtr></mtable></math><img id="ib0009" file="imgb0009.tif" wi="100" he="81" img-content="math" img-format="tif"/></maths></p><p id="p0101" num="0101">In this case, by applying decorrelators on a frequency domain, the same source mapping information such as D_L, D_R, and the like before the application of the decorrelators can be generated. So, it can be implemented in a simple manner.</p><p id="p0102" num="0102">A third method of generating source mapping information using CLD, ICC and/or decorrelators employs decorrelators having the all-pass characteristic as the decorrelators of the second method. In this case, the all-pass characteristic means that a size is fixed with a phase variation only. And, the present invention can use decorrelators having the all-pass characteristic as the decorrelators of the first method.</p><p id="p0103" num="0103">A fourth method of generating source mapping information using CLD, ICC and/or decorrelators carries out decorrelation by using decorrelators for the respective channels (e.g., L, R, C, Ls, Rs, etc.) instead of using 'd<sub>0</sub>' to 'd<sub>3</sub>' of the second method. In this case, the source mapping information can be expressed as Math <figref idrefs="f0004">Figure 8</figref>.</p><p id="p0104" num="0104"><maths id="math0010" num="MathFigure 8"><math display="block"><mfenced open="[" close="]"><mtable><mtr><mtd><mi>L</mi></mtd></mtr><mtr><mtd><mi>R</mi></mtd></mtr><mtr><mtd><mi>C</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">LFE</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">Ls</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">Rs</mi></mtd></mtr></mtable></mfenced><mo>=</mo><mfenced open="[" close="]"><mtable><mtr><mtd><msub><mi>A</mi><mrow><mi>L</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>K</mi><mi>L</mi></msub><mo>⁢</mo><msub><mi>d</mi><mi>L</mi></msub></mtd></mtr><mtr><mtd><msub><mi>A</mi><mrow><mi>R</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>K</mi><mi>R</mi></msub><mo>⁢</mo><msub><mi>d</mi><mi>R</mi></msub></mtd></mtr><mtr><mtd><msub><mi>A</mi><mrow><mi>C</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>K</mi><mi>C</mi></msub><mo>⁢</mo><msub><mi>d</mi><mi>C</mi></msub></mtd></mtr><mtr><mtd><msub><mi>c</mi><mrow><mn>2</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>4</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>2</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>1</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>0</mn></mrow></msub></mtd></mtr><mtr><mtd><msub><mi>A</mi><mrow><mi mathvariant="italic">LS</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>K</mi><mi mathvariant="italic">Ls</mi></msub><mo>⁢</mo><msub><mi>d</mi><mi mathvariant="italic">Ls</mi></msub></mtd></mtr><mtr><mtd><msub><mi>A</mi><mrow><mi mathvariant="italic">RS</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>K</mi><mi mathvariant="italic">Rs</mi></msub><mo>⁢</mo><msub><mi>d</mi><mi mathvariant="italic">Rs</mi></msub></mtd></mtr></mtable></mfenced><mo>⁢</mo><mi>m</mi></math><img id="ib0010" file="imgb0010.tif" wi="63" he="52" img-content="math" img-format="tif"/></maths></p><p id="p0105" num="0105">In this case, 'k' is an energy value of a decorrelated signal determined from CLD and ICC values. And, 'd_L', 'd_R', 'd_C', 'd_Ls' and 'd_Rs' indicate decorrelators applied to channels, respectively.</p><p id="p0106" num="0106">A fifth method of generating source mapping information using CLD, ICC and/or decorrelators maximizes a decorrelation effect by configuring 'd_L' and 'd_R'<!-- EPO <DP n="15"> --> symmetric to each other in the fourth method and configuring 'd_Ls' and 'd_Rs' symmetric to each other in the fourth method. In particular, assuming d_R=f(d_L) and d_Rs=f(d_Ls), it is necessary to design 'd_L', 'd_C' and 'd_Ls' only.</p><p id="p0107" num="0107">A sixth method of generating source mapping information using CLD, ICC and/or decorrelators is to configure the 'd_L' and 'd_Ls' to have a correlation in the fifth method. And, the 'd_L' and 'd_C' can be configured to have a correlation as well.</p><p id="p0108" num="0108">A seventh method of generating source mapping information using CLD, ICC and/ or decorrelators is to use the decorrelators in the third method as a serial or nested structure of the all-pas filters. The seventh method utilizes a fact that the all-pass characteristic is maintained even if the all-pass filter is used as the serial or nested structure. In case of using the all-pass filter as the serial or nested structure, it is able to obtain more various kinds of phase responses. Hence, the decorrelation effect can be maximized.</p><p id="p0109" num="0109">An eighth method of generating source mapping information using CLD, ICC and/ or decorrelators is to use the related art decorrelator and the frequency-domain decorrelator of the second method together. In this case, a multi-channel signal can be expressed as Math <figref idrefs="f0004">Figure 9</figref>.</p><p id="p0110" num="0110"><maths id="math0011" num="MathFigure 9"><math display="block"><mfenced open="[" close="]"><mtable><mtr><mtd><mi>L</mi></mtd></mtr><mtr><mtd><mi>R</mi></mtd></mtr><mtr><mtd><mi>C</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">LFE</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">Ls</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">Rs</mi></mtd></mtr></mtable></mfenced><mo>=</mo><mfenced open="[" close="]"><mtable><mtr><mtd><msub><mi>A</mi><mrow><mi>L</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>K</mi><mi>L</mi></msub><mo>⁢</mo><msub><mi>d</mi><mi>L</mi></msub></mtd></mtr><mtr><mtd><msub><mi>A</mi><mrow><mi>R</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>K</mi><mi>R</mi></msub><mo>⁢</mo><msub><mi>d</mi><mi>R</mi></msub></mtd></mtr><mtr><mtd><msub><mi>A</mi><mrow><mi>C</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>K</mi><mi>C</mi></msub><mo>⁢</mo><msub><mi>d</mi><mi>C</mi></msub></mtd></mtr><mtr><mtd><msub><mi>c</mi><mrow><mn>2</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>4</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>2</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>1</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>0</mn></mrow></msub></mtd></mtr><mtr><mtd><msub><mi>A</mi><mrow><mi mathvariant="italic">LS</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>K</mi><mi mathvariant="italic">Ls</mi></msub><mo>⁢</mo><msub><mi>d</mi><mi mathvariant="italic">Ls</mi></msub></mtd></mtr><mtr><mtd><msub><mi>A</mi><mrow><mi mathvariant="italic">RS</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>K</mi><mi mathvariant="italic">Rs</mi></msub><mo>⁢</mo><msub><mi>d</mi><mi mathvariant="italic">Rs</mi></msub></mtd></mtr></mtable></mfenced><mo>⁢</mo><mi>m</mi><mo>+</mo><mfenced open="[" close="]"><mtable><mtr><mtd><msub><mi>P</mi><mrow><mi>L</mi><mo>⁢</mo><mn>0</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mrow><mi mathvariant="italic">new</mi><mo>⁢</mo><mn>0</mn></mrow></msub><mfenced><mi>m</mi></mfenced><mo>+</mo><msub><mi>P</mi><mrow><mi>L</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mrow><mi mathvariant="italic">new</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mfenced><mi>m</mi></mfenced><mo>+</mo><mo>⋯</mo></mtd></mtr><mtr><mtd><msub><mi>P</mi><mrow><mi>R</mi><mo>⁢</mo><mn>0</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mrow><mi mathvariant="italic">new</mi><mo>⁢</mo><mn>0</mn></mrow></msub><mfenced><mi>m</mi></mfenced><mo>+</mo><msub><mi>P</mi><mrow><mi>R</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mrow><mi mathvariant="italic">new</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mfenced><mi>m</mi></mfenced><mo>+</mo><mo>⋯</mo></mtd></mtr><mtr><mtd><msub><mi>P</mi><mrow><mi>C</mi><mo>⁢</mo><mn>0</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mrow><mi mathvariant="italic">new</mi><mo>⁢</mo><mn>0</mn></mrow></msub><mfenced><mi>m</mi></mfenced><mo>+</mo><msub><mi>P</mi><mrow><mi>C</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mrow><mi mathvariant="italic">new</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mfenced><mi>m</mi></mfenced><mo>+</mo><mo>⋯</mo></mtd></mtr><mtr><mtd><mn>0</mn></mtd></mtr><mtr><mtd><msub><mi>P</mi><mrow><mi mathvariant="italic">Ls</mi><mo>⁢</mo><mn>0</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mrow><mi mathvariant="italic">new</mi><mo>⁢</mo><mn>0</mn></mrow></msub><mfenced><mi>m</mi></mfenced><mo>+</mo><msub><mi>P</mi><mrow><mi mathvariant="italic">Ls</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mrow><mi mathvariant="italic">new</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mfenced><mi>m</mi></mfenced><mo>+</mo><mo>⋯</mo></mtd></mtr><mtr><mtd><msub><mi>P</mi><mrow><mi mathvariant="italic">Rs</mi><mo>⁢</mo><mn>0</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mrow><mi mathvariant="italic">new</mi><mo>⁢</mo><mn>0</mn></mrow></msub><mfenced><mi>m</mi></mfenced><mo>+</mo><msub><mi>P</mi><mrow><mi mathvariant="italic">Rs</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mrow><mi mathvariant="italic">new</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mfenced><mi>m</mi></mfenced><mo>+</mo><mo>⋯</mo></mtd></mtr></mtable></mfenced></math><img id="ib0011" file="imgb0011.tif" wi="120" he="51" img-content="math" img-format="tif"/></maths></p><p id="p0111" num="0111">In this case, a filter coefficient generating process uses the same process explained in the first method except that 'A' is changed into 'A+Kd'.</p><p id="p0112" num="0112">A ninth method of generating source mapping information using CLD, ICC and/or decorrelators is to generate an additionally decorrelated value by applying a frequency domain decorrelator to an output of the related art decorrelator in case of using the related art decorrelator. Hence, it is able to generate source mapping information with a small operational quantity by overcoming the limitation of the frequency domain decorrelator.</p><p id="p0113" num="0113">A tenth method of generating source mapping information using CLD, ICC and/or decorrelators is expressed as Math <figref idrefs="f0004">Figure 10</figref>.</p><p id="p0114" num="0114"><!-- EPO <DP n="16"> --><maths id="math0012" num="MathFigure 10"><math display="block"><mfenced open="[" close="]"><mtable><mtr><mtd><mi>L</mi></mtd></mtr><mtr><mtd><mi>R</mi></mtd></mtr><mtr><mtd><mi>C</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">LFE</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">Ls</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">Rs</mi></mtd></mtr></mtable></mfenced><mo>=</mo><mfenced open="[" close="]"><mtable><mtr><mtd><msub><mi>A</mi><mrow><mi>L</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><mi>m</mi><mo>+</mo><msub><mi>K</mi><mi>L</mi></msub><mo>⁢</mo><msub><mi>d</mi><mi>L</mi></msub><mfenced><mi>m</mi></mfenced></mtd></mtr><mtr><mtd><msub><mi>A</mi><mrow><mi>R</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><mi>m</mi><mo>+</mo><msub><mi>K</mi><mi>R</mi></msub><mo>⁢</mo><msub><mi>d</mi><mi>R</mi></msub><mfenced><mi>m</mi></mfenced></mtd></mtr><mtr><mtd><msub><mi>A</mi><mrow><mi>C</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><mi>m</mi><mo>+</mo><msub><mi>K</mi><mi>C</mi></msub><mo>⁢</mo><msub><mi>d</mi><mi>C</mi></msub><mfenced><mi>m</mi></mfenced></mtd></mtr><mtr><mtd><msub><mi>c</mi><mrow><mn>2</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>4</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>2</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>c</mi><mrow><mn>1</mn><mo>,</mo><mi mathvariant="italic">OTT</mi><mo>⁢</mo><mn>0</mn></mrow></msub><mo>⁢</mo><mi>m</mi></mtd></mtr><mtr><mtd><msub><mi>A</mi><mrow><mi mathvariant="italic">LS</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><mi>m</mi><mo>+</mo><msub><mi>K</mi><mi mathvariant="italic">Ls</mi></msub><mo>⁢</mo><msub><mi>d</mi><mi mathvariant="italic">Ls</mi></msub><mfenced><mi>m</mi></mfenced></mtd></mtr><mtr><mtd><msub><mi>A</mi><mrow><mi mathvariant="italic">RS</mi><mo>⁢</mo><mn>1</mn></mrow></msub><mo>⁢</mo><mi>m</mi><mo>+</mo><msub><mi>K</mi><mi mathvariant="italic">Rs</mi></msub><mo>⁢</mo><msub><mi>d</mi><mi mathvariant="italic">Rs</mi></msub><mfenced><mi>m</mi></mfenced></mtd></mtr></mtable></mfenced></math><img id="ib0012" file="imgb0012.tif" wi="65" he="46" img-content="math" img-format="tif"/></maths></p><p id="p0115" num="0115">In this case, 'di_(m)'(i=L, R, C, Ls, Rs) is a decorrelator output value applied to a channel-i. And, the output value can be processed on a time domain, a frequency domain, a QMF domain, a hybrid domain, or the like. If the output value is processed on a domain different from a currently processed domain, it can be converted by domain conversion. It is able to use the same 'd for d_L, d_R, d_C, d_Ls, and d_Rs. In this case, Math <figref idrefs="f0004">Figure 10</figref> can be expressed in a very simple manner.</p><p id="p0116" num="0116">If Math <figref idrefs="f0004">Figure 10</figref> is applied to Math <figref idrefs="f0001">Figure 1</figref>, Math <figref idrefs="f0001">Figure 1</figref> can be expressed as Math <figref idrefs="f0004">Figure 11</figref>.</p><p id="p0117" num="0117"><maths id="math0013" num="MathFigure 11"><math display="block"><mtable><mtr><mtd><mi>Lo</mi><mo>=</mo><mi>HM_L</mi><mo>*</mo><mi mathvariant="normal">m</mi><mo>+</mo><mi>HMD_L</mi><mo>*</mo><mi mathvariant="normal">d</mi><mfenced><mi mathvariant="normal">m</mi></mfenced></mtd></mtr><mtr><mtd><mi>Ro</mi><mo>=</mo><mi>HM_R</mi><mo>*</mo><mi mathvariant="normal">R</mi><mo>+</mo><mi>HMD_R</mi><mo>*</mo><mi mathvariant="normal">d</mi><mfenced><mi mathvariant="normal">m</mi></mfenced></mtd></mtr></mtable></math><img id="ib0013" file="imgb0013.tif" wi="57" he="24" img-content="math" img-format="tif"/></maths></p><p id="p0118" num="0118">In this case, rendering information HM_L is a value resulting from combining spatial information and filter information to generate a surround signal Lo with an input m. And, rendering information HM_R is a value resulting from combining spatial information and filter information to generate a surround signal Ro with an input m. Moreover, 'd(m)' is a decorrelator output value generated by transferring a decorrelator output value on an arbitrary domain to a value on a current domain or a decorrelator output value generated by being processed on a current domain. Rendering information HMD_L is a value indicating an extent of the decorrelator output value d(m) that is added to 'Lo' in rendering the d(m), and also a value resulting from combining spatial information and filter information together. Rendering information HMD_R is a value indicating an extent of the decorrelator output value d(m) that is added to 'Ro' in rendering the d(m).</p><p id="p0119" num="0119">Thus, in order to perform a rendering process on a mono downmix signal, the present invention proposes a method of generating a surround signal by rendering the rendering information generated by combining spatial information and filter information (e.g., HRTF filter coefficient) to a downmix signal and a decorrelated downmix signal. The rendering process can be executed regardless of domains. If 'd(m)' is expressed as 'd*m'(product operator) being executed on a frequency domain,<!-- EPO <DP n="17"> --> Math <figref idrefs="f0004">Figure 11</figref> can be expressed as Math <figref idrefs="f0005">Figure 12</figref>.</p><p id="p0120" num="0120"><maths id="math0014" num="MathFigure 12"><math display="block"><mtable columnalign="left"><mtr><mtd><mi>Lo</mi><mo>=</mo><mi>HM_L</mi><mo>*</mo><mi mathvariant="normal">m</mi><mo>+</mo><mi>HMD_L</mi><mo>*</mo><mi mathvariant="normal">d</mi><mo>*</mo><mi mathvariant="normal">m</mi><mo>=</mo><mi>HMoverall_L</mi><mo>*</mo><mi mathvariant="normal">m</mi></mtd></mtr><mtr><mtd><mi>Ro</mi><mo>=</mo><mi>HM_R</mi><mo>*</mo><mi mathvariant="normal">m</mi><mo>+</mo><mi>HMD_R</mi><mo>*</mo><mi mathvariant="normal">d</mi><mo>*</mo><mi mathvariant="normal">m</mi><mo>=</mo><mi>HMoverall_R</mi><mo>*</mo><mi mathvariant="normal">m</mi></mtd></mtr></mtable></math><img id="ib0014" file="imgb0014.tif" wi="91" he="26" img-content="math" img-format="tif"/></maths></p><p id="p0121" num="0121">Thus, in case of performing a rendering process on a downmix signal on a frequency domain, it is ale to minimize an operational quantity in a manner of representing a value resulting from combining spatial information, filter information and decorrelators appropriately as a product form.</p><p id="p0122" num="0122"><figref idrefs="f0003">FIG. 6 and FIG. 7</figref> are detailed block diagrams of a rendering unit for a stereo downmix signal according to one embodiment of the present invention.</p><p id="p0123" num="0123">Referring to <figref idrefs="f0003">FIG. 6</figref>, the rendering unit 900 includes a rendering unit-A 910 and a rendering unit-B 920.</p><p id="p0124" num="0124">If a downmix signal is a stereo signal, the spatial information converting unit 1000 generates rendering information for left and right channels of the downmix signal. The rendering unit-A 910 generates a surround signal by rendering the rendering information for the left channel of the downmix signal to the left channel of the downmix signal. And, the rendering unit-B 920 generates a surround signal by rendering the rendering information for the right channel of the downmix signal to the right channel of the downmix signal. The names of the channels are just exemplary, which does not put limitation on the present invention.</p><p id="p0125" num="0125">The rendering information can include rendering information delivered to a same channel and rendering information delivered to another channel.</p><p id="p0126" num="0126">For instance, the spatial information converting unit 1000 is able to generate rendering information HL_L and HL_R inputted to the rendering unit for the left channel of the downmix signal, in which rendering information HL_L is delivered to a left output corresponding to the same channel and the rendering information HL_R is delivered to a right output corresponding to the another channel. And, the spatial information converting unit 1000 is able to generate rendering information HR_R and HR_L inputted to the rendering unit for the right channel of the downmix signal, in which the rendering information HR_R is delivered to a right output corresponding to the same channel and the rendering information HR_L is delivered to a left output corresponding to the another channel.</p><p id="p0127" num="0127">Referring to <figref idrefs="f0003">FIG. 7</figref>, the rendering unit 900 includes a rendering unit-1A 911, a rendering unit-2A 912, a rendering unit-1B 921, and a rendering unit-2B 922.</p><p id="p0128" num="0128">The rendering unit 900 receives a stereo downmix signal and rendering information from the spatial information converting unit 1000. Subsequently, the rendering unit 900 generates a surround signal by rendering the rendering information to the stereo<!-- EPO <DP n="18"> --> downmix signal.</p><p id="p0129" num="0129">In particular, the rendering unit-1A 911 performs rendering by using rendering information HL_L delivered to a same channel among rendering information for a left channel of a downmix signal. The rendering unit-2A 912 performs rendering by using rendering information HL_R delivered to a another channel among rendering information for a left channel of a downmix signal. The rendering unit-1B 921 performs rendering by using rendering information HR_R delivered to a same channel among rendering information for a right channel of a downmix signal. And, the rendering unit-2B 922 performs rendering by using rendering information HR_L delivered to another channel among rendering information for a right channel of a downmix signal.</p><p id="p0130" num="0130">In the following description, the rendering information delivered to another channel is named 'cross-rendering information' The cross-rendering information HL_R or HR_L is applied to a same channel and then added to another channel by an adder. In this case, the cross-rendering information HL_R and/or HR_L can be zero. If the cross-rendering information HL_R and/or HR_L is zero, it means that no contribution is made to the corresponding path.</p><p id="p0131" num="0131">An example of the surround signal generating method shown in <figref idrefs="f0003">FIG. 6 or FIG. 7</figref> is explained as follows.</p><p id="p0132" num="0132">First of all, if a downmix signal is a stereo signal, the downmix signal defined as 'x', source mapping information generated by using spatial information defined as 'D', prototype filter information defined as 'G', a multi-channel signal defined as 'p' and a surround signal defined as 'y' can be represented by matrixes shown in Math <figref idrefs="f0005">Figure 13</figref>.</p><p id="p0133" num="0133"><maths id="math0015" num="MathFigure 13"><math display="block"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold">x</mi><mo>=</mo><mfenced open="[" close="]"><mtable><mtr><mtd><mi mathvariant="italic">Li</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">Ri</mi></mtd></mtr></mtable></mfenced><mspace width="2em"/><mi mathvariant="bold">p</mi><mo>=</mo><mfenced open="[" close="]"><mtable columnalign="left"><mtr><mtd><mi>L</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">Ls</mi></mtd></mtr><mtr><mtd><mi>R</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">Rs</mi></mtd></mtr><mtr><mtd><mi>C</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">LFE</mi></mtd></mtr></mtable></mfenced><mspace width="2em"/><mi mathvariant="bold">D</mi><mo>=</mo><mfenced open="[" close="]"><mtable columnalign="left"><mtr><mtd><mi mathvariant="italic">D_L</mi><mo>⁢</mo><mn>1</mn></mtd><mtd><mi mathvariant="italic">D_L</mi><mo>⁢</mo><mn>2</mn></mtd></mtr><mtr><mtd><mi mathvariant="italic">D_Ls</mi><mo>⁢</mo><mn>1</mn></mtd><mtd><mi mathvariant="italic">D_Ls</mi><mo>⁢</mo><mn>2</mn></mtd></mtr><mtr><mtd><mi mathvariant="italic">D_R</mi><mo>⁢</mo><mn>1</mn></mtd><mtd><mi mathvariant="italic">D_R</mi><mo>⁢</mo><mn>2</mn></mtd></mtr><mtr><mtd><mi mathvariant="italic">D_Rs</mi><mo>⁢</mo><mn>1</mn></mtd><mtd><mi mathvariant="italic">D_Rs</mi><mo>⁢</mo><mn>2</mn></mtd></mtr><mtr><mtd><mi mathvariant="italic">D_C</mi><mo>⁢</mo><mn>1</mn></mtd><mtd><mi mathvariant="italic">D_C</mi><mo>⁢</mo><mn>2</mn></mtd></mtr><mtr><mtd><mi mathvariant="italic">D_LFE</mi><mo>⁢</mo><mn>1</mn></mtd><mtd><mi mathvariant="italic">D_LFE</mi><mo>⁢</mo><mn>2</mn></mtd></mtr></mtable></mfenced></mtd></mtr><mtr><mtd><mi mathvariant="bold">G</mi><mo>=</mo><mfenced open="[" close="]"><mtable><mtr><mtd><mi mathvariant="italic">GL_L</mi></mtd><mtd><mi mathvariant="italic">GLs_L</mi></mtd><mtd><mi mathvariant="italic">GR_L</mi></mtd><mtd><mi mathvariant="italic">GRs_L</mi></mtd><mtd><mi mathvariant="italic">GC_L</mi></mtd><mtd><mi mathvariant="italic">GLFE_L</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">GL_R</mi></mtd><mtd><mi mathvariant="italic">GLs_R</mi></mtd><mtd><mi mathvariant="italic">GR_R</mi></mtd><mtd><mi mathvariant="italic">GRs_R</mi></mtd><mtd><mi mathvariant="italic">GC_R</mi></mtd><mtd><mi mathvariant="italic">GLFE_R</mi></mtd></mtr></mtable></mfenced><mspace width="1em"/><mi mathvariant="bold">y</mi><mo>=</mo><mfenced open="[" close="]"><mtable><mtr><mtd><mi mathvariant="italic">Lo</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">Ro</mi></mtd></mtr></mtable></mfenced></mtd></mtr></mtable></math><img id="ib0015" file="imgb0015.tif" wi="87" he="50" img-content="math" img-format="tif"/></maths></p><p id="p0134" num="0134">In this case, if the above values are on a frequency domain, they can be developed as follows.</p><p id="p0135" num="0135">First of all, the multi-channel signal p, as shown in Math <figref idrefs="f0005">Figure 14</figref>, can be expressed as a product between the source mapping information D generated by using the spatial information and the downmix signal x.</p><p id="p0136" num="0136"><!-- EPO <DP n="19"> --><maths id="math0016" num="MathFigure 14"><math display="block"><mi mathvariant="bold">p</mi><mo>=</mo><mi mathvariant="bold">D</mi><mo>⋅</mo><mi mathvariant="bold">x</mi><mspace width="1em"/><mfenced open="[" close="]"><mtable columnalign="left"><mtr><mtd><mi>L</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">Ls</mi></mtd></mtr><mtr><mtd><mi>R</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">Rs</mi></mtd></mtr><mtr><mtd><mi>C</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">LFE</mi></mtd></mtr></mtable></mfenced><mo>=</mo><mfenced open="[" close="]"><mtable columnalign="left"><mtr><mtd><mi mathvariant="italic">D_L</mi><mo>⁢</mo><mn>1</mn></mtd><mtd><mi mathvariant="italic">D_L</mi><mo>⁢</mo><mn>2</mn></mtd></mtr><mtr><mtd><mi mathvariant="italic">D_Ls</mi><mo>⁢</mo><mn>1</mn></mtd><mtd><mi mathvariant="italic">D_Ls</mi><mo>⁢</mo><mn>2</mn></mtd></mtr><mtr><mtd><mi mathvariant="italic">D_R</mi><mo>⁢</mo><mn>1</mn></mtd><mtd><mi mathvariant="italic">D_R</mi><mo>⁢</mo><mn>2</mn></mtd></mtr><mtr><mtd><mi mathvariant="italic">D_Rs</mi><mo>⁢</mo><mn>1</mn></mtd><mtd><mi mathvariant="italic">D_Rs</mi><mo>⁢</mo><mn>2</mn></mtd></mtr><mtr><mtd><mi mathvariant="italic">D_C</mi><mo>⁢</mo><mn>1</mn></mtd><mtd><mi mathvariant="italic">D_C</mi><mo>⁢</mo><mn>2</mn></mtd></mtr><mtr><mtd><mi mathvariant="italic">D_LFE</mi><mo>⁢</mo><mn>1</mn></mtd><mtd><mi mathvariant="italic">D_LFE</mi><mo>⁢</mo><mn>2</mn></mtd></mtr></mtable></mfenced><mo>⁢</mo><mfenced open="[" close="]"><mtable><mtr><mtd><mi mathvariant="italic">Li</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">Ri</mi></mtd></mtr></mtable></mfenced></math><img id="ib0016" file="imgb0016.tif" wi="77" he="38" img-content="math" img-format="tif"/></maths></p><p id="p0137" num="0137">The surround signal y, as shown in Math <figref idrefs="f0005">Figure 15</figref>, can be generated by rendering the prototype filter information G to the multi-channel signal p.</p><p id="p0138" num="0138"><maths id="math0017" num="MathFigure 15"><math display="block"><mi mathvariant="bold">y</mi><mo>=</mo><mi mathvariant="bold">G</mi><mo>⋅</mo><mi mathvariant="bold">p</mi></math><img id="ib0017" file="imgb0017.tif" wi="36" he="14" img-content="math" img-format="tif"/></maths></p><p id="p0139" num="0139">In this case, if Math <figref idrefs="f0005">Figure 14</figref> is inserted in the p, it can be generated as Math <figref idrefs="f0006">Figure 16</figref>.</p><p id="p0140" num="0140"><maths id="math0018" num="MathFigure 16"><math display="block"><mi mathvariant="bold">y</mi><mo>=</mo><mi mathvariant="bold">GDx</mi></math><img id="ib0018" file="imgb0018.tif" wi="38" he="16" img-content="math" img-format="tif"/></maths></p><p id="p0141" num="0141">In this case, if rendering information H is defined as H=GD, the surround signal y and the downmix signal x can have a relation of Math <figref idrefs="f0006">Figure 17</figref>.</p><p id="p0142" num="0142"><maths id="math0019" num="MathFigure 17"><math display="block"><mi mathvariant="normal">H</mi><mo>=</mo><mfenced open="[" close="]"><mtable><mtr><mtd><mi mathvariant="italic">HL_L</mi></mtd><mtd><mi mathvariant="italic">HR_L</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">HL_R</mi></mtd><mtd><mi mathvariant="italic">HR_R</mi></mtd></mtr></mtable></mfenced><mo>,</mo><mspace width="1em"/><mi mathvariant="bold">y</mi><mo>=</mo><mi mathvariant="bold">Hx</mi></math><img id="ib0019" file="imgb0019.tif" wi="66" he="26" img-content="math" img-format="tif"/></maths></p><p id="p0143" num="0143">Hence, after the rendering information H has been generated by processing the product between the filter information and the source mapping information, the downmix signal x is multiplied by the rendering information H to generate the surround signal y.</p><p id="p0144" num="0144">According to the definition of the rendering information H, the rendering information H can be expressed as Math <figref idrefs="f0007">Figure 18</figref>.</p><p id="p0145" num="0145"><maths id="math0020" num="MathFigure 18"><math display="block"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold">H</mi><mo>=</mo><mi mathvariant="bold">GD</mi></mtd></mtr><mtr><mtd><mfenced open="[" close="]"><mtable><mtr><mtd><mi mathvariant="italic">GL_L</mi></mtd><mtd><mi mathvariant="italic">GLs_L</mi></mtd><mtd><mi mathvariant="italic">GR_L</mi></mtd><mtd><mi mathvariant="italic">GRs_L</mi></mtd><mtd><mi mathvariant="italic">GC_L</mi></mtd><mtd><mi mathvariant="italic">GLFE_L</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">GL_R</mi></mtd><mtd><mi mathvariant="italic">GLs_R</mi></mtd><mtd><mi mathvariant="italic">GR_R</mi></mtd><mtd><mi mathvariant="italic">GRs_R</mi></mtd><mtd><mi mathvariant="italic">GC_R</mi></mtd><mtd><mi mathvariant="italic">GLFE_R</mi></mtd></mtr></mtable></mfenced><mo>⁢</mo><mfenced open="[" close="]"><mtable columnalign="left"><mtr><mtd><mi mathvariant="italic">D_L</mi><mo>⁢</mo><mn>1</mn></mtd><mtd><mi mathvariant="italic">D_L</mi><mo>⁢</mo><mn>2</mn></mtd></mtr><mtr><mtd><mi mathvariant="italic">D_Ls</mi><mo>⁢</mo><mn>1</mn></mtd><mtd><mi mathvariant="italic">D_Ls</mi><mo>⁢</mo><mn>2</mn></mtd></mtr><mtr><mtd><mi mathvariant="italic">D_R</mi><mo>⁢</mo><mn>1</mn></mtd><mtd><mi mathvariant="italic">D_R</mi><mo>⁢</mo><mn>2</mn></mtd></mtr><mtr><mtd><mi mathvariant="italic">D_Rs</mi><mo>⁢</mo><mn>1</mn></mtd><mtd><mi mathvariant="italic">D_Rs</mi><mo>⁢</mo><mn>2</mn></mtd></mtr><mtr><mtd><mi mathvariant="italic">D_C</mi><mo>⁢</mo><mn>1</mn></mtd><mtd><mi mathvariant="italic">D_C</mi><mo>⁢</mo><mn>2</mn></mtd></mtr><mtr><mtd><mi mathvariant="italic">D_LFE</mi><mo>⁢</mo><mn>1</mn></mtd><mtd><mi mathvariant="italic">D_LFE</mi><mo>⁢</mo><mn>2</mn></mtd></mtr></mtable></mfenced></mtd></mtr></mtable></math><img id="ib0020" file="imgb0020.tif" wi="110" he="46" img-content="math" img-format="tif"/></maths></p><p id="p0146" num="0146"><figref idrefs="f0004">FIG. 8 and FIG. 9</figref> are detailed block diagrams of a rendering unit for a mono downmix signal according to one embodiment of the present invention.</p><p id="p0147" num="0147">Referring to <figref idrefs="f0004">FIG. 8</figref>, the rendering unit 900 includes a rendering unit-A 930 and a rendering unit-B 940.</p><p id="p0148" num="0148">If a downmix signal is a mono signal, the spatial information converting unit 1000<!-- EPO <DP n="20"> --> generates rendering information HM_L and HM_R, in which the rendering information HM_L is used in rendering the mono signal to a left channel and the rendering information HM_R is used in rendering the mono signal to a right channel.</p><p id="p0149" num="0149">The rendering unit-A 930 applies the rendering information HM_L to the mono downmix signal to generate a surround signal of the left channel. The rendering unit-B 940 applies the rendering information HM_R to the mono downmix signal to generate a surround signal of the right channel.</p><p id="p0150" num="0150">The rendering unit 900 in the drawing does not use a decorrelator. Yet, if the rendering unit-A 930 and the rendering unit-B 940 performs rendering by using the rendering information Hmoverall_R and Hmoverall_L defined in Math <figref idrefs="f0005">Figure 12</figref>, respectively, it is able to obtain the outputs to which the decorrelator is applied, respectively.</p><p id="p0151" num="0151">Meanwhile, in case of attempting to obtain an output in a stereo signal instead of a surround signal after completion of the rendering performed on a mono downmix signal, the following two methods are possible.</p><p id="p0152" num="0152">The first method is that instead of using rendering information for a surround effect, a value used for a stereo output is used. In this case, it is able to obtain a stereo signal by modifying only the rendering information in the structure shown in <figref idrefs="f0002">FIG. 3</figref>.</p><p id="p0153" num="0153">The second method is that in a decoding process for generating a multi-channel signal by using a downmix signal and spatial information, it is able to obtain a stereo signal by performing the decoding process to only a corresponding step to obtain a specific channel number.</p><p id="p0154" num="0154">Referring to <figref idrefs="f0004">FIG. 9</figref>, the rendering unit 900 corresponds to a case in which a decorrelated signal is represented as one, i.e., Math <figref idrefs="f0004">Figure 11</figref>. The rendering unit 900 includes a rendering unit-1A 931, a rendering unit-2A 932, a rendering unit-1B 941, and a rendering unit-2B 942. The rendering unit 900 is similar to the rendering unit for the stereo downmix signal except that the rendering unit 900 includes the rendering units 941 and 942 for a decorrelated signal.</p><p id="p0155" num="0155">In case of the stereo downmix signal, it can be interpreted that one of two channels is a decorrelated signal. So, without employing additional decorrelators, it is able to perform a rendering process by using the formerly defined four kinds of rendering information HL_L, HL_R and the like. In particular, the rendering unit-1A 931 generates a signal to be delivered to a same channel by applying the rendering information HM_L to a mono downmix signal. The rendering unit-2A 932 generates a signal to be delivered to another channel by applying the rendering information HM_R to the mono downmix signal. The rendering unit-1B 941 generates a signal to be delivered to a same channel by applying the rendering information HMD_R to a decorrelated signal. And, the rendering unit-2B 942 generates a signal to be delivered to another channel<!-- EPO <DP n="21"> --> by applying the rendering information HMD_L to the decorrelated signal.</p><p id="p0156" num="0156">If a downmix signal is a mono signal, a downmix signal defined as x, source channel information defined as D, prototype filter information defined as G, a multi-channel signal defined as p, and a surround signal defined as y can be represented by matrixes shown in Math <figref idrefs="f0008">Figure 19</figref>.</p><p id="p0157" num="0157"><maths id="math0021" num="MathFigure 19"><math display="block"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold">x</mi><mo>=</mo><mfenced open="[" close="]"><mi mathvariant="italic">Mi</mi></mfenced><mspace width="2em"/><mi mathvariant="bold">p</mi><mo>=</mo><mfenced open="[" close="]"><mtable columnalign="left"><mtr><mtd><mi>L</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">Ls</mi></mtd></mtr><mtr><mtd><mi>R</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">Rs</mi></mtd></mtr><mtr><mtd><mi>C</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">LFE</mi></mtd></mtr></mtable></mfenced><mspace width="2em"/><mi mathvariant="bold">D</mi><mo>=</mo><mfenced open="[" close="]"><mtable columnalign="left"><mtr><mtd><mi mathvariant="italic">D_L</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">D_Ls</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">D_R</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">D_Rs</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">D_C</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">D_LFE</mi></mtd></mtr></mtable></mfenced></mtd></mtr><mtr><mtd><mi mathvariant="bold">G</mi><mo>=</mo><mfenced open="[" close="]"><mtable><mtr><mtd><mi mathvariant="italic">GL_L</mi></mtd><mtd><mi mathvariant="italic">GLs_L</mi></mtd><mtd><mi mathvariant="italic">GR_L</mi></mtd><mtd><mi mathvariant="italic">GRs_L</mi></mtd><mtd><mi mathvariant="italic">GC_L</mi></mtd><mtd><mi mathvariant="italic">GLFE_L</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">GL_R</mi></mtd><mtd><mi mathvariant="italic">GLs_R</mi></mtd><mtd><mi mathvariant="italic">GR_R</mi></mtd><mtd><mi mathvariant="italic">GRs_R</mi></mtd><mtd><mi mathvariant="italic">GC_R</mi></mtd><mtd><mi mathvariant="italic">GLFE_R</mi></mtd></mtr></mtable></mfenced><mo>,</mo><mspace width="1em"/><mi mathvariant="bold">y</mi><mo>=</mo><mfenced open="[" close="]"><mtable><mtr><mtd><mi mathvariant="italic">Lo</mi></mtd></mtr><mtr><mtd><mi mathvariant="italic">Ro</mi></mtd></mtr></mtable></mfenced></mtd></mtr></mtable></math><img id="ib0021" file="imgb0021.tif" wi="104" he="61" img-content="math" img-format="tif"/></maths></p><p id="p0158" num="0158">In this case, the relation between the matrixes is similar to that of the case that the downmix signal is the stereo signal. So its details are omitted.</p><p id="p0159" num="0159">Meanwhile, the source mapping information described with reference to <figref idrefs="f0002">FIG. 4</figref> and <figref idrefs="f0003">FIG. 5</figref> and the rendering information generated by using the source mapping information have values differing per frequency band, parameter band, and/or transmitted timeslot. In this case, if a value of the source mapping information and/or the rendering information has a considerably big difference between neighbor bands or between boundary timeslots, distortion may take place in the rendering process. To prevent the distortion, a smoothing process on a frequency and/or time domain is needed. Another smoothing method suitable for the rendering is usable as well as the frequency domain smoothing and/or the time domain smoothing. And, it is able to use a value resulting from multiplying the source mapping information or the rendering information by a specific gain.</p><p id="p0160" num="0160"><figref idrefs="f0004">FIG. 10 and FIG. 11</figref> are block diagrams of a smoothing unit and an expanding unit according to one embodiment of the present invention.</p><p id="p0161" num="0161">A smoothing method according to the present invention, as shown in <figref idrefs="f0004">FIG. 10 and FIG. 11</figref>, is applicable to rendering information and/or source mapping information. Yet, the smoothing method is applicable to other type information. In the following description, smoothing on a frequency domain is described. Yet, the present invention includes time domain smoothing as well as the frequency domain smoothing.</p><p id="p0162" num="0162">Referring to <figref idrefs="f0004">FIG. 10 and FIG. 11</figref>, the smoothing unit 1042 is capable of performing smoothing on rendering information and/or source mapping information. A detailed example of a position of the smoothing occurrence will be described with reference to<!-- EPO <DP n="22"> --> <figref idrefs="f0007 f0008 f0009">FIGs. 18 to 20</figref> later.</p><p id="p0163" num="0163">The smoothing unit 1042 can be configured with an expanding unit 1043, in which the rendering information and/or source mapping information can be expanded into a wider range, for example filter band, than that of a parameter band. In particular, the source mapping information can be expanded to a frequency resolution (e.g., filter band) corresponding to filter information to be multiplied by the filter information (e.g., HRTF filter coefficient). The smoothing according to the present invention is executed prior to or together with the expansion. The smoothing used together with the expansion can employ one of the methods shown in <figref idrefs="f0005 f0006">FIGs. 12 to 16</figref>.</p><p id="p0164" num="0164"><figref idrefs="f0005">FIG. 12</figref> is a graph to explain a first smoothing method according to one embodiment of the present invention.</p><p id="p0165" num="0165">Referring to <figref idrefs="f0005">FIG. 12</figref>, a first smoothing method uses a value having the same size as spatial information in each parameter band. In this case, it is able to achieve a smoothing effect by using a suitable smoothing function.</p><p id="p0166" num="0166"><figref idrefs="f0005">FIG. 13</figref> is a graph to explain a second smoothing method according to one embodiment of the present invention.</p><p id="p0167" num="0167">Referring to <figref idrefs="f0005">FIG. 13</figref>, a second smoothing method is to obtain a smoothing effect by connecting representative positions of parameter band. The representative position is a right center of each of the parameter bands, a central position proportional to a log scale, a bark scale, or the like, a lowest frequency value, or a position previously determined by a different method.</p><p id="p0168" num="0168"><figref idrefs="f0005">FIG. 14</figref> is a graph to explain a third smoothing method according to one embodiment of the present invention.</p><p id="p0169" num="0169">Referring to <figref idrefs="f0005">FIG. 14</figref>, a third smoothing method is to perform smoothing in a form of a curve or straight line smoothly connecting boundaries of parameters. In this case, the third smoothing method uses a preset boundary smoothing curve or low pass filtering by the first order or higher IIR filter or FIR filter.</p><p id="p0170" num="0170"><figref idrefs="f0005">FIG. 15</figref> is a graph to explain a fourth smoothing method according to one embodiment of the present invention.</p><p id="p0171" num="0171">Referring to <figref idrefs="f0005">FIG. 15</figref>, a fourth smoothing method is to achieve a smoothing effect by adding a signal such as a random noise to a spatial information contour. In this case, a value differing in channel or band is usable as the random noise. In case of adding a random noise on a frequency domain, it is able to add only a size value while leaving a phase value intact. The fourth smoothing method is able to achieve an inter-channel decorrelation effect as well as a smoothing effect on a frequency domain.</p><p id="p0172" num="0172"><figref idrefs="f0006">FIG. 16</figref> is a graph to explain a fifth smoothing method according to one embodiment of the present invention.</p><p id="p0173" num="0173">Referring to <figref idrefs="f0006">FIG. 16</figref>, a fifth smoothing method is to use a combination of the<!-- EPO <DP n="23"> --> second to fourth smoothing methods. For instance, after the representative positions of the respective parameter bands have been connected, the random noise is added and low path filtering is then applied. In doing so, the sequence can be modified. The fifth smoothing method minimizes discontinuous points on a frequency domain and an inter-channel decorrelation effect can be enhanced.</p><p id="p0174" num="0174">In the first to fifth smoothing methods, a total of powers for spatial information values (e.g., CLD values) on the respective frequency domains per channel should be uniform as a constant. For this, after the smoothing method is performed per channel, power normalization should be performed. For instance, if a downmix signal is a mono signal, level values of the respective channels should meet the relation of Math <figref idrefs="f0009">Figure 20</figref>.</p><p id="p0175" num="0175"><maths id="math0022" num="MathFigure 20"><math display="block"><mi>D_L</mi><mfenced><mi>pb</mi></mfenced><mo>+</mo><mi>D_R</mi><mfenced><mi>pb</mi></mfenced><mo>+</mo><mi>D_C</mi><mfenced><mi>pb</mi></mfenced><mo>+</mo><mi>D_Ls</mi><mfenced><mi>pb</mi></mfenced><mo>+</mo><mi>D_Rs</mi><mfenced><mi>pb</mi></mfenced><mo>+</mo><mi>D_Lfe</mi><mfenced><mi>pb</mi></mfenced><mo>=</mo><mi mathvariant="normal">C</mi></math><img id="ib0022" file="imgb0022.tif" wi="132" he="15" img-content="math" img-format="tif"/></maths></p><p id="p0176" num="0176">In this case, 'pb = 0- total parameter band number 1' and 'C' is an arbitrary constant.</p><p id="p0177" num="0177"><figref idrefs="f0006">FIG. 17</figref> is a diagram to explain prototype filter information per channel.</p><p id="p0178" num="0178">Referring to <figref idrefs="f0006">FIG. 17</figref>, for rendering, a signal having passed through GL_L filter for a left channel source is sent to a left output, whereas a signal having passed through GL_R filter is sent to a right output.</p><p id="p0179" num="0179">Subsequently, a left final output (e.g., Lo) and a right final output (e.g., Ro) are generated by adding all signals received from the respective channels. In particular, the rendered left/right channel outputs can be expressed as Math <figref idrefs="f0010">Figure 21</figref>.</p><p id="p0180" num="0180"><maths id="math0023" num="MathFigure 21"><math display="block"><mtable><mtr><mtd><mi>Lo</mi><mo>=</mo><mi mathvariant="normal">L</mi><mo>*</mo><mi>GL_L</mi><mo>+</mo><mi mathvariant="normal">C</mi><mo>*</mo><mi>GC_L</mi><mo>+</mo><mi mathvariant="normal">R</mi><mo>*</mo><mi>GR_L</mi><mo>+</mo><mi>Ls</mi><mo>*</mo><mi>GLs_L</mi><mo>+</mo><mi>Rs</mi><mo>*</mo><mi>GRs_L</mi></mtd></mtr><mtr><mtd><mi>Ro</mi><mo>=</mo><mi mathvariant="normal">L</mi><mo>*</mo><mi>GL_R</mi><mo>+</mo><mi mathvariant="normal">C</mi><mo>*</mo><mi>GC_R</mi><mo>+</mo><mi mathvariant="normal">R</mi><mo>*</mo><mi>GR_R</mi><mo>+</mo><mi>Ls</mi><mo>*</mo><mi>GLs_R</mi><mo>+</mo><mi>Rs</mi><mo>*</mo><mi>GRs_R</mi></mtd></mtr></mtable></math><img id="ib0023" file="imgb0023.tif" wi="138" he="24" img-content="math" img-format="tif"/></maths></p><p id="p0181" num="0181">In the present invention, the rendered left/right channel outputs can be generated by using the L, R, C, Ls, and Rs generated by decoding the downmix signal into the multi-channel signal using the spatial information. And, the present invention is able to generate the rendered left/right channel outputs using the rendering information without generating the L, R, C, Ls, and Rs, in which the rendering information is generated by using the spatial information and the filter information.</p><p id="p0182" num="0182">A process for generating rendering information using spatial information is explained with reference to <figref idrefs="f0007 f0008 f0009">FIGs. 18 to 20</figref> as follows.</p><p id="p0183" num="0183"><figref idrefs="f0007">FIG. 18</figref> is a block diagram for a first method of generating rendering information in a spatial information converting unit 900 according to one embodiment of the present invention.</p><p id="p0184" num="0184">Referring to <figref idrefs="f0007">FIG. 18</figref>, as mentioned in the foregoing description, the spatial information<!-- EPO <DP n="24"> --> converting unit 900 includes the source mapping unit 1010, the sub-rendering information generating unit 1020, the integrating unit 1030, the processing unit 1040, and the domain converting unit 1050. The spatial information converting unit 900 has the same configuration shown in <figref idrefs="f0002">FIG. 3</figref>.</p><p id="p0185" num="0185">The sub-rendering information generating unit 1020 includes at least one or more sub-rendering information generating units (1<sup>st</sup> sub-rendering information generating unit to N<sup>th</sup> sub-rendering information generating unit).</p><p id="p0186" num="0186">The sub-rendering information generating unit 1020 generates sub-rendering information by using filter information and source mapping information.</p><p id="p0187" num="0187">For instance, if a downmix signal is a mono signal, the first sub-rendering information generating unit is able to generate sub-rendering information corresponding to a left channel on a multi-channel. And, the sub-rendering information can be represented as Math <figref idrefs="f0010">Figure 22</figref> using the source mapping information D_L and the converted filter information GL_L' and GL_R'</p><p id="p0188" num="0188"><maths id="math0024" num="MathFigure 22"><math display="block"><mtable columnalign="left"><mtr><mtd><mi>FL_L</mi><mo>=</mo><mi>D_L</mi><mo>*</mo><mi mathvariant="normal">GL_Lʹ</mi></mtd></mtr><mtr><mtd><mfenced separators=""><mi>mono input</mi><mo>→</mo><mi>filter coefficient to left output channel</mi></mfenced></mtd></mtr><mtr><mtd><mi>FL_R</mi><mo>=</mo><mi>D_L</mi><mo>*</mo><mi mathvariant="normal">GL_Rʹ</mi></mtd></mtr><mtr><mtd><mfenced separators=""><mi>mono input</mi><mo>→</mo><mi>filter coefficient to right output channel</mi></mfenced></mtd></mtr></mtable></math><img id="ib0024" file="imgb0024.tif" wi="121" he="42" img-content="math" img-format="tif"/></maths></p><p id="p0189" num="0189">In this case, the D_L is a value generated by using the spatial information in the source mapping unit 1010. Yet, a process for generating the D_L can follow the tree structure.</p><p id="p0190" num="0190">The second sub-rendering information generating unit is able to generate sub-rendering information FR_L and FR_R corresponding to a right channel on the multi-channel. And, the N<sup>th</sup> sub-rendering information generating unit is able to generate sub-rendering information FRs_L and FRs_R corresponding to a right surround channel on the multi-channel.</p><p id="p0191" num="0191">If a downmix signal is a stereo signal, the first sub-rendering information generating unit is able to generate sub-rendering information corresponding to the left channel on the multi-channel. And, the sub-rendering information can be represented as Math <figref idrefs="f0011">Figure 23</figref> by using the source mapping information D_L1 and D_L2.</p><p id="p0192" num="0192"><!-- EPO <DP n="25"> --><maths id="math0025" num="MathFigure 23"><math display="block"><mtable columnalign="left"><mtr><mtd><mi>FL_L</mi><mo>⁢</mo><mn>1</mn><mo>=</mo><mi>D_L</mi><mo>⁢</mo><mn>1</mn><mo>*</mo><mi mathvariant="normal">GL_Lʹ</mi></mtd></mtr><mtr><mtd><mfenced separators=""><mi>left input</mi><mo>→</mo><mi>filter coefficient to left output channel</mi></mfenced></mtd></mtr><mtr><mtd><mi>FL_L</mi><mo>⁢</mo><mn mathvariant="normal">2</mn><mo>=</mo><mi>D_L</mi><mo>⁢</mo><mn>2</mn><mo>*</mo><mi mathvariant="normal">GL_Lʹ</mi></mtd></mtr><mtr><mtd><mfenced separators=""><mi>right input</mi><mo>→</mo><mi>filter coefficient to left output channel</mi></mfenced></mtd></mtr><mtr><mtd><mi>FL_R</mi><mo>⁢</mo><mn>1</mn><mo>=</mo><mi>D_L</mi><mo>⁢</mo><mn>1</mn><mo>*</mo><mi mathvariant="normal">GL_Rʹ</mi></mtd></mtr><mtr><mtd><mfenced separators=""><mi>left input</mi><mo>→</mo><mi>filter coefficient to right output channel</mi></mfenced></mtd></mtr><mtr><mtd><mi>FL_R</mi><mo>⁢</mo><mn>2</mn><mo>=</mo><mi>D_L</mi><mo>⁢</mo><mn>2</mn><mo>*</mo><mi mathvariant="normal">GL_Rʹ</mi></mtd></mtr><mtr><mtd><mfenced separators=""><mi>right input</mi><mo>→</mo><mi>filter coefficient to right output channel</mi></mfenced></mtd></mtr></mtable></math><img id="ib0025" file="imgb0025.tif" wi="122" he="74" img-content="math" img-format="tif"/></maths></p><p id="p0193" num="0193">In Math <figref idrefs="f0011">Figure 23</figref>, the FL_R1 is explained for example as follows.</p><p id="p0194" num="0194">First of all, in the FL_R1, 'L' indicates a position of the multi-channel, 'R' indicates an output channel of a surround signal, and '1' indicates a channel of the downmix signal. Namely, the FL_R1 indicates the sub-rendering information used in generating the right output channel of the surround signal from the left channel of the downmix signal.</p><p id="p0195" num="0195">Secondly, the D_L1 and the D_L2 are values generated by using the spatial information in the source mapping unit 1010.</p><p id="p0196" num="0196">If a downmix signal is a stereo signal, it is able to generate a plurality of sub-rendering informations from at least one sub-rendering information generating unit in the same manner of the case that the downmix signal is the mono signal. The types of the sub-rendering informations generated by a plurality of the sub-rendering information generating units are exemplary, which does not put limitation on the present invention.</p><p id="p0197" num="0197">The sub-rendering information generated by the sub-rendering information generating unit 1020 is transferred to the rendering unit 900 via the integrating unit 1030, the processing unit 1040, and the domain converting unit 1050.</p><p id="p0198" num="0198">The integrating unit 1030 integrates the sub-rendering informations generated per channel into rendering information (e.g., HL_L, HL_R, HR_L, HR_R) for a rendering process. An integrating process in the integrating unit 1030 is explained for a case of a mono signal and a case of a stereo signal as follows.</p><p id="p0199" num="0199">First of all, if a downmix signal is a mono signal, rendering information can be expressed as Math <figref idrefs="f0011">Figure 24</figref>.</p><p id="p0200" num="0200"><maths id="math0026" num="MathFigure 24"><math display="block"><mtable columnalign="left"><mtr><mtd><mi>HM_L</mi><mo>=</mo><mi>FL_L</mi><mo>+</mo><mi>FR_L</mi><mo>+</mo><mi>FC_L</mi><mo>+</mo><mi>FLs_L</mi><mo>+</mo><mi>FRs_L</mi><mo>+</mo><mi>FLFE_L</mi></mtd></mtr><mtr><mtd><mi>HM_R</mi><mo>=</mo><mi>FL_R</mi><mo>+</mo><mi>FR_R</mi><mo>+</mo><mi>FC_R</mi><mo>+</mo><mi>FLs_R</mi><mo>+</mo><mi>FRs_R</mi><mo>+</mo><mi>FLFE_R</mi></mtd></mtr></mtable></math><img id="ib0026" file="imgb0026.tif" wi="114" he="25" img-content="math" img-format="tif"/></maths><!-- EPO <DP n="26"> --></p><p id="p0201" num="0201">Secondly, if a downmix signal is a stereo signal, rendering information can be expressed as Math <figref idrefs="f0012">Figure 25</figref>.</p><p id="p0202" num="0202"><maths id="math0027" num="MathFigure 25"><math display="block"><mtable columnalign="left"><mtr><mtd><mi>HM_L</mi><mo>=</mo><mi>FL_L</mi><mo>⁢</mo><mn>1</mn><mo>+</mo><mi>FR_L</mi><mo>⁢</mo><mn>1</mn><mo>+</mo><mi>FC_L</mi><mo>⁢</mo><mn>1</mn><mo>+</mo><mi>FLs_L</mi><mo>⁢</mo><mn>1</mn><mo>+</mo><mi>FRs_L</mi><mo>⁢</mo><mn>1</mn><mo>+</mo><mi>FLFE_L</mi><mo>⁢</mo><mn>1</mn></mtd></mtr><mtr><mtd><mi>HR_L</mi><mo>=</mo><mi>FL_L</mi><mo>⁢</mo><mn>2</mn><mo>+</mo><mi>FR_L</mi><mo>⁢</mo><mn>2</mn><mo>+</mo><mi>FC_L</mi><mo>⁢</mo><mn>2</mn><mo>+</mo><mi>FLs_L</mi><mo>⁢</mo><mn>2</mn><mo>+</mo><mi>FRs_L</mi><mo>⁢</mo><mn>2</mn><mo>+</mo><mi>FLFE_L</mi><mo>⁢</mo><mn>2</mn></mtd></mtr><mtr><mtd><mi>HL_R</mi><mo>=</mo><mi>FL_R</mi><mo>⁢</mo><mn>1</mn><mo>+</mo><mi>FR_R</mi><mo>⁢</mo><mn>1</mn><mo>+</mo><mi>FC_R</mi><mo>⁢</mo><mn>1</mn><mo>+</mo><mi>FLs_R</mi><mo>⁢</mo><mn>1</mn><mo>+</mo><mi>FRs_R</mi><mo>⁢</mo><mn>1</mn><mo>+</mo><mi>FLFE_R</mi><mo>⁢</mo><mn>1</mn></mtd></mtr><mtr><mtd><mi>HR_R</mi><mo>=</mo><mi>FL_R</mi><mo>⁢</mo><mn>2</mn><mo>+</mo><mi>FR_R</mi><mo>⁢</mo><mn>2</mn><mo>+</mo><mi>FC_R</mi><mo>⁢</mo><mn>2</mn><mo>+</mo><mi>FLs_R</mi><mo>⁢</mo><mn>2</mn><mo>+</mo><mi>FRs_R</mi><mo>⁢</mo><mn>2</mn><mo>+</mo><mi>FLFE_R</mi><mo>⁢</mo><mn>2</mn></mtd></mtr></mtable></math><img id="ib0027" file="imgb0027.tif" wi="126" he="39" img-content="math" img-format="tif"/></maths></p><p id="p0203" num="0203">Subsequently, the processing unit 1040 includes an interpolating unit 1041 and/or a smoothing unit 1042 and performs interpolation and/or smoothing for the rendering information. The interpolation and/or smoothing can be executed on a time domain, a frequency domain, or a QMF domain. In the specification, the time domain is taken as an example, which does not put limitation on the present invention.</p><p id="p0204" num="0204">The interpolation is performed to obtain rendering information non-existing between the rendering informations if the transmitted rendering information has a wide interval on the time domain. For instance, assuming that rendering informations exist in an n<sup>th</sup> timeslot and an (n+k)<sup>th</sup> timeslot (k&gt;1), respectively, it is able to perform linear interpolation on a not-transmitted timeslot by using the generated rendering informations (e.g., HL_L, HR_L, HL_R, HR_R).</p><p id="p0205" num="0205">The rendering information generated from the interpolation is explained with reference to a case that a downmix signal is a mono signal and a case that the downmix signal is a stereo signal.</p><p id="p0206" num="0206">If the downmix signal is the mono signal, the interpolated rendering information can be expressed as Math <figref idrefs="f0012">Figure 26</figref>.</p><p id="p0207" num="0207"><maths id="math0028" num="MathFigure 26"><math display="block"><mtable><mtr><mtd><mi>HM_L</mi><mo>⁢</mo><mfenced separators=""><mi mathvariant="normal">n</mi><mo>+</mo><mi mathvariant="normal">j</mi></mfenced><mo>=</mo><mi>HM_L</mi><mfenced><mi mathvariant="normal">n</mi></mfenced><mo>*</mo><mfenced separators=""><mn mathvariant="normal">1</mn><mo>-</mo><mi mathvariant="normal">a</mi></mfenced><mo>+</mo><mi>HM_L</mi><mo>⁢</mo><mfenced separators=""><mi mathvariant="normal">n</mi><mo>+</mo><mi mathvariant="normal">k</mi></mfenced><mo>*</mo><mi mathvariant="normal">a</mi></mtd></mtr><mtr><mtd><mi>HM_R</mi><mo>⁢</mo><mfenced separators=""><mi mathvariant="normal">n</mi><mo>+</mo><mi mathvariant="normal">j</mi></mfenced><mo>=</mo><mi>HM_R</mi><mfenced><mi mathvariant="normal">n</mi></mfenced><mo>*</mo><mfenced separators=""><mn mathvariant="normal">1</mn><mo>-</mo><mi mathvariant="normal">a</mi></mfenced><mo>+</mo><mi>HM_R</mi><mo>⁢</mo><mfenced separators=""><mi mathvariant="normal">n</mi><mo>+</mo><mi mathvariant="normal">k</mi></mfenced><mo>*</mo><mi mathvariant="normal">a</mi></mtd></mtr></mtable></math><img id="ib0028" file="imgb0028.tif" wi="97" he="23" img-content="math" img-format="tif"/></maths></p><p id="p0208" num="0208">If the downmix signal is the stereo signal, the interpolated rendering information can be expressed as Math <figref idrefs="f0013">Figure 27</figref>.</p><p id="p0209" num="0209"><maths id="math0029" num="MathFigure 27"><math display="block"><mtable columnalign="left"><mtr><mtd><mi>HL_L</mi><mo>⁢</mo><mfenced separators=""><mi mathvariant="normal">n</mi><mo>+</mo><mi mathvariant="normal">j</mi></mfenced><mo>=</mo><mi>HL_L</mi><mfenced><mi mathvariant="normal">n</mi></mfenced><mo>*</mo><mfenced separators=""><mn mathvariant="normal">1</mn><mo>-</mo><mi mathvariant="normal">a</mi></mfenced><mo>+</mo><mi>HL_L</mi><mo>⁢</mo><mfenced separators=""><mi mathvariant="normal">n</mi><mo>+</mo><mi mathvariant="normal">k</mi></mfenced><mo>*</mo><mi mathvariant="normal">a</mi></mtd></mtr><mtr><mtd><mi>HR_L</mi><mo>⁢</mo><mfenced separators=""><mi mathvariant="normal">n</mi><mo>+</mo><mi mathvariant="normal">j</mi></mfenced><mo>=</mo><mi>HR_L</mi><mfenced><mi mathvariant="normal">n</mi></mfenced><mo>*</mo><mfenced separators=""><mn mathvariant="normal">1</mn><mo>-</mo><mi mathvariant="normal">a</mi></mfenced><mo>+</mo><mi>HR_L</mi><mo>⁢</mo><mfenced separators=""><mi mathvariant="normal">n</mi><mo>+</mo><mi mathvariant="normal">k</mi></mfenced><mo>*</mo><mi mathvariant="normal">a</mi></mtd></mtr><mtr><mtd><mi>HL_R</mi><mo>⁢</mo><mfenced separators=""><mi mathvariant="normal">n</mi><mo>+</mo><mi mathvariant="normal">j</mi></mfenced><mo>=</mo><mi>HL_R</mi><mfenced><mi mathvariant="normal">n</mi></mfenced><mo>*</mo><mfenced separators=""><mn mathvariant="normal">1</mn><mo>-</mo><mi mathvariant="normal">a</mi></mfenced><mo>+</mo><mi>HL_R</mi><mo>⁢</mo><mfenced separators=""><mi mathvariant="normal">n</mi><mo>+</mo><mi mathvariant="normal">k</mi></mfenced><mo>*</mo><mi mathvariant="normal">a</mi></mtd></mtr><mtr><mtd><mi>HR_R</mi><mo>⁢</mo><mfenced separators=""><mi mathvariant="normal">n</mi><mo>+</mo><mi mathvariant="normal">j</mi></mfenced><mo>=</mo><mi>HR_R</mi><mfenced><mi mathvariant="normal">n</mi></mfenced><mo>*</mo><mfenced separators=""><mn mathvariant="normal">1</mn><mo>-</mo><mi mathvariant="normal">a</mi></mfenced><mo>+</mo><mi>HR_R</mi><mo>⁢</mo><mfenced separators=""><mi mathvariant="normal">n</mi><mo>+</mo><mi mathvariant="normal">k</mi></mfenced><mo>*</mo><mi mathvariant="normal">a</mi></mtd></mtr></mtable></math><img id="ib0029" file="imgb0029.tif" wi="97" he="38" img-content="math" img-format="tif"/></maths></p><p id="p0210" num="0210">In this case, it is 0&lt;j&lt;k. 'j' and 'k' are integers. And, 'a' is a real number corresponding to '0&lt;a&lt;1' to be expressed as Math <figref idrefs="f0013">Figure 28</figref>.<!-- EPO <DP n="27"> --></p><p id="p0211" num="0211"><maths id="math0030" num="MathFigure 28"><math display="block"><mi mathvariant="normal">a</mi><mo>=</mo><mi mathvariant="normal">j</mi><mo>/</mo><mi mathvariant="normal">k</mi></math><img id="ib0030" file="imgb0030.tif" wi="35" he="19" img-content="math" img-format="tif"/></maths></p><p id="p0212" num="0212">If so, it is able to obtain a value corresponding to the not-transmitted timeslot on a straight line connecting the values in the two timeslots according to Math <figref idrefs="f0013">Figure 27</figref> and Math <figref idrefs="f0013">Figure 28</figref>. Details of the interpolation will be explained with reference to <figref idrefs="f0010">FIG. 22</figref> and <figref idrefs="f0011">FIG. 23</figref> later.</p><p id="p0213" num="0213">In case that a filter coefficient value abruptly varies between two neighboring timeslots on a time domain, the smoothing unit 1042 executes smoothing to prevent a problem of distortion due to an occurrence of a discontinuous point. The smoothing on the time domain can be carried out using the smoothing method described with reference to <figref idrefs="f0005 f0006">FIGs. 12 to 16</figref>. The smoothing can be performed together with expansion. And, the smoothing may differ according to its applied position. If a downmix signal is a mono signal, the time domain smoothing can be represented as Math <figref idrefs="f0014">Figure 29</figref>.</p><p id="p0214" num="0214"><maths id="math0031" num="MathFigure 29"><math display="block"><mtable><mtr><mtd><mi>HM_L</mi><mfenced><mi mathvariant="normal">n</mi></mfenced><mo>⁢</mo><mi mathvariant="normal">ʹ</mi><mo>=</mo><mi>HM_L</mi><mfenced><mi mathvariant="normal">n</mi></mfenced><mo>*</mo><mi mathvariant="normal">b</mi><mo>+</mo><mi>HM_L</mi><mo>⁢</mo><mfenced separators=""><mi mathvariant="normal">n</mi><mo>-</mo><mn mathvariant="normal">1</mn></mfenced><mo>⁢</mo><mi mathvariant="normal">ʹ</mi><mo>*</mo><mfenced separators=""><mn mathvariant="normal">1</mn><mo>-</mo><mi mathvariant="normal">b</mi></mfenced></mtd></mtr><mtr><mtd><mi>HM_R</mi><mfenced><mi mathvariant="normal">n</mi></mfenced><mo>⁢</mo><mi mathvariant="normal">ʹ</mi><mo>=</mo><mi>HM_R</mi><mfenced><mi mathvariant="normal">n</mi></mfenced><mo>*</mo><mi mathvariant="normal">b</mi><mo>+</mo><mi>HM_R</mi><mo>⁢</mo><mfenced separators=""><mi mathvariant="normal">n</mi><mo>-</mo><mn mathvariant="normal">1</mn></mfenced><mo>⁢</mo><mi mathvariant="normal">ʹ</mi><mo>*</mo><mfenced separators=""><mn mathvariant="normal">1</mn><mo>-</mo><mi mathvariant="normal">b</mi></mfenced></mtd></mtr></mtable></math><img id="ib0031" file="imgb0031.tif" wi="89" he="25" img-content="math" img-format="tif"/></maths></p><p id="p0215" num="0215">Namely, the smoothing can be executed by the 1-pol IIR filter type performed in a manner of multiplying the rendering information HM_L(n-1) or HM_R(n-1) smoothed in a previous timeslot n-1 by (1-b), multiplying the rendering information HM_L(n) or HM)R(n) generated in a current timeslot n by b, and adding the two multiplications together. In this case, 'b' is a constant for 0&lt;b&lt;1. If 'b' gets smaller, a smoothing effect becomes greater. If 'b' gets bigger, a smoothing effect becomes smaller. And, the rest of the filters can be applied in the same manner.</p><p id="p0216" num="0216">The interpolation and the smoothing can be represented as one expression shown in Math <figref idrefs="f0014">Figure 30</figref> by using Math <figref idrefs="f0014">Figure 29</figref> for the time domain smoothing.</p><p id="p0217" num="0217"><maths id="math0032" num="MathFigure 30"><math display="block"><mtable columnalign="left"><mtr><mtd><mi>HM_L</mi><mo>⁢</mo><mfenced separators=""><mi mathvariant="normal">n</mi><mo>+</mo><mi mathvariant="normal">j</mi></mfenced><mo>⁢</mo><mi mathvariant="normal">ʹ</mi><mo>=</mo><mfenced separators=""><mi>HM_L</mi><mfenced><mi mathvariant="normal">n</mi></mfenced><mo>*</mo><mfenced separators=""><mn mathvariant="normal">1</mn><mo>-</mo><mi mathvariant="normal">a</mi></mfenced><mo>+</mo><mi>HM_L</mi><mo>⁢</mo><mfenced separators=""><mi mathvariant="normal">n</mi><mo>+</mo><mi mathvariant="normal">k</mi></mfenced><mo>*</mo><mi mathvariant="normal">a</mi></mfenced><mo>*</mo><mi mathvariant="normal">b</mi><mo>+</mo><mi>HM_L</mi><mo>⁢</mo><mfenced separators=""><mi mathvariant="normal">n</mi><mo>+</mo><mi mathvariant="normal">j</mi><mo>-</mo><mn mathvariant="normal">1</mn></mfenced><mo>⁢</mo><mi mathvariant="normal">ʹ</mi><mo>*</mo><mfenced separators=""><mn mathvariant="normal">1</mn><mo>-</mo><mi mathvariant="normal">b</mi></mfenced></mtd></mtr><mtr><mtd><mi>HM_R</mi><mo>⁢</mo><mfenced separators=""><mi mathvariant="normal">n</mi><mo>+</mo><mi mathvariant="normal">j</mi></mfenced><mo>⁢</mo><mi mathvariant="normal">ʹ</mi><mo>=</mo><mfenced separators=""><mi>HM_R</mi><mfenced><mi mathvariant="normal">n</mi></mfenced><mo>*</mo><mfenced separators=""><mn mathvariant="normal">1</mn><mo>-</mo><mi mathvariant="normal">a</mi></mfenced><mo>+</mo><mi>HM_R</mi><mo>⁢</mo><mfenced separators=""><mi mathvariant="normal">n</mi><mo>+</mo><mi mathvariant="normal">k</mi></mfenced><mo>*</mo><mi mathvariant="normal">a</mi></mfenced><mo>*</mo><mi mathvariant="normal">b</mi><mo>+</mo><mi>HM_R</mi><mo>⁢</mo><mfenced separators=""><mi mathvariant="normal">n</mi><mo>+</mo><mi mathvariant="normal">j</mi><mo>-</mo><mn mathvariant="normal">1</mn></mfenced><mo>⁢</mo><mi mathvariant="normal">ʹ</mi><mo>*</mo><mfenced separators=""><mn mathvariant="normal">1</mn><mo>-</mo><mi mathvariant="normal">b</mi></mfenced></mtd></mtr></mtable></math><img id="ib0032" file="imgb0032.tif" wi="152" he="26" img-content="math" img-format="tif"/></maths></p><p id="p0218" num="0218">If the interpolation is performed by the interpolating unit 1041 and/or if the smoothing is performed by the smoothing unit 1042, rendering information having an energy value different from that of prototype rendering information may be obtained. To prevent this problem, energy normalization may be executed in addition.</p><p id="p0219" num="0219">Finally, the domain converting unit 1050 performs domain conversion on the rendering information for a domain for executing the rendering. If the domain for executing the rendering is identical to the domain of rendering information, the domain<!-- EPO <DP n="28"> --> conversion may not be executed. Thereafter, the domain-converted rendering information is transferred to the rendering unit 900.</p><p id="p0220" num="0220"><figref idrefs="f0008">FIG. 19</figref> is a block diagram for a second method of generating rendering information in a spatial information converting unit according to one embodiment of the present invention.</p><p id="p0221" num="0221">The second method is similar to the first method in that a spatial information converting unit 1000 includes a source mapping unit 1010, a sub-rendering information generating unit 1020, an integrating unit 1030, a processing unit 1040, and a domain converting unit 1050 and in that the sub-rendering information generating unit 1020 includes at least one sub-rendering information generating unit.</p><p id="p0222" num="0222">Referring to <figref idrefs="f0008">FIG. 19</figref>, the second method of generating the rendering information differs from the first method in a position of the processing unit 1040. So, interpolation and/or smoothing can be performed per channel on sub-rendering information (e.g., FL_L and FL_R in case of mono signal or FL_L1, FL_L2, FL_R1, FL_R2 in case of stereo signal) generated per channel in the sub-rendering information generating unit 1020.</p><p id="p0223" num="0223">Subsequently, the integrating unit 1030 integrates the interpolated and/or smoothed sub-rendering informations into rendering information.</p><p id="p0224" num="0224">The generated rendering information is transferred to the rendering unit 900 via the domain converting unit 1050.</p><p id="p0225" num="0225"><figref idrefs="f0009">FIG. 20</figref> is a block diagram for a third method of generating rendering filter information in a spatial information converting unit according to one embodiment of the present invention.</p><p id="p0226" num="0226">The third method is similar to the first or second method in that a spatial information converting unit 1000 includes a source mapping unit 1010, a sub-rendering information generating unit 1020, an integrating unit 1030, a processing unit 1040, and a domain converting unit 1050 and in that the sub-rendering information generating unit 1020 includes at least one sub-rendering information generating unit.</p><p id="p0227" num="0227">Referring to <figref idrefs="f0009">FIG. 20</figref>, the third method of generating the rendering information differs from the first or second method in that the processing unit 1040 is located next to the source mapping unit 1010. So, interpolation and/or smoothing can be performed per channel on source mapping information generated by using spatial information in the source mapping unit 1010.</p><p id="p0228" num="0228">Subsequently, the sub-rendering information generating unit 1020 generates sub-rendering information by using the interpolated and/or smoothed source mapping information and filter information.</p><p id="p0229" num="0229">The sub-rendering information is integrated into rendering information in the integrating unit 1030. And, the generated rendering information is transferred to the<!-- EPO <DP n="29"> --> rendering unit 900 via the domain converting unit 1050.</p><p id="p0230" num="0230"><figref idrefs="f0010">FIG. 21</figref> is a diagram to explain a method of generating a surround signal in a rendering unit according to one embodiment of the present invention. <figref idrefs="f0010">FIG. 21</figref> shows a rendering process executed on a DFT domain. Yet, the rendering process can be implemented on a different domain in a similar manner as well. <figref idrefs="f0010">FIG. 21</figref> shows a case that an input signal is a mono downmix signal. Yet, <figref idrefs="f0010">FIG. 21</figref> is applicable to other input channels including a stereo downmix signal and the like in the same manner.</p><p id="p0231" num="0231">Referring to <figref idrefs="f0010">FIG. 21</figref>, a mono downmix signal on a time domain preferentially executes windowing having an overlap interval OL in the domain converting unit. <figref idrefs="f0010">Fig. 21</figref> shows a case that 50% overlap is used. Yet, the present invention includes cases of using other overlaps.</p><p id="p0232" num="0232">A window function for executing the windowing can employ a function having a good frequency selectivity on a DFT domain by being seamlessly connected without discontinuity on a time domain. For instance, a sine square window function can be used as the window function.</p><p id="p0233" num="0233">Subsequently, zero padding ZL of a tab length [precisely, (tab length) -1] of a rendering filter using rendering information converted in the domain converting unit is performed on a mono downmix signal having a length OL*2 obtained from the windowing. A domain conversion is then performed into a DFT domain. <figref idrefs="f0009">FIG. 20</figref> shows that a block-k downmix signal is domain-converted into a DFT domain.</p><p id="p0234" num="0234">The domain-converted downmix signal is rendered by a rendering filter that uses rendering information. The rendering process can be represented as a product of a downmix signal and rendering information. The rendered downmix signal undergoes IDFT (Inverse Discrete Fourier Transform) in the inverse domain converting unit and is then overlapped with the downmix signal (block k-1 in <figref idrefs="f0009">FIG. 20</figref>) previously executed with a delay of a length OL to generate a surround signal.</p><p id="p0235" num="0235">Interpolation can be performed on each block undergoing the rendering process. The interpolating method is explained as follows.</p><p id="p0236" num="0236"><figref idrefs="f0010">FIG. 22</figref> is a diagram for a first interpolating method according to one embodiment of the present invention. Interpolation according to the present invention can be executed on various positions. For instance, the interpolation can be executed on various positions in the spatial information converting unit shown in <figref idrefs="f0007 f0008 f0009">FIGs. 18 to 20</figref> or can be executed in the rendering unit. Spatial information, source mapping information, filter information and the like can be used as the values to be interpolated. In the specification, the spatial information is exemplarily used for description. Yet, the present invention is not limited to the spatial information. The interpolation is executed after or together with expansion to a wider band.</p><p id="p0237" num="0237">Referring to <figref idrefs="f0010">FIG. 22</figref>, spatial information transferred from an encoding apparatus c<!-- EPO <DP n="30"> --> an be transferred from a random position instead of being transmitted each timeslot. One spatial frame is able to carry a plurality of spatial information sets (e.g., parameter sets n and n+1 in <figref idrefs="f0010">FIG. 22</figref>). In case of a low bit rate, one spatial frame is able to carry a single new spatial information set. So, interpolation is carried out for a not-transmitted timeslot using values of a neighboring transmitted spatial information set. An interval between windows for executing rendering does not always match a timeslot. So, an interpolated value at a center of the rendering windows (K-1, K, K+1, K+2, etc.), as shown in <figref idrefs="f0010">FIG. 22</figref>, is found to use. Although <figref idrefs="f0010">FIG. 22</figref> shows that linear interpolation is carried out between timeslots where a spatial information set exists, the present invention is not limited to the interpolating method. For instance, interpolation is not carried out on a timeslot where a spatial information set does not exist. Instead, a previous or preset value can be used.</p><p id="p0238" num="0238"><figref idrefs="f0011">FIG. 23</figref> is a diagram for a second interpolating method according to one embodiment of the present invention.</p><p id="p0239" num="0239">Referring to <figref idrefs="f0011">FIG. 23</figref>, a second interpolating method according to one embodiment of the present invention has a structure that an interval using a previous value, an interval using a preset default value and the like are combined. For instance, interpolation can be performed by using at least one of a method of maintaining a previous value, a method of using a preset default value, and a method of executing linear interpolation in an interval of one spatial frame. In case that at least two new spatial information sets exist in one window, distortion may take place. In the following description, block switching for preventing the distortion is explained.</p><p id="p0240" num="0240"><figref idrefs="f0011">FIG. 24</figref> is a diagram for a block switching method according to one embodiment of the present invention.</p><p id="p0241" num="0241">Referring to (a) shown in <figref idrefs="f0011">FIG. 24</figref>, since a window length is greater than a timeslot length, at least two spatial information sets (e.g., parameter sets n and n+1 in <figref idrefs="f0011">FIG. 24</figref>) can exist in one window interval. In this case, each of the spatial information sets should be applied to a different timeslot. Yet, if one value resulting from interpolating the at least two spatial information sets is applied, distortion may take place. Namely, distortion attributed to time resolution shortage according to a window length can take place.</p><p id="p0242" num="0242">To solve this problem, a switching method of varying a window size to fit resolution of a timeslot can be used. For instance, a window size, as shown in (b) of <figref idrefs="f0011">FIG. 24</figref>, can be switched to a shorter-sized window for an interval requesting a high resolution. In this case, at a beginning and an ending portion of switched windows, connecting windows is used to prevent seams from occurring on a time domain of the switched windows.</p><p id="p0243" num="0243">The window length can be decided by using spatial information in a decoding<!-- EPO <DP n="31"> --> apparatus instead of being transferred as separate additional information. For instance, a window length can be determined by using an interval of a timeslot for updating spatial information. Namely, if the interval for updating the spatial information is narrow, a window function of short length is used. If the interval for updating the spatial information is wide, a window function of long length is used. In this case, by using a variable length window in rendering, it is advantageous not to use bits for sending window length information separately. Two types of window length are shown in (b) of <figref idrefs="f0011">FIG. 24</figref>. Yet, windows having various lengths can be used according to transmission frequency and relations of spatial information. The decided window length information is applicable to various steps for generating a surround signal, which is explained in the following description.</p><p id="p0244" num="0244"><figref idrefs="f0012">FIG. 25</figref> is a block diagram for a position to which a window length decided by a window length deciding unit is applied according to one embodiment of the present invention.</p><p id="p0245" num="0245">Referring to <figref idrefs="f0012">FIG. 25</figref>, a window length deciding unit 1400 is able to decide a window length by using spatial information. Information for the decided window length is applicable to a source mapping unit 1010, an integrating unit 1030, a processing unit 1040, domain converting units 1050 and 1100, and a inverse domain converting unit 1300. <figref idrefs="f0012">Fig. 25</figref> shows a case that a stereo downmix signal is used. Yet, the present invention is not limited to the stereo downmix signal only. As mentioned in the foregoing description, even if a window length is shortened, a length of zero padding decided according to a filter tab number is not adjustable. So, a solution for the problem is explained in the following description.</p><p id="p0246" num="0246"><figref idrefs="f0012">FIG. 26</figref> is a diagram for filters having various lengths used in processing an audio signal according to one embodiment of the present invention. As mentioned in the foregoing description, if a length of zero padding decided according to a filter tab number is not adjusted, an overlapping amounting to a corresponding length substantially occurs to bring about time resolution shortage. A solution for the problem is to reduce the length of the zero padding by restricting a length of a filter tab. A method of reducing the length of the zero padding can be achieved by truncating a rear portion of a response (e.g., a diffusing interval corresponding to reverberation). In this case, a rendering process may be less accurate than a case of not truncating the rear portion of the filter response. Yet, filter coefficient values on a time domain are very small to mainly affect reverberation. So, a sound quality is not considerably affected by the truncating.</p><p id="p0247" num="0247">Referring to <figref idrefs="f0012">FIG. 26</figref>, four kinds of filters are usable. The four kinds of the filters are usable on a DFT domain, which does not put limitation on the present invention.</p><p id="p0248" num="0248">A filter-N indicates a filter having a long filter length FL and a length 2*OL of a<!-- EPO <DP n="32"> --> long zero padding of which filter tab number is not restricted. A filter-N2 indicates a filter having a zero padding length 2*OL shorter than that of the filter-N1 by restricting a tab number of filter with the same filter length FL. A filter-N3 indicates a filter having a long zero padding length 2*OL by not restricting a tab number of filter with a filter length FL shorter than that of the filter-N1. And, a filter-N4 indicates a filter having a window length FL shorter than that of the filter-N1 with a short zero padding length 2*OL by restricting a tab number of filter.</p><p id="p0249" num="0249">As mentioned in the foregoing description, it is able to solve the problem of time resolution using the above exemplary four kinds of the filters. And, for the rear portion of the filter response, a different filter coefficient is usable for each domain.</p><p id="p0250" num="0250"><figref idrefs="f0013">FIG. 27</figref> is a diagram for a method of processing an audio signal dividedly by using a plurality of subfilters according to one embodiment of the present invention one filter may be divided into subfilters having filter coefficients differing from each other. After processing the audio signal by using the subfilters, a method of adding results of the processing can be used. In case applying spatial information to a rear portion of a filter response having small energy, i.e., in case of performing rendering by using a filter with a long filter tab, the method provides function for processing dividedly the audio signal by a predetermined length unit. For instance, since the rear portion of the filter response is not considerably varied per HRTF corresponding to each channel, it is able to perform the rendering by extracting a coefficient common to a plurality of windows. In the present specification, a case of execution on a DFT domain is described. Yet, the present invention is not limited to the DFT domain.</p><p id="p0251" num="0251">Referring to <figref idrefs="f0013">FIG. 27</figref>, after one filter FL has been divided into a plurality of sub-areas, a plurality of the sub-areas can be processed by a plurality of subfilters (filter-A and filter-B) having filter coefficients differing from each other.</p><p id="p0252" num="0252">Subsequently, an output processed by the filter-A and an output processed by the filter-B are combined together. For instance, IDFT (Inverse Discrete Fourier Transform) is performed on each of the output processed by the filter-A and the output processed by the filter-B to generate a time domain signal. And, the generated signals are added together. In this case, a position, to which the output processed by the filter-B is added, is time-delayed by FL more than a position of the output processed by the filter-A. In this way, the signal processed by a plurality of the subfilters brings the same effect of the case that the signal is processed by a single filter.</p><p id="p0253" num="0253">And, the present invention includes a method of rendering the output processed by the filter-B to a downmix signal directly. In this case, it is able to render the output to the downmix signal by using coefficients extracting from spatial information, the spatial information in part or without using the spatial information.</p><p id="p0254" num="0254">The method is characterized in that a filter having a long tab number can be applied<!-- EPO <DP n="33"> --> dividedly and that a rear portion of the filter having small energy is applicable without conversion using spatial information. In this case, if conversion using spatial information is not applied, a different filter is not applied to each processed window. So, it is unnecessary to apply the same scheme as the block switching. <figref idrefs="f0012">FIG. 26</figref> shows that the filter is divided into two areas. Yet, the present invention is able to divide the filter into a plurality of areas.</p><p id="p0255" num="0255"><figref idrefs="f0013">FIG. 28</figref> is a block diagram for a method of rendering partition rendering information generated by a plurality of subfilters to a mono downmix signal according to one embodiment of the present invention. <figref idrefs="f0013">FIG. 28</figref> relates to one rendering coefficient. The method can be executed per rendering coefficient.</p><p id="p0256" num="0256">Referring to <figref idrefs="f0013">FIG. 28</figref>, the filter-A information of <figref idrefs="f0013">FIG. 27</figref> corresponds to first partition rendering information HM_L_A and the filter-B information of <figref idrefs="f0013">FIG. 27</figref> corresponds to second partition rendering information HM_L_B. <figref idrefs="f0013">FIG. 28</figref> shows an embodiment of partition into two subfilters. Yet, the present invention is not limited to the two subfilters. The two subfilters can be obtained via a splitting unit 1500 using the rendering information HM_L generated in the spatial information generating unit 1000. Alternatively, the two subfilters can be obtained using prototype HRTF information or information decided according to a user's selection. The information decided according to a user's selection may include spatial information selected according to a user's taste for example. In this case, HM_L_A is the rendering information based on the received spatial information. and, HM_L_B may be the rendering information for providing a 3-dimensional effect commonly applied to signals.</p><p id="p0257" num="0257">As mentioned in the foregoing description, the processing with a plurality of the subfilters is applicable to a time domain and a QMF domain as well as the DFT domain. In particular, the coefficient values split by the filter-A and the filter-B are applied to the downmix signal by time or QMF domain rendering and are then added to generate a final signal.</p><p id="p0258" num="0258">The rendering unit 900 includes a first partition rendering unit 950 and a second partition rendering unit 960. The first partition rendering unit 950 performs a rendering process using HM_L_A, whereas the second partition rendering unit 960 performs a rendering process using HM_L_B.</p><p id="p0259" num="0259">If the filter-A and the filter-B, as shown in <figref idrefs="f0013">FIG. 27</figref>, are splits of a same filter according to time, it is able to consider a proper delay to correspond to the time interval. <figref idrefs="f0013">FIG. 28</figref> shows an example of a mono downmix signal. In case of using mono downmix signal and decorrelator, a portion corresponding to the filter-B is applied not to the decorrelator but to the mono downmix signal directly.</p><p id="p0260" num="0260"><figref idrefs="f0014">FIG. 29</figref> is a block diagram for a method of rendering partition rendering information<!-- EPO <DP n="34"> --> generated using a plurality of subfilters to a stereo downmix signal according to one embodiment of the present invention.</p><p id="p0261" num="0261">A partition rendering process shown in <figref idrefs="f0014">FIG. 29</figref> is similar to that of <figref idrefs="f0013">FIG. 28</figref> in that two subfilters are obtained in a splitter 1500 by using rendering information generated by the spatial information converting unit 1000, prototype HRTF filter information or user decision information. The difference from <figref idrefs="f0013">FIG. 28</figref> lies in that a partition rendering process corresponding to the filter-B is commonly applied to L/R signals.</p><p id="p0262" num="0262">In particular, the splitter 1500 generates first partition rendering information corresponding to filter-A information, second partition rendering information, and third partition rendering information corresponding to filter-B information. In this case, the third partition rendering information can be generated by using filter information or spatial information commonly applicable to the L/R signals.</p><p id="p0263" num="0263">Referring to <figref idrefs="f0014">FIG. 29</figref>, a rendering unit 900 includes a first partition rendering unit 970, a second partition rendering unit 980, and a third partition rendering unit 990.</p><p id="p0264" num="0264">The third partition rendering information generates is applied to a sum signal of the L/R signals in the third partition rendering unit 990 to generate one output signal. The output signal is added to the L/R output signals, which are independently rendered by a filter-A1 and a filter-A2 in the first and second partition rendering units 970 and 980, respectively, to generate surround signals. In this case, the output signal of the third partition rendering unit 990 can be added after an appropriate delay. In <figref idrefs="f0014">FIG. 29</figref>, an expression of cross rendering information applied to another channel from L/R inputs is omitted for convenience of explanation.</p><p id="p0265" num="0265"><figref idrefs="f0014">FIG. 30</figref> is a block diagram for a first domain converting method of a downmix signal according to one embodiment of the present invention. The rendering process executed on the DFT domain has been described so far. As mentioned in the foregoing description, the rendering process is executable on other domains as well as the DFT domain. Yet, <figref idrefs="f0014">FIG. 30</figref> shows the rendering process executed on the DFT domain. A domain converting unit 1100 includes a QMF filter and a DFT filter. An inverse domain converting unit 1300 includes an IDFT filter and an IQMF filter. <figref idrefs="f0014">FIG. 30</figref> relates to a mono downmix signal, which does not put limitation on the present invention.</p><p id="p0266" num="0266">Referring to <figref idrefs="f0014">Fig. 30</figref>, a time domain downmix signal of p samples passes through a QMF filter to generate P sub-band samples. W samples are recollected per band. After windowing is performed on the recollected samples, zero padding is performed. M-point DFT (FFT) is then executed. In this case, the DFT enables a processing by the aforesaid type windowing. A value connecting the M/2 frequency domain values per band obtained by the M-point DFT to P bands can be regarded as an approximate value of a frequency spectrum obtained by M/2*P-point DFT. So, a filter coefficient<!-- EPO <DP n="35"> --> represented on a M/2*P-point DFT domain is multiplied by the frequency spectrum to bring the same effect of the rendering process on the DFT domain.</p><p id="p0267" num="0267">In this case, the signal having passed through the QMF filter has leakage, e.g., aliasing between neighboring bands. In particular, a value corresponding to a neighbor band smears in a current band and a portion of a value existing in the Current band is shifted to the neighbor band. In this case, if QMF integration is executed, an original signal can be recovered due to QMF characteristics. Yet, if a filtering process is performed on the signal of the corresponding band as the case in the present invention, the signal is distorted by the leakage. To minimize this problem, a process for recovering an original signal can be added in a manner of having a signal pass through a leakage minimizing butterfly B prior to performing DFT per band after QMF in the domain converting unit 100 and performing a reversing process V after IDFT in the inverse domain converting unit 1300.</p><p id="p0268" num="0268">Meanwhile, to match the generating process of the rendering information generated in the spatial information converting unit 1000 with the generating process of the downmix signal, DFT can be performed on a QMF pass signal for prototype filter information instead of executing M/2*P-point DFT in the beginning. In this case, delay and data spreading due to QMF filter may exist.</p><p id="p0269" num="0269"><figref idrefs="f0015">FIG. 31</figref> is a block diagram for a second domain converting method of a downmix signal according to one embodiment of the present invention. <figref idrefs="f0015">FIG. 31</figref> shows a rendering process performed on a QMF domain.</p><p id="p0270" num="0270">Referring to <figref idrefs="f0015">FIG. 31</figref>, a domain converting unit 1100 includes a QMF domain converting unit and an inverse domain converting unit 1300 includes an IQMF domain converting unit. A configuration shown in <figref idrefs="f0015">FIG. 31</figref> is equal to that of the case of using DFT only except that the domain converting unit is a QMF filter. In the following description, the QMF is referred to as including a QMF and a hybrid QMF having the same bandwidth. The difference from the case of using DFT only lies in that the generation of the rendering information is performed on the QMF domain and that the rendering process is represented as a convolution instead of the product on the DFT domain, since the rendering process performed by a renderer-M 3012 is executed on the QMF domain.</p><p id="p0271" num="0271">Assuming that the QMF filter is provided with B bands, a filter coefficient can be represented as a set of filter coefficients having different features (coefficients) for the B bands. Occasionally, if a filter tab number becomes a first order (i.e., multiplied by a constant), a rendering process on a DFT domain having B frequency spectrums and an operational process are matched. Math <figref idrefs="f0015">Figure 31</figref> represents a rendering process executed in one QMF band (b) for one path for performing the rendering process using rendering information HM_L.<!-- EPO <DP n="36"> --></p><p id="p0272" num="0272"><maths id="math0033" num="MathFigure 31"><math display="block"><msub><mi mathvariant="italic">Lo_m</mi><mi>b</mi></msub><mfenced><mi>k</mi></mfenced><mo>=</mo><msub><mi mathvariant="italic">HM_L</mi><mi>b</mi></msub><mo>*</mo><mi>m</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi mathvariant="italic">filter_order</mi><mo>-</mo><mn>1</mn></mrow></munderover></mstyle><msub><mi mathvariant="italic">hm_l</mi><mi>b</mi></msub><mfenced><mi>i</mi></mfenced><mo>⁢</mo><msub><mi>m</mi><mi>b</mi></msub><mo>⁢</mo><mfenced separators=""><mi>k</mi><mo>-</mo><mi>i</mi></mfenced></math><img id="ib0033" file="imgb0033.tif" wi="128" he="34" img-content="math" img-format="tif"/></maths></p><p id="p0273" num="0273">In this case, k indicates a time order in QMF band, i.e., a timeslot unit. The rendering process executed on the QMF domain is advantageous in that, if spatial information transmitted is a value applicable to the QMF domain, application of corresponding data is most facilitated and that distortion in the course of application can be minimized. Yet, in case of QMF domain conversion in the prototype filter information (e.g., prototype filter coefficient) converting process, a considerable operational quantity is required for a process of applying the converted value. In this case, the operational quantity can be minimized by the method of parameterizing the HRTF coefficient in the filter information converting process.</p><heading id="h0009"><b>Industrial Applicability</b></heading><p id="p0274" num="0274">Accordingly, the signal processing method and apparatus of the present invention uses spatial information provided by an encoder to generate surround signals by using HRTF filter information or filter information according to a user in a decoding apparatus in capable of generating multi-channels. And, the present invention is usefully applicable to various kinds of decoders capable of reproducing stereo signals only.</p><p id="p0275" num="0275">While the present invention has been described and illustrated herein with reference to the preferred embodiments thereof, it will be apparent to those skilled in the art that various modifications and variations can be made therein without departing from the scope of the invention. Thus, it is intended that the present invention covers the modifications and variations of this invention that come within the scope of the appended claims and their equivalents.</p></description><claims mxw-id="PCLM56979236" lang="DE" load-source="patent-office"><!-- EPO <DP n="39"> --><claim id="c-de-01-0001" num="0001"><claim-text>Verfahren zur Verarbeitung eines Audiosignals, umfassend:
<claim-text>Empfangen eines Downmix-Signals und von Rauminformationen, wobei die Rauminformationen zumindest Kanalpegeldifferenz-, "CLD", Parameter umfassen, wobei das Downmix-Signal durch Herabmischen eines Mehrkanalaudiosignals erzeugt wird;</claim-text>
<claim-text>Erzeugen von Quellabbildungsinformationen durch Verwenden der Rauminformationen;</claim-text>
<claim-text>Erzeugen von Unter-Renderinginformationen durch Anwenden von Head-related transfer function-, "HRTF", Filterinformationen für einen Surroundeffekt auf die Quellabbildungsinformationen;</claim-text>
<claim-text>Erzeugen von Renderinginformationen durch Integrieren der Unter-Renderinginformationen; und</claim-text>
<claim-text>Erzeugen eines Surroundsignals mit dem Surroundeffekt durch Anwenden der Renderinginformationen auf das Downmix-Signal, wobei</claim-text>
<claim-text>das Downmix-Signal einen linken Eingangskanal und einen rechten Eingangskanal umfasst, und wobei das erzeugte Surroundsignal einen linken Ausgangskanal und einen rechten Ausgangssignal umfasst, und</claim-text>
<claim-text>die Rendering-Informationen eine erste Renderinginformation und eine zweite Renderinginformation umfassen, wobei die erste Renderinginformation zum Erzeugen des linken Ausgangskanals dient durch ihre Anwendung auf den linken Eingangskanal oder zum Erzeugen des rechten Ausgangskanals dient durch ihre Anwendung auf den rechten Eingangskanal, und die zweite Renderinginformation zum Erzeugen des rechten Ausgangskanals dient durch ihre Anwendung auf den linken Eingangskanal oder zum Erzeugen des linken Ausgangskanals dient durch ihre Anwendung auf den rechten Eingangskanal.</claim-text></claim-text></claim><claim id="c-de-01-0002" num="0002"><claim-text>Verfahren gemäß Anspruch 1, wobei die Rauminformationen weiterhin Interkanalkorrelationsparameter umfassen.</claim-text></claim><claim id="c-de-01-0003" num="0003"><claim-text>Verfahren gemäß Anspruch 1 oder 2, wobei die Quellabbildungsinformationen Informationen in Entsprechung zu jedem Kanal des Mehrkanalaudiosignals sind.<!-- EPO <DP n="40"> --></claim-text></claim><claim id="c-de-01-0004" num="0004"><claim-text>Verfahren gemäß zumindest einem der Ansprüche 1 bis 3, wobei die Unter-Renderinginformationen Informationen umfassen, die erzeugt sind durch Anwendung der HRTF-Filterinformationen auf zumindest zwei Quellabbildungsinformationen.</claim-text></claim><claim id="c-de-01-0005" num="0005"><claim-text>Verfahren gemäß zumindest einem der Ansprüche 1 bis 4, wobei die HRTF-Filterinformationen in Informationen eines Bereichs des erzeugten Surroundsignalbereichs umgewandelt werden.</claim-text></claim><claim id="c-de-01-0006" num="0006"><claim-text>Vorrichtung zur Verarbeitung eines Audiosignals, umfassend:
<claim-text>- eine Demultiplexingeinheit (600), die ein Downmix-Signal und Rauminformationen empfängt, wobei die Rauminformationen zumindest Kanalpegeldifferenz-, "CLD", Parameter umfassen, wobei das Downmix-Signal durch Herabmischen eines Mehrkanalaudiosignals erzeugt wird;<br/>
eine Quellabbildungseinheit (1010), die Quellabbildungsinformationen unter Verwendung der Rauminformationen erzeugt;<br/>
eine Unter-Renderinginformationserzeugungseinheit (1020), die Unter-Renderinginformationen erzeugt durch Anwenden von Head-related transfer function-, "HRTF", Filterinformationen für einen Surroundeffekt auf die Quellabbildungsinformationen;<br/>
eine Integrationseinheit (1030), die Rendering-Informationen durch Integrieren der zumindest einen der Unter-Renderinginformationen erzeugt; und<br/>
eine Renderingeinheit (900), die ein Surroundsignal mit dem Surroundeffekt erzeugt durch Anwenden der Rendering-Informationen auf das Downmix-Signal, wobei<br/>
das Downmix-Signal einen linken Eingangskanal und einen rechten Eingangskanal umfasst, und wobei das erzeugte Surroundsignal einen linken Ausgangskanal und einen rechten Ausgangskanal umfasst, und<br/>
die Renderinginformationen eine erste Renderinginformation und eine zweite Renderinginformation umfassen, wobei die erste Renderinginformation zum Erzeugen des linken Ausgangskanals dient durch ihre Anwendung auf den linken Eingangskanal oder zum Erzeugen des rechten Ausgangskanals dient durch ihre Anwendung auf den rechten Eingangskanal, und wobei die zweite Renderinginformation zum Erzeugen des rechten Ausgangskanals dient durch ihre Anwendung auf den linken Eingangskanal oder zum Erzeugen des linken Ausgangskanals dient durch ihre Anwendung auf den rechten Eingangskanal.</claim-text></claim-text></claim><claim id="c-de-01-0007" num="0007"><claim-text>Vorrichtung gemäß Anspruch 6, wobei die Rauminformationen weiterhin Interkanalkorrelationsparameter umfassen.<!-- EPO <DP n="41"> --></claim-text></claim><claim id="c-de-01-0008" num="0008"><claim-text>Vorrichtung gemäß Anspruch 6 oder 7, wobei die Quellabbildungsinformationen Informationen in Entsprechung zu jedem Kanal des Mehrkanalsignals sind.</claim-text></claim><claim id="c-de-01-0009" num="0009"><claim-text>Vorrichtung gemäß zumindest einem der Ansprüche 6 bis 8, wobei die Unter-Renderinginformationen Informationen umfassen, die erzeugt werden durch Anwenden der HRTF-Filterinformation auf zumindest zwei Quellabbildungsinformationen.</claim-text></claim><claim id="c-de-01-0010" num="0010"><claim-text>Vorrichtung gemäß zumindest einem der Ansprüche 6 bis 9, wobei die Filterinformationen in Informationen eines Bereichs des erzeugten Surroundsignalbereichs umgewandelt werden.</claim-text></claim></claims><claims mxw-id="PCLM56979237" lang="EN" load-source="patent-office"><!-- EPO <DP n="37"> --><claim id="c-en-01-0001" num="0001"><claim-text>A method of processing an audio signal, comprising:
<claim-text>receiving a downmix signal and spatial information, the spatial information including at least channel level difference "CLD" parameters, the downmix signal generated by downmixing a multi-channel audio signal;</claim-text>
<claim-text>generating source mapping information by using the spatial information;</claim-text>
<claim-text>generating sub-rendering information by applying Head-Related Transfer Function "HRTF" filter information for a surround effect to the source mapping information;</claim-text>
<claim-text>generating rendering information by integrating the sub-rendering information; and</claim-text>
<claim-text>generating a surround signal having the surround effect by applying the rendering information to the downmix signal, wherein</claim-text>
<claim-text>the downmix signal include a left input channel and a right input channel, and the generated surround signal includes a left output channel and a right output channel, and</claim-text>
<claim-text>the rending information comprises a first rendering information and a second rendering information, the first rendering information for generating the left output channel by being applied to the left input channel or for generating the right output channel by being applied to the right input channel and the second rendering information for generating the right output channel by being applied to the left input channel or for generating the left output channel by being applied to the right input channel.</claim-text></claim-text></claim><claim id="c-en-01-0002" num="0002"><claim-text>The method of claim 1, wherein the spatial information further includes inter-channel correlation parameters.</claim-text></claim><claim id="c-en-01-0003" num="0003"><claim-text>The method of claims 1 or 2, wherein the source mapping information is information corresponding to each channel of the multi-channel audio signal.</claim-text></claim><claim id="c-en-01-0004" num="0004"><claim-text>The method of any one of claims 1 to 3, wherein the sub-rendering information includes information generated by applying the HRTF filter information to at least two source mapping informations.</claim-text></claim><claim id="c-en-01-0005" num="0005"><claim-text>The method of any one of claims 1 to 4, wherein the HRTF filter information is domain-converted into information of a domain of the generated the surround signal.<!-- EPO <DP n="38"> --></claim-text></claim><claim id="c-en-01-0006" num="0006"><claim-text>An apparatus for processing an audio signal, comprising:
<claim-text>a demultiplexing unit (600) that receives a downmix signal and spatial information, the spatial information including at least channel level difference "CLD" parameters, the downmix signal generated by downmixing a multi-channel audio signal;</claim-text>
<claim-text>a source mapping unit (1010) that generates source mapping information by using the spatial information;</claim-text>
<claim-text>a sub-rendering information generating unit (1020) that generates sub-rendering information by applying Head-Related Transfer Function "HRTF" filter information for a surround effect to the source mapping information;</claim-text>
<claim-text>an integrating unit (1030) that generates rendering information by integrating the at least one of the sub-rendering information; and</claim-text>
<claim-text>a rendering unit (900) that generates a surround signal having the surround effect by applying the rendering information to the downmix signal, wherein</claim-text>
<claim-text>the downmix signal include a left input channel and a right input channel, and the generated surround signal includes a left output channel and a right output channel, and</claim-text>
<claim-text>the rending information comprises a first rendering information and a second rendering information, the first rendering information for generating the left output channel by being applied to the left input channel or for generating the right output channel by being applied to the right input channel and the second rendering information for generating the right output channel by being applied to the left input channel or for generating the left output channel by being applied to the right input channel.</claim-text></claim-text></claim><claim id="c-en-01-0007" num="0007"><claim-text>The apparatus of claim 6, wherein the spatial information further includes inter-channel correlation parameters.</claim-text></claim><claim id="c-en-01-0008" num="0008"><claim-text>The apparatus of claims 6 or 7, wherein the source mapping information is information corresponding to each channel of the multi-channel signal.</claim-text></claim><claim id="c-en-01-0009" num="0009"><claim-text>The apparatus of any one of claims 6 to 8, wherein the sub-rendering information includes information generated by applying the HRTF filter information to at least two source mapping informations.</claim-text></claim><claim id="c-en-01-0010" num="0010"><claim-text>The apparatus of any one of claims 6 to 9, wherein the filter information is domain-converted into information of a domain of the generated surround signal.</claim-text></claim></claims><claims mxw-id="PCLM56979238" lang="FR" load-source="patent-office"><!-- EPO <DP n="42"> --><claim id="c-fr-01-0001" num="0001"><claim-text>Procédé de traitement d'un signal audio, comprenant les étapes consistant à:
<claim-text>recevoir un signal de sous-mixage et des informations spatiales, les informations spatiales incluant au moins des paramètres de différence de niveau de canal « CLD », le signal de sous-mixage généré en sous-mixant un signal audio multicanaux ;</claim-text>
<claim-text>générer des informations de mise en correspondance de source en utilisant les informations spatiales ;</claim-text>
<claim-text>générer des informations de sous-rendu en appliquant les informations de filtre de fonction de transfert asservi aux mouvements de la tête « HRTF » pour un effet d'ambiance aux informations de mise en correspondance de source ;</claim-text>
<claim-text>générer des informations de rendu en intégrant les informations de sous-rendu ; et</claim-text>
<claim-text>générer un signal d'ambiance ayant l'effet d'ambiance en appliquant les informations de rendu au signal de sous-mixage, dans lequel</claim-text>
<claim-text>le signal de sous-mixage comprend un canal d'entrée de gauche et un canal d'entrée de droite, et le signal d'ambiance généré comprend un canal de sortie de gauche et un canal de sortie de droite, et</claim-text>
<claim-text>les informations de rendu comprennent des premières informations de rendu et des deuxièmes informations de rendu, les premières informations de rendu destinées à générer le canal de sortie de gauche en étant appliquées au canal d'entrée de gauche ou destinées à générer le canal de sortie de droite en étant appliquées au canal d'entrée de droite et les deuxièmes informations de rendu destinées à générer le canal de sortie de droite en étant appliquées au canal d'entrée de gauche ou destinées à générer le canal de sortie de gauche en étant appliquées au canal d'entrée de droite.</claim-text></claim-text></claim><claim id="c-fr-01-0002" num="0002"><claim-text>Procédé selon la revendication 1, dans lequel les informations spatiales comprennent en outre des paramètres de corrélation entre canaux.</claim-text></claim><claim id="c-fr-01-0003" num="0003"><claim-text>Procédé selon la revendication 1 ou 2, dans lequel les informations de mise en correspondance de source sont des informations correspondant à chaque canal du signal audio multicanaux.<!-- EPO <DP n="43"> --></claim-text></claim><claim id="c-fr-01-0004" num="0004"><claim-text>Procédé selon l'une quelconque des revendications 1 à 3, dans lequel les informations de sous-rendu comprennent des informations générées en appliquant les informations de filtre HRTF à au moins deux informations de mise en correspondance de source.</claim-text></claim><claim id="c-fr-01-0005" num="0005"><claim-text>Procédé selon l'une quelconque des revendications 1 à 4, dans lequel les informations de filtre HRTF sont converties en domaine en informations d'un domaine du signal d'ambiance généré.</claim-text></claim><claim id="c-fr-01-0006" num="0006"><claim-text>Appareil de traitement d'un signal audio, comprenant:
<claim-text>une unité (600) de démultiplexage qui reçoit un signal de sous-mixage et des informations spatiales, les informations spatiales incluant au moins des paramètres de différence de niveau de canal « CLD », le signal de sous-mixage généré en sous-mixant un signal audio multicanaux ;</claim-text>
<claim-text>une unité (1010) de mise en correspondance de source qui génère des informations de mise en correspondance de source en utilisant les informations spatiales ;</claim-text>
<claim-text>une unité (1020) de génération d'informations de sous-rendu qui génère des informations de sous-rendu en appliquant des informations de filtre de fonction de transfert asservie aux mouvements de la tête « HRTF » pour un effet d'ambiance aux informations de mise en correspondance de source ;</claim-text>
<claim-text>une unité (1030) d'intégration qui génère des informations de rendu en intégrant au moins l'une des informations de sous-rendu ; et</claim-text>
<claim-text>une unité (900) de rendu qui génère un signal d'ambiance ayant l'effet d'ambiance en appliquant les informations de rendu au signal de sous-mixage, dans lequel</claim-text>
<claim-text>le signal de sous-mixage comprend un canal d'entrée de gauche et un canal d'entrée de droite, et le signal d'ambiance généré comprend un canal de sortie de gauche et un canal de sortie de droite, et</claim-text>
<claim-text>les informations de rendu comprennent des premières informations de rendu et deuxièmes informations de rendu, les premières informations de rendu destinées à générer le canal de sortie de gauche en étant appliquées au canal d'entrée de gauche ou destinées à générer le canal de sortie de droite en étant appliquées au canal d'entrée de droite et les deuxièmes informations de rendu destinées à générer le canal de sortie de droite en étant appliquées au canal d'entrée de gauche ou destinées à générer le canal de sortie de gauche en étant appliquées au canal d'entrée de droite.</claim-text><!-- EPO <DP n="44"> --></claim-text></claim><claim id="c-fr-01-0007" num="0007"><claim-text>Appareil selon la revendication 6, dans lequel les informations spatiales comprennent en outre des paramètres de corrélation entre canaux.</claim-text></claim><claim id="c-fr-01-0008" num="0008"><claim-text>Appareil selon la revendication 6 ou 7, dans lequel les informations de mise en correspondance de source sont des informations correspondant à chaque canal du signal multicanaux.</claim-text></claim><claim id="c-fr-01-0009" num="0009"><claim-text>Appareil selon l'une quelconque des revendications 6 à 8, dans lequel les informations de sous-rendu comprennent des informations générées en appliquant les informations de filtre HRTF à au moins deux informations de mise en correspondance de source.</claim-text></claim><claim id="c-fr-01-0010" num="0010"><claim-text>Appareil selon l'une quelconque des revendications 6 à 9, dans lequel les informations de filtre sont converties en domaine en informations d'un domaine du signal d'ambiance généré.</claim-text></claim></claims><drawings mxw-id="PDW16668809" load-source="patent-office"><!-- EPO <DP n="45"> --><figure id="f0001" num="1,2"><img id="if0001" file="imgf0001.tif" wi="110" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="46"> --><figure id="f0002" num="3,4"><img id="if0002" file="imgf0002.tif" wi="132" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="47"> --><figure id="f0003" num="5,6,7"><img id="if0003" file="imgf0003.tif" wi="130" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="48"> --><figure id="f0004" num="8,9,10,11"><img id="if0004" file="imgf0004.tif" wi="130" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="49"> --><figure id="f0005" num="12,13,14,15"><img id="if0005" file="imgf0005.tif" wi="114" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="50"> --><figure id="f0006" num="16,17"><img id="if0006" file="imgf0006.tif" wi="125" he="170" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="51"> --><figure id="f0007" num="18"><img id="if0007" file="imgf0007.tif" wi="132" he="175" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="52"> --><figure id="f0008" num="19"><img id="if0008" file="imgf0008.tif" wi="130" he="171" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="53"> --><figure id="f0009" num="20"><img id="if0009" file="imgf0009.tif" wi="132" he="174" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="54"> --><figure id="f0010" num="21,22"><img id="if0010" file="imgf0010.tif" wi="151" he="216" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="55"> --><figure id="f0011" num="23,24(a),24(b)"><img id="if0011" file="imgf0011.tif" wi="135" he="180" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="56"> --><figure id="f0012" num="25,26"><img id="if0012" file="imgf0012.tif" wi="133" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="57"> --><figure id="f0013" num="27,28"><img id="if0013" file="imgf0013.tif" wi="165" he="211" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="58"> --><figure id="f0014" num="29,30"><img id="if0014" file="imgf0014.tif" wi="165" he="207" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="59"> --><figure id="f0015" num="31"><img id="if0015" file="imgf0015.tif" wi="141" he="116" img-content="drawing" img-format="tif"/></figure></drawings><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
