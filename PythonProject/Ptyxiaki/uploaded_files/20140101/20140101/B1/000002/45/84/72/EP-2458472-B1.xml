<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2458472-B1" country="EP" doc-number="2458472" kind="B1" date="20140101" family-id="45315518" file-reference-id="315078" date-produced="20180826" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="146553063" ucid="EP-2458472-B1"><document-id><country>EP</country><doc-number>2458472</doc-number><kind>B1</kind><date>20140101</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-11190551-A" is-representative="YES"><document-id mxw-id="PAPP154826986" load-source="docdb" format="epo"><country>EP</country><doc-number>11190551</doc-number><kind>A</kind><date>20111124</date><lang>EN</lang></document-id><document-id mxw-id="PAPP190123557" load-source="docdb" format="original"><country>EP</country><doc-number>11190551.9</doc-number><date>20111124</date></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC140448279" ucid="KR-20100119282-A" load-source="docdb"><document-id format="epo"><country>KR</country><doc-number>20100119282</doc-number><kind>A</kind><date>20101129</date></document-id></priority-claim></priority-claims><dates-of-public-availability><intention-to-grant-date><date>20130620</date></intention-to-grant-date></dates-of-public-availability><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL1988118063" load-source="docdb">G01S   7/52        20060101ALI20130603BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1988118354" load-source="docdb">A61B   8/00        20060101ALI20130603BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1988124347" load-source="docdb">G06F   1/16        20060101AFI20130603BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL1988125507" load-source="docdb">G06F   3/01        20060101ALI20130603BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-1645109340" load-source="docdb" scheme="CPC">G06F  19/00        20130101 LI20180430BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1999877479" load-source="docdb" scheme="CPC">G06F   1/1601      20130101 LI20151114BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1999881164" load-source="docdb" scheme="CPC">G01S   7/52        20130101 LI20151114BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1999883720" load-source="docdb" scheme="CPC">A61B   8/463       20130101 LI20151116BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1999884836" load-source="docdb" scheme="CPC">G06F   3/013       20130101 LI20151116BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1999885304" load-source="docdb" scheme="CPC">A61B   8/462       20130101 FI20151116BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1999885321" load-source="docdb" scheme="CPC">G09G2320/0261      20130101 LA20151114BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1999886803" load-source="docdb" scheme="CPC">G09G2340/045       20130101 LA20151114BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT132191673" lang="DE" load-source="patent-office">Ultraschallsystem zur Bereitstellung eines für die Haltung eines Benutzers optimierten Ultraschallbildes</invention-title><invention-title mxw-id="PT132191674" lang="EN" load-source="patent-office">Ultrasound system for providing an ultrasound image optimized for posture of a user</invention-title><invention-title mxw-id="PT132191675" lang="FR" load-source="patent-office">Système ultrasonore permettant de fournir une image ultrasonore optimisée pour la position d'un utilisateur</invention-title></technical-data><parties><applicants><applicant mxw-id="PPAR918132413" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>SAMSUNG MEDISON CO LTD</last-name><address><country>KR</country></address></addressbook></applicant><applicant mxw-id="PPAR918138891" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>SAMSUNG MEDISON CO., LTD.</last-name></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR918164145" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>KIM JUNG SOO</last-name><address><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR918157159" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>KIM, JUNG SOO</last-name></addressbook></inventor><inventor mxw-id="PPAR918996131" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>KIM, JUNG SOO</last-name><address><street>3 Fl., R&amp;D Center, Samsung Medison Co., Ltd., Medison Building, 1003 Daechi-dong, Gangnam-gu,</street><city>135-851 Seoul</city><country>KR</country></address></addressbook></inventor></inventors><assignees><assignee mxw-id="PPAR918996133" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Samsung Medison Co., Ltd.</last-name><iid>101239841</iid><address><street>114, Yangdukwon-ri</street><city>Nam-myun Hongchun-gun Kangwon do 250-875</city><country>KR</country></address></addressbook></assignee></assignees><agents><agent mxw-id="PPAR918996132" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Schmid, Wolfgang</last-name><iid>101034322</iid><address><street>Lorenz &amp; Kollegen Patentanwälte Partnerschaftsgesellschaft Alte Ulmer Straße 2</street><city>89522 Heidenheim</city><country>DE</country></address></addressbook></agent></agents></parties><international-convention-data><designated-states><ep-contracting-states><country mxw-id="DS548826464" load-source="docdb">AL</country><country mxw-id="DS548972533" load-source="docdb">AT</country><country mxw-id="DS548826465" load-source="docdb">BE</country><country mxw-id="DS548966524" load-source="docdb">BG</country><country mxw-id="DS548964970" load-source="docdb">CH</country><country mxw-id="DS548881266" load-source="docdb">CY</country><country mxw-id="DS548972534" load-source="docdb">CZ</country><country mxw-id="DS548826466" load-source="docdb">DE</country><country mxw-id="DS548881267" load-source="docdb">DK</country><country mxw-id="DS548881268" load-source="docdb">EE</country><country mxw-id="DS548974283" load-source="docdb">ES</country><country mxw-id="DS548966525" load-source="docdb">FI</country><country mxw-id="DS548966530" load-source="docdb">FR</country><country mxw-id="DS548826467" load-source="docdb">GB</country><country mxw-id="DS548881269" load-source="docdb">GR</country><country mxw-id="DS548826468" load-source="docdb">HR</country><country mxw-id="DS548972535" load-source="docdb">HU</country><country mxw-id="DS548964971" load-source="docdb">IE</country><country mxw-id="DS548881270" load-source="docdb">IS</country><country mxw-id="DS548966531" load-source="docdb">IT</country><country mxw-id="DS548881271" load-source="docdb">LI</country><country mxw-id="DS548965513" load-source="docdb">LT</country><country mxw-id="DS548972536" load-source="docdb">LU</country><country mxw-id="DS548965586" load-source="docdb">LV</country><country mxw-id="DS548965587" load-source="docdb">MC</country><country mxw-id="DS548852847" load-source="docdb">MK</country><country mxw-id="DS548852848" load-source="docdb">MT</country><country mxw-id="DS548974284" load-source="docdb">NL</country><country mxw-id="DS548966532" load-source="docdb">NO</country><country mxw-id="DS548852849" load-source="docdb">PL</country><country mxw-id="DS548964972" load-source="docdb">PT</country><country mxw-id="DS548974285" load-source="docdb">RO</country><country mxw-id="DS548964973" load-source="docdb">RS</country><country mxw-id="DS548852850" load-source="docdb">SE</country><country mxw-id="DS548964978" load-source="docdb">SI</country><country mxw-id="DS548966533" load-source="docdb">SK</country><country mxw-id="DS548852851" load-source="docdb">SM</country><country mxw-id="DS548881272" load-source="docdb">TR</country></ep-contracting-states></designated-states></international-convention-data></bibliographic-data><description mxw-id="PDES63957057" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><heading id="h0001">TECHNICAL FIELD</heading><p id="p0001" num="0001">The present invention generally relates to ultrasound systems, and more particularly to an ultrasound system for providing an ultrasound image optimized according to the posture of a user.</p><heading id="h0002">BACKGROUND</heading><p id="p0002" num="0002">An ultrasound system with non-invasive and non-destructive nature has been extensively used in the medical field to obtain information on an inside of a target object. Such an ultrasound system provides a doctor in real time with a high resolution image of the inside of the target object without the need to perform any surgical operation, which can be used to play an important role in the medical field.</p><p id="p0003" num="0003">The ultrasound system transmits ultrasound signals to the target object, receives the ultrasound signals (i.e., ultrasound echo signals) reflected from the target object, and performs signal processing upon the received ultrasound echo signals to thereby acquire ultrasound data. The ultrasound system performs scan conversion or rendering processing upon the acquired ultrasound data to form an ultrasound image.</p><p id="p0004" num="0004">When using the ultrasound system, a user adjusts manually a position and/or an angle of a monitor in a three-dimensional direction (e.g., up/down and/or right/left) according to a position (i.e., posture) of the user. Such an ultrasound system is not user-friendly<!-- EPO <DP n="2"> --> since the user adjusts manually the position and/or the angle of the monitor while acquiring the ultrasound images of the target object. Further, since the ultrasound system provides a fixed ultrasound image regardless of the posture of the user, the user must change his/her posture to see the ultrasound image displayed on the monitor.</p><p id="p0005" num="0005">An ultrasound system according to the preamble of claim 1 is known from <patcit id="pcit0001" dnum="JP2006167043A"><text>JP 2006 167043 A</text></patcit>.</p><heading id="h0003">SUMMARY</heading><p id="p0006" num="0006">The present invention provides some embodiments of an ultrasound system for detecting the posture of a user and providing an optimal ultrasound image for the posture of the user.</p><p id="p0007" num="0007">According to one embodiment of the present invention, an ultrasound system comprises the features stated in claim 1.</p><heading id="h0004">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p0008" num="0008"><ul><li><figref idrefs="f0001"><b>FIG. 1</b></figref> is a block diagram showing an ultrasound system according to a first embodiment.</li><li><figref idrefs="f0002"><b>FIG. 2</b></figref> is a block diagram showing an ultrasound data acquisition unit according to the first embodiment.</li><li><figref idrefs="f0002"><b>FIG. 3</b></figref> is a schematic diagram showing an example of a sensing unit according to the first embodiment.</li><li><figref idrefs="f0003"><b>FIG. 4</b></figref> is a schematic diagram showing another example of a sensing unit according to the first embodiment.</li><li><figref idrefs="f0004"><b>FIG. 5</b></figref> is a flow chart showing a process of forming an optimal ultrasound image for<!-- EPO <DP n="3"> --> posture of a user in accordance with the first embodiment.</li><li><figref idrefs="f0005"><b>FIG 6</b></figref> is a block diagram showing an ultrasound system according to a second embodiment.</li><li><figref idrefs="f0006"><b>FIG. 7</b></figref> is a schematic diagram showing an example of a display unit according to the second embodiment.</li><li><figref idrefs="f0007"><b>FIG. 8</b></figref> is a schematic diagram showing an example of a sensing unit according to the second embodiment.</li><li><figref idrefs="f0008"><b>FIG 9</b></figref> is a schematic diagram showing another example of a sensing unit according to the second embodiment.</li><li><figref idrefs="f0009"><b>FIG 10</b></figref> is a flow chart showing a process of forming an optimal ultrasound image for posture of a user in accordance with the second embodiment.</li></ul><!-- EPO <DP n="4"> --></p><heading id="h0005">DETAILED DESCRIPTION</heading><p id="p0009" num="0009">A first embodiment of the present disclosure will now be described in detail with reference to the drawings.</p><heading id="h0006"><u>First Embodiment</u></heading><p id="p0010" num="0010"><figref idrefs="f0001">FIG. <b>1</b></figref> is a block diagram showing an ultrasound system according to a first embodiment of the present disclosure. Referring to <figref idrefs="f0001"><b>FIG. 1</b></figref>, an ultrasound system 100 includes an ultrasound data acquisition unit 110, a display unit 120, a sensing unit 130, a storage unit 140 and a processing unit 150.</p><p id="p0011" num="0011">The ultrasound data acquisition unit 110 is configured to transmit ultrasound signals to a target object and receive the ultrasound signals (i.e., ultrasound echo signals) reflected from the target object to thereby acquire ultrasound data.</p><p id="p0012" num="0012"><figref idrefs="f0002"><b>FIG. 2</b></figref> is a block diagram showing the ultrasound data acquisition unit according to the first embodiment. Referring to <figref idrefs="f0002"><b>FIG. 2</b></figref>, the ultrasound data acquisition unit 110 includes an ultrasound probe 210, a transmit signal generating section 220, a beam forming section 230 and an ultrasound data forming section 240.</p><p id="p0013" num="0013">The ultrasound probe 210 includes a plurality of transducer elements (not shown) configured to perform reciprocal conversion between electric signals and ultrasound signals. The ultrasound probe 210 is operable to transmit the ultrasound signals to the target object along each of a plurality of scan lines (not shown) and receive the ultrasound echo signals reflected from the target object, thereby forming receive signals. The receive signal is an analog signal. The ultrasound probe 210 may be at least one of a convex probe, a linear probe and the like.<br/>
<!-- EPO <DP n="5"> -->The transmit signal generating section 220 is configured to control transmission of the ultrasound signals. The transmit signal generating section 220 is configured to generate the transmit signals for acquiring an ultrasound image in consideration of the transducer elements and focal points. The ultrasound image includes a brightness mode (B-mode) image, a spectral Doppler image, a color Doppler image, a three-dimensional ultrasound image, an elasticity image and the like. The ultrasound probe 210 is operable to convert the transmit signals provided from the transmit signal generating section 220 into the ultrasound signals and transmit the ultrasound signals to the target object. Further, the ultrasound probe 210 is operable to receive the ultrasound echo signals reflected from the target object to thereby form the receive signals.</p><p id="p0014" num="0014">The beam forming section 230 is configured to form digital signals by performing analog-to-digital conversion on the receive signals outputted from the ultrasound probe 210. The beam forming section 230 is further configured to form receive-focused beams by receive-focusing the digital signals in consideration of the transducer elements and the focal points.</p><p id="p0015" num="0015">The ultrasound data forming section 240 is configured to form the ultrasound data corresponding to the ultrasound image by using the receive-focused beams provided from the beam forming section 230. The ultrasound data includes radio frequency (RF) data or in-phase/quadrature (IQ) data, although the ultrasound data may not be limited thereto. Further, the ultrasound data forming section 240 is also configured to perform a variety of signal processing (e.g., gain adjustment, etc.), which is necessary to form the ultrasound data, upon the receive-focused beams.<!-- EPO <DP n="6"> --></p><p id="p0016" num="0016">Referring back to <figref idrefs="f0001"><b>FIG. 1</b></figref>, the display unit 120 displays the ultrasound image. In the present embodiment, the display unit 120 includes a monitor 121 (shown in <figref idrefs="f0002"><b>FIGS. 3</b></figref> and <figref idrefs="f0003"><b>4</b></figref>), the position and angle of which can be adjusted manually up and down and/or right and left, or a monitor fixed to the ultrasound system 100.</p><p id="p0017" num="0017">The sensing unit 130 may be installed on one side of the monitor 121. The sensing unit 130 is be configured to detect a position of the user, a distance between the user and the monitor 121, a height of the user with respect to the monitor 121 and a viewing angle of the user toward the monitor 121 to thereby form and output the sensing signals corresponding thereto.</p><p id="p0018" num="0018">In one example, as shown in <figref idrefs="f0002"><b>FIG. 3</b></figref>, the sensing unit 130, which is installed on one side (e.g., frame) of the monitor 121, includes first sensors FS<sub>1</sub> to FS<sub>4</sub> configured to detect the position of the user, the distance between the user and the monitor 121, the height of the user with respect to the monitor 121 and the viewing angle of the user toward the monitor 121 to thereby form and output the sensing signals corresponding thereto. Any device may be employed as the first sensors FS<sub>1</sub> to FS<sub>4</sub> as long as the device can detect the position of the user, the distance between the user and the monitor 121, the height of the user with respect to the monitor 121 and the viewing angle of the user toward the monitor 121, and form and output the sensing signals corresponding thereto. For example, the first sensors FS<sub>1</sub> to FS<sub>4</sub> may include at least one of a camera, a webcam and the like. The first sensors FS<sub>1</sub> to FS<sub>4</sub> may be provided inside or outside the monitor 121.</p><p id="p0019" num="0019">While the sensing unit 130 includes four first sensors FS<sub>1</sub> to FS<sub>4</sub> in the above-described example, one of ordinary skill in the art may fully understand that the number as well<!-- EPO <DP n="7"> --> as the position of the first sensors can be varied as necessary, and not be limited to those described in the example.</p><p id="p0020" num="0020">In another example, as shown in <figref idrefs="f0003"><b>FIG. 4</b></figref>, the sensing unit 130, which is installed on one side (i.e., frame) of the monitor 121, includes first sensors (FS<sub>1</sub> to FS<sub>4</sub>) configured to detect the position of the user, the height of the user with respect to the monitor 121 and the viewing angle of the user toward the monitor 121 to thereby form and output first sensing signals corresponding thereto. The sensing unit 130 further includes second sensors SS<sub>1</sub> and SS<sub>2</sub> configured to detect the distance between the user and the monitor 121 to form and output second sensing signals corresponding thereto. Any device may be employed as the second sensors SS<sub>1</sub> and SS<sub>2</sub> as long as the device can detect the distance between the user and the monitor 121, and form and output the sensing signals corresponding thereto. For example, the second sensors SS<sub>1</sub> and SS<sub>2</sub> may include a distance detecting sensor. The second sensors SS<sub>1</sub> and SS<sub>2</sub> may be provided inside or outside the monitor 121.</p><p id="p0021" num="0021">While the sensing unit 130 includes two second sensors SS<sub>1</sub> and SS<sub>2</sub> in the above-described example, one of ordinary skill in the art will fully understand that the number as well as the position of the second sensor can be varied as necessary, and not be limited to those described in this example.</p><p id="p0022" num="0022">The storage unit 140 is configured to store optimal posture information necessary for providing optimal ultrasound image according to the posture of the user. In the present embodiment, the optimal posture information may include information on the optimal distance between the user and the monitor 121, the optimal height of the user with respect to the monitor 121 and the optimal viewing angle of the user toward the<!-- EPO <DP n="8"> --> monitor 121.</p><p id="p0023" num="0023">The processing unit 150 is coupled to the ultrasound data acquisition unit 110, the sensing unit 130 and the storage unit 140. The processing unit 150 includes at least one of a central processing unit (CPU), a microprocessor, a graphic processing unit (GPU) and the like.</p><p id="p0024" num="0024"><figref idrefs="f0004"><b>FIG. 5</b></figref> is a flow chart showing a process of forming the optimal ultrasound image for the posture of the user in accordance with the first embodiment. Referring to <figref idrefs="f0004"><b>FIG. 5</b></figref>, the processing unit 150 is configured to produce the ultrasound image by using the ultrasound data provided from the ultrasound data acquisition unit 110 at S502. The ultrasound image is produced through scan conversion or rendering processing. The produced ultrasound image may be displayed on the monitor 121 of the display unit 120.</p><p id="p0025" num="0025">The processing unit 150 is configured to form posture information, which indicates the posture of the user with respect to the monitor 121, based on the sensing signals provided from the sensing unit 130 at S504. In the present embodiment, the posture information includes the distance between the user and the monitor 121, the height of the user with respect to the monitor 121 and the viewing angle of the user toward the monitor 121. However, the posture information may not be limited thereto.</p><p id="p0026" num="0026">In one example, if the sensing signals are provided from the first sensors FS<sub>1</sub> to FS<sub>4</sub>, then the processing unit 150 is configured to detect the user's face (more preferably, the user's eyes) by using the provided sensing signals. The user's face can be detected through vision recognition (i.e., image recognition) and the like. By using the<!-- EPO <DP n="9"> --> detected user's face as a reference point, the processing unit 150 may calculate the distance between the monitor 121 and the user, the height of the user with respect to the monitor 121 (i.e., height of the user's eyes with respect to the monitor 121) and the viewing angle of the user toward the monitor 121. Calculation of the distance, height and viewing angle can be performed by using a variety of well-known methods so that the detailed description thereof will be omitted in the present embodiment. In this way, the processing unit 150 may form the posture information including the calculated distance, height and viewing angle.</p><p id="p0027" num="0027">In another example, if the first sensing signals are provided from the first sensors FS<sub>1</sub> to FS<sub>4</sub>, then the processing unit 150 is configured to detect the user's face (more preferably, the user's eyes) by using the provided first sensing signals. The processing unit 150 is configured to calculate the height of the user with respect to the monitor 121 (i.e., height of the user's eyes with respect to the monitor 121) and the viewing angle of the user toward the monitor 121 by utilizing the detected user's face as a reference point. Further, if the second sensing signals from the second sensors SS<sub>1</sub> and SS<sub>2</sub>, then the processing unit 150 is configured to calculate the distance between the monitor 121 and the user by using the provided second sensing signals. In this way, the processing unit 150 is configured to form the posture information including the calculated distance, height and viewing angle.</p><p id="p0028" num="0028">The processing unit 150 is configured to extract the optimal posture information from the storage unit 140 at S506 and compare the extracted optimal posture information with the posture information to thereby acquire posture difference information at S508. The posture difference information includes respective differential values of the distance, height and viewing angle.<!-- EPO <DP n="10"> --></p><p id="p0029" num="0029">The processing unit 150 is configured to perform image processing upon the ultrasound image based on the posture difference information and the posture information to obtain the optimal ultrasound image for the position of the user at S510. The ultrasound image with the optimal image processing performed may be displayed on the monitor 121 of the display unit 120.</p><p id="p0030" num="0030">In one example, if the ultrasound image is a two-dimensional or three-dimensional ultrasound image and the posture difference information includes the differential value of the distance, then the processing unit 150 may magnify or downscale the ultrasound image in proportion to the distance differential value included in the posture difference information. In another example, if the ultrasound image is a two-dimensional or three-dimensional ultrasound image and the posture difference information includes the differential value of the viewing angle, then the processing unit 150 is configured to vertically or horizontally magnify/downscale the ultrasound image, or tilt or extend the ultrasound image toward the user, in proportion to the viewing angle differential value included in the posture difference information. In another example, if the ultrasound image is a three-dimensional ultrasound image and the posture difference information includes the differential value of the viewing angle, then the processing unit 150 may rotate the three-dimensional ultrasound image based on the viewing angle differential value included in the posture difference information.</p><heading id="h0007"><u>Second Embodiment</u></heading><p id="p0031" num="0031"><figref idrefs="f0005"><b>FIG. 6</b></figref> is a block diagram showing a configuration of an ultrasound system in accordance with a second embodiment. Referring to <figref idrefs="f0005"><b>FIG. 6</b></figref>, an ultrasound system 600 includes an ultrasound data acquisition unit 610, a display unit 620, a sensing unit 630, a storage unit 640 and a processing unit 650.<!-- EPO <DP n="11"> --></p><p id="p0032" num="0032">The ultrasound data acquisition unit 610 is configured to transmit ultrasound signals to a target object and receive the ultrasound echo signals reflected from the target object to thereby acquire ultrasound data corresponding to an ultrasound image. The ultrasound data acquisition unit 610 in the present embodiment may be identically configured with the ultrasound data acquisition unit 110 in the first embodiment and thus will not be described in detail in this embodiment.</p><p id="p0033" num="0033">The display unit 620 displays the ultrasound image. In the present embodiment, the display unit 620 includes a monitor 710 configured to display the ultrasound image, a driving section 720 configured to move the monitor 710 in a three-dimensional direction (e.g., back/forth or right/left) and a supporting section 730 configured to support the driving section 720, as shown in <figref idrefs="f0006"><b>FIG. 7</b></figref>. The driving section 720 may be embodied with the well-known devices so that the detailed description thereof will be omitted in the present embodiment.</p><p id="p0034" num="0034">The sensing unit 630 is installed on one side of the monitor 710. The sensing unit 630 is configured to detect a position of the user, a distance between the user and the monitor 710, a height of the user with respect to the monitor 710, a viewing angle of the user toward the monitor 710 and a three-dimensional position of the monitor 710 to thereby form and output sensing signals corresponding thereto.</p><p id="p0035" num="0035">In one example, as shown in <figref idrefs="f0007"><b>FIG. 8</b></figref>, the sensing unit 630, which is installed on one side (e.g., frame) of the monitor 710, includes first sensors FS<sub>1</sub> to FS<sub>4</sub> configured to detect the position of the user, the distance between the user and the monitor 710, the height of the user with respect to the monitor 710 and the viewing angle of the user toward the<!-- EPO <DP n="12"> --> monitor 710 to thereby form and output first sensing signals corresponding thereto. The sensing unit 130 further includes second sensors TS<sub>1</sub> to TS<sub>4</sub> configured to detect a current posture (i.e., position) of the monitor 710 against the predetermined reference position of the monitor to thereby form and output second sensing signals corresponding thereto.</p><p id="p0036" num="0036">In the embodiment, any device may be employed as the first sensors FS<sub>1</sub> to FS<sub>4</sub> as long as the device can detect the position of the user, the distance between the user and the monitor 710, the height of the user with respect to the monitor and the viewing angle of the user toward the monitor 710, and form and output the sensing signals corresponding thereto. For example, the first sensors FS<sub>1</sub> to FS<sub>4</sub> include at least one of a camera, a webcam and the like. The first sensors FS<sub>1</sub> to FS<sub>4</sub> may be provided inside or outside the monitor 710. Further, any device may be employed as the second sensors TS<sub>1</sub> to TS<sub>4</sub> as long as the device can detect the current attitude (i.e., position) of the monitor 710 against the predetermined reference position of the monitor, and form and output the sensing signals corresponding thereto. For example, the second sensors TS<sub>1</sub> to TS<sub>4</sub> include at least one of a gyro sensor, a tilt sensor and the like. The second sensors TS<sub>1</sub> to TS<sub>4</sub> may be provided inside or outside the monitor 710.</p><p id="p0037" num="0037">While the sensing unit 630 includes four first sensors FS<sub>1</sub> to FS<sub>4</sub> and four second sensors TS<sub>1</sub> to TS<sub>4</sub> in the above-described example, one of ordinary skill in the art will fully understand that the numbers as well as the positions of the first and second sensors can be varied as necessary, and not be limited to those described in this example.</p><p id="p0038" num="0038">In another example, as shown in <figref idrefs="f0008"><b>FIG. 9</b></figref>, the sensing unit 630, which is installed on one<!-- EPO <DP n="13"> --> side (e.g., frame) of the monitor 710, includes first sensors FS<sub>1</sub> to FS<sub>4</sub> configured to detect the position of the user, the height of the user with respect to the monitor 710 and the viewing angle of the user toward the monitor 710 to thereby form and output first sensing signals corresponding thereto. The sensing unit 630 further includes second sensors TS<sub>1</sub> to TS<sub>4</sub> configured to detect the current attitude (i.e., position) of the monitor 710 against the predetermined reference position of the monitor to thereby form and output second signals corresponding thereto. The sensing unit 630 further includes third sensors SS<sub>1</sub> to SS<sub>4</sub> configured to detect the distance between the user and the monitor 710 to thereby form and output third sensing signals corresponding thereto. Any device may be employed as the third sensors SS<sub>1</sub> to SS<sub>4</sub> as long as the device can detect the distance between the user and the monitor 710, and form and output the sensing signals corresponding thereto. For example, the third sensors SS<sub>1</sub> to SS<sub>4</sub> include a distance detecting sensor. The third sensors SS<sub>1</sub> to SS<sub>4</sub> may be provided inside or outside the monitor 710.</p><p id="p0039" num="0039">While the sensing unit 630 includes four first sensors FS<sub>1</sub> to FS<sub>4</sub>, four second sensors TS<sub>1</sub> to TS<sub>4</sub> and four third sensors SS<sub>1</sub> to SS<sub>4</sub> in the above-described example, one of ordinary skill in the art will fully understand that the numbers as well as the positions of the first to third sensors can be varied as necessary, and not be limited to those described in this example.</p><p id="p0040" num="0040">The storage unit 640 is configured to store optimal posture information for providing optimal ultrasound image for the posture of the user. In the present embodiment, the optimal posture information includes information on the optimal distance between the user and the monitor 710, the optimal height of the user with respect to the monitor 710 and the optimal viewing angle of the user toward the monitor 710.<!-- EPO <DP n="14"> --></p><p id="p0041" num="0041">The processing unit 650 is coupled to the ultrasound data acquisition unit 610, the display unit 620, the sensing unit 630 and the storage unit 640. The processing unit 650 includes at least one of a central processing unit (CPU), a microprocessor unit, a graphic processing unit (GPU) and the like.</p><p id="p0042" num="0042"><figref idrefs="f0009"><b>FIG. 10</b></figref> is a flow chart showing a process of forming the optimal ultrasound image for the user's posture in accordance with the second embodiment. Referring to <figref idrefs="f0009"><b>FIG. 10</b></figref>, the processing unit 650 is configured to produce the ultrasound image by using the ultrasound data provided from the ultrasound data acquisition unit 610 at S1002. The ultrasound image is displayed on the monitor 710 of the display unit 620. The ultrasound image is produced through scan conversion or rendering processing.</p><p id="p0043" num="0043">The processing unit 650 is configured to form posture information based on the sensing signals provided from the sensing unit 630 at S1004. In the present embodiment, the posture information includes first posture information indicating the posture of the user with respect to the monitor 710 and second posture information indicating the position (i.e., attitude) of the monitor 710. The first posture information includes the distance between the user and the monitor 710, the height of the user with respect to the monitor 710 and the viewing angle of the user toward the monitor 710. However, the posture information may not be limited thereto.</p><p id="p0044" num="0044">In one example, if the first sensing signals are provided from the first sensors FS<sub>1</sub> to FS<sub>4</sub>, then the processing unit 650 is configured to detect the user's face (more preferably, the user's eyes) by using the provided first sensing signals. The user's face is detected through vision recognition (i.e., image recognition) and the like. By using the detected user's face as a reference point, the processing unit 650 is configured to<!-- EPO <DP n="15"> --> calculate the distance between the monitor 710 and the user, the height of the user with respect to the monitor 710 (i.e., height of the user's eyes with respect to the monitor 710) and the viewing angle of the user toward the monitor 710. The distance, height and viewing angle can be calculated by using a variety of well-known methods so that the detailed description thereof will be omitted in the present embodiment. In this way, the processing unit 650 is configured to form the first posture information including the calculated distance, height and viewing angle. Further, the processing unit 650, provided with the second sensing signals from the second sensors TS<sub>1</sub> to TS<sub>4</sub>, is configured to form the second posture information indicating the current attitude (e.g., tilt, rotation, etc.) of the monitor 710 by using the second sensing signals.</p><p id="p0045" num="0045">In another example, provided with the first sensing signals from the first sensors FS<sub>1</sub> to FS<sub>4</sub>, the processing unit 650 is configured to detect the user's face (more preferably, the user's eyes) by using the first sensing signals. The processing unit 650 is configured to calculate the height of the user with respect to the monitor 710 (i.e., height of the user's eyes with respect to the monitor 710) and the viewing angle of the user toward the monitor 710 by utilizing the detected user's face as a reference point. Further, the processing unit 650, provided with the third sensing signals from the third sensors SS<sub>1</sub> to SS<sub>4</sub>, may be configured to calculate the distance between the monitor 710 by using the third sensing signals. In this way, the processing unit 650 may be configured to form the first posture information including the calculated distance, height and viewing angle. Furthermore, the processing unit 650, provided with the second sensing signals from the second sensors TS<sub>1</sub> to TS<sub>4</sub>, may form the second posture information indicating the current attitude (e.g., tilt, rotation, etc.) of the monitor 710 by using the second sensing signals.<!-- EPO <DP n="16"> --></p><p id="p0046" num="0046">The processing unit 650 is configured to extract the optimal posture information from the storage unit 640 at S1006 and compare the extracted optimal posture information with the posture information to thereby acquire posture difference information at S1008. The posture difference information may include respective differential values of the distance, height and viewing angle. However, the posture information may not be limited thereto.</p><p id="p0047" num="0047">The processing unit 650 is configured to compute a moving range of the monitor 710 based on the posture difference information at S1010. In this embodiment, the moving range is the range within which the monitor 710 may be moved to face the user's full face. The moving range is computed by using various well-known methods. Thus, it will not be described in detail in the present embodiment.</p><p id="p0048" num="0048">Based on the posture information (i.e., the second posture information), the processing unit 650 is configured to compute a movable range, which is the maximum range within which the monitor 710 can be moved in a three-dimensional direction (e.g., back/forth, right/left or the like) to face the user's full face at S1012.</p><p id="p0049" num="0049">The processing unit 650 is configured to compare the computed moving range with the computed movable range at S1014. If it is determined that the moving range exceeds the movable range, then the processing unit 650 may move the monitor 710 as widely as the movable range by driving the driving section 720 at S1016. The processing unit 650 is configured to perform image processing upon the ultrasound image to obtain the optimal image for the posture of the user at S1018. For example, the processing unit 650 is configured to calculate the differential value between the moving range and the movable range and perform a process, which is similar to the step S510 in the first<!-- EPO <DP n="17"> --> embodiment, in proportion to the calculated differential value.</p><p id="p0050" num="0050">Further, if it is determined that the moving range falls within the movable range, then the processing unit 650 may move the monitor 710 as widely as the moving range by driving the driving section 720 at S1020.</p><p id="p0051" num="0051">While the invention has been shown and described with reference to exemplary embodiments thereof, it will be understood by those skilled in the art that various changes in form and details may be made therein without departing from the scope of the invention as defined by the appended claims.</p></description><claims mxw-id="PCLM56978660" lang="DE" load-source="patent-office"><!-- EPO <DP n="21"> --><claim id="c-de-01-0001" num="0001"><claim-text>Ultraschallsystem (100, 600), welches folgendes aufweist:
<claim-text>Eine Ultraschalldaten-Beschaffungseinheit (110, 610), die dafür vorgesehen ist, Ultraschallsignale zu einem Zielobjekt zu übertragen und von dem Zielobjekt reflektierte Ultraschallechosignale zu empfangen, um dadurch Ultraschalldaten zu erlangen;</claim-text>
<claim-text>eine Anzeigeeinheit (120, 620), die einen Monitor (121, 710) aufweist und dafür vorgesehen ist, ein Ultraschallbild anzuzeigen;</claim-text>
<claim-text>eine Abtasteinheit (130, 630), die dafür vorgesehen ist, eine Position eines Benutzers und einen Abstand zwischen dem Benutzer und dem Monitor (121, 710) zu detektieren, um auf die Weise dazu entsprechende Abtastsignale zu bilden und auszugeben;</claim-text>
<claim-text>eine Speichereinheit (140, 640), die dafür vorgesehen ist, optimale Haltungsinformationen zu speichern, die notwendig sind, um ein optimales Ultraschallbild gemäß einer Haltung des Benutzers zur Verfügung zu stellen; und</claim-text>
<claim-text>eine Verarbeitungseinheit (150, 650), die mit der Ultraschalldaten-Beschaffungseinheit (110, 610), der Abtasteinheit (130, 630) und der Speichereinheit (140, 640) verbunden ist, wobei die Verarbeitungseinheit (150, 650) dafür vorgesehen ist, das Ultraschallbild durch Verwenden der Ultraschalldaten und Durchführen einer optimalen Bildverarbeitung für die Haltung des Benutzers an dem Ultraschallbild basierend auf den Abtastsignalen und der optimalen Haltungsinformation zu erzeugen,</claim-text>
<claim-text><b>dadurch gekennzeichnet, dass</b></claim-text>
<claim-text>die Abtasteinheit (130, 630) auf einer Seite des Monitors (121, 710) installiert ist und dafür vorgesehen ist, eine Höhe des Benutzers in Bezug auf den Monitor (121, 710) und einen Blickwinkel des Benutzers in Richtung des Monitors (121,<!-- EPO <DP n="22"> --> 710) zu detektieren, um auf diese Weise entsprechende Ausgabeabtastsignale zu bilden und auszugeben, wobei die optimale Bildverarbeitung auf den der Höhe und dem Blickwinkel entsprechenden Abtastsignale basiert.</claim-text></claim-text></claim><claim id="c-de-01-0002" num="0002"><claim-text>Ultraschallsystem (100, 600) nach Anspruch 1, wobei die Abtasteinheit (130, 630) folgendes aufweist:
<claim-text>Erste Sensoren (FS<sub>1</sub>, FS<sub>2</sub>, FS<sub>3</sub>, FS<sub>4</sub>), die dafür vorgesehen sind, die Position des Benutzers, die Höhe des Benutzers in Bezug auf den Monitor (121, 710) und den Blickwinkel des Benutzers in Richtung des Monitors (121, 710) zu ermitteln, um auf diese Weise dazu entsprechende erste Abtastsignale zu bilden und auszugeben; und</claim-text>
<claim-text>zweite Sensoren (SS<sub>1</sub>, SS<sub>2</sub>), die dafür vorgesehen sind, den Abstand zwischen dem Benutzer und dem Monitor (121, 710) zu ermitteln, um auf diese Weise dazu entsprechende zweite Abtastsignale zu bilden und auszugeben.</claim-text></claim-text></claim><claim id="c-de-01-0003" num="0003"><claim-text>Ultraschallsystem (100, 600) nach Anspruch 1, wobei die Verarbeitungseinheit (150, 650) für folgendes vorgesehen ist:
<claim-text>Auf die Position des Benutzers in Bezug zu dem Monitor (121, 710) hinweisende Haltungsinformationen basierend auf den Abtastsignalen zu bilden,</claim-text>
<claim-text>die optimalen Haltungsinformationen mit den Haltungsinformationen zu vergleichen, um Haltungsunterschiedsinformationen zu bilden, und</claim-text>
<claim-text>die optimale Bildverarbeitung an dem Ultraschallbild basierend auf den Haltungsunterschiedsinformationen und den Haltungsinformationen durchzuführen.</claim-text></claim-text></claim><claim id="c-de-01-0004" num="0004"><claim-text>Ultraschallsystem (100, 600) nach Anspruch 3, wobei die Haltungsinformationen den Abstand zwischen dem Monitor (121, 710) und dem Benutzer, die Höhe des Benutzers in Bezug auf den Monitor (121, 710) und den Blickwinkel des Benutzers in Richtung des Monitors (121, 710) beinhalten.</claim-text></claim><claim id="c-de-01-0005" num="0005"><claim-text>Ultraschallsystem (100, 600) nach Anspruch 3, wobei die Verarbeitungseinheit (150, 650) für folgendes vorgesehen ist:<!-- EPO <DP n="23"> -->
<claim-text>Das Gesicht des Benutzers basierend auf den Abtastsignalen zu ermitteln, und den Abstand zwischen dem Monitor (121, 710) und dem Benutzer, die Höhe des Benutzers in Bezug auf den Monitor (121, 710) und den Blickwinkel des Benutzers in Richtung des Monitors (121, 710) durch Verwenden des ermittelten Gesichts des Benutzers als ein Referenzpunkt zu berechnen.</claim-text></claim-text></claim><claim id="c-de-01-0006" num="0006"><claim-text>Ultraschallsystem (100, 600) nach Anspruch 1, wobei die Anzeigeeinheit (120, 620) des Weiteren eine Antriebspartie (720) aufweist, die dafür vorgesehen ist, den Monitor (121, 710) in einer dreidimensionalen Richtung zu bewegen, und wobei die Abtasteinheit (130, 630) des Weiteren dafür vorgesehen ist, eine Position des Monitors (121, 710) gegen eine vorbestimmte Referenzposition des Monitors (121, 710) zu ermitteln.</claim-text></claim><claim id="c-de-01-0007" num="0007"><claim-text>Ultraschallsystem (100, 600) nach Anspruch 6, wobei die Verarbeitungseinheit (150, 650) des Weiteren dafür vorgesehen ist, die Antriebspartie anzutreiben, um den Monitor (121, 710) zu bewegen.</claim-text></claim></claims><claims mxw-id="PCLM56978661" lang="EN" load-source="patent-office"><!-- EPO <DP n="18"> --><claim id="c-en-01-0001" num="0001"><claim-text>An ultrasound system (100, 600), comprising:
<claim-text>an ultrasound data acquisition unit (110, 610) configured to transmit ultrasound signals to a target object and receive ultrasound echo signals reflected from the target object to thereby acquire ultrasound data;</claim-text>
<claim-text>a display unit (120, 620) including a monitor (121, 710) and being configured to display an ultrasound image;</claim-text>
<claim-text>a sensing unit (130, 630) being configured to detect a position of a user and a distance between the user and the monitor (121, 710) to thereby form and output sensing signals corresponding thereto;</claim-text>
<claim-text>a storage unit (140, 640) configured to store optimal posture information necessary for providing an optimal ultrasound image according to a posture of the user; and</claim-text>
<claim-text>a processing unit (150, 650) coupled to the ultrasound data acquisition unit (110, 610), the sensing unit (130, 630) and the storage unit (140, 640), the processing unit (150, 650) being configured to form the ultrasound image by using the ultrasound data and perform an optimal image processing for the posture of the user upon the ultrasound image based on the sensing signals and the optimal posture information,</claim-text>
<claim-text><b>characterized in that</b></claim-text>
<claim-text>the sensing unit (130, 630) is installed on one side of the monitor (121, 710) and is configured to detect a height of the user with respect to the monitor (121, 710) and a viewing angle of the user toward the monitor (121, 710) to thereby form and output sensing signals corresponding thereto, wherein the optimal image processing is based on the sensing signals corresponding to the height and the viewing angle.</claim-text><!-- EPO <DP n="19"> --></claim-text></claim><claim id="c-en-01-0002" num="0002"><claim-text>The ultrasound system (100, 600) of Claim 1, wherein the sensing unit (130, 630) includes:
<claim-text>first sensors (FS<sub>1,</sub> FS<sub>2</sub>, FS<sub>3</sub>, FS<sub>4</sub>) configured to detect the position of the user, the height of the user with respect to the monitor (121, 710) and the viewing angle of the user toward the monitor (121, 710) to thereby form and output first sensing signals corresponding thereto; and</claim-text>
<claim-text>second sensors (SS<sub>1</sub>, SS<sub>2</sub>) configured to detect the distance between the user and the monitor (121, 710) to thereby form and output second sensing signals corresponding thereto.</claim-text></claim-text></claim><claim id="c-en-01-0003" num="0003"><claim-text>The ultrasound system (100, 600) of Claim 1, wherein the processing unit (150, 650) is configured to:
<claim-text>form posture information indicative of the position of the user with respect to the monitor (121, 710) based on the sensing signals,</claim-text>
<claim-text>compare the optimal posture information with the posture information to form posture difference information, and</claim-text>
<claim-text>perform the optimal image processing upon the ultrasound image based on the posture difference information and the posture information.</claim-text></claim-text></claim><claim id="c-en-01-0004" num="0004"><claim-text>The ultrasound system (100, 600) of Claim 3, wherein the posture information includes the distance between the monitor (121, 710) and the user, the height of the user with respect to the monitor (121, 710) and the viewing angle of the user toward the monitor (121, 710).</claim-text></claim><claim id="c-en-01-0005" num="0005"><claim-text>The ultrasound system (100, 600) of Claim 3, wherein the processing unit (150, 650) is configured to:<!-- EPO <DP n="20"> -->
<claim-text>detect the user's face based on the sensing signals, and</claim-text>
<claim-text>calculate the distance between the monitor (121, 710) and the user, the height of the user with respect to the monitor (121, 710) and the viewing angle of the user toward the monitor (121, 710) by using the detected user's face as a reference point.</claim-text></claim-text></claim><claim id="c-en-01-0006" num="0006"><claim-text>The ultrasound system (100, 600) of Claim 1, wherein the display unit (120, 620) further includes a driving section (720) configured to move the monitor (121, 710) in a three-dimensional direction and the sensing unit (130, 630) is further configured to detect a position of the monitor (121, 710) against a predetermined reference position of the monitor (121, 710).</claim-text></claim><claim id="c-en-01-0007" num="0007"><claim-text>The ultrasound system (100, 600) of Claim 6, wherein the processing unit (150, 650) is further configured to drive the driving section to move the monitor (121, 710).</claim-text></claim></claims><claims mxw-id="PCLM56978662" lang="FR" load-source="patent-office"><!-- EPO <DP n="24"> --><claim id="c-fr-01-0001" num="0001"><claim-text>Système ultrasonique (100, 600) comportant :
<claim-text>une unité ultrasonique d'acquisition de données (110, 610) agencée pour transmettre des signaux ultrasoniques vers un objet cible et pour recevoir des signaux d'échos ultrasoniques réfléchis par l'objet cible pour acquérir des données par ce moyen ;</claim-text>
<claim-text>une unité d'affichage (120, 620) comportant un moniteur (121, 710) configuré pour afficher une image ultrasonique ;</claim-text>
<claim-text>une unité de détection (130, 630) configurée pour détecter une position d'un utilisateur et une distance entre l'utilisateur et le moniteur (121, 710) pour créer de ce fait un signal et émettre des signaux de détection correspondants ;</claim-text>
<claim-text>une unité de mémorisation (140, 640) configurée pour mémoriser une information de position optimale nécessaire pour fournir une image ultrasonique optimale correspondant à une position de l'utilisateur ; et</claim-text>
<claim-text>une unité de traitement (150, 650) couplée à l'unité ultrasonique d'acquisition de données (110, 610), l'unité de détection (130, 630) et l'unité de mémorisation (140, 640), l'unité de traitement (150, 650) étant configurée pour former l'image ultrasonique en utilisant les données ultrasoniques et en réalisant un traitement de l'image optimale pour la position de l'utilisateur avec l'image ultrasonique basée sur les signaux de détection et l'information de position optimale,</claim-text>
<claim-text><b>caractérisé en ce que</b></claim-text>
<claim-text>l'unité de détection (130, 630) est installée sur un côté du moniteur (121, 710) et est configurée pour détecter une hauteur de l'utilisateur par rapport au moniteur (121, 710) et un angle de vision de l'utilisateur vers le moniteur (121, 710) pour former ainsi des signaux sortants de détection<!-- EPO <DP n="25"> --> correspondants, dans lequel le traitement de l'image optimale est basé sur les signaux détectés correspondant à la hauteur et à l'angle de vision.</claim-text></claim-text></claim><claim id="c-fr-01-0002" num="0002"><claim-text>Système ultrasonique (100, 600) selon la revendication 1, dans lequel l'unité de détection (130, 630) comporte :
<claim-text>des premiers détecteurs (FS<sub>1</sub>, FS<sub>2</sub>, FS<sub>3</sub>, FS<sub>4</sub>) configurés pour détecter la position de l'utilisateur, la hauteur de l'utilisateur par rapport au moniteur (121, 710) pour former ainsi et émettre des premiers signaux de détection correspondants ; et</claim-text>
<claim-text>des seconds détecteurs (SS<sub>1</sub>, SS<sub>2</sub>) configurés pour détecter la distance entre l'utilisateur et le moniteur (121, 710) pour former ainsi et émettre des seconds signaux de détection correspondants.</claim-text></claim-text></claim><claim id="c-fr-01-0003" num="0003"><claim-text>Système ultrasonique (100, 600) selon la revendication 1, dans lequel l'unité de traitement (150, 650) est configurée pour :
<claim-text>créer une information de position indicative d'une localisation d'un utilisateur par rapport au moniteur (121, 710), basée sur les signaux de détection,</claim-text>
<claim-text>comparer l'information de position optimale avec l'information de position pour créer une information correspondant à une différence de position, et</claim-text>
<claim-text>réaliser le traitement d'image optimal sur l'image ultrasonique basée sur l'information de différence de position et l'information de position.</claim-text></claim-text></claim><claim id="c-fr-01-0004" num="0004"><claim-text>Système ultrasonique (100, 600) selon la revendication 3, dans lequel l'information de position inclut la distance entre le moniteur (121, 710) et l'utilisateur, la hauteur de l'utilisateur par rapport au moniteur (121, 710) et l'angle de vision de l'utilisateur vers le moniteur (121, 710).</claim-text></claim><claim id="c-fr-01-0005" num="0005"><claim-text>Système ultrasonique (100, 600) selon la revendication 3, dans lequel l'unité de traitement (150, 650) est configurée pour :<!-- EPO <DP n="26"> -->
<claim-text>détecter la face de l'utilisateur sur la base des signaux de détection, et</claim-text>
<claim-text>calculer la distance entre le moniteur (121, 710) et l'utilisateur, la hauteur de l'utilisateur par rapport au moniteur (121, 710) et l'angle de vision de l'utilisateur vers le moniteur (121, 710) en utilisant la face détectée de l'utilisateur comme point de référence.</claim-text></claim-text></claim><claim id="c-fr-01-0006" num="0006"><claim-text>Système ultrasonique (100, 600) selon la revendication 1, dans lequel l'unité d'affichage (120, 620) comporte en outre une section de pilotage (720) pour déplacer le moniteur (121, 710) dans une direction tridimensionnelle et l'unité de détection (130, 630) est en outre configurée pour détecter une position du moniteur (121, 710) vers une position de référence prédéterminée du moniteur (121, 710).</claim-text></claim><claim id="c-fr-01-0007" num="0007"><claim-text>Système ultrasonique (100, 600) selon la revendication 6, dans lequel l'unité de traitement (150, 650) est en outre configurée pour piloter l'unité de commande pour déplacer le moniteur (121, 710).</claim-text></claim></claims><drawings mxw-id="PDW16668643" load-source="patent-office"><!-- EPO <DP n="27"> --><figure id="f0001" num="1"><img id="if0001" file="imgf0001.tif" wi="134" he="141" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="28"> --><figure id="f0002" num="2,3"><img id="if0002" file="imgf0002.tif" wi="154" he="229" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="29"> --><figure id="f0003" num="4"><img id="if0003" file="imgf0003.tif" wi="154" he="128" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="30"> --><figure id="f0004" num="5"><img id="if0004" file="imgf0004.tif" wi="101" he="122" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="31"> --><figure id="f0005" num="6"><img id="if0005" file="imgf0005.tif" wi="136" he="137" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="32"> --><figure id="f0006" num="7"><img id="if0006" file="imgf0006.tif" wi="98" he="151" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="33"> --><figure id="f0007" num="8"><img id="if0007" file="imgf0007.tif" wi="160" he="130" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="34"> --><figure id="f0008" num="9"><img id="if0008" file="imgf0008.tif" wi="160" he="130" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="35"> --><figure id="f0009" num="10"><img id="if0009" file="imgf0009.tif" wi="165" he="185" img-content="drawing" img-format="tif"/></figure></drawings><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
