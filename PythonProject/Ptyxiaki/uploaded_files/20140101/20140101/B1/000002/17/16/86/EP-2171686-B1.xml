<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2171686-B1" country="EP" doc-number="2171686" kind="B1" date="20140101" family-id="40042741" file-reference-id="318260" date-produced="20180822" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="146553989" ucid="EP-2171686-B1"><document-id><country>EP</country><doc-number>2171686</doc-number><kind>B1</kind><date>20140101</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-08789288-A" is-representative="NO"><document-id mxw-id="PAPP154827912" load-source="docdb" format="epo"><country>EP</country><doc-number>08789288</doc-number><kind>A</kind><date>20080711</date><lang>EN</lang></document-id><document-id mxw-id="PAPP222721338" load-source="docdb" format="original"><country>EP</country><doc-number>08789288.1</doc-number><date>20080711</date></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC140447302" ucid="IB-2008052812-W" linkage-type="W" load-source="docdb"><document-id format="epo"><country>IB</country><doc-number>2008052812</doc-number><kind>W</kind><date>20080711</date></document-id></priority-claim><priority-claim mxw-id="PPC140453709" ucid="US-95225707-P" load-source="docdb"><document-id format="epo"><country>US</country><doc-number>95225707</doc-number><kind>P</kind><date>20070727</date></document-id></priority-claim></priority-claims><dates-of-public-availability><intention-to-grant-date><date>20130722</date></intention-to-grant-date></dates-of-public-availability><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL1988126040" load-source="docdb">G06T   7/00        20060101AFI20090224BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-1646579264" load-source="docdb" scheme="CPC">G06F  19/00        20130101 LI20180427BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1840005477" load-source="docdb" scheme="CPC">G06Q  50/22        20130101 FI20170307BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1840005478" load-source="docdb" scheme="CPC">G06T  19/00        20130101 LI20170307BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1861417645" load-source="docdb" scheme="CPC">G06T   7/33        20170101 LI20170102BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1861423049" load-source="docdb" scheme="CPC">G06T   7/149       20170101 LI20170102BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1861427702" load-source="docdb" scheme="CPC">G06T   7/12        20170101 LI20170102BHEP        </classification-cpc><classification-cpc mxw-id="PCL1988100503" load-source="docdb" scheme="CPC">G06T2200/24        20130101 LA20131218BHEP        </classification-cpc><classification-cpc mxw-id="PCL1988116179" load-source="docdb" scheme="CPC">G06T2210/41        20130101 LA20131218BHEP        </classification-cpc><classification-cpc mxw-id="PCL1988119924" load-source="docdb" scheme="CPC">G06T2207/30004     20130101 LA20131220BHEP        </classification-cpc><classification-cpc mxw-id="PCL1988127865" load-source="docdb" scheme="CPC">G06T2207/20101     20130101 LA20131220BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT132194451" lang="DE" load-source="patent-office">INTERAKTIVE ATLAS-BILDREGISTRIERUNG</invention-title><invention-title mxw-id="PT132194452" lang="EN" load-source="patent-office">INTERACTIVE ATLAS TO IMAGE REGISTRATION</invention-title><invention-title mxw-id="PT132194453" lang="FR" load-source="patent-office">RECALAGE INTERACTIF ENTRE ATLAS ET IMAGE</invention-title></technical-data><parties><applicants><applicant mxw-id="PPAR918155235" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>KONINKL PHILIPS NV</last-name><address><country>NL</country></address></addressbook></applicant><applicant mxw-id="PPAR918134168" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>KONINKLIJKE PHILIPS N.V.</last-name></addressbook></applicant><applicant mxw-id="PPAR918165225" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>PHILIPS INTELLECTUAL PROPERTY</last-name><address><country>DE</country></address></addressbook></applicant><applicant mxw-id="PPAR918146417" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>PHILIPS INTELLECTUAL PROPERTY &amp; STANDARDS GMBH</last-name></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR918153236" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>PEKAR VLADIMIR</last-name><address><country>US</country></address></addressbook></inventor><inventor mxw-id="PPAR918173489" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>PEKAR, VLADIMIR</last-name></addressbook></inventor><inventor mxw-id="PPAR918998604" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>PEKAR, VLADIMIR</last-name><address><street>c/o 595 Miner Road</street><city>Cleveland, Ohio 44143</city><country>US</country></address></addressbook></inventor><inventor mxw-id="PPAR918154044" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>VIK TORBJOERN</last-name><address><country>US</country></address></addressbook></inventor><inventor mxw-id="PPAR918147219" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>VIK, TORBJOERN</last-name></addressbook></inventor><inventor mxw-id="PPAR918998606" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>VIK, TORBJOERN</last-name><address><street>c/o 595 Miner Road</street><city>Cleveland, Ohio 44143</city><country>US</country></address></addressbook></inventor><inventor mxw-id="PPAR918152904" load-source="docdb" sequence="3" format="epo"><addressbook><last-name>SCHULZ HEINRICH</last-name><address><country>US</country></address></addressbook></inventor><inventor mxw-id="PPAR918141856" load-source="docdb" sequence="3" format="intermediate"><addressbook><last-name>SCHULZ, HEINRICH</last-name></addressbook></inventor><inventor mxw-id="PPAR918998605" load-source="patent-office" sequence="3" format="original"><addressbook><last-name>SCHULZ, HEINRICH</last-name><address><street>c/o 595 Miner Road</street><city>Cleveland, Ohio 44143</city><country>US</country></address></addressbook></inventor><inventor mxw-id="PPAR918150665" load-source="docdb" sequence="4" format="epo"><addressbook><last-name>JAFFRAY DAVID</last-name><address><country>US</country></address></addressbook></inventor><inventor mxw-id="PPAR918161631" load-source="docdb" sequence="4" format="intermediate"><addressbook><last-name>JAFFRAY, DAVID</last-name></addressbook></inventor><inventor mxw-id="PPAR918998603" load-source="patent-office" sequence="4" format="original"><addressbook><last-name>JAFFRAY, DAVID</last-name><address><street>c/o 595 Miner Road</street><city>Cleveland, Ohio 44143</city><country>US</country></address></addressbook></inventor></inventors><assignees><assignee mxw-id="PPAR918998609" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Koninklijke Philips N.V.</last-name><iid>101391185</iid><address><street>High Tech Campus 5</street><city>5656 AE Eindhoven</city><country>NL</country></address></addressbook></assignee><assignee mxw-id="PPAR918998607" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>Philips Intellectual Property &amp; Standards GmbH</last-name><iid>100798256</iid><address><street>Lübeckertordamm 5</street><city>20099 Hamburg</city><country>DE</country></address></addressbook></assignee></assignees><agents><agent mxw-id="PPAR918998608" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Van Velzen, Maaike Mathilde</last-name><iid>100766108</iid><address><street>Philips Intellectual Property &amp; Standards P.O. Box 220</street><city>5600 AE Eindhoven</city><country>NL</country></address></addressbook></agent></agents></parties><international-convention-data><pct-or-regional-filing-data ucid="IB-2008052812-W"><document-id><country>IB</country><doc-number>2008052812</doc-number><kind>W</kind><date>20080711</date><lang>EN</lang></document-id></pct-or-regional-filing-data><pct-or-regional-publishing-data ucid="WO-2009016530-A2"><document-id><country>WO</country><doc-number>2009016530</doc-number><kind>A2</kind><date>20090205</date><lang>EN</lang></document-id></pct-or-regional-publishing-data><designated-states><ep-contracting-states><country mxw-id="DS548982212" load-source="docdb">AT</country><country mxw-id="DS548871250" load-source="docdb">BE</country><country mxw-id="DS548982866" load-source="docdb">BG</country><country mxw-id="DS548831142" load-source="docdb">CH</country><country mxw-id="DS548871251" load-source="docdb">CY</country><country mxw-id="DS548982213" load-source="docdb">CZ</country><country mxw-id="DS548985325" load-source="docdb">DE</country><country mxw-id="DS548871252" load-source="docdb">DK</country><country mxw-id="DS548871253" load-source="docdb">EE</country><country mxw-id="DS548989728" load-source="docdb">ES</country><country mxw-id="DS548982867" load-source="docdb">FI</country><country mxw-id="DS548831143" load-source="docdb">FR</country><country mxw-id="DS548985330" load-source="docdb">GB</country><country mxw-id="DS548871254" load-source="docdb">GR</country><country mxw-id="DS548985331" load-source="docdb">HR</country><country mxw-id="DS548982214" load-source="docdb">HU</country><country mxw-id="DS548831144" load-source="docdb">IE</country><country mxw-id="DS548871255" load-source="docdb">IS</country><country mxw-id="DS548982868" load-source="docdb">IT</country><country mxw-id="DS548871256" load-source="docdb">LI</country><country mxw-id="DS548982869" load-source="docdb">LT</country><country mxw-id="DS548886392" load-source="docdb">LU</country><country mxw-id="DS548982870" load-source="docdb">LV</country><country mxw-id="DS548982871" load-source="docdb">MC</country><country mxw-id="DS548886393" load-source="docdb">MT</country><country mxw-id="DS548886394" load-source="docdb">NL</country><country mxw-id="DS548831145" load-source="docdb">NO</country><country mxw-id="DS548886395" load-source="docdb">PL</country><country mxw-id="DS548989729" load-source="docdb">PT</country><country mxw-id="DS548991621" load-source="docdb">RO</country><country mxw-id="DS548886396" load-source="docdb">SE</country><country mxw-id="DS548985332" load-source="docdb">SI</country><country mxw-id="DS548831146" load-source="docdb">SK</country><country mxw-id="DS548871257" load-source="docdb">TR</country></ep-contracting-states></designated-states></international-convention-data><office-specific-data><eptags><ep-no-a-document-published>*</ep-no-a-document-published></eptags></office-specific-data></bibliographic-data><description mxw-id="PDES63957558" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><p id="p0001" num="0001">The present application fmds particular utility in medical imaging systems. However, it will be appreciated that the described technique(s) may also find application in other types of imaging systems, scanning systems, and/or other medical applications.</p><p id="p0002" num="0002">A need for effective interactive tools that allow easy initialization and refinement of a 3-D anatomical atlas is present in many applications. One particular application is in radiotherapy planning. Another application is in the refinement of the result of an automatic segmentation algorithm, since automatic algorithms are often error-prone due to a number of reasons: image artifacts, pathologies, etc.</p><p id="p0003" num="0003">Patent application <patcit id="pcit0001" dnum="WO2005038711A1"><text>WO2005/038711A1</text></patcit> relates to a scanner that acquires images of a subject. A 3D model of an organ is selected from an organ model database and dropped over an image of an actual organ. A best fitting means globally scales, translates and/or rotates the model to best fit the actual organ represented by the image.</p><p id="p0004" num="0004">Patent application <patcit id="pcit0002" dnum="WO2005078666A1"><text>WO2005/078666A1</text></patcit> relates to real time user interaction with deformable surfaces of segmentation. An image processing system comprising 3D processing means of automatic segmentation of an object using a 3D deformable surface model is disclosed.</p><p id="p0005" num="0005">Patent application <patcit id="pcit0003" dnum="US20040249270A1"><text>US2004/0249270A1</text></patcit> relates to a processor for analyzing tubular structure such as blood vessels. Using medical 3D image data, at least one of a volume-rendering image, a flat reformatted image on an arbitrary section, a curved reformatted image, and a maximum value projection image is prepared as a reference image. Vessel center lines are extracted from this reference image, and at least one of a vessel stretched image based on the center line and a perpendicular sectional image substantially perpendicular to the center line is prepared.</p><p id="p0006" num="0006">With conventional techniques, when a user is fitting an outline of an organ to an image of a patient's actual organ, planar slices through the organ are displayed. For instance, three orthogonal slices may be displayed. In current systems, the user can only modify the contours in the slice. This is labor-intensive for volumetric modifications. For 3D surface interaction on the other hand, changes in the slice causes changes in adjacent slices which cannot be seen. This is non-intuitive and requires a high level of<!-- EPO <DP n="2"> --> expertise when using conventional systems. Finally, for surface mesh representations, the mesh can degenerate when much user-interaction is performed.</p><p id="p0007" num="0007">There is an unmet need in the art for systems and methods that facilitate overcoming the deficiencies noted above.</p><p id="p0008" num="0008">In accordance with one aspect, a system for interactive registration of an anatomical structure model to a 3D clinical image include a memory that stores an atlas of 3D contoured models of anatomical structures; a display that presents a view of the clinical image and a selected contoured model overlaying the clinical image, and a user input device that a user employs to move one of a selected pair of landmark points on the contoured model. The system further includes a processor that receives landmark point movement information from the user input device and executes an algorithm for adjusting a display plane of the contoured model in real time.</p><p id="p0009" num="0009">A method of interactively registering a 3D contoured anatomical structure model to a clinical image of the structure in a patient includes presenting a model, selected from an atlas of models and overlaid on the clinical image, to a user, and deforming a portion of the selected model in a direction indicated by the user. The method further includes displaying a pair of user-entered landmark points, which define start and end points along the portion of the deformed model, and adding the landmark points to a set of landmark point pairs stored in a memory. The method also includes calculating a volumetric deformation function for the model using the user-entered landmark points, applying the volumetric deformation function to deform the model, and presenting the updated model to the user in substantially real time.</p><p id="p0010" num="0010">An elastic 3D contoured model registration apparatus, includes means for presenting a model, selected from an atlas of models and overlaid on the clinical image, to a user, and means for permitting the user to click on the model and drag a cursor in a direction in which the user wants to deform the model. The apparatus further includes means for displaying a pair of user-entered landmark points, which define start and end positions of a line of travel of the cursor, to the user, and means for adding the landmark points to a set of landmark point pairs stored in a memory, calculating a volumetric deformation function for the model using the user-entered<!-- EPO <DP n="3"> --> landmark points, and applying the volumetric deformation function to deform the model. The means for presenting displays the updated model to the user in real time.</p><p id="p0011" num="0011">An atlas of 3D contoured models of anatomical structures includes a plurality of models of anatomical structures, generated from scanned images of anatomical structures of one or more subjects, wherein the models are deformable in three dimensions and in substantially real time by a user. A machine-readable medium stores the plurality of models for recall and manipulation by an operator.</p><p id="p0012" num="0012">A therapy planning method includes inputting clinical image data, selecting a contour model, from an atlas of contoured models, based on patient data, to overlay the clinical image data, and manipulating the selected contour model to develop a therapy plan.</p><p id="p0013" num="0013">One advantage is that 3D contoured models of anatomical structures are deformed in real time, mitigating a need for staying within a defined display plane when deforming a model.</p><p id="p0014" num="0014">Another advantage resides in employing user-entered landmarks to dynamically adjust a display plane.</p><p id="p0015" num="0015">Still further advantages of the subject innovation will be appreciated by those of ordinary skill in the art upon reading and understand the following detailed description.</p><p id="p0016" num="0016">Still further advantages are realized in that the method is meshless. It is thus independent of the surface representation, and problems with degenerating meshes are avoided.</p><p id="p0017" num="0017">The innovation may take form in various components and arrangements of components, and in various steps and arrangements of steps. The drawings are only for purposes of illustrating various aspects and are not to be construed as limiting the invention.
<ul><li><figref idrefs="f0001">FIGURE 1</figref> illustrates a manual editing tool for elastically registering an atlas of anatomical structures to 3D clinical images to provide dynamic display plane updates in real time, in accordance with various aspects.<!-- EPO <DP n="4"> --></li><li><figref idrefs="f0002">FIGURE 2</figref> illustrates a line segment (ls) between two landmark points (p<sub>1</sub>, p<sub>2</sub>) that defines a set of planes (e.g., an infinite number of planes that contain the line segment).</li><li><figref idrefs="f0003">FIGURE 3</figref> illustrates a method for manipulating images of anatomical structures in a patient, according to various features described herein.</li><li><figref idrefs="f0004">FIGURE 4</figref> is an illustration of a method of generating slice views of an image volume, in accordance with various features.</li><li><figref idrefs="f0005">FIGURE 5</figref> illustrates a hospital system that may be employed in conjunction with the various systems and/or methods described herein.</li></ul></p><p id="p0018" num="0018"><figref idrefs="f0001">FIGURE 1</figref> illustrates a manual editing tool <b>10</b> for elastically registering a contour(s) selected from an atlas <b>26</b> of anatomical structures to 3D clinical images. The editing tool provides dynamic display plane updates in real time. The atlas can include models of one or several anatomical structures, (e.g., organs such as the heart lung(s), brain, spleen, liver, intestine, stomach, gall bladder; other structures such as bone(s), muscle, etc.), and such structures can be parameterized. Further, a plurality of models can be provided for various anatomical structures, e.g., corresponding to adult, child, obese, skinny, male, female, etc. For instance, parameterization can be performed using a mesh technique, non-uniform rational B-splines (NURBS), or some other parameterization protocol. The tool <b>10</b> facilitates providing a user with a reliable, intuitive, and interactive 3D editing application. According to one embodiment, the tool uses techniques similar to those used in the gaming industry (See, e.g., <nplcit id="ncit0001" npl-type="s"><text>M. Müller, B. Heidelberger, M. Teschner, and M. Gross. Meshless deformations based on shape matching. Proc. of SIGGRAPH '05, pages 471-478, 2005</text></nplcit>, describing a technique for rendering a surface and not volumetric image information).</p><p id="p0019" num="0019">The tool <b>10</b> facilitates 3D manipulation of a contoured image volume model, which in turn permits a user to manipulate contours of an image volume model in multiple planes, rather than in just one plane. For instance, a user accesses a virtual tool kit <b>11</b> with electronically-defined tools to push, pull, or otherwise adjust the model contour in three dimensions. For example, the tools define surfaces of various radii, shapes, and sizes, including a single point, that can press or pull the contour to mold its shape. The user can push or pull the tool along the displayed plane or at an angle to the<!-- EPO <DP n="5"> --> displayed plane. As a point on the contour is pulled or pushed off of one or more of the displayed planes, the tool automatically changes the displayed plane(s) so that the user can see a desired image volume contour portion superimposed on a clinical image volume throughout the period during which the contour portion is being manipulated. The image volume can comprise one or multiple anatomical structures, e.g., adjacent organs. For instance, a user can pull a specific point on a contour or contoured model to a corresponding point on an image of an anatomical structure in a patient. In one example, a significant point may be a spinous process on a vertebra, and the user can drag a corresponding process on the contoured model to the spinous process on the patient's vertebra to more closely align the model to the actual image volume. Between constrained points, the model elastically deforms. Contoured models, which can comprise one or more anatomical structures, are generated from patient data, such as scans or other images of the structure(s). In one embodiment, a number of scans or images of one or more subjects are employed to generate one or more average, or "normal," model(s) of the structure(s).</p><p id="p0020" num="0020">The displayed slice or surface need not be planar, but may be curved as well. For instance, a contour surface can be curved to match the curvature of a spine. In one embodiment, organ outlines are stored in the atlas individually, and can be combined or assembled by the user to form an area of interest. In another embodiment, outlines for organs in commonly imaged areas can be preassembled, such that the outlines for all organs in preassembled area can be downloaded, uploaded, or otherwise accessed as a group.</p><p id="p0021" num="0021">The tool includes a user interface <b>12</b> that is coupled to an imager <b>14</b>. For instance, the imager <b>14</b> can be a computed tomography (CT) scanning system or a variant thereof, a magnetic resonance imaging (MRI) system or variant thereof, or any other suitable imager for generating 2D or 3D images of a patient or portion of a patient.</p><p id="p0022" num="0022">The user interface <b>14</b> includes a processor <b>16</b> that executes machine-readable instructions and/or routines, which are stored in a memory <b>18</b>, for manipulating a 3D image of one or more organs in a patient. Such images are displayed to a user via a display <b>20</b>, and the user is permitted to manipulate the images using an input device <b>22</b>. The memory <b>18</b> additionally stores information and/or routines related to the atlas <b>26</b>, including 3D images and/or maps of various organs, which are then used as a template on<!-- EPO <DP n="6"> --> which is overlaid a corresponding image <b>24</b> of a patient's organ(s). Additionally, the memory stores information and/or routines related displaying clinical and atlas images to the user via the display <b>20</b>, as well as routines for manipulating atlas and/or clinical images in response to user input via the input device <b>22</b>. Moreover, the memory stores image data <b>24</b> related to the image of the patient and landmark data <b>28</b> describing landmark pairs and the like. The input device can be, for example, a keyboard and cursor, a stylus, a mouse, or some other suitable input device.</p><p id="p0023" num="0023"><figref idrefs="f0002">FIGURE 2</figref>, which is to be viewed in conjunction with <figref idrefs="f0001">Figure 1</figref>, illustrates a line segment (ls) between two landmark points (p<sub>1</sub>, p<sub>2</sub>) that defines a set of planes (e.g., an infinite number of planes that contain the line segment). In an example, a displayed plane (P<sub>d</sub>) is a function of the line segment between two landmarks, and a point p<sub>3</sub> to which one of the landmarks is moved by the user. For instance, the initial positions of the two landmark points p<sub>1</sub> and p<sub>2</sub> provide two points to define the display plane P<sub>d</sub>, and the final position p<sub>3</sub> of the manipulated landmark point provides a third point to complete the set of three points to define the display plane. In this example, the user clicks on one of the two landmark points, drags the selected landmark point to new 3D coordinates, and releases the mouse button. The coordinates at which the mouse button is released are registered by the processor <b>16</b>, and stored to memory <b>18</b> as a new landmark pair. In this manner, the new coordinates to which the user moves one of the landmark points are used to define the display plane, and thus the adjusted landmark point is within the display plane and visible to the user. The processor <b>16</b> reorients the corresponding one of the displayed slices to lie in the defined display plane P<sub>d</sub>.</p><p id="p0024" num="0024">For example, the display <b>20</b> displays three orthogonal planes P<sub>1</sub>, P<sub>2</sub>, and P<sub>3</sub>, which intersect at point p<sub>2</sub>, which is to be moved. As point p<sub>2</sub> is moved to point p<sub>3</sub>, the new display plane P<sub>d</sub> is defined, and the corresponding displayed plane P<sub>2</sub> is rotated to become co-planar with plane P<sub>d</sub>.</p><p id="p0025" num="0025">In another embodiment, the atlas comprises a plurality of labeled models representing different anatomical structures or combinations or structures that may be imaged by the imager <b>14</b>. Additionally, the atlas can comprise a number of differentsized models for each anatomical structure or combination of structures. For instance, liver-and-kidney models of different sizes can be stored in the atlas as well as separate liver models and kidney models, which may also have multiple sizes. A user can<!-- EPO <DP n="7"> --> associate first and second points in the model with first and second points in the clinical image, and can deform the model to match the clinical image. For instance, the user can drag a landmark point to a new location and see how the view changes as the landmark is dragged.</p><p id="p0026" num="0026">According to another embodiment, a user can zoom in on the image and model for fine-tuning of the contour. Additionally, a user can employ arrow keys or the like, in addition to or in place of, the stylus or mouse to manipulate the landmark points. The processor can employ splines with local and/or global support to facilitate elastic warping of the contoured model(s) to the image. In another embodiment, deformation of the model(s) by the user can be limited by a bounding box or the like, beyond which the user may not drag a landmark point to deform the model or contour thereof.</p><p id="p0027" num="0027"><figref idrefs="f0003">FIGURE 3</figref> illustrates a method <b>30</b> for manipulating images of anatomical structures in a patient, according to various features described herein. The method can be, for instance, executed by the processor <b>16</b> as a sequence of routines or the like. In one embodiment, the processor and/or a user brings an atlas of anatomical structures to an initial position (e.g., either automatically or manually, respectively), at <b>32</b>. For example, planar, orthogonal slices of an image, generated by the imager <b>14</b>, are displayed together with the contours of the surface models (e.g., from the atlas) intersecting the planar slices. In order to improve the initial segmentation, the user employs a mouse or stylus to click and draw, in any chosen plane, in the direction the user wants to deform the contour. Landmark information is received by the processor and/or memory at <b>34</b>. When the user releases the mouse or stylus button, a pair of corresponding landmarks is displayed in the image, e.g. connected by a line segment, at <b>36</b>. The landmarks define the beginning and end points of the segment, and are added to a set (which may be empty initially) of already existing paired landmarks stored in the memory, at <b>38</b>.</p><p id="p0028" num="0028">From the set of paired landmarks, a volumetric deformation function is calculated (e.g. by using mass-spring models, or parametric transformations such as based on Wendland functions, elastic body splines, thin-plate splines, etc.) and applied to the atlas, at <b>40</b>. The display of the atlas contours is updated on the fly (e.g., in real time) when a new landmark pair is inserted to or deleted from the set, at <b>42</b>. In this manner, the user simply clicks and drags points on a clinical image to more closely align the image with the stored atlas image(s) in a selected plane.<!-- EPO <DP n="8"> --></p><p id="p0029" num="0029"><figref idrefs="f0004">FIGURE 4</figref> is an illustration of a method <b>60</b> of generating slice views of an image volume, in accordance with various features. The method can be, for instance, executed by the processor <b>16</b> as a sequence of routines or the like. A user-defined landmark pair is selected by a user, at <b>62</b>. The user drags a landmark using the user input device <b>22</b>, and the processor displaces the landmark on the display <b>20</b> according to user input, at <b>64</b>, to refine the output result. According to one embodiment, the user can jump to any of the landmark pairs and see a slice through the image volume that contains the line segment defined by the two landmarks, e.g. by using an orthoviewer or the like.</p><p id="p0030" num="0030">Optionally, the user can adjust the landmark to define a "cut-plane"' which, after releasing the mouse or stylus button, displays a slice that "cuts" the image volume orthogonally to the slice view that was used to adjust the landmark, at 66. Providing the cut-plane can facilitate enhancing 3D interaction.</p><p id="p0031" num="0031">In other embodiments of the described systems and/or methods, specialized input devices, such as a 3D mouse or joystick, can be used to further improve the efficiency of manual interactions. The described techniques can be used as a pure manual editing tool or to provide pre- and post-processing functionality in combination with any suitable automated registration and segmentation techniques. Additionally, the systems and methods herein can be used in medical image processing systems, therapy planning workstations, and the like, as will be appreciated by those of skill in the art.</p><p id="p0032" num="0032">With reference to <figref idrefs="f0005">FIGURE 5</figref>, an exemplary hospital system may include a plurality of imaging devices <b>100</b>, such as CT, MRI, or the like, which generate imaging data that are reconstructed by individual or shared reconstruction processors <b>102</b> to generate 3D image representations. The image representations are communicated over a network <b>104</b> to a central memory <b>106.</b></p><p id="p0033" num="0033">At a station <b>110</b> connected with the network, an operator uses an input device <b>112</b> to move a selected 3D image representation from the central memory to a local memory <b>114</b>. A video processor 116 selects, for example, three orthogonal slices, which are displayed in view ports <b>118<sub>1</sub></b>, <b>118<sub>2</sub></b>, and <b>118<sub>3</sub></b> of a monitor <b>120</b>. A fourth view port <b>118<sub>4</sub></b> can display a surface rendered volume, close-up view, or the like. The operator, trough the input device <b>112</b>, selects the slices to be displayed.</p><p id="p0034" num="0034">The operator uses the input device to select a 3D contour from an atlas <b>122</b> that can be stored in a selected contour memory <b>124</b>. The video processor superimposes<!-- EPO <DP n="9"> --> the same three planes of the selected contour on the slices displayed in ports <b>118<sub>1</sub></b>, <b>118<sub>2</sub></b>, and <b>118<sub>3</sub></b>. To conform the contour to the shape of one or more of the organs in the clinical image, the operator uses the input device to designate the characteristic points on one or more of the 3D slices. As described above, the operator can designate a first characteristic point, e.g., a characteristic point of the image and the contour that have already been brought into coincidence. The operator then designates a second characteristic point on the image and a third characteristic point on the contour, which third characteristic point on the corresponds to the second characteristic point. Note that these three points may not be visible concurrently. Rather, the operator may have to shift one or more of the displayed planes to find and/or designate the three characteristic points.</p><p id="p0035" num="0035">Once the three points have been designated, the video processor display a slice defined by the three points, e.g., in the fourth view port <b>118<sub>4</sub></b>. As the operator pulls or pushes the third characteristic point on the contour toward the second characteristic point on the organ, the contour deflects elastically in three dimensions. During this motion, the operator can watch the deflection of the contour in the plane of the motion on the fourth view port. Changes in the contour may also be seen in the other displayed slices. The changed contour shape is stored in the memory <b>124.</b> The operator repeats this procedure as many times as necessary to conform the contour to the organ.</p><p id="p0036" num="0036">The shaped contour can be stored in the central memory <b>106</b> or used directly in another process. For instance, a therapy planning (e.g., radiation, ablation, etc.) station <b>130</b> can use the contour to plan a therapy session. Once planned to the satisfaction of the operator, the planned therapy is transferred to a therapy device <b>132</b> that implements the planned session. Other stations may use the shaped contour in various other planning processes.</p></description><claims mxw-id="PCLM56980163" lang="DE" load-source="patent-office"><!-- EPO <DP n="13"> --><claim id="c-de-01-0001" num="0001"><claim-text>System zur interaktiven Registrierung eines Modells einer anatomischen Struktur zu einem klinischen 3D-Bild, das Folgendes umfasst:
<claim-text>einen Speicher (18), der einen Atlas (26) mit 3D-Konturmodellen von anatomischen Strukturen speichert,</claim-text>
<claim-text>eine Anzeige (20), die eine Ansicht des klinischen Bildes und ein ausgewähltes Konturmodell darstellt, das das klinische Bild überlagert,</claim-text>
<claim-text>ein Benutzereingabegerät (22), die ein Benutzer dazu verwendet, einen Merkpunkt eines ausgewählten Paares Merkpunkte auf dem Konturmodell zu einem dritten Merkpunkt zu bewegen, und</claim-text>
<claim-text>einen Prozessor (16), der Informationen zu Bewegungen von Merkpunkten von dem Benutzereingabegerät (22) empfängt und einen Algorithmus ausführt, um eine Anzeigeebene des Konturmodells in Echtzeit anzupassen, wobei die Anzeigeebene durch das ausgewählte Paar Merkpunkte und den dritten Merkpunkt definiert wird.</claim-text></claim-text></claim><claim id="c-de-01-0002" num="0002"><claim-text>System nach Anspruch 1, wobei der Atlas (26) Konturmodelle unterschiedlicher Größe einer gegebenen anatomischen Struktur enthält.</claim-text></claim><claim id="c-de-01-0003" num="0003"><claim-text>System nach Anspruch 2, wobei der Atlas (26) Konturmodelle von Gruppen anatomischer Strukturen enthält.</claim-text></claim><claim id="c-de-01-0004" num="0004"><claim-text>System nach Anspruch 1, wobei das Eingabegerät (22) eine Taste umfasst, wobei der Benutzer die Taste betätigt, während er einen Cursor auf eine erste Stelle auf dem angezeigten Konturmodell hält, den Cursor zu einer zweiten Stelle auf dem angezeigten Konturmodell bewegt und die Taste an der zweiten Stelle loslässt, um eine Strecke zu definieren.</claim-text></claim><claim id="c-de-01-0005" num="0005"><claim-text>System nach Anspruch 4, wobei die erste und die zweite Stelle in dem Speicher (18) als ein Paar Merkpunkte gespeichert werden.<!-- EPO <DP n="14"> --></claim-text></claim><claim id="c-de-01-0006" num="0006"><claim-text>System nach Anspruch 5, wobei der Benutzer ein Paar Merkpunkte auswählt und einen ersten Merkpunkt des Paares Merkpunkte zu einer neuen Position zieht, um die Anzeigeebene zu definieren, und wobei der Prozessor die Anzeigeebene in Echtzeit aktualisiert, wenn der Benutzer den ersten Merkpunkt zieht.</claim-text></claim><claim id="c-de-01-0007" num="0007"><claim-text>System nach Anspruch 1, wobei der Benutzer erste und zweite Merkpunkte auf dem klinischen Bild und einen dritten Merkpunkt auf dem Konturmodell auswählt, wobei der dritte Merkpunkt entweder dem ersten oder dem zweiten Merkpunkt entspricht, wobei der von dem Prozessor (16) ausgeführte Algorithmus einen Schnitt in der von dem ersten, dem zweiten und dem dritten Merkpunkt definierten Ebene definiert und die Anzeige (20) veranlasst, den Schnitt anzuzeigen.</claim-text></claim><claim id="c-de-01-0008" num="0008"><claim-text>System nach Anspruch 1, wobei das Konturmodell zur Angleichung an das klinische Bild deformiert wird und anhand des deformierten Konturmodells ein Strahlentherapieplan generiert wird.</claim-text></claim><claim id="c-de-01-0009" num="0009"><claim-text>System nach Anspruch 1, wobei der Prozessor (16) eine volumetrische Deformationsfunktion erzeugt und die Funktion zur Anpassung der Anzeigeebene auf das Konturmodell anwendet.</claim-text></claim><claim id="c-de-01-0010" num="0010"><claim-text>System nach Anspruch 9, wobei der Prozessor (18) die volumetrische Deformationsfunktion anhand von zumindest entweder eines Feder-Masse-Modells, einer parametrischen Transformation einer Wendland-Funktion, Splines elastischer Körper oder Thin-Plate-Splines erzeugt.</claim-text></claim><claim id="c-de-01-0011" num="0011"><claim-text>System nach Anspruch 1, wobei die 3D-Konturmodelle aus Daten eines klinischen Bildes generiert werden.</claim-text></claim><claim id="c-de-01-0012" num="0012"><claim-text>System nach Anspruch 1, das ferner Folgendes umfasst:
<claim-text>eine Routine oder Mittel (32) zur Einstellung des Konturmodelles auf eine Anfangsposition, in der es ein Bild eines Patienten überlagert,<!-- EPO <DP n="15"> --></claim-text>
<claim-text>eine Routine oder Mittel (34) zum Empfang einer Benutzereingabe für die Deformation des Konturmodells,</claim-text>
<claim-text>eine Routine oder Mittel (36) zur Anzeige von vom Benutzer eingegebenen Merkpunkten,</claim-text>
<claim-text>eine Routine oder Mittel (38) zum Hinzufügen von vom Benutzer eingegebenen Merkpunktpaaren zu einem Satz mit existierenden Merkpunktpaaren,</claim-text>
<claim-text>eine Routine oder Mittel (40) zur Berechnung einer volumetrischen Deformationsfunktion für die Deformation des Konturmodells gemäß der Benutzereingabe und</claim-text>
<claim-text>eine Routine oder Mittel (42) zur Aktualisierung einer angezeigten Kontur des Modells in Echtzeit.</claim-text></claim-text></claim><claim id="c-de-01-0013" num="0013"><claim-text>System nach Anspruch 1, wobei der Prozessor so konfiguriert ist, dass er<br/>
Benutzereingaben hinsichtlich vom Benutzer definierten Merkpunktpaaren in dem angezeigten Konturmodell empfängt,<br/>
Koordinaten von Merkpunktpaaren des im Atlas (26) gespeicherten Konturmodells aktualisiert,<br/>
Benutzereingaben hinsichtlich der Bewegung eines ersten Merkpunktes in einem ausgewählten Merkpunktpaar empfängt und<br/>
das Konturmodell in Echtzeit als Reaktion auf die Bewegung des ersten Merkpunktes aktualisiert.</claim-text></claim><claim id="c-de-01-0014" num="0014"><claim-text>Verfahren zur interaktiven Registrierung eines Modells einer anatomischen Struktur zu einem klinischen 3D-Bild, das Folgendes umfasst:
<claim-text>Speichern in einem Speicher (18) eines Atlas (26) von 3D-Konturmodellen von anatomischen Strukturen,</claim-text>
<claim-text>Anzeigen über eine Anzeige (20) einer Ansicht des klinischen Bildes und eines ausgewählten Konturmodells, das das klinische Bild überlagert,</claim-text>
<claim-text>Bewegen über ein Benutzereingabegerät (22) eines Merkpunktes eines ausgewählten Paares Merkpunkte auf dem Konturmodell zu einem dritten Merkpunkt und</claim-text>
<claim-text>Empfangen durch einen Prozessor (16) von Informationen zu Bewegungen von Merkpunkten von dem Benutzereingabegerät (22) und Ausführen eines Algorithmus,<!-- EPO <DP n="16"> --> um eine Anzeigeebene des Konturmodells in Echtzeit anzupassen, wobei die Anzeigeebene durch das ausgewählte Paar Merkpunkte und den dritten Merkpunkt definiert wird.</claim-text></claim-text></claim><claim id="c-de-01-0015" num="0015"><claim-text>Prozessor (16) oder computerlesbares Medium (18), der bzw. das für die Ausführung des Verfahrens nach Anspruch 14 programmiert ist.</claim-text></claim></claims><claims mxw-id="PCLM56980164" lang="EN" load-source="patent-office"><!-- EPO <DP n="10"> --><claim id="c-en-01-0001" num="0001"><claim-text>A system for interactive registration of an anatomical structure model to a 3D clinical image, including:
<claim-text>a memory (<b>18</b>) that stores an atlas (<b>26</b>) of 3D contoured models of anatomical structures;</claim-text>
<claim-text>a display (<b>20</b>) that presents a view of the clinical image and a selected contoured model overlaying the clinical image;</claim-text>
<claim-text>a user input device (<b>22</b>) that a user employs to move one of a selected pair of<br/>
landmark points on the contoured model to a third landmark point; and</claim-text>
<claim-text>a processor (<b>16</b>) that receives landmark point movement information from the user input device (<b>22</b>) and executes an algorithm for adjusting a display plane of the contoured model in real time, wherein the display plane is defined by the selected pair of landmark points and the third landmark point.</claim-text></claim-text></claim><claim id="c-en-01-0002" num="0002"><claim-text>The system according to claim 1, wherein the atlas (<b>26</b>) includes differently-sized contoured models of a given anatomical structure.</claim-text></claim><claim id="c-en-01-0003" num="0003"><claim-text>The system according to claim 2, wherein the atlas (<b>26</b>) includes contoured models of groups of anatomical structures.</claim-text></claim><claim id="c-en-01-0004" num="0004"><claim-text>The system according to claim 1, wherein the input device (<b>22</b>) includes a button that the user depresses while hovering a cursor at a first location on the displayed contoured model, moves the cursor to a second location on the displayed contour model, and releases the button at the second location to define a line segment.</claim-text></claim><claim id="c-en-01-0005" num="0005"><claim-text>The system according to claim 4, wherein the first and second locations are stored to the memory (<b>18</b>) as a pair of landmark points.</claim-text></claim><claim id="c-en-01-0006" num="0006"><claim-text>The system according to claim 5, wherein the user selects a pair of landmark points and drags a first landmark point of the pair of landmark points to a new position to<!-- EPO <DP n="11"> --> define the display plane, and the processor updates the display plane in real time as the user drags the first landmark point.</claim-text></claim><claim id="c-en-01-0007" num="0007"><claim-text>The system according to claim 1, wherein the user selects first and second landmark points on the clinical image and a third landmark point on the contoured model, which third landmark point corresponds to one of the first and second landmark points and wherein the algorithm executed by the processor (<b>16</b>) defines a slice in the plane defined by the first, second, and third landmark points and causes the display (<b>20</b>) to display the slice.</claim-text></claim><claim id="c-en-01-0008" num="0008"><claim-text>The system according to claim 1, wherein the contoured model is deformed to align with the clinical image and a radiation therapy plan is generated using the deformed contoured model.</claim-text></claim><claim id="c-en-01-0009" num="0009"><claim-text>The system according to claim 1, wherein the processor (<b>16</b>) generates a volumetric deformation function and applies the function to the contoured model to adjust the display plane.</claim-text></claim><claim id="c-en-01-0010" num="0010"><claim-text>The system according to claim 9, wherein the processor (<b>18</b>) generates the volumetric deformation function using at least one of a spring-mass model, Wendland-function parametric transformation, elastic-body splines, or thin-plate splines.</claim-text></claim><claim id="c-en-01-0011" num="0011"><claim-text>The system according to claim 1, wherein the 3D contoured models are generated from clinical image data.</claim-text></claim><claim id="c-en-01-0012" num="0012"><claim-text>The system according to claim 1, further including:
<claim-text>a routine or means (<b>32</b>) for setting the contoured model to an initial position overlaying an image of a patient;</claim-text>
<claim-text>a routine or means (<b>34</b>) for receiving user input to deform the contoured model;</claim-text>
<claim-text>a routine or means (<b>36</b>) for displaying user-entered landmark points;</claim-text>
<claim-text>a routine or means (<b>38</b>) for adding user-entered landmark point pairs to a set of existing landmark point pairs;</claim-text>
<claim-text>a routine or means (<b>40</b>) for calculating a volumetric deformation function for deforming the contoured model according to the user input; and<!-- EPO <DP n="12"> --></claim-text>
<claim-text>a routine or means (<b>42</b>) for updating a displayed contour of the model in real time.</claim-text></claim-text></claim><claim id="c-en-01-0013" num="0013"><claim-text>The system according to claim 1, wherein the processor is configured to:
<claim-text>receive user input relating to user-defined landmark point pairs within the displayed contoured model;</claim-text>
<claim-text>update landmark pair coordinates in the contoured model stored in the atlas (<b>26</b>);</claim-text>
<claim-text>receive user input related to movement of a first landmark point in a selected landmark point pair; and</claim-text>
<claim-text>update the contoured model in real time in response to the movement of the first landmark point.</claim-text></claim-text></claim><claim id="c-en-01-0014" num="0014"><claim-text>A method for interactive registration of an anatomical structure model to a 3D clinical image comprising the steps of:
<claim-text>storing, in a memory (<b>18</b>) an atlas (<b>26</b>) of 3D contoured models of anatomical structures;</claim-text>
<claim-text>presenting via a display (<b>20</b>) a view of the clinical image and a selected contoured model overlaying the clinical image;</claim-text>
<claim-text>moving, via a user input device (<b>22</b>), one of a selected pair of landmark points on the contoured model to a third landmark point; and</claim-text>
<claim-text>receiving, by a processor (<b>16</b>), landmark point movement information from the user input device (<b>22</b>) and executing an algorithm for adjusting a display plane of the contoured model in real time, wherein the display plane is defined by the selected pair of landmark points and the third landmark point.</claim-text></claim-text></claim><claim id="c-en-01-0015" num="0015"><claim-text>A processor (<b>16</b>) or computer-readable medium (<b>18</b>) programmed to perform the method of claim 14.</claim-text></claim></claims><claims mxw-id="PCLM56980165" lang="FR" load-source="patent-office"><!-- EPO <DP n="17"> --><claim id="c-fr-01-0001" num="0001"><claim-text>Système d'alignement interactif d'un modèle de structure anatomique avec une image clinique 3D, comprenant :
<claim-text>une mémoire (18) qui stocke un atlas (26) de modèles de contours 3D de structures anatomiques ;</claim-text>
<claim-text>un affichage (20) qui présente une vue de l'image clinique et un modèle de contour sélectionné superposé sur l'image clinique ;</claim-text>
<claim-text>un dispositif d'entrée d'utilisateur (22) qu'un utilisateur emploie pour déplacer l'un d'une paire sélectionnée de points de référence sur le modèle de contour à un troisième point de référence ; et</claim-text>
<claim-text>un processeur (16) qui reçoit des informations de déplacement de point de référence de la part du dispositif d'entrée d'utilisateur (22) et qui exécute un algorithme pour ajuster un plan d'affichage du modèle de contour en temps réel, dans lequel le plan d'affichage est défini par la paire sélectionnée de points de référence et le troisième point de référence.</claim-text></claim-text></claim><claim id="c-fr-01-0002" num="0002"><claim-text>Système selon la revendication 1, dans lequel l'atlas (26) comprend des modèles de contours de tailles différentes d'une structure anatomique donnée.</claim-text></claim><claim id="c-fr-01-0003" num="0003"><claim-text>Système selon la revendication 2, dans lequel l'atlas (26) comprend des modèles de contours de groupes de structures anatomiques.</claim-text></claim><claim id="c-fr-01-0004" num="0004"><claim-text>Système selon la revendication 1, dans lequel le dispositif d'entrée (22) comprend un bouton sur lequel l'utilisateur appuie en faisant passer un curseur sur un premier emplacement du modèle de contour affiché, puis l'utilisateur déplace le curseur à un deuxième emplacement sur le modèle de contour affiché et relâche le bouton au deuxième emplacement pour définir un segment de ligne.<!-- EPO <DP n="18"> --></claim-text></claim><claim id="c-fr-01-0005" num="0005"><claim-text>Système selon la revendication 4, dans lequel les premier et deuxième emplacements sont stockés dans la mémoire (18) sous la forme d'une paire de points de référence.</claim-text></claim><claim id="c-fr-01-0006" num="0006"><claim-text>Système selon la revendication 5, dans lequel l'utilisateur sélectionne une paire de points de référence et fait glisser un premier point de référence de la paire de points de référence à une nouvelle position pour définir le plan d'affichage, et le processeur actualise le plan d'affichage en temps réel lorsque l'utilisateur fait glisser le premier point de référence.</claim-text></claim><claim id="c-fr-01-0007" num="0007"><claim-text>Système selon la revendication 1, dans lequel l'utilisateur sélectionne des premier et deuxième points de référence sur l'image clinique et un troisième point de référence sur le modèle de contour, ledit troisième point de référence correspondant à l'un des premier et deuxième points de référence, et dans lequel l'algorithme exécuté par le processeur (16) définit une tranche dans le plan défini par les premier, deuxième et troisième points de référence et amène l'affichage (20) à afficher la tranche.</claim-text></claim><claim id="c-fr-01-0008" num="0008"><claim-text>Système selon la revendication 1, dans lequel le modèle de contour est déformé pour s'aligner avec l'image clinique et un plan de thérapie par rayonnement est généré en utilisant le modèle de contour déformé.</claim-text></claim><claim id="c-fr-01-0009" num="0009"><claim-text>Système selon la revendication 1, dans lequel le processeur (16) génère une fonction de déformation volumétrique et applique la fonction au modèle de contour pour ajuster le plan d'affichage.</claim-text></claim><claim id="c-fr-01-0010" num="0010"><claim-text>Système selon la revendication 9, dans lequel le processeur (16) génère la fonction de déformation volumétrique en utilisant au moins l'un d'un modèle de masse élastique, une transformation paramétrique de fonction de Wendland, des cannelures de corps élastiques ou des cannelures de plaques minces.</claim-text></claim><claim id="c-fr-01-0011" num="0011"><claim-text>Système selon la revendication 1, dans lequel les modèles de contours 3D sont générés à partir de données d'images cliniques.<!-- EPO <DP n="19"> --></claim-text></claim><claim id="c-fr-01-0012" num="0012"><claim-text>Système selon la revendication 1, comprenant en outre :
<claim-text>une routine ou un moyen (32) pour régler le modèle de contour à une position initiale superposée sur une image d'un patient ;</claim-text>
<claim-text>une routine ou un moyen (34) pour recevoir une entrée d'utilisateur pour déformer le modèle de contour ;</claim-text>
<claim-text>une routine ou un moyen (36) pour afficher des points de référence entrés par l'utilisateur ;</claim-text>
<claim-text>une routine ou un moyen (38) pour ajouter des paires de points de référence entrées par l'utilisateur à un ensemble de paires de points de référence existantes ;</claim-text>
<claim-text>une routine ou un moyen (40) pour calculer une fonction de déformation volumétrique pour déformer le modèle de contour en fonction de l'entrée d'utilisateur ; et</claim-text>
<claim-text>une routine ou un moyen (42) pour actualiser un contour affiché du modèle en temps réel.</claim-text></claim-text></claim><claim id="c-fr-01-0013" num="0013"><claim-text>Système selon la revendication 1, dans lequel le processeur est configuré pour effectuer :
<claim-text>la réception d'une entrée d'utilisateur relative à des paires de points de référence définies par l'utilisateur à l'intérieur du modèle de contour affiché ;</claim-text>
<claim-text>l'actualisation des coordonnées de paires de points de référence dans le modèle de contour stocké dans l'atlas (26) ;</claim-text>
<claim-text>la réception d'une entrée d'utilisateur relative à un déplacement d'un premier point de référence dans une paire de points de référence sélectionnée ; et</claim-text>
<claim-text>l'actualisation du modèle de contour en temps réel en réponse au déplacement du premier point de référence.</claim-text></claim-text></claim><claim id="c-fr-01-0014" num="0014"><claim-text>Procédé d'alignement interactif d'un modèle de structure anatomique avec une image clinique 3D, comprenant les étapes de :
<claim-text>le stockage, dans une mémoire (18), d'un atlas (26) de modèles de contours 3D de structures anatomiques ;</claim-text>
<claim-text>la présentation, par l'intermédiaire d'un affichage (20), d'une vue de l'image clinique et d'un modèle de contour sélectionné superposé sur l'image clinique ;<!-- EPO <DP n="20"> --></claim-text>
<claim-text>le déplacement, par l'intermédiaire d'un dispositif d'entrée d'utilisateur (22), de l'un d'une paire sélectionnée de points de référence sur le modèle de contour à un troisième point de référence ; et</claim-text>
<claim-text>la réception, par un processeur (16), d'informations de déplacement de point de référence de la part du dispositif d'entrée d'utilisateur (22) et l'exécution d'un algorithme pour ajuster un plan d'affichage du modèle de contour en temps réel, dans lequel le plan d'affichage est défini par la paire sélectionnée de points de référence et le troisième point de référence.</claim-text></claim-text></claim><claim id="c-fr-01-0015" num="0015"><claim-text>Processeur (16) ou support lisible par ordinateur (18) programmé pour effectuer le procédé de la revendication 14.</claim-text></claim></claims><drawings mxw-id="PDW16669076" load-source="patent-office"><!-- EPO <DP n="21"> --><figure id="f0001" num="1"><img id="if0001" file="imgf0001.tif" wi="156" he="165" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="22"> --><figure id="f0002" num="2"><img id="if0002" file="imgf0002.tif" wi="165" he="214" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="23"> --><figure id="f0003" num="3"><img id="if0003" file="imgf0003.tif" wi="136" he="218" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="24"> --><figure id="f0004" num="4"><img id="if0004" file="imgf0004.tif" wi="137" he="141" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="25"> --><figure id="f0005" num="5"><img id="if0005" file="imgf0005.tif" wi="165" he="206" img-content="drawing" img-format="tif"/></figure></drawings><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
