<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2680563-A2" country="EP" doc-number="2680563" kind="A2" date="20140101" family-id="48771284" file-reference-id="315735" date-produced="20180824" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="146549125" ucid="EP-2680563-A2"><document-id><country>EP</country><doc-number>2680563</doc-number><kind>A2</kind><date>20140101</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-13173901-A" is-representative="YES"><document-id mxw-id="PAPP154823048" load-source="docdb" format="epo"><country>EP</country><doc-number>13173901</doc-number><kind>A</kind><date>20130626</date><lang>EN</lang></document-id><document-id mxw-id="PAPP173226834" load-source="docdb" format="original"><country>EP</country><doc-number>13173901.3</doc-number><date>20130626</date><lang>EN</lang></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC140452368" ucid="JP-2012147729-A" load-source="docdb"><document-id format="epo"><country>JP</country><doc-number>2012147729</doc-number><kind>A</kind><date>20120629</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL-1833766687" load-source="docdb">H04N   1/00        20060101AFI20170313BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-1833766688" load-source="docdb">G06F   1/32        20060101ALI20170313BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-1833766689" load-source="docdb">G01J   5/34        20060101ALI20170313BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-1833766690" load-source="docdb">G01J   5/00        20060101ALI20170313BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-1833766691" load-source="docdb">G01J   5/02        20060101ALI20170313BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-1833766692" load-source="docdb">G01J   5/08        20060101ALI20170313BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-1713566674" load-source="docdb" scheme="CPC">Y02D  10/159       20180101 LA20180103BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1713570614" load-source="docdb" scheme="CPC">Y02D  50/20        20180101 LA20180103BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1713571077" load-source="docdb" scheme="CPC">Y02D  10/173       20180101 LA20180103BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1713575031" load-source="docdb" scheme="CPC">Y02D  10/171       20180101 LA20180103BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1839982434" load-source="docdb" scheme="CPC">H04N2201/0098      20130101 LA20170308BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1839984954" load-source="docdb" scheme="CPC">H04N   1/00928     20130101 LI20170308BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1839987899" load-source="docdb" scheme="CPC">H04N   1/00395     20130101 LI20170308BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2019234001" load-source="docdb" scheme="CPC">G01J   5/0806      20130101 LI20150929BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2019234214" load-source="docdb" scheme="CPC">G01J   5/0025      20130101 LI20150929BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2019234255" load-source="docdb" scheme="CPC">G01J   5/025       20130101 LI20150929BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2021989350" load-source="docdb" scheme="CPC">G06F   1/3231      20130101 LI20150915BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2021990600" load-source="docdb" scheme="CPC">G01J   5/34        20130101 LI20150917BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2021995022" load-source="docdb" scheme="CPC">G06F   1/3287      20130101 LI20150917BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2021997930" load-source="docdb" scheme="CPC">G06F   1/3284      20130101 LI20150917BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2059337646" load-source="docdb" scheme="CPC">H04N   1/00891     20130101 LI20150502BHEP        </classification-cpc><classification-cpc mxw-id="PCL-2059339640" load-source="docdb" scheme="CPC">H04N   1/00912     20130101 LI20150502BHEP        </classification-cpc><classification-cpc mxw-id="PCL1991311910" load-source="docdb" scheme="CPC">H04N   1/00896     20130101 FI20131226BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT132179859" lang="DE" load-source="patent-office">Bilderzeugungsvorrichtung und Steuerverfahren dafür</invention-title><invention-title mxw-id="PT132179860" lang="EN" load-source="patent-office">Image forming apparatus and control method therefor</invention-title><invention-title mxw-id="PT132179861" lang="FR" load-source="patent-office">Appareil de formation d'images et son procédé de commande</invention-title><citations><non-patent-citations><nplcit><text>None</text><sources><source mxw-id="PNPL45130739" load-source="docdb" name="APP"/></sources></nplcit></non-patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR918162444" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>KYOCERA DOCUMENT SOLUTIONS INC</last-name><address><country>JP</country></address></addressbook></applicant><applicant mxw-id="PPAR918147713" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>KYOCERA DOCUMENT SOLUTIONS INC.</last-name></addressbook></applicant><applicant mxw-id="PPAR918992403" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Kyocera Document Solutions Inc.</last-name><iid>101370346</iid><address><street>1-2-28, Tamatsukuri Chuo-ku</street><city>Osaka-shi, Osaka 540-8585</city><country>JP</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR918134265" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>MIYAMOTO NARUYUKI</last-name><address><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR918146506" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>MIYAMOTO, NARUYUKI</last-name></addressbook></inventor><inventor mxw-id="PPAR918983336" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>MIYAMOTO, NARUYUKI</last-name><address><street>c/o Kyocera Document Solutions Inc. 1-2-28, Tamatsukuri, Chuo-ku, Osaka-shi</street><city>OSAKA, 540-8585</city><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR918155506" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>TANISAKI YUKIO</last-name><address><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR918148004" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>TANISAKI, YUKIO</last-name></addressbook></inventor><inventor mxw-id="PPAR918982818" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>TANISAKI, YUKIO</last-name><address><street>c/o Kyocera Document Solutions Inc. 1-2-28, Tamatsukuri, Chuo-ku, Osaka-shi</street><city>OSAKA, 540-8585</city><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR918137613" load-source="docdb" sequence="3" format="epo"><addressbook><last-name>NARUSE KENTARO</last-name><address><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR918151886" load-source="docdb" sequence="3" format="intermediate"><addressbook><last-name>NARUSE, KENTARO</last-name></addressbook></inventor><inventor mxw-id="PPAR918981700" load-source="patent-office" sequence="3" format="original"><addressbook><last-name>NARUSE, KENTARO</last-name><address><street>c/o Kyocera Document Solutions Inc. 1-2-28, Tamatsukuri, Chuo-ku, Osaka-shi</street><city>OSAKA, 540-8585</city><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR918152389" load-source="docdb" sequence="4" format="epo"><addressbook><last-name>TEZUKA RIE</last-name><address><country>JP</country></address></addressbook></inventor><inventor mxw-id="PPAR918146064" load-source="docdb" sequence="4" format="intermediate"><addressbook><last-name>TEZUKA, RIE</last-name></addressbook></inventor><inventor mxw-id="PPAR918982404" load-source="patent-office" sequence="4" format="original"><addressbook><last-name>TEZUKA, RIE</last-name><address><street>c/o Kyocera Document Solutions Inc. 1-2-28, Tamatsukuri, Chuo-ku, Osaka-shi</street><city>OSAKA, 540-8585</city><country>JP</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR918992945" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Beetz &amp; Partner</last-name><iid>100060481</iid><address><street>Patentanwälte Steinsdorfstrasse 10</street><city>80538 München</city><country>DE</country></address></addressbook></agent></agents></parties><international-convention-data><designated-states><ep-contracting-states><country mxw-id="DS548842818" load-source="docdb">AL</country><country mxw-id="DS548847482" load-source="docdb">AT</country><country mxw-id="DS548842819" load-source="docdb">BE</country><country mxw-id="DS548835892" load-source="docdb">BG</country><country mxw-id="DS548848436" load-source="docdb">CH</country><country mxw-id="DS548802295" load-source="docdb">CY</country><country mxw-id="DS548802296" load-source="docdb">CZ</country><country mxw-id="DS548844175" load-source="docdb">DE</country><country mxw-id="DS548842820" load-source="docdb">DK</country><country mxw-id="DS548842821" load-source="docdb">EE</country><country mxw-id="DS548801453" load-source="docdb">ES</country><country mxw-id="DS548835893" load-source="docdb">FI</country><country mxw-id="DS548835894" load-source="docdb">FR</country><country mxw-id="DS548844176" load-source="docdb">GB</country><country mxw-id="DS548842822" load-source="docdb">GR</country><country mxw-id="DS548844177" load-source="docdb">HR</country><country mxw-id="DS548802297" load-source="docdb">HU</country><country mxw-id="DS548848437" load-source="docdb">IE</country><country mxw-id="DS548842823" load-source="docdb">IS</country><country mxw-id="DS548835895" load-source="docdb">IT</country><country mxw-id="DS548842824" load-source="docdb">LI</country><country mxw-id="DS548844178" load-source="docdb">LT</country><country mxw-id="DS548847483" load-source="docdb">LU</country><country mxw-id="DS548835896" load-source="docdb">LV</country><country mxw-id="DS548844179" load-source="docdb">MC</country><country mxw-id="DS548847484" load-source="docdb">MK</country><country mxw-id="DS548847485" load-source="docdb">MT</country><country mxw-id="DS548848158" load-source="docdb">NL</country><country mxw-id="DS548848438" load-source="docdb">NO</country><country mxw-id="DS548848159" load-source="docdb">PL</country><country mxw-id="DS548801454" load-source="docdb">PT</country><country mxw-id="DS548846439" load-source="docdb">RO</country><country mxw-id="DS548801455" load-source="docdb">RS</country><country mxw-id="DS548848160" load-source="docdb">SE</country><country mxw-id="DS548844181" load-source="docdb">SI</country><country mxw-id="DS548848439" load-source="docdb">SK</country><country mxw-id="DS548848440" load-source="docdb">SM</country><country mxw-id="DS548842825" load-source="docdb">TR</country></ep-contracting-states><ep-extended-states><ep-extended-state-data><country>BA</country></ep-extended-state-data><ep-extended-state-data><country>ME</country></ep-extended-state-data></ep-extended-states></designated-states></international-convention-data></bibliographic-data><abstract mxw-id="PA128669795" lang="EN" load-source="patent-office"><p id="pa01" num="0001">In an image forming apparatus, a first detection portion includes a pyroelectric sensor and detects the upper half of the human body. A first signal generation portion generates a first signal whose level varies according to the output value of the pyroelectric sensor. A second detection portion includes a pyroelectric sensor and detects a lower area than the first detection portion. A second signal generation portion generates a second signal whose level varies according to the output value of the pyroelectric sensor. A storage portion stores discrimination data including data defining, with respect to the waveforms of the first and second signals, a condition for recognizing a human moving toward the image forming apparatus and a condition for recognizing a human crossing a detection area of the pyroelectric sensors. A recognition portion recognizes the direction of movement of a human.
<img id="iaf01" file="imgaf001.tif" wi="123" he="82" img-content="drawing" img-format="tif"/></p></abstract><abstract mxw-id="PA128499168" lang="EN" source="EPO" load-source="docdb"><p>In an image forming apparatus, a first detection portion includes a pyroelectric sensor and detects the upper half of the human body. A first signal generation portion generates a first signal whose level varies according to the output value of the pyroelectric sensor. A second detection portion includes a pyroelectric sensor and detects a lower area than the first detection portion. A second signal generation portion generates a second signal whose level varies according to the output value of the pyroelectric sensor. A storage portion stores discrimination data including data defining, with respect to the waveforms of the first and second signals, a condition for recognizing a human moving toward the image forming apparatus and a condition for recognizing a human crossing a detection area of the pyroelectric sensors. A recognition portion recognizes the direction of movement of a human.</p></abstract><description mxw-id="PDES63955225" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><p id="p0001" num="0001">The present disclosure relates to an image forming apparatus that recognizes movement of a human body (hereinafter also a "human" or a "user") by exploiting heat radiated therefrom.</p><p id="p0002" num="0002">Conventionally, an infrared sensor that detects infrared radiation emanating from a human is commonly used to detect whether or not a human is present within a detection area. For example, results of detecting presence/absence of a human body are used for surveillance and other purposes. For example, a detecting device that uses two sensor units to detect a human body as described below is known.</p><p id="p0003" num="0003">Specifically, a passive infrared human body detection device is known that is provided with: two sensor units each comprising a light receiving element and an optical system, the first sensor unit being arranged with its light receiving direction pointing to the upper half of the human body to be detected so as to have a detection area that does not reach the ground, the second sensor unit being arranged to have a detection area below that detection area so as to point to the ground at a predetermined detection distance away; two level detection circuits that output detection signals when the output electrical signals from the light receiving elements of the two sensor units exceed predetermined levels; and a human body detection circuit that outputs a human body detection signal when both of the level detection circuits output the detection signals.</p><p id="p0004" num="0004">When a user wants an image forming apparatus (such as a multifunction product or a copier) to execute a job such as copying or document reading, to make settings and to command execution of the job, the user operates the image forming apparatus.</p><p id="p0005" num="0005">An infrared sensor may be provided on the image forming apparatus. Whether or not a human is present within the detection area of the infrared sensor may be detected so that results of the detection can be used to manage and control the operation of the image forming apparatus. For example, when presence of a human is detected within the detection area of the infrared sensor, power saving mode, in which the supply of electric power to particular portions in the image forming apparatus is stopped, can be canceled. Then, the user can make the image forming apparatus execute a job with almost no wait.</p><p id="p0006" num="0006">However, even in a case like when a human passes by in front of the image forming apparatus, the human enters the detection area of the infrared sensor. In this case, the user approaches the<!-- EPO <DP n="2"> --> image forming apparatus with no intention to use it; accordingly, there is no need to restart the supply of the electric power to the particular portions (power saving mode should be maintained). However, by conventional detection using an infrared sensor, a human simply passing by (a human simply entering the detection area of the infrared sensor) causes cancellation of the pyroelectric sensor, resulting in unnecessary consumption of electric power.</p><p id="p0007" num="0007">To eliminate such waste, whether or not a human is approaching the image forming apparatus should be detected accurately. However, by conventional human body detection using an infrared sensor, presence of a human within the detection area of the infrared sensor can be detected, but whether the user is moving toward the image forming apparatus or is simply crossing the detection area is not detected with an accurate distinction. Thus, there is conventionally the problem that the direction of movement of a human with respect to the image forming apparatus cannot be detected accurately.</p><p id="p0008" num="0008">Here, in the conventional technology mentioned above, the use of two sensor units with different detection areas may increase the likelihood of achieving accurate detection of presence/absence of a human. However, the conventional technology mentioned above does not provide a procedure, method, or technique that enables recognition of whether a human is moving toward the spot where the sensor is provided or is crossing the detection area of the sensor with an accurate distinction. Thus, the conventional technology mentioned above is not free from the problem discussed above.</p><heading id="h0001"><b>SUMMARY</b></heading><p id="p0009" num="0009">To solve the problem discussed above, an image forming apparatus includes a first detection portion, a first signal generation portion, a second detection portion, a second signal generation portion, a storage portion, and a recognition portion. The first detection portion includes a pyroelectric sensor, and detects the upper half of the human body. The first signal generation portion receives the output of the pyroelectric sensor of the first detection portion to generate a first signal whose level varies according to whether or not the output value of the pyroelectric sensor of the first detection portion is greater than a prescribed threshold value. The second detection portion includes a pyroelectric sensor, and detects a lower area than the first detection portion to detect the lower half of the human body. The second signal<!-- EPO <DP n="3"> --> generation portion receives the output of the pyroelectric sensor of the second detection portion to generate a second signal whose level varies according to whether or not the output value of the pyroelectric sensor of the second detection portion is greater than a prescribed threshold value. The storage portion stores discrimination data including data defining, with respect to the waveforms of the first and second signals, a condition for recognizing a human moving toward the image forming apparatus and a condition for recognizing a human crossing a detection area of the pyroelectric sensors. The recognition portion recognizes the direction of movement of a human with respect to the image forming apparatus by recognizing, based on the waveforms of the first and second signals and the discrimination data, whether a human is moving toward the image forming apparatus and whether a human is crossing the detection area of the pyroelectric sensors.</p><p id="p0010" num="0010">Further features and advantages of the present disclosure will become apparent from the description of embodiments given below.</p><heading id="h0002"><b>BRIEF DESCRIPTION OF THE DRAWINGS</b></heading><p id="p0011" num="0011"><ul><li><figref idrefs="f0001">Fig. 1</figref> is a schematic front sectional view of a multifunction product.</li><li><figref idrefs="f0002">Fig. 2</figref> is a diagram showing a hardware configuration of a multifunction product.</li><li><figref idrefs="f0003">Fig. 3</figref> is a diagram showing a flow of a power supply system of a multifunction product.</li><li><figref idrefs="f0004">Fig. 4</figref> is a diagram showing a flow of processing of the outputs of pyroelectric sensors.</li><li><figref idrefs="f0005">Fig. 5</figref> is a diagram showing the detection areas of first and second detection portions.</li><li><figref idrefs="f0006">Fig. 6</figref> is a timing chart showing the waveforms of first and second signals according to movement direction in a multifunction product according to a first embodiment.</li><li><figref idrefs="f0007">Fig. 7</figref> is a diagram showing discrimination data in a multifunction product according to the first embodiment.</li><li><figref idrefs="f0008">Fig. 8</figref> is a flow chart showing a flow of control for switching power saving mode according to human movement direction in a multifunction product.</li><li><figref idrefs="f0009">Fig. 9</figref> is a timing chart showing the waveforms of first and second signals according to movement direction in a multifunction product according to a second embodiment.</li><li><figref idrefs="f0010">Fig. 10</figref> is a diagram showing discrimination data in a multifunction product according to the second embodiment.</li><li><figref idrefs="f0011">Fig. 11</figref> is a timing chart showing the waveforms of relevant signals according to movement<!-- EPO <DP n="4"> --> direction in a multifunction product according to a third embodiment.</li><li><figref idrefs="f0012">Fig. 12</figref> is a diagram showing discrimination data in a multifunction product according to the third embodiment.</li></ul></p><heading id="h0003"><b>DETAILED DESCRIPTION</b></heading><p id="p0012" num="0012">Hereinafter, embodiments of the present disclosure will be described with reference to <figref idrefs="f0001 f0002 f0003 f0004 f0005 f0006 f0007 f0008 f0009 f0010 f0011 f0012">Figs. 1 to 12</figref>. First, with reference to <figref idrefs="f0001 f0002 f0003 f0004 f0005 f0006 f0007 f0008">Figs. 1 to 8</figref>, a first embodiment will be described; then with reference to <figref idrefs="f0009">Figs. 9</figref> and <figref idrefs="f0010">10</figref>, a second embodiment will be described; and then with reference to <figref idrefs="f0011">Figs. 11</figref> and <figref idrefs="f0012">12</figref>, a third embodiment will be described. The following description of those embodiments deals with a multifunction product 100 (also known as a multifunction peripheral or a multifunction printer, corresponding to an image forming apparatus) as an example. It should be understood, however, that the specific features in terms of structure, arrangement, and other aspects that are mentioned in the description of the embodiments are not meant to limit the scope of the disclosure but are merely examples for description purposes.</p><heading id="h0004"><b>(Outline of the Construction of a Multifunction Product 100)</b></heading><p id="p0013" num="0013">First, with reference to <figref idrefs="f0001">Fig. 1</figref>, an outline of a multifunction product 100 according to an embodiment will be described. <figref idrefs="f0001">Fig. 1</figref> is a schematic front sectional view of the multifunction product 100.</p><p id="p0014" num="0014">The multifunction product 100 is provided with, in a topmost part thereof, a reading section 101 (image reading device) which includes a document transport section 1a and an image reading section 1b. The document transport section 1a transports one sheet after another of a document stacked on a document placement tray 11 to a reading position (a position over a contact glass 14a for feed-reading) in the image reading section 1b. The document placement tray 11 is provided with a document placement detection sensor 12 for detecting placement of a document. The document placement detection sensor 12 is an optical sensor, and its output varies between when a document is placed and when no document is placed.</p><p id="p0015" num="0015">About a pivot (not shown) provided at the sheets' leading side, the document transport section 1a can be lifted up to be opened. As indicated by a broken line in <figref idrefs="f0001">Fig. 1</figref>, an open/close detection sensor 13 is provided for detecting whether the document transport section 1a is open or closed. For example, the open/close detection sensor 13 may be an interlock-type<!-- EPO <DP n="5"> --> switch that makes contact with the bottom face of the document transport section 1a, or may be a reflection-type optical sensor. The output of the open/close detection sensor 13 varies according to whether the document transport section 1a is in an open or closed state.</p><p id="p0016" num="0016">During a job such as copying, scanning, or image data transmission, the image reading section 1b reads a document and generates image data. On the top face of the image reading section 1b, contact glass 14 (comprising two types 14a and 14b) is provided. Inside, there are provided optical system members such as a movable frame (on which an exposure lamp, a mirror, etc. are mounted) that moves in a horizontal direction (for example, in the left/right direction in <figref idrefs="f0001">Fig. 1</figref>), a lens, and an image sensor (for example, a CCD image sensor). In a case where a document that is transported sequentially, one sheet after another, by the document transport section 1a is read, the movable frame is fixed under the feed-reading contact glass 14a, while the light reflected from the document is directed through the lens to the image sensor. On the other hand, when a document placed on the stationary-reading contact glass 14b is read, the movable frame is moved in a horizontal direction.</p><p id="p0017" num="0017">By using those optical system members, the image reading section 1b irradiates the document with light; the image reading section 1b then performs A/D conversion on the output values from the pixels of the image sensor that has received the light reflected from the document, and thereby generates image data. Based on the read image data, the multifunction product 100 can perform printing and transmission (printing and transmission functions).</p><p id="p0018" num="0018">As indicated by a broken line in <figref idrefs="f0001">Fig. 1</figref>, in an upper front part, an operation panel 2 is provided which accepts entry of settings and instructions for copying and the like and which displays various kinds of information. In a front-edge part of the operation panel 2, there are provided a first detection portion 71 and a second detection portion 72 (described in detail later) which each include a pyroelectric sensor.</p><p id="p0019" num="0019">Inside the main unit of the multifunction product 100, a printing engine section 102 is provided which includes a sheet feeding section 3a, a transport section 3b, an image formation section 4a, and a fusing section 4b. The printing engine section 102 performs printing on sheets of paper according to the image data.</p><p id="p0020" num="0020">In the sheet feeding section 3a, a total of three cassettes 31 (31a, 31b, and 31c) for housing and feeding sheets are stacked one over another in a vertical direction. The cassettes 31 (31a to 31c) are each provided with a sheet feed roller 32. The sheet feed roller 32 is driven to<!-- EPO <DP n="6"> --> rotate to feed the housed sheets. Each cassette 31 can be unloaded and loaded for sheet replenishment. To detect whether or not the cassettes 31 are loaded or unloaded, load/unload detection sensors 3 are provided one for each of them. The load/unload detection sensors 33 may be interlock-type switches that make contact with one face of each cassette 31, or may be reflection-type optical sensors, and their outputs vary according to whether the corresponding cassettes are loaded or unloaded.</p><p id="p0021" num="0021">The transport section 3b is a passage through which sheets are transported within the apparatus. In the transport section 3b, there are provided, among others, a plurality of pairs of transport rollers 34 (in <figref idrefs="f0001">Fig. 1</figref>, a total of seven pairs 34a to 34g from the upstream side) which are driven to rotate for sheet transport, and a pair of registration rollers 35 which keeps a transported sheet at stand-by short of the image formation section 4a to feed it in synchronism with the timing of transfer of a toner image.</p><p id="p0022" num="0022">For removal of jammed sheets and for maintenance in general, the multifunction product 100 has a front cover (not shown) that can be opened and closed. To detect whether the front cover is open or closed, a cover open/close sensor 36 is provided. The cover open/close sensor 36 may be an interlock-type switch that makes contact with part of the front cover, or may be an optical sensor, and its output varies according to whether the front cover is open or closed.</p><p id="p0023" num="0023">The image formation section 4a forms an image (toner image) based on image data, and transfers the toner image onto a sheet transported from the sheet feeding section 3a. Used as the image data is the image data of a document acquired by the image reading section 1b, or image data received from a computer 200 (see <figref idrefs="f0002">Fig. 2</figref>) or a facsimile (FAX) machine 300. The image formation section 4a is provided with a photosensitive drum 41 and, arranged around it, a charging device 42, an exposure device 43, a developing device 44, a transfer roller 45, a cleaning device 46, etc.</p><p id="p0024" num="0024">During toner image formation, the photosensitive drum 41 is driven to rotate. The charging device 42 charges the photosensitive drum 41 to a predetermined potential. The exposure device 43 outputs laser light L based on the image data, and scans, with the light L, the surface of the photosensitive drum 41 to form an electrostatic latent image. The developing device 44 then develops the electrostatic latent image with toner. To the transfer roller 45, a predetermined voltage is applied. Thus, the toner image on the photosensitive drum 41 is<!-- EPO <DP n="7"> --> transferred onto the sheet that passes through the nip between the transfer roller 45 and the photosensitive drum 41. The cleaning device 46 removes the toner and the like that remain on the photosensitive drum 41 after transfer.</p><p id="p0025" num="0025">The fusing section 4b fuses the toner image transferred onto the sheet. The fusing section 4b includes a heating roller 47, incorporating a heating body, and a pressing roller 48. After toner fusion, the sheet is ejected onto the ejection tray 37.</p><heading id="h0005"><b>(Hardware Configuration of the Multifunction product 100)</b></heading><p id="p0026" num="0026">Next, with reference to <figref idrefs="f0002">Fig. 2</figref>, the hardware configuration of the multifunction product 100 according to an embodiment will be described. <figref idrefs="f0002">Fig. 2</figref> is a diagram showing the hardware configuration of the multifunction product 100.</p><p id="p0027" num="0027">The multifunction product 100 has a main control section 5 (corresponding to a recognition portion) which is composed of a combination of various devices, circuits, and the like. The main control section 5 is communicatably connected to the reading section 101, the operation panel 2, the printing engine section 102, a power supply section 6, etc., and communicates with them to control their operation.</p><p id="p0028" num="0028">The main control section 5 includes a CPU 51, a storage portion 52, an image processing portion 53, a clock portion 54, a communication portion 55, etc. The CPU 51 is the arithmetic processing unit of the main control section 5. The CPU 51 performs processing and control based on data and programs stored in the storage portion 52. The storage portion 52 includes a non-volatile storage device (flash ROM) and a volatile storage device (for example, RAM). The storage portion 52 stores data and programs needed in various kinds of control that accompany execution of jobs. The main control section 5 is connectable to a HDD 56 as a large-capacity storage device. The HDD 56 stores data and programs needed in various kinds of control, image data, and the like.</p><p id="p0029" num="0029">The image processing portion 53 applies image processing to the image data generated by the image reading section 1b or image data fed in from outside. The image processing portion 53 includes an ASIC dedicated to image processing and a memory for image processing. The image data having undergone the image processing is fed to the exposure device 43 for printing (copier function, printer function), or stored in the HDD 56 (scanner function), or transmitted from the communication portion 55 (scanner function, facsimile transmission function). The CPU 51 and the storage portion 52 may be used to implement the functions of<!-- EPO <DP n="8"> --> the image processing portion 53.</p><p id="p0030" num="0030">The clock portion 54 counts time. The communication portion 55 is an interface for conducting communication with an external computer 200 (a personal computer or a server) or a facsimile machine 300 across a network, a communication line, a cable, or the like. Accordingly, the communication portion 55 includes appropriate connectors and circuits, devices, controllers, etc. for communication. By communication through the communication portion 55, the multifunction product 100 can perform printing based on printing data received from outside (printer function), and can transmit image data to the external computer 200 or the facsimile machine 300 (transmission function).</p><p id="p0031" num="0031">For document reading, the main control section 5 is communicatably connected to the reading section 101 (the image reading section 1b and the document transport section 1a). During a job such as copying or image data transmission, the image reading section 1b and document transport section 1a are instructed by the main control section 5 to execute a document reading job.</p><p id="p0032" num="0032">The main control section 5 is communicatably connected also to the operation panel 2, which accepts entry of settings into, and displays indications from, the multifunction product 100. The operation panel 2 transmits to the main control section 5 the fact that a key is pressed and which key it is. Thereby the main control section 5 recognizes which key is pressed out of the hardware keys on the operation panel 2 and the keys displayed on a liquid crystal display portion.</p><p id="p0033" num="0033">As described previously, the multifunction product 100 is provided with the printing engine section 102 as the section that executes printing jobs. Within the printing engine section 102, there is provided an engine control portion 102a which is instructed by the main control section 5 to actually control the operation of the printing engine section 102. The engine control portion 102a includes a CPU, a memory for storing programs and data for controlling printing and other functions. The engine control portion 102a controls the members (for example, motors, circuits, heaters, etc.) included in the printing engine section 102 to achieve sheet feeding, transport, toner image formation, temperature control in the fusing section 4b, and other functions</p><p id="p0034" num="0034">As the section related to the management of electric power within the multifunction product 100, the power supply section 6 is provided. The power supply section 6 controls the supply<!-- EPO <DP n="9"> --> of electric power to the individual portions within the multifunction product 100. The power supply section 6 includes a power supply device 61, a power control portion 62 (for example, a CPU or a microprocessor) which controls the supply of electric power by controlling the power supply device 61 and a switch portion 64, a memory 63 which stores data and programs for the power supply section 6, the switch portion 64, an I/F portion 65, etc.</p><p id="p0035" num="0035">The power supply device 61 has a rectification circuit, a voltage step-up circuit, a voltage step-down circuit, etc., and is connected to a commercial electric power source. The power supply device 61 generates a plurality of voltages needed for the operation of the multifunction product 100. The switch portion 64 turns on and off the supply of electric power to the individual portions, such as the reading section 101 and the printing engine section 102, of the multifunction product 100. In other words, the power supply section 6 (power control portion 62), by using the switch portion 64, connects and disconnects the electric power supply line from the power supply device 61 to the reading section 101, the 102, etc. to turn on and off the supply of electric power to the individual portions. The I/F portion 65 is an interface for communication with the main control section 5 etc.</p><heading id="h0006">(Invoking and Canceling Power Saving Mode)</heading><p id="p0036" num="0036">Next, with reference to <figref idrefs="f0003">Fig. 3</figref>, invocation and cancellation of power saving mode in a multifunction product 100 according to an embodiment will be described. <figref idrefs="f0003">Fig. 3</figref> is a diagram showing the power supply system of the multifunction product 100.</p><p id="p0037" num="0037">The power supply device 61 in the power supply section 6 generates a plurality of voltages. Moreover, as shown in <figref idrefs="f0003">Fig. 3</figref>, the power supply section 6 includes the switch portion 64. The switch portion 64 includes a plurality of semiconductor switches, such as FETs or bipolar transistors, or mechanical switches, or the like. As the switch portion 64 is turned on and off, the supply of electric power to the reading section 101, the operation panel 2, the printing engine section 102, etc. is switched between on and off. In <figref idrefs="f0003">Fig. 3</figref>, the lines the supply of electric power across which can be turned on and off by the switch portion 64 are indicated by solid lines.</p><p id="p0038" num="0038">After, as a result of the main power supply being turned on, or power saving mode being canceled, normal mode goes into effect, whenever the conditions for invocation of power saving mode are fulfilled, the main control section 5 instructs the power supply section 6 to invoke power saving mode. The main control section 5 recognizes a human approaching the<!-- EPO <DP n="10"> --> multifunction product 100, passing by it, or otherwise moving with respect to it according to a first signal S1 based on the output of a pyroelectric sensor 71a (see <figref idrefs="f0004">Fig. 4</figref>) and a second signal S2 based on the output of a pyroelectric sensor 72a and, based on the result of the recognition, checks whether or not the conditions for invocation of power saving mode are fulfilled.</p><p id="p0039" num="0039">The main control section 5 uses the first and second detection portions 71 and 72 which include the pyroelectric sensors in such a way that, when a human is recognized to be moving in a direction away (receding) from the image forming apparatus, the main control section 5 recognizes that the conditions for invocation of power saving mode are fulfilled (details will be given later).</p><p id="p0040" num="0040">When a user intends to do a job such as copying or scanning, he needs to make the multifunction product 100 read a document, and accordingly the user, with the document in his hand, moves toward the multifunction product 100. In this case, on completion of the job, the user moves away from the multifunction product 100.</p><p id="p0041" num="0041">However, there are also cases, as when printing is performed based on job execution data including image data received from the external computer 200 or the facsimile machine 300, where the multifunction product 100 executes a job without a human moving toward it. In such cases, the main control section 5 recognizes that the conditions for invocation of power saving mode are fulfilled when a predetermined transition period elapses with no human moving toward the multifunction product 100 after completion of execution of a job. The main control section 5 may also shift the multifunction product 100 into power saving mode when a power saving mode invoking key provided on the operation panel 2 is pressed.</p><p id="p0042" num="0042">On recognizing that the conditions for invocation of power saving mode are fulfilled, the main control section 5 instructs the power supply section 6 to invoke power saving mode. When so instructed, the power supply section 6 shifts the multifunction product 100 into power saving mode. To reduce electric power consumption, the power supply section 6 stops the supply of electric power to predetermined portions (power-supply-suspended portions) such as the operation panel 2, the printing engine section 102, the reading section 101, etc., thereby shifting the multifunction product 100 into power saving mode. In power saving mode, the multifunction product 100 is in a state unable to execute part of its jobs, such as copying, scanning, and transmission.</p><p id="p0043" num="0043">As indicated by broken lines in <figref idrefs="f0003">Fig. 3</figref>, to enable, even in power saving mode, recognition of<!-- EPO <DP n="11"> --> whether a human is moving toward the multifunction product 100 or simply passing by in front of the multifunction product 100, electric power continues being supplied to the first detection portion 71, to a first signal generation portion 81, which processes the output of the first detection portion 71, to the second detection portion 72, to a second signal generation portion 82, which processes the output of the second detection portion 72, and to the main control section 5, which recognizes human movement direction based on the output signal (first signal S1) of the first signal generation portion 81 and the output signal (second signal S2) of the second signal generation portion 82. Also, to enable, even in power saving mode, reception of printing data from an external device such as the external computer 200, electric power continues being supplied to the communication portion 55 as well.</p><p id="p0044" num="0044">In power saving mode, to save power, the supply of electric power to part of the blocks in the main control section 5 is stopped; however, electric power continues being supplied to those portions of the main control section 5 which check whether or not the conditions for cancellation of power saving mode (restoration of normal mode) are fulfilled.</p><p id="p0045" num="0045">In power saving mode, on recognizing a human moving toward the multifunction product 100 based on the first and second signals S1 and S2, the main control section 5 determines that power saving mode should be canceled.</p><p id="p0046" num="0046">When power saving mode is canceled and normal mode is restored, the supply of electric power is restarted to those portions to which the supply of electric power has been stopped, namely the main control section 5, the reading section 101, the operation panel 2, the printing engine section 102, etc. These portions, to which the supply of electric power is now restarted, start a warming-up procedure to make the multifunction product 100 ready to execute jobs. Conventionally, there are provided a plurality of portions that detect operation done on the multifunction product 100 (such as the operation panel 2, a touch panel portion 22 provided on the operation panel 2, a loading/unloading detection sensor 33, the cover open/close sensor 36, the document placement detection sensor 12, the open/close detection sensor 13, etc., which will hereinafter be referred to as "operation detection portions" for convenience' sake). Conventionally, whenever any of such operation detection portions detects operation done on an image forming apparatus, power saving mode is canceled.</p><p id="p0047" num="0047">Accordingly, even in power saving mode, electric power continues being supplied to the operation detection portions to keep them enabled. By contrast, according to the embodiment,<!-- EPO <DP n="12"> --> it is when a human moves toward the multifunction product 100 that power saving mode is canceled; that is, in the multifunction product 100 according to the embodiment, no electric power is supplied to the operation detection portions. This helps reduce electric power consumption in the power saving mode as compared with the conventional norm.</p><heading id="h0007"><b>(Detection Portions and Signal Generation Portions)</b></heading><p id="p0048" num="0048">Next, with reference to <figref idrefs="f0004">Figs. 4</figref> and <figref idrefs="f0005">5</figref>, detection portions and signal generation portions according to an embodiment will be described. <figref idrefs="f0004">Fig. 4</figref> is a diagram showing the flow of processing of the outputs of the pyroelectric sensors. <figref idrefs="f0005">Fig. 5</figref> is a diagram showing the detection areas of the first and second detection portions 71 and 72.</p><p id="p0049" num="0049">As shown in <figref idrefs="f0004">Fig. 4</figref>, the image forming apparatus according to the embodiment is provided with a first detection portion 71 and a second detection portion 72. The first detection portion 71 includes a pyroelectric sensor 71a, and the second detection portion 72 includes the a pyroelectric sensor 72a. The pyroelectric sensors 71a and 72a are sensors that exploit the pyroelectric effect, whereby electric charge is produced by dielectric polarization on the surface of a dielectric when it is heated. The pyroelectric sensors 71a and 72a are pyroelectric-type infrared sensor of which the output voltages vary according to the amount of infrared radiation that they receive from the human body. In the embodiment, the pyroelectric sensors 71a and 72a are not of the type that emits infrared radiation, and therefore their electric power consumption is extremely low.</p><p id="p0050" num="0050">In the embodiment, the pyroelectric sensors 71a and 72a are provided on the operation panel 2. So that the pyroelectric sensors 71a and 72a can efficiently receive infrared radiation emanating from the user, they are provided in a front edge part of the operation panel 2 (see <figref idrefs="f0001">Fig. 1</figref>).</p><p id="p0051" num="0051">The first detection portion 71 includes a first lens 71L. The first lens 71L is a lens for setting the detection area of the pyroelectric sensor 71a. The second detection portion 72 includes a second lens 72L. The second lens 72L is a lens for setting the detection area of the pyroelectric sensor 72a. Used as the first and second lenses 71L and 72L are Fresnel lenses. Now, with reference to <figref idrefs="f0005">Fig. 5</figref>, the detection areas of the first detection portion 71 (pyroelectric sensor 71a) and the second detection portion 72 (pyroelectric sensor 72a) will be described. As shown in <figref idrefs="f0005">Fig. 5</figref>, the detection area of the pyroelectric sensor 72a is set to be an area in which the upper half of the human body is detected. For example, the detection area of<!-- EPO <DP n="13"> --> the pyroelectric sensor 71a is set by the first lens 71L to be a range of one meter or higher (to about several meters) relative to the floor surface.</p><p id="p0052" num="0052">On the other hand, as shown in <figref idrefs="f0005">Fig. 5</figref>, the detection area of the pyroelectric sensor 72a is set to be an area in which the lower half of the human body is detected. The detection area of the pyroelectric sensor 72a is set by the second lens 72L to be a range of several tens of centimeters or lower relative to the floor surface.</p><p id="p0053" num="0053">The output of the pyroelectric sensor 71a is fed to the first signal generation portion 81. The first signal generation portion 81 includes an amplifier 81a that amplifiers the output voltage of the pyroelectric sensor 71a. After being amplified by the amplifier 81a, the output of the pyroelectric sensor 71a is fed to a digitizing circuit 81b.</p><p id="p0054" num="0054">The digitizing circuit 81b generates a signal whose level varies according to whether the output value of the pyroelectric sensor 71a after amplification is greater than a predetermined threshold value or not. The digitizing circuit 81b includes a threshold voltage generation circuit 81c which generates a threshold voltage and a comparator 81d which compares the output value of the pyroelectric sensor 71a after amplification with the threshold value. In the embodiment, the digitizing circuit 81b outputs a high level while the output of the pyroelectric sensor 71a after amplification is greater than the threshold value, and outputs a low level while it is equal to or smaller than the threshold value. The logic levels of the high and low levels may be the other way around.</p><p id="p0055" num="0055">On the other hand, the output of the pyroelectric sensor 72a of the second detection portion 72 is fed to the second signal generation portion 82. The second signal generation portion 82 includes an amplifier 82a that amplifiers the output voltage of the pyroelectric sensor 72a. After being amplified by the amplifier 82a, the output of the pyroelectric sensor 72a is fed to a digitizing circuit 82b.</p><p id="p0056" num="0056">The digitizing circuit 82b generates a signal whose level varies according to whether the output value of the pyroelectric sensor 72a after amplification is greater than a predetermined threshold value or not. The digitizing circuit 82b includes a threshold voltage generation circuit 82c which generates a threshold voltage and a comparator 82d which compares the output value of the pyroelectric sensor 72a after amplification with the threshold value. The digitizing circuit 82b outputs a high level while the output of the pyroelectric sensor 72a after amplification is greater than the threshold value, and outputs a low level while it is equal to or<!-- EPO <DP n="14"> --> smaller than the threshold value. The logic levels of the high and low levels may be the other way around.</p><p id="p0057" num="0057">As shown in <figref idrefs="f0004">Fig. 4</figref>, the first and second signal generation portions 81 and 82 may be provided outside the operation panel 2. The first and second signal generation portions 81 and 82 may instead be provided within the operation panel 2, or on a circuit board within the main control section 5; there is no particular restriction on where it is to be provided.</p><p id="p0058" num="0058">The first signal S1 generated by and fed out from the first signal generation portion 81 and the second signal S2 generated by and fed out from the second signal generation portion 82 are fed to the main control section 5. By using the first and second signals S1 and S2, the main control section 5 recognizes the direction of the user's movement.</p><heading id="h0008"><b>(Movement Direction Recognition Based on the Waveforms of the First and Second Signals S1 and S2)</b></heading><p id="p0059" num="0059">Now, with reference to <figref idrefs="f0006">Figs. 6</figref> and <figref idrefs="f0007">7</figref>, a description will be given of movement direction recognition based on the waveforms of the first and second signals S1 and S2 according to a first embodiment. <figref idrefs="f0006">Fig. 6</figref> is a timing chart showing the waveforms of the first and second signals S1 and S2 reflecting movement direction as observed in the multifunction product 100 according to the first embodiment. <figref idrefs="f0007">Fig. 7</figref> is a diagram showing discrimination data D in the multifunction product 100 according to the first embodiment. Described below will be an example where the same lenses (lenses with equivalent characteristics) are used as the first and second lenses 71L and 72L of the first and second detection portions 71 and 72. First, with reference to the relevant part of the timing chart shown in <figref idrefs="f0006">Fig. 6</figref>, the characteristics observed in the waveforms of the first and second signals S1 and S2 when a human is moving toward the multifunction product 100 (an approaching event) will be described.</p><p id="p0060" num="0060">In an approaching event, a human moving toward the multifunction product 100 is equivalent to a heat source (infrared radiation generation source) moving toward the sensors. Accordingly, the intensity and amount of infrared radiation incident on the pyroelectric sensor 71a for detecting the upper half of the human body gradually increase in relative terms. Reflecting this situation, based on the output of the pyroelectric sensor 71a for the upper half of the human body, the first signal generation portion 81 outputs the first signal S1 such that its high-level period becomes gradually long. In other words, in an approaching event, the pyroelectric sensor 71a, the first lens 71L, and the first signal generation portion 81 are so set<!-- EPO <DP n="15"> --> that the duty factor of the second signal S2 gradually increases.</p><p id="p0061" num="0061">On the other hand, as the amount of infrared radiation received varies, the output of the pyroelectric sensor varies. In an approaching event, two feet advance alternately toward the pyroelectric sensor 72a for the lower half of the human body. Reflecting this situation, based on the output of the pyroelectric sensor 72a for the lower half of the human body, the second signal generation portion 82 outputs the second signal S2 such that it has a higher frequency and a shorter cycle than the first signal S1. In other words, in an approaching event, the pyroelectric sensor 72a, the second lens 72L, and the second signal generation portion 82 are so set that the second signal S2 has a higher frequency than the first signal S1.</p><p id="p0062" num="0062">By contrast, in a receding event, a human moving away from the multifunction product 100 is equivalent to a heat source (infrared radiation generation source) moving away. Accordingly, the intensity and amount of infrared radiation incident on the pyroelectric sensor 71a for detecting the upper half of the human body gradually decrease in relative terms. Reflecting this situation, based on the output of the pyroelectric sensor 71a for the upper half of the human body, the first signal generation portion 81 outputs the first signal S1 such that its high-level period becomes gradually short. In other words, in a receding event, the pyroelectric sensor 71a, the first lens 71L, and the first signal generation portion 81 are so set that the duty factor of the first signal S1 gradually decreases.</p><p id="p0063" num="0063">On the other hand, as the amount of infrared radiation received varies, the output of the pyroelectric sensor varies. In a receding event, the distances from the pyroelectric sensor 72a for the lower half of the human body to two feet gradually increase alternately. Reflecting this situation, based on the output of the pyroelectric sensor 72a for the lower half of the human body, the second signal generation portion 82 outputs the second signal S2 such that it has a higher frequency and a shorter cycle than the first signal S1. In other words, in a receding event, the pyroelectric sensor 72a, the second lens 72L, and the second signal generation portion 82 are so set that the second signal S2 has a higher frequency than the first signal S1. When a user passes by in front of the multifunction product 100 (crossing the detection areas of the pyroelectric sensors) (a crossing event), the pyroelectric sensor 71a for detecting the upper half of the human body detects the swing of arms (hands). In other words, with respect to the pyroelectric sensor 71a, the arm swings at short intervals. The swing of the arm causes the infrared radiation incident on the pyroelectric sensor 71a to vary at short intervals.<!-- EPO <DP n="16"> --> Reflecting the situation, in a crossing event, based on the output of the pyroelectric sensor 71a for the upper half of the human body, the first signal generation portion 81 generates the first signal S1 such that it has a higher frequency and a shorter cycle than the second signal S2. In other words, in a crossing event, the pyroelectric sensor 71a, the first lens 71L, and the first signal generation portion 81 are so set that the first signal S1 has a higher frequency than the second signal S2.</p><p id="p0064" num="0064">On the other hand, as a human crosses the detection areas, the angle from which the infrared radiation from the human body is incident on the pyroelectric sensor 72a varies from slant to head-on to slant, and when the angle is head-on relative to the pyroelectric sensor 72a for the lower half of the human body, the infrared radiation is most efficiently incident on the pyroelectric sensor 72a. Thus, based on the output of the pyroelectric sensor 72a for the lower half of the human body, the second signal generation portion 82 generates the second signal S2 such that the high-level period becomes first gradually long and then, after the peak is reached (when the human body is right in front of the pyroelectric sensor), increasingly short. In other words, in a crossing event, the second detection portion 72, the second lens 72L, and the second signal generation portion 82 are so set that the duty factor of the second signal S2 first increases and then decreases.</p><p id="p0065" num="0065">As described above, human movement with respect to the multifunction product 100 can produce, in the variation patterns of the first and second signals S1 and S2 and in the relationships between them in terms of frequency and cycle, characteristics so distinctive as to allow discrimination of whether a human is approaching, receding, or crossing.</p><p id="p0066" num="0066">Accordingly, as shown in <figref idrefs="f0007">Fig. 7</figref>, as discrimination data D for recognizing and discriminating human movement direction (approaching, recessing, or crossing), it is possible to define variation patterns of the first and second signals S1 and S2 and relationships between them in terms of frequency and cycle. The discrimination data D is preferably stored in the storage portion 52.</p><p id="p0067" num="0067">As shown in <figref idrefs="f0007">Fig. 7</figref>, as a condition for recognizing a human approaching the multifunction product 100, based on the above-described characteristics of the relevant signals in an approaching event, it is possible to define, in the discrimination data D, conditions that the frequency f1 of the first signal S1 is lower than the frequency f2 of the second signal S2 (the cycle T1 of the first signal S1 is longer than the cycle T2 of the second signal S2) and that<!-- EPO <DP n="17"> --> the high-level period Th1 of the first signal S1 is becoming gradually long (the duty factor of the first signal S1 is increasing).</p><p id="p0068" num="0068">Moreover, as shown in <figref idrefs="f0007">Fig. 7</figref>, as a condition for recognizing a human receding from the multifunction product 100, based on the above-described characteristics of the relevant signals in a receding event, it is possible to define, in the discrimination data D, conditions that the frequency f1 of the first signal S1 is lower than the frequency f2 of the second signal S2 (the cycle T1 of the first signal S1 is longer than the cycle T2 of the second signal S2) and that the high-level period Th1 of the first signal S1 is becoming gradually short (the duty factor of the first signal S1 is decreasing).</p><p id="p0069" num="0069">Moreover, as shown in <figref idrefs="f0007">Fig. 7</figref>, as a condition for recognizing a human passing by in front of the multifunction product 100 (crossing the detection areas of the pyroelectric sensors), based on the above-described characteristics of the relevant signals in a crossing event, it is possible to define, in the discrimination data D, a condition that the frequency f1 of the first signal S1 is higher than the frequency f2 of the second signal S2 (the cycle T1 of the first signal S1 is shorter than the cycle T2 of the second signal S2) and that the high-level period Th2 of the second signal S2 becomes first increasingly long and then increasingly short (the duty factor of the second signal S2 first increases and then decreases).</p><p id="p0070" num="0070">Based on the discrimination data D described above, to recognize human movement direction, as shown in <figref idrefs="f0006">Fig. 6</figref>, the main control section 5 (the CPU 51 and the clock portion 54) measures the cycle T1 and the high-level period Th1 of the first signal S1. Based on the measured cycle T1, the main control section 5 can calculate the frequency f1 of the first signal S1. By dividing the high-level period Th1 of the first signal S1 by its cycle T1, the main control section 5 can calculate the duty factor of the first signal S1.</p><p id="p0071" num="0071">Likewise, the main control section 5 (the CPU 51 and the clock portion 54) measures the cycle T2 and the high-level period Th2 of the second signal S2. Based on the measured cycle T2, the main control section 5 can calculate the frequency f2 of the second signal S2. By dividing the high-level period Th2 of second signal S2 by its cycle T2, the main control section 5 can calculate the duty factor of the second signal S2.</p><p id="p0072" num="0072">Then, based on the cycle T1, the frequency f1, and the high-level period Th1 of the first signal S1, the cycle T2, the frequency f2, and the high-level period Th2 of the second signal S2, and the discrimination data D, the main control section 5 recognizes human movement direction.<!-- EPO <DP n="18"> --></p><heading id="h0009"><b>(Switching of Power Saving Mode According to Human Movement Direction)</b></heading><p id="p0073" num="0073">Next, with reference to <figref idrefs="f0008">Fig. 8</figref>, a description will be given of the flow of control for the switching of power saving mode according to human movement direction in the multifunction product 100. <figref idrefs="f0008">Fig. 8</figref> is a flow chart showing the flow of control for the switching of power saving mode according to human movement direction in the multifunction product 100.</p><p id="p0074" num="0074">The flow of <figref idrefs="f0008">Fig. 8</figref> starts when the main power supply to the multifunction product 100 is turned on. A switch for turning on the main power supply is provided on the operation panel 2, or on a side face of the multifunction product 100. The user can, by operating the switch to an on position, turn on the power to the multifunction product 100 and, by operating the switch to an off position, turn off the power to the multifunction product 100.</p><p id="p0075" num="0075">When the main power supply is turned on, the power supply section 6 starts the supply of electric power within the multifunction product 100, to the main control section 5, the reading section 101, the printing engine section 102, the operation panel 2, etc. (step #1). Now, electric power is supplied to all the portions within the multifunction product 100, and a warming-up procedure is performed to make the multifunction product 100 ready to operate (step #2). Through the warming-up procedure, the main control section 5, the reading section 101, and the operation panel 2 are started up, and in the printing engine section 102, toner is stirred, the fusing section 4b is heated, and other preparations are made. When the main power supply is turned on, through the warming-up procedure, the multifunction product 100 is started up in normal mode, in which all of its functions are readily available. The control section 1 lets the power supply section 6 continue the supply of electric power to the portions to which the supply of electric power can be suspended, and thereby keeps the multifunction product 100 in normal mode (step #3).</p><p id="p0076" num="0076">Subsequently, based on the first and second signals S1 and S2 and the discrimination data D, the main control section 5 checks whether or not a user is moving away (receding) from the multifunction product 100 (step #4). Specifically, the main control section 5 measures the cycles of the first and second signals S1 and S2 and the periods for which they are high, and checks whether or not the measured results meet the conditions defined in the discrimination data D for recognizing a human moving away.</p><p id="p0077" num="0077">When it is not recognized that a human is moving away (step #4, "No"), the main control<!-- EPO <DP n="19"> --> section 5 checks whether or not to invoke power saving mode (step #5). Scanning, copying, and other jobs involve a human approaching and receding from the multifunction product 100; by contrast, jobs such as a printer job and a job of transmitting image data stored in the storage portion 52 can trigger cancellation of power saving mode with no human approaching the multifunction product 100. After completion of the warming-up procedure, or after completion of execution of a job, the main control section 5 checks whether or not a predetermined transition period elapses with no human approaching the multifunction product 100 and no input of job execution data reaching the communication portion 55. When power saving mode should not be invoked (step #5, "No"), the flow returns to step #3.</p><p id="p0078" num="0078">By contrast, when a human is moving away from the multifunction product 100 (step #4, "Yes"), or when power saving mode should be invoked (step #5, "Yes"), the main control section 5 instructs the power supply section 6 to invoke power saving mode (step #6). When so instructed, the power supply section 6 stops the supply of electric power to the predetermined portions to which the supply of electric power should now be stopped, while continuing the supply of electric power to part of the first and second signal generation portions 81 and 82 (step #7) etc.</p><p id="p0079" num="0079">Then, based on the first and second signals S1 and S2 and the discrimination data D, the main control section 5 checks whether or not a human is approaching (moving toward) the multifunction product 100 (step #8). Specifically, the main control section 5 measures the cycles of the first and second signals S1 and S2 and the periods for which they are high, and checks whether or not the measured results meet the conditions defined in the discrimination data D for recognizing a human approaching.</p><p id="p0080" num="0080">When it is not recognized that a human is approaching the multifunction product 100 (step #8, "No"), the main control section 5 checks whether or not to cancel power saving mode (step #9). For example, the main control section 5 checks whether or not job execution data (data containing data commanding execution of a job and image data related to the job to be executed) has been received via the communication portion 55 from the external computer 200, the facsimile machine 300, or the like. When power saving mode should be maintained (step #9, "No"), the flow returns to step #7.</p><p id="p0081" num="0081">On the other hand, when it is recognized that a human is moving toward the multifunction product 100 (step #8, "Yes"), or when power saving mode should be canceled (step #9,<!-- EPO <DP n="20"> --> "Yes"), the main control section 5 lets the main control section 5 restart the supply of electric power to the portions to which the supply of electric power has been stopped in power saving mode, and thereby cancels power saving mode (step #10). As a result, in the multifunction product 100, the warming-up procedure is started in the portions to which the supply of electric power is restarted, namely the printing engine section 102, etc. (step #11). The flow then returns to <figref idrefs="f0003">Fig. 3</figref>. In this way, the main control section 5 recognizes, with a clear distinction, whether a human is moving toward the multifunction product 100 or is crossing the detection areas. Thus, a human simply entering the detection areas of the pyroelectric sensors as by crossing them does not trigger the main control section 5 to instruct the power supply section 6 to cancel power saving mode.</p><p id="p0082" num="0082">The upper and lower halves of the human body move in different manners. Also, between when a human is moving toward the image forming apparatus (multifunction product 100) and when a human is crossing the detection areas, the human body has different angles with respect to the pyroelectric sensors. For these reasons, in the waveforms of the first and second signals S1 and S2, such characteristics (conditions) can appear as allow discrimination of movement direction. Accordingly, the image forming apparatus (multifunction product 100) according to the first embodiment includes: a first detection portion 71 including a pyroelectric sensor 71a, for detecting the upper half of the human body; a first signal generation portion 81 that receives the output of the pyroelectric sensor 71a of the first detection portion 71 to generate a first signal S1 whose level varies according to whether or not the output value of the pyroelectric sensor 71a of the first detection portion 71 is greater than a predetermined threshold value; a second detection portion 72 including a pyroelectric sensor 72a, for detecting an area lower than the first detection portion 71 to detect the lower half of the human body; a second signal generation portion 82 that receives the output of the pyroelectric sensor 72a of the second detection portion 72 to generate a second signal S2 whose level varies according to whether or not the output of the pyroelectric sensor 72a of the second detection portion 72 is greater than a predetermined threshold value; a storage portion 52 for storing discrimination data D including data defining, with respect to the waveforms of the first and second signals S1 and S2, a condition for recognizing a human moving toward the image forming apparatus (multifunction product 100) and a condition for recognizing a human (user) is crossing the detection areas of the pyroelectric sensors; and a recognition<!-- EPO <DP n="21"> --> portion (main control section 5) for recognizing the direction of movement of the human with respect to the image forming apparatus (multifunction product 100) by recognizing, based on the waveforms of the first and second signals S1 and S2 and the discrimination data D, whether a human is moving toward the image forming apparatus (multifunction product 100) and whether a human is crossing the detection areas of the pyroelectric sensors.</p><p id="p0083" num="0083">Thus, based on the characteristics of the waveform of the first signal S1 which varies according to the movement of the upper half of the human body and the characteristics of the waveform of the second signal S2 which varies according to the movement of the lower half of the human body, it is possible to accurately discriminate/distinguish whether a human is moving closer or passing by. It is thus possible to accurately recognize/detect, not simply whether or not a human is present within the detection areas, but the direction of movement of a human with respect to the image forming apparatus (multifunction product 100).</p><p id="p0084" num="0084">The upper and lower halves of the human body move in different manners. Also, while the amount and intensity of infrared radiation incident on the pyroelectric sensors from the human body as a human moves toward the image forming apparatus (multifunction product 100) (the heat radiated from the human to the pyroelectric sensors) increase, the amount and intensity of infrared radiation incident on the pyroelectric sensors from the human body as a human is moving away decrease. For these reasons, in the waveforms of the first and second signals S1 and S2, such characteristics (conditions) can appear as allow discrimination of movement direction, namely moving closer or moving away. Accordingly, with respect to the waveforms of the first and second signals S1 and S2, the storage portion 52 stores, in discrimination data D, data defining a condition for recognizing a human moving away from the image forming apparatus, and, based on the waveforms of the first and second signals S1 and S2 and the discrimination data D, the recognition portion (main control section 5) recognizes whether or not a human is moving away from the image forming apparatus. Thus, based on the characteristics of the waveforms of the first and second signals S1 and S2, it is possible to accurately recognize even whether a human is moving away. It is thus possible to accurately recognize/detect, not simply whether or not a human is present within the detection areas, but the direction of movement of a human with respect to the image forming apparatus (multifunction product 100).</p><p id="p0085" num="0085">When power saving mode is not in effect and the recognition portion (main control section 5)<!-- EPO <DP n="22"> --> recognizes a human moving away from the image forming apparatus (multifunction product 100), the power supply section 6 supplies electric power only to part of the image forming apparatus (multifunction product 100) to shift the image forming apparatus (multifunction product 100) into power saving mode; when power saving mode is in effect and the recognition portion (main control section 5) recognizes a human moving toward the image forming apparatus (multifunction product 100), the power supply section 6 restarts the supply of electric power to all or part of the portions to which the supply of electric power has been stopped in power saving mode, and thereby cancels power saving mode; when the recognition portion (main control section 5) recognizes a human passing by, the power supply section 6 does not switch the mode of electric power supply. Thus, when a human is moving toward the image forming apparatus (multifunction product 100) to use it, the image forming apparatus (multifunction product 100) is shifted out of power saving mode. Accordingly, when a human reaches in front of the image forming apparatus (multifunction product 100), power saving mode has been canceled and the supply of electric power has been restarted to the relevant portions; thus, the human can make the image forming apparatus (multifunction product 100) execute a job with almost no wait. On the other hand, when a human is moving away from the image forming apparatus (multifunction product 100), the image forming apparatus (multifunction product 100) is shifted into power saving mode. Accordingly, whenever the image forming apparatus goes into an unused state, it can immediately be shifted into power saving mode, and this helps greatly reduce the electric power consumption of the image forming apparatus (multifunction product 100). Moreover, even a human passing by can be accurately discriminated/recognized, and thus power saving mode is not erroneously canceled, permitting the image forming apparatus (multifunction product 100) to remain in a power saving state as long as possible.</p><p id="p0086" num="0086">Due to the difference between the movement of the upper and lower halves of the human body, and due to the varying angles of the human body relative to the pyroelectric sensors, the waveforms of the first and second signals S1 and S2 vary according to whether a human is moving toward, moving away from, or passing by the image forming apparatus (multifunction product 100). The first and second signals S1 and S2 exhibit a signal variation pattern that appears only when a human is moving toward the image forming apparatus, a signal variation pattern that appears only when a human is moving away from it, and a signal variation pattern<!-- EPO <DP n="23"> --> that appears only when a human is passing by it. Accordingly, the storage portion 52 stores as the discrimination data D that defines variation patterns of the first and second signals S1 and S2; the recognition portion (main control section 5) recognizes the variation pattern of the first and second signals S1 and S2 and, by checking whether or not it agrees with one defined in the discrimination data D, recognizes human movement direction. It is thus possible to correctly recognize the direction of movement of a human with respect to the image forming apparatus.</p><p id="p0087" num="0087">Due to the difference between the movement of the upper and lower halves of the human body, and due to the varying angles of the human body relative to the pyroelectric sensors, the relationships between the first and second signals S1 and S2 in terms of frequency and cycle can vary according to whether a human is moving toward, moving away from, or passing by the image forming apparatus (multifunction product 100). In other words, there are cases where it is possible, based on the relationships between the first and second signals S1 and S2 in terms of frequency and cycle, to discriminate whether a human is moving toward, moving away from, or passing by the image forming apparatus. Accordingly, the storage portion 52 stores as the discrimination data D defining the relationships between the first and second signals S1 and S2 in terms of frequency or cycle; the recognition portion (main control section 5) calculates the frequencies or cycles of the first and second signals S1 and S2 and, based on the discrimination data D and the calculated frequencies or cycles, recognizes human movement direction. It is thus possible to correctly recognize the direction of movement of a human with respect to the image forming apparatus.</p><p id="p0088" num="0088">Moreover, in the first embodiment, for the pyroelectric sensor 71a of the first detection portion 71, the first lens 71L is provided, and for the pyroelectric sensor 72a of the second detection portion 72, the second lens 72L is provided. The first and second lenses 71L and 72L are lenses with equivalent characteristics. Moreover, in the discrimination data D, there are defined, as a condition for discriminating a human approaching the image forming apparatus (multifunction product 100), conditions that the frequency f1 of the first signal S1 is lower than the frequency f2 of the second signal S2 (that is, the cycle of the first signal S1 is longer than the cycle T2 of the second signal S2 and that the duty factor of the first signal S1 is increasing; as a condition for discriminating a human moving away from the image forming apparatus, conditions that the frequency f1 of the first signal S1 is lower than the frequency f2<!-- EPO <DP n="24"> --> of the second signal S2 (the cycle T1 of the first signal S1 is longer than the cycle T2 of the second signal S2) and that the duty factor of the first signal S1 is decreasing; as a condition for discriminating a human passing by, conditions that the frequency f1 of the first signal S1 is higher than the frequency f2 of the second signal S2 and that the duty factor of the second signal S2 first increases and decreases. This makes it possible to accurately recognize the direction of movement of a human.</p><heading id="h0010"><b>(Second Embodiment)</b></heading><p id="p0089" num="0089">Next, with reference to <figref idrefs="f0004">Figs. 4</figref>, <figref idrefs="f0009">9</figref>, and <figref idrefs="f0010">10</figref>, a second embodiment will be described. <figref idrefs="f0009">Fig. 9</figref> is a timing chart showing the waveforms of the first and second signals S1 and S2 reflecting movement direction as observed in the multifunction product 100 according to the second embodiment. <figref idrefs="f0010">Fig. 10</figref> is a diagram showing discrimination data D in the multifunction product 100 according to the second embodiment.</p><p id="p0090" num="0090">In this embodiment, the first lens 71L of the first detection portion 71 and the second lens 72L of the second detection portion 72 are made different so that, for each of the cases where a human is approaching, receding from, and passing by the multifunction product 100, the first and second signals S1 and S2 are given different waveforms than in the first embodiment. In other respects, a configuration similar to that in the first embodiment can be adopted. Accordingly, with respect to common features, the relevant parts of the description of the first embodiment are to be referred to, and no overlapping description or illustration will be given unless necessary.</p><p id="p0091" num="0091">One difference of the second embodiment from the first embodiment is that, by giving the first and second lenses 71L and 72L different focal lengths (for example, by giving the first lens 71L a shorter focal length and the second lens 72L a longer focal length than the first lens 71L so that the second lens 72L receives infrared radiation in an intentionally wider range on average), or by designing them to transmit different amounts of infrared radiation, or by giving the first and second detection portions 71 and 72 different detection areas, or by adjusting threshold value, the outputs of the respective pyroelectric sensors are so adjusted that the first and second signals S1 and S2 have output waveforms in the discrimination data D to each other.</p><p id="p0092" num="0092">A human moving toward the multifunction product 100 is equivalent to a heat source (infrared radiation generation source) moving toward it. Accordingly, in this embodiment, in<!-- EPO <DP n="25"> --> an approaching event, the lenses, the first and second detection portions 71 and 72, and the first and second signal generation portions 81 and 82 are so set that the high-level periods of the first signal S1 based on the pyroelectric sensor 71a detecting the upper half of the human body and the second signal S2 based on the pyroelectric sensor 72a detecting the lower half of the human body both become gradually long.</p><p id="p0093" num="0093">A human moving away from the multifunction product 100 is equivalent to a heat source (infrared radiation generation source) moving away from it. Accordingly, in this embodiment, in a receding event, the lenses, the first and second detection portions 71 and 72, and the first and second signal generation portions 81 and 82 are so set that the high-level periods of the first signal S1 based on the pyroelectric sensor 71a detecting the upper half of the human body and the second signal S2 based on the pyroelectric sensor 72a detecting the lower half of the human body both become gradually short.</p><p id="p0094" num="0094">By adjusting the first lens 71L, it is possible to set the first detection portion 71 so that the pyroelectric sensor 71a for detecting the upper half of the human body detects the swing of arms (hands) when a human passes by in front of the multifunction product 100 (crossing the detection areas of the pyroelectric sensors). Likewise, by adjusting the second lens 72L, it is possible to set the second detection portion 72 so that the pyroelectric sensor 72a for detecting the lower half of the human body detects the swing of legs when a human passes by in front of the multifunction product 100 (crossing the detection areas of the pyroelectric sensors). By exploiting the fact that the swing of hands causes the infrared radiation incident on the document transport section 1a to vary and the fact that the swing of the leg causes the infrared radiation incident on the pyroelectric sensor 72a to vary, the first and second signal generation portions 81 and 82 generate the first and second signals S1 and S2 with higher frequencies (with shorter cycles) than in an approaching or recessing event. In other words, the first and second detection portions 71 and 72 and the first and second signal generation portions 81 and 82 are so set that the frequencies of the first and second signals S1 and S2 in a crossing event are significantly higher than in an approaching or recessing event.</p><p id="p0095" num="0095">As described above, also in this embodiment, as a human moves with respect to the multifunction product 100, in the variation patterns of the first and second signals S1 and S2 and in the relationships between them in terms of frequency and cycle, characteristics can appear that are so striking as to allow discrimination of whether a human is approaching,<!-- EPO <DP n="26"> --> receding, or passing by.</p><p id="p0096" num="0096">Accordingly, as shown in <figref idrefs="f0010">Fig. 10</figref>, in the discrimination data D for recognition/discrimination of human movement direction (approaching, recessing, or crossing), it is possible to define waveform variation patterns of the first and second signals S1 and S2 and relationships between them in terms of frequency and cycle. The discrimination data D is preferably stored in the storage portion 52.</p><p id="p0097" num="0097">As shown in <figref idrefs="f0010">Fig. 10</figref>, as a condition for discriminating a human approaching the multifunction product 100, based on the above-mentioned characteristics of the relevant signals in an approaching event, it is possible to define, in the discrimination data D, a condition that the high-level periods of the first and second signals S1 and S2 are both becoming gradually long (the duty factors of the first and second signals S1 and S2 are increasing). The main control section 5 checks whether or not the high-level periods of the first and second signals S1 and S2 become longer several consecutive times.</p><p id="p0098" num="0098">As shown in <figref idrefs="f0010">Fig. 10</figref>, as a condition for discriminating a human moving away from the multifunction product 100, based on the above-mentioned characteristics of the relevant signals in a receding event, it is possible to define, in the discrimination data D, a condition that the high-level periods of the first and second signals S1 and S2 are both becoming gradually short (the duty factors of the first and second signals S1 and S2 are decreasing). The main control section 5 checks whether or not the high-level periods of the first and second signals S1 and S2 both become shorter several consecutive times.</p><p id="p0099" num="0099">As shown in <figref idrefs="f0010">Fig. 10</figref>, as a condition for discriminating a human passing by in front of the multifunction product 100 (crossing the detection areas of the pyroelectric sensors), based on the above-mentioned characteristics of the relevant signals in a crossing event, it is possible to define, in the discrimination data D, a condition that the frequencies f1 and f2 of the first and second signals S1 and S2 are higher than a prescribed frequency fa (the cycles T1 and T2 of the first and second signals S1 and S2 are shorter than a prescribed cycle Ta) can be defined. The frequency fa is a frequency higher than the frequencies in an approaching or receding event, and is a frequency that is considered to signify passing by (a frequency as is detected in a crossing event). The prescribed cycle Ta is a cycle shorter than the cycles in an approaching or receding event, and is a cycle that is considered to signify passing by (a cycle as is detected in a crossing event).<!-- EPO <DP n="27"> --></p><p id="p0100" num="0100">As shown in <figref idrefs="f0009">Fig. 9</figref>, the main control section 5 (the CPU 51 and the clock portion 54) measures the cycle T1 and the high-level period Th1 of the first signal S1. Based on the measured cycle T1, the main control section 5 can calculate the frequency f1 of the first signal S1. Moreover, by dividing the high-level period Th1 of the first signal S1 by its cycle T1, the main control section 5 can calculate the duty factor of the first signal S1.</p><p id="p0101" num="0101">Likewise, as shown in <figref idrefs="f0009">Fig. 9</figref>, the main control section 5 (the CPU 51 and the clock portion 54) measures the cycle T2 and the high-level period Th2 of the second signal S2. Based on the measured cycle T2, the main control section 5 can calculate the frequency f2 of the second signal S2. Moreover, by dividing the high-level period Th2 of the second signal S2 by its cycle T2, the main control section 5 can calculate the duty factor of the second signal S2. Also in this embodiment, by using the cycle T1, the frequency f1, and the high-level period Th1 of the first signal S1, the cycle T2, the frequency f2, and the high-level period Th2 of the second signal S2, and the discrimination data D, the main control section 5 can recognize human movement direction.</p><p id="p0102" num="0102">As described above, in the second embodiment, the first detection portion 71, the first signal generation portion 81, the second detection portion 72, and the second signal generation portion 82 are so adjusted that the output waveforms of the first and second signals S1 and S2 are closer to each other. Moreover, in the discrimination data D, there are defined, as the condition for discriminating a human approaching the image forming apparatus (multifunction product 100), a condition that the duty factors of the first and second signals S1 and S2 are increasing; as the condition for discriminating a human receding from the image forming apparatus, a condition that the duty factors of the first and second signals S1 and S2 are decreasing; and as the condition for discriminating a human passing by, a condition that the frequencies f1 and f2 of the first and second signals S1 and S2 are higher than a previous determined frequency fa (that is, the cycles T1 and T2 of the first and second signals S1 and S2 are both shorter than a prescribed cycle Ta). It is thus possible to accurately recognize human movement direction.</p><p id="p0103" num="0103">Furthermore, in this embodiment, the first and second detection portions 71 and 72 are so adjusted that the waveforms of the first and second signals S1 and S2 are closer to each other. Accordingly, as shown in <figref idrefs="f0004">Fig. 4</figref>, a synthesized signal generating portion 9 for synthesizing the first and second signals S1 and S2 together may be provided. <figref idrefs="f0004">Fig. 4</figref> shows an example<!-- EPO <DP n="28"> --> where, as the synthesized signal generating portion 9, an OR circuit is provided. Human movement direction (approaching, recessing, or crossing) may then be recognized/discriminated according to the so synthesized signal S3.</p><p id="p0104" num="0104">In <figref idrefs="f0009">Fig. 9</figref>, the timing chart shows the waveform of the synthesized signal S3 resulting from synthesis of the first and second signals S1 and S2 in each of approaching, receding, and crossing events. According to the direction of movement of a human approaching, receding from, or passing by the multifunction product 100, similar characteristics appear in the waveform of the synthesized signal S3 as well. Accordingly, also for the synthesized signal S3, conditions for determining whether a human is approaching, receding from, or passing by the multifunction product 100 may be included in the discrimination data D.</p><p id="p0105" num="0105">For example, as shown in <figref idrefs="f0010">Fig. 10</figref>, as a condition for discriminating a human approaching the multifunction product 100, based on the above-mentioned characteristics of the synthesized signal S3 in an approaching event that are similar to those of the first and second signals S1 and S2, it is possible to define, in the discrimination data D, a condition that the high-level period of the synthesized signal S3 is becoming increasingly long (the duty factor of the synthesized signal S3 is increasing). The main control section 5 checks whether or not the high-level period Th3 of the synthesized signal S3 becomes longer several consecutive times. As shown in <figref idrefs="f0010">Fig. 10</figref>, as a condition for discriminating a human receding from the multifunction product 100, based on the above-mentioned characteristics of the synthesized signal S3 in a receding event that are similar to those of the first and second signals S1 and S2, it is possible to define, in the discrimination data D, a condition that the high-level period of the synthesized signal S3 is becoming increasingly short (the duty factor of the synthesized signal S3 is decreasing). The main control section 5 checks whether or not the high-level period Th3 of the synthesized signal S3 becomes shorter several consecutive times.</p><p id="p0106" num="0106">As shown in <figref idrefs="f0010">Fig. 10</figref>, as a condition for discriminating a human passing by in front of the multifunction product 100 (crossing the detection areas of the pyroelectric sensors), based on the above-mentioned characteristics of the synthesized signal S3 in a crossing event that are similar to those of the first and second signals S1 and S2, it is possible to define, in the discrimination data D, a condition that the frequency of the synthesized signal S3 is higher than a frequency fa prescribed as a frequency that can be regarded as higher than the frequency in an approaching or receding event.<!-- EPO <DP n="29"> --></p><p id="p0107" num="0107">To enable recognition of human movement direction based on the discrimination data D for the synthesized signal S3, the main control section 5 (the CPU 51 and the clock portion 54) can feed the synthesized signal S3 from the synthesized signal generating portion 9 to the main control section 5 (see <figref idrefs="f0006">Fig. 6</figref>). According to the synthesized signal S3, the main control section 5 measures the cycle T3 and the high-level period Th3 of the synthesized signal S3. Based on the measured cycle T3, the main control section 5 can calculate the frequency f3 of the synthesized signal S3. Moreover, by dividing the high-level period Th3 of the synthesized signal S3 by its cycle T3, the main control section 5 can calculate the duty factor of the synthesized signal S3.</p><p id="p0108" num="0108">Thus, also by busing the cycle T3, the frequency f3, and the high-level period Th3 of the synthesized signal S3 and the discrimination data D, the main control section 5 can recognize human movement direction. The main control section 5 can recognize human movement direction based on the first and second signals S1 and S2 and separately recognize human movement direction based on the synthesized signal S3 so as to conclude, when the two recognition results agree, that a human is moving closer, moving away, or passing by. Instead, the main control section 5 may recognize human movement direction based on the first and second signals S1 and S2 alone, or may recognize human movement direction based on the synthesized signal S3 alone.</p><heading id="h0011"><b>(Third Embodiment)</b></heading><p id="p0109" num="0109">Next, with reference to <figref idrefs="f0011">Figs. 11</figref> and <figref idrefs="f0012">12</figref>, a third embodiment will be described. <figref idrefs="f0011">Fig. 11</figref> is a timing chart showing the waveforms of the relevant signals reflecting movement direction as observed in the multifunction product 100 according to the third embodiment. <figref idrefs="f0012">Fig. 12</figref> is a diagram showing discrimination data D in the multifunction product 100 according to the third embodiment.</p><p id="p0110" num="0110">In this embodiment, the first lens 71L of the first detection portion 71 and the second lens 72L of the second detection portion 72 are made different so that, for each of the cases where a human is approaching, receding from, and passing by the multifunction product 100, the waveforms of the first and second signals S1 and S2 are adjusted to be different than in the first embodiment. In other respects, a configuration similar to those in the first and second embodiments can be adopted. Accordingly, with respect to common features, the relevant parts of the description of the first and second embodiments are to be referred to, and no<!-- EPO <DP n="30"> --> overlapping description or illustration will be given unless necessary.</p><p id="p0111" num="0111">One difference of the third embodiment from the first embodiment is that, by giving the first and second lenses 71L and 72L different focal lengths, or by adjusting the amounts of infrared radiation incident on the sensors, or by giving the first and second detection portions 71 and 72 different detection areas, or by adjusting the threshold values, the outputs of the respective pyroelectric sensors are so adjusted that the first and second signals S1 and S2 have output waveforms closer to each other.</p><p id="p0112" num="0112">Specifically, in the multifunction product 100 according to the third embodiment, the lenses, the first and second detection portions 71 and 72, and the first and second signal generation portions 81 and 82 are so set that the frequencies of the first and second signals S1 and S2 in approaching and receding events are higher than their frequencies in a crossing event. In other words, the lenses, the first and second detection portions 71 and 72, and the first and second signal generation portions 81 and 82 are so set that the cycles of the first and second signals S1 and S2 when a human moves toward or away from the image forming apparatus are shorter than their cycles when a human crosses it.</p><p id="p0113" num="0113">Moreover, in the multifunction product 100 according to the third embodiment, the first and second detection portions 71 and 72 and the first and second signal generation portions 81 and 82 are so set that, in a crossing event, the high-level periods Th1 and Th2 of the first and second signals S1 and S2 first become increasingly long and then increasingly short (the duty factors of the first and second signals S1 and S2 first increase and then decrease).</p><p id="p0114" num="0114">As described above, also in this embodiment, based on characteristics that appear in the variation patterns of the first and second signals S1 and S2 and in the relationships between them in terms of frequency and cycle, it can be possible to discriminate whether a human is approaching or crossing.</p><p id="p0115" num="0115">Accordingly, as shown in <figref idrefs="f0012">Fig. 12</figref>, in the discrimination data D for recognizing/discriminating human movement direction (approaching, recessing, or crossing), it is possible to define waveform variation patterns of the first and second signals S1 and S2 and relationships between them in terms of frequency and cycle. The discrimination data D is preferably stored in the storage portion 52.</p><p id="p0116" num="0116">As shown in <figref idrefs="f0012">Fig. 12</figref>, as a condition for discriminating a human moving toward or away from the multifunction product 100, based on the above-mentioned characteristics of the relevant<!-- EPO <DP n="31"> --> signals in approaching and receding events, it is possible to define, in the discrimination data D, a condition that the frequencies f1 and f2 of the first and second signals S1 and S2 are higher than a prescribed frequency fb (the cycles T1 and T2 of the first and second signals S1 and S2 are both shorter than a prescribed cycle Tb). The prescribed frequency fb is a frequency higher than in a crossing event, and is a frequency that is considered to be a frequency observed during approach or recession. The prescribed cycle Tb is a cycle shorter than in a crossing event, and is a cycle that is considered to be a cycle observed during approach or recession.</p><p id="p0117" num="0117">Moreover, as shown in <figref idrefs="f0012">Fig. 12</figref>, as a condition for discriminating a human passing by in front of the multifunction product 100 (crossing the detection areas of the pyroelectric sensors), based on the above-mentioned characteristics of the relevant signals in a crossing event, it is possible to define, in the discrimination data D, a condition that the high-level periods of the first and second signals S1 and S2 both become first increasingly long and then increasingly short (the duty factors of the first and second signals S1 and S2 first increase and then decrease). For example, the main control section 5 checks whether or not the high-level periods of the first and second signals S1 and S2 both become longer several consecutive times and then become increasingly short.</p><p id="p0118" num="0118">Based on the discrimination data D described above, to recognize human movement direction, as shown in <figref idrefs="f0006">Fig. 6</figref>, the main control section 5 (the CPU 51 and the clock portion 54) measures the cycle T1 and the high-level period Th1 of the first signal S1. Based on the measured cycle T1, the main control section 5 can calculate the frequency f1 of the first signal S1. Moreover, by dividing the high-level period Th1 of the first signal S1 by its cycle T1, the main control section 5 can calculate the duty factor of the first signal S1.</p><p id="p0119" num="0119">Moreover, based on the discrimination data D described above, to recognize human movement direction, as shown in <figref idrefs="f0006">Fig. 6</figref>, the main control section 5 (the CPU 51 and the clock portion 54) measures the cycle T2 and the high-level period Th2 of the second signal S2. Based on the measured cycle T2, the main control section 5 can calculate the frequency f2 of the second signal S2. Moreover, by dividing the high-level period Th2 of the second signal S2 by its cycle T2, the main control section 5 can calculate the duty factor of the second signal S2.</p><p id="p0120" num="0120">Also in this embodiment. by using the cycle T1, the frequency f1, and the high-level period<!-- EPO <DP n="32"> --> Th1 of the first signal S1, the cycle T2, the frequency f2, and the high-level period Th2 of the second signal S2, and the discrimination data D, the main control section 5 can recognize human movement direction. The cycle and the frequency are in an inversely proportional relationship, and therefore finding one allows the determination of the other.</p><p id="p0121" num="0121">As described above, in the third embodiment, the first detection portion 71, the first signal generation portion 81, the second detection portion 72, and the second signal generation portion 82 are so adjusted that the output waveforms of the first and second signals S1 and S2 are closer to each other. Moreover, in the discrimination data D, there are defined, as a condition for discriminating a human approaching or receding from the image forming apparatus (multifunction product 100), a condition that the frequencies f1 and f2 of the first and second signals S1 and S2 are higher than the prescribed frequency fb (that is, the cycles T1 and T2 of the first and second signals S1 and S2 are shorter than the prescribed cycle Tb); and as a condition for discriminating a human passing by, a condition that the duty factors of the first and second signals S1 and S2 both first increase and then decrease.</p><p id="p0122" num="0122">Furthermore, in this embodiment, the first and second detection portions 71 and 72 are so adjusted that the waveforms of the first and second signals S1 and S2 are closer together. Accordingly, as shown in <figref idrefs="f0004">Fig. 4</figref>, a synthesized signal generating portion 9 for synthesizing the first and second signals S1 and S2 together may be provided. <figref idrefs="f0004">Fig. 4</figref> shows an example where, as the synthesized signal generating portion 9, an OR circuit is provided. Human movement direction (approaching, recessing, or crossing) may then be recognized/discriminated according to the so synthesized signal S3.</p><p id="p0123" num="0123">In <figref idrefs="f0012">Fig. 12</figref>, the timing chart shows the waveform of the synthesized signal S3 resulting from synthesis of the first and second signals S1 and S2 in each of approaching, receding, and crossing events. According to the direction of movement of a human with respect to the multifunction product 100, similar characteristics appear in the waveform of the synthesized signal S3 as well. Accordingly, also for the synthesized signal S3, conditions for determining whether a human is approaching, receding from, or passing by the multifunction product 100 may be included in the discrimination data D.</p><p id="p0124" num="0124">As shown in <figref idrefs="f0012">Fig. 12</figref>, as a condition for discriminating a human approaching or receding from the multifunction product 100, based on the above-mentioned characteristics of the synthesized signal S3 in an approaching event that reflect those of the first and second signals<!-- EPO <DP n="33"> --> S1 and S2, it is possible to define, in the discrimination data D, a condition that the frequency f3 of the synthesized signal S3 is higher than the prescribed frequency fb (the cycle T3 of the synthesized signal S3 is shorter than the prescribed cycle Tb).</p><p id="p0125" num="0125">Moreover, as shown in <figref idrefs="f0012">Fig. 12</figref>, as a condition for discriminating a human passing by in front of the multifunction product 100, based on the above-mentioned characteristics of the synthesized signal S3 in an approaching event that reflect those of the first and second signals S1 and S2, it is possible to define, in the discrimination data D, a condition that the high-level period Th3 of the synthesized signal S3 becomes first increasingly long and then increasingly short (the duty factor of the synthesized signal S3 first increases and then decreases). The main control section 5 checks whether or not the high-level period Th3 of the synthesized signal S3 becomes longer several consecutive times and then becomes increasingly short. Based on the discrimination data D for the synthesized signal S3, to enable recognition of human movement direction, the main control section 5 (the CPU 51 and the clock portion 54) can feed the synthesized signal S3 from the synthesized signal generating portion 9 to the main control section 5 (see <figref idrefs="f0006">Fig. 6</figref>). Based on the synthesized signal S3, the main control section 5 measures the cycle T3 and the high-level period Th3 of the synthesized signal S3. Based on the measured cycle T3, the main control section 5 can calculate the frequency f3 of the synthesized signal S3. Moreover, by dividing the high-level period Th3 of the synthesized signal S3 by its cycle T3, the main control section 5 can calculate the duty factor of the synthesized signal S3.</p><p id="p0126" num="0126">Thus, also by using the cycle T3, the frequency f3, and the high-level period Th3 of the synthesized signal S3 and the discrimination data D, the main control section 5 can recognize human movement direction. The main control section 5 can recognize human movement direction based on the first and second signals S1 and S2 and separately recognize human movement direction based on the synthesized signal S3 so as to conclude, when the two recognition results agree, that a human is moving closer, moving away, or passing by. Instead, the main control section 5 may recognize human movement direction based on the first and second signals S1 and S2 alone, or may recognize human movement direction based on the synthesized signal S3 alone.</p><p id="p0127" num="0127">In the waveform of the first and second signals S1 and S2 synthesized together (of the synthesized signal S3), there may appear characteristics in terms of frequency and cycle that<!-- EPO <DP n="34"> --> allow discrimination of a human moving toward the image forming apparatus (multifunction product 100), or characteristics in terms of frequency and cycle that allow discrimination of a human moving away from the image forming apparatus, or characteristics in terms of frequency and cycle that allow discrimination of a human crossing the detection area. Accordingly, the image forming apparatuses (multifunction products 100) according to the second and third embodiments include, in addition to the configuration and benefits described previously in connection with the first embodiment, the synthesized signal generating portion 9 which synthesizes the first and second signals S1 and S2 to generate the synthesized signal S3; moreover, the storage portion 52 stores, as the discrimination data D, data defining variation patterns of the synthesized signal S3 so that the recognition portion (main control section 5) recognizes the variation pattern of the synthesized signal S3 and, according to whether or not it agrees with one defined in the discrimination data D, recognizes human movement direction. It is thus possible to accurately recognize the direction of movement of a human with respect to the image forming apparatus (multifunction product 100).</p><p id="p0128" num="0128">Moreover, in the image forming apparatuses (multifunction products 100) according to the second and third embodiments, the pyroelectric sensor of the first detection portion 71 is provided with the first lens 71L, the pyroelectric sensor of the second detection portion 72 is provided with the second lens 72L, and the first and second lenses 71L and 72L are given different focal points. This makes it possible to intentionally give the first and second signals S1 and S2 such waveforms in which so notable characteristics appear as to allow discrimination of whether a human is moving toward the image forming apparatus (multifunction product 100), moving away from it, or crossing the detection area.</p><p id="p0129" num="0129">The present disclosure is to be understood to disclose corresponding methods as well.</p><p id="p0130" num="0130">While the present disclosure has proceeded by way of embodiments, they are in no way meant to limit the scope of the disclosure; what is disclosed herein may be implemented with any modifications or variations made without departing from the spirit of the present disclosure. The above embodiments of the invention as well as the appended claims and figures show multiple characterizing features of the invention in specific combinations. The skilled person will easily be able to consider further combinations or sub-combinations of these features in order to adapt the invention as defined in the claims to his specific needs.</p></description><claims mxw-id="PCLM56976138" lang="EN" load-source="patent-office"><!-- EPO <DP n="35"> --><claim id="c-en-0001" num="0001"><claim-text>An image forming apparatus, comprising:
<claim-text>a first detection portion (71) including a pyroelectric sensor (71a) and adapted to detect an upper half of a human body;</claim-text>
<claim-text>a first signal generation portion (81) adapted to receive an output of the pyroelectric sensor (71a) of the first detection portion (71) to generate a first signal (S1) whose level varies according to whether or not an output value of the pyroelectric sensor (71a) of the first detection portion (71) is greater than a prescribed threshold value;</claim-text>
<claim-text>a second detection portion (72) including a pyroelectric sensor (72a) and adapted to detect a lower area than the first detection portion (71) to detect a lower half of the human body;</claim-text>
<claim-text>a second signal generation portion (82) adapted to receive an output of the pyroelectric sensor (72a) of the second detection portion (72) to generate a second signal (S2) whose level varies according to whether or not an output value of the pyroelectric sensor (72a) of the second detection portion (72) is greater than a prescribed threshold value;</claim-text>
<claim-text>a storage portion (52) for storing discrimination data (D) including data defining, with respect to waveforms of the first and second signals (S1, S2), a condition for recognizing a human moving toward the image forming apparatus (100) and a condition for recognizing a human crossing a detection area of the pyroelectric sensors (71a, 72a); and</claim-text>
<claim-text>a recognition portion (5) adapted to recognize a direction of movement of a human with respect to the image forming apparatus (100) by recognizing, based on the waveforms of the first and second signals (S1, S2) and the discrimination data (D), whether a human is moving toward the image forming apparatus (100) and whether a human is crossing the detection area of the pyroelectric sensors (71a, 72a).</claim-text></claim-text></claim><claim id="c-en-0002" num="0002"><claim-text>The apparatus according to claim 1, wherein<br/>
the storage portion (52) further stores, in the discrimination data (D), with respect to the waveforms of the first and second signals (S1, S2), data defining a condition for recognizing a human moving away from the image forming apparatus (100), and<br/>
the recognition portion (5) is adapted to recognize also whether a human is moving away from the image forming apparatus (100) based on the waveforms of the first and second<!-- EPO <DP n="36"> --> signals (S1, S2) and the discrimination data (D).</claim-text></claim><claim id="c-en-0003" num="0003"><claim-text>The apparatus according to claim 2, further comprising a power supply portion (6) adapted<br/>
to shift the image forming apparatus (100) into power saving mode by supplying electric power to only a portion of the image forming apparatus (100) when the recognition portion (5) recognizes a human moving away from the image forming apparatus (100) while a power saving mode is not in effect,<br/>
to cancel power saving mode by restarting supply of electric power to all or part of the portion to which the supply of electric power has been stopped in power saving mode when the recognition portion (5) recognizes a human moving toward the image forming apparatus (100) while power saving mode is in effect, and<br/>
not to change an electric power supply mode when the recognition portion (5) recognizes a human crossing.</claim-text></claim><claim id="c-en-0004" num="0004"><claim-text>The apparatus according to any one of claims 1 to 3, wherein<br/>
the storage portion (52) stores, in the discrimination data (D), data defining a variation pattern of the first and second signals (S1, S2), and<br/>
the recognition portion (5) is adapted to recognize a variation pattern of the first and second signals (S1, S2) to recognize the direction of the movement of the human based on whether or not the recognized pattern agrees with the pattern defined in the discrimination data (D).</claim-text></claim><claim id="c-en-0005" num="0005"><claim-text>The apparatus according to any one of claims 1 to 4, wherein<br/>
the storage portion (52) stores, in the discrimination data (D), data defining a relationship between the first and second signals (S1, S2) in terms of frequency or cycle, and<br/>
the recognition portion (5) is adapted to calculate a frequency or a cycle of the first and second signals (S1, S2) to recognize the direction of the movement of the human based on the discrimination data (D).</claim-text></claim><claim id="c-en-0006" num="0006"><claim-text>The apparatus according to any one of claims 1 to 5, further comprising a<!-- EPO <DP n="37"> --> synthesized signal generation portion (9) adapted to generate a synthesized signal (S3) by synthesizing the first and second signals (S1, S2) together, wherein<br/>
the storage portion (52) stores, in the discrimination data (D), data defining a variation pattern of the synthesized signal (S3), and<br/>
the recognition portion (5) is adapted to recognize a variation pattern of the synthesized signal (S3) to recognize the direction of the movement of the human based on whether or not the recognized pattern agrees with the pattern defined in the discrimination data (D).</claim-text></claim><claim id="c-en-0007" num="0007"><claim-text>The apparatus according to claim 6, wherein<br/>
the pyroelectric sensor (71a) of the first detection portion (71) is provided with a first lens (L1),<br/>
the pyroelectric sensor (72a) of the second detection portion (72) is provided with a second lens (L2), and<br/>
the first and second lenses (L1, L2) have different focal points.</claim-text></claim><claim id="c-en-0008" num="0008"><claim-text>The apparatus according to any one of claims 2 to 5, wherein<br/>
the pyroelectric sensor (71a) of the first detection portion (71) is provided with a first lens (L1),<br/>
the pyroelectric sensor (72a) of the second detection portion (72) is provided with a second lens (L2),<br/>
the first and second lenses (L1, L2) have equivalent characteristics, and<br/>
the storage portion (52) stores, in the discrimination data (D),<br/>
as the condition for recognizing a human approaching the image forming apparatus (100), conditions that a frequency of the first signal (S1) is lower than a frequency of the second signal (S2) and that a duty factor of the first signal (S1) is increasing,<br/>
as the condition for recognizing a human receding from the image forming apparatus (100), conditions that the frequency of the first signal (S1) is lower than the frequency of the second signal (S2) and that the duty factor of the first signal (S1) is decreasing, and<br/>
as the condition for recognizing a human crossing, conditions that the<!-- EPO <DP n="38"> --> frequency of the first signal (S1) is higher than the frequency of the second signal (S2) and that a duty factor of the second signal (S2) first increases and then decreases.</claim-text></claim><claim id="c-en-0009" num="0009"><claim-text>The apparatus according to any one of claims 2 to 5, wherein<br/>
the first detection portion (71), the first signal generation portion (81), the second detection portion (72), and the second signal generation portion (82) are adjusted such that output waveforms of the first and second signals (S1, S2) are closer to each other, and<br/>
the storage portion (52) stores, in the discrimination data (D),<br/>
as the condition for recognizing a human approaching the image forming apparatus (100), a condition that duty factors of the first and second signals (S1, S2) are increasing,<br/>
as the condition for recognizing a human receding from the image forming apparatus (100), a condition that the duty factors of the first and second signals (S1, S2) are decreasing, and<br/>
as the condition for recognizing a human crossing, a condition that frequencies of the first and second signals (S1, S2) are higher than a prescribed frequency.</claim-text></claim><claim id="c-en-0010" num="0010"><claim-text>The apparatus according to any one of claims 2 to 5, wherein<br/>
the first detection portion (71), the first signal generation portion (81), the second detection portion (72), and the second signal generation portion (82) are adjusted such that output waveforms of the first and second signals (S1, S2) are closer to each other, and<br/>
the storage portion (52) stores, in the discrimination data (D),<br/>
as the condition for recognizing a human approaching or receding from the image forming apparatus (100), a condition that frequencies of the first and second signals (S1, S2) are higher than a prescribed frequency, and<br/>
as the condition for recognizing a human crossing, a condition that duty factors of the first and second signals (S1, S2) both first increase and then decrease.</claim-text></claim><claim id="c-en-0011" num="0011"><claim-text>A method of controlling an image forming apparatus, comprising:
<claim-text>detecting an upper half of a human body using a first detection portion (71) including a pyroelectric sensor (71a, 72a);<!-- EPO <DP n="39"> --></claim-text>
<claim-text>receiving an output of the pyroelectric sensor (71a, 72a) of the first detection portion (71) to make a first signal generation portion (81) generate a first signal (S1) whose level varies according to whether or not an output value of the pyroelectric sensor (71a, 72a) of the first detection portion (71) is greater than a prescribed threshold value;</claim-text>
<claim-text>detecting a lower half of the human body using a second detection portion (72) including a pyroelectric sensor (71a, 72a) and detecting a lower area than the first detection portion (71);</claim-text>
<claim-text>receiving an output of the pyroelectric sensor (71a, 72a) of the second detection portion (72) to make a second signal generation portion (82) generate a second signal (S2) whose level varies according to whether or not an output value of the pyroelectric sensor (71a, 72a) of the second detection portion (72) is greater than a prescribed threshold value;</claim-text>
<claim-text>storing, as discrimination data (D), data defining, with respect to waveforms of the first and second signals (S1, S2), a condition for recognizing a human moving toward the image forming apparatus (100) and a condition for recognizing a human crossing a detection area of the pyroelectric sensors (71a, 72a); and</claim-text>
<claim-text>recognizing a direction of movement of a human with respect to the image forming apparatus (100) by recognizing, based on the waveforms of the first and second signals (S1, S2) and the discrimination data (D), whether a human is moving toward the image forming apparatus (100) and whether a human is crossing the detection area of the pyroelectric sensors (71a, 72a).</claim-text></claim-text></claim><claim id="c-en-0012" num="0012"><claim-text>The method according to claim 11, comprising:
<claim-text>further storing, in the discrimination data (D), with respect to waveforms of the first and second signals (S1, S2), data defining a condition for recognizing a human moving away from the image forming apparatus (100); and</claim-text>
<claim-text>recognizing also whether a human is moving away from the image forming apparatus (100) based on the waveforms of the first and second signals (S1, S2) and the discrimination data (D).</claim-text></claim-text></claim><claim id="c-en-0013" num="0013"><claim-text>The method according to claim 12, comprising:
<claim-text>shifting the image forming apparatus (100) into a power saving mode by supplying<!-- EPO <DP n="40"> --> electric power to only a portion of the image forming apparatus (100) when the recognition portion (5) recognizes a human moving away from the image forming apparatus (100) while a power saving mode is not in effect;</claim-text>
<claim-text>canceling power saving mode by restarting supply of electric power to all or part of the portion to which the supply of electric power has been stopped in power saving mode when the recognition portion (5) recognizes a human moving toward the image forming apparatus (100) while power saving mode is in effect; and</claim-text>
<claim-text>not changing an electric power supply mode when the recognition portion (5) recognizes a human crossing.</claim-text></claim-text></claim><claim id="c-en-0014" num="0014"><claim-text>The method according to any one of claims 11 to 13, comprising:
<claim-text>storing, in the discrimination data (D), data defining a variation pattern of the first and second signals (S1, S2);</claim-text>
<claim-text>recognizing a variation pattern of the first and second signals (S1, S2); and</claim-text>
<claim-text>recognizing the direction of the movement of the human based on whether or not the recognized pattern agrees with the pattern defined in the discrimination data (D).</claim-text></claim-text></claim><claim id="c-en-0015" num="0015"><claim-text>The method according to any one of claims 11 to 14, comprising:
<claim-text>storing, in the discrimination data (D), data defining a relationship between the first and second signals (S1, S2) in terms of frequency or cycle; and</claim-text>
<claim-text>calculating a frequency or a cycle of the first and second signals (S1, S2) to recognize the direction of the movement of the human based on the discrimination data (D).</claim-text></claim-text></claim></claims><drawings mxw-id="PDW16666923" load-source="patent-office"><!-- EPO <DP n="41"> --><figure id="f0001" num="1"><img id="if0001" file="imgf0001.tif" wi="165" he="218" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="42"> --><figure id="f0002" num="2"><img id="if0002" file="imgf0002.tif" wi="164" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="43"> --><figure id="f0003" num="3"><img id="if0003" file="imgf0003.tif" wi="165" he="213" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="44"> --><figure id="f0004" num="4"><img id="if0004" file="imgf0004.tif" wi="158" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="45"> --><figure id="f0005" num="5"><img id="if0005" file="imgf0005.tif" wi="165" he="117" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="46"> --><figure id="f0006" num="6"><img id="if0006" file="imgf0006.tif" wi="165" he="188" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="47"> --><figure id="f0007" num="7"><img id="if0007" file="imgf0007.tif" wi="165" he="153" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="48"> --><figure id="f0008" num="8"><img id="if0008" file="imgf0008.tif" wi="158" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="49"> --><figure id="f0009" num="9"><img id="if0009" file="imgf0009.tif" wi="165" he="226" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="50"> --><figure id="f0010" num="10"><img id="if0010" file="imgf0010.tif" wi="165" he="169" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="51"> --><figure id="f0011" num="11"><img id="if0011" file="imgf0011.tif" wi="165" he="229" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="52"> --><figure id="f0012" num="12"><img id="if0012" file="imgf0012.tif" wi="165" he="129" img-content="drawing" img-format="tif"/></figure></drawings><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
