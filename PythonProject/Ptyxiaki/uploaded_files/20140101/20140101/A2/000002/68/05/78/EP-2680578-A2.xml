<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2680578-A2" country="EP" doc-number="2680578" kind="A2" date="20140101" family-id="48699524" file-reference-id="317082" date-produced="20180824" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="146549110" ucid="EP-2680578-A2"><document-id><country>EP</country><doc-number>2680578</doc-number><kind>A2</kind><date>20140101</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-13168902-A" is-representative="YES"><document-id mxw-id="PAPP154823033" load-source="docdb" format="epo"><country>EP</country><doc-number>13168902</doc-number><kind>A</kind><date>20130523</date><lang>EN</lang></document-id><document-id mxw-id="PAPP220439653" load-source="docdb" format="original"><country>EP</country><doc-number>13168902.8</doc-number><date>20130523</date></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC140449748" ucid="US-201213532555-A" load-source="docdb"><document-id format="epo"><country>US</country><doc-number>201213532555</doc-number><kind>A</kind><date>20120625</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL2066399210" load-source="docdb">H04N   7/18        20060101AFI20140401BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-1833766693" load-source="docdb" scheme="CPC">H04N   7/181       20130101 FI20170325BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1833766694" load-source="docdb" scheme="CPC">B64D2011/0061      20130101 LA20170325BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1833766695" load-source="docdb" scheme="CPC">B64D  47/08        20130101 LI20170325BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1833766696" load-source="docdb" scheme="CPC">B64D  43/00        20130101 LI20170325BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT132179814" lang="DE" load-source="patent-office">Fahrzeuganzeigesystem</invention-title><invention-title mxw-id="PT132179815" lang="EN" load-source="patent-office">Vehicle display system</invention-title><invention-title mxw-id="PT132179816" lang="FR" load-source="patent-office">Système d'affichage de véhicule</invention-title><citations><non-patent-citations><nplcit><text>None</text><sources><source mxw-id="PNPL45130732" load-source="docdb" name="APP"/></sources></nplcit></non-patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR918156973" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>BOEING CO</last-name><address><country>US</country></address></addressbook></applicant><applicant mxw-id="PPAR918154084" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>THE BOEING COMPANY</last-name></addressbook></applicant><applicant mxw-id="PPAR918986720" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>The Boeing Company</last-name><iid>100235575</iid><address><street>100 North Riverside Plaza</street><city>Chicago, IL 60606-2016</city><country>US</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR918172330" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>LARSEN TY</last-name><address><country>US</country></address></addressbook></inventor><inventor mxw-id="PPAR918139346" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>LARSEN, TY</last-name></addressbook></inventor><inventor mxw-id="PPAR918991634" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>LARSEN, TY</last-name><address><street>5732 East Drive</street><city>Everett, WA 98203</city><country>US</country></address></addressbook></inventor><inventor mxw-id="PPAR918133987" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>LIM EDWIN C</last-name><address><country>US</country></address></addressbook></inventor><inventor mxw-id="PPAR918139143" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>LIM, EDWIN C.</last-name></addressbook></inventor><inventor mxw-id="PPAR918985038" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>LIM, EDWIN C.</last-name><address><street>20113 Wood-Duvall Road</street><city>Everett, WA 98072</city><country>US</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR918982101" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Hylarides, Paul Jacques</last-name><suffix>et al</suffix><iid>100051584</iid><address><street>Arnold &amp; Siedsma Sweelinckplein 1</street><city>2517 GK The Hague</city><country>NL</country></address></addressbook></agent></agents></parties><international-convention-data><designated-states><ep-contracting-states><country mxw-id="DS548842972" load-source="docdb">AL</country><country mxw-id="DS548802203" load-source="docdb">AT</country><country mxw-id="DS548843298" load-source="docdb">BE</country><country mxw-id="DS548846109" load-source="docdb">BG</country><country mxw-id="DS548835743" load-source="docdb">CH</country><country mxw-id="DS548845417" load-source="docdb">CY</country><country mxw-id="DS548802204" load-source="docdb">CZ</country><country mxw-id="DS548843299" load-source="docdb">DE</country><country mxw-id="DS548845418" load-source="docdb">DK</country><country mxw-id="DS548845419" load-source="docdb">EE</country><country mxw-id="DS548843069" load-source="docdb">ES</country><country mxw-id="DS548801367" load-source="docdb">FI</country><country mxw-id="DS548846110" load-source="docdb">FR</country><country mxw-id="DS548843300" load-source="docdb">GB</country><country mxw-id="DS548845420" load-source="docdb">GR</country><country mxw-id="DS548843301" load-source="docdb">HR</country><country mxw-id="DS548802205" load-source="docdb">HU</country><country mxw-id="DS548835744" load-source="docdb">IE</country><country mxw-id="DS548845421" load-source="docdb">IS</country><country mxw-id="DS548846111" load-source="docdb">IT</country><country mxw-id="DS548845422" load-source="docdb">LI</country><country mxw-id="DS548801368" load-source="docdb">LT</country><country mxw-id="DS548842472" load-source="docdb">LU</country><country mxw-id="DS548801369" load-source="docdb">LV</country><country mxw-id="DS548801374" load-source="docdb">MC</country><country mxw-id="DS548842473" load-source="docdb">MK</country><country mxw-id="DS548842474" load-source="docdb">MT</country><country mxw-id="DS548843302" load-source="docdb">NL</country><country mxw-id="DS548846112" load-source="docdb">NO</country><country mxw-id="DS548801376" load-source="docdb">PL</country><country mxw-id="DS548835745" load-source="docdb">PT</country><country mxw-id="DS548843303" load-source="docdb">RO</country><country mxw-id="DS548835746" load-source="docdb">RS</country><country mxw-id="DS548801377" load-source="docdb">SE</country><country mxw-id="DS548843402" load-source="docdb">SI</country><country mxw-id="DS548846113" load-source="docdb">SK</country><country mxw-id="DS548801378" load-source="docdb">SM</country><country mxw-id="DS548845423" load-source="docdb">TR</country></ep-contracting-states><ep-extended-states><ep-extended-state-data><country>BA</country></ep-extended-state-data><ep-extended-state-data><country>ME</country></ep-extended-state-data></ep-extended-states></designated-states></international-convention-data></bibliographic-data><abstract mxw-id="PA128669781" lang="EN" load-source="patent-office"><p id="pa01" num="0001">A method and apparatus comprising a view generator. The view generator is configured to identify a position of a mobile display device relative to an exterior of a vehicle. The view generator is further configured to identify image data from a sensor system for the vehicle that corresponds to a field of view of the mobile display device from the position of the mobile display device relative to the vehicle. The view generator is further configured to display an external view for the vehicle on the mobile display device using the image data.
<img id="iaf01" file="imgaf001.tif" wi="165" he="95" img-content="drawing" img-format="tif"/></p></abstract><abstract mxw-id="PA128499154" lang="EN" source="EPO" load-source="docdb"><p>A method and apparatus comprising a view generator. The view generator is configured to identify a position of a mobile display device relative to an exterior of a vehicle. The view generator is further configured to identify image data from a sensor system for the vehicle that corresponds to a field of view of the mobile display device from the position of the mobile display device relative to the vehicle. The view generator is further configured to display an external view for the vehicle on the mobile display device using the image data.</p></abstract><description mxw-id="PDES63955211" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><heading id="h0001"><b>BACKGROUND INFORMATION</b></heading><heading id="h0002"><b>Field:</b></heading><p id="p0001" num="0001">The present disclosure relates generally to vehicles and, in particular, to displaying information about the exterior environment around a vehicle. Still more particularly, the present disclosure relates to a method and apparatus for displaying information about the exterior environment around the vehicle using a mobile device.</p><heading id="h0003"><b>Background:</b></heading><p id="p0002" num="0002">In operating vehicles, the operator of a vehicle typically looks through windows in the vehicle to see the environment around the vehicle. Depending on the design of the vehicle, the field of view provided by the windows in the vehicle may be more limited than desired. The field of view is the extent of the environment that can be seen at any given moment in time.</p><p id="p0003" num="0003">An aircraft is an example of a vehicle that may have a field of view that is limited. A pilot is currently only able to see a limited field of view from the windows in the flight deck of the aircraft. This field of view is sufficient during flight of the aircraft.</p><p id="p0004" num="0004">However, when the aircraft is on the ground, performing operations with the limited field of view from the windows in the flight deck of the aircraft may be more difficult than desired. For example, the view of the environment outside of the aircraft may make performing operations such as flight checks more difficult. For example, visual observations of the outside of the aircraft may be more difficult to make from the flight deck. As a result, some of the separation observations may need to be made by the pilot walking around the exterior of the aircraft or exiting the flight deck and looking through windows in the passenger cabin.</p><p id="p0005" num="0005">In another example, taxiing in the aircraft may be more challenging with the limited field of view from the windows in the flight deck of the aircraft. For example, with the field of view from the flight deck of the aircraft, seeing whether clearance is present for the wing of an aircraft with respect to a building or other structure may be difficult to perform.</p><p id="p0006" num="0006">Therefore, it would be desirable to have a method and apparatus that takes into account at least some of the issues discussed above, as well as other possible issues.</p><heading id="h0004"><b>SUMMARY</b></heading><p id="p0007" num="0007">In one illustrative embodiment, an apparatus comprises a view generator. The view generator is configured to identify a position of a mobile display device relative to an<!-- EPO <DP n="2"> --> exterior of a vehicle. The view generator is further configured to identify image data from a sensor system for the vehicle that corresponds to a field of view of the mobile display device from the position of the mobile display device relative to the vehicle. The view generator is further configured to display an external view for the vehicle on the mobile display device using the image data.</p><p id="p0008" num="0008">In another illustrative embodiment, an apparatus comprises a view generator. The view generator configured to identify a position of a mobile display device relative to an exterior of a location in a vehicle. The view generator is further configured to identify image data from a sensor system for the vehicle that corresponds to a field of view of the mobile display device from the position of the mobile display device relative to the exterior of the vehicle. The view generator is further configured to display an external view of the vehicle on the mobile display device using the image data.</p><p id="p0009" num="0009">In yet another illustrative embodiment, a method for displaying an external view of a vehicle is present. A position of a mobile display device is identified relative to an exterior of the vehicle. Image data is identified from a sensor system for the vehicle that corresponds to a field of view of the mobile display device from the position of the mobile display device. The external view for the vehicle is displayed on the mobile display device using the image data.</p><p id="p0010" num="0010">The features and functions can be achieved independently in various embodiments of the present disclosure or may be combined in yet other embodiments in which further details can be seen with reference to the following description and drawings.</p><p id="p0011" num="0011">According to an aspect of the present disclosure there is provided apparatus comprising: a view generator configured to identify a position of a mobile display device relative to an exterior of a vehicle; identify image data from a sensor system for the vehicle that corresponds to a field of view of the mobile display device from the position of the mobile display device relative to the vehicle; and display an external view for the vehicle on the mobile display device using the image data.</p><p id="p0012" num="0012">Advantageously the apparatus is further comprising a mobile display device. Advantageously the apparatus is further comprising a view generator configured to change the image data displayed on the mobile display device to display a current external view of the vehicle from the field of view of the mobile display device when the position of the mobile display device changes.</p><p id="p0013" num="0013">Advantageously the apparatus is further comprising a the view generator configured to select a camera in the sensor system generating the image data corresponding to the field of view of the mobile display device based on the position of the mobile display device.</p><p id="p0014" num="0014">Advantageously the apparatus is further comprising a view generator configured to receive sensor data corresponding to the field of view of the mobile display device from the<!-- EPO <DP n="3"> --> sensor system and generate information about the external view displayed on the mobile display device using the image data and present the information about the external view displayed on the mobile display device. Preferably the information presented is selected from at least one of a graphical indicator, a text, a video, a sound, an instruction, a caution, a guide, environmental information, and an object identifier. Preferably the information displayed on the external view displayed on the mobile display device forms an augmented reality of the external view of the vehicle.</p><p id="p0015" num="0015">Advantageously the apparatus is further comprising a sensor system associated with at least one of the vehicle, a number of objects, and another vehicle.</p><p id="p0016" num="0016">Advantageously the apparatus is further comprising a mobile display device in a location selected from one of an interior of the vehicle, a side of the vehicle, and an exterior of the vehicle.</p><p id="p0017" num="0017">Advantageously the apparatus is further comprising a mobile display device selected from one of a hand-held mobile display device, a mobile phone, a tablet computer, a laptop computer, a liquid crystal display, and an organic light emitting display.</p><p id="p0018" num="0018">According to a further aspect of the present disclosure there is provided an apparatus comprising: a view generator configured to identify a position of a mobile display device relative to an exterior of a location in a vehicle; identify image data from a sensor system for the vehicle that corresponds to a field of view of the mobile display device from the position of the mobile display device relative to the vehicle; and display an external view for the vehicle on the mobile display device using the image data.</p><p id="p0019" num="0019">Advantageously the exterior of the location in the vehicle is selected from one of another location in the vehicle not visible from the location and an environment outside of the vehicle.</p><p id="p0020" num="0020">According to a yet further aspect of the present disclosure there is provided a method for displaying an external view of a vehicle, the method comprising: identifying a position of a mobile display device relative to an exterior of the vehicle; identifying image data from a sensor system for the vehicle that corresponds to a field of view of the mobile display device from the position of the mobile display device; and displaying the external view for the vehicle on the mobile display device using the image data.</p><p id="p0021" num="0021">Advantageously the method is further comprising the step of identifying the field of view of the mobile display device at the position of the mobile display device, and<br/>
wherein displaying the image data on the mobile display device comprises: displaying the image data on the mobile display device with the field of view identified for the mobile display device.<!-- EPO <DP n="4"> --></p><p id="p0022" num="0022">Advantageously the method is further comprising the step of changing the external view displayed on the mobile display device to display a current external view of the vehicle from the field of view of the mobile display device when the position of the mobile display device changes. Advantageously the method is further comprising the step of<br/>
selecting a camera in the sensor system generating the image data corresponding to the field of view of the mobile display device based on the position of the mobile display device.</p><p id="p0023" num="0023">Advantageously the method is further comprising the steps of receiving sensor data corresponding to the field of view of the mobile display device from the sensor system; generating information about the external view displayed on the mobile display device using the image data; and presenting the information about the external view displayed on the mobile display device. Preferably the information presented is selected from at least one of a graphical indicator, a text, a video, a sound, an instruction, a caution, a guide, environmental information, and an object identifier.</p><p id="p0024" num="0024">Advantageously the method is further comprising a step wherein the mobile display device is in a location selected from one of an interior of the vehicle, a side of the vehicle, and the exterior of the vehicle.</p><p id="p0025" num="0025">Advantageously the method is further comprising a step wherein the sensor system is associated with at least one of the vehicle, a number of objects, and another vehicle.</p><p id="p0026" num="0026">Advantageously the method is further comprising a step wherein the vehicle is selected from one of an aircraft, a surface ship, a tank, a personnel carrier, a train, a spacecraft, a submarine, a bus, and an automobile.</p><p id="p0027" num="0027">Advantageously the method is further comprising a step wherein the mobile display device is selected from one of a hand-held mobile display device, a mobile phone, a tablet computer, a laptop computer, a liquid crystal display, and an organic light emitting display.</p><heading id="h0005"><b>BRIEF DESCRIPTION OF THE DRAWINGS</b></heading><p id="p0028" num="0028">The novel features believed characteristic of the illustrative embodiments are set forth in the appended claims. The illustrative embodiments, however, as well as a preferred mode of use, further objectives and features thereof, will best be understood by reference to the following detailed description of an illustrative embodiment of the present disclosure when read in conjunction with the accompanying drawings, wherein:
<ul><li><figref idrefs="f0001"><b>Figure 1</b></figref> is an illustration of an aircraft in accordance with an illustrative embodiment;<!-- EPO <DP n="5"> --></li><li><figref idrefs="f0002"><b>Figure 2</b></figref> is an illustration of a block diagram of a display environment in accordance with an illustrative embodiment;</li><li><figref idrefs="f0003"><b>Figure 3</b></figref> is an illustration of a block diagram of a sensor system in accordance with an illustrative embodiment;</li><li><figref idrefs="f0003"><b>Figure 4</b></figref> is an illustration of a data packet in accordance with an illustrative embodiment;</li><li><figref idrefs="f0004"><b>Figure 5</b></figref> is an illustration of a block diagram of a display environment in accordance with an illustrative embodiment;</li><li><figref idrefs="f0005"><b>Figure 6</b></figref> is an illustration of a block diagram of a display environment in accordance with an illustrative embodiment;</li><li><figref idrefs="f0006"><b>Figure 7</b></figref> is an illustration of positioning of a mobile display device in accordance with an illustrative embodiment;</li><li><figref idrefs="f0007"><b>Figure 8</b></figref> is an illustration of a sensor system associated with an aircraft in accordance with an illustrative embodiment;</li><li><figref idrefs="f0008"><b>Figure 9</b></figref> is an illustration of a sensor system associated with an aircraft in accordance with an illustrative embodiment;</li><li><figref idrefs="f0009"><b>Figure 10</b></figref> is an illustration of a flight deck in an aircraft in accordance with an illustrative embodiment;</li><li><figref idrefs="f0010"><b>Figure 11</b></figref> is an illustration of a view within a flight deck in accordance with an illustrative embodiment;</li><li><figref idrefs="f0011"><b>Figure 12</b></figref> is an illustration of a view within a flight deck in accordance with an illustrative embodiment;</li><li><figref idrefs="f0012"><b>Figure 13</b></figref> is an illustration of a display environment in accordance with an illustrative embodiment;</li><li><figref idrefs="f0013"><b>Figure 14</b></figref> is an illustration of an external view displayed on a mobile display device in accordance with an illustrative embodiment;</li><li><figref idrefs="f0014"><b>Figure 15</b></figref> is an illustration of an external view displayed on a mobile display device in accordance with an illustrative embodiment;</li><li><figref idrefs="f0015"><b>Figure 16</b></figref> is an illustration of an external view displayed on a mobile display device in accordance with an illustrative embodiment;</li><li><figref idrefs="f0016"><b>Figure 17</b></figref> is an illustration of a flowchart of a process for displaying an external view of a vehicle in accordance with an illustrative embodiment;</li><li><figref idrefs="f0016"><b>Figure 18</b></figref> is an illustration of a flowchart of a process for identifying image data for displaying an external view for a vehicle in accordance with an illustrative embodiment;<!-- EPO <DP n="6"> --></li><li><figref idrefs="f0017"><b>Figure 19</b></figref> is an illustration of a flowchart of a process for installing a viewing application to display an external view for a vehicle in accordance with an illustrative embodiment;</li><li><figref idrefs="f0017"><b>Figure 20</b></figref> is an illustration of a flowchart of a process for displaying an external view for a vehicle in accordance with an illustrative embodiment;</li><li><figref idrefs="f0018"><b>Figure 21</b></figref> is an illustration of a data processing system in accordance with an illustrative embodiment;</li><li><figref idrefs="f0019"><b>Figure 22</b></figref> is an illustration of an aircraft manufacturing and service method in accordance with an illustrative embodiment; and</li><li><figref idrefs="f0019"><b>Figure 23</b></figref> is an illustration of an aircraft in which an illustrative embodiment may be implemented.</li></ul></p><heading id="h0006"><b>DETAILED DESCRIPTION</b></heading><p id="p0029" num="0029">The illustrative embodiments recognize and take into account one or more different considerations. For example, the illustrative embodiments recognize and take into account that sensor systems may be used on an aircraft to provide additional information about the environment around the aircraft.</p><p id="p0030" num="0030">The illustrative embodiments also recognize and take into account that cameras may be associated with the aircraft to provide information to the pilot of the aircraft. Information in the form of images, such as those in a video, are displayed on a display device in the aircraft.</p><p id="p0031" num="0031">The illustrative embodiments recognize and take into account that the display of video on a display device may not provide a desired perspective for the pilot. Further, the display device provides a fixed field of view that may not provide as much information as desired to the pilot.</p><p id="p0032" num="0032">Thus, the illustrative embodiments provide a method and apparatus for displaying an external view of a vehicle such as an aircraft. A position of a mobile display device relative to an exterior of the vehicle is identified. Image data from a sensor system for the vehicle that corresponds to a field of view of the mobile display device from the position of the mobile display device is identified. An external view from the vehicle is displayed on the mobile display device using the image data.</p><p id="p0033" num="0033">In this manner, image data such as a video feed from a camera may be displayed from the mobile display device. As the position of the mobile display device changes, video feeds from other cameras may be displayed on the mobile display device. In other words, the mobile display device may provide a view as if the mobile display device were a window from the interior of the vehicle to the exterior of the vehicle.<!-- EPO <DP n="7"> --></p><p id="p0034" num="0034">With reference now to the figures and, in particular, with reference to <figref idrefs="f0001"><b>Figure 1</b></figref><b>,</b> an illustration of an aircraft is depicted in accordance with an illustrative embodiment. In this illustrative example, aircraft <b>100</b> has wing <b>102</b> and wing <b>104</b> attached to body <b>106.</b> Aircraft <b>100</b> includes engine <b>108</b> attached to wing <b>102</b> and engine <b>110</b> attached to wing <b>104.</b></p><p id="p0035" num="0035">Body <b>106</b> has tail section <b>112.</b> Horizontal stabilizer <b>114,</b> horizontal stabilizer <b>116,</b> and vertical stabilizer <b>118</b> are attached to tail section <b>112</b> of body <b>106.</b></p><p id="p0036" num="0036">Aircraft <b>100</b> is an example of an aircraft in which a display system may be implemented in accordance with an illustrative embodiment. In these illustrative examples, aircraft <b>100</b> has field of view <b>120</b> from windows <b>122</b> for flight deck <b>124</b> of aircraft <b>100.</b></p><p id="p0037" num="0037">A display system may be used to extend field of view <b>120</b> for a pilot in flight deck <b>124.</b> The display system may provide a larger field of view without relying on adding additional windows for flight deck <b>124.</b></p><p id="p0038" num="0038">With the extended field of view, other portions of the environment outside of flight deck <b>124</b> may be seen by the pilot. For example, the pilot may be able to view wing <b>102,</b> engine <b>110,</b> vertical stabilizer <b>118,</b> and other portions of aircraft <b>100.</b> Additionally, the pilot also may be able to see objects such as operators on the ground, ground vehicles, buildings, and other structures around aircraft <b>100.</b></p><p id="p0039" num="0039">Turning now to <figref idrefs="f0002"><b>Figure 2</b></figref><b>,</b> an illustration of a block diagram of a display environment is depicted in accordance with an illustrative embodiment. In this illustrative example, display environment <b>200</b> includes vehicle <b>202.</b> Vehicle <b>202</b> may be aircraft <b>100</b> in <figref idrefs="f0001"><b>Figure 1</b></figref><b>.</b> As depicted, vehicle display system <b>204</b> may be used with vehicle <b>202</b> to increase how much of external environment <b>206</b> around vehicle <b>202</b> may be seen by operator <b>208</b> of vehicle <b>202.</b></p><p id="p0040" num="0040">In these illustrative examples, vehicle display system <b>204</b> includes view generator <b>210,</b> mobile display device <b>212,</b> and sensor system <b>214.</b> View generator <b>210</b> may be implemented in software, hardware, or a combination of the two. When software is used, the operations performed by view generator <b>210</b> may be implemented in the program code configured to be run on a processor unit. When hardware is employed, the hardware may include circuits that operate to perform the operations in view generator <b>210.</b></p><p id="p0041" num="0041">In the illustrative examples, the hardware may take the form of a circuit system, an integrated circuit, an application specific integrated circuit (ASIC), a programmable logic device, or some other suitable type of hardware configured to perform a number of operations. With a programmable logic device, the device is configured to perform the number of operations. The device may be reconfigured at a later time or may be permanently configured to perform the number of operations. Examples of programmable logic devices include, for example, a programmable logic array, a programmable array logic, a field programmable logic array, a field<!-- EPO <DP n="8"> --> programmable gate array, and other suitable hardware devices. Additionally, the processes may be implemented in organic components integrated with inorganic components and/or may be comprised entirely of organic components excluding a human being. For example, the processes may be implemented as circuits in organic semiconductors.</p><p id="p0042" num="0042">In this illustrative example, view generator <b>210</b> may be implemented in computer system <b>216.</b> Computer system <b>216</b> is comprised of one or more computers. When more than one computer is present, those computers may be in communication with each other through a communications medium such as a network.</p><p id="p0043" num="0043">Mobile display device <b>212</b> is a hardware device and may include software that runs on mobile display device <b>212.</b> For example, the software may include viewing application <b>217.</b> In these illustrative examples, mobile display device <b>212</b> may be, for example, selected from one of a hand-held mobile display device, a mobile phone, a tablet computer, a laptop computer, a liquid crystal display, an organic light emitting display, and other suitable devices configured to display information.</p><p id="p0044" num="0044">Sensor system <b>214</b> is a hardware system that may include software. Sensor system <b>214</b> is configured to generate sensor data <b>218</b> about external environment <b>206</b> around vehicle <b>202.</b> Sensor data <b>218</b> may include image data <b>220.</b> Image data <b>220</b> may be images of external environment <b>206</b> around vehicle <b>202.</b></p><p id="p0045" num="0045">As depicted, sensor system <b>214</b> may be associated with vehicle <b>202,</b> number of objects <b>238,</b> or both vehicle <b>202</b> and number of objects <b>238.</b> Number of objects <b>238</b> is one or more objects in external environment <b>206</b> around vehicle <b>202.</b> In these illustrative examples, an object in number of objects <b>238</b> may be, for example, without limitation, a human operator, a truck, a cargo carrier, an airport ground support vehicle, an airport building, a gate, a barrier, a fence, a tower, or some other suitable object.</p><p id="p0046" num="0046">In this illustrative example, view generator <b>210</b> is configured to identify position <b>222</b> of mobile display device <b>212.</b> Position <b>222</b> is relative to exterior <b>224</b> of vehicle <b>202.</b> In this illustrative example, position <b>222</b> may include a location of mobile display device <b>212</b> in three-dimensional space and an orientation of mobile display device <b>212.</b></p><p id="p0047" num="0047">In this illustrative example, viewing application <b>217</b> may send position <b>222</b> from mobile display device <b>212</b> to view generator <b>210.</b> Based on position <b>222</b> of mobile display device <b>212,</b> view generator <b>210</b> is configured to identify image data <b>220</b> for vehicle <b>202</b> that corresponds to field of view <b>226</b> for mobile display device <b>212</b> from position <b>222</b> of mobile display device <b>212</b> relative to vehicle <b>202.</b> View generator <b>210</b> is configured to display external view <b>228</b> for vehicle <b>202</b> on mobile display device <b>212</b> using image data <b>220.</b></p><p id="p0048" num="0048">In this illustrative example, view generator <b>210</b> may display external view <b>228</b> for vehicle <b>202</b> on mobile display device <b>212</b> by sending image data stream <b>229</b> to mobile display<!-- EPO <DP n="9"> --> device <b>212.</b> When mobile display device <b>212</b> receives image data stream <b>229,</b> viewing application <b>217</b> displays external view <b>228</b> for vehicle <b>202</b> on mobile display device <b>212</b> using image data stream <b>229.</b></p><p id="p0049" num="0049">In other words, mobile display device <b>212</b> may act as a virtual window when mobile display device <b>212</b> is located in interior <b>230</b> of vehicle <b>202.</b> Mobile display device <b>212</b> also may act as a virtual window through vehicle <b>202</b> when mobile display device <b>212</b> is located on a side of vehicle <b>202</b> outside of vehicle <b>202.</b></p><p id="p0050" num="0050">When position <b>222</b> of mobile display device <b>212</b> changes, external view <b>228</b> displayed on mobile display device <b>212</b> is changed to display current external view <b>232</b> for vehicle <b>202</b> from field of view <b>226</b> of mobile display device <b>212</b> to reflect the change in position <b>222</b> of mobile display device <b>212.</b></p><p id="p0051" num="0051">When position <b>222</b> of mobile display device <b>212</b> changes, field of view <b>226</b> for mobile display device <b>212</b> may change. As a result, image data <b>220</b> corresponding to field of view <b>226</b> also may change such that image data <b>220</b> corresponds to the change in field of view <b>226.</b> In other words, image data <b>220</b> may be selected from different sensors <b>234</b> within sensor system <b>214.</b> In the illustrative examples, other types of sensor data <b>218</b> may be used in addition to or in place of image data <b>220</b> in sensor data <b>218</b> to generate image data stream <b>229.</b> In other words, sensor data <b>218</b> may be "fused" such that image data stream <b>229</b> includes information generated from multiple sensors of the same type, different type, or of both the same type and different type from sensors <b>234</b> in sensor system <b>214.</b></p><p id="p0052" num="0052">Additionally, view generator <b>210</b> also may receive sensor data <b>218</b> from sensor system <b>214.</b> Sensor data <b>218</b> may include different data from image data <b>220.</b> Sensor data <b>218</b> may be used to identify information <b>236</b> about external view <b>228</b> of vehicle <b>202.</b> Information <b>236</b> may be information about at least one of vehicle <b>202</b> or number of objects <b>238</b> in external environment <b>206</b> around vehicle <b>202.</b> In these illustrative examples, information <b>236</b> may be selected from at least one of a graphical indicator, a text, a video, a sound, an instruction, a caution, a guide, environmental information, an object identifier, and/or other types of information.</p><p id="p0053" num="0053">As used herein, the phrase "at least one of", when used with a list of items, means different combinations of one or more of the listed items may be used and only one of each item in the list may be needed. For example, "at least one of item A, item B, and item C" may include, without limitation, item A or item A and item B. This example also may include item A, item B, and item C, or item B and item C. In other examples, "at least one of" may be, for example, without limitation, two of item A, one of item B, and ten of item C; four of item B and seven of item C; and other suitable combinations.<!-- EPO <DP n="10"> --></p><p id="p0054" num="0054">Information <b>236</b> may be presented along with external view <b>228</b> displayed on mobile display device <b>212.</b> The presentation of information <b>236</b> may be made audibly, visually, tactilely, or some combination thereof. Information <b>236</b> is used to provide augmented reality <b>240</b> to operator <b>208</b> in these illustrative examples. In other words, a view of external environment <b>206</b> may be provided in which elements in external environment <b>206</b> are augmented by additional output such as sound, video, graphical indicators, text, and other types of output.</p><p id="p0055" num="0055">In this manner, vehicle display system <b>204</b> may be used by operator <b>208</b> to obtain more information about external environment <b>206</b> than currently possible through using windows or other types of portals in vehicle <b>202.</b> Further, with the different illustrative embodiments, vehicle display system <b>204</b> also may provide augmented reality <b>240</b> to operator <b>208.</b> With augmented reality <b>240,</b> information such as information <b>236</b> may be presented along with image data <b>220</b> to provide better situational awareness of external environment <b>206</b> around vehicle <b>202.</b></p><p id="p0056" num="0056">Turning now to <figref idrefs="f0003"><b>Figure 3</b></figref><b>,</b> an illustration of a block diagram of a sensor system is depicted in accordance with an illustrative embodiment. In this figure, examples of components used in sensor system <b>214</b> in <figref idrefs="f0002"><b>Figure 2</b></figref> are illustrated.</p><p id="p0057" num="0057">As depicted, sensor system <b>214</b> includes at least one of visible light camera <b>300,</b> infrared camera <b>302,</b> ultrasonic sensor <b>304,</b> ice detector <b>306,</b> global positioning system <b>308,</b> and other suitable components. One or more of these components may be associated with vehicle <b>202.</b> In still other illustrative examples, one or more of these components may be associated with number of objects <b>238.</b> In other words, sensor system <b>214</b> may not be located only on vehicle <b>202.</b></p><p id="p0058" num="0058">When one component is "associated" with another component, the association is a physical association in the depicted examples. For example, a first component, sensor system <b>214,</b> may be considered to be associated with a second component, vehicle <b>202,</b> by being secured to the second component, bonded to the second component, mounted to the second component, welded to the second component, fastened to the second component, and/or connected to the second component in some other suitable manner. The first component also may be connected to the second component using a third component. The first component may also be considered to be associated with the second component by being formed as part of and/or an extension of the second component.</p><p id="p0059" num="0059">Visible light camera <b>300</b> may generate image data <b>220.</b> In these illustrative examples, image data <b>220</b> may be individual images, a video data stream, or some combination thereof. Image data <b>220</b> may be, for example, images of external environment <b>206</b> around vehicle <b>202.</b> In other illustrative examples, image data <b>220</b> may include images for vehicle <b>202.</b></p><p id="p0060" num="0060">Visible light camera <b>300</b> may include various optics and may provide a level of resolution that allows for zooming in on various objects that provide a desired level of detail. This<!-- EPO <DP n="11"> --> desired level of detail may be provided without having to change the position of visible light camera <b>300.</b> In other illustrative examples, the optics may include a zoom lens for changing the level of optical detail.</p><p id="p0061" num="0061">Infrared camera <b>302</b> also may generate image data <b>220.</b> Image data <b>220</b> may include images of external environment <b>206,</b> vehicle <b>202,</b> or some combination thereof. Further, image data <b>220</b> also may be used to identify information about vehicle <b>202,</b> number of objects <b>238</b> in external environment <b>206,</b> or a combination thereof. This information may include, for example, temperatures of vehicle <b>202,</b> number of objects <b>238,</b> or some combination thereof. This temperature may be used to generate information <b>236</b> for augmented reality <b>240.</b> This combination of data is another example of how information may be combined or "fused" in image data stream <b>229</b> to provide external view <b>228</b> on mobile display device <b>212</b> in <figref idrefs="f0002"><b>Figure 2</b></figref><b>.</b></p><p id="p0062" num="0062">Ultrasonic sensor <b>304</b> may provide sensor data <b>218.</b> For example, ultrasonic sensor <b>304</b> may indicate a presence of an object in number of objects <b>238,</b> a distance to an object in number of objects <b>238,</b> or both. The presence of number of objects <b>238</b> and the distance to number of objects <b>238</b> may be used to generate information <b>236</b> for augmented reality <b>240.</b></p><p id="p0063" num="0063">Ice detector <b>306</b> may generate information about a presence of ice on exterior <b>224</b> of vehicle <b>202.</b> Whether ice is present on exterior <b>224</b> may be used to generate information <b>236</b> for augmented reality <b>240.</b></p><p id="p0064" num="0064">Global positioning system <b>308</b> generates information about the position of objects such as mobile display device <b>212,</b> sensor system <b>214,</b> number of objects <b>238,</b> or some combination thereof. The position of mobile display device <b>212</b> as well as the position of sensor system <b>214</b> may be used to identify field of view <b>226</b> for mobile display device <b>212.</b> The position of number of objects <b>238</b> may be used to form information <b>236</b> for augmented reality <b>240.</b> The position of sensor system <b>214</b> may aid in identifying what the image should look like when displayed on mobile display device <b>212.</b></p><p id="p0065" num="0065">The illustrations of sensors that may be used in sensor system <b>214</b> in <figref idrefs="f0003"><b>Figure 3</b></figref> are only meant as examples. These examples are not intended to limit the types of number of sensors that may be used to implement sensors <b>234</b> in sensor system <b>214</b> in <figref idrefs="f0002"><b>Figure 2</b></figref><b>.</b> For example, other types of sensors may be used in addition to or in place of the ones illustrated in <figref idrefs="f0003"><b>Figure 3</b></figref><b>.</b> Some other non-limiting examples include a laser radar system, an inertial measurement unit, a radio frequency sensor, an optical sensor, and other suitable types of sensors.</p><p id="p0066" num="0066">With reference now to <figref idrefs="f0003"><b>Figure 4</b></figref><b>,</b> an illustration of a data packet is depicted in accordance with an illustrative embodiment. Data packet <b>400</b> is an example of a data packet that may be in image data <b>220</b> in <figref idrefs="f0002"><b>Figure 2</b></figref><b>.</b></p><p id="p0067" num="0067">As depicted, data packet <b>400</b> includes image data <b>402,</b> position <b>404,</b> distance data <b>406,</b> field of view <b>408,</b> installed optics <b>410,</b> unique equipment identifier <b>412,</b> and other suitable<!-- EPO <DP n="12"> --> types of information. Image data <b>402</b> is one or more images generated by a camera. This image data may be for visible or non-visible light detected by the camera.</p><p id="p0068" num="0068">Position <b>404</b> is the position of the camera generating data packet <b>400.</b> In this illustrative example, position <b>404</b> may include a location in three-dimensions and an orientation of the camera. Distance data <b>406</b> may indicate a distance to one or more objects in image data <b>402.</b> Distance data <b>406</b> also may indicate a range of distances, such as a grid, within the field of view of the camera. This object may be, for example, without limitation, an aircraft, a building, a human operator, a ground vehicle, and other suitable objects.</p><p id="p0069" num="0069">Field of view <b>408</b> indicates a field of view of the camera. Installed optics <b>410</b> may indicate different capabilities for the camera. For example, installed optics <b>410</b> may indicate whether a zoom lens is present in the camera. Unique equipment identifier <b>412</b> is a unique identifier for the camera.</p><p id="p0070" num="0070">The illustration of vehicle display system <b>204</b> in <figref idrefs="f0002"><b>Figure 2</b></figref> and the different components in <figref idrefs="f0003"><b>Figure 3</b> and <b>Figure 4</b></figref> are not meant to imply limitations to the manner in which an illustrative embodiment may be implemented. Other components in addition to or in place of the ones illustrated may be used. Some components may be unnecessary. Also, the blocks are presented to illustrate some functional components. One or more of these blocks may be combined, divided, or combined and divided into different blocks when implemented in an illustrative embodiment.</p><p id="p0071" num="0071">For example, although the illustrative examples are described with respect to an aircraft, an illustrative embodiment may be applied to other vehicles other than aircraft. These other vehicles may include, for example, without limitation, a submarine, a personnel carrier, a tank, a train, an automobile, a bus, a spacecraft, a surface ship, and other suitable vehicles.</p><p id="p0072" num="0072">In still another illustrative example, view generator <b>210</b> may be configured to identify position <b>222</b> of mobile display device <b>212</b> relative to an exterior of a location in vehicle <b>202.</b> This location exterior to the location in vehicle <b>202</b> may be another location inside of vehicle <b>202</b> not visible to operator <b>208</b> from the location inside of vehicle <b>202.</b> For example, the location of operator <b>208</b> may be the flight deck of an aircraft. The other location may be, for example, a passenger cabin, a cargo area, or some other location within the aircraft.</p><p id="p0073" num="0073">Turning now to <figref idrefs="f0004"><b>Figure 5</b></figref><b>,</b> an illustration of a block diagram of a display environment is depicted in accordance with an illustrative embodiment. In this depicted example, an example of an implementation of display environment <b>200</b> in <figref idrefs="f0002"><b>Figure 2</b></figref> is shown. As depicted, display environment <b>500</b> may be implemented in aircraft <b>502.</b></p><p id="p0074" num="0074">In this depicted example, computer system <b>504</b> is located in aircraft <b>502.</b> Computer system <b>504</b> includes view generator <b>506</b> and application server <b>508.</b> Computer system <b>504</b> also may include other hardware or software components used to operate aircraft <b>502.</b><!-- EPO <DP n="13"> --></p><p id="p0075" num="0075">In this illustrative example, mobile display device <b>510</b> may download viewing application <b>512</b> from application server <b>508</b> over wireless communications link <b>513.</b></p><p id="p0076" num="0076">Viewing application <b>512</b> is software configured to display external views for aircraft <b>502</b> using image data stream <b>514</b> generated by view generator <b>506.</b> Viewing application <b>512</b> may be sent by application server <b>508</b> to mobile display device <b>510</b> for use in displaying image data stream <b>514</b> on mobile display device <b>510.</b> In these illustrative examples, view generator <b>506</b> receives image data <b>516</b> from cameras <b>518</b> on aircraft <b>502.</b></p><p id="p0077" num="0077">View generator <b>506</b> generates image data stream <b>514</b> based on position <b>520</b> received for mobile display device <b>510</b> over wireless communications link <b>513.</b> In these illustrative examples, image data stream <b>514</b> is sent to mobile display device <b>510</b> over wireless communications link <b>513.</b></p><p id="p0078" num="0078">Turning now to <figref idrefs="f0005"><b>Figure 6</b></figref><b>,</b> an illustration of a block diagram of a display environment is depicted in accordance with an illustrative embodiment. In this depicted example, an example of an implementation of display environment <b>200</b> in <figref idrefs="f0002"><b>Figure 2</b></figref> is shown.</p><p id="p0079" num="0079">In this illustrative example, display environment <b>600</b> includes airport computer system <b>602</b> and aircraft <b>604</b> at airport <b>605.</b> View generator <b>606</b> and application server <b>608</b> are located in airport computer system <b>602.</b></p><p id="p0080" num="0080">As depicted, view generator <b>606</b> is located in airport computer system <b>602</b> rather than aircraft computer system <b>610</b> in this illustrative example. With this implementation, viewing the external environment around aircraft <b>604</b> occurs when aircraft <b>604</b> is on the ground at airport <b>605.</b> In this manner, less computing resources may be needed from aircraft computer system <b>610.</b></p><p id="p0081" num="0081">As depicted, aircraft computer system <b>610</b> receives image data <b>612</b> from cameras <b>614</b> on aircraft <b>604.</b> Image data <b>612</b> may be sent to view generator <b>606</b> in airport computer system <b>602</b> over wireless communications link <b>616.</b></p><p id="p0082" num="0082">Additionally, view generator <b>606</b> also may receive image data <b>618</b> from cameras <b>620.</b> Cameras <b>620</b> may be located on different objects or structures such as ground vehicles, a terminal, a tower, or other suitable structures.</p><p id="p0083" num="0083">In these illustrative examples, view generator <b>606</b> generates image data stream <b>622</b> and sends image data stream <b>622</b> to mobile display device <b>624</b> in aircraft <b>604</b> over wireless communications link <b>616.</b> In this illustrative example, image data stream <b>622</b> may be displayed on mobile display device <b>624</b> using viewing application <b>626.</b> Viewing application <b>626</b> may be downloaded from application server <b>608</b> in airport computer system <b>602.</b> In this illustrative example, viewing application <b>626</b> may communicate with aircraft computer system <b>610</b> using communications link <b>628.</b></p><p id="p0084" num="0084">The illustration of example implementations for a display environment in <figref idrefs="f0004"><b>Figure 5</b></figref> and <figref idrefs="f0005"><b>Figure 6</b></figref> is not meant to imply limitations to the manner in which other illustrative<!-- EPO <DP n="14"> --> embodiments may be implemented. For example, in some illustrative examples, cameras may be present only at airport <b>605</b> and not on aircraft <b>604.</b> In this manner, existing aircraft that do not have cameras may still obtain external views on the aircraft without needing upgrades or refurbishing.</p><p id="p0085" num="0085">In still other illustrative examples, an application server may not be necessary. Instead, the viewing application may be preloaded onto a mobile display device. In another illustrative example, the different communications links may be secured through encryption or other mechanisms. In this manner, access to information sent across communications links may be restricted to those devices authorized to have access to the information.</p><p id="p0086" num="0086">Turning now to <figref idrefs="f0006"><b>Figure 7</b></figref><b>,</b> an illustration of positioning of a mobile display device is depicted in accordance with an illustrative embodiment. Mobile display device <b>700</b> is an example of a physical implementation for mobile display device <b>212</b> shown in block form in <figref idrefs="f0002"><b>Figure 2</b></figref><b>.</b></p><p id="p0087" num="0087">Mobile display device <b>700</b> takes the form of tablet computer <b>702</b> having display <b>704</b> on side <b>706</b> of tablet computer <b>702.</b> Position <b>708</b> of tablet computer <b>702</b> may be identified using a global positioning system and an accelerometer system within tablet computer <b>702.</b> The global positioning system may provide location <b>710</b> of tablet computer <b>702</b> in three-dimensional space. The accelerometer system may identify orientation <b>712</b> of tablet computer <b>702.</b> In these illustrative examples, orientation <b>712</b> may be direction <b>714</b> in which side <b>716</b> of tablet computer <b>702</b> faces.</p><p id="p0088" num="0088">In this illustrative example, tablet computer <b>702</b> has field of view <b>718.</b> Field of view <b>718</b> is based on orientation <b>712</b> in this illustrative example. Field of view <b>718</b> may be based on the size of display <b>704</b> or may be selected arbitrarily depending on the particular implementation.</p><p id="p0089" num="0089">In these illustrative examples, tablet computer <b>702</b> may be located within the interior of aircraft <b>100</b> in <figref idrefs="f0001"><b>Figure 1</b></figref><b>,</b> such as in flight deck <b>124.</b> In other illustrative examples, tablet computer <b>702</b> may be located on a side of aircraft <b>100.</b> In this manner, tablet computer <b>702</b> may provide a view of external environment <b>206</b> from flight deck <b>124</b> inside of aircraft <b>100.</b></p><p id="p0090" num="0090">For example, tablet computer <b>702</b> may be located on a side of aircraft <b>100</b> while an operator performs inspections. When located on a side of aircraft <b>100,</b> tablet computer <b>702</b> may display views of external environment <b>206</b> on the other side of aircraft <b>100.</b> In other words, tablet computer <b>702</b> may provide a virtual window through aircraft <b>100.</b></p><p id="p0091" num="0091">Turning now to <figref idrefs="f0007"><b>Figure 8</b></figref><b>,</b> an illustration of a sensor system associated with an aircraft is depicted in accordance with an illustrative embodiment. In this illustrative example, a top view of aircraft <b>100</b> with sensor system <b>800</b> is shown.<!-- EPO <DP n="15"> --></p><p id="p0092" num="0092">In particular, sensor system <b>800</b> includes cameras <b>802, 804, 806, 808</b> and <b>810.</b> Camera <b>802</b> has field of view <b>812,</b> camera <b>804</b> has field of view <b>814,</b> camera <b>806</b> has field of view <b>816,</b> camera <b>808</b> has field of view <b>818,</b> and camera <b>810</b> has field of view <b>820.</b></p><p id="p0093" num="0093">In <figref idrefs="f0008"><b>Figure 9</b></figref><b>,</b> an illustration of a sensor system associated with an aircraft is depicted in accordance with an illustrative embodiment. A perspective view of aircraft <b>100</b> is shown in this figure with field of views <b>812, 814, 816, 818,</b> and <b>820</b> generated by sensor system <b>800.</b></p><p id="p0094" num="0094">Each of the cameras associated with the field of views may generate video data of the exterior environment around aircraft <b>100.</b> This video data may be used to increase the field of view visible to an operator located within flight deck <b>124</b> of aircraft <b>100</b> beyond field of view <b>120.</b></p><p id="p0095" num="0095">Turning now to <figref idrefs="f0009"><b>Figure 10</b></figref><b>,</b> an illustration of a flight deck in an aircraft is depicted in accordance with an illustrative embodiment. In this illustrative example, a cross-sectional view of flight deck <b>124</b> is seen taken along lines <b>10-10</b> in <figref idrefs="f0001"><b>Figure 1</b></figref><b>.</b></p><p id="p0096" num="0096">In this illustrative example, operator <b>1000</b> may look in various directions such as directions <b>1002, 1004, 1006, 1008,</b> and <b>1010.</b> When operator <b>1000</b> looks in direction <b>1002,</b> operator <b>1000</b> may see the external environment outside of aircraft <b>100</b> through windows <b>122.</b> However, when operator <b>1000</b> looks in directions <b>1004, 1006, 1008,</b> and <b>1010,</b> the operator does not see the external environment outside of aircraft <b>100.</b> Aircraft structures <b>1012</b> inside flight deck <b>124</b> prevent operator <b>1000</b> from seeing the external environment outside of aircraft <b>100.</b></p><p id="p0097" num="0097">Views of the external environment outside of aircraft <b>100</b> in directions <b>1004, 1006, 1008,</b> and <b>1010</b> may be provided through mobile display device <b>700</b> in <figref idrefs="f0006"><b>Figure 7</b></figref><b>.</b> Mobile display device <b>700</b> in <figref idrefs="f0006"><b>Figure 7</b></figref> may display external views of the external environment around aircraft <b>100</b> in these directions.</p><p id="p0098" num="0098">Turning now to <figref idrefs="f0010"><b>Figure 11</b></figref><b>,</b> an illustration of a view within a flight deck is depicted in accordance with an illustrative embodiment. In this illustrative example, a view of flight deck <b>124</b> is shown in direction <b>1006.</b> As can be seen in this view, aircraft structures <b>1012</b> block a view of the external environment around aircraft <b>100</b> in direction <b>1006.</b></p><p id="p0099" num="0099">In this illustrative example, mobile display device <b>700</b> is pointed in direction <b>1006.</b> Display <b>704</b> on mobile display device <b>700</b> displays image data from sensor system <b>800</b> to display an external view for aircraft <b>100.</b> Mobile display device <b>700</b> provides a virtual window to operator <b>1000.</b> As mobile display device <b>700</b> is moved to different directions, the external view displayed on display <b>704</b> of mobile display device also may change to correspond to the external view that would be seen from the aircraft if a window was present.</p><p id="p0100" num="0100">Turning now to <figref idrefs="f0011"><b>Figure 12</b></figref><b>,</b> an illustration of a view within a flight deck is depicted in accordance with an illustrative embodiment. In this depicted example, a view from<!-- EPO <DP n="16"> --> direction <b>1010</b> is shown. In this view, aircraft structures <b>1012</b> block the view of the external environment around aircraft <b>100</b> in direction <b>1010.</b></p><p id="p0101" num="0101">Mobile display device <b>700</b> is pointed in direction <b>1010.</b> With mobile display device <b>700</b> pointed in this direction, the external view for aircraft <b>100</b> in direction <b>1010</b> may be seen on display <b>704.</b></p><p id="p0102" num="0102">Turning now to <figref idrefs="f0012"><b>Figure 13</b></figref><b>,</b> an illustration of a display environment is depicted in accordance with an illustrative embodiment. Display environment <b>1300</b> is an example of a physical implementation for display environment <b>200</b> in <figref idrefs="f0002"><b>Figure 2</b></figref><b>.</b> In this illustrative example, aircraft <b>100</b> is located at terminal <b>1302.</b> In particular, aircraft <b>100</b> is located at gate <b>1304</b> at terminal <b>1302.</b></p><p id="p0103" num="0103">In this illustrative example, sensor system <b>1306</b> includes sensor system <b>800</b> associated with aircraft <b>100.</b> Additionally, sensor system <b>1306</b> also includes sensor system <b>1308</b> associated with a number of objects at terminal <b>1302.</b> In this illustrative example, sensor system <b>1308</b> also includes camera <b>1310,</b> camera <b>1312,</b> and camera <b>1314.</b> Camera <b>1310</b> is associated with light pole <b>1316,</b> camera <b>1312</b> is associated with light pole <b>1318,</b> and camera <b>1314</b> is associated with ground service vehicle <b>1320.</b></p><p id="p0104" num="0104">Camera <b>1310</b> provides field of view <b>1322,</b> camera <b>1312</b> provides field of view <b>1324,</b> and camera <b>1314</b> provides field of view <b>1326.</b> These cameras provide additional image data that may be used to display the external environment around aircraft <b>100.</b> In other words, display <b>704</b> on mobile display device <b>700</b> may display views based on image data from at least one of sensor system <b>800</b> and sensor system <b>1308</b> in sensor system <b>1306.</b></p><p id="p0105" num="0105">The illustration of <figref idrefs="f0006 f0007 f0008 f0009 f0010 f0011 f0012"><b>Figures 7-13</b></figref> are not meant to limit the manner in which different illustrative embodiments may be implemented. The examples illustrated in these figures are provided as examples of physical implementations for components in vehicle display system <b>204</b> in <figref idrefs="f0002"><b>Figure 2</b></figref><b>.</b></p><p id="p0106" num="0106">For example, other numbers of cameras may be present on aircraft <b>100.</b> For example, seven cameras, ten cameras, or some other number of cameras may be associated with aircraft <b>100.</b> In still other illustrative examples, mobile display device <b>700</b> may be used outside of aircraft <b>100.</b> For example, operator <b>1000</b> may perform visual inspections outside of aircraft <b>100.</b> Mobile display device <b>700</b> may be used to provide a view through aircraft <b>100.</b> For example, operator <b>1000</b> may be on one side of aircraft <b>100</b> and may use mobile display device <b>700</b> to see the external view on the other side of aircraft <b>100</b> while performing inspections or other operations.</p><p id="p0107" num="0107">Turning now to <figref idrefs="f0013"><b>Figure 14</b></figref><b>,</b> an illustration of an external view displayed on a mobile display device is depicted in accordance with an illustrative embodiment. In this<!-- EPO <DP n="17"> --> illustrative example, display <b>1400</b> is an example of display <b>704</b> on mobile display device <b>700</b> in <figref idrefs="f0006"><b>Figure 7</b></figref><b>.</b></p><p id="p0108" num="0108">As depicted, external view <b>1401</b> displayed on display <b>1400</b> is generated using image data from one or more cameras associated with aircraft <b>100</b> or from cameras associated with other objects in the environment around aircraft <b>100.</b> External view <b>1401</b> is based on a position of mobile display device <b>700</b> within aircraft <b>100</b> in this illustrative example.</p><p id="p0109" num="0109">In this illustrative example, wing <b>102</b> of aircraft <b>100</b> is seen in the external view on display <b>1400.</b> Additionally, a number of objects such as airport building <b>1402</b> and operator <b>1404</b> also are shown in this view displayed on mobile display device <b>700.</b></p><p id="p0110" num="0110">Additionally, other information may be displayed in addition to wing <b>102,</b> airport building <b>1402,</b> and operator <b>1404.</b> In this illustrative example, the display of the external view <b>1401</b> for aircraft <b>100</b> may be augmented with graphical indicator <b>1406</b> and text <b>1408.</b> Graphical indicator <b>1406</b> identifies an area on ground <b>1410</b> in external view <b>1401.</b> Additionally, text <b>1408</b> provides an alert about the area. In this illustrative example, the alert indicates an engine threat for objects that may be present in the area identified by graphical indicator <b>1406.</b></p><p id="p0111" num="0111">Turning next to <figref idrefs="f0014"><b>Figure 15</b></figref><b>,</b> an illustration of an external view displayed on a mobile display device is depicted in accordance with an illustrative embodiment. In this illustrative example, display <b>1500</b> is an example of display <b>704</b> on mobile display device <b>700</b> in <figref idrefs="f0006"><b>Figure 7</b></figref><b>.</b></p><p id="p0112" num="0112">As depicted, external view <b>1501</b> displayed on display <b>1500</b> is generated using image data from one or more cameras associated with aircraft <b>100</b> or from cameras associated with other objects in the environment around aircraft <b>100.</b> External view <b>1501</b> is based on a position of mobile display device <b>700</b> within aircraft <b>100</b> in this illustrative example.</p><p id="p0113" num="0113">In this illustrative example, wing <b>102</b> and engine <b>108</b> for aircraft <b>100</b> are seen in external view <b>1501</b> on display <b>1500.</b> In this illustrative example, graphical indicator <b>1502</b> is displayed on portions of wing <b>102</b> and engine <b>108.</b> This graphical indicator indicates a presence of ice on these aircraft structures. The identification of ice may be made through sensors in a sensor system for the aircraft such as an ice detector, a color filter configured to increase shadow visibility, or some other suitable type of sensor.</p><p id="p0114" num="0114">Turning now to <figref idrefs="f0015"><b>Figure 16</b></figref><b>,</b> an illustration of an external view displayed on a mobile display device is depicted in accordance with an illustrative embodiment. In this illustrative example, a zoomed view of external view <b>1501</b> in <figref idrefs="f0014"><b>Figure 15</b></figref> is shown. In this manner, an operator may see more detail of a particular portion of external view <b>1501.</b> The selection of the portion may be based on the operator seeing graphical indicator <b>1502.</b> In this manner, the operator may make an additional inspection of wing <b>102.</b><!-- EPO <DP n="18"> --></p><p id="p0115" num="0115">The illustration of external views and information augmented in the external views in <figref idrefs="f0013 f0014 f0015"><b>Figures 14-16</b></figref> are only provided as some example implementations of information that may be displayed on a mobile display device. These examples are not meant to limit the manner in which other displays of external views may be implemented.</p><p id="p0116" num="0116">In other illustrative examples, the external view may be displayed from more than one view point depending on the particular implementation. For example, the external view displayed may be from a camera having a field of view corresponding to the field of view for the mobile display device. Another camera may provide image data for objects in the field of view for the mobile display device, but may be located from another view point. In other words, the objects in the field of view of the mobile display device may be displayed using image data from cameras that may show the same objects but from different viewpoints.</p><p id="p0117" num="0117">Thus, the image data from these two different cameras may provide image data that corresponds to a field of view of the mobile display device in these illustrative examples. In other words, the "virtual window" provided by the mobile display device may not correspond exactly to a window at that direction pointed to by the mobile display device. However, the external view displayed includes image data to show the objects that would be seen from that direction.</p><p id="p0118" num="0118">In some illustrative examples, a modeling program may be used to generate three-dimensional information about different objects such as an aircraft, an airport, vehicles, and other suitable objects. The three-dimensional information may be used to include these objects in an image data stream displayed on a mobile display device when image data is not available for these objects from a sensor system. In this manner, a scene of objects in the field of view may be recreated more accurately than possible with just image data from cameras in the sensor system.</p><p id="p0119" num="0119">With reference now to <figref idrefs="f0016"><b>Figure 17</b></figref><b>,</b> an illustration of a flowchart of a process for displaying an external view of a vehicle is depicted in accordance with an illustrative embodiment. This process may be implemented in display environment <b>200</b> in <figref idrefs="f0002"><b>Figure 2</b></figref><b>.</b> In particular, this process may be implemented using view generator <b>210</b> in <figref idrefs="f0002"><b>Figure 2</b></figref><b>.</b></p><p id="p0120" num="0120">The process begins by identifying a position of a mobile display device relative to an exterior of the vehicle (operation <b>1700).</b> The process then identifies image data from a sensor system for the vehicle that corresponds to a field of view of the mobile display device from the position of the mobile display device (operation <b>1702).</b></p><p id="p0121" num="0121">The process displays an external view for the vehicle on the mobile display device using the image data (operation <b>1704)</b> with the process returning to operation <b>1700.</b> The process may continue in this fashion until the view is no longer needed by the operator. In this illustrative example, the view generator may cause the display of the external view on the mobile display device by sending an image data stream of the external view to the mobile display device.<!-- EPO <DP n="19"> --></p><p id="p0122" num="0122">Turning now to <figref idrefs="f0016"><b>Figure 18</b></figref><b>,</b> an illustration of a flowchart of a process for identifying image data for displaying an external view for a vehicle is depicted in accordance with an illustrative embodiment. This process is an example of an implementation for operation <b>1702</b> in <figref idrefs="f0016"><b>Figure 17</b></figref><b>.</b></p><p id="p0123" num="0123">The process begins by identifying a position of the mobile display device (operation <b>1800).</b> Thereafter, the process identifies a field of view for the mobile display device at the position (operation <b>1802).</b> This field of view identifies what objects may be seen based on the position of the mobile display device.</p><p id="p0124" num="0124">Thereafter, the process identifies image data that corresponds to the field of view of the mobile display device at the position (operation <b>1804),</b> with the process terminating thereafter. In operation <b>1804,</b> the image data may be image data generated by a camera having a field of view closest to the mobile display device. This identification may be made by identifying a camera with a position closest to the mobile display device.</p><p id="p0125" num="0125">In other illustrative examples, the correspondence to the field of view for the mobile display device may be made by identifying image data having substantially the same objects in the field of view of the mobile display device. In some illustrative examples, different structures in the flight deck may be used by the mobile display device to identify its orientation within the aircraft. For example, structures such as windows, a door, a display, and other structures may be used by the mobile display device to identify its position within the flight deck or other location within the aircraft.</p><p id="p0126" num="0126">Turning now to <figref idrefs="f0017"><b>Figure 19</b></figref><b>,</b> an illustration of a flowchart of a process for installing a viewing application to display an external view for a vehicle is depicted in accordance with an illustrative embodiment. The process illustrated in <figref idrefs="f0017"><b>Figure 19</b></figref> may be implemented using mobile display device <b>212</b> in <figref idrefs="f0002"><b>Figure 2</b></figref><b>.</b></p><p id="p0127" num="0127">The process begins by establishing a communications link to an aircraft computer system (operation <b>1900).</b> The process requests a number of applications from the aircraft computer system (operation <b>1902).</b> In this illustrative example, the mobile display device may be a tablet computer on which an application may be loaded for use in performing operations to manage the vehicle or obtain information about the vehicle. In this illustrative example, one of the applications may include viewing application <b>217.</b> The particular applications requested in operation <b>1902</b> may be based on user input from an operator or may be a pre-defined request.</p><p id="p0128" num="0128">The process receives and installs the number of applications on the mobile display device (operation <b>1904),</b> with the process terminating thereafter.</p><p id="p0129" num="0129">With reference now to <figref idrefs="f0017"><b>Figure 20</b></figref><b>,</b> an illustration of a flowchart of a process for displaying an external view for a vehicle is depicted in accordance with an illustrative embodiment. The process illustrated in <figref idrefs="f0017"><b>Figure 20</b></figref> may be implemented using mobile display<!-- EPO <DP n="20"> --> device <b>212</b> in <figref idrefs="f0002"><b>Figure 2</b></figref><b>.</b> In these illustrative examples, this process may be implemented in viewing application <b>217</b> in <figref idrefs="f0002"><b>Figure 2</b></figref><b>.</b></p><p id="p0130" num="0130">The process begins by identifying a position of the mobile display device (operation <b>2000).</b> The position may include a three-dimensional location and an orientation of the mobile display device. The position data about the mobile display device is sent to a view generator (operation <b>2002).</b></p><p id="p0131" num="0131">Thereafter, an image data stream is received (operation <b>2004).</b> This image data stream may include one or more images. The process displays an external view for the vehicle using the image data (operation <b>2006).</b> The process then returns to operation <b>2000</b> until the viewing application is terminated.</p><p id="p0132" num="0132">The flowcharts and block diagrams in the different depicted embodiments illustrate the architecture, functionality, and operation of some possible implementations of apparatus and methods in an illustrative embodiment. In this regard, each block in the flowcharts or block diagrams may represent a module, segment, function, and/or a portion of an operation or step. For example, one or more of the blocks may be implemented as program code, in hardware, or a combination of the program code and hardware. When implemented in hardware, the hardware may, for example, take the form of integrated circuits that are manufactured or configured to perform one or more operations in the flowcharts or block diagrams.</p><p id="p0133" num="0133">In some alternative implementations of an illustrative embodiment, the function or functions noted in the blocks may occur out of the order noted in the figures. For example, in some cases, two blocks shown in succession may be executed substantially concurrently, or the blocks may sometimes be performed in the reverse order, depending upon the functionality involved. Also, other blocks may be added in addition to the illustrated blocks in a flowchart or block diagram.</p><p id="p0134" num="0134">Turning now to <figref idrefs="f0018"><b>Figure 21</b></figref><b>,</b> an illustration of a data processing system is depicted in accordance with an illustrative embodiment. Data processing system <b>2100</b> may be used to implement computer system <b>216,</b> mobile display device <b>212,</b> mobile display device <b>700,</b> airport computer system <b>602,</b> aircraft computer system <b>610,</b> and computer system <b>504,</b> as well as other computers or devices that may process data or other information.</p><p id="p0135" num="0135">In this illustrative example, data processing system <b>2100</b> includes communications framework <b>2102,</b> which provides communications between processor unit <b>2104,</b> memory <b>2106,</b> persistent storage <b>2108,</b> communications unit <b>2110,</b> input/output (I/O) unit <b>2112,</b> display <b>2114,</b> and sensor system <b>2115.</b> In this example, communication framework may take the form of a bus system.<!-- EPO <DP n="21"> --></p><p id="p0136" num="0136">Processor unit <b>2104</b> serves to execute instructions for software that may be loaded into memory <b>2106.</b> Processor unit <b>2104</b> may be a number of processors, a multi-processor core, or some other type of processor, depending on the particular implementation.</p><p id="p0137" num="0137">Memory <b>2106</b> and persistent storage <b>2108</b> are examples of storage devices <b>2116.</b> A storage device is any piece of hardware that is capable of storing information, such as, for example, without limitation, data, program code in functional form, and/or other suitable information either on a temporary basis and/or a permanent basis. Storage devices <b>2116</b> may also be referred to as computer readable storage devices in these illustrative examples. Memory <b>2106,</b> in these examples, may be, for example, a random access memory or any other suitable volatile or non-volatile storage device. Persistent storage <b>2108</b> may take various forms, depending on the particular implementation.</p><p id="p0138" num="0138">For example, persistent storage <b>2108</b> may contain one or more components or devices. For example, persistent storage <b>2108</b> may be a hard drive, a flash memory, a rewritable optical disk, a rewritable magnetic tape, or some combination of the above. The media used by persistent storage <b>2108</b> also may be removable. For example, a removable hard drive may be used for persistent storage <b>2108.</b></p><p id="p0139" num="0139">Communications unit <b>2110,</b> in these illustrative examples, provides for communications with other data processing systems or devices. In these illustrative examples, communications unit <b>2110</b> is a network interface card.</p><p id="p0140" num="0140">Input/output unit <b>2112</b> allows for input and output of data with other devices that may be connected to data processing system <b>2100.</b> For example, input/output unit <b>2112</b> may provide a connection for user input through a keyboard, a mouse, touch screen, and/or some other suitable input device. Further, input/output unit <b>2112</b> may send output to a printer. Display <b>2114</b> provides a mechanism to display information to a user.</p><p id="p0141" num="0141">Sensor system <b>2115</b> is configured to generate sensor data about data processing system <b>2100,</b> the environment around data processing system <b>2100,</b> or both. Sensor system <b>2115</b> may include, for example, at least one of a global positioning system, an accelerometer, a camera, and other suitable types of sensors.</p><p id="p0142" num="0142">Instructions for the operating system, applications, and/or programs may be located in storage devices <b>2116,</b> which are in communication with processor unit <b>2104</b> through communications framework <b>2102.</b> The processes of the different embodiments may be performed by processor unit <b>2104</b> using computer-implemented instructions, which may be located in a memory, such as memory <b>2106.</b></p><p id="p0143" num="0143">These instructions are referred to as program code, computer usable program code, or computer readable program code that may be read and executed by a processor in processor unit <b>2104.</b> The program code in the different embodiments may be embodied on<!-- EPO <DP n="22"> --> different physical or computer readable storage media, such as memory <b>2106</b> or persistent storage <b>2108.</b></p><p id="p0144" num="0144">Program code <b>2118</b> is located in a functional form on computer readable media <b>2120</b> that is selectively removable and may be loaded onto or transferred to data processing system <b>2100</b> for execution by processor unit <b>2104.</b> Program code <b>2118</b> and computer readable media <b>2120</b> form computer program product <b>2122</b> in these illustrative examples. In one example, computer readable media <b>2120</b> may be computer readable storage media <b>2124</b> or computer readable signal media <b>2126.</b></p><p id="p0145" num="0145">In these illustrative examples, computer readable storage media <b>2124</b> is a physical or tangible storage device used to store program code <b>2118</b> rather than a medium that propagates or transmits program code <b>2118.</b></p><p id="p0146" num="0146">Alternatively, program code <b>2118</b> may be transferred to data processing system <b>2100</b> using computer readable signal media <b>2126.</b> Computer readable signal media <b>2126</b> may be, for example, a propagated data signal containing program code <b>2118.</b> For example, computer readable signal media <b>2126</b> may be an electromagnetic signal, an optical signal, and/or any other suitable type of signal. These signals may be transmitted over communications links, such as wireless communications links, optical fiber cable, coaxial cable, a wire, and/or any other suitable type of communications link.</p><p id="p0147" num="0147">The different components illustrated for data processing system <b>2100</b> are not meant to provide architectural limitations to the manner in which different embodiments may be implemented. The different illustrative embodiments may be implemented in a data processing system including components in addition to and/or in place of those illustrated for data processing system <b>2100.</b> Other components shown in <figref idrefs="f0018"><b>Figure 21</b></figref> can be varied from the illustrative examples shown. The different embodiments may be implemented using any hardware device or system capable of running program code <b>2118.</b></p><p id="p0148" num="0148">Illustrative embodiments of the disclosure may be described in the context of aircraft manufacturing and service method <b>2200</b> as shown in <figref idrefs="f0019"><b>Figure 22</b></figref> and aircraft <b>2300</b> as shown in <figref idrefs="f0019"><b>Figure 23</b></figref><b>.</b> Turning first to <figref idrefs="f0019"><b>Figure 22</b></figref><b>,</b> an illustration of an aircraft manufacturing and service method is depicted in accordance with an illustrative embodiment. During pre-production, aircraft manufacturing and service method <b>2200</b> may include specification and design <b>2202</b> of aircraft <b>2300</b> in <figref idrefs="f0019"><b>Figure 23</b></figref> and material procurement <b>2204.</b></p><p id="p0149" num="0149">During production, component and subassembly manufacturing <b>2206</b> and system integration <b>2208</b> of aircraft <b>2300</b> in <figref idrefs="f0019"><b>Figure 23</b></figref> takes place. Thereafter, aircraft <b>2300</b> in <figref idrefs="f0019"><b>Figure 23</b></figref> may go through certification and delivery <b>2210</b> in order to be placed in service <b>2212.</b> While in service <b>2212</b> by a customer, aircraft <b>2300</b> in <figref idrefs="f0019"><b>Figure 23</b></figref> is scheduled for routine maintenance and<!-- EPO <DP n="23"> --> service <b>2214,</b> which may include modification, reconfiguration, refurbishment, and other maintenance or service.</p><p id="p0150" num="0150">Each of the processes of aircraft manufacturing and service method <b>2200</b> may be performed or carried out by a system integrator, a third party, and/or an operator. In these examples, the operator may be a customer. For the purposes of this description, a system integrator may include, without limitation, any number of aircraft manufacturers and major-system subcontractors; a third party may include, without limitation, any number of vendors, subcontractors, and suppliers; and an operator may be an airline, a leasing company, a military entity, a service organization, and so on.</p><p id="p0151" num="0151">With reference now to <figref idrefs="f0019"><b>Figure 23</b></figref><b>,</b> an illustration of an aircraft is depicted in which an illustrative embodiment may be implemented. In this example, aircraft <b>2300</b> is produced by aircraft manufacturing and service method <b>2200</b> in <figref idrefs="f0019"><b>Figure 22</b></figref> and may include airframe <b>2302</b> with plurality of systems <b>2304</b> and interior <b>2306.</b> Examples of systems <b>2304</b> include one or more of propulsion system <b>2308,</b> electrical system <b>2310,</b> hydraulic system <b>2312,</b> and environmental system <b>2314.</b> Any number of other systems may be included. Although an aerospace example is shown, different illustrative embodiments may be applied to other industries, such as the automotive industry.</p><p id="p0152" num="0152">Apparatus and methods embodied herein may be employed during at least one of the stages of aircraft manufacturing and service method <b>2200</b> in <figref idrefs="f0019"><b>Figure 22</b></figref><b>.</b> For example, one or more illustrative embodiments may be implemented during specification and design <b>2202</b> to design aircraft <b>2300</b> to include components for a vehicle display system. In yet other illustrative examples, one or more components for a vehicle display system may be installed in aircraft <b>2300</b> during system integration <b>2208.</b></p><p id="p0153" num="0153">In another illustrative example, a vehicle display system may be added to aircraft <b>2300</b> during maintenance and service <b>2214.</b> This vehicle display system may be added as during normal maintenance or during upgrades or refurbishment of aircraft <b>2300.</b></p><p id="p0154" num="0154">Thus, the illustrative embodiments provide a method and apparatus for providing increased situational awareness of an environment around a vehicle to an operator of the vehicle. In these illustrative examples, a vehicle display system may be implemented in an aircraft to provide a broader field of view than currently available through the windows in the flight deck of the aircraft.</p><p id="p0155" num="0155">Further, the images for the external view around the aircraft may be augmented with additional information. This additional information may provide guidance, warnings, alerts, and other types of information to aid an operator of the aircraft during operation of the aircraft on the ground. These operations may include, for example, without limitation, pre-flight inspections, taxiing, gate approaches, and other suitable operations.<!-- EPO <DP n="24"> --></p><p id="p0156" num="0156">Further, one or more of the illustrative embodiments may be implemented without using specially designed head-mounted displays. Instead, the illustrative examples may be implemented using mobile display devices such as a mobile phone, a tablet computer, or some other suitable type of device. In this manner, mobile display devices currently used for other applications also may include a capability for viewing external views of the aircraft. As a result, a reduction in the number of devices needed to operate an aircraft may result from using an illustrative embodiment.</p><p id="p0157" num="0157">The description of the different illustrative embodiments has been presented for purposes of illustration and description, and is not intended to be exhaustive or limited to the embodiments in the form disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art. Further, different illustrative embodiments may provide different features as compared to other illustrative embodiments. The embodiment or embodiments selected are chosen and described in order to best explain the principles of the embodiments, the practical application, and to enable others of ordinary skill in the art to understand the disclosure for various embodiments with various modifications as are suited to the particular use contemplated.</p></description><claims mxw-id="PCLM56976124" lang="EN" load-source="patent-office"><!-- EPO <DP n="25"> --><claim id="c-en-0001" num="0001"><claim-text>A method for displaying an external view (228) of a vehicle (202), the method comprising:
<claim-text>identifying a position (222) of a mobile display device (212) relative to an exterior (224) of the vehicle (202);</claim-text>
<claim-text>identifying image data (220) from a sensor system (214) for the vehicle (202) that corresponds to a field of view (226) of the mobile display device (212) from the position (222) of the mobile display device (212); and</claim-text>
<claim-text>displaying the external view (228) for the vehicle (202) on the mobile display device (212) using the image data (220).</claim-text></claim-text></claim><claim id="c-en-0002" num="0002"><claim-text>The method of claim 1 further comprising:
<claim-text>identifying the field of view (226) of the mobile display device (212) at the position (222) of the mobile display device (212), and<br/>
wherein displaying the image data (220) on the mobile display device (212) comprises:</claim-text>
<claim-text>displaying the image data (220) on the mobile display device (212) with the field of view (226) identified for the mobile display device (212).</claim-text></claim-text></claim><claim id="c-en-0003" num="0003"><claim-text>The method of claim 1 or 2 further comprising:
<claim-text>changing the external view (228) displayed on the mobile display device (212) to display a current external view (232) of the vehicle (202) from the field of view (226) of the mobile display device (212) when the position (222) of the mobile display device (212) changes.</claim-text></claim-text></claim><claim id="c-en-0004" num="0004"><claim-text>The method of any of the preceding claims further comprising:
<claim-text>selecting a camera in the sensor system (214) generating the image data (220) corresponding to the field of view (226) of the mobile display device (212) based on the position (222) of the mobile display device (212).</claim-text></claim-text></claim><claim id="c-en-0005" num="0005"><claim-text>The method of any of the preceding claims further comprising:
<claim-text>receiving sensor data (218) corresponding to the field of view (226) of the mobile display device (212) from the sensor system (214);</claim-text>
<claim-text>generating information (236) about the external view (228) displayed on the mobile display device (212) using the image data (220); and</claim-text>
<claim-text>presenting the information (236) about the external view (228) displayed on the mobile display device (212).</claim-text><!-- EPO <DP n="26"> --></claim-text></claim><claim id="c-en-0006" num="0006"><claim-text>The method of claim 5, wherein the information (236) presented is selected from at least one of a graphical indicator, a text, a video, a sound, an instruction, a caution, a guide, environmental information, and an object identifier.</claim-text></claim><claim id="c-en-0007" num="0007"><claim-text>The method of any of the preceding claims, wherein the mobile display device (212) is in a location selected from one of an interior (230) of the vehicle (202), a side of the vehicle (202), and an exterior (224) of the vehicle (202).</claim-text></claim><claim id="c-en-0008" num="0008"><claim-text>The method of any of the preceding claims, wherein the sensor system (214) is associated with at least one of the vehicle (202), a number of objects (238), and another vehicle (202).</claim-text></claim><claim id="c-en-0009" num="0009"><claim-text>The method of any of the preceding claims, wherein the vehicle (202) is selected from one of an aircraft, a surface ship, a tank, a personnel carrier, a train, a spacecraft, a submarine, a bus, and an automobile.</claim-text></claim><claim id="c-en-0010" num="0010"><claim-text>The method of any of the preceding claims, wherein the mobile display device (212) is selected from one of a hand-held mobile display device, a mobile phone, a tablet computer, a laptop computer, a liquid crystal display, and an organic light emitting display.</claim-text></claim><claim id="c-en-0011" num="0011"><claim-text>An apparatus comprising:
<claim-text>a view generator (210) configured to identify a position (222) of a mobile display device (212) relative to an exterior (224) of a location in a vehicle (202); identify image data (220) from a sensor system (214) for the vehicle (202) that corresponds to a field of view (226) of the mobile display device (212) from the position (222) of the mobile display device (212) relative to the vehicle (202); and display an external view (228) for the vehicle (202) on the mobile display device (212) using the image data (220).</claim-text></claim-text></claim><claim id="c-en-0012" num="0012"><claim-text>The apparatus of claim 11, wherein the exterior (224) of the location in a vehicle (202) is selected from one of another location in the vehicle (202) not visible from the location and an environment outside of the vehicle (202).</claim-text></claim><claim id="c-en-0013" num="0013"><claim-text>The apparatus of claim 13 further comprising:
<claim-text>the mobile display device (212).</claim-text><!-- EPO <DP n="27"> --></claim-text></claim><claim id="c-en-0014" num="0014"><claim-text>The apparatus of any of claims 11-13, wherein the view generator (210) is configured to change the image data (220) displayed on the mobile display device (212) to display a current external view (232) of the vehicle (202) from the field of view (226) of the mobile display device (212) when the position (222) of the mobile display device (212) changes.</claim-text></claim></claims><drawings mxw-id="PDW16666909" load-source="patent-office"><!-- EPO <DP n="28"> --><figure id="f0001" num="1"><img id="if0001" file="imgf0001.tif" wi="146" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="29"> --><figure id="f0002" num="2"><img id="if0002" file="imgf0002.tif" wi="165" he="214" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="30"> --><figure id="f0003" num="3,4"><img id="if0003" file="imgf0003.tif" wi="165" he="214" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="31"> --><figure id="f0004" num="5"><img id="if0004" file="imgf0004.tif" wi="142" he="228" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="32"> --><figure id="f0005" num="6"><img id="if0005" file="imgf0005.tif" wi="142" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="33"> --><figure id="f0006" num="7"><img id="if0006" file="imgf0006.tif" wi="165" he="199" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="34"> --><figure id="f0007" num="8"><img id="if0007" file="imgf0007.tif" wi="165" he="220" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="35"> --><figure id="f0008" num="9"><img id="if0008" file="imgf0008.tif" wi="165" he="225" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="36"> --><figure id="f0009" num="10"><img id="if0009" file="imgf0009.tif" wi="165" he="225" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="37"> --><figure id="f0010" num="11"><img id="if0010" file="imgf0010.tif" wi="165" he="229" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="38"> --><figure id="f0011" num="12"><img id="if0011" file="imgf0011.tif" wi="163" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="39"> --><figure id="f0012" num="13"><img id="if0012" file="imgf0012.tif" wi="163" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="40"> --><figure id="f0013" num="14"><img id="if0013" file="imgf0013.tif" wi="165" he="227" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="41"> --><figure id="f0014" num="15"><img id="if0014" file="imgf0014.tif" wi="165" he="227" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="42"> --><figure id="f0015" num="16"><img id="if0015" file="imgf0015.tif" wi="165" he="214" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="43"> --><figure id="f0016" num="17,18"><img id="if0016" file="imgf0016.tif" wi="165" he="214" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="44"> --><figure id="f0017" num="19,20"><img id="if0017" file="imgf0017.tif" wi="165" he="214" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="45"> --><figure id="f0018" num="21"><img id="if0018" file="imgf0018.tif" wi="165" he="214" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="46"> --><figure id="f0019" num="22,23"><img id="if0019" file="imgf0019.tif" wi="165" he="214" img-content="drawing" img-format="tif"/></figure></drawings><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
