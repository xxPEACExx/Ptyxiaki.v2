<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2679147-A2" country="EP" doc-number="2679147" kind="A2" date="20140101" family-id="48792962" file-reference-id="310635" date-produced="20180826" status="corrected" lang="DE"><bibliographic-data><publication-reference fvid="146550921" ucid="EP-2679147-A2"><document-id><country>EP</country><doc-number>2679147</doc-number><kind>A2</kind><date>20140101</date><lang>DE</lang></document-id></publication-reference><application-reference ucid="EP-13174043-A" is-representative="YES"><document-id mxw-id="PAPP154824844" load-source="docdb" format="epo"><country>EP</country><doc-number>13174043</doc-number><kind>A</kind><date>20130627</date><lang>DE</lang></document-id><document-id mxw-id="PAPP174953002" load-source="docdb" format="original"><country>EP</country><doc-number>13174043.3</doc-number><date>20130627</date></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC140454627" ucid="DE-102012105664-A" load-source="docdb"><document-id format="epo"><country>DE</country><doc-number>102012105664</doc-number><kind>A</kind><date>20120628</date></document-id></priority-claim><priority-claim mxw-id="PPC140450233" ucid="US-201261665331-P" load-source="docdb"><document-id format="epo"><country>US</country><doc-number>201261665331</doc-number><kind>P</kind><date>20120628</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL-2145963373" load-source="docdb">G02B  27/00        20060101ALI20141009BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-2145963891" load-source="docdb">G06F   3/01        20060101ALN20141009BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-2145965499" load-source="docdb">G06K   9/00        20060101ALI20141009BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-2145965770" load-source="docdb">A61B   3/113       20060101AFI20141009BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-2145969711" load-source="docdb">G06K  19/06        20060101ALN20141009BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL1988109878" load-source="docdb" scheme="CPC">A61B   3/113       20130101 FI20131002BHEP        </classification-cpc><classification-cpc mxw-id="PCL2094215448" load-source="docdb" scheme="CPC">G06F   3/013       20130101 LI20131002BHEP        </classification-cpc><classification-cpc mxw-id="PCL2102372379" load-source="docdb" scheme="CPC">G06K   9/00597     20130101 LI20140729BHEP        </classification-cpc><classification-cpc mxw-id="PCL2102377333" load-source="docdb" scheme="CPC">G02B  27/0093      20130101 LI20140729BHEP        </classification-cpc><classification-cpc mxw-id="PCL2114896793" load-source="docdb" scheme="CPC">G06K   9/00335     20130101 LI20140915BHEP        </classification-cpc><classification-cpc mxw-id="PCL2114898612" load-source="docdb" scheme="CPC">G06K   9/0061      20130101 LI20140915BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT132185247" lang="DE" load-source="patent-office">Verfahren und Vorrichtung zur Kodierung von Augen- und Blickverlaufsdaten</invention-title><invention-title mxw-id="PT132185248" lang="EN" load-source="patent-office">Method and device for encoding eye and viewing direction data</invention-title><invention-title mxw-id="PT132185249" lang="FR" load-source="patent-office">Procédé et dispositif de codage de données de suivi de l'oeil et du regard</invention-title><citations><patent-citations><patcit mxw-id="PCIT361594755" load-source="docdb" ucid="US-RE40014-E"><document-id format="epo"><country>US</country><doc-number>RE40014</doc-number><kind>E</kind><date>20080101</date></document-id><sources><source name="APP" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT242657606" load-source="docdb" ucid="WO-1999018842-A1"><document-id format="epo"><country>WO</country><doc-number>1999018842</doc-number><kind>A1</kind><date>19990422</date></document-id><sources><source name="APP" created-by-npl="N"/></sources></patcit></patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR918164623" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>HEIN OLIVER</last-name><address><country>DE</country></address></addressbook></applicant><applicant mxw-id="PPAR918171854" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>HEIN, OLIVER</last-name></addressbook></applicant><applicant mxw-id="PPAR918986355" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Hein, Oliver</last-name><iid>101390104</iid><address><street>Husumer Straße 23</street><city>20249 Hamburg</city><country>DE</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR918163515" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>HEIN OLIVER</last-name><address><country>DE</country></address></addressbook></inventor><inventor mxw-id="PPAR918158975" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>HEIN, OLIVER</last-name></addressbook></inventor><inventor mxw-id="PPAR918979557" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>HEIN, OLIVER</last-name><address><street>Husumer Straße 23</street><city>20249 Hamburg</city><country>DE</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR918994078" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>2K Patentanwälte Blasberg Kewitz &amp; Reichel</last-name><iid>100061307</iid><address><street>Partnerschaft Schumannstrasse 27</street><city>60325 Frankfurt am Main</city><country>DE</country></address></addressbook></agent></agents></parties><international-convention-data><designated-states><ep-contracting-states><country mxw-id="DS548928637" load-source="docdb">AL</country><country mxw-id="DS548834647" load-source="docdb">AT</country><country mxw-id="DS548928979" load-source="docdb">BE</country><country mxw-id="DS548906921" load-source="docdb">BG</country><country mxw-id="DS548920738" load-source="docdb">CH</country><country mxw-id="DS548918276" load-source="docdb">CY</country><country mxw-id="DS548834648" load-source="docdb">CZ</country><country mxw-id="DS548814160" load-source="docdb">DE</country><country mxw-id="DS548928980" load-source="docdb">DK</country><country mxw-id="DS548918277" load-source="docdb">EE</country><country mxw-id="DS548862768" load-source="docdb">ES</country><country mxw-id="DS548906926" load-source="docdb">FI</country><country mxw-id="DS548906927" load-source="docdb">FR</country><country mxw-id="DS548814161" load-source="docdb">GB</country><country mxw-id="DS548928981" load-source="docdb">GR</country><country mxw-id="DS548928986" load-source="docdb">HR</country><country mxw-id="DS548918278" load-source="docdb">HU</country><country mxw-id="DS548920739" load-source="docdb">IE</country><country mxw-id="DS548928987" load-source="docdb">IS</country><country mxw-id="DS548906928" load-source="docdb">IT</country><country mxw-id="DS548918279" load-source="docdb">LI</country><country mxw-id="DS548814162" load-source="docdb">LT</country><country mxw-id="DS548834649" load-source="docdb">LU</country><country mxw-id="DS548814163" load-source="docdb">LV</country><country mxw-id="DS548814164" load-source="docdb">MC</country><country mxw-id="DS548922115" load-source="docdb">MK</country><country mxw-id="DS548922116" load-source="docdb">MT</country><country mxw-id="DS548834650" load-source="docdb">NL</country><country mxw-id="DS548862769" load-source="docdb">NO</country><country mxw-id="DS548834651" load-source="docdb">PL</country><country mxw-id="DS548862774" load-source="docdb">PT</country><country mxw-id="DS548834652" load-source="docdb">RO</country><country mxw-id="DS548862775" load-source="docdb">RS</country><country mxw-id="DS548834653" load-source="docdb">SE</country><country mxw-id="DS548814166" load-source="docdb">SI</country><country mxw-id="DS548920740" load-source="docdb">SK</country><country mxw-id="DS548920741" load-source="docdb">SM</country><country mxw-id="DS548922117" load-source="docdb">TR</country></ep-contracting-states><ep-extended-states><ep-extended-state-data><country>BA</country></ep-extended-state-data><ep-extended-state-data><country>ME</country></ep-extended-state-data></ep-extended-states></designated-states></international-convention-data></bibliographic-data><abstract mxw-id="PA128671231" lang="DE" load-source="patent-office"><p id="pa01" num="0001">Vorgeschlagen wird ein Verfahren und eine Vorrichtung zur Kodierung von Augen- und Blickverlaufsdaten (DAT), welche Raumparameter (t, x, y) in Form von Zahlengruppen (Z0, Z1, Z2...) angeben, die mittels einer Blickerfassungsvorrichtung (Eye-Tracker) gewonnen werden und jeweils einem Blickpunkt (A, B, C, D, E ...) zugeordnet sind. Aus den Zahlengruppen werden paarweise jeweils Zahlenpaare (Z0,Z1; Z0,Z2; Z0,Z3...) miteinander kombiniert, um für jede Kombination einen Wert (W) zu erhalten, der zumindest den räumlichen Abstand (S) zwischen den zwei Blickpunkten (E, C) angibt, wobei die erhaltenen Werte (W) eine Kodierung für die Augen- und Blickverlaufsdaten (DAT) darstellen. Vorzugsweise werden die Werte (W) in Form einer Matrix (M) erfasst und gespeichert. Die Matrix wird vorzugsweise einer oder mehreren Operationen (Filterung, anisotrope Diffusion) unterzogen, so dass die Ergebnismatrix schließlich eine Kodierung bzw. einen Code für Fixierungen, Sakkaden und glatte Folgebewegungen eines Blickpfades darstellt.
<img id="iaf01" file="imgaf001.tif" wi="78" he="106" img-content="drawing" img-format="tif"/></p></abstract><abstract mxw-id="PA128500604" lang="DE" source="EPO" load-source="docdb"><p>Vorgeschlagen wird ein Verfahren und eine Vorrichtung zur Kodierung von Augen- und Blickverlaufsdaten (DAT), welche Raumparameter (t, x, y) in Form von Zahlengruppen (Z0, Z1, Z2...) angeben, die mittels einer Blickerfassungsvorrichtung (Eye-Tracker) gewonnen werden und jeweils einem Blickpunkt (A, B, C, D, E ...) zugeordnet sind. Aus den Zahlengruppen werden paarweise jeweils Zahlenpaare (Z0,Z1; Z0,Z2; Z0,Z3...) miteinander kombiniert, um für jede Kombination einen Wert (W) zu erhalten, der zumindest den räumlichen Abstand (S) zwischen den zwei Blickpunkten (E, C) angibt, wobei die erhaltenen Werte (W) eine Kodierung für die Augen- und Blickverlaufsdaten (DAT) darstellen. Vorzugsweise werden die Werte (W) in Form einer Matrix (M) erfasst und gespeichert. Die Matrix wird vorzugsweise einer oder mehreren Operationen (Filterung, anisotrope Diffusion) unterzogen, so dass die Ergebnismatrix schließlich eine Kodierung bzw. einen Code für Fixierungen, Sakkaden und glatte Folgebewegungen eines Blickpfades darstellt.</p></abstract><abstract mxw-id="PA135487742" lang="EN" source="transcript" load-source="docdb"><p>The method (100) involves indicating time and space parameters in the form of set of numbers and obtaining the time and space parameters by an eye-tracking device (101). A focal point is assigned. The numbers are combined to obtain a value for each combination that indicates spatial distance between the two viewing points. The eye movement data is represented by the obtained value ??that is stored in the form of a matrix. A view path is represented, acquired and stored. An independent claim is included for a device for encoding movement data of eye.</p></abstract><description mxw-id="PDES63956661" lang="DE" load-source="patent-office"><!-- EPO <DP n="1"> --><p id="p0001" num="0001">Die Erfindung betrifft ein Verfahren und eine Vorrichtung zur Kodierung von Augen- und Blickverlaufsdaten. Insbesondere betrifft die Erfindung eine Kodierung von Augen- und Blickverlaufsdaten für eine Blicksteuerung einer Mensch-Maschine-Interaktion. Die mittels der Erfindung durchgeführte Blicksteuerung soll beispielsweise im Bereich von Benutzer-abhängigen Augen-und Blickverlaufs-gesteuerten Prozessen in technischen Vorrichtungen, wie z.B. Maschinen, Geräten, Computern, Anlagen, Fahrzeugen usw. eingesetzt werden.</p><p id="p0002" num="0002">Aus dem Stand der Technik sind an sich Verfahren und Vorrichtungen bekannt, die Augen- und Blickverlaufsdaten von Personen erfassen, um den sogenannten Blickpfad darzustellen, d.h. den zeitlichen Blickverlauf, welcher das Blickverhalten der Person beim Betrachten einer bildlichen Darstellung (z.B. Foto, Werbeplakat) oder einer Szene (z.B. Situation im Straßenverkehr, Film) wiedergibt. Üblicherweise werden Augen- und Blickverlaufsdaten mit Hilfe einer Blickerfassungsvorrichtung, eines sogenannten Eye-Tracker, erfasst.</p><p id="p0003" num="0003">Ein solches Verfahren und eine solche Blickerfassungsvorrichtung werden beispielsweise in der <patcit id="pcit0001" dnum="WO9918842A1"><text>WO 99 / 18842 A1</text></patcit> beschrieben. Dort wird auch eine Datenauswertung beschrieben, mit der typische Augenbewegungsmuster erkannt werden können.</p><p id="p0004" num="0004">Ein weiteres Verfahren der bekannten Art wird z.B. in der <patcit id="pcit0002" dnum="USRE40014E1"><text>US RE 40014 E1</text></patcit> offenbart.<!-- EPO <DP n="2"> --></p><p id="p0005" num="0005">Die bekannten Eye-Tracker liefern zeitaufgelöste Positionsdaten des Kopfes und der Augen einer Versuchsperson. Aus diesen Daten können die zeitaufgelösten Schnittpunkte der Sehstrahlen der Augen des Betrachters mit den Objekten einer statischen oder dynamischen Szene, wie sie z.B. bei der Betrachtung eines Plakates, eines Werbespots, der Bedienkonsole einer Maschine (z.B. Auto- oder Flugzeug-Cockpit), der Oberfläche eines Computers, etc. entstehen, ermittelt werden. Dazu werden die Positionsdaten des Kopfes und der Augen des Betrachters mit einer relativ hohen Abtast-Frequenz von bis zu 2000 Hz und mehr bestimmt.</p><p id="p0006" num="0006">Für die Aufzeichnung stehen üblicherweise verschiedene Techniken zur Verfügung. Die für eine breite Massenanwendung geeignetste Technik, da minimal invasiv und damit für die Versuchsperson nicht belastend oder einschränkend, besteht in der videobasierten Aufzeichnung des Kopfes der Versuchsperson unter zwei verschiedenen Winkeln im Infrarotbereich und einer sich anschließenden Bildverarbeitung, welche die Positionsdaten des Kopfes und der Augen aus den Bilddaten errechnet.</p><p id="p0007" num="0007">Aus der Bildanalyse können die Kopfposition und Iris- / Pupillenpositionen nach vorheriger Kalibrierung ermittelt werden. Diese oftmals in Echtzeit durchgeführte Ermittlung erfolgt durch die vom Hersteller des Eye-Trackers gelieferte Software. In dieser Form sind die Daten für den Endanwender, z.B. einen Psychologen, welcher das Betrachtungsschema eines Werbespots untersucht, jedoch nicht interpretierbar. Daher besteht der Bedarf, die Daten Endanwender-freundlich aufzubereiten.</p><p id="p0008" num="0008">Üblicherweise geschieht die Klassifizierung und Interpretation der Daten durch die Zerlegung der Verlaufsdaten in Fixierungen (Cluster von Blickpunkten) und Blicksprüngen (Sakkaden), wobei aus (Kognitions-) psychologischer Sicht die Fixierungen interessieren und die Sakkaden für grundlegende physiologische Prozesse interessant sind. Jedoch beruhen die hierfür bekannten Rechenverfahren bzw. Algorithmen auf einer Bewertung der Blickpunkte nach<!-- EPO <DP n="3"> --> deren räumlicher Dispersion oder/und deren Geschwindigkeit bzw. Beschleunigung. Die Algorithmen erfordern eine Parametrisierung vom Endnutzer, bzw. Voreinstellungen für die Parameter vom Hersteller, welche einen möglichst großen Anwendungsbereich abdecken, dadurch aber für spezielle Anwendungsfälle zu ungenau sein können, da die Wahl der Parametrisierung der Algorithmen das Ergebnis signifikant beeinflussen kann. Ferner sind die Parameter zum Teil individuellen, also auf die Versuchsperson bzw. Personengruppe bezogenen, Schwankungen unterworfen oder/und sind von den im Versuch gestellten Aufgaben abhängig. Daher muss bei den bekannten Rechenverfahren bzw. Algorithmen der Endnutzer Erfahrung in der Wahl der Parameter mitbringen, was in der Praxis nur selten der Fall ist oder er muss sich auf eine ungefähre Parametrierung ("Daumenregel") verlassen. Die bekannten Rechenverfahren bzw. Algorithmen sind auch nicht auf die Betrachtung von dynamischen Szenen ausgelegt, in denen der Betrachter bewegten Objekten mit den Augen folgt. Die Abtrennung einer weiteren Art von Augen- und Blickbewegung, der sogenannten glatten Folgebewegung, wie sie bei der Betrachtung von dynamischen Szenen auftritt, gilt gegenwärtig als schwer und wurde bislang noch nicht zufriedenstellend gelöst.</p><p id="p0009" num="0009">Es ist daher Aufgabe der Erfindung, ein Verfahren und eine Vorrichtung vorzuschlagen, die eine Auswertung von Augen- und Blickverlaufsdaten ermöglichen, wobei die eingangs genannten Nachteile überwunden werden. Insbesondere soll die Erfindung das schnelle und zuverlässige Erkennen von Fixierungen und Sakkaden ermöglichen, um Steuerungen von Mensch-Maschine-Interaktionen zu verbessern. Außerdem soll die Erfindung das Erkennen von glatten Folgebewegung (engl. smooth pursuits) bei der Betrachtung dynamischer Szenen ermöglichen. Die Erfindung soll für weite Bereiche der Technik einsetzbar sein, nämlich überall dort, wo Mensch-Maschine-Interaktionen zur Steuerung von Maschinen, Geräten, Computern, Anlagen, Fahrzeugen usw. gewünscht oder erforderlich sind. Die Erfindung soll auch in wissenschaftlichen Gebieten einsetzbar sein, wie z.B. Ergonomie (engl. human factors), Lesen, Neurologie, Physiologie, Psychologie usw. Die Erfindung soll auch im Bereich des Marketings und der Werbung einsetzbar sein.<!-- EPO <DP n="4"> --></p><p id="p0010" num="0010">Zur Lösung der Aufgaben wird ein erfindungsgemäßes Verfahren mit den Merkmalen des Anspruchs 1 vorgeschlagen sowie eine Vorrichtung mit den Merkmalen des nebengeordneten Anspruchs.</p><p id="p0011" num="0011">Demnach wird ein Verfahren zur Kodierung von Augen- und Blickverlaufsdaten vorgeschlagen, bei dem die Augen- und Blickverlaufsdaten Zeit- und Raumparameter in Form von Zahlengruppen angeben, die mittels einer Blickerfassungsvorrichtung (Eye-Tracker) gewonnen werden und jeweils einem Blickpunkt zugeordnet sind. Dabei werden aus den Zahlengruppen paarweise jeweils Zahlenpaare miteinander kombiniert, um für jede Kombination einen Wert zu erhalten, der zumindest den räumlichen Abstand zwischen den zwei Blickpunkten angibt, denen das jeweilige Zahlenpaar zugeordnet ist, wobei die erhaltenen Werte eine Kodierung für die Augen- und Blickverlaufsdaten darstellen.</p><p id="p0012" num="0012">Vorzugsweise stellen die Zahlengruppen entsprechend der Zeit- und Raumparameter Zahlentrippel dar, wobei aus den Zahlentrippeln paarweise jeweils zwei Zahlentrippel miteinander kombiniert werden, um für jede Kombination einen Wert zu erhalten, der zumindest den zeitlichen und räumlichen Abstand zwischen den zwei Blickpunkten angibt.</p><p id="p0013" num="0013">Bevorzugt werden die Werte (Ergebniswerte aller möglichen Kombinationen) in Form einer ersten Matrix erfasst und gespeichert. Diese erste Matrix wird vorzugsweise einer Glättungs-Filterung, insbesondere einer anisotropen Filterung, unterzogen, um eine zweite Matrix zu erhalten, die gegenüber der ersten Matrix einen (deutlich) reduzierten Datenumfang aufweist. Die erste und/oder zweite Matrix kann einer Schwellwert-Filterung unterzogen werden, um eine dritte Matrix zu erhalten, die gegenüber der ersten bzw. zweiten Matrix einen (noch weiter) reduzierten Datenumfang aufweist. Die erste, zweite und/oder dritte Matrix stellt eine Kodierung bzw. einen Code für Fixierungen und Sakkaden eines (Rohdaten-) Blickpfades dar.<!-- EPO <DP n="5"> --></p><p id="p0014" num="0014">Außerdem kann die Glättungs-Filterung der ersten Matrix in Form einer anisotropen Diffusion durchgeführt werden, um eine vierte Matrix zu erhalten, die eine Kodierung für Fixierungen, Sakkaden und glatte Folgebewegungen eines Blickpfades darstellt.</p><p id="p0015" num="0015">Die Erfindung stellt also ein Verfahren bereit, welches eine ternäre Klassifizierung der Positionsdaten in Fixierungen und Sakkaden sowie (optional) glatte Folgebewegungen in robuster und in für die Untersuchung spezifischer Weise ermöglicht und welche vom Endanwender nicht parametrisiert werden müssen, bzw. eine intuitive, visuell geleitete Konfigurierung ermöglichen, wenn dies vom Anwender aus Gründen der Nachvollziehbarkeit und Validierung gewünscht ist.</p><p id="p0016" num="0016">Die Erfindung stellt eine integrierte Lösung zur Auswertung von Augen- und Blickbewegungen in der Form von Verlaufsdaten dar und verwendet Augen- und Blickverlaufsdaten, welche als zeitaufgelöste Ortsdaten beim Einsatz von Eye-Trackern in diversen Themengebieten entstehen, wie z.B. Usability-, Werbe- und Marktforschung, Computersteuerung (Mensch-Maschine-Schnittstelle), Fahr-/ Flugsimulatoren, Psychologie, Medizinische Diagnostik etc.. Das erfindungsgemäße Verfahren verwendet die Augen- und Blickverlaufsdaten in ihrer Rohform (Rohdaten) und wendet auf diese ein oder mehrere Verarbeitungsschritte an, um a) Rauschen/Datenfehler zu reduzieren und um b) aus den Rohdaten Fach-/ Themenspezifische Informationsinhalte zu extrahieren. Die hier vorgeschlagene Lösung beinhaltet ein integriertes System von Verfahrensschritten zur automatisierten Durchführung von a) und b) und liefert eine Kodierung bzw. einen Code zur Darstellung des Blickprozesses und zur Auswertung desselben. Alle Verfahrensschritte der vorgeschlagenen Lösung bzw. die Rechenmodule können in einer Vorrichtung zur Steuerung bzw. Unterstützung von Mensch-Maschine-Interaktionen integriert werden und ermöglichen es, dass die Steuerung vom Endnutzer in intuitiver Weise bedient werden kann.<!-- EPO <DP n="6"> --></p><p id="p0017" num="0017">Ein wesentlicher Aspekt des hier vorgestellten Verfahrens ist die Verdichtung bzw. Beschreibung der Daten durch die Kombination von Methoden aus einem weiten Spektrum der Mathematik (Geometrie, Topologie, Algebra, Differentialgleichungen, etc.) sowie die Interpretation der so beschriebenen Daten durch Informationstheoretische Methoden. Die Systematisierung der gewonnenen Beschreibungen erfolgt durch den Einsatz von Algorithmen des maschinellen Lernens. Durch die Kombination der Methoden wird der vom Endnutzer benötigte hohe Grad an Automatisation und Datenkondensation erreicht sowie der für die Interpretation der Ergebnisse nötige Grad an Abstraktion vermittelt. Die Verarbeitungsstrecke ist für den Endanwender parameterfrei, was besonders vorteilhaft ist, da der Endanwender normalerweise kein methodisches Wissen auf der Ebene der zur Anwendung kommenden Algorithmen mitbringt, sondern sich darauf verlässt, dass die implementierten Verfahren ihm die benötigten Endauswertungen in robuster Form zur Verfügung stellen. Die möglichst hohe Robustheit und Verlässlichkeit der erfindungsgemäßen Lösung ist insbesondere vorteilhaft zu sehen im Zusammenhang mit der Blicksteuerung von Maschinen und in der Medizinischen Diagnostik. Die Erfindung ist aber nicht auf diese Anwendungsbereiche beschränkt, sondern kann generell für jede Form von Mensch-Maschine-Interaktion benutzt werden.</p><p id="p0018" num="0018">Die Erfindung kann in einem breiten Spektrum von möglichen Einsatzbereichen zur Anwendung kommen:</p><p id="p0019" num="0019">Gegenwärtig von besonderem Interesse ist der Bereich der sog. Gaze-Contingent Technologies bzw. Displays. Dieser Bereich umfasst die durch den Blick gesteuerte Anpassung des Computerbildschirms an die Interessensinhalte des Nutzers bzw. Users. Dazu wird der Blick des Nutzers durch zwei Kameras am Computer aufgezeichnet und der Interessensbereich des Nutzers auf dem Bildschirm berechnet. In Abhängigkeit von dem dort dargestellten Inhalt wird dann die lokale Information angepasst, so könnte z.B. eine Lesehilfe den Text dort vergrößern oder bei einer Stockung im Leseprozess von fremdsprachlichen Texten Übersetzungen anbieten. Für Smartphones ist eine selektive Vergrößerung (Zoomen) oftmals wünschenswert, da die Displaygröße limitiert ist.<!-- EPO <DP n="7"> --></p><p id="p0020" num="0020">Ein weiterer Einsatzbereich ist die Steuerung von Mouse-Zeigern, Cursorn und dergleichen. Für die Bedienung des Computers wird an einer "Blick-Mouse" gearbeitet, d.h. an einer durch den Blick des Benutzers gesteuerten Mouse-Zeiger-Bewegung (komplementär zum mit dem Touch Screen). Für die Unterstützung von Menschen mit einer schweren körperlichen Behinderungwird wird an der Umsetzung eines "Blick-Keyboards" gearbeitet, d.h. an einer durch den Blick des Benutzers gesteuerten Tastatur-Eingabe. An sich ist die Integration der Kameras in die Hardware eines Computers gegenwärtig kein technisches oder preisliches Problem mehr. Die momentane Restriktion besteht in der Auswertung und Interpretation der Blickdaten. So ist die Blickbewegung im Gegensatz zur Bewegung der Hände eine zum größten Teil unbewusste Aktion, deren gezielte Nutzung noch viele Fragen aufwirft. Dieses Beispiel lässt sich nahezu beliebig erweitern:</p><p id="p0021" num="0021">Beispielsweise dienen blickgesteuerte Fahrassistenzsysteme dazu, den Autofahrer in Abhängigkeit von der Verkehrssituation mit zusätzlicher Information gezielt zu versorgen bzw. ihn bei gefährlichen Situationen zu warnen (beginnende Ermüdung, kein Blick in den Rückspiegel bei Überholprozessen etc.). In der Medizin zeigt sich ein bedeutendes Potential für die Frühdiagnostik von neurologischen Erkrankungen, wenn große Patientengruppen systematisch auswertbar werden. In der Werbung gilt dies für die Untersuchung von Konsumentengruppen. Hier kommen mobile Gaze-Tracker zum Einsatz. Die Prototypen von Brillen mit integrierten Computern zeigen, dass die Restriktionen durch die Hardware immer kleiner werden.</p><p id="p0022" num="0022">Das hier vorgestellte Verfahren umfasst auch den Vergleich von mehreren Blickpfaden, um Ähnlichkeiten zwischen den Blickverhalten zu erkennen, zu qualifizieren und zu quantisieren, insbesondere in Form von Ähnlichkeitswerten bzw. einer Ähnlichkeitsmatrix, anhand derer eine Klassifizierung bzw. ein Clustering von Blickverhalten durchgeführt werden kann. Dieser Aspekt kann auch als eigenständige Erfindung verstanden werden.<!-- EPO <DP n="8"> --></p><p id="p0023" num="0023">Hierzu werden für mindestens zwei Blickpfade jeweils eine Matrix erstellt wird und diese verarbeitet und einem Vergleich unterzogen werden, um für jeden Vergleich einen Ähnlichkeitswert zu erhalten, der die Ähnlichkeit der den mindestens zwei Blickpfaden zugrunde liegenden Blickverhalten anzeigt.</p><p id="p0024" num="0024">Dabei wird der Ähnlichkeitswert der Blickpfade durch deren Kolmogorov-Komplexität charakterisiert in Form ihrer Kompressibilität, welche auf einer Kombination von prädiktiver Kodierung, Lauflängen-Kodierung und Huffman-Kodierung der jeweils ersten Matrix basiert.</p><p id="p0025" num="0025">Vorzugsweise wird dazu die Matrix eines jeden Blickpfades in Untermatrizen zerlegt, deren Größe abhängig von der Abtastfrequenz der Blickerfassungs-Vorrichtung ist.</p><p id="p0026" num="0026">Dann werden die Untermatrizen jeweils einer harmonischen Analyse unterzogen, insbesondere einer Analyse mittels Walsh-Funktionen oder Cosinus-Funktionen, um transformierte Untermatrizen zu erhalten.</p><p id="p0027" num="0027">Anschließend werden die transformierten Untermatrizen einer jeden Matrix einem Kompression-Prozess unterzogen, um eine komprimierte Matrix zu erhalten, welche die am meisten signifikanten Koeffizienten enthält und ein reduziertes Volumen aufweist.</p><p id="p0028" num="0028">Dabei wird das reduzierte Volumen oder die Kompressibilität durch einen Kompressions-Wert repräsentiert, der die Länge in Bit der komprimierten Matrix des jeweiligen Blickpfades angibt.</p><p id="p0029" num="0029">Bevorzugt werden deutlich mehr als zwei Blickpfade, die durch ihre Matrizen repräsentiert werden, paarweise kombiniert, um für jede Kombination einen Ähnlichkeitswert zu erhalten, der die Ähnlichkeit der den mehreren Blickpfaden zugrunde liegenden Blickverhalten anzeigt. Dabei kann der Ähnlichkeitswert insbesondere gemäß der folgenden Gleichung ermittelt werden:<!-- EPO <DP n="9"> --> <maths id="math0001" num="(1)"><math display="block"><mi>x</mi><mo>=</mo><mfrac><mrow><mi mathvariant="normal">C</mi><mfenced separators=""><mi mathvariant="normal">a</mi><mo>⁢</mo><mi mathvariant="normal">b</mi></mfenced><mo>-</mo><mi>min</mi><mfenced open="{" close="}" separators=""><mi>C</mi><mfenced><mi>a</mi></mfenced><mo>,</mo><mi>C</mi><mfenced><mi>b</mi></mfenced></mfenced></mrow><mrow><mi>max</mi><mfenced open="{" close="}" separators=""><mi mathvariant="normal">C</mi><mfenced><mi mathvariant="normal">a</mi></mfenced><mo>,</mo><mi mathvariant="normal">C</mi><mfenced><mi mathvariant="normal">b</mi></mfenced></mfenced></mrow></mfrac></math><img id="ib0001" file="imgb0001.tif" wi="84" he="24" img-content="math" img-format="tif"/></maths><br/>
wobei C(a) und C(b) die Länge in Bit der komprimierten Matrix des jeweiligen Blickpfades a bzw. b bezeichnen, und C(a,b) die Länge des kombinierten Blickpfades aus a und b bezeichnen.</p><p id="p0030" num="0030">Die berechneten Ähnlichkeitswerte bilden dann die Elemente einer Ähnlichkeitsmatrix, welche als Grundlage für einen Klassifizierungs- bzw. Clustering-Vorgang verwendet wird, wobei die Ähnlichkeitsmatrix insbesondere einem Klassifizierungs- bzw. Clustering-Vorgang unterzogen, der einen hierarchisch strukturierten Baum oder eine selbst-organisierte Karte erstellt.</p><p id="p0031" num="0031">Das Verfahren eignet sich besonders zur Blicksteuerung einer Mensch-Maschine-Interaktion, zur Diagnose mentaler Krankheiten oder psychischer Verwirrung, oder zum Forschen im Bereich Marketing und Werbung. Zahlreiche weitere Anwendungsgebiete sind denkbar.</p><p id="p0032" num="0032">Die Erfindung wird nachfolgend anhand von Ausführungsbeispielen und unter Bezugnahme auf die beiliegenden Zeichnungen (<figref idrefs="f0001 f0002 f0003 f0004 f0005 f0006 f0007 f0008 f0009 f0010 f0011 f0012 f0013 f0014">Figuren 1-13</figref>) beschrieben:</p><p id="p0033" num="0033">In der <figref idrefs="f0001">Fig. 1</figref> ist in üblicher Darstellung ein Sehstrahlendiagramm (engl. scanpath) gezeigt, welches den Blickverlauf einer Testperson beim Betrachten einer Bildvorlage (z.B. Internetseite) wiedergibt. Dort wo sich der Blickpfad für eine Zeitdauer lokal auf einen Bereich beschränkt, spricht man von einer Fixierung. Dort wo der Blickpfad schnell von einer Fixierung zur nächsten Fixierung verläuft, spricht man von Sakkaden. Das Sehstrahlendiagramm repräsentiert die grafische Darstellung von Augen- und Blickverlaufsdaten, welche ein herkömmlicher Eye-Tracker liefert. Für die Aufzeichnung der Daten stehen verschiedene Techniken zur Verfügung. Die für eine breite Massenanwendung geeignetste Technik, da minimal invasiv und damit für die Versuchsperson nicht belastend oder einschränkend, besteht in der videobasierten Aufzeichnung des Kopfes der<!-- EPO <DP n="10"> --> Versuchsperson unter zwei verschiedenen Winkeln im Infrarotbereich und einer sich anschließenden Bildverarbeitung, welche die Positionsdaten des Kopfes und der Augen aus den Bilddaten errechnet. Die Erfindung setzt auf den Kopf-/ Augen-Positionsdaten, bzw. den Schnittpunktdaten der Sehstrahlen mit den betrachteten Objekten auf.</p><p id="p0034" num="0034">Die <figref idrefs="f0002">Fig. 2</figref> zeigt ein Ablaufdiagramm für das erfindungsgemäße Verfahren 100, welches grob in folgende Abschnitte unterteilt werden kann:
<ol><li>a) Erfassen und Speichern der Bilddaten mittels Eye-Tracker (Schritte 101 - 103);</li><li>b) Erste Datenaufbereitung, insbesondere Reinigung, Zerlegung und Klassifizierung (Schritt bzw. Block 110), wobei aus den Rohdaten DAT eine erste Matrix M erzeugt wird;</li><li>c) Weitere Datenaufbereitung (optionaler Block 120), wobei in der erzeugten Matrix (bereinigte Daten) eine oder mehrere Strukturen erkannt werden, die für typische individuelle Verhaltensmuster (Schritte 126-127) oder gruppenspezifische Verhaltensweisen stehen (Schritte 121-125);</li><li>d) Nachfolgende Datenauswertung (Block 130), wobei die aufbereiteten Daten (Matrix) mit einem oder mehreren kognitiven Modellen verglichen wird, um das sich ausprägende Verhaltensmuster bzw. die Verhaltensweise einem typischen Verhalten bzw. einem diesem zugrunde liegenden kognitiven Prozess zuzuordnen.</li></ol></p><p id="p0035" num="0035">Die Erfindung kann ein handelsübliches Gerät zur Aufzeichnung von Augen- und Blickverlaufsdaten (Eye-Tracker; Block 101) und eine Datenbank (Block 103) zur Speicherung der Daten verwenden. In der Datenbank kann auch eine Softwarebibliothek abgelegt sein, welche die Algorithmen zur automatischen Auswertung der Daten beinhaltet, sowie einer Arbeitsoberfläche und Repräsentationsschicht, welche die Module dem Endnutzer in einer intuitiven, seiner fachlichen Fragestellung gerechten Form zur Verfügung stellt.</p><heading id="h0001"><b>Die Erfindung ermöglicht eine schnelle und zuverlässige Zerlegung des Blickpfades in Fixierungen, Sakkaden und glatte Folgebewegungen:</b></heading><!-- EPO <DP n="11"> --><p id="p0036" num="0036">Denn es wird hier ein Verfahren bereit gestellt, welches eine ternäre Klassifizierung der Positionsdaten in Fixierungen, Sakkaden und glatte Folgebewegungen in robuster und in für die Untersuchung spezifischer Weise ermöglicht und welche vom Endanwender nicht parametrisiert werden müssen, bzw. eine intuitive, visuell geleitete Konfigurierung ermöglichen, wenn dies vom Anwender aus Gründen der Nachvollziehbarkeit und Validierung gewünscht ist. Außerdem erlaubt die Erfindung eine Anbindung der gewonnenen und aufbereiteten Daten an kognitive Architekturen (s. Block 130 in <figref idrefs="f0002">Fig. 2</figref>).</p><heading id="h0002"><b>Die Erfindung liefert eine Anbindung an kognitive Architekturen:</b></heading><p id="p0037" num="0037">Aufgrund der Komplexität der Prozesse, welche den Augen- und Blickbewegungen zugrunde liegen, existiert derzeit kein definitives Modell, was den empirischen Augen- und Blickverlauf erschöpfend beschreiben kann. Zum gegenwärtigen Stand der Forschung ist es vorherrschende Meinung, dass es sich, von einfachen Paradigmen abgesehen, um eine Mischung aus tiefliegenden physiologischen Basisprozessen (Bottom-Up) und höheren kognitiven Prozessen (Top-Down) handeln muss. Für die meisten in der Praxis relevanten Fragestellungen muss eine Modellierung beide Ebenen in Betracht ziehen. Um die höheren kognitiven Prozesse berücksichtigen zu können, stellt die vorgeschlagene Lösung eine Schnittstelle zu den gängigen kognitiven Architekturen bereit.</p><heading id="h0003"><b>Die Erfindung umfasst auch die Bildung von Gruppen von Betrachtern durch Maschinelles Lernen:</b></heading><p id="p0038" num="0038">Hierzu wird eine Kombination von Auswertungsmethoden vorgeschlagen, welche einen Vergleich und eine Klassifizierung von Blickpfaden über Versuchsgruppen hinweg in robuster Weise ermöglicht. Die Auswertung erfordert dabei keinen spezifischen Input vom Endnutzer, sondern liefert die Daten in der vom Endnutzer benötigten abstrahierten Form. Dazu müssen die Rohdaten in eine Form gebracht werden, die einen expliziten Vergleich in der Form von<!-- EPO <DP n="12"> --> Vergleichsmetriken ermöglicht. Die vorgeschlagene Lösung stellt derartige Metriken bereit und liefert die Klassifikation / Clusterung in der Form von Graphen. Desweiteren stellt die Lösung ebenfalls die geläufigen Metriken zur Verfügung, um zu etablierten Methoden kompatibel zu sein.</p><p id="p0039" num="0039">Eine verlässliche Bewertung des angenommenen Modells wird durch den expliziten Vergleich der Augen- und Blickverlaufsdaten möglichst umfangreicher Versuchsgruppen verbessert. Diese Vergleichsdaten können den gängigen statistischen Tests genügen. Die Lösung integriert gängige Teststatistiken, z.B. ANOVA, etc..</p><heading id="h0004"><b>Was die Datenspeicherung und Algorithmen-Implementierung angeht, so wird folgendes beachtet:</b></heading><p id="p0040" num="0040">Aufgrund der hohen Aufzeichnungsrate für die Daten (bis zu 2000 Hz und mehr), der zeitlichen Länge von praxisrelevanten Untersuchungen (ein Werbespot dauert einige zig Sekunden bis Minuten) sowie der Größe von Versuchsgruppen kommen sehr große Datenvolumina zustande. Deren effektive Verarbeitung erfordert selbst bei modernster Hardware entsprechend ausgebildete Verfahren, um die Arbeitslast für die Maschine und den Menschen möglichst gering zu halten. Die vorgeschlagene Lösung stellt dazu neuartige, im Zusammenhang mit Blickverlaufsdaten noch nicht verwendete, Verfahren bereit. Die Implementierung der Algorithmen nutzt die Möglichkeiten zum Rechnen auf Multiprozessor-Architekturen und dem Rechnen auf der / den Grafikkarte(n).</p><p id="p0041" num="0041">Ein weiterer wesentlicher Aspekt in der Umsetzung der integrierten Lösung ist der Laufzeitaspekt. Alle Auswertungen können interaktiv erfolgen und benötigen keine längeren Rechenzeiten auf einem handelsüblichen PC / Laptop. Dies ist eine für den Praxiseinsatz von großem Vorteil.</p><heading id="h0005"><b>Die Erfindung schlägt eine Augen- / Blickverlaufsbeschreibung durch Raum-Zeit-Matrix vor:</b></heading><!-- EPO <DP n="13"> --><p id="p0042" num="0042">Die Protokollierung der Positionsdaten erfolgt als eine endliche Folge von Blickpunkten <i>GP<sub>i</sub></i>. Die Blickpunkte werden als eine Liste von Zahlentripeln (<i>t</i>,<i>x</i>,<i>y</i>)<sub><i>i</i>∈{0,1,...,<i>n</i>}</sub> gespeichert. Die Menge der Zahlentripel {<i>GP<sub>i</sub></i>} sei bezeichnet mit <i>GP</i> = {<i>GP<sub>i</sub></i>}, wobei die Koordinaten <i>x</i>,<i>y</i>,<i>t</i> entweder kontinuierlich oder als diskret angenommen ("Pixelkoordinaten") werden, wobei die Messungen aufgrund der endlichen Messgenauigkeit immer diskret sind.</p><p id="p0043" num="0043">Die hier vorgeschlagene Lösung beschreibt die Daten durch eine Raum-Zeit-Matrix (Space-Time-Matrix, ST-Matrix, STM) [d]p, welche sämtliche mögliche Distanzen d (siehe auch S in <figref idrefs="f0005">Fig. 4a</figref>) zwischen allen Raum-Zeit-Punkten beinhaltet. Die Distanz d zwischen zwei Raum-(Zeit)-Punkten kann bzgl. mehrerer Metriken (Euklidisch, Minkowski I<sub>p</sub>, Minkowski Raum-Zeit) bestimmt werden. Dies führt zu einer bzgl. der jeweiligen Symmetriegruppe invarianten Darstellung. Um zu einem besseren intuitiven Verständnis zu gelangen, kann die Distanzmatrix als Graubild dargestellt werden. Das Graubild wird durch die (affine) Abbildung der nicht-negativen Distanzen in den Grauwertebereich erhalten. Dies sei exemplarisch für den oben gezeigten Pfad bzgl. der Euklidischen Metrik anhand der <figref idrefs="f0003 f0004">Figuren 3a-c</figref> gezeigt:</p><p id="p0044" num="0044">Die den Rohdaten, die durch das Sehstrahlendiagramm repräsentiert werden (<figref idrefs="f0003">Fig. 3a</figref> entspricht einer verkleinerten Darstellung der <figref idrefs="f0001">Fig. 1</figref>) können auch in einer dreidimensionalen Darstellung mittels Raum-Zeit-Punkten dargestellt werden (siehe <figref idrefs="f0003">Fig. 3b</figref> mit den Raumkoordinaten x, y und der Zeitkoordinate t). Die Matrix entspricht einer Kodierung bzw. eine Informations-Code für das Blickverhalten (engl. visual behavior). Durch die nachfolgend beschriebene Datenverarbeitung (Block 110 in <figref idrefs="f0002">Fig. 2</figref>) wird die Information weiter komprimiert , woraus sich eine hoch-effiziente und aussagekräftige Darstellung desBlickverhaltens ergibt.</p><p id="p0045" num="0045">Die Matrix M ist symmetrisch, da die (Euklidische) Distanz symmetrisch ist. Deutlich in der Matrix zu erkennen, ist eine blockartige/ rektanguloide/ rektilineare/ isothetische Struktur, welche die Clusterung des Pfades in der Raum-Zeit darstellt. Diese Struktur ist die Grundlage zur Extraktion der<!-- EPO <DP n="14"> --> Pfadabschnitte aus den Daten. Das isothetische Grundmuster bzgl. der Zeitachse macht die STM einfach auswertbar.</p><p id="p0046" num="0046">Anhand der <figref idrefs="f0005">Fig. 4a und 4b</figref> wird die Berechnung bzw. Bildung der Matrix näher veranschaulicht. Die <figref idrefs="f0005">Fig. 4a</figref> zeigt einen sehr vereinfachten Sehstrahlenverlauf (engl. gaze trajectory) ausgehend vom Blickpunkt A bis zum Blickpunkt E. Die <figref idrefs="f0005">Fig. 4a</figref> zeigt zum einfacheren Verständnis nur den Anfang eines Blickverlaufs und nicht einen kompletten Blickverlauf wie z.B. in <figref idrefs="f0001">Fig. 1</figref>. Jeder Blickpunkt wird durch ein Zahlentrippel repräsentiert, das die Zeit t, und die jeweiligen Raumkoordinaten X und Y angibt. Der Blickpunkt E hat beispielsweise das Zahlentrippel (t4, x4, y4), welches auch aus Zahlengruppe Z4 verstanden werden kann. Erfindungsgemäß werden nun die Zahlengruppen Z0 Z1, Z2, Z3, Z4, ...Zn paarweise miteinander kombiniert, wobei jeweils die Distanz S (siehe <figref idrefs="f0005">Fig. 4a</figref>) zwischen den zwei Bildpunkten ermittelt und in eine Matrix M (s. <figref idrefs="f0005">Fig. 4b</figref>) eingetragen wird.</p><p id="p0047" num="0047">In der <figref idrefs="f0005">Fig. 4b</figref> ist der Aufbau der Matrix M veranschaulicht. Der Wert W2/4 gibt die Distanz zwischen den Blickpunkten E und C bzw. Zahlengruppen Z2 und Z4 an. Die Operation wird für alle möglichen Kombination durchgeführt. Bei einer Abtastfrequenz von 1000 Hz ergibt sich innerhalb eines Messzeitraumes von 1 Sekunde bereits ein Datenvolumen vom 1000x1000 Zahlentrippeln. Dieses Datenvolumen wird aber durch die später beschriebenen Filterungen deutlich reduziert.</p><p id="p0048" num="0048">Zunächst erhält man eine recht umfangreiche erste Matrix. Dies wird anhand eines weiteren Beispiels (<figref idrefs="f0006">Fig. 5a und 5b</figref>) veranschaulicht:</p><p id="p0049" num="0049">Wie dort in <figref idrefs="f0006">Fig. 5a</figref> gezeigt, ist der Blickverlauf etwas umfangreicher als in <figref idrefs="f0005">Fig. 4a</figref>, wobei der Blick zunächst vom Bereich A (erste Fixierung) ausgeht und zum Bereich B (zweite Fixierung) springt (erste Sakkade). Dann geht es zum Bereich C (dritte Fixierung) und von dort zurück zum Bereich A (vierte Fixierung) und dann zum Bereich D. Es wird also die erste Fixierung A nochmals aufgesucht,<!-- EPO <DP n="15"> --> d.h. die Daten der ersten Fixierung korrelieren stark mit den Daten der vierten Fixierung.</p><p id="p0050" num="0050">Dieses Blickverhalten (engl. visual behavior) wird nicht vollkommen durch das Blickverlaufs-Diagramm der <figref idrefs="f0006">Fig. 5a</figref> (oder <figref idrefs="f0005">Fig. 4a</figref>) wiedergegeben, weil bei dieser Darstellung nur die räumliche Dimension gezeigt werden kann und nicht auch die zeitliche Dimension. Allerding wird das Blickverhalten vollkommen in der Struktur der erhaltenen Matrix M' nach <figref idrefs="f0006">Fig. 5</figref> wiedergegeben (ebenso durch M in <figref idrefs="f0005">Fig. 4b</figref>):</p><p id="p0051" num="0051">Ausgehend von t=0 (linke obere Ecke) bis zu t= 1000 (rechte untere Ecke) zeigt sich zunächst ein größeres dunkles Quadrat, dessen Ausdehnung die zeitliche Verweildauer am Fixierungsbereich A wiedergibt. Dann folgt (entlang der Diagonalen) ein etwas kleines dunkles Quadrat, dessen Ausdehnung die zeitliche Verweildauer am Fixierungsbereich B wiedergibt. Die benachbarten Flächen (Kopplungsfelder) zeigen durch ihren Grauwert an, dass dieses zweite Quadrat einen anderen Fixierungsbereich (nämlich B) angibt, der zu dem ersten Bereich A beabstandet ist. Die Grauwerte sind also ein Maß für die Distanz zwischen den Bereichen A, B, C .... Wie anhand des vorletzten Quadrats zu erkennen ist, gibt es zwei sehr dunkle Flächen, die diesem und dem ersten Quadrat zugeordnet sind (dieselbe Spalte bzw. Reihe). Der hohe Grauwert zeigt an, dass die beiden Quadrate sehr wenig voneinander beabstandete Bereichen betreffen: Das vorletzte Quadrat (auf der Diagonalen) betrifft nämlich auch den Bereich A (siehe Rücksprung in <figref idrefs="f0006">Fig. 5a</figref>). Das letzte Quadrat hat mit dem ersten Quadrat jedoch nur fast weiße Kopplungsfelder gemein, d.h. das letzte Quadrat betrifft einen Bereich (nämlich D), der sehr weit vom ersten Bereich A entfernt ist.</p><p id="p0052" num="0052">Das Datenvolumen der Matrix M bzw. M' kann deutlich verringert werden, ohne dass die Aussagefähigkeit der Matrix-Struktur darunter leidet. Im Gegenteil: Durch die hier vorgeschlagene Datenreduzierung (Filterung, Schwellwert) wird die Prägnanz der Matrixstruktur noch weiter erhöht (gefilterte Matrix in <figref idrefs="f0007">Fig. 6a</figref>) und kann sogar in eine standardisierte Darstellung überführt werden (Scharz-Weiss-Matrix quasi wie 2D-Matrixcode in <figref idrefs="f0007">Fig. 6b</figref>), um mit üblichen Darstellungen ("ABC-String") in Einklang gebracht werden zu können.<!-- EPO <DP n="16"> --></p><heading id="h0006"><b>Die Erfindung umfasst auch eine Extraktion der Pfadabschnitte durch Raum-Zeit-Filterung:</b></heading><p id="p0053" num="0053">Eine grundlegende Beschreibung des Blickpfades (engl. scanpath), wie es gegenwärtiger Stand ist, erfolgt durch die symbolische Angabe der Fixierungen als eine Buchstabenfolge "ABCADEBE..." sowie die den Fixierungen zugeordneten Größen - Dauer einer Fixation/ Ausmaß einer Fixation. Desweiteren können Größen zur Charakterisierung einer Sakkade bestimmt werden - Sprungweite einer Sakkade / Richtung einer Sakkade. Die gängigen Lösungen erreichen die Extraktion dieser Größen durch die Ableitung der Sakkaden aus den Pfaddaten gemäß der eingangs genannten Kriterien. Hierzu ist oftmals eine händische Datenauswertung erforderlich. Die Fixierungen werden dann als die Abschnitte zwischen den Sakkaden gesetzt.</p><p id="p0054" num="0054">Die vorgeschlagene Lösung extrahiert die interessierenden Größen dagegen aus der Raum-Zeit-Matrix und kann voll-automatisch durchgeführt werden. Die Extraktion erfolgt in mehreren Schritten. Der erste Schritt besteht in einer Filterung der Raum-Zeit (Space-Time-Filtering <i>STF</i>). Dies ist eine anisotrope Filterung mit zwei gekoppelten Kernen, z.B. zwei Gauß-Kernen: <maths id="math0002" num=""><math display="block"><mi mathvariant="italic">STF</mi><mfenced><msub><mfenced open="[" close="]"><mi>d</mi></mfenced><mi>p</mi></msub></mfenced><mo>=</mo><mfrac><mn>1</mn><msub><mi>W</mi><mi>p</mi></msub></mfrac><mstyle displaystyle="false"><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>q</mi><mo>∈</mo><msup><mi>T</mi><mn>2</mn></msup></mrow></munder></mstyle><msub><mi>G</mi><msub><mi>σ</mi><mi>t</mi></msub></msub><mo>⁢</mo><mfenced separators=""><mo>‖</mo><mi>p</mi><mo>-</mo><mi>q</mi><mo>‖</mo></mfenced><mo>⁢</mo><msub><mi>G</mi><msub><mi>σ</mi><mi>s</mi></msub></msub><mo>⁢</mo><mfenced><mfenced open="|" close="|" separators=""><msub><mi>d</mi><mi>p</mi></msub><mo>-</mo><msub><mi>d</mi><mi>q</mi></msub></mfenced></mfenced><mo>⁢</mo><msub><mi>d</mi><mi>q</mi></msub></mstyle></math><img id="ib0002" file="imgb0002.tif" wi="109" he="20" img-content="math" img-format="tif"/></maths></p><p id="p0055" num="0055">Der Faktor Wp normalisiert die Gauß-Gewichte zu 1: <maths id="math0003" num=""><math display="block"><msub><mi>W</mi><mi>p</mi></msub><mo>=</mo><mstyle displaystyle="false"><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>q</mi><mo>∈</mo><mi>S</mi></mrow></munder></mstyle><msub><mi>G</mi><msub><mi>σ</mi><mi>t</mi></msub></msub><mo>⁢</mo><mfenced separators=""><mo>‖</mo><mi>p</mi><mo>-</mo><mi>q</mi><mo>‖</mo></mfenced><mo>⁢</mo><msub><mi>G</mi><msub><mi>σ</mi><mi>s</mi></msub></msub><mo>⁢</mo><mfenced><mfenced open="|" close="|" separators=""><msub><mi>d</mi><mi>p</mi></msub><mo>-</mo><msub><mi>d</mi><mi>q</mi></msub></mfenced></mfenced></mstyle></math><img id="ib0003" file="imgb0003.tif" wi="77" he="21" img-content="math" img-format="tif"/></maths></p><p id="p0056" num="0056">Die Parameter σ<i><sub>t</sub></i> und σ<i><sub>s</sub></i> sind dabei primär nicht als numerischen Parameter zu betrachten, sondern als Parameter mit grundlegender physiologischer Relevanz und hängen damit vom physiologischen / psychologischen Modell ab. Ein kleines σ<i><sub>t</sub></i> bedeutet eine enge zeitliche Kohärenz im Prozess der Betrachtung und ein<!-- EPO <DP n="17"> --> kleines σ<i><sub>s</sub></i> bedeutet eine enge räumliche Kohärenz zwischen den betrachteten Inhalten. Die Vorgehensweise der Filterung ist analog der bilateralen Bildverarbeitung. Das Ergebnis ist ein reduziertes Schema, welches die Grundinformationen zum Prozess auf Ebene der Augen- / Blickdaten in zweidimensionaler Form enthält. Ein solches Schema zeigt die geglättete (engl. smooth filtered) Matrix M* in <figref idrefs="f0007">Figur 6a</figref>.</p><p id="p0057" num="0057">Die quadratischen Blöcke entlang der Hauptdiagonalen der Matrix (s. auch <figref idrefs="f0006">Fig. 5b</figref>) kodieren die Fixierungen. Die Kantenlänge, bzw. die Anzahl der Zellen entlang der Diagonalen eines Blocks, ist die Dauer der Fixierung. Die Grauwerte in den quadratischen Blöcken entlang der Diagonalen der Raum-Zeit-gefilterten STM (durch Glätten bzw. anisotropes Filtern erhaltende Matrix M*) entsprechen dabei der mittleren räumlichen Ausdehnung der Fixation. Die Grauwerte in den rechteckigen Blöcken im restlichen Teil der Matrix entsprechen den mittleren Abständen zwischen den Fixierungen. Durch das Setzen eines Schwellenwertes für den räumlichen Abstand in der STM auf die räumliche Dispersion einer mittleren Fixierung kann die Matrix weiter vereinfacht werden, woraus sich eine Schwellwert-gefilterte Matrix M** ergibt. Dies wird anhand der <figref idrefs="f0007">Fig. 6b</figref> im Vergleich mit <figref idrefs="f0007">Fig. 6a</figref> veranschaulicht. Demnach wird aus der ersten Matrix (s. M in <figref idrefs="f0001">Fig. 1</figref> oder M' in <figref idrefs="f0006">Fig. 5b</figref>) eine erste Glättungs-gefilterte Matirx M* erzeugt, aus der wiederum eine dritte Schwellwert-gefilterte Matrix M** erzeugt werden kann. Diese Matrix M** kann auch direkt aus der ersten (Rohdaten-) Matrix M bzw. M' erzeugt werden.</p><p id="p0058" num="0058">In dieser Darstellung entspricht die äußere Form der Codierung des Blickpfades der bekannten Matrix Code Kodierung, wie sie z.B. bei DataMatrix zur Kodierung von Internet-Links, Postwertzeichen, Waren, etc. Verwendung findet. Ersetzt man jetzt die Quadrate der Diagonalen durch Buchstaben und berücksichtigt dabei die Kopplungen, so erhält man die zum gegenwärtigen Zeitpunkt übliche Darstellung des Blickpfades durch eine Buchstabenfolge (Stringdarstellung) "ABCACD". Dies wird anhand der <figref idrefs="f0008">Figuren 7a und 7b</figref> veranschaulicht.<!-- EPO <DP n="18"> --></p><p id="p0059" num="0059">Die Darstellung des Blickpfades als Buchstabenfolge ("ABC-String") ist der momentane Standard. Die Ableitung zeigt aber auch, wie viel Information auf den Weg zur Stringdarstellung verworfen wurde.</p><p id="p0060" num="0060">Die Bereitstellung / Berücksichtigung dieser Information ist ebenfalls Gegenstand der Erfindung. Dazu schlägt die Erfindung die Codierung des Blickpfades in der Form eines erweiterten Matrix Codes gemäß der <figref idrefs="f0006">Figur 5b</figref> vor. Der Matrix Code ist erweitert, weil er keine schwarzen/weißen Module sondern Module mit Grauwerten nutzt, Matrix-Grauwerte-Code. Diese Darstellung verschlüsselt wesentlich mehr Information als die Stringdarstellung und ist die Grundlage erweiterter Auswertungen. Zu Zwecken der Vergleichbarkeit kann die vorgeschlagene Lösung aber auch mit der Stringdarstellung arbeiten. So werden die Levenshtein-Distanzen zwischen Strings bestimmt.</p><p id="p0061" num="0061">Die anisotrope Filterung lässt sich als der Grenzfall einer anisotropen Diffusion auffassen, welche durch eine Partielle Differentialgleichung beschrieben wird. Durch die geeignete Wahl des Diffusionstensors lassen sich weitere gesuchte Aspekte aus der STM extrahieren. Dies ermöglicht insbesondere, die glatte Folgebewegung sauber aus den Daten zu extrahieren. Die glatte Folgebewegung (engl. smooth pusuit) ist bei dynamischen Szenen relevant, wo der Betrachter mit den Augen einem bewegten Objekt folgt. Für die automatische Bestimmung der glatten Folgebewegung gibt es zurzeit noch keinen Standard. Die simultane ternäre Bestimmung von Sakkaden, Fixierungen und glatten Folgebewegungen für dynamische Szenen gilt als außergewöhnlich kompliziert. Die Anwendung einer anisotropen Diffusion auf die Space-Time-Matrix STM lässt diesen Abschnitt im Blickpfad neben den Fixierungen und Sakkaden einfach erkennen. In der <figref idrefs="f0009">Fig. 8</figref> ist beispielhaft eine Matrix M" dargestellt, in welcher der Bereich der glatten Folgebewegung SPPS eine Linien- bzw. Gradienten-Struktur zeigt im Gegensatz zu den Sakkaden SAC, die scharfe Kanten bzw. Ecken aufweisen. Die Matrix M" kann als vierte Matrix verstanden werden, welche die Anwendung einer anisotropen Diffusion aus der ersten Matrix (siehe z.B. Matrix M' in <figref idrefs="f0006">Fig. 5b</figref>) gewonnen wird.<!-- EPO <DP n="19"> --></p><heading id="h0007"><b>Die Erfindung umfasst auch einen Vergleich von Blickpfaden:</b></heading><p id="p0062" num="0062">Für die weitergehenden Auswertungen ist die (informationstheoretische) Struktur der Distanzmatrix maßgeblich (s. auch Block 120 in <figref idrefs="f0002">Fig. 2</figref>). Grundlegend für das weitere Vorgehen ist die Informationsäquivalenz zwischen der Distanzmatrix und dem Spektrum der Distanzen. Das heißt formal, dass die Verteilung der Distanzen (Spektrum der Distanzen) <i>his<sub>GP</sub></i>(d)≡#{(i,j)|0≤ i&lt; j ≤ n, d(<i>GP<sub>i</sub></i>, <i>GP<sub>j</sub></i>) = d} <i>his<sub>GP</sub></i>(d)=#{(i,j)|0≤ i &lt; j ≤ n, d(<i>GP<sub>i</sub></i>, <i>GP<sub>j</sub></i>) = d} im wesentlichen nur einen Blickpfad als Lösung besitzt. Damit lassen sich zwei Blickpfade bzw. zwei unterschiedliche Ausschnitte aus einem Blickpfad, durch einen Vergleich der jeweiligen Histogramme in Beziehung setzen. Als Ähnlichkeitsmaß dienen die üblichen Distanzmaße für Spektren, wie z.B. die Kullback-Leibler Divergenz, Jensen Shannon Divergenz, X<sup>2</sup>-Tests, Kolmogorov-Smirnov-Test, Earth-Mover's-Distance, Histogramm-Durchschnitt, Kosinus-Distanz, Euklidische-Distanz, etc.</p><p id="p0063" num="0063">Eine Steigerung oder Reduktion in der Vergleichstiefe lässt sich erreichen, wenn die übergeordnete Struktur der Distanzmatrix betrachtet bzw. nicht betrachtet wird. Dazu wird die Struktur der Distanzmatrix als Textur aufgefasst. Ausgewertet wird das Tamura-Textur-Histogramm, Gabor-Features, Local-Image-Feaure-Patches-Histogramm, Local-Image-Feature-SIFT-Histogramm, Edge-Histogramm, ...</p><p id="p0064" num="0064">Die Erfindung stellt weitere Varianten zum Vergleich von Blickpfaden bereit. Dies wird hier unter Bezugnahme auf die <figref idrefs="f0012 f0013 f0014">Figuren 11-13</figref> beschrieben. In der <figref idrefs="f0014">Fig. 13</figref> werden die Verarbeitung/Aufbereitung und der Vergleich von zwei Blickpfaden veranschalicht, die durch zwei Matrizen STMa und STMb repräsentiert werden.</p><p id="p0065" num="0065">Eine Variante beruht auf der normalisierten Kompressionsdistanz der in der Form von STMs kodierten Blickpfade.<!-- EPO <DP n="20"> --> <maths id="math0004" num="(1)"><math display="block"><mi>x</mi><mo>=</mo><mfrac><mrow><mi mathvariant="normal">C</mi><mfenced separators=""><mi mathvariant="normal">a</mi><mo>⁢</mo><mi mathvariant="normal">b</mi></mfenced><mo>-</mo><mi>min</mi><mfenced open="{" close="}" separators=""><mi>C</mi><mfenced><mi>a</mi></mfenced><mo>,</mo><mi>C</mi><mfenced><mi>b</mi></mfenced></mfenced></mrow><mrow><mi>max</mi><mfenced open="{" close="}" separators=""><mi mathvariant="normal">C</mi><mfenced><mi mathvariant="normal">a</mi></mfenced><mo>,</mo><mi mathvariant="normal">C</mi><mfenced><mi mathvariant="normal">b</mi></mfenced></mfenced></mrow></mfrac></math><img id="ib0004" file="imgb0004.tif" wi="105" he="28" img-content="math" img-format="tif"/></maths></p><p id="p0066" num="0066">C(a) und C(b) bezeichnen die Länge in Bit der komprimierten STMs (Raum-Zeit-Matrizen) der Pfade a und b, C(a,b) bezeichnet die Länge des kombinierten Pfades aus a und b. Die Komprimierung der Pfade erfolgt dabei mit den standardmäßigen Verfahren der Informatik zur Datenkomprimierung, jedoch in einer auf die Problemstellung zugeschnittenen Weise. Die Komprimierung der jeweiligen STM (siehe STMa, STMb sowie kombinierte STMa,b in <figref idrefs="f0014">Fig. 13</figref>) stellt die Approximation an die Kolmogorov-Komplexität der jeweiligen STM dar, welche definiert ist, als die Länge des kürzesten Programms zur Berechnung der STM auf einem universellen Computer. Dies sei im Folgenden an zwei Beispielen erläutert. Es sei festgehalten, dass die Wahl des Komprimierungsverfahrens prinzipiell beliebig sein kann. Insbesondere ermöglicht aber die der Struktur der STM angepasste Wahl die Fokussierung auf die aus fachlicher Sicht interessierenden Aspekte und verkürzt die Rechenzeit auf praktikable Zeiten. Die Erfindung macht sich deshalb die an sich bekannten gängigen Verfahren der Informatik zur Datenkomprimierung zu Nutze und ermöglicht dem Endnutzer eine variable Vorgehensweise. Die Nutzung der Kolmogorov-Komplexität als theoretische Grundlage zur Datenanalyse ist in der Literatur bekannt und wird deshalb nicht weiter ausgeführt. Für die Erfindung maßgeblich ist deren konkrete Implementation in der Kombination mit der STM:</p><p id="p0067" num="0067">Die erfindungsgemäße Bestimmung dieser speziellen Distanz geschieht in zwei generellen Schritten (s. auch <figref idrefs="f0014">Fig. 13</figref>): In einem ersten Schritt wird die STM (z.B. STMa) in Untermatrizen (m1, m2, ...) zerlegt, wobei deren Größe variabel ist. Diese richtet sich nach der Samplingrate des Eye-Trackers und der für die Fragestellung sinnvollen physiologischen Zeitskala (wenn Fixationen betrachtet werden, liegt diese im Bereich von 100 ms). So könnte eine 128x128 Matrix in 16x16 8x8 Matrizen zerlegt werden. Eine Potenz von 2 ist nicht erforderlich, vereinfacht aber die Skalierung. Die einzelnen Untermatrizen werden anschließend einer diskreten harmonischen Analyse unterzogen (s. HAN in <figref idrefs="f0014">Fig.<!-- EPO <DP n="21"> --> 13</figref>). Dazu kommen mehrere Funktionen-Systeme zum Einsatz. Die Wahl des Systems hängt von der Detailtiefe der STM ab. So sind Walsh-Funktionen für die gefilterte Schwarz-Weiß-Matrix besonders geeignet. In der beiliegenden <figref idrefs="f0012">Fig. 11</figref> werden beispielhaft die Walsh-Funktionen für das 8x8-System gezeigt.</p><p id="p0068" num="0068">Ein für die Darstellung im Grauwertbereich geeignetes System besteht aus den diskreten Cosinus-Funktionen. In der <figref idrefs="f0013">Fig. 12</figref> werden hierzu ebenfalls die für ein 8x8 System genutzten Cosinus-Funktionen gezeigt.</p><p id="p0069" num="0069">Die Ergebnisse der harmonischen Analyse HAN, die auf jede Untermatrix m1, m2, ... einer jeden STM angewendet wird (d.h. auf die Untermatrizen von STMa, STMb und STMa,b), sind transformierte Untermatrizen m1*, m2* ... des verwendeten Basis-Systems (z.B. Walsh). Dies bedeutet, dass jede Untermatrix (z.B. m1*) die Gewichte der jeweiligen Walsh-Funktion repräsentiert. Der erste Eintrag oder das bedeutendsten Gewicht (engl. most significant weight) in den Untermatrizen ist prädiktions-kodiert.</p><p id="p0070" num="0070">Der zweite Schritt beinhaltet den eigentlichen Vergleich durch Kompression CMPR. Dieser beruht auf einer Entropie-Kodierung der transformierten Pfade in separater und in kombinierter Fassung. Die Transformations-Gewichte werden dazu entweder blockweise kodiert oder in für jede Basisfunktion separaten Sequenzen kodiert. Die Entropie-Kodierung erfolgt z.B. in der Form einer Huffman-Kodierung oder einer arithmetischen Kodierung. Da es nur auf den relativen Vergleich der Kompressionsrate ankommt, dient die arithmetische Kodierung der theoretischen Untersuchung des Verfahrens. Die komprimierten Matrizen A*, B* und AB* enthalten im Wesentlichen die bedeutendsten Koeffizienten (engl. most significant coefficients) und weisen dadurch ein (deutlich) reduziertes Volumen gegenüber den Eingangs-Matrizen auf. Die Kompressionsrate (etwa 10-40%) bzw. das verringerte Volumen kann durch die Werte C(a), C(b) und (Ca,b) ausgedrückt werden. Dies bedeutet"dass in der finalen Form drei kodierte Blickpfade vorliegen, die gemäß obiger Gleichung (1) zu einem Distanzausdruck bzw. Ähnlichkeitswert verbunden werden. Dies geschieht für alle zu vergleichenden Pfadpaare. Das Ergebnis ist eine<!-- EPO <DP n="22"> --> Koeffizienten-Matrix (siehe Ähnlichkeits-Matrix SMAT in <figref idrefs="f0014">Fig. 13</figref>), welche als Input für Clusterverfahren dient. Das Clustering erfolgt mit den gängigen Verfahren aus dem Datamining und liefert z.B. einen hierarchisch gegliederten Baum oder eine Self-organizing map.</p><p id="p0071" num="0071">Die beschriebenen Vergleiche sind wesentlich exakter und tiefliegender als die momentan in der Literatur beschriebenen Verfahren. Diese repräsentieren die Folge der Fixierungen in einer Zeichenkette und nutzen dann die String-Editing Distanz und dynamische Programmierung als Maß für die Ähnlichkeit bzw. Unähnlichkeit. Die Bestimmung des Strings erfolgt dabei durch die Zuordnung der im ersten Schritt bestimmten Fixierungen auf die im Stimulus / Szene vorhandenen Areas-of-Interest (AOI) oder auch Regions-of-Interest (ROI). Die Bestimmung der AOI kann dabei durch eine einfache Gitterung des Raumes / der Ebene oder durch vom Endnutzer nach menschlichen Ermessen bestimmten Kriterien erfolgen (Gridded AOI und Semantic AOI). Eine weitere Aggregation kann durch die Clusterung der Fixierungen durch Clusteralgorithmen erfolgen.</p><heading id="h0008"><b>Die Erfindung umfasst auch die Darstellung der Blickverlaufsdaten und die Formulierung einer Hypothese zum Blickpfad:</b></heading><p id="p0072" num="0072">Die erhobenen Blickverlaufsdaten im Zusammenhang mit der dargebotenen Szene erlauben eine Bestimmung des Netzhautbildes des Betrachters. Dies ermöglicht es, die so bestimmte Szene in der Form einer 3D-Darstellung dem Auswerter zur Verfügung zu stellen. Der Auswerter sitzt gewissermaßen im Auge der Versuchsperson. Dadurch kann der Auswerter ein genaues subjektives Bild darüber gewinnen, was die Versuchsperson betrachtet hat. Dies erlaubt es, genauer eine Hypothese über den Blickverlauf im Zusammenhang mit der Szene zu formulieren. Die Darstellung der Szene kann dabei in 3D erfolgen, wobei der 3D Effekt durch Farbverschiebung als auch durch den Einsatz einer Shutter-Technologie erreicht wird. Wahlweise kann auch die 2D Darstellung erfolgen. Diese sei exemplarisch anhand der <figref idrefs="f0010">Figur 9</figref> gezeigt, da eine 3D-Darstellung nicht in gedruckter Form (auf Druckpapier etc.) möglich ist.<!-- EPO <DP n="23"> --></p><heading id="h0009"><b>Zum Formulieren einer Hypothese zum Blickpfad ist folgendes zu sagen:</b></heading><p id="p0073" num="0073">Die betrachtete Szene kann räumlich quantisiert werden. Die Raumbereiche entsprechen dabei den ROIs. Mit der Maus kann durch Tasteneinzeldruck die Fixation in einer ROI simuliert werden. Die Anzahl der Tastendrücke entspricht der Dauer der Fixation. Diese ist als Parameter frei wählbar. Der so gewonnene hypothetische Blickpfad wird protokolliert und kann danach mit den Versuchsdaten der Einzelpersonen in der Datenbank verglichen werden. Die statistische Auswertung der Ähnlichkeiten zwischen den Hypothesen und den Beobachtungsdaten gibt dann die nötige Sicherheit zu Wahrscheinlichkeit der formulierten Hypothese. Durch dieses Vorgehen kann auf hoher abstrakter Ebene ein Prozessmodel für die Augen- / Blickdaten gewonnen werden und direkt an den experimentellen Daten getestet werden. Siehe <figref idrefs="f0011">Figur 10</figref>.</p><heading id="h0010"><b>Die Erfindung ermöglicht auch den Export des Blickprozesses in einen kognitiven Prozess:</b></heading><p id="p0074" num="0074">Die Interpretation des so gewonnenen Prozessmodells für die Augen- / Blickdaten geschieht in einem Kognitiven Modell (s. auch Block 130 in <figref idrefs="f0002">Fig. 2</figref>). Es existieren innerhalb der Psychologie mehrartige Kognitive Modelle / Architekturen, z.B. ACT, SOAR, EPIC, etc. Die vorgeschlagene Erfindung stellt eine Schnittstelle bereit, um das Prozessmodell für die Augen- Blickdaten an das Prozess-Modell für den kognitiven Prozess anzubinden.</p><heading id="h0011"><b>Zudem umfasst die Erfindung eine integrierte Datenspeicherung:</b></heading><p id="p0075" num="0075">Aufgrund der weitreichenden fachlichen Fragestellungen ist das Sammeln und der Austausch von Daten durch multizentrische Studien wünschenswert. Dies erfordert eine möglichst offene und einfach strukturierte Datenorganisation. Die Lösung beinhaltet zwei Formen der Datenspeicherung. Für die Verwaltung umfangreicher Datensätze steht eine Anbindung an eine marktgängige relationale SQL-Datenbank zur Verfügung. Weiterhin können die Daten in XMLformatierter Weise in Textdateien direkt gespeichert werden (NoSQL Konzept).<!-- EPO <DP n="24"> --> Während der Laufzeit des Programes arbeitet die Lösung aufgrund der Performance mit einer In-Memory-Datenbank. Bei der Anlegung der einzelnen Datensätze vergibt die Lösung GUIDs, um bei multizentrischen Studien die Mehrfachvergabe von Schlüsseln zu vermeiden und damit die Zusammenführung von mehreren Datensätzen zu ermöglichen.</p><heading id="h0012"><b>Zusammenfassend können folgende Eigenschaften hier kurz festgehalten werden:</b></heading><p id="p0076" num="0076">Die Erfindung liefert ein Verfahren zur Erhebung, Sammlung, Darstellung und/oder Auswertung von Blickverlaufsdaten in integrierter Umgebung. Die Darstellung von Augen- / Blickbewegungen erfolgt über einen Matrix-Grauwerte-Code.</p><p id="p0077" num="0077">Die Erfindung leistet eine simultane ternäre Zerlegung von Augen - bzw. Blickbewegungen in Fixierungen, Sakkaden und glatten Folgebewegungen bei der Betrachtung von statischen und dynamischen Szenen. Es wird ein Vergleich von Blickpfaden durch Vergleiche von Histogrammen für verschiedene Features ermöglicht.</p><p id="p0078" num="0078">Das hier vorgeschlagene Verfahren dient u.a. zur Erhebung von Blickverlaufsdaten für vorgegebene Paradigmen, wie Freie Betrachtung, Search Task, Raven's progressive Matrizen, Stroop, Change Blindness, etc.. Das Verfahren dient auch zur Erhebung von frei vorgegebenen statischen und dynamischen Szenen, wie der Betrachten eines Werbeplakates, Werbespots, Films, Videospiels, Flug-/Fahrsimulation, Interaktion mit einer grafischen Benutzeroberfläche. Es ermöglicht die manuelle Definition von ROIs über statischen und dynamischen Szenen. Auch ermöglicht das Verfahren eine automatische Bestimmung von statischen und dynamischen ROIs.</p><p id="p0079" num="0079">Das Verfahren ist zur Speicherung von Blickverlaufsdaten für multizentrische Studien im Zusammenhang mit den Daten der Blickparadigmen geeignet. Auch ist das Verfahren zur automatischen Segmentierung des untersuchten Kollektivs<!-- EPO <DP n="25"> --> in Ähnlichkeitscluster geeignet. Es wird u.a. eine statistische und visuelle Darstellung der Befunde in integrierter Umgebung erzielt.</p><p id="p0080" num="0080">Das Verfahren eignet sich zur 3D Darstellung der Blickdaten / Rückrechnung der Daten auf das Sehfeld und dessen Darstellung als 3D Szene. Auch eignet sich das Verfahren zur freien Definition einer Hypothese zum Blickverlauf und Vergleich der Hypothese mit den Daten der Datenbank sowie statistische Tests zur Hypothese.</p><p id="p0081" num="0081">Die ersten Aspekte der vorliegenden Erfindung werden hier nochmals unter Bezugnahme auf die <figref idrefs="f0001 f0002 f0003 f0004 f0005 f0006 f0007 f0008 f0009 f0010 f0011">Figuren 1-10</figref> zusammenfasst:</p><p id="p0082" num="0082">In dem erfindungsgemäßen Verfahren (s. <figref idrefs="f0002">Fig. 2</figref>) zur Kodierung von Augen- und Blickverlaufsdaten DAT, werden diese Daten als Zeit- und Raumparameter t, x, y (s. <figref idrefs="f0003">Fig. 3b</figref> und <figref idrefs="f0005">4a</figref>) in Form von Zahlengruppen Z0, Z1, Z2... (s. <figref idrefs="f0005">Fig. 4b</figref>) angeben, welche mittels einer Blickerfassungsvorrichtung ET gewonnen werden und welche jeweils einem Blickpunkt A, B, C, D, E ... innerhalb eines Blickpfades (z.B. Blickpfad a in <figref idrefs="f0005">Fig. 4a</figref>) zugeordnet werden, wobei aus den Zahlengruppen paarweise jeweils Zahlenpaare (z.B. Z0,Z1; Z0,Z2; Z0,Z3...) miteinander kombiniert werden, um für jede Kombination einen Wert (siehe z.B. W2/4 in <figref idrefs="f0005">Fig. 4b</figref>) zu erhalten, der zumindest den räumlichen Abstand S zwischen den zwei Blickpunkten (z.B. E, C) angibt, denen das jeweilige Zahlenpaar (d.h. Z2, Z4) zugeordnet ist, wobei die erhaltenen Werte eine Kodierung bzw. einen Code für die Augen- und Blickverlaufsdaten DAT darstellen.</p><p id="p0083" num="0083">Die Zahlengruppen (Z0, Z1, Z2...) können entsprechend der Zeit- und Raumparameter (t, x, y) in Zahlentrippel (t0, x0, y0; t1, x1, y1, ...) dargestellt werden, wobei aus den Zahlentrippeln paarweise jeweils zwei Zahlentrippel miteinander kombiniert werden, um für jede Kombination einen Wert (W2/4) zu erhalten, der zumindest den zeitlichen und räumlichen Abstand (S) zwischen den zwei Blickpunkten (E, C) angibt.<!-- EPO <DP n="26"> --></p><p id="p0084" num="0084">Erfindungsgemäß werden bevorzugter Weise diese Werte in Form einer ersten Matrix (siehe z.B. M in <figref idrefs="f0004">Fig. 3c</figref> und <figref idrefs="f0005">4b</figref>), die den jeweiligen Blickpfad (a) repräsentiert, erfasst und gespeichert. Dabei kann die erste Matrix (M, M') einer Glättungs-Filterung, insbesondere einer anisotropen Filterung, unterzogen werden, um eine zweite Matrix (siehe M* in <figref idrefs="f0007">Fig. 6a</figref>) zu erhalten, die gegenüber der ersten Matrix (M) einen reduzierten Datenumfang aufweist.</p><p id="p0085" num="0085">Auch kann die erste oder zweite Matrix (M; M*) einer Schwellwert-Filterung unterzogen werden, um eine dritte Matrix (siehe M** in <figref idrefs="f0007">Fig. 6b</figref>) zu erhalten, die gegenüber der ersten bzw. zweiten Matrix (M*) einen reduzierten Datenumfang aufweist.</p><p id="p0086" num="0086">Vorzugsweise wird die erste Matrix (siehe auch M' in <figref idrefs="f0006">Fig. 5b</figref>) einer Glättungs-Filterung in Form einer anisotropen Diffusion unterzogen wird, um eine vierte Matrix (siehe M" in <figref idrefs="f0009">Fig. 8</figref>) zu erhalten, die gegenüber der ersten Matrix (M') einen reduzierten Datenumfang aufweist. Dabei stellen die erste, zweite, dritte und/oder vierte Matrix eine Kodierung für Fixierungen und Sakkaden des Blickpfades (a) dar.</p><p id="p0087" num="0087">Die weiteren Aspekte der vorliegenden Erfindung werden hier nochmals unter Bezugnahme auf die <figref idrefs="f0012 f0013 f0014">Figuren 11-13</figref> zusammenfasst, wobei erkennbar wird, dass diese Aspekte auch als eigenständige Erfindung aufgefasst werden können: Die Erfindung stellt weitere Varianten zum Vergleich von Blickpfaden bereit. Dies wird hier unter Bezugnahme auf die <figref idrefs="f0012 f0013 f0014">Figuren 11-13</figref> beschrieben. In der <figref idrefs="f0014">Fig. 13</figref> werden die Verarbeitung/Aufbereitung und der Vergleich von zwei Blickpfaden veranschalicht, die durch zwei Matrizen STMa und STMb repräsentiert werden.</p><p id="p0088" num="0088">Wie insbesondere anhand der <figref idrefs="f0014">Fig. 13</figref> erläutert wurde, wird auch ein Vergleich von Blickpfaden vorgeschlagen. Dazu wird für mindestens zwei Blickpfade (a, b) jeweils eine Matrix (STMa, STMb) erstellt, so wie dies bereits anhand der <figref idrefs="f0001 f0002 f0003 f0004 f0005 f0006 f0007 f0008 f0009 f0010 f0011 f0012">Figuren 1-11</figref> beschrieben wurde (s. dort insbesondere die erstellte erste Matrix M, M').<!-- EPO <DP n="27"> --></p><p id="p0089" num="0089">Die Matrizen können verarbeitet / aufbereitet werden (s. auch M* und M" in den <figref idrefs="f0007">Figuren 6a</figref> bzw. 8).</p><p id="p0090" num="0090">Dann werden die Matrizen (s. STMa, STMb in <figref idrefs="f0014">Fig. 13</figref>) einem Vergleich unterzogen, um für jeden Vergleich einen Ähnlichkeitswert (X) zu erhalten, der die Ähnlichkeit der den mindestens zwei Blickpfaden (a, b) zugrunde liegenden Blickverhalten anzeigt.</p><p id="p0091" num="0091">Dabei wird der Ähnlichkeitswert (X) der Blickpfade (a, b) durch deren Kolmogorov-Komplexität charakterisiert in Form ihrer Kompressibilität (C ), welche auf einer Kombination von prädiktiver Kodierung, Lauflängen-Kodierung und Huffman-Kodierung der jeweils ersten Matrix (STMa, STMb) basiert.</p><p id="p0092" num="0092">Vorzugsweise wird die Matrix (STMa, STMb) eines jeden Blickpfades (a, b) in Untermatrizen (m1, m2, ...) zerlegt, deren Größe abhängig von der Abtastfrequenz der Blickerfassungs-Vorrichtung (ET) ist.</p><p id="p0093" num="0093">Dann werden die Untermatrizen (m1, m2, ..) jeweils einer harmonischen Analyse (HAN) unterzogen, insbesondere einer Analyse mittels Walsh-Funktionen oder Cosinus-Funktionen, um transformierte Untermatrizen (m1*, m2*, ..) zu erhalten.</p><p id="p0094" num="0094">Danach werden die transformierten Untermatrizen (m1*, m2*, ...) einer jeden Matrix (STMa) einem Kompression-Prozess (CMPR) unterzogen, um eine komprimierte Matrix (A*) zu erhalten, welche die am meisten signifikanten Koeffizienten enthält und ein reduziertes Volumen aufweist. Dabei wird das reduzierte Volumen oder die Kompressibilität durch einen Kompressions-Wert (C(a),...) repräsentiert, der die Länge in Bit der komprimierten Matrix (A*,...) des jeweiligen Blickpfades (a, ...) angibt.</p><p id="p0095" num="0095">Vorzugsweise werden deutlich mehr als zwei Blickpfade (a, b, ...), die durch ihre Matrizen (STMa, STMb, ...) repräsentiert werden, paarweise kombiniert, um für jede Kombination einen Ähnlichkeitswert (X) zu erhalten, der die Ähnlichkeit der den mehreren Blickpfaden zugrunde liegenden Blickverhalten anzeigt. Dabei wird<!-- EPO <DP n="28"> --> der Ähnlichkeitswert (X) insbesondere gemäß der folgenden Gleichung ermittelt: <maths id="math0005" num="(1)"><math display="block"><mi>x</mi><mo>=</mo><mfrac><mrow><mi mathvariant="normal">C</mi><mfenced separators=""><mi mathvariant="normal">a</mi><mo>⁢</mo><mi mathvariant="normal">b</mi></mfenced><mo>-</mo><mi>min</mi><mfenced open="{" close="}" separators=""><mi>C</mi><mfenced><mi>a</mi></mfenced><mo>,</mo><mi>C</mi><mfenced><mi>b</mi></mfenced></mfenced></mrow><mrow><mi>max</mi><mfenced open="{" close="}" separators=""><mi mathvariant="normal">C</mi><mfenced><mi mathvariant="normal">a</mi></mfenced><mo>,</mo><mi mathvariant="normal">C</mi><mfenced><mi mathvariant="normal">b</mi></mfenced></mfenced></mrow></mfrac></math><img id="ib0005" file="imgb0005.tif" wi="89" he="19" img-content="math" img-format="tif"/></maths><br/>
wobei C(a) und C(b) die Länge in Bit der komprimierten Matrix des jeweiligen Blickpfades a bzw. b bezeichnen, und C(a,b) die Länge des kombinierten Blickpfades aus a und b bezeichnen.</p><p id="p0096" num="0096">Die Ähnlichkeitswerte (X) können die Elemente einer Ähnlichkeitsmatrix (SMAT) bilden, welche als Grundlage für einen Klassifizierungs- bzw. Clustering-Vorgang verwendet wird, wobei die Ähnlichkeitsmatrix (SMAT) insbesondere einem Klassifizierungs- bzw. Clustering-Vorgang unterzogen, der einen hierarchisch strukturierten Baum oder eine selbst-organisierte Karte erstellt.</p><p id="p0097" num="0097">Die Erfindung eignet sich insbesondere, aber nicht ausschließlich, zur Blicksteuerung einer Mensch-Maschine-Interaktion, zur Diagnose mentaler Krankheiten oder psychischer Verwirrung, oder zum Forschen im Bereich Marketing und Werbung.</p></description><claims mxw-id="PCLM56977600" lang="DE" load-source="patent-office"><!-- EPO <DP n="29"> --><claim id="c-de-0001" num="0001"><claim-text>Verfahren zur Kodierung von Augen- und Blickverlaufsdaten (DAT), bei dem die Augen- und Blickverlaufsdaten (DAT) Zeit- und Raumparameter (t, x, y) in Form von Zahlengruppen (Z0, Z1, Z2...) angeben, die mittels einer Blickerfassungsvorrichtung (ET) gewonnen werden und jeweils einem Blickpunkt (A, B, C, D, E ...) innerhalb eines Blickpfades (a) zugeordnet werden, wobei aus den Zahlengruppen paarweise jeweils Zahlenpaare (Z0,Z1; Z0,Z2; Z0,Z3...) miteinander kombiniert werden, um für jede Kombination einen Wert (W2/4) zu erhalten, der zumindest den räumlichen Abstand (S) zwischen den zwei Blickpunkten (E, C) angibt, denen das jeweilige Zahlenpaar (Z2, Z4) zugeordnet ist, wobei die erhaltenen Werte eine Kodierung bzw. einen Code für die Augen- und Blickverlaufsdaten (DAT) darstellen.</claim-text></claim><claim id="c-de-0002" num="0002"><claim-text>Verfahren nach Anspruch 1, wobei die Zahlengruppen (Z0, Z1, Z2...) entsprechend der Zeit- und Raumparameter (t, x, y) Zahlentrippel (t0, x0, y0; t1, x1, y1, ...) darstellen und wobei aus den Zahlentrippeln paarweise jeweils zwei Zahlentrippel miteinander kombiniert werden, um für jede Kombination einen Wert (W2/4) zu erhalten, der zumindest den zeitlichen und räumlichen Abstand (S) zwischen den zwei Blickpunkten (E, C) angibt.</claim-text></claim><claim id="c-de-0003" num="0003"><claim-text>Verfahren nach Anspruch 1 oder 2, wobei die Werte in Form einer ersten Matrix (M), die den Blickpfad (a) repräsentiert, erfasst und gespeichert werden.</claim-text></claim><claim id="c-de-0004" num="0004"><claim-text>Verfahren nach Anspruch 3, wobei die erste Matrix (M, M') einer Glättungs-Filterung, insbesondere einer anisotropen Filterung, unterzogen wird, um eine zweite Matrix (M*) zu erhalten, die gegenüber der ersten Matrix (M) einen reduzierten Datenumfang aufweist.<!-- EPO <DP n="30"> --></claim-text></claim><claim id="c-de-0005" num="0005"><claim-text>Verfahren nach Anspruch 4, wobei die erste oder zweite Matrix (M; M*) einer Schwellwert-Filterung unterzogen wird, um eine dritte Matrix (M**) zu erhalten, die gegenüber der ersten bzw. zweiten Matrix (M*) einen reduzierten Datenumfang aufweist.</claim-text></claim><claim id="c-de-0006" num="0006"><claim-text>Verfahren nach Anspruch 3 oder 4, wobei die erste Matrix (M') einer Glättungs-Filterung in Form einer anisotropen Diffusion unterzogen wird, um eine vierte Matrix (M") zu erhalten, die gegenüber der ersten Matrix (M') einen reduzierten Datenumfang aufweist.</claim-text></claim><claim id="c-de-0007" num="0007"><claim-text>Verfahren nach einem der Ansprüche 3-6, wobei die erste, zweite, dritte und/oder vierte Matrix eine Kodierung für Fixierungen und Sakkaden des Blickpfades (a) darstellt.</claim-text></claim><claim id="c-de-0008" num="0008"><claim-text>Verfahren nach einem der Ansprüche 3-7, wobei für mindestens zwei Blickpfade (a, b) jeweils eine Matrix (STMa, STMb) erstellt wird und diese verarbeitet und einem Vergleich unterzogen werden, um für jeden Vergleich einen Ähnlichkeitswert (X) zu erhalten, der die Ähnlichkeit der den mindestens zwei Blickpfaden (a, b) zugrunde liegenden Blickverhalten anzeigt.</claim-text></claim><claim id="c-de-0009" num="0009"><claim-text>Verfahren nach Anspruch 8, wobei der Ähnlichkeitswert (X) der Blickpfade (a, b) durch deren Kolmogorov-Komplexität charakterisiert wird in Form ihrer Kompressibilität (C ), welche auf einer Kombination von prädiktiver Kodierung, Lauflängen-Kodierung und Huffman-Kodierung der jeweils ersten Matrix (STMa, STMb) basiert.</claim-text></claim><claim id="c-de-0010" num="0010"><claim-text>Verfahren nach einem der Ansprüche 8 oder 9, wobei die Matrix (STMa, STMb) eines jeden Blickpfades (a, b) in Untermatrizen (m1, m2, ...) zerlegt wird, deren Größe abhängig von der Abtastfrequenz der Blickerfassungs-Vorrichtung (ET) ist.<!-- EPO <DP n="31"> --></claim-text></claim><claim id="c-de-0011" num="0011"><claim-text>Verfahren nach Anspruch 10, wobei die Untermatrizen (m1, m2, ..) jeweils einer harmonischen Analyse (HAN) unterzogen werden, insbesondere einer Analyse mittels Walsh-Funktionen oder Cosinus-Funktionen, um transformierte Untermatrizen (m1*, m2*, ..) zu erhalten.</claim-text></claim><claim id="c-de-0012" num="0012"><claim-text>Verfahren nach Anspruch 11, wobei die transformierten Untermatrizen (m1*, m2*, ...) einer jeden Matrix (STMa) einem Kompression-Prozess (CMPR) unterzogen werden, um eine komprimierte Matrix (A*) zu erhalten, welche die am meisten signifikanten Koeffizienten enthält und ein reduziertes Volumen aufweist.</claim-text></claim><claim id="c-de-0013" num="0013"><claim-text>Verfahren nach Anspruch 12, wobei das reduzierte Volumen oder die Kompressibilität durch einen Kompressions-Wert (C(a),...) repräsentiert wird, der die Länge in Bit der komprimierten Matrix (A*,...) des jeweiligen Blickpfades (a, ...) angibt.</claim-text></claim><claim id="c-de-0014" num="0014"><claim-text>Verfahren nach einem der Ansprüche 8-13, wobei mehrere Blickpfade (a, b, ...), die durch ihre Matrizen (STMa, STMb, ...) repräsentiert werden, paarweise kombiniert werden, um für jede Kombination einen Ähnlichkeitswert (X) zu erhalten, der die Ähnlichkeit der den mehreren Blickpfaden zugrunde liegenden Blickverhalten anzeigt, wobei der Ähnlichkeitswert (X) insbesondere gemäß der folgenden Gleichung ermittelt wird: <maths id="math0006" num="(1)"><math display="block"><mi>x</mi><mo>=</mo><mfrac><mrow><mi mathvariant="normal">C</mi><mfenced separators=""><mi mathvariant="normal">a</mi><mo>⁢</mo><mi mathvariant="normal">b</mi></mfenced><mo>-</mo><mi>min</mi><mfenced open="{" close="}" separators=""><mi>C</mi><mfenced><mi>a</mi></mfenced><mo>,</mo><mi>C</mi><mfenced><mi>b</mi></mfenced></mfenced></mrow><mrow><mi>max</mi><mfenced open="{" close="}" separators=""><mi mathvariant="normal">C</mi><mfenced><mi mathvariant="normal">a</mi></mfenced><mo>,</mo><mi mathvariant="normal">C</mi><mfenced><mi mathvariant="normal">b</mi></mfenced></mfenced></mrow></mfrac></math><img id="ib0006" file="imgb0006.tif" wi="94" he="19" img-content="math" img-format="tif"/></maths><br/>
wobei C(a) und C(b) die Länge in Bit der komprimierten Matrix des jeweiligen Blickpfades a bzw. b bezeichnen, und C(a,b) die Länge des kombinierten Blickpfades aus a und b bezeichnen.</claim-text></claim><claim id="c-de-0015" num="0015"><claim-text>Verfahren nach Anspruch 14, wobei die Ähnlichkeitswerte (X) die Elemente einer Ähnlichkeitsmatrix (SMAT) bilden, welche als Grundlage für einen Klassifizierungs- bzw. Clustering-Vorgang verwendet wird, wobei<!-- EPO <DP n="32"> --> die Ähnlichkeitsmatrix (SMAT) insbesondere einem Klassifizierungs- bzw. Clustering-Vorgang unterzogen, der einen hierarchisch strukturierten Baum oder eine selbst-organisierte Karte erstellt.</claim-text></claim><claim id="c-de-0016" num="0016"><claim-text>Vorrichtung zur Durchführung des Verfahrens nach einem der vorhergehenden Ansprüche.</claim-text></claim><claim id="c-de-0017" num="0017"><claim-text>Verwendung der Vorrichtung nach Anspruch 16 zur Blicksteuerung einer Mensch-Maschine-Interaktion, zur Diagnose mentaler Krankheiten oder psychischer Verwirrung, oder zum Forschen im Bereich Marketing und Werbung.</claim-text></claim></claims><drawings mxw-id="PDW16668287" load-source="patent-office"><!-- EPO <DP n="33"> --><figure id="f0001" num="1"><img id="if0001" file="imgf0001.tif" wi="165" he="178" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="34"> --><figure id="f0002" num="2"><img id="if0002" file="imgf0002.tif" wi="165" he="226" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="35"> --><figure id="f0003" num="3a,3b"><img id="if0003" file="imgf0003.tif" wi="142" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="36"> --><figure id="f0004" num="3c"><img id="if0004" file="imgf0004.tif" wi="162" he="220" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="37"> --><figure id="f0005" num="4a,4b"><img id="if0005" file="imgf0005.tif" wi="145" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="38"> --><figure id="f0006" num="5a,5b"><img id="if0006" file="imgf0006.tif" wi="145" he="231" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="39"> --><figure id="f0007" num="6a,6b"><img id="if0007" file="imgf0007.tif" wi="137" he="230" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="40"> --><figure id="f0008" num="7a,7b"><img id="if0008" file="imgf0008.tif" wi="130" he="227" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="41"> --><figure id="f0009" num="8"><img id="if0009" file="imgf0009.tif" wi="157" he="198" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="42"> --><figure id="f0010" num="9"><img id="if0010" file="imgf0010.tif" wi="165" he="149" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="43"> --><figure id="f0011" num="10"><img id="if0011" file="imgf0011.tif" wi="164" he="189" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="44"> --><figure id="f0012" num="11"><img id="if0012" file="imgf0012.tif" wi="162" he="198" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="45"> --><figure id="f0013" num="12"><img id="if0013" file="imgf0013.tif" wi="151" he="189" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="46"> --><figure id="f0014" num="13"><img id="if0014" file="imgf0014.tif" wi="165" he="228" img-content="drawing" img-format="tif"/></figure></drawings><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
