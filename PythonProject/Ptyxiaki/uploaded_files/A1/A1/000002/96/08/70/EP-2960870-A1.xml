<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2960870-A1" country="EP" doc-number="2960870" kind="A1" date="20151230" family-id="53938048" file-reference-id="265844" date-produced="20180826" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="160451811" ucid="EP-2960870-A1"><document-id><country>EP</country><doc-number>2960870</doc-number><kind>A1</kind><date>20151230</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-15173296-A" is-representative="YES"><document-id mxw-id="PAPP193866590" load-source="patent-office" format="original"><country>EP</country><doc-number>15173296.3</doc-number><date>20150623</date><lang>EN</lang></document-id><document-id mxw-id="PAPP193866591" load-source="docdb" format="epo"><country>EP</country><doc-number>15173296</doc-number><kind>A</kind><date>20150623</date><lang>EN</lang></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC162031369" ucid="US-201462018083-P" load-source="docdb"><document-id format="epo"><country>US</country><doc-number>201462018083</doc-number><kind>P</kind><date>20140627</date></document-id></priority-claim><priority-claim mxw-id="PPC162033428" ucid="US-201514706160-A" load-source="docdb"><document-id format="epo"><country>US</country><doc-number>201514706160</doc-number><kind>A</kind><date>20150507</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL-1988523328" load-source="docdb">G06T  19/20        20110101AFI20151111BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-1886960696" load-source="docdb" scheme="CPC">G06T2219/2016      20130101 LA20161018BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1886960697" load-source="docdb" scheme="CPC">G06T2219/021       20130101 LA20161018BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1886960698" load-source="docdb" scheme="CPC">G06T2210/44        20130101 LA20161018BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1886960699" load-source="docdb" scheme="CPC">G06T2210/41        20130101 LA20161018BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1886960700" load-source="docdb" scheme="CPC">G06T  19/20        20130101 LI20161018BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1984697078" load-source="docdb" scheme="CPC">G06T   7/0012      20130101 LI20151231BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1984700751" load-source="docdb" scheme="CPC">G06T  11/003       20130101 FI20151231BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT165546899" lang="DE" load-source="patent-office">VISUALISIERUNGSVERFAHREN FÜR EIN MENSCHLICHES SKELETT AUSGEHEND VON MEDIZINISCHER ABTASTUNG</invention-title><invention-title mxw-id="PT165546900" lang="EN" load-source="patent-office">A VISUALIZATION METHOD FOR A HUMAN SKELETON FROM A MEDICAL SCAN</invention-title><invention-title mxw-id="PT165546901" lang="FR" load-source="patent-office">PROCÉDÉ DE VISUALISATION D'UN SQUELETTE HUMAIN À PARTIR D'UN SCANNAGE MÉDICAL</invention-title><citations><patent-citations><patcit mxw-id="PCIT385402406" load-source="docdb" ucid="US-20080049991-A1"><document-id format="epo"><country>US</country><doc-number>20080049991</doc-number><kind>A1</kind><date>20080228</date></document-id><sources><source name="SEA" category="IY" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335744897" load-source="docdb" ucid="US-20080287796-A1"><document-id format="epo"><country>US</country><doc-number>20080287796</doc-number><kind>A1</kind><date>20081120</date></document-id><sources><source name="SEA" category="A" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335741025" load-source="docdb" ucid="US-20130070996-A1"><document-id format="epo"><country>US</country><doc-number>20130070996</doc-number><kind>A1</kind><date>20130321</date></document-id><sources><source name="APP" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335740532" load-source="docdb" ucid="US-20130077841-A1"><document-id format="epo"><country>US</country><doc-number>20130077841</doc-number><kind>A1</kind><date>20130328</date></document-id><sources><source name="APP" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335746364" load-source="docdb" ucid="US-20140093153-A1"><document-id format="epo"><country>US</country><doc-number>20140093153</doc-number><kind>A1</kind><date>20140403</date></document-id><sources><source name="APP" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335744770" load-source="docdb" ucid="US-7627159-B2"><document-id format="epo"><country>US</country><doc-number>7627159</doc-number><kind>B2</kind><date>20091201</date></document-id><sources><source name="APP" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT356617735" load-source="docdb" ucid="WO-2006050102-A2"><document-id format="epo"><country>WO</country><doc-number>2006050102</doc-number><kind>A2</kind><date>20060511</date></document-id><sources><source name="SEA" category="AD" created-by-npl="N"/></sources></patcit></patent-citations><non-patent-citations><nplcit><text>ATILLA P. KIRALY ET AL: "A novel visualization method for the ribs within chest volume data", PROCEEDINGS OF SPIE, vol. 6141, 2 March 2006 (2006-03-02), pages 1 - 8, XP055225273, ISSN: 0277-786X, DOI: 10.1117/12.651690</text><sources><source mxw-id="PNPL57906944" load-source="docdb" name="SEA" category="A"/></sources></nplcit><nplcit><text>C. ANDUJAR; E. PUPPO, THE EUROGRAPHICS ASSOCIATION, 2012</text><sources><source mxw-id="PNPL57906945" load-source="docdb" name="APP"/></sources></nplcit><nplcit><text>F.L. BOOKSTEIN: "Principle Warps: Thin-Plate Splines and the Decomposition of Deformations", IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, vol. 11, no. 6, June 1980 (1980-06-01), pages 567 - 585</text><sources><source mxw-id="PNPL57906946" load-source="docdb" name="APP"/></sources></nplcit><nplcit><text>H. RINGL ET AL: "The Skull Unfolded: A Cranial CT Visualization Algorithm for Fast and Easy Detection of Skull Fractures", RADIOLOGY, vol. 255, no. 2, 23 March 2010 (2010-03-23), pages 553 - 562, XP055013821, ISSN: 0033-8419, DOI: 10.1148/radiol.10091096</text><sources><source mxw-id="PNPL57906947" load-source="docdb" name="SEA" category="A"/></sources></nplcit><nplcit><text>J. KRETSCHMER ET AL.: "ADR - Anatomy-Driven Reformatiori", IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, vol. 20, no. 12, December 2014 (2014-12-01), pages 2496 - 2505</text><sources><source mxw-id="PNPL62638846" load-source="docdb" name="APP"/></sources></nplcit><nplcit><text>K. ROHR ET AL.: "''Landmark-Based Elastic Registration Using Approximating Thin-Plate Splines", IEEE TRANSACTIONS ON MEDICAL IMAGING, vol. 20, no. 6, June 2001 (2001-06-01), pages 526 - 534</text><sources><source mxw-id="PNPL62638847" load-source="docdb" name="APP"/></sources></nplcit><nplcit><text>M. ZOLLHOFER ET AL.: "GPU based ARAP Deformation using Volumetric Lattices", EUROGRAPHICS, 2012</text><sources><source mxw-id="PNPL62638848" load-source="docdb" name="APP"/></sources></nplcit><nplcit><text>SILVER D ET AL: "RESHAPING MEDICAL VOLUMETRIC DATA FOR ENHANCED VISUALIZATION", MEDICINE MEETS VIRTUAL REALITY CONFERENCE, XX, XX, vol. 2/10, 23 January 2002 (2002-01-23), pages 488 - 493, XP009061681</text><sources><source mxw-id="PNPL57906951" load-source="docdb" name="SEA" category="IY"/></sources></nplcit><nplcit><text>SINGH V ET AL: "Interactive Volume Manipulation with Selective Rendering for Improved Visualization", VOLUME VISUALIZATION AND GRAPHICS, 2004 IEEE SYMPOSIUM ON AUSTIN, TX, USA 11-12 OCT. 2004, PISCATAWAY, NJ, USA,IEEE, 11 October 2004 (2004-10-11), pages 95 - 102, XP010759842, ISBN: 978-0-7803-8781-2</text><sources><source mxw-id="PNPL57906952" load-source="docdb" name="SEA" category="Y"/></sources></nplcit></non-patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR1103327582" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>SIEMENS AG</last-name><address><country>DE</country></address></addressbook></applicant><applicant mxw-id="PPAR1103320031" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>SIEMENS AKTIENGESELLSCHAFT</last-name></addressbook></applicant><applicant mxw-id="PPAR1101640846" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Siemens Aktiengesellschaft</last-name><iid>101362070</iid><address><street>Wittelsbacherplatz 2</street><city>80333 München</city><country>DE</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR1103337810" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>KRETSCHMER JAN</last-name><address><country>DE</country></address></addressbook></inventor><inventor mxw-id="PPAR1103323485" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>KRETSCHMER, JAN</last-name></addressbook></inventor><inventor mxw-id="PPAR1101641289" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>KRETSCHMER, JAN</last-name><address><street>Fürther Straße 154</street><city>90429 Nürnberg</city><country>DE</country></address></addressbook></inventor><inventor mxw-id="PPAR1103330191" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>LAY NATHAN</last-name><address><country>US</country></address></addressbook></inventor><inventor mxw-id="PPAR1103316584" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>LAY, NATHAN</last-name></addressbook></inventor><inventor mxw-id="PPAR1101642058" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>LAY, NATHAN</last-name><address><street>4306 Ravens Crest Drive</street><city>Plainsboro, NJ New Jersey 08536</city><country>US</country></address></addressbook></inventor><inventor mxw-id="PPAR1103324321" load-source="docdb" sequence="3" format="epo"><addressbook><last-name>ZHOU SHAOHUA KEVIN</last-name><address><country>US</country></address></addressbook></inventor><inventor mxw-id="PPAR1103308027" load-source="docdb" sequence="3" format="intermediate"><addressbook><last-name>ZHOU, SHAOHUA KEVIN</last-name></addressbook></inventor><inventor mxw-id="PPAR1101641020" load-source="patent-office" sequence="3" format="original"><addressbook><last-name>ZHOU, SHAOHUA KEVIN</last-name><address><street>94 Marion Drive</street><city>Plainsboro, NJ New Jersey 08536</city><country>US</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR1101641735" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Reinhard - Skuhra - Weise &amp; Partner GbR</last-name><iid>100060500</iid><address><street>Patentanwälte Behnisch Barth Charles Hassa Peckmann &amp; Partner mbB Friedrichstrasse 31</street><city>80801 München</city><country>DE</country></address></addressbook></agent></agents></parties><international-convention-data><designated-states><ep-contracting-states><country mxw-id="DS660610970" load-source="docdb">AL</country><country mxw-id="DS660692674" load-source="docdb">AT</country><country mxw-id="DS660610976" load-source="docdb">BE</country><country mxw-id="DS660615311" load-source="docdb">BG</country><country mxw-id="DS660614986" load-source="docdb">CH</country><country mxw-id="DS660693130" load-source="docdb">CY</country><country mxw-id="DS660692687" load-source="docdb">CZ</country><country mxw-id="DS660610977" load-source="docdb">DE</country><country mxw-id="DS660693135" load-source="docdb">DK</country><country mxw-id="DS660693136" load-source="docdb">EE</country><country mxw-id="DS660701714" load-source="docdb">ES</country><country mxw-id="DS660615312" load-source="docdb">FI</country><country mxw-id="DS660615313" load-source="docdb">FR</country><country mxw-id="DS660610978" load-source="docdb">GB</country><country mxw-id="DS660693137" load-source="docdb">GR</country><country mxw-id="DS660610987" load-source="docdb">HR</country><country mxw-id="DS660692688" load-source="docdb">HU</country><country mxw-id="DS660614995" load-source="docdb">IE</country><country mxw-id="DS660610988" load-source="docdb">IS</country><country mxw-id="DS660615314" load-source="docdb">IT</country><country mxw-id="DS660693138" load-source="docdb">LI</country><country mxw-id="DS660785171" load-source="docdb">LT</country><country mxw-id="DS660692689" load-source="docdb">LU</country><country mxw-id="DS660785172" load-source="docdb">LV</country><country mxw-id="DS660785173" load-source="docdb">MC</country><country mxw-id="DS660690867" load-source="docdb">MK</country><country mxw-id="DS660690868" load-source="docdb">MT</country><country mxw-id="DS660701723" load-source="docdb">NL</country><country mxw-id="DS660615323" load-source="docdb">NO</country><country mxw-id="DS660690869" load-source="docdb">PL</country><country mxw-id="DS660614996" load-source="docdb">PT</country><country mxw-id="DS660701724" load-source="docdb">RO</country><country mxw-id="DS660614997" load-source="docdb">RS</country><country mxw-id="DS660690870" load-source="docdb">SE</country><country mxw-id="DS660614998" load-source="docdb">SI</country><country mxw-id="DS660615324" load-source="docdb">SK</country><country mxw-id="DS660690875" load-source="docdb">SM</country><country mxw-id="DS660693143" load-source="docdb">TR</country></ep-contracting-states><ep-extended-states><ep-extended-state-data><country>BA</country></ep-extended-state-data><ep-extended-state-data><country>ME</country></ep-extended-state-data></ep-extended-states></designated-states></international-convention-data></bibliographic-data><abstract mxw-id="PA166480181" lang="EN" load-source="patent-office"><p id="pa01" num="0001">A visualization method is provided that allows for the unfolding of a human skeleton from a medical image scan and providing increased efficiency for interacting with the image scan and whole body bone reading from such scans. That is, a full head-to-toe unfolded skeleton view (e.g., a 2D unfolded view) is realized for improved visualization and diagnostic capabilities.
<img id="iaf01" file="imgaf001.tif" wi="62" he="126" img-content="drawing" img-format="tif"/></p></abstract><abstract mxw-id="PA166759993" lang="EN" source="EPO" load-source="docdb"><p>A visualization method is provided that allows for the unfolding of a human skeleton from a medical image scan and providing increased efficiency for interacting with the image scan and whole body bone reading from such scans. That is, a full head-to-toe unfolded skeleton view (e.g., a 2D unfolded view) is realized for improved visualization and diagnostic capabilities.</p></abstract><description mxw-id="PDES98404882" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><heading id="h0001">TECHNICAL FIELD</heading><p id="p0001" num="0001">The present invention relates generally to medical imaging, and, more particularly, to visualizing, unfolding and analyzing a human skeleton from a medical scan.</p><heading id="h0002">BACKGROUND OF THE INVENTION</heading><p id="p0002" num="0002">State of the art whole body image scanning systems are often utilized in diagnosing a variety of medical ailments from medical scans such as computed tomography (CT), magnetic resonance (MR), positron emission tomography-computed tomography (PET/CT), single photon emission-computed tomography (SPECT/CT), and PET/MRI, to name just few. Many times patient bone assessment is required during diagnostic evaluation from such medical scans which can be a time consuming task given that current clinical practices require the reading of multiplanar rendering (MPR) planes in a sequential fashion.</p><p id="p0003" num="0003">Further, bone assessment from such medical scans can be error prone due to the inherent complexity of human bone shapes and the associated twisted geometry, and that bone intensity (including marrow) varies across individual patients having different bone anomalies (e.g., cancer metastasis, simple fractures, and complex fractures from acute/trauma). This complexity is exacerbated when functional imaging modality (e.g., PET/CT or SPECT/CT or PET/MRI) is utilized for acquiring whole body scans in an effort to discover so-called "hot spots" located throughout the human body.</p><p id="p0004" num="0004">In addition to the complexity introduced by the nature of human bones and associated skeleton structure, it can also be non-intuitive for the user<!-- EPO <DP n="2"> --></p><p id="p0005" num="0005">(e.g., medical technician or medical doctor) to interact with the medical scan from the aforementioned systems. Further, difficulties may arise in navigating the medical image volume itself, marking findings from the image scan and/or drawing bone centerlines. For example, the medical scan generated may be a 3D CT volume which provides a large amount of data that is difficult and tedious for such medical professionals to visualize, examine in an efficient manner, and perform various diagnostic operations.</p><p id="p0006" num="0006">Existing techniques directed to improving the visualization of ribs in, for example, CT volumes in 3D medical image volumes and to unfold the rib cage into a 2D image are described in <patcit id="pcit0001" dnum="US20130070996A"><text>U.S. Patent Application Publication No. 2013/0070996</text></patcit>, <i>"Method and System for Up-Vector Detection for Ribs in Computed Tomography Volumes",</i> D. Liu et al., published on March 21, 2013 (hereinafter "Liu"), and <patcit id="pcit0002" dnum="US7627159B"><text>U.S. Patent No. 7,627,159</text></patcit>, <i>"2D Visualization for Rib Analysis",</i> A. Kiraly et al., issued on December 1, 2009 (hereinafter "Kiraly"), each of which is hereby incorporated by reference for all purposes. These techniques allow for the unfolding of the 3D rib cage image into a 2D image to improve examination time and reduce ambiguity in interpreting the CT data of the ribs.</p><p id="p0007" num="0007">A need exists for an improved technique of unfolding and visualizing the full human skeleton from a medical scan and interacting with the image scan for full body bone reading.</p><heading id="h0003">BRIEF SUMMARY OF THE EMBODIMENTS</heading><p id="p0008" num="0008">In accordance with various embodiments, a visualization method is provided that allows for the unfolding of a human skeleton from a medical image scan and providing increased efficiency for interacting with the image scan and whole body bone reading from such scans. That is, in accordance with various embodiments, a full head-to-toe unfolded skeleton view<!-- EPO <DP n="3"> --> (e.g., a 2D unfolded view) is realized for improved visualization and diagnostic capabilities.</p><p id="p0009" num="0009">In accordance with an embodiment, given a 3D medical scan, automatic image segmentation is utilized to segment an image volume of the human skeleton (having a plurality of bones) from the medical scan into a 3D mesh or binary mask corresponding to the entire skeleton that is specific to the medical scan (i.e., the skeleton specific to the patient being diagnosed). The image volume could be of the entire skeleton itself or individual image volumes of each bone of the plurality of bones that define the skeleton. Alternatively, the image segmentation could produce a plurality of 3D meshes with one mask per different bone of the skeleton or a multi-label mask with each label corresponding to a different bone.</p><p id="p0010" num="0010">After segmenting the skeleton from the medical scan, in accordance with an embodiment, bone unfolding is accomplished using one or more patient-specific warping functions. In particular, the segmented skeleton is divided into various groups consisting of different portions of the skeleton. Illustratively, a first group is defined to include the spine, ribs and pelvis, a second group for the left arm and hand, a third group for the right arm and hand, a fourth group for the left leg and left foot, a fifth group for the right leg and right foot, and a sixth group for the head/skull. For each identified group, a warping function is applied to unfold and straighten the individual bones and respective skeleton features.</p><p id="p0011" num="0011">For example, a warping function is computed that will straighten the spine, flatten the ribs and flatten the pelvis. Further, a separate warping function will be computed for each upper and lower extremity (e.g., defined by the second, third, fourth and fifth groups identified above) which will fit the respective bones of a select extremity into one image plane. As such, in accordance with the embodiment, a 2D planar view is generated of the entire unfolded bone structure of the skeleton being examined. In accordance with a<!-- EPO <DP n="4"> --> further embodiment, a 3D rendering view is also generated of the entire skeleton body structure of the patient.</p><p id="p0012" num="0012">Advantageously, in accordance with various embodiments, the generated unfolded views of the individual bones and associated full skeleton body can be used to more efficiently visualize the images, analyze the patient (and subject medical scan thereof) and diagnosis medical conditions. For example, in accordance with an embodiment, the user can interact with the unfolded skeletal images by rotating individual bones in the unfolded views or selecting a particular bone to view and the image system will immediately move the corresponding location(s) in the corresponding 3D image view that may be displayed to the user. The user may also move various portions of the skeletal image to simulate articulated motions of an extremity, for example, to assist in the overall diagnosis.</p><p id="p0013" num="0013">These and other advantages of the embodiments will be apparent to those of ordinary skill in the art by reference to the following detailed description and the accompanying drawings.</p><heading id="h0004">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p0014" num="0014"><ul><li><figref idrefs="f0001">FIG. 1</figref> shows an illustrative full body CT medical scan;</li><li><figref idrefs="f0002">FIG. 2</figref> shows a flowchart of illustrative operations for unfolding and visualizing a human skeleton in accordance with an embodiment;</li><li><figref idrefs="f0003">FIG. 3</figref> shows an illustrative 2D planar image of unfolding and visualizing a human skeleton from a medical scan in accordance with an embodiment;</li><li><figref idrefs="f0004">FIG. 4</figref> shows an illustrative 3D rending view of the unfolded human skeleton depicted in <figref idrefs="f0003">FIG. 3</figref> in accordance with an embodiment;</li><li><figref idrefs="f0005">FIG. 5</figref> shows a flowchart of illustrative operations for visualizing, interacting and manipulating unfolded skeleton views, for example, the view shown in <figref idrefs="f0003">FIG. 3</figref>, in accordance with an embodiment; and<!-- EPO <DP n="5"> --></li><li><figref idrefs="f0006">FIG. 6</figref> is a high-level block diagram of an exemplary computer capable of implementing various embodiments herein.</li></ul></p><heading id="h0005">DETAILED DESCRIPTION</heading><p id="p0015" num="0015"><figref idrefs="f0001">FIG. 1</figref> shows an illustrative full body CT medical scan 100 of a human that can be generated using any number of well-known medical imaging systems utilized in diagnosing a variety of medical ailments from medical scans such as CT, MR, PET/CT, SPECT/CT and PET/MRI, to name just few. As will be appreciated, medical scan 100 is generated and utilized for examination of medical conditions of a human patient, for example, in regions such as the shoulder 110, upper extremity 120, lower extremity 130 or head 140, to name just a few. However, examination of medical scan 100 itself can be time consuming, inefficient and error prone.</p><p id="p0016" num="0016">In accordance with various embodiments, a visualization method is provided that allows for the unfolding of a human skeleton from a 3D medical image scan and providing increased efficiency for interacting with the image scan and whole body bone reading from such scans. That is, in accordance with various embodiments, a full head-to-toe unfolded skeleton view (e.g., a 2D unfolded view) is realized for improved visualization and diagnostic capabilities.</p><p id="p0017" num="0017">More particularly, <figref idrefs="f0002">FIG. 2</figref> shows a flowchart of illustrative operations 200 for unfolding and visualizing a human skeleton in accordance with an embodiment. In accordance with the embodiment, at step 210, a 3D medical scan is received, for example, medical scan 100 as shown in <figref idrefs="f0001">FIG. 1</figref>. For example, the 3D medical scan may be received directly from a scanner used to acquire such a medical scan or may be received by loading a previously stored 3D medical scan (e.g., from a memory or other storage device). At step 220, the human skeleton is segmented from the 3D medical scan. Illustratively, in accordance with an embodiment, automatic image segmentation is utilized to<!-- EPO <DP n="6"> --> segment the human skeleton from the medical scan into a 3D mesh or binary mask corresponding to the entire skeleton that is specific to the medical scan (i.e., the skeleton specific to the patient being diagnosed). Alternatively, the image segmentation could produce a plurality of 3D meshes with one mask per different bone of the skeleton or a multi-label mask with each label corresponding to a different bone. Examples of such image segmentation techniques are as described in <patcit id="pcit0003" dnum="US20130077841A"><text>U.S. Patent Application Publication No. 2013/0077841</text></patcit>, <i>"Method and System for Automatic Rib Centerline Extraction Using Learning Base Deformable Template Matching",</i> D. Wu et al., published on March 28, 2013 (hereinafter "Wu") which describes a method for rib extraction, and <patcit id="pcit0004" dnum="US20140093153A"><text>U.S. Patent Application Publication No. 2014/0093153</text></patcit>, <i>"Method and System for Bone Segmentation for Joint Replacement Surgery',</i> M. Sofka et al. published on April 3, 2014 (hereinafter "Sofka") which describes a method for segmenting multiple knee bones, each of which is incorporated by reference herein for all purposes.</p><p id="p0018" num="0018">After segmenting the skeleton from the medical scan, in accordance with an embodiment, bone unfolding is accomplished using one or more patient-specific warping functions. In particular, at step 230, various groups are identified consisting of different portions of the skeleton. As will be appreciated, the human skeleton is comprised of a plurality of bones which may need to be visualized in order to provide an appropriate and accurate medical diagnosis. As such, the segmented skeleton is divided into groups of skeletal sections. Illustratively, a first group is defined to correspond with the spine, ribs and pelvis, a second group for the left arm and hand, a third group for the right arm and hand, a fourth group for the left leg and left foot, a fifth group for the right leg and right foot, and a sixth group for the head/skull. For each identified group, at step 240, a warping function is generated to unfold and straighten the individual bones and respective skeleton features. For example, a warping function is computed that will straighten the spine, flatten the ribs and flatten the pelvis. Further, a separate warping function will be computed for each upper and<!-- EPO <DP n="7"> --> lower extremity (e.g., defined by the second, third, fourth and fifth groups identified above) which will fit all the bones of a respective extremity into a planar setting that exposes a significantly improved alignment of the structure with a plane. As such, at step 250, an image of the unfolded human skeleton is generated and, at step 260, the unfolded skeleton image is displayed to a user (e.g., medical technician or medical doctor) for visualization and diagnostic purposes.</p><p id="p0019" num="0019">Warping functions do not necessarily have to be grouped by anatomical components. This means that multiple (preferably, but not necessarily attached) anatomical structures can be unfolded with one combined warping function. For example, the spine and the pelvic bone or a hand and the corresponding arm can be mapped with one comprehensive warp to preserve their spatial relationship, or to visualize joints. The general problem of finding low-distortion mappings between objects of different shape is a classical problem in computer graphics and well understood. For example, it appears (amongst other fields) in texture mapping, ambient space warping, surface-based mesh deformation and volumetric mesh deformation</p><p id="p0020" num="0020">The general form of a 3D warping function W(x): R^3 -&gt; R^3 maps every point in space to a different location. Common choices to define such mappings are based on smooth interpolations of sparse landmark offsets by making use of so-called radial basis functions (RBFs), for example, thin plate spline RBFs as described in<nplcit id="ncit0001" npl-type="s"><text> F.L. Bookstein, "Principle Warps: Thin-Plate Splines and the Decomposition of Deformations", IEEE Transactions on Pattern Analysis and Machine Intelligence, pp. 567-585, Vol. 11, No. 6, June 1980</text></nplcit>, and <nplcit id="ncit0002" npl-type="s"><text>K. Rohr et al., "Landmark-Based Elastic Registration Using Approximating Thin-Plate Splines", IEEE Transactions on Medical Imaging, pp. 526-534, Vol. 20, No. 6, June 2001</text></nplcit>, each of which is hereby incorporated by reference for all purposes. Further, a different class of approaches is based on a discretization of space into small cells that are consistently mapped to a deformed setting, for example, as<!-- EPO <DP n="8"> --> described in <nplcit id="ncit0003" npl-type="b"><text>M. Zollhofer et al, "GPU based ARAP Deformation using Volumetric Lattices", Eurographics 2012/C. Andujar, E. Puppo, The Eurographics Association 2012</text></nplcit>, which is hereby incorporated by reference for all purposes, or methods that parameterize the surrounding of a planar mesh as described in<nplcit id="ncit0004" npl-type="s"><text> J. Kretschmer et al., "ADR - Anatomy-Driven Reformation", pp. 2496-2505, IEEE Transactions on Visualization and Computer Graphics, Vol. 20, No. 12, December 2014</text></nplcit>, which is hereby incorporated by reference for all purposes.</p><p id="p0021" num="0021">In general the warping function W(x) itself is an interchangeable component. Preferable properties of the component include smoothness (i.e., the mapping should not fold), the preservation of angles (i.e., conformality) and the preservation of distances (i.e., rigidity) and usually different trade-offs between the two have to be made. Further, the warping function W(x) might be defined in a volumetric manner (e.g., defining a warp for a certain surrounding of the unfolded surface) or for the unfolding surface only (e.g., flattening a surface only).</p><p id="p0022" num="0022">Advantageously, in accordance with various embodiments, the generated unfolded views of the full skeleton body can be used to visualize the image and more efficiently analyze the patient (and subject medical scan thereof) and diagnosis medical conditions. For example, <figref idrefs="f0003">FIG. 3</figref> shows an illustrative 2D planar image 300 of the unfolding of a human skeleton from a medical scan in accordance with an embodiment as detailed herein above. As shown in <figref idrefs="f0003">FIG. 3</figref>, various image portions show the unfolding of the individual bones from the segmented image as described above. For example, view 310 shows the first group defined to include the spine, ribs and pelvis, view 320 shows the second group for the left arm and hand, view 330 shows the third group for the right arm and hand, view 340 shows the fourth group for the left leg and left foot, view 350 shows the fifth group for the right leg and right foot, and view 360 and view 370 show, respectively, the sixth group for the head/skull.<!-- EPO <DP n="9"> --></p><p id="p0023" num="0023">In addition to 2D views, in accordance with a further embodiment, <figref idrefs="f0004">FIG. 4</figref> shows an illustrative 3D rending view 400 of the unfolded human skeleton depicted in <figref idrefs="f0003">FIG. 3</figref> to allow for further visualization and diagnostic capabilities. As shown in <figref idrefs="f0004">FIG. 4</figref>, various image portions show the unfolding of the individual bones from the segmented image as described above. For example, view 410 shows the first group defined to include the spine, ribs and pelvis, view 420 shows the second group for the left arm and hand, view 430 shows the third group for the right arm and hand, view 440 shows the fourth group for the left leg and left foot, view 450 shows the fifth group for the right leg and right foot, and view 460 shows the sixth group for the head/skull.</p><p id="p0024" num="0024">As noted previously, in accordance with various embodiments, the generated unfolded views of the full skeleton body can be used to more efficiently visualize the image and analyze the patient (and subject medical scan thereof) and diagnosis medical conditions. <figref idrefs="f0005">FIG. 5</figref> shows a flowchart of illustrative operations 500 for visualizing, interacting and manipulating unfolded skeleton views, for example, the view shown in <figref idrefs="f0003">FIG. 3</figref>, in accordance with an embodiment. At step 510, in accordance with an embodiment, the unfolded skeleton image(s) are received, such unfolded skeleton image(s) are generated as detailed above. As such, at step 520, the user can interact with the unfolded skeletal images by rotating individual bones in the unfolded views or selecting a particular bone to view and the image system will immediately map, at step 530, the corresponding location(s) in the corresponding 3D image view. The user may also move various portions of the skeletal image to simulate articulated motions of an extremity, for example, to assist in the overall diagnosis. As such, at step 540 if a simulation is desired, the articulated motion(s) to simulate are identified, at step 550, from direct input received from the user, and the simulation is generated, at step 560, and displayed at step 570 for further diagnostic evaluation.<!-- EPO <DP n="10"> --></p><p id="p0025" num="0025">The above-described methods are described using computed tomography (CT) as the imaging modality, but the various embodiments are not limited thereto. The above-described methods may be similarly applied on other imaging modalities, such as MR, PET/CT, SPECT/CT, PET/MRI, x-ray, and ultrasound, to name just a few.</p><p id="p0026" num="0026">The above-described methods for unfolding an entire skeleton from 3D volume to a 2D image and visualizing, evaluating and manipulating the unfolded skeleton images may be implemented on a computer using well-known computer processors, memory units, storage devices, computer software, and other components. A high level block diagram of such a computer is illustrated in <figref idrefs="f0006">FIG. 6</figref>. Computer 600 contains a processor 610 which controls the overall operation of the computer 600 by executing computer program instructions which define such operation. The computer program instructions may be stored in a storage device 630, or other computer readable medium (e.g., magnetic disk, CD ROM, etc.) and loaded into memory 640 when execution of the computer program instructions is desired. Thus, the steps of the methods of <figref idrefs="f0002">FIGS. 2</figref> and <figref idrefs="f0005">5</figref>, respectively, may be defined by the computer program instructions stored in the memory 640 and/or storage 630 and controlled by the processor 610 executing the computer program instructions. An image acquisition device 660, such as a CT scanner, can be connected to the computer 600 to input images to the computer 600. It is possible to implement the image acquisition device 660 and the computer 600 as one device. It is also possible that the image acquisition device 660 and the computer 600 communicate wirelessly through a network in a well-known fashion.</p><p id="p0027" num="0027">In a possible embodiment, computer 600 may be located remotely with respect to the image acquisition device 660 and may perform the method steps of <figref idrefs="f0002">FIG. 2</figref> and/or <figref idrefs="f0005">FIG. 5</figref> as part of a server or cloud-based service (or architecture). The computer 600 also includes one or more network interfaces 620 for communicating with other devices via a network. The<!-- EPO <DP n="11"> --> computer 600 also includes other input/output devices 650 that enable user interaction with the computer 600 (e.g., display, keyboard, mouse, speakers, buttons, etc.). One skilled in the art will recognize that an implementation of an actual computer could contain other components as well, and that <figref idrefs="f0006">FIG. 6</figref> is a high level representation of some of the components of such a computer for illustrative purposes.</p><p id="p0028" num="0028">It should be noted that for clarity of explanation, the illustrative embodiments described herein may be presented as comprising individual functional blocks or combinations of functional blocks. The functions these blocks represent may be provided through the use of either dedicated or shared hardware, including, but not limited to, hardware capable of executing software. Illustrative embodiments may comprise digital signal processor ("DSP") hardware and/or software performing the operation described herein. Thus, for example, it will be appreciated by those skilled in the art that the block diagrams herein represent conceptual views of illustrative functions, operations and/or circuitry of the principles described in the various embodiments herein. Similarly, it will be appreciated that any flowcharts, flow diagrams, state transition diagrams, pseudo code, program code and the like represent various processes which may be substantially represented in computer readable medium and so executed by a computer, machine or processor, whether or not such computer, machine or processor is explicitly shown. One skilled in the art will recognize that an implementation of an actual computer or computer system may have other structures and may contain other components as well, and that a high level representation of some of the components of such a computer is for illustrative purposes.</p><p id="p0029" num="0029">The foregoing Detailed Description is to be understood as being in every respect illustrative and exemplary, but not restrictive, and the scope of the invention disclosed herein is not to be determined from the Detailed Description, but rather from the claims as interpreted according to the full breadth permitted<!-- EPO <DP n="12"> --> by the patent laws. It is to be understood that the embodiments shown and described herein are only illustrative of the principles of the present invention and that various modifications may be implemented by those skilled in the art without departing from the scope and spirit of the invention. Those skilled in the art could implement various other feature combinations without departing from the scope and spirit of the invention.<!-- EPO <DP n="13"> --></p><heading id="h0006">FURTHER EMBODIMENTS</heading><p id="p0030" num="0030"><ol><li>1. A method for visualizing a skeleton having a plurality of bones, the method comprising:
<ul><li>segmenting, from a three-dimensional (3D) image scan of a body including the skeleton, an image volume for the skeleton;</li><li>straightening each bone of the plurality of bones based on a corresponding segmented image volume of the skeleton; and</li><li>generating a two-dimensional (2D) image based on the straightened corresponding segmented image volume of each bone of the plurality of bones.</li></ul></li><li>2. The method of embodiment 1 further comprising:
<ul><li>displaying the generated 2D image.</li></ul></li><li>3. The method of embodiment 1, wherein the straightening each bone of the plurality of bones step, further comprises:
<ul><li>identifying a plurality of image groups from the segmented image volume of the skeleton, each image group of the plurality of image groups corresponding with one or more portions of the skeleton; and</li><li>calculating a warping function for each image group of the plurality of image groups.</li></ul></li><li>4. The method of embodiment 3 wherein a first image group of the plurality of image groups includes a spine, rib cage and pelvis, and a second image group of the plurality of image groups includes at least one arm.</li><li>5. The method of embodiment 4 further comprising:
<ul><li>identifying, using the 2D image, at least one articulated motion involving particular bones of the plurality of bones; and<!-- EPO <DP n="14"> --> simulating the at least one articulated motion.</li></ul></li><li>6. The method of embodiment 5 further comprising:
<ul><li>displaying the simulated at least one articulated motion.</li></ul></li><li>7. The method of embodiment 2 wherein the 3D image scan comprises a computed tomography (CT) image of the body.</li><li>8. The method of embodiment 5, wherein the segmenting the image volume of the skeleton step further comprises:
<ul><li>ordering and labeling each bone of the plurality of bones.</li></ul></li><li>9. A method for visualizing a skeleton having a plurality of bones, the method comprising:
<ul><li>segmenting, from a three-dimensional (3D) image scan of a body including the skeleton, an image volume for each bone of the plurality of bones of the skeleton;</li><li>straightening each bone of the plurality of bones based on its respective segmented image volume; and</li><li>generating a two-dimensional (2D) image based on the respective straightened segmented image volume of each bone of the plurality of bones.</li></ul></li><li>10. The method of embodiment 9 further comprising:
<ul><li>displaying the generated 2D image.</li></ul></li><li>11. The method of embodiment 9, wherein the straightening each bone of the plurality of bones step further comprises:
<ul><li>identifying a plurality of image groups from the respective segmented image volume of each bone of the plurality of bones, each image group of the<!-- EPO <DP n="15"> --> plurality of image groups corresponding with one or more portions of the skeleton; and</li><li>calculating a warping function for each image group of the plurality of image groups.</li></ul></li><li>12. The method of embodiment 11 wherein a first image group of the plurality of image groups includes at least one leg, and a second image group of the plurality of image groups includes a head.</li><li>13. The method of embodiment 9 wherein the 3D image scan comprises a magnetic resonance (MR) image of the body.</li><li>14. The method of embodiment 9 wherein the 3D image scan comprises a positron emission tomography-computed tomography (PET/CT) image of the body.</li><li>15. The method of embodiment 11 wherein the warping function for each image group preserves a spatial relationship between the one or more portions of the skeleton corresponding to such image group.</li><li>16. The method of embodiment 9 further comprising:
<ul><li>identifying, using the 2D image, at least one articulated motion involving particular bones of the plurality of bones; and</li><li>simulating the at least one articulated motion.</li></ul></li><li>17. The method of embodiment 16 further comprising:
<ul><li>displaying the simulated at least one articulated motion; and</li><li>modifying the 2D image based on an input defined from the displaying of the simulated at least one articulated motion.</li></ul><!-- EPO <DP n="16"> --></li><li>18. A non-transitory computer-readable medium storing computer program instructions for executing a method of visualization, the computer program instructions, when executed on a processor, cause the processor to perform operations comprising:
<ul><li>segmenting, from a three-dimensional (3D) image scan of a body including a skeleton having a plurality of bones, an image volume for the skeleton;</li><li>straightening each bone of the plurality of bones based on a corresponding segmented image volume of the skeleton; and</li><li>generating a two-dimensional (2D) image based on the corresponding straightened segmented image volume of each bone of the plurality of bones.</li></ul></li><li>19. The non-transitory computer-readable medium of embodiment 18 wherein the operations further comprise:
<ul><li>identifying a plurality of image groups from the segmented image volume of the skeleton, each image group of the plurality of image groups corresponding with one or more portions of the skeleton; and</li><li>calculating a warping function for each image group of the plurality of image groups.</li></ul></li><li>20. The non-transitory computer-readable medium of embodiment 19 wherein the 3D image scan comprises a computed tomography (CT) image of the body, and the operations further comprising:
<ul><li>displaying a simulation of at least one articulated motion involving particular ones of the plurality of bones; and</li><li>modifying the 2D image based on an input defined from the displaying of the simulated at least one articulated motion.</li></ul></li></ol></p></description><claims mxw-id="PCLM90459832" lang="EN" load-source="patent-office"><!-- EPO <DP n="17"> --><claim id="c-en-0001" num="0001"><claim-text>A method for visualizing a skeleton having a plurality of bones, the method comprising:
<claim-text>segmenting, from a three-dimensional (3D) image scan of a body including the skeleton, an image volume for the skeleton;</claim-text>
<claim-text>straightening each bone of the plurality of bones based on a corresponding segmented image volume of the skeleton; and</claim-text>
<claim-text>generating a two-dimensional (2D) image based on the straightened corresponding segmented image volume of each bone of the plurality of bones.</claim-text></claim-text></claim><claim id="c-en-0002" num="0002"><claim-text>The method of claim 1 further comprising:
<claim-text>displaying the generated 2D image.</claim-text></claim-text></claim><claim id="c-en-0003" num="0003"><claim-text>The method according to any of the preceding claims, wherein the straightening each bone of the plurality of bones step, further comprises:
<claim-text>identifying a plurality of image groups from the segmented image volume of the skeleton, each image group of the plurality of image groups corresponding with one or more portions of the skeleton; and</claim-text>
<claim-text>calculating a warping function for each image group of the plurality of image groups.</claim-text></claim-text></claim><claim id="c-en-0004" num="0004"><claim-text>The method of claim 3 wherein a first image group of the plurality of image groups includes a spine, rib cage and pelvis, and a second image group of the plurality of image groups includes at least one arm.</claim-text></claim><claim id="c-en-0005" num="0005"><claim-text>The method according to any of the preceding claims further comprising:<!-- EPO <DP n="18"> -->
<claim-text>identifying, using the 2D image, at least one articulated motion involving particular bones of the plurality of bones; and</claim-text>
<claim-text>simulating the at least one articulated motion, in particular displaying the simulated at least one articulated motion.</claim-text></claim-text></claim><claim id="c-en-0006" num="0006"><claim-text>The method according to any of the preceding claims wherein the 3D image scan comprises a computed tomography (CT) image of the body.</claim-text></claim><claim id="c-en-0007" num="0007"><claim-text>The method according to any of the preceding claims, wherein the segmenting the image volume of the skeleton step further comprises:
<claim-text>ordering and labeling each bone of the plurality of bones.</claim-text></claim-text></claim><claim id="c-en-0008" num="0008"><claim-text>A method for visualizing a skeleton having a plurality of bones, the method comprising:
<claim-text>segmenting, from a three-dimensional (3D) image scan of a body including the skeleton, an image volume for each bone of the plurality of bones of the skeleton;</claim-text>
<claim-text>straightening each bone of the plurality of bones based on its respective segmented image volume; and</claim-text>
<claim-text>generating a two-dimensional (2D) image based on the respective straightened segmented image volume of each bone of the plurality of bones.</claim-text></claim-text></claim><claim id="c-en-0009" num="0009"><claim-text>The method of claim 8 further comprising:
<claim-text>displaying the generated 2D image.</claim-text></claim-text></claim><claim id="c-en-0010" num="0010"><claim-text>The method of claim 8 or 9, wherein the straightening each bone of the plurality of bones step further comprises:
<claim-text>identifying a plurality of image groups from the respective segmented image volume of each bone of the plurality of bones, each image group of the<!-- EPO <DP n="19"> --> plurality of image groups corresponding with one or more portions of the skeleton; and</claim-text>
<claim-text>calculating a warping function for each image group of the plurality of image groups.</claim-text></claim-text></claim><claim id="c-en-0011" num="0011"><claim-text>The method of claim 10 wherein a first image group of the plurality of image groups includes at least one leg, and a second image group of the plurality of image groups includes a head and/or wherein the warping function for each image group preserves a spatial relationship between the one or more portions of the skeleton corresponding to such image group.</claim-text></claim><claim id="c-en-0012" num="0012"><claim-text>The method of any of the claims 8 to 11 wherein the 3D image scan comprises a magnetic resonance (MR) image of the body and/or a positron emission tomography-computed tomography (PET/CT) image of the body and/or a positron emission tomography-computed tomography (PET/CT) image of the body.</claim-text></claim><claim id="c-en-0013" num="0013"><claim-text>The method of any of the claims 8 to 12 further comprising:
<claim-text>identifying, using the 2D image, at least one articulated motion involving particular bones of the plurality of bones; and</claim-text>
<claim-text>simulating the at least one articulated motion.</claim-text></claim-text></claim><claim id="c-en-0014" num="0014"><claim-text>The method of claim 13 further comprising:
<claim-text>displaying the simulated at least one articulated motion; and</claim-text>
<claim-text>modifying the 2D image based on an input defined from the displaying of the simulated at least one articulated motion.</claim-text><!-- EPO <DP n="20"> --></claim-text></claim><claim id="c-en-0015" num="0015"><claim-text>A non-transitory computer-readable medium storing computer program instructions for executing a method of visualization, the computer program instructions, when executed on a processor, cause the processor to perform a method according to any of the claims 1 to 14.</claim-text></claim></claims><drawings mxw-id="PDW20422544" load-source="patent-office"><!-- EPO <DP n="21"> --><figure id="f0001" num="1"><img id="if0001" file="imgf0001.tif" wi="68" he="132" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="22"> --><figure id="f0002" num="2"><img id="if0002" file="imgf0002.tif" wi="98" he="190" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="23"> --><figure id="f0003" num="3"><img id="if0003" file="imgf0003.tif" wi="137" he="181" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="24"> --><figure id="f0004" num="4"><img id="if0004" file="imgf0004.tif" wi="139" he="208" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="25"> --><figure id="f0005" num="5"><img id="if0005" file="imgf0005.tif" wi="108" he="216" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="26"> --><figure id="f0006" num="6"><img id="if0006" file="imgf0006.tif" wi="144" he="172" img-content="drawing" img-format="tif"/></figure></drawings><search-report-data><doc-page id="srep0001" file="srep0001.tif" wi="159" he="233" type="tif"/><doc-page id="srep0002" file="srep0002.tif" wi="159" he="233" type="tif"/><doc-page id="srep0003" file="srep0003.tif" wi="159" he="233" type="tif"/></search-report-data><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
