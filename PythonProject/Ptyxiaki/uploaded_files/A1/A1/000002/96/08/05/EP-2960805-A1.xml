<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2960805-A1" country="EP" doc-number="2960805" kind="A1" date="20151230" family-id="53502394" file-reference-id="311904" date-produced="20180824" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="160451472" ucid="EP-2960805-A1"><document-id><country>EP</country><doc-number>2960805</doc-number><kind>A1</kind><date>20151230</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-15001835-A" is-representative="YES"><document-id mxw-id="PAPP193865912" load-source="patent-office" format="original"><country>EP</country><doc-number>15001835.6</doc-number><date>20150622</date><lang>EN</lang></document-id><document-id mxw-id="PAPP193865913" load-source="docdb" format="epo"><country>EP</country><doc-number>15001835</doc-number><kind>A</kind><date>20150622</date><lang>EN</lang></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC162034064" ucid="US-201414314750-A" load-source="docdb"><document-id format="epo"><country>US</country><doc-number>201414314750</doc-number><kind>A</kind><date>20140625</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL-1988520785" load-source="docdb">G06F  17/30        20060101ALI20151014BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-1988524597" load-source="docdb">G06F  17/16        20060101AFI20151014BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-1627894635" load-source="docdb" scheme="CPC">G06F  17/30153     20130101 LI20180509BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1627894636" load-source="docdb" scheme="CPC">G06F  17/16        20130101 FI20180609BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT165545882" lang="DE" load-source="patent-office">DÜNN-BESETZTE LINEARE ALGEBRA IN EINER SPALTENORIENTIERTEN IN-MEMORY-DATENBANK</invention-title><invention-title mxw-id="PT165545883" lang="EN" load-source="patent-office">SPARSE LINEAR ALGEBRA IN COLUMN-ORIENTED IN-MEMORY DATABASE</invention-title><invention-title mxw-id="PT165545884" lang="FR" load-source="patent-office">ALGÈBRE LINÉAIRE ÉPARSE DANS UNE BASE DE DONNÉES EN MÉMOIRE ORIENTÉE PAR COLONNES</invention-title><citations><patent-citations><patcit mxw-id="PCIT335745773" load-source="docdb" ucid="US-20130159248-A1"><document-id format="epo"><country>US</country><doc-number>20130159248</doc-number><kind>A1</kind><date>20130620</date></document-id><sources><source name="SEA" category="Y" created-by-npl="N"/></sources></patcit></patent-citations><non-patent-citations><nplcit><text>DAVID KERNERT ET AL: "Bringing Linear Algebra Objects to Life in a Column-Oriented In-Memory Database", IN-MEMORY DATA MANAGEMENT AND ANALYSIS (IMDM 2013), 26 August 2013 (2013-08-26), pages 1 - 12, XP055218953, ISBN: 978-3-319-13960-9, Retrieved from the Internet &lt;URL:http://www-db.in.tum.de/other/imdm2013/papers/Kernert.pdf&gt; [retrieved on 20151007]</text><sources><source mxw-id="PNPL57906899" load-source="docdb" name="SEA" category="Y"/></sources></nplcit><nplcit><text>DAVID KERNERT ET AL: "SLACID - sparse linear algebra in a column-oriented in-memory database system", SCIENTIFIC AND STATISTICAL DATABASE MANAGEMENT, ACM, 2 PENN PLAZA, SUITE 701 NEW YORK NY 10121-0701 USA, 30 June 2014 (2014-06-30), pages 1 - 12, XP058053486, ISBN: 978-1-4503-2722-0, DOI: 10.1145/2618243.2618254</text><sources><source mxw-id="PNPL57906900" load-source="docdb" name="SEA" category="XP"/></sources></nplcit><nplcit><text>None</text><sources><source mxw-id="PNPL62638793" load-source="docdb" name="APP"/></sources></nplcit><nplcit><text>OPEN SOURCE ALGLIB: "Sparse matrices", ALGLIB USER GUIDE, 27 February 2013 (2013-02-27), pages 1 - 3, XP055219504, Retrieved from the Internet &lt;URL:https://web.archive.org/web/20130227021442/http://www.alglib.net/matrixops/sparse.php&gt; [retrieved on 20151008]</text><sources><source mxw-id="PNPL57906901" load-source="docdb" name="SEA" category="A"/></sources></nplcit><nplcit><text>VISHAL SIKKA ET AL: "Efficient transaction processing in SAP HANA database", PROCEEDINGS OF THE 2012 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, SIGMOD '12, 20 May 2012 (2012-05-20), New York, New York, USA, pages 731 - 24, XP055197662, ISBN: 978-1-45-031247-9, DOI: 10.1145/2213836.2213946</text><sources><source mxw-id="PNPL57906902" load-source="docdb" name="SEA" category="Y"/></sources></nplcit></non-patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR1103319575" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>SAP SE</last-name><address><country>DE</country></address></addressbook></applicant><applicant mxw-id="PPAR1103316475" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>SAP SE</last-name></addressbook></applicant><applicant mxw-id="PPAR1101640257" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>SAP SE</last-name><iid>101471558</iid><address><street>Dietmar-Hopp-Allee 16</street><city>69190 Walldorf</city><country>DE</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR1103308705" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>KERNERT DAVID</last-name><address><country>DE</country></address></addressbook></inventor><inventor mxw-id="PPAR1103337844" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>Kernert, David</last-name></addressbook></inventor><inventor mxw-id="PPAR1101652424" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Kernert, David</last-name><address><street>c/o SAP SE, Global IP Group, Dietmar-Hopp-Allee 16</street><city>69190 Walldorf</city><country>DE</country></address></addressbook></inventor><inventor mxw-id="PPAR1103336561" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>KOEHLER FRANK</last-name><address><country>DE</country></address></addressbook></inventor><inventor mxw-id="PPAR1103313042" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>KOEHLER, FRANK</last-name></addressbook></inventor><inventor mxw-id="PPAR1101653479" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>KOEHLER, FRANK</last-name><address><street>c/o SAP SE, Global IP Group, Dietmar-Hopp-Allee 16</street><city>69190 Walldorf</city><country>DE</country></address></addressbook></inventor><inventor mxw-id="PPAR1103336026" load-source="docdb" sequence="3" format="epo"><addressbook><last-name>LEHNER WOLFGANG</last-name><address><country>DE</country></address></addressbook></inventor><inventor mxw-id="PPAR1103307126" load-source="docdb" sequence="3" format="intermediate"><addressbook><last-name>LEHNER, WOLFGANG</last-name></addressbook></inventor><inventor mxw-id="PPAR1101653005" load-source="patent-office" sequence="3" format="original"><addressbook><last-name>LEHNER, WOLFGANG</last-name><address><street>c/o SAP SE, Global IP Group, Dietmar-Hopp-Allee 16</street><city>69190 Walldorf</city><country>DE</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR1101653802" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Müller-Boré &amp; Partner Patentanwälte</last-name><iid>100060440</iid><address><street>Friedenheimer Brücke 21</street><city>80639 München</city><country>DE</country></address></addressbook></agent></agents></parties><international-convention-data><designated-states><ep-contracting-states><country mxw-id="DS660783476" load-source="docdb">AL</country><country mxw-id="DS660610534" load-source="docdb">AT</country><country mxw-id="DS660783478" load-source="docdb">BE</country><country mxw-id="DS660687790" load-source="docdb">BG</country><country mxw-id="DS660685542" load-source="docdb">CH</country><country mxw-id="DS660611024" load-source="docdb">CY</country><country mxw-id="DS660610543" load-source="docdb">CZ</country><country mxw-id="DS660783479" load-source="docdb">DE</country><country mxw-id="DS660611025" load-source="docdb">DK</country><country mxw-id="DS660611026" load-source="docdb">EE</country><country mxw-id="DS660685123" load-source="docdb">ES</country><country mxw-id="DS660687795" load-source="docdb">FI</country><country mxw-id="DS660687796" load-source="docdb">FR</country><country mxw-id="DS660783480" load-source="docdb">GB</country><country mxw-id="DS660611031" load-source="docdb">GR</country><country mxw-id="DS660783481" load-source="docdb">HR</country><country mxw-id="DS660610544" load-source="docdb">HU</country><country mxw-id="DS660685547" load-source="docdb">IE</country><country mxw-id="DS660611032" load-source="docdb">IS</country><country mxw-id="DS660687797" load-source="docdb">IT</country><country mxw-id="DS660611033" load-source="docdb">LI</country><country mxw-id="DS660606578" load-source="docdb">LT</country><country mxw-id="DS660690432" load-source="docdb">LU</country><country mxw-id="DS660606579" load-source="docdb">LV</country><country mxw-id="DS660606580" load-source="docdb">MC</country><country mxw-id="DS660690433" load-source="docdb">MK</country><country mxw-id="DS660690434" load-source="docdb">MT</country><country mxw-id="DS660687798" load-source="docdb">NL</country><country mxw-id="DS660685124" load-source="docdb">NO</country><country mxw-id="DS660685548" load-source="docdb">PL</country><country mxw-id="DS660690491" load-source="docdb">PT</country><country mxw-id="DS660687803" load-source="docdb">RO</country><country mxw-id="DS660690492" load-source="docdb">RS</country><country mxw-id="DS660685549" load-source="docdb">SE</country><country mxw-id="DS660610545" load-source="docdb">SI</country><country mxw-id="DS660685125" load-source="docdb">SK</country><country mxw-id="DS660685550" load-source="docdb">SM</country><country mxw-id="DS660606582" load-source="docdb">TR</country></ep-contracting-states><ep-extended-states><ep-extended-state-data><country>BA</country></ep-extended-state-data><ep-extended-state-data><country>ME</country></ep-extended-state-data></ep-extended-states></designated-states></international-convention-data></bibliographic-data><abstract mxw-id="PA166479842" lang="EN" load-source="patent-office"><p id="pa01" num="0001">Embodiments relate to storing sparse matrices in an in-memory column-oriented database system. Specifically, recent hardware shifts of primary storage from disc into memory, allow execution of linear algebra queries directly in the database engine. Dynamic matrix manipulation operations (like online insertion or deletion of elements) are not covered by most linear algebra frameworks. Therefore a hybrid architecture comprises a read-optimized main structure, and a write-optimized delta structure. The resulting system layout derived from the Compressed Sparse Row (CSR) representation, integrates well with a columnar database design. Moreover, the resulting architecture is amenable to a wide range of non-numerical use cases when dictionary encoding is used. Performance in specific examples is evaluated for dynamic sparse matrix workloads, by applying work flows of nuclear science and network graphs. Embodiments allow performing linear algebra operations on large, sparse matrices commonly associated with scientific computations and analytical business applications.
<img id="iaf01" file="imgaf001.tif" wi="153" he="82" img-content="drawing" img-format="tif"/>
<img id="iaf02" file="imgaf002.tif" wi="164" he="212" img-content="drawing" img-format="tif"/></p></abstract><abstract mxw-id="PA166759654" lang="EN" source="EPO" load-source="docdb"><p>Embodiments relate to storing sparse matrices in an in-memory column-oriented database system. Specifically, recent hardware shifts of primary storage from disc into memory, allow execution of linear algebra queries directly in the database engine. Dynamic matrix manipulation operations (like online insertion or deletion of elements) are not covered by most linear algebra frameworks. Therefore a hybrid architecture comprises a read-optimized main structure, and a write-optimized delta structure. The resulting system layout derived from the Compressed Sparse Row (CSR) representation, integrates well with a columnar database design. Moreover, the resulting architecture is amenable to a wide range of non-numerical use cases when dictionary encoding is used. Performance in specific examples is evaluated for dynamic sparse matrix workloads, by applying work flows of nuclear science and network graphs. Embodiments allow performing linear algebra operations on large, sparse matrices commonly associated with scientific computations and analytical business applications.</p></abstract><description mxw-id="PDES98404543" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><heading id="h0001">BACKGROUND</heading><p id="p0001" num="0001">Embodiments relate to databases, and in particular, to methods and systems performing sparse linear algebra in a column-oriented in-memory database.</p><p id="p0002" num="0002">Unless otherwise indicated herein, the approaches described in this section are not prior art to the claims in this application and are not admitted to be prior art by inclusion in this section.</p><p id="p0003" num="0003">Linear algebra in the context of database systems is a subject of research, as it is a fundamental pillar of analytical algorithms. Matrices and matrix operations are used in a variety of use cases in the science and business world. Among these application fields are: nuclear physics, genome analysis, electrical, mechanical and chemical engineering, economical correlation analysis, machine learning and text mining, and graph algorithms, to mention only a few.</p><p id="p0004" num="0004">In the era of big data and the data deluge in business and science environments, data replication from database management systems (DBMS) into external linear algebra systems (for instance MATLAB or R), consumes increasing amounts of time and memory. As a consequence, data should only reside in a single system, which for business environments usually is a relational DBMS. However, disk-based DBMS's may exhibit poor performance of random access patterns on large data sets, such as linear algebra operations on very large matrices.</p><p id="p0005" num="0005">The decrease in Random Access Memory (RAM) prices in recent years has laid the foundation for the shift of the database storage from hard disc into main memory. This trend toward such "in-memory database" technology has resulted in considerable performance gains for analytical queries on large data sets. With the data residing in RAM, it has become worthwhile to investigate how structures and algorithms of numerical libraries can be integrated into the database engine.</p><p id="p0006" num="0006">Besides the change in database system design due to the emerging hardware trends, the introduction of a column-oriented database design has shown performance advantages on<!-- EPO <DP n="2"> --> analytical workloads. Such performance stands in contrast to conventional row-oriented approaches.</p><p id="p0007" num="0007">Accordingly, there is a need for apparatuses and methods for performing sparse linear algebra in column-oriented in-memory database systems.</p><heading id="h0002">SUMMARY</heading><p id="p0008" num="0008">Embodiments relate to storing sparse matrices in an in-memory column-oriented database system. Specifically, recent hardware shifts of primary storage from disc into memory, allow execution of linear algebra queries directly in the database engine. Dynamic matrix manipulation operations (like online insertion or deletion of elements) are not covered by most linear algebra frameworks. Therefore a hybrid architecture comprises a read-optimized main structure, and a write-optimized delta structure. The resulting system layout derived from the Compressed Sparse Row (CSR) representation, integrates well with a columnar database design. Moreover, the resulting architecture is amenable to a wide range of non-numerical use cases when dictionary encoding is used. Performance in specific examples is evaluated for dynamic sparse matrix workloads, by applying work flows of nuclear science and network graphs. Embodiments allow performing linear algebra operations on large, sparse matrices commonly associated with scientific computations and analytical business applications.</p><p id="p0009" num="0009">An embodiment of a computer-implemented method comprises causing an engine to store an updatable column representation of data including a row column in a main structure and in a delta structure of an in-memory database, and causing the engine to merge the delta structure into the main structure when a delta exceeds a threshold. The engine is caused to sort columns of the updatable column representation according to values of the row column. The engine is caused to derive an index according to the sorted columns. The engine is caused to reference the index to perform an algebraic operation, and to store a result of the algebraic operation.</p><p id="p0010" num="0010">A non-transitory computer readable storage medium embodies a computer program for performing a method comprising causing an engine to store an updatable column representation of data including a row column in a main structure and in a delta structure of an in-memory database, and causing the engine to merge the delta structure into the main structure when a delta exceeds a threshold. The engine is caused to sort columns of the<!-- EPO <DP n="3"> --> updatable column representation according to values of the row column. The engine is caused to derive an index according to the sorted columns. The engine is caused to reference the index to perform an algebraic operation, and to cause the engine to store a result of the algebraic operation.</p><p id="p0011" num="0011">An embodiment of a computer system comprises one or more processors and a software program executable on said computer system. The software program is configured to cause an engine to store an updatable column representation of data including a row column in a main structure and in a delta structure of an in-memory database, and to cause the engine to merge the delta structure into the main structure when a delta exceeds a threshold. The engine is caused to sort columns of the updatable column representation according to values of the row column. The engine is caused to derive an index according to the sorted columns. The engine is caused to reference the index to perform an algebraic operation, and to cause the engine to store a result of the algebraic operation.</p><p id="p0012" num="0012">In certain embodiments the column representation comprises a Compressed Sparse Row (CSR) representation and a value comprises a row pointer.</p><p id="p0013" num="0013">According to some embodiments the data comprises a matrix.</p><p id="p0014" num="0014">In particular embodiments the column representation utilizes dictionary encoding.</p><p id="p0015" num="0015">Various embodiments may further comprise updating the delta structure utilizing a validity control vector.</p><p id="p0016" num="0016">According to some embodiments the algebraic operation comprises matrix-vector multiplication.</p><p id="p0017" num="0017">Particular embodiments may further comprise updating the delta structure by appending a triple.</p><p id="p0018" num="0018">The following detailed description and accompanying drawings provide a better understanding of the nature and advantages of embodiments.</p><heading id="h0003">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p0019" num="0019"><ul><li><figref idrefs="f0001">Figure 1</figref> shows an overview of different approaches to represent a matrix logically in a DBMS, and corresponding internal representations in a columnar storage.<!-- EPO <DP n="4"> --></li><li><figref idrefs="f0002">Figure 2</figref> shows the CSR representation, with compression of the row container shown at left, and the row pointer vector (RowPtr) shown at right. The access path to the first matrix row is sketched.</li><li><figref idrefs="f0003">Figure 3</figref> shows a social network graph table and the dictionary-encoded columnar storage architecture.</li><li><figref idrefs="f0004">Figure 4</figref> shows a column-oriented architecture containing a static main and an incremental delta structure.</li><li><figref idrefs="f0005">Figure 5</figref> shows matrix subarray access patterns.</li><li><figref idrefs="f0006 f0007 f0008">Figures 6A-6F</figref> show for the algorithm of <figref idrefs="f0013">Figure 10</figref>, runtime performance comparison of the main-delta architecture against static CSR, a pure triple table and a dense array using different matrices and x-vectors with a varying population density <i>ρ</i><sup>x</sup>. For each plot, the corresponding sparse matrix was filled with nonzero elements between consecutive query executions, which results in an increasing matrix population density along the x-axis. The delta merge threshold was set to deltaT = 15%.</li><li><figref idrefs="f0009">Figures 7A-B</figref> shows comparison of the execution duration of the algorithm of <figref idrefs="f0014">Figure 12</figref> on graph Gra1 and Gra2 between a CSR and a triple table with respective sparse (SpI) and dense (DI) intermediate structures. The x-axis denotes the depth parameter of the algorithm of <figref idrefs="f0014">Figure 12</figref>.</li><li><figref idrefs="f0010">Figures 8A-B</figref> show comparison of the overall query throughput with <i>N<sub>read</sub> =</i> 50 using the different approaches relative to CSRMem on Mat1 and Mat3.</li><li><figref idrefs="f0011 f0012">Figures 9A-9D</figref> show average duration of a matrix <i>k</i>-rows (upper plot) and a <i>k-</i>column (lower plot) delete operation and the following algorithm of <figref idrefs="f0013">Figure 10</figref> (20 times repeated) execution query. The left bar denotes the total query execution time. The operations were performed on matrix Mat1 and Mat2 with <i>k</i> = 0.01<i>m</i> and <i>k</i> = 0.01<i>n,</i> respectively.</li><li><figref idrefs="f0013">Figure 10</figref> shows steps of a process for performing sparse matrix-vector multiplication according to an embodiment.</li><li><figref idrefs="f0014">Figure 11</figref> shows steps of a process for eigenvalue calculation according to an embodiment.<!-- EPO <DP n="5"> --></li><li><figref idrefs="f0014">Figure 12</figref> shows steps of a process for performing breadth-first searching according to an embodiment.</li><li><figref idrefs="f0015">Figure 13</figref> illustrates a system configured to perform linear algebra according to one embodiment.</li><li><figref idrefs="f0016">Figure 13A</figref> shows an enlarged view of a database layer according to an embodiment.</li><li><figref idrefs="f0017">Figure 13B</figref> illustrates steps of an embodiment of a method of performing linear algebra according to an embodiment.</li><li><figref idrefs="f0018">Figure 14</figref> illustrates hardware of a special purpose computing machine configured to perform linear algebra according to an embodiment.</li><li><figref idrefs="f0019">Figure 15</figref> illustrates an example of a computer system.</li></ul></p><heading id="h0004">DETAILED DESCRIPTION</heading><p id="p0020" num="0020">Described herein are techniques for performing linear algebra in a column-oriented in-memory database system according to an embodiment. In the following description, for purposes of explanation, numerous examples and specific details are set forth in order to provide a thorough understanding of the present invention. It will be evident, however, to one skilled in the art that the present invention as defined by the claims may include some or all of the features in these examples alone or in combination with other features described below, and may further include modifications and equivalents of the features and concepts described herein.</p><p id="p0021" num="0021">Embodiments relate to storing sparse matrices in an in-memory column-oriented database system. Specifically, recent hardware shifts of primary storage from disc into memory, allow execution of linear algebra queries directly in the database engine. Dynamic matrix manipulation operations (like online insertion or deletion of elements) are not covered by most linear algebra frameworks. Therefore a hybrid architecture comprises a read-optimized main structure, and a write-optimized delta structure. The resulting system layout derived from the Compressed Sparse Row (CSR) representation, integrates well with a columnar database design. Moreover, the resulting architecture is amenable to a wide range of non-numerical use cases when dictionary encoding is used. Performance in specific<!-- EPO <DP n="6"> --> examples is evaluated for dynamic sparse matrix workloads, by applying work flows of nuclear science and network graphs. Embodiments allow performing linear algebra operations on large, sparse matrices commonly associated with scientific computations and analytical business applications.</p><p id="p0022" num="0022">There are at least two major limitations of using of a conventional DBMS for linear algebra applications. First, random access on hard disc and unsuitable data structures and operators can result in poor performance.</p><p id="p0023" num="0023">A second restriction is usability. Since relational DBMS's do not provide appropriate data objects, such as matrices and vectors, data scientists often rely on handwritten and highly specialized solutions. But rather than being responsible for maintaining hardware-dependent solutions, many scientists would prefer to work on a more conceptual level. A DBMS with integrated support for matrices as first class citizens could serve as a framework for scalable linear algebra queries, and supersedes the need for copying data to an external algebra system.</p><p id="p0024" num="0024">The integration of linear algebra operations into the database system may impose one or more conditions. One possible condition is an avoidance of data transfer. Specifically, with the data persisted and kept consistently in a single database system with integrated linear algebra functionality, the expensive copying into external systems becomes dispensable.</p><p id="p0025" num="0025">Another condition is for a single source of truth. In particular, the absence of redundant copies of data in external systems avoids data inconsistencies. Moreover, the corresponding meta data of data sets can be updated synchronously and consistently with the raw data.</p><p id="p0026" num="0026">Still another condition is efficient implementation. Data scientists seek a system that is able to compete with existing high performance systems, which usually are optimized for the platform hardware. Efficient algorithms for linear algebra have been researched and can be referenced. Carefully tuned library algorithms can be reused as a kernel for medium-sized matrices. Herein, medium-sized matrices are referred to as data volumes which fit into the memory of a single machine.<!-- EPO <DP n="7"> --></p><p id="p0027" num="0027">Yet another condition is manipulation of data. In several analytic work flows, large matrices are not static objects. Single elements, rows, columns, or matrix subregions should be able to be read, updated or deleted by the user.</p><p id="p0028" num="0028">Another condition is a standardized user Application Program Interface (API). Users from science environments desire to have an declarative and standardized language for matrix manipulation primitives and linear algebra operations.</p><p id="p0029" num="0029">To address these conditions, an architecture for sparse matrices is presented that integrates with a column-oriented in-memory DBMS, and provides an application interface allowing work flows from science and business environments to be run efficiently.</p><p id="p0030" num="0030">Embodiments may include one or more of the following characteristics. One characteristic is a mutable sparse matrix architecture. A matrix architecture with a columnar layout is presented by taking advantage of well-known, ordered sparse matrix data structures. Moreover, a two-layered main-delta storage can be exploited to provide dynamic matrix manipulation in constant time, without being penalized by a reordering of the optimized main matrix representation.</p><p id="p0031" num="0031">Another characteristic is the matrix application interface. Similar to the data manipulation language of transactional, relational systems, embodiments provide an application interface to access and manipulate matrices.</p><p id="p0032" num="0032">Another characteristic is applicability to non-numeric use cases. Relational tables can be reinterpreted as sparse matrices, and analytical queries can be rewritten to exploit efficient linear algebra algorithms.</p><p id="p0033" num="0033">Described further below is an implementation of different matrix representations, and evaluation of the performance of the architecture against alternative approaches using real world applications of science and network graphs.</p><p id="p0034" num="0034"><figref idrefs="f0015">Figure 13</figref> shows a simplified view of a system 1300 configured to perform linear algebra according to an embodiment. Application layer 1302 provides the environment supporting operation of a software program 1304, such as a financial (FI) planning platform. One example of such software is Enterprise Resource Planning (ERP) software available from SAP AG of Walldorf, Germany.<!-- EPO <DP n="8"> --></p><p id="p0035" num="0035">The software program resident within the application layer, is designed to access and manipulate (e.g., perform linear algebraic operations upon) various types of data present in a database (DB) layer 1306. The application layer then presents that data and/or the results of the manipulation to a user 1320.</p><p id="p0036" num="0036">In particular, that database layer may comprise a non-transitory computer readable storage medium 1308 having an in-memory database stored thereon. The database layer further comprises an in-memory database engine 1312 that is configured to govern interaction with the underlying database structure.</p><p id="p0037" num="0037">As shown and described in detail in connection with <figref idrefs="f0004">Figure 4</figref> (below), particular embodiments may employ a storage architecture in which columns are separated into a static main structure 1310 that is compressed and read-optimized, and an incremental delta structure 1311 that is write-optimized. The delta storage is periodically merged into the main storage that includes a reorganization that sorts the columns. After this sorting, an index (e.g., CSR index) is created. The index is then referenced by the matrix engine to perform an algorithm comprising an algebraic operation.</p><p id="p0038" num="0038">The database layer further comprises a Matrix Engine 1314. As described in detail below, in response to communications 1315 with the application layer, the matrix engine is configured to perform linear algebra operations upon data stored in the database layer.</p><p id="p0039" num="0039">In particular, <figref idrefs="f0016">Figure 13A</figref> shows an enlarged view of an embodiment of an in-memory database layer, in this particular case the HANA in-memory database available from SAP AG of Walldorf, Germany. This database layer 1306 comprises the matrix data in the form of a Compressed Sparse Row (CSR) index 1372.</p><p id="p0040" num="0040"><figref idrefs="f0016">Figure 13A</figref> shows the database layer as comprising a relational stack 1373 receiving inputs 1375 as SQL, Java DataBase Connectivity (JDBC), or Open DataBase Connectivity (ODBC). The relational stack comprises a SQL Compiler, SQL runtime, and relational application program interface (API).</p><p id="p0041" num="0041">The <figref idrefs="f0016">Figure 13A</figref> moreover shows a Matrix Stack 1374 that is configured to receive inputs 1377 in the form of a Remote Procedure Call (RPC) from the overlying application layer. This Matrix Stack 1374 comprises an engine that is aware of the matrix-structure and includes several algorithms. One of these algorithms is for general matrix vector multiplication (gemv) 1376. The matrix engine further exists with the corresponding<!-- EPO <DP n="9"> --> application program interface (Matrix API 1378) for creating a matrix table and the gemv algorithm.</p><p id="p0042" num="0042"><figref idrefs="f0016">Figure 13A</figref> furthermore shows the CSR index 1372 as being part of the column store engine 1380. This column store engine works as part of the in-memory database engine independently from the MatrixEngine/API, to provide functionality of the HANA in-memory database.</p><p id="p0043" num="0043">While the above <figref idrefs="f0016">Figure 13A</figref> shows one specific in-memory database layer implemented as the SAP HANA database, this is not required. Other types of in-memory databases are known, including but not limited to the SYBASE IQ database also available from SAP AG; the Microsoft Embedded SQL for C (ESQL/C) database available from Microsoft Corp. of Redmond, Washington; and the Exalytics In-Memory database available from Oracle Corp. of Redwood Shores, California.</p><p id="p0044" num="0044"><figref idrefs="f0017">Figure 13B</figref> is a simplified flow diagram showing steps of a process 1350 according to an embodiment. A first step 1352 comprises creating a representation of a matrix as three columns (each for <i>row, column</i> coordinates and the <i>value</i>), and storing the columns in a read-optimized main memory structure, and incremental updates in a write-optimized delta memory structure.</p><p id="p0045" num="0045">A second step 1354 comprises optionally merging the delta memory structure into the main memory structure when appropriate. An example of when such merger occurs is where the delta size exceeds a certain threshold that may be defined in the system.</p><p id="p0046" num="0046">A third step 1356 comprises sorting the columns by values of the row column. A fourth step 1358 comprises deriving an index that exploits the sorting.</p><p id="p0047" num="0047">A fifth step 1360 comprises performing an algebraic operation referencing the index. A sixth step 1362 comprises storing a result of the algebraic operation.</p><p id="p0048" num="0048">Embodiments are now further illustrated and described in connection with the following examples. These examples are illustrated in conjunction with <figref idrefs="f0001 f0002 f0003 f0004 f0005 f0006 f0007 f0008 f0009 f0010 f0011 f0012">Figures 1-9D</figref>.</p><p id="p0049" num="0049">The matrix storage architecture is first discussed. This aspect addresses the architectural question of how a large sparse matrix should be represented in a columnar database system. Therefore, different columnar data structures for matrices are considered with regard to their integrability into an in-memory DBMS.<!-- EPO <DP n="10"> --></p><p id="p0050" num="0050">The challenge of many analytical database systems (which strive for both quick query execution and immediate updates), is the dualism of read- and write-optimized structures. The representations are examined according to the following two criteria: optimization for read access and the complexity of manipulations, i.e. the mutability of the data structure.</p><p id="p0051" num="0051">Since these opposed characteristics are unlikely to be achieved by a single structure, a main-delta approach is employed. This relies upon separation of an abstract storage layer into two different physical representations - an optimized (compressed) static and a mutable delta structure.</p><p id="p0052" num="0052">At least four different representations for matrices may be considered with respect to their applicability in the main-delta architecture. One representation is the matrix table.</p><p id="p0053" num="0053">A straightforward way of storing matrices in a RDBMS is to translate matrix rows to table rows and matrix columns to table columns. This approach results in a <i>m</i> × <i>n</i>-sized table for a <i>m</i> × <i>n</i> matrix, as shown in a) of <figref idrefs="f0001">Figure. 1</figref>. In a column-oriented DBMS this would be reflected as <i>n</i> separate column storage containers. However, this representation often reaches its limitations if matrices are very wide, since the number of table columns in common DBMS's is usually restricted. The apparent advantage (that the matrix table representation is intuitive because it preserves the logical two-dimensionality of a matrix) loses its justification when the matrix size grows to an extent where displaying the matrix interactively is simply not feasible anymore.</p><p id="p0054" num="0054">Moreover, the matrix table is a dense representation, which makes it unusable for sparse matrices, unless the individual columns are compressed. Compressing the individual columns would decrease memory consumption, but usually adds the decompression to the algorithm execution runtime. The advantage of individual column compression in conventional business tables becomes superfluous as the columns of a matrix tend to be of similar structure.</p><p id="p0055" num="0055">Another representation is the single value column. Specifically, another way of representing a matrix is to put every value (including zeros) adjacently into one large, consecutive value sequence. This translates into a single table column, shown as b) in <figref idrefs="f0001">Figure 1</figref>. This internally results in a large value container. To avoid misunderstanding with a matrix column, container refers to the storage structure for a column in a column-store DBMS.<!-- EPO <DP n="11"> --></p><p id="p0056" num="0056">For this representation, a 2D to 1D linearization is needed. This mapping is implicitly performed on regular 2D-arrays in most programming languages, since the memory is sequentially addressable either way. Embodiments may use a row-by-row sequence, which is effectively a linearization according to the row-major order. The position of each matrix element in the sequence can be calculated using its 2D coordinates and the matrix <i>m</i> × <i>n</i> dimensions, i.e. the position of an element (<i>i, j</i>) in the sequence is <i>i · n + j.</i> The advantage of this uncompressed representation is that reads and writes are of constant complexity, whereas the disadvantage lies in the static memory consumption of <i>O</i>(<i>m · n),</i> independent of the sparsity of the matrix.</p><p id="p0057" num="0057">It should be mentioned that the single value column representation is clearly not relational, since positional referencing within a single table column elements is usually not supported and contradicts the relational thought of having an unordered set of relations. However, it is assumed that a logical layer for addressing single matrix elements in the DBMS exists, and the uncompressed 1D array representation is used as a comparison measure in the evaluation.</p><p id="p0058" num="0058">A third way of representing a matrix is as a collection of triples. This is shown as c) in <figref idrefs="f0001">Figure 1</figref>. Each triple contains the row and column coordinate, and the value of the corresponding matrix element: <i>&lt;row, col, val&gt;.</i> The <i>row</i> and <i>col</i> attributes form a composite primary key, thus duplicate matrix elements are avoided. This variant turns out to be effective if the matrix is sparse, because only the non-zero elements have to be kept and the order of the rows is generally arbitrary.</p><p id="p0059" num="0059">In a column-oriented database, this triple table is represented as separate containers in the storage layer. Each of the containers has the length <i>N<sub>nz</sub></i> which is equal to the number of non-zero matrix elements, resulting in a total memory consumption of <i>O</i>(<i>3N<sub>nz</sub></i>)<i>.</i> To find an element in the unsorted, not indexed triple table a full column scan (O(<i>N<sub>nz</sub></i>)) is required. The insertion of additional non-zero matrix elements is performed in constant time as they can just be appended to the end of the respective physical container, which makes the triple representation suitable as delta structure in our architecture. Further compression of the triple table can be achieved by sorting it according to one of the coordinates. The thereby resulting adjacent chunks of identical numbers in the corresponding container can then be compressed. This, however, influences the update and algorithmic behavior, so that the compressed format is considered as a separate representation.<!-- EPO <DP n="12"> --></p><p id="p0060" num="0060">Still another possible representation is the compressed sparse row and compressed sparse column format that are sparse matrix structures in the numerical algebra community. For the sake of simplicity, this description is confined to the CSR representation of <figref idrefs="f0002">Figure 2</figref>. The CSC representation of a matrix A is equal to the CSR representation of the transposed matrix <i>A<sup>T</sup>,</i> and vice versa. The CSR representation is effectively a compression of the row-major-ordered triple representation. The row-major order allows replacing the row container by a row pointer vector (RowPtr) which contains only the start positions of each matrix row, as shown in <figref idrefs="f0002">Figure 2</figref>. The central characteristic of the row pointer vector is that it also acts as an index, since a look-up for a row coordinate value provides the physical positions of the matrix row in the remaining containers of the triple table. As an example, to get all elements of the first row, every triple from the row start position <i>RowPtr</i>[1] up to the end position <i>RowPtr</i>[2] <i>-</i> 1 is returned. The row pointer vector of an <i>m</i> × <i>n</i> matrix has thus the size m + 1, where the (<i>m</i> + 1)<i><sup>th</sup></i> element denotes the end position of the <i>m<sup>th</sup></i> row in the column and value containers. The total memory consumption is <i>O</i>(<i>2N<sub>nz</sub></i> + <i>(m</i> + 1)), thus usually less than that of the triple format, because the inequation (<i>m</i> +1) ≤ <i>N<sub>nz</sub></i> is only violated if the matrix contains rows of zeros.</p><p id="p0061" num="0061">In the original CSR implementation, the materialized row container is discarded and replaced completely by the row pointer vector. As contrasted to the uncompressed triple representation, the complexity for the inverse access (i.e., finding the row coordinate <i>x</i> to a table position <i>i</i>) is not constant. For this operation the interval of the start positions I : [<i>I</i><sub><i>V</i> ;</sub><i>I</i><sub><i>V</i>+1</sub>] where i ∈ I has to be determined. However, this can be easily performed using a binary search in an asymptotic complexity of <i>O</i>(ln(<i>m</i>+ 1)), as the row pointer vector is sorted. In contrast to many naive conventional compression techniques that are used columnar stores, a partial or complete decompression of the row pointer vector is not necessary. The row access in <i>O</i>(1) and the (average) single element access in <maths id="math0001" num=""><math display="inline"><mrow><mi>O</mi><mfenced separators=""><mrow><mi>ln</mi><mspace width="1em"/></mrow><msqrt><mrow><msub><mi>N</mi><mi mathvariant="italic">nz</mi></msub></mrow></msqrt></mfenced></mrow></math><img id="ib0001" file="imgb0001.tif" wi="24" he="8" img-content="math" img-format="tif" inline="yes"/></maths> time makes it a reasonable choice for our static main storage structure.</p><p id="p0062" num="0062">The impact of the linearization order is now discussed. As the linearization order plays an important role in most of the abovementioned representations, it may be recognized that certain algorithmic patterns favor certain orders. The row-major and column-major ordering are biased linearization techniques. For instance, a row-major order would not be chosen as internal layout when it is likely that complete columns are accessed. A single column iteration translates into a <i>jump</i> memory access pattern on a row-major order, since the<!-- EPO <DP n="13"> --> addresses are separated by the row width and spread over the complete memory section, whereas it yields in a cache-efficient, locally restricted and sequential memory scan on a column-major order. Although there are nonbiased linearizations, such as the recursive Morton order or the Hilbert curve, they exhibit poor cache locality for one-directional algorithmic patterns, e.g., BLAS level 2 operations.</p><p id="p0063" num="0063">Furthermore, the linearization order defines the compression either CSR (row-major) or CSC (column-major). With the row pointer vector as index, algorithms with a row-centric pattern obviously benefit from a CSR structure whereas column-centric algorithms would favor a CSC-based approach. This introduces a bias in algorithmic performance, but the majority of algorithms are usually one-directional, i.e., they can be expressed in a way that accesses only one of the two dimensions. Examples are the matrix-vector multiplication or the graph breadth-first search, discussed below. However, if an algorithm favors a CSC structure, but the matrix is available in CSR representation, then often an alternative algorithm working on the transposed structure can be used, since <i>A<sub>CSR</sub></i> = (<i>A<sup>T</sup></i>)<i><sub>csc</sub>.</i></p><p id="p0064" num="0064">Nevertheless, in contrast to the sole use of numerical libraries or common algebra systems, where the user is required to define the matrix representation in advance, and has to be aware of the algorithmic access and manipulation patterns, a DBMS that accommodates query statistics can act as advisor to reorder the matrix representation.</p><p id="p0065" num="0065">System Architecture is now discussed. In particular, an approach for supporting mutable sparse matrices integrates with a column-oriented DBMS. In particular, the mutability of large matrix data sets (a condition described above) is provided without losing the advantage of optimized storage structures. Moreover, the efficient indexing method of the CSR representation can be exploited by arbitrary tables, when integer dictionary-encoding is used.</p><p id="p0066" num="0066">It is noted that the following data structures of our architecture are contained in RAM. In particular in sparse linear algebra, random access patterns are usual, which becomes clearer in sketching example algorithms below. For not being penalized by hard disk accesses, a main memory database environment is chosen which does not pose a limitation, since recent in-memory systems are reaching storage scales of 1 TB and more.</p><p id="p0067" num="0067">In recent DBMS's the storage architecture of each column is separated into a static main structure compressed and read-optimized for online analytical processing (OLAP), and<!-- EPO <DP n="14"> --> an incremental delta structure write-optimized for online transactional processing (OLTP). The delta storage is merged into the main storage periodically, and each of these merge steps includes a reorganization, the original purpose of which is to improve the compression ratio by reordering the table rows. Here, according to embodiments the reorganization is exploited to sort the columns by their values. This step is transparent to the user and can be implemented in a way so that online query execution performance is not affected. The internal algorithms are usually dependent on the representation and are therefore executed separately on the main and the delta storage.</p><p id="p0068" num="0068">The static main component is now discussed. The static main component contains a data representation that is optimized for read operations, and moreover to the patterns of sparse matrix algorithms. The evaluation which follows later below, shows that a CSR (CSC) representation turns out to be beneficial in a variety of use cases, especially in the applications which are related to the sparse matrix-vector multiplication. Besides its efficiency and applicability in many numerical libraries, the CSR representation integrates well into a column-oriented DBMS, since the row pointer vector is at the same time both an index for the triple table and the compressed version of the row container itself.</p><p id="p0069" num="0069">The CSR representation, and thus the derived <i>CSR index</i> (the CSR index corresponds to the row pointer vector) are not limited to applications with matrices. Every database table accommodating a relation <i>R =</i> {<i>a</i><sub>1</sub>,<i>a</i><sub>2</sub> , ...} of at least two attributes and arbitrary values, except the null value (<i>a<sub>i</sub></i> ≠ NULL), can be transformed into an internal CSR structure, if the values are translated into subsequent integer values. Embodiments may employ a column-store DBMS that uses by default dictionary encoding for every column in order to reduce the memory consumption and improve the scan performance, since table values in business environments are predominantly reoccurring strings. Thus, each table value of arbitrary format is assigned an integer <i>id</i> ∈ {0,1,...,<i>n<sub>values</sub></i> - 1}, so that only the integer value IDs are materialized and kept in the containers. This circumstance allows for creating a CSR-based representation for a large group of use cases.</p><p id="p0070" num="0070">The dictionary encoding is sketched in <figref idrefs="f0003">Figure 3</figref>, which shows the internal database representation of a social network table that contains <i>string</i> and <i>date</i> values. The left portion a) shows the logical view of the table in the database with two attributes (<i>Name, Friend of</i>) that denote the graph topology, and an auxiliary attribute <i>(Since).</i> The right portion b) shows the internal representation that comprises dictionaries and integer columns.<!-- EPO <DP n="15"> --></p><p id="p0071" num="0071">The dictionary of the <i>Name</i> attribute is sorted in ascending order by its values, which are then assigned consecutive integers, starting with zero. As a result, the materialized container for a table column comprises only integer values. The single precondition for the applicability of CSR-based representation according to embodiments, is the ordering of the table. The sorting of every container in the corresponding table according to the value ids of the leading attribute, which is <i>Name</i> in <figref idrefs="f0003">Figure 3</figref> and Row for a matrix table, is performed during the reorganization step following a delta merge. After sorting the table, the CSR index is created.</p><p id="p0072" num="0072">In the original form of CSR a two-level nested sorting is used to achieve a strictly row-major ordering of a two-dimensional matrix. The sort order is first by row, then by column values. However, the latter is not required to create the CSR index, although a subordering of the column leads to an increased algorithmic performance. This can be explained by cache effects: during a matrix vector multiplication, the column coordinates refer to positions in the target array. If they were randomly ordered, many cache-lines would have to be evicted and reloaded again, whereas an ascending order leads to cache-friendly writes.</p><p id="p0073" num="0073">The incremental delta component is now discussed. The sorted characteristic of the optimized CSR representation makes it a static structure that is not mutable in constant time. Hence, in common numerical algebra work-flows the representation has to be rebuilt after manipulating the matrix, even for slight changes like the single insert of an additional nonzero matrix element. This results in a <i>O</i>(<i>N</i> ln N) sorting overhead that becomes particularly expensive for very large matrices in a dynamic workload.</p><p id="p0074" num="0074">Thus, the architecture as shown in <figref idrefs="f0004">Figure 4</figref> foresees an updatable, incremental delta structure that coexists with the static main structure.</p><p id="p0075" num="0075">Inserts of non-zero elements are processed by simply appending a &lt;<i>row</i>, <i>col, val&gt;</i> triple to the unsorted delta structure. Updates of already existing nonzero elements are performed in-place, i.e., either in main or delta. For a single element update, this requires a binary search on the column container on the main and a scan on the delta structure, thus on average <maths id="math0002" num=""><math display="inline"><mrow><mi>O</mi><mo>⁢</mo><mfenced separators=""><mrow><mi>ln</mi><mspace width="1em"/></mrow><msqrt><mrow><msubsup><mi>N</mi><mi mathvariant="italic">nz</mi><mi>M</mi></msubsup></mrow></msqrt><mo>+</mo><msubsup><mi>N</mi><mi mathvariant="italic">nz</mi><mi mathvariant="normal">Δ</mi></msubsup></mfenced></mrow></math><img id="ib0002" file="imgb0002.tif" wi="35" he="8" img-content="math" img-format="tif" inline="yes"/></maths> time.</p><p id="p0076" num="0076">Deletions of elements require an additional structure to keep track of the deleted elements. For this purpose our architecture contains <i>validity control</i> (VC) bitvectors for the<!-- EPO <DP n="16"> --> main table, the CSR index and the delta structure. For every deleted element, the bit of the corresponding container position in the respective main (II-VC) or delta bitvector (Δ-VC) is unset. Moreover, if a complete matrix row is removed, for instance row <i>k</i>, then the corresponding bit at position <i>k</i> of the IV-VC bitvector is unset.</p><p id="p0077" num="0077">The matrix application interface is now discussed. In classical database workloads, tables are commonly manipulated dynamically by inserting, updating or deleting data elements. However, the dynamic characteristic of relational database workflows also holds for large sparse matrix applications, as described for the nuclear science use case below. Hence, it is a valid assumption that sparse matrices are not just queried in a single-pass, but rather modified in-between subsequent query executions as part of an analytical workflow (e.g. the nuclear energy example below). Therefore, embodiments offer the user an interface with which sparse matrix data can be manipulated in a similar manner as relational tables with data manipulation language (DML) commands.</p><p id="p0078" num="0078">Basic manipulation primitives for matrix data are now discussed from a logical perspective, and also what an application interface could look like. According to embodiments, a database system contains matrices as first-class citizens, for instance by extending SQL with a matrix data type. Thus, matrices are defined in the data definition language (DDL) as such with the specification of its dimensions, which are stored as metadata in the system. The following application interfaces can then be exposed as built-in procedures that process matrix data types.</p><p id="p0079" num="0079">Access Patterns are now discussed. As a basis for the following algorithms and examples, the application programming interface for referencing matrix elements and regions is briefly introduced. Each of the two matrix dimensions can be queried by providing either a point, range or no restriction. Based on this assumption, a subarray referencing matrix is shown in <figref idrefs="f0005">Figure 5</figref>.</p><p id="p0080" num="0080">To fetch single elements or matrix subregions the command <b>get:</b> is defined. This <b>get:</b> is the counterpart of the relational <i>select ... where</i> statement, where the filter condition is replaced by a topological reference according to patterns shown in <figref idrefs="f0005">Figure 5</figref>. For example, get <b>A(5,3)</b> returns a single matrix element, <b>get A(*,3)</b> references the third column and <b>get A(1,</b>*) the first row of matrix A. Two-dimensional submatrices are returned by defining their row and column range, such as <b>get A([2,5],[3,5])</b> to retrieve the rectangular region between<!-- EPO <DP n="17"> --> the edge elements <b>A(2,3)</b> and <b>A(5,5).</b> The complete matrix is referenced by providing no restriction in both dimensions, thus <b>A(*,*)</b>.</p><p id="p0081" num="0081">Data manipulation primitives are now discussed. From the relational SQL perspective, the DML comprises commands to insert, delete, and update elements. The difference to a logical matrix context is that every single element of the matrix space <i>m</i> × <i>n</i> does in fact exist, independent of its value, including zero elements. Thus, there is no other interpretation of inserting a single matrix element than updating the already existing zero element of the matrix at the corresponding position. In the same way a deletion of a single element is rather described as setting the nonzero value to zero. However, if a complete row or column, or a submatrix is inserted with dimensions of either <i>m</i> × <i>k</i> or <i>k</i> × <i>n</i>, then an insert can also be interpreted as an expansion of the matrix by <i>k</i> rows or columns, respectively. In a similar manner, a deletion of regions spanning the whole row- or column range can be seen as an effective shrinking of the matrix. To remove this ambiguity, the following commands are defined.</p><p id="p0082" num="0082">The set: command sets any single element or region in the matrix space <i>m</i> × <i>n</i> and overrides the previous value of the corresponding matrix region. As an example, <b>set A(9,3) value 5.0</b> sets a value at position <b>(9,3),</b> whereas <b>set A([2,2],[3,3]) values (0.0, 0.0, 0.0, 0.0)</b> sets all the values of the square submatrix to zero.</p><p id="p0083" num="0083">The <b>delete:</b> command only applies to either a <i>m</i> × <i>k</i> (<i>k</i> rows) or a <i>k</i> × <i>n</i> (<i>k</i> columns) subregion of the corresponding <i>m</i> × <i>n</i> matrix. It affects the matrix dimension in such a way that the adjacent parts are shifted to the first free place which was formerly populated by a deleted row/column. Thus, the resulting matrix has either the dimension of (<i>m - k</i>) × <i>n</i> or <i>m</i> × (<i>n - k</i>)<i>,</i> respectively. For instance, <b>delete A(*,3)</b> executed on a 4 × 4 matrix A deletes the third column which changes the dimensions of <b>A</b> to 4 × 3.</p><p id="p0084" num="0084">The <b>insert:</b> command is the logical counterpart of the delete operation. The insertion of either <i>k</i> rows or <i>k</i> columns results in matrix dimensions of either (<i>m</i> + <i>k)</i> × <i>n</i> or <i>m</i> × (<i>n + k</i>)<i>.</i></p><p id="p0085" num="0085">The <b>copy:</b> command copies single elements, complete rows, columns or submatrices from any source position to a target position. If the target position exceeds the matrix bounds, then the copy operation only applies to <i>m</i> × <i>k</i> or <i>k</i> × <i>n</i> subregions. The overflowing rows or columns then affect the matrix dimension in the same way as an insert. The copy<!-- EPO <DP n="18"> --> operation is derived by a consecutive get and set operations, if the target position stays within the matrix bounds, and by a get and set/insert operation if the target position exceeds the matrix bounds.</p><p id="p0086" num="0086">The <b>flip:</b> command exchanges a <i>k</i> × I subregion from a source position to a target position, which must not exceed the matrix bounds. The flip cannot be implemented solely by consecutive get and set commands, since either the target or source region has to be buffered temporarily.</p><p id="p0087" num="0087">Next to these basic commands, a variety of further operations can be defined, such as transpose. However, manipulations of a sparse matrix, such as insertion of elements, is not foreseen in common algebra systems such as Matlab. By contrast, they can be integrated into matrix architectures according to embodiments as described herein. Setting single elements in a matrix is a fundamental operation in a variety of applications, for example in LU-decomposition methods, such as Gaussian Elimination or the Doolittle algorithm. Moreover, some analytical workflows tend to remove complete matrix rows or columns. In the example from nuclear science described below chunks of <i>k</i> rows and columns are deleted from the sparse matrix. Other examples are graph algorithms, where the elimination of a graph vertex corresponds to the removal of the adjacency matrix row (and the respective column).</p><p id="p0088" num="0088">Now discussed are two sparse matrix applications from different domains. It is shown how they can be run on the columnar main-delta architecture. Implementation of the sparse matrix-vector multiplication internally used as a kernel is described in the following two examples. A first example is the Lanczos algorithm for numerical eigenvalue calculation, taken from a theoretical nuclear physics analysis. A second example is an inclusive breadth-first search on network graphs.</p><p id="p0089" num="0089">Sparse matrix vector multiplication is now discussed. Let: <maths id="math0003" num=""><math display="block"><mrow><mi>y</mi><mo>=</mo><mi>A</mi><mo>⋅</mo><mi>x</mi></mrow></math><img id="ib0003" file="imgb0003.tif" wi="19" he="8" img-content="math" img-format="tif"/></maths><br/>
be a matrix-vector multiplication with <i>x</i> E <i>R<sup>m</sup></i> and <i>A</i> ∈ <i>R<sup>m×n</sup></i>. For illustrational purposes consider the transposed equation: <maths id="math0004" num=""><math display="block"><mrow><msup><mi>y</mi><mi>T</mi></msup><mo>=</mo><msup><mi>x</mi><mi>T</mi></msup><mo>⋅</mo><msup><mi>A</mi><mi>T</mi></msup></mrow></math><img id="ib0004" file="imgb0004.tif" wi="24" he="7" img-content="math" img-format="tif"/></maths><br/>
which can be written as follows.<!-- EPO <DP n="19"> --> <maths id="math0005" num=""><math display="block"><mrow><mtable><mtr><mtd><msup><mi>y</mi><mi>T</mi></msup><mo>=</mo><mfenced separators=""><msub><mi>x</mi><mn>1</mn></msub><mspace width="1em"/><msub><mi>x</mi><mn>2</mn></msub><mspace width="1em"/><msub><mi>x</mi><mn>3</mn></msub><mspace width="1em"/><mo>…</mo></mfenced><mo>⋅</mo><mfenced><mtable><mtr><mtd><msub><mi>A</mi><mn>11</mn></msub></mtd><mtd><msub><mi>A</mi><mn>12</mn></msub></mtd><mtd><msub><mi>A</mi><mn>13</mn></msub></mtd><mtd><mspace width="1em"/></mtd></mtr><mtr><mtd><msub><mi>A</mi><mn>12</mn></msub></mtd><mtd><msub><mi>A</mi><mn>22</mn></msub></mtd><mtd><msub><mi>A</mi><mn>23</mn></msub></mtd><mtd><mo>⋯</mo></mtd></mtr><mtr><mtd><msub><mi>A</mi><mn>13</mn></msub></mtd><mtd><msub><mi>A</mi><mn>23</mn></msub></mtd><mtd><msub><mi>A</mi><mn>33</mn></msub></mtd><mtd><mspace width="1em"/></mtd></mtr><mtr><mtd><mspace width="1em"/></mtd><mtd><mo>⋯</mo></mtd><mtd><mspace width="1em"/></mtd><mtd><mspace width="1em"/></mtd></mtr></mtable></mfenced></mtd></mtr><mtr><mtd><mspace width="1em"/></mtd></mtr><mtr><mtd><mtable columnalign="left"><mtr><mtd><msup><mi>y</mi><mi>T</mi></msup><mo>=</mo></mtd><mtd><msub><mi>x</mi><mn>1</mn></msub><mo>⋅</mo><mfenced separators=""><msub><mi>a</mi><mrow><mn>11</mn><mspace width="1em"/></mrow></msub><mo>⁢</mo><msub><mi>A</mi><mrow><mn>12</mn><mspace width="1em"/></mrow></msub><mo>⁢</mo><msub><mi>A</mi><mrow><mn>13</mn><mspace width="1em"/></mrow></msub><mo>⋯</mo></mfenced><mo>+</mo></mtd></mtr><mtr><mtd><mspace width="1em"/></mtd><mtd><msub><mi>x</mi><mn>2</mn></msub><mo>⋅</mo><mfenced separators=""><msub><mi>a</mi><mrow><mn>21</mn><mspace width="1em"/></mrow></msub><mo>⁢</mo><msub><mi>A</mi><mrow><mn>22</mn><mspace width="1em"/></mrow></msub><mo>⁢</mo><msub><mi>A</mi><mrow><mn>23</mn><mspace width="1em"/></mrow></msub><mo>⋯</mo></mfenced><mo>+</mo></mtd></mtr><mtr><mtd><mspace width="1em"/></mtd><mtd><mo>⋯</mo></mtd></mtr></mtable></mtd></mtr></mtable></mrow></math><img id="ib0005" file="imgb0005.tif" wi="104" he="47" img-content="math" img-format="tif"/></maths></p><p id="p0090" num="0090">From a implementational perspective, the linearity of the operation allows the independent, sequential processing on the main-delta data layout. With <i>A = A<sup>M</sup></i> + <i>A</i><sup>Δ</sup>, one obtains the superposition <maths id="math0006" num=""><math display="block"><mrow><msup><mi>y</mi><mi>T</mi></msup><mo>=</mo><msup><mi>x</mi><mi>T</mi></msup><mo>⋅</mo><msup><mfenced separators=""><msup><mi>A</mi><mi>M</mi></msup><mo>+</mo><msup><mi>A</mi><mi mathvariant="normal">Δ</mi></msup></mfenced><mi>T</mi></msup><mo>=</mo><munder><mrow><munder><mrow><msup><mi>x</mi><mi>T</mi></msup><mo>⋅</mo><msup><mi>A</mi><mrow><mi>M</mi><mo>,</mo><mi>T</mi></mrow></msup></mrow><mrow><mo>︸</mo></mrow></munder></mrow><mi>①</mi></munder><mo>+</mo><munder><mrow><munder><mrow><msup><mi>x</mi><mi>T</mi></msup><mo>⋅</mo><msup><mi>A</mi><mrow><mi mathvariant="normal">Δ</mi><mo>,</mo><mi>T</mi></mrow></msup></mrow><mrow><mo>︸</mo></mrow></munder></mrow><mi>②</mi></munder></mrow></math><img id="ib0006" file="imgb0006.tif" wi="105" he="16" img-content="math" img-format="tif"/></maths></p><p id="p0091" num="0091">Implementation for the multiplication based on a main-delta architecture is sketched in the algorithm of <figref idrefs="f0013">Figure 10</figref>.</p><p id="p0092" num="0092">The first part of the code (line 4-13) is a sparse matrix vector multiplication using the CSR index. For each nonzero vector element <i>x<sub>i</sub></i>, a index lookup for the corresponding matrix row i provides the start and end position of the containers in the main structure. Moreover, the II-VC bitvector is checked for each <i>x<sub>i</sub></i>, in order to skip the meanwhile deleted matrix rows. The same check has to be performed in the inner loop for each element using the IV-VC bitvector before the target vector <i>y</i> is written.</p><p id="p0093" num="0093">The second part (line 14-17) of the algorithm of <figref idrefs="f0013">Figure 10</figref> iterates over the valid elements of the incremental delta structure and adds the product results to the respective element holder in the target vector. It is noteworthy that by using this implementation, neither the first nor the second part of the algorithm of <figref idrefs="f0013">Figure 10</figref> requires a search scan in contrast to naive column store approaches.</p><heading id="h0005"><u>Example 1: Nuclear Energy State Analysis</u></heading><p id="p0094" num="0094">Here, a workflow from theoretical nuclear physics is used as a benchmark in the evaluation. In this analysis, the energy states of an atomic nucleus are determined by an eigenvalue calculation of a large, sparse Hamiltonian matrix which stems out of a<!-- EPO <DP n="20"> --> preprocessed nuclear physics theory simulation. The eigenvalue calculation is based on the Lanczos method sketched in the algorithm of <figref idrefs="f0014">Figure 11</figref>.</p><p id="p0095" num="0095">The getEnergyStates procedure resembles an importance truncation method. The dots denote pre- and postprocessing steps of the analysis (details of which are omitted here to outline the interface calls to the database system). A part of the analysis is a quantum state selection sketched via the selectDel call, which returns the coordinates of the matrix row- and columns that are selected for truncation. Since the Hamiltonian matrix is symmetric, the operation comprises the deletion of row-columns pairs which is executed by calling the delete command of the matrix interface (line 5). After the deletion, the lanczos function is called again. These two steps are repeated until a goodness criteria is achieved. Finally, the resulting eigenvalues λ were returned, which refer to the nuclear energy states.</p><p id="p0096" num="0096">The lanczos function itself is an iterative method, which effectively comprises a matrix-vector multiplication (line 11) and an update part (line 12). It processes the resulting vectors and forms an orthonormal basis of the eigenspace. Here, the bottleneck of the Lanczos function is the matrix-vector multiplication in line 11, which in this case is a call to the algorithm shown in <figref idrefs="f0013">Figure 10</figref>.</p><heading id="h0006"><u>Example 2: Breadth-First Search</u></heading><p id="p0097" num="0097">Queries on relational data from a non-numeric environment (especially with a graph-like topology), can be evaluated by exploiting a sparse matrix architecture according to an embodiment. As an example an <i>inclusive</i> breadth-first search is described. It is inclusive, because it returns all vertices that are discovered on paths with a length up to a certain traversal depth. However, this does not pose a restriction, since the algorithm can be rewritten in such a way that exclusively paths of a certain length are returned.</p><p id="p0098" num="0098">The breadth-first search is inherently similar to a matrix vector multiplication (the algorithm of <figref idrefs="f0013">Figure 10</figref>), which is explained by the dualism between a graph and its adjacency matrix.</p><p id="p0099" num="0099"><figref idrefs="f0003">Figure 3</figref> shows an example table that represents friend connections of a social network graph. It sketches two attributes <i>Name</i> and <i>Friend-of</i> which denote the start and the target vertices of the graph, and thus the sparse adjacency matrix. Furthermore it contains an additional attribute <i>Since,</i> but we want to emphasize that the table may contain an arbitrary number of additional property attributes since they have no effect on the leading topological attributes. A common query on such a social networks table would for instance be: <i>'who are<!-- EPO <DP n="21"> --> the friends of the friends of person X?',</i> which is in fact a breadth-first search with depth=2 and start node <i>X.</i></p><p id="p0100" num="0100">The algorithm of <figref idrefs="f0014">Figure 12</figref> shows the breadth-first algorithm that internally calls the algorithm of <figref idrefs="f0013">Figure 10</figref>. It effectively wraps an iterative matrix-vector multiplication by converting the start vertex set into a vector <i>x</i> and the target vertices vector <i>y</i> back into a result set. Internally, algorithm 1 multiplies the <i>x<sub>i</sub></i> values with the sparse matrix values (<i>A</i>)<i><sub>ij</sub></i>, which usually refer to the edge weights. However, the graph must not necessarily have weighted edges. The additional floating point operation is nevertheless rather cheap, so that for unweighted graph edges, the value container <i>Main. Val</i> in line 13, algorithm 1, might just be filled with dummy values. A typical example for an algorithm working on weighted graphs is page rank. A modified version of the algorithm of <figref idrefs="f0013">Figure 10</figref> is used in the evaluation. The modified version uses sparse vectors for <i>x</i> and <i>y,</i> i.e., a tuple list of <i>&lt;row, val&gt;</i> pairs instead of a dense array. This is in particular a reasonable choice for very sparse matrices, since the number of non-zero entries of the product vector <i>y</i> depends on the matrix population density <i>ρ = N<sub>nz</sub></i>/(<i>n</i> × <i>n</i>) and the number of non-zero elements of <i>x</i>.</p><p id="p0101" num="0101">Evaluation is achieved by first comparing the static query execution performance of the main-delta architecture against the different various possible matrix representations previously mentioned. Thereafter, the performance on dynamic workloads using the Example 1 is improves against naive approaches.</p><p id="p0102" num="0102">The system for a prototype implementation contains an Intel Xeon X5650 CPU with 48 GB RAM. As there are currently no standardized benchmarks for large scale linear algebra operations in a database context, it is difficult to provide a comprehensive comparison against other systems. Therefore, the real world example workflows described above were taken and compared against the presented architecture to evaluate performance against alternative variants that could be implemented in a database system. In the context of this evaluation, single-threaded versions of the algorithms were implemented. However, as each of the structures is horizontally partitionable, it is expected that a parallelization does not change the qualitative results for the applied algorithms.
<tables id="tabl0001" num="0001"><table frame="all"><title>Table 1 lists the matrix data sets used in the evaluation.</title><tgroup cols="5"><colspec colnum="1" colname="col1" colwidth="16mm"/><colspec colnum="2" colname="col2" colwidth="27mm"/><colspec colnum="3" colname="col3" colwidth="16mm"/><colspec colnum="4" colname="col4" colwidth="19mm"/><colspec colnum="5" colname="col5" colwidth="13mm"/><thead><row><entry valign="top">Name</entry><entry valign="top">Matrix Type</entry><entry valign="top">Dim.</entry><entry align="center" valign="top"><i>N<sub>nz</sub></i></entry><entry valign="top"><i>ρ</i>[%]</entry></row></thead><tbody><row><entry>Mat1</entry><entry>NCSM</entry><entry>800</entry><entry>309 K</entry><entry>47.2</entry></row><!-- EPO <DP n="22"> --><row><entry>Mat2</entry><entry>NCSM</entry><entry>3440</entry><entry>2.930 M</entry><entry>24.7</entry></row><row><entry>Mat3</entry><entry>NCSM</entry><entry>17040</entry><entry>42.962 M</entry><entry>14.8</entry></row><row><entry>Gra1</entry><entry>Slashdot Netw.</entry><entry>77360</entry><entry>905 K</entry><entry>0.01</entry></row><row><entry>Gra2</entry><entry>Roadnet CA</entry><entry>1,971 K</entry><entry>5.533 M</entry><entry>10<sup>-6</sup></entry></row></tbody></tgroup></table></tables></p><p id="p0103" num="0103">In particular, Table 1 shows Sparse matrices and graphs of different dimensions and population densities. The <i>ρ = N<sub>nz</sub></i>/(<i>n</i> × <i>n</i>) value denotes the population density (rounded) of each matrix. All matrices are square (<i>n</i> × <i>n).</i></p><p id="p0104" num="0104">The matrix data sets of Table 1 include three Hamiltonian matrices from a nuclear science simulation of different scale (Mat1, Mat2 &amp; Mat3), a social (Gra1) and a street network graph (Gra2). The Hamiltonian matrices stem from a no core shell model (NCSM) simulation and were provided by the theoretical nuclear physics research group of the Technical University of Darmstadt. The graphs are taken from the SNAP graph library (http://snap.stanford.edu/data/index.html).</p><p id="p0105" num="0105">The static algorithm execution is now described. <figref idrefs="f0006 f0008">Figures 6A-F</figref> show the relative performance comparison of the algorithm of <figref idrefs="f0013">Figure 10</figref> using a columnar main-delta sparse matrix architecture against the following representations.</p><p id="p0106" num="0106">For a pure CSR representation, the immutable CSR representation is taken as a baseline for the algorithmic performance for the static experiments. For a triple representation, the pure triple representation serves as naive alternative approach for database-integrated algebra on mutable sparse matrices. For a dense representation, this is included in the following cases only for illustrational purposes only, since it is not scaling and for most sparse matrices its memory consumption is order of magnitudes higher, as for example 10<sup>5</sup><i>x</i> for Gra2.</p><p id="p0107" num="0107">In this experiment, values of random matrix elements were subsequently set. The matrix coordinates were chosen randomly in order to get an unbiased perception of the set performance. The varying matrix population density <i>ρ</i> is denoted along the x-axis of the plots, which reaches up to a complete occupation (Mat1) with nonzero elements (p = 100%). The saw-tooth line belongs to the main-delta representation. Its shape is reasoned by the dynamically growing number of non-zero elements. All elements that are inserted into the main-delta architecture are at first accommodated by the delta triple representation. Thus, the delta size continuously increases until a certain occupation threshold <i>Δ<sub>T</sub></i> is reached, which<!-- EPO <DP n="23"> --> was set to 15%. Then, the delta part is merged into the main structure and the delta occupation shifts back to zero. The main-delta execution time is then effectively a superposition of the triple and CSR representation, i.e. <i>T</i><sub><i>m</i>/</sub><i><sub>d</sub> = T<sub>CSR</sub></i> ((1-Δ)<i>ρ</i>) + <i>T<sub>tripie</sub></i> (Δ<i>ρ</i>)<i>.</i> The sort overhead for the pure CSR representation is not included in the static measurement, but it is taken into consideration in the second part of the evaluation.</p><p id="p0108" num="0108">The plots of <figref idrefs="f0006 f0007">Figs. 6A-D</figref> differ in the number of nonzero elements of the vector <i>x</i> that takes part in the multiplication. This variable, which we call <maths id="math0007" num=""><math display="inline"><mrow><msup><mi>ρ</mi><mi>x</mi></msup><mo>=</mo><msubsup><mi>N</mi><mi mathvariant="italic">nz</mi><mi>x</mi></msubsup><mo>/</mo><mi>m</mi><mo>,</mo></mrow></math><img id="ib0007" file="imgb0007.tif" wi="24" he="7" img-content="math" img-format="tif" inline="yes"/></maths> has a significant influence on the performance of the algorithm of <figref idrefs="f0013">Figure 10</figref> and becomes even more significant for the algorithm of <figref idrefs="f0014">Figure 12</figref> on the graph Gra1 data set. With increasing <i>ρ<sup>x</sup></i> the runtime performance of the triple representation approaches to that of CSR, which also explains why the slope of saw-tooth decreases with increasing <i>ρ<sup>x</sup>.</i> If every element <i>x<sub>i</sub></i> is nonzero, the advantage of having the CSR index disappears, since each matrix row has to be visited either way. Hence, the remaining benefit of the CSR representation is solely its row-major ordering, which leads to a better cache locality. It is worthwhile mentioning, that even for completely dense matrices, the dense representation does not result in a better performance than using a CSR representation. This could be explained with the sequential single-pass access pattern of the algorithm of <figref idrefs="f0013">Figure 10</figref>, which allows prefetching of both the column and the value container. Finally, the <i>O</i>(<i>N<sub>nz</sub></i>) behavior of the algorithm of <figref idrefs="f0013">Figure 10</figref> results in a 1/<i>ρ</i>-convergence of the dense performance relative to CSR.</p><p id="p0109" num="0109">A similar measurement was carried out using the inclusive breadth-first search (algorithm of <figref idrefs="f0014">Figure 12</figref>) on both graphs (Gra1 and Gra2). Therefore, the graph matrices were left unmanipulated and solely varied the search depth parameter of the algorithm of <figref idrefs="f0014">Figure 12</figref>, which is denoted along the x-axis of the plots. It is noted that the main-delta architecture is (up to a negligibly deviation) equal to CSR in this measurement, since we consider an isolated query execution on static data under the condition that all data has been merged and is residing in the main structure.</p><p id="p0110" num="0110"><figref idrefs="f0009">Figures 7A-B</figref> present the execution runtimes of CSR and triple representation, each with the dense and the sparse version of the intermediate result vectors <i>x, y.</i> The noticeable influence of the <i>x</i> vector population density <i>ρ<sup>x</sup>,</i> which refers to the number of discovered vertices <i>Q</i> in the algorithm of <figref idrefs="f0014">Figure 12</figref>, on the overall algorithmic performance was already observed in the previous measurements in <figref idrefs="f0006 f0008">Figures 6A-F</figref>. This dependency is even more significant for the inclusive breadth-first search, since the start <i>x</i> vector only contains a single<!-- EPO <DP n="24"> --> non-zero element. In this case, the dense array-based <i>x</i> implementation (DI) iterates over every zero entry, which is why the of <figref idrefs="f0014">Figure 12</figref> performs obviously worse for small depths than using the list-based sparse <i>x</i> implementation (SpI). However, there is a turning point, where the vector density <i>x</i> reaches a certain density threshold <i>ρ</i><sup>x</sup><sub>T</sub>, the exact value of which depends on the details of the respective implementation. In the experiment, the turning point is reached between depths two and three for the social graph Gra1. In the analogous measurement on Gra2, the turning point depth is at a considerably larger depth, which exceeds the x-range of the plot.</p><p id="p0111" num="0111">Finding the right spot to internally switch from a sparse to a dense <i>x</i> provides clearly a tweak option that could be part of an optimizer. Nevertheless, it is observed that independent from the intermediate vector representation, the inclusive breadth-first search using the CSR representation outperforms the naive triple approach by up to four orders of magnitude (<figref idrefs="f0006 f0008">Figures 6A-E</figref>, SpI). This can be reasoned with the index character of CSR, which is of particular importance for hypersparse problems, which are regularly found in graph contexts</p><p id="p0112" num="0112">Dynamic workload is now discussed. The throughput of dynamic workloads was measured on large, sparse matrix data and the main-delta architecture was compared against four different alternative approaches. These include the triple, the dense representation, and the following.</p><p id="p0113" num="0113">A CSRMem approach is taken as a baseline for the following comparisons. A cached CSR version of the sparse matrix is kept in memory and is only rebuilt when an read query is requested, after a manipulation of the matrix has been executed.</p><p id="p0114" num="0114">A copy-sort CSR approach is compared against a naive approach, which includes copying and ordering of the data before each algorithm execution request. This is commonly done in science and analytic work flows, in order to transfer the data and bring it in shape for a third party system, where the actual calculations are executed.</p><heading id="h0007"><u>Example 3</u></heading><p id="p0115" num="0115">In the first experiment, consecutive single element inserts (write queries) are interleaved with periodic executions of the algorithm of <figref idrefs="f0013">Figure 10</figref> (read queries). Moreover, the ratio of the number of read queries <i>N<sub>read</sub></i> to the number of interleaved writes <i>N<sub>write</sub></i> was varied according to following formula: <i>N<sub>read</sub></i>+<i>N<sub>write</sub></i> = (1+α)<i>N<sub>read</sub></i>, where α is the insert-to-query ratio N<sub>write</sub>/N<sub>read</sub> which takes values from 0.02 to 1.<!-- EPO <DP n="25"> --></p><p id="p0116" num="0116"><figref idrefs="f0010">Figures 8A-B</figref> present the resulting relative query throughput of a mixed query workflow performed on matrices Mat1 and Mat3. To put it in other words, it shows the speedup factor of the overall execution time for <i>N<sub>read</sub></i> + <i>N<sub>write</sub></i> = 50 queries using a main-delta architecture and other approaches compared relative to CSRMem. For α→1, the main-delta architecture outperforms the naive CSRMem and copy-sort CSR approaches by orders of magnitude, whereas the difference to the triple and dense array representation is similar as in the static comparison, since these structures are both mutable and not significantly affected by interleaved inserts.</p><heading id="h0008"><u>Example 4</u></heading><p id="p0117" num="0117">A second experiment chose a scenario close to the work flow from theoretical nuclear physics that is sketched in the algorithm of <figref idrefs="f0014">Figure 11</figref>. Although the original scenario comprises row and column deletions, it was decided to split the experiment in a row- and an column-exclusive deletion variant, in order to measure the impact of linearization on the respective deletions.</p><p id="p0118" num="0118"><figref idrefs="f0011 f0012">Figures 9A-D</figref> show the average duration of a <i>k</i>-rows delete operation (<i>k =</i> 0.01 <i>m</i>), which is followed by a read query. It is observable that the deletion costs of the main-delta architecture are negligible, and the algorithm execution performance is nearly as good as the pure CSR representation. The low costs of the delete row operand on the dense and CSRMem representations can be explained by its efficient implementation, which essentially consists of copying of a contiguous memory section.</p><p id="p0119" num="0119">The analogous measurements for column delete operations shows that the main-delta approach has the best deletion performance on Mat2. When the matrix is larger, the impact of cache misses by jumping over the row-major ordered dense array increases significantly.</p><p id="p0120" num="0120">In summary, embodiments present an approach to integrate sparse matrices into a column-oriented in-memory database system with integrated support for updates and deletions of matrix elements. The evaluation has shown that the algorithmic performance of the architecture of a read-optimized main and a write-optimized, mutable delta representation outperforms naive approaches and deviates only negligibly from using immutable structures. Moreover, the integer dictionary encoding of the columnar database architecture allows an easy transition from pure numerical matrices to general structured data, for example graph data.<!-- EPO <DP n="26"> --></p><p id="p0121" num="0121">The architecture according to embodiments is extensible to integrate and take advantage of efficient numerical C++ libraries, since the use of the well-known CSR sparse matrix structures dispenses the need of time- and memory-consuming data conversations. It is shown that introducing mutability of sparse matrices without losing algorithmic performance yields to an overall benefit for users of dynamic sparse matrix workloads. Finally, database technologies are used to improve the overall performance for graph algorithms and science work flows, which bridges the gap between linear algebra and relational DBMS's.</p><p id="p0122" num="0122"><figref idrefs="f0018">Figure 14</figref> illustrates hardware of a special purpose computing machine configured to perform linear algebra according to an embodiment. In particular, computer system 1401 comprises a processor 1402 that is in electronic communication with a non-transitory computer-readable storage medium 1403. This computer-readable storage medium has stored thereon code 1404 corresponding to an in-memory database engine. Code 1405 corresponds to a matrix engine. Code may be configured to reference data stored in a database of a non-transitory computer-readable storage medium, for example as may be present locally or in a remote database server. Software servers together may form a cluster or logical network of computer systems programmed with software programs that communicate with each other and work together in order to process requests.</p><p id="p0123" num="0123">An example computer system 1510 is illustrated in <figref idrefs="f0019">Figure 15</figref>. Computer system 1510 includes a bus 1505 or other communication mechanism for communicating information, and a processor 1501 coupled with bus 1505 for processing information. Computer system 1510 also includes a memory 1502 coupled to bus 705 for storing information and instructions to be executed by processor 1501, including information and instructions for performing the techniques described above, for example. This memory may also be used for storing variables or other intermediate information during execution of instructions to be executed by processor 1501. Possible implementations of this memory may be, but are not limited to, random access memory (RAM), read only memory (ROM), or both. A storage device 1503 is also provided for storing information and instructions. Common forms of storage devices include, for example, a hard drive, a magnetic disk, an optical disk, a CD-ROM, a DVD, a flash memory, a USB memory card, or any other medium from which a computer can read. Storage device 1503 may include source code, binary code, or software files for performing the techniques above, for example. Storage device and memory are both examples of computer readable mediums.<!-- EPO <DP n="27"> --></p><p id="p0124" num="0124">Computer system 1510 may be coupled via bus 1505 to a display 1512, such as a cathode ray tube (CRT) or liquid crystal display (LCD), for displaying information to a computer user. An input device 1511 such as a keyboard and/or mouse is coupled to bus 1505 for communicating information and command selections from the user to processor 1501. The combination of these components allows the user to communicate with the system. In some systems, bus 1505 may be divided into multiple specialized buses.</p><p id="p0125" num="0125">Computer system 1510 also includes a network interface 1504 coupled with bus 1505. Network interface 1504 may provide two-way data communication between computer system 1510 and the local network 1520. The network interface 1504 may be a digital subscriber line (DSL) or a modem to provide data communication connection over a telephone line, for example. Another example of the network interface is a local area network (LAN) card to provide a data communication connection to a compatible LAN. Wireless links are another example. In any such implementation, network interface 1504 sends and receives electrical, electromagnetic, or optical signals that carry digital data streams representing various types of information.</p><p id="p0126" num="0126">Computer system 1510 can send and receive information, including messages or other interface actions, through the network interface 1504 across a local network 1520, an Intranet, or the Internet 1530. For a local network, computer system 1510 may communicate with a plurality of other computer machines, such as server 1515. Accordingly, computer system 1510 and server computer systems represented by server 1515 may form a cloud computing network, which may be programmed with processes described herein. In the Internet example, software components or services may reside on multiple different computer systems 1510 or servers 1531-1535 across the network. The processes described above may be implemented on one or more servers, for example. A server 1531 may transmit actions or messages from one component, through Internet 1530, local network 1520, and network interface 1504 to a component on computer system 1510. The software components and processes described above may be implemented on any computer system and send and/or receive information across a network, for example.</p><p id="p0127" num="0127">The above description illustrates various embodiments of the present invention along with examples of how certain aspects may be implemented. The above examples and embodiments should not be deemed to be the only embodiments, and are presented to illustrate the flexibility and advantages of the present invention as defined by the following<!-- EPO <DP n="28"> --> claims. Based on the above disclosure and the following claims, other arrangements, embodiments, and implementations may be employed.</p></description><claims mxw-id="PCLM90459480" lang="EN" load-source="patent-office"><!-- EPO <DP n="29"> --><claim id="c-en-0001" num="0001"><claim-text>A computer-implemented method comprising:
<claim-text>causing an engine to store an updatable column representation of data including a row column in a main structure and in a delta structure of an in-memory database;</claim-text>
<claim-text>causing the engine to merge the delta structure into the main structure when a delta exceeds a threshold;</claim-text>
<claim-text>causing the engine to sort columns of the updatable column representation according to values of the row column;</claim-text>
<claim-text>causing the engine to derive an index according to the sorted columns;</claim-text>
<claim-text>causing the engine to reference the index to perform an algebraic operation; and</claim-text>
<claim-text>causing the engine to store a result of the algebraic operation.</claim-text></claim-text></claim><claim id="c-en-0002" num="0002"><claim-text>A method as in claim 1 wherein the column representation comprises a Compressed Sparse Row (CSR) representation and a value comprises a row pointer.</claim-text></claim><claim id="c-en-0003" num="0003"><claim-text>A method as in claim 1 or 2, wherein the data comprises a matrix; and/or<br/>
wherein the column representation utilizes dictionary encoding.</claim-text></claim><claim id="c-en-0004" num="0004"><claim-text>A method according to any one of claims 1 to 3, further comprising updating the delta structure utilizing a validity control vector; and/or<br/>
wherein the algebraic operation comprises matrix-vector multiplication.</claim-text></claim><claim id="c-en-0005" num="0005"><claim-text>A method according to any one of claims 1 to 4, further comprising updating the delta structure by appending a triple.<!-- EPO <DP n="30"> --></claim-text></claim><claim id="c-en-0006" num="0006"><claim-text>A non-transitory computer readable storage medium embodying a computer program for performing a method, said method comprising:
<claim-text>causing an engine to store an updatable column representation of data including a row column in a main structure and in a delta structure of an in-memory database;</claim-text>
<claim-text>causing the engine to merge the delta structure into the main structure when a delta exceeds a threshold;</claim-text>
<claim-text>causing the engine to sort columns of the updatable column representation according to values of the row column;</claim-text>
<claim-text>causing the engine to derive an index according to the sorted columns;<br/>
causing the engine to reference the index to perform an algebraic operation; and causing the engine to store a result of the algebraic operation.</claim-text></claim-text></claim><claim id="c-en-0007" num="0007"><claim-text>A non-transitory computer readable storage medium as in claim 6 wherein the column representation comprises a Compressed Sparse Row (CSR) representation and a value comprises a row pointer.</claim-text></claim><claim id="c-en-0008" num="0008"><claim-text>A non-transitory computer readable storage medium as in claim 6 or 7, wherein the data comprises a matrix; and/or<br/>
wherein the column representation utilizes dictionary encoding.</claim-text></claim><claim id="c-en-0009" num="0009"><claim-text>A non-transitory computer readable storage medium according to any one of claims 6 to 8, further comprising updating the delta structure utilizing a validity control vector; and/or<br/>
wherein the algebraic operation comprises matrix-vector multiplication.</claim-text></claim><claim id="c-en-0010" num="0010"><claim-text>A non-transitory computer readable storage medium according to any one of claims 6 to 9, further comprising updating the delta structure by appending a triple.</claim-text></claim><claim id="c-en-0011" num="0011"><claim-text>A computer system comprising:
<claim-text>one or more processors;<br/>
a software program, executable on said computer system, the software<!-- EPO <DP n="31"> --> program configured to:
<claim-text>cause an engine to store an updatable column representation of data including a row column in a main structure and in a delta structure of an in-memory database;</claim-text>
<claim-text>cause the engine to merge the delta structure into the main structure when a delta exceeds a threshold;</claim-text>
<claim-text>cause the engine to sort columns of the updatable column representation according to values of the row column;</claim-text>
<claim-text>cause the engine to derive an index according to the sorted columns;</claim-text></claim-text>
<claim-text>cause the engine to reference the index to perform an algebraic operation; and</claim-text>
<claim-text>cause the engine to store a result of the algebraic operation.</claim-text></claim-text></claim><claim id="c-en-0012" num="0012"><claim-text>A computer system as in claim 11 wherein the column representation comprises a Compressed Sparse Row (CSR) representation and a value comprises a row pointer.</claim-text></claim><claim id="c-en-0013" num="0013"><claim-text>A computer system as in claim 11 or 12, wherein the data comprises a matrix; and/or<br/>
wherein the column representation utilizes dictionary encoding.</claim-text></claim><claim id="c-en-0014" num="0014"><claim-text>A computer system according to any one of claims 11 to 13, wherein the algebraic operation comprises matrix-vector multiplication; and/or<br/>
wherein the engine is further caused to update the delta structure utilizing a validity control vector.</claim-text></claim><claim id="c-en-0015" num="0015"><claim-text>A computer system according to any one of claims 11 to 14, wherein the engine is further caused to update the delta structure by appending a triple.</claim-text></claim></claims><drawings mxw-id="PDW20422206" load-source="patent-office"><!-- EPO <DP n="32"> --><figure id="f0001" num="1a,1b,1c"><img id="if0001" file="imgf0001.tif" wi="162" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="33"> --><figure id="f0002" num="2"><img id="if0002" file="imgf0002.tif" wi="120" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="34"> --><figure id="f0003" num="3a,3b"><img id="if0003" file="imgf0003.tif" wi="108" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="35"> --><figure id="f0004" num="4"><img id="if0004" file="imgf0004.tif" wi="129" he="227" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="36"> --><figure id="f0005" num="5"><img id="if0005" file="imgf0005.tif" wi="165" he="228" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="37"> --><figure id="f0006" num="6A,6B"><img id="if0006" file="imgf0006.tif" wi="152" he="231" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="38"> --><figure id="f0007" num="6C,6D"><img id="if0007" file="imgf0007.tif" wi="152" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="39"> --><figure id="f0008" num="6E,6F"><img id="if0008" file="imgf0008.tif" wi="152" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="40"> --><figure id="f0009" num="7A,7B"><img id="if0009" file="imgf0009.tif" wi="152" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="41"> --><figure id="f0010" num="8A,8B"><img id="if0010" file="imgf0010.tif" wi="152" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="42"> --><figure id="f0011" num="9A,9B"><img id="if0011" file="imgf0011.tif" wi="152" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="43"> --><figure id="f0012" num="9C,9D"><img id="if0012" file="imgf0012.tif" wi="152" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="44"> --><figure id="f0013" num="10"><img id="if0013" file="imgf0013.tif" wi="165" he="177" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="45"> --><figure id="f0014" num="11,12"><img id="if0014" file="imgf0014.tif" wi="165" he="212" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="46"> --><figure id="f0015" num="13"><img id="if0015" file="imgf0015.tif" wi="151" he="214" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="47"> --><figure id="f0016" num="13A"><img id="if0016" file="imgf0016.tif" wi="163" he="231" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="48"> --><figure id="f0017" num="13B"><img id="if0017" file="imgf0017.tif" wi="165" he="200" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="49"> --><figure id="f0018" num="14"><img id="if0018" file="imgf0018.tif" wi="161" he="179" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="50"> --><figure id="f0019" num="15"><img id="if0019" file="imgf0019.tif" wi="165" he="216" img-content="drawing" img-format="tif"/></figure></drawings><search-report-data><doc-page id="srep0001" file="srep0001.tif" wi="160" he="233" type="tif"/><doc-page id="srep0002" file="srep0002.tif" wi="160" he="233" type="tif"/><doc-page id="srep0003" file="srep0003.tif" wi="160" he="233" type="tif"/></search-report-data><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
