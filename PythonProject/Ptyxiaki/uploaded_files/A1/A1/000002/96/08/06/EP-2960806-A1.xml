<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2960806-A1" country="EP" doc-number="2960806" kind="A1" date="20151230" family-id="53502489" file-reference-id="316602" date-produced="20180824" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="160451471" ucid="EP-2960806-A1"><document-id><country>EP</country><doc-number>2960806</doc-number><kind>A1</kind><date>20151230</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-15174139-A" is-representative="YES"><document-id mxw-id="PAPP193865910" load-source="patent-office" format="original"><country>EP</country><doc-number>15174139.4</doc-number><date>20150626</date><lang>EN</lang></document-id><document-id mxw-id="PAPP193865911" load-source="docdb" format="epo"><country>EP</country><doc-number>15174139</doc-number><kind>A</kind><date>20150626</date><lang>EN</lang></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC162029071" ucid="IN-2074MU2014-A" load-source="docdb"><document-id format="epo"><country>IN</country><doc-number>2074MU2014</doc-number><kind>A</kind><date>20140626</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL-1988520131" load-source="docdb">G07C   5/00        20060101ALI20151106BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-1988522886" load-source="docdb">G06F  17/18        20060101AFI20151106BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-1613213050" load-source="docdb" scheme="CPC">G07C   5/0808      20130101 LI20180724BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1613213051" load-source="docdb" scheme="CPC">G06F  17/16        20130101 LI20180722BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1984704021" load-source="docdb" scheme="CPC">G06F  17/18        20130101 FI20160106BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT165545879" lang="DE" load-source="patent-office">ERKENNUNG EINES EREIGNISSES AUS ZEITREIHENDATENSEQUENZEN</invention-title><invention-title mxw-id="PT165545880" lang="EN" load-source="patent-office">DETECTING AN EVENT FROM TIME-SERIES DATA SEQUENCES</invention-title><invention-title mxw-id="PT165545881" lang="FR" load-source="patent-office">DÉTECTION D'UN ÉVÉNEMENT À PARTIR DE SÉQUENCES DE DONNÉES EN SÉRIE TEMPORELLE</invention-title><citations><patent-citations><patcit mxw-id="PCIT335740070" load-source="docdb" ucid="US-20140111647-A1"><document-id format="epo"><country>US</country><doc-number>20140111647</doc-number><kind>A1</kind><date>20140424</date></document-id><sources><source name="SEA" category="Y" created-by-npl="N"/></sources></patcit></patent-citations><non-patent-citations><nplcit><text>"EPIA 2009", 12 October 2009, PROGRESS IN ARTIFICIAL INTELLIGENCE, SPRINGER BERLIN HEIDELBERG, BERLIN, HEIDELBERG, ISBN: 978-3-642-04685-8, article RUI PEREIRA ET AL: "Learning Visual Object Categories with Global Descriptors and Local Features", pages: 225 - 236, XP019131992</text><sources><source mxw-id="PNPL57906894" load-source="docdb" name="SEA" category="A"/></sources></nplcit><nplcit><text>EHTESHAM HASSAN ET AL: "Multi-sensor event detection using shape histograms", DATA SCIENCES, 16 August 2014 (2014-08-16), 2 Penn Plaza, Suite 701 New York NY 10121-0701 USA, pages 1 - 14, XP055221659, ISBN: 978-1-4503-3436-5, Retrieved from the Internet &lt;URL:http://arxiv.org/pdf/1408.3733.pdf&gt; [retrieved on 20151016]</text><sources><source mxw-id="PNPL70737241" load-source="docdb" name="SEA" category="XP"/></sources></nplcit><nplcit><text>EHTESHAM HASSAN ET AL: "Multi-sensor event detection using shape histograms", DATA SCIENCES, ACM, 2 PENN PLAZA, SUITE 701 NEW YORK NY 10121-0701 USA, 18 March 2015 (2015-03-18), pages 20 - 29, XP058068963, ISBN: 978-1-4503-3436-5, DOI: 10.1145/2732587.2732591</text><sources><source mxw-id="PNPL57906896" load-source="docdb" name="SEA" category="XP"/></sources></nplcit><nplcit><text>KUMAR ROY: "'Leaming Words from Sights and Sounds: A Computational Model", 1 September 1999 (1999-09-01), XP055140284, Retrieved from the Internet &lt;URL:http://web.media.mit.edu/~dkroy/papers/pdf/phd_thesis_1999.pdf&gt; [retrieved on 20140915]</text><sources><source mxw-id="PNPL57906897" load-source="docdb" name="SEA" category="A"/></sources></nplcit><nplcit><text>L. S. RIBEIRO: "Object recognition for semantic robot vision", MASTER'S THESIS, 1 January 2008 (2008-01-01), Universidade de Aveiro, pages 1 - 64, XP055222899, Retrieved from the Internet &lt;URL:http://ria.ua.pt/bitstream/10773/2057/1/2009001002.pdf&gt; [retrieved on 20151022]</text><sources><source mxw-id="PNPL57906898" load-source="docdb" name="SEA" category="Y"/></sources></nplcit><nplcit><text>None</text><sources><source mxw-id="PNPL62638792" load-source="docdb" name="APP"/></sources></nplcit></non-patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR1103337456" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>TATA CONSULTANCY SERVICES LTD</last-name><address><country>IN</country></address></addressbook></applicant><applicant mxw-id="PPAR1103343434" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>TATA CONSULTANCY SERVICES LIMITED</last-name></addressbook></applicant><applicant mxw-id="PPAR1101643949" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Tata Consultancy Services Limited</last-name><iid>101138018</iid><address><street>Nirmal Building 9th Floor Nariman Point Mumbai 400 021</street><city>Maharashtra</city><country>IN</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR1103343308" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>HASSAN Ehtesham</last-name><address><country>IN</country></address></addressbook></inventor><inventor mxw-id="PPAR1103331577" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>Hassan,, Ehtesham</last-name></addressbook></inventor><inventor mxw-id="PPAR1101644454" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Hassan,, Ehtesham</last-name><address><street>Tata Consultancy Services Limited 10th Floor, Block C Kings Canyon ASF Insignia Gurgaon Faridabad Road Gawal Pahari Gurgaon</street><city>122003 Haryana</city><country>IN</country></address></addressbook></inventor><inventor mxw-id="PPAR1103338254" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>AGARWAL PUNEET</last-name><address><country>IN</country></address></addressbook></inventor><inventor mxw-id="PPAR1103323602" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>AGARWAL, PUNEET</last-name></addressbook></inventor><inventor mxw-id="PPAR1101648389" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>AGARWAL, PUNEET</last-name><address><street>Tata Consultancy Services Limited 154, B Block A Sector 63, Phase III Noida Distt Gautam Buddha Nagar Noida</street><city>201301 Uttar Pradesh</city><country>IN</country></address></addressbook></inventor><inventor mxw-id="PPAR1103340359" load-source="docdb" sequence="3" format="epo"><addressbook><last-name>SHROFF GAUTAM</last-name><address><country>IN</country></address></addressbook></inventor><inventor mxw-id="PPAR1103341121" load-source="docdb" sequence="3" format="intermediate"><addressbook><last-name>SHROFF, GAUTAM</last-name></addressbook></inventor><inventor mxw-id="PPAR1101644874" load-source="patent-office" sequence="3" format="original"><addressbook><last-name>SHROFF, GAUTAM</last-name><address><street>Tata Consultancy Services Limited 10th Floor, Block C Kings Canyon ASF Insignia Gurgaon Faridabad Road Gawal Pahari Gurgaon</street><city>122003 Haryana</city><country>IN</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR1101648492" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Potter Clarkson LLP</last-name><iid>101340609</iid><address><street>The Belgrave Centre Talbot Street</street><city>Nottingham NG1 5GG</city><country>GB</country></address></addressbook></agent></agents></parties><international-convention-data><designated-states><ep-contracting-states><country mxw-id="DS660687779" load-source="docdb">AL</country><country mxw-id="DS660685115" load-source="docdb">AT</country><country mxw-id="DS660687781" load-source="docdb">BE</country><country mxw-id="DS660606570" load-source="docdb">BG</country><country mxw-id="DS660783473" load-source="docdb">CH</country><country mxw-id="DS660685528" load-source="docdb">CY</country><country mxw-id="DS660685116" load-source="docdb">CZ</country><country mxw-id="DS660687782" load-source="docdb">DE</country><country mxw-id="DS660685529" load-source="docdb">DK</country><country mxw-id="DS660685530" load-source="docdb">EE</country><country mxw-id="DS660611011" load-source="docdb">ES</country><country mxw-id="DS660606571" load-source="docdb">FI</country><country mxw-id="DS660783474" load-source="docdb">FR</country><country mxw-id="DS660687787" load-source="docdb">GB</country><country mxw-id="DS660685539" load-source="docdb">GR</country><country mxw-id="DS660687788" load-source="docdb">HR</country><country mxw-id="DS660685117" load-source="docdb">HU</country><country mxw-id="DS660611012" load-source="docdb">IE</country><country mxw-id="DS660685540" load-source="docdb">IS</country><country mxw-id="DS660606572" load-source="docdb">IT</country><country mxw-id="DS660685541" load-source="docdb">LI</country><country mxw-id="DS660606573" load-source="docdb">LT</country><country mxw-id="DS660690408" load-source="docdb">LU</country><country mxw-id="DS660606574" load-source="docdb">LV</country><country mxw-id="DS660606575" load-source="docdb">MC</country><country mxw-id="DS660690409" load-source="docdb">MK</country><country mxw-id="DS660690410" load-source="docdb">MT</country><country mxw-id="DS660611013" load-source="docdb">NL</country><country mxw-id="DS660610531" load-source="docdb">NO</country><country mxw-id="DS660611014" load-source="docdb">PL</country><country mxw-id="DS660606576" load-source="docdb">PT</country><country mxw-id="DS660685118" load-source="docdb">RO</country><country mxw-id="DS660606577" load-source="docdb">RS</country><country mxw-id="DS660611023" load-source="docdb">SE</country><country mxw-id="DS660783475" load-source="docdb">SI</country><country mxw-id="DS660610532" load-source="docdb">SK</country><country mxw-id="DS660610533" load-source="docdb">SM</country><country mxw-id="DS660690431" load-source="docdb">TR</country></ep-contracting-states><ep-extended-states><ep-extended-state-data><country>BA</country></ep-extended-state-data><ep-extended-state-data><country>ME</country></ep-extended-state-data></ep-extended-states></designated-states></international-convention-data></bibliographic-data><abstract mxw-id="PA166479841" lang="EN" load-source="patent-office"><p id="pa01" num="0001">The present subject matter discloses a system and a method for detecting an event from time-series data sequences. The system receives time-series data sequences generated by sensors, wherein the time-series data sequences comprise sample points. The system pairs the sample points with one another for determining pairs of the sample points. The system computes Euclidean distances and angles between the sample points for determining distance matrix and angle matrix corresponding to the sample points. Further, the system determines global distribution of the plurality of pairs of sample points, wherein the global distribution of the plurality of pairs of sample points represent 2D shape histogram for the time-series data sequence. Further, the system concatenates the 2D shape histogram for each time-series data sequence to generate a concatenated shape histogram. Finally the system matches the concatenated shape histogram to pre-stored shape histograms for determining the event.
<img id="iaf01" file="imgaf001.tif" wi="78" he="94" img-content="drawing" img-format="tif"/></p></abstract><abstract mxw-id="PA166759653" lang="EN" source="EPO" load-source="docdb"><p>The present subject matter discloses a system and a method for detecting an event from time-series data sequences. The system receives time-series data sequences generated by sensors, wherein the time-series data sequences comprise sample points. The system pairs the sample points with one another for determining pairs of the sample points. The system computes Euclidean distances and angles between the sample points for determining distance matrix and angle matrix corresponding to the sample points. Further, the system determines global distribution of the plurality of pairs of sample points, wherein the global distribution of the plurality of pairs of sample points represent 2D shape histogram for the time-series data sequence. Further, the system concatenates the 2D shape histogram for each time-series data sequence to generate a concatenated shape histogram. Finally the system matches the concatenated shape histogram to pre-stored shape histograms for determining the event.</p></abstract><description mxw-id="PDES98404542" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><heading id="h0001">CROSS-REFERENCE TO RELATED APPLICATIONS AND PRIORITY</heading><p id="p0001" num="0001">The present application claims priority from Indian patent application <patcit id="pcit0001" dnum="IN2074MUM2014"><text>2074/MUM/2014 filed on 26th June 2014</text></patcit>.</p><heading id="h0002">TECHNICAL FIELD</heading><p id="p0002" num="0002">The present subject matter described herein, in general, relates to detecting an event from time-series data sequences.</p><heading id="h0003">BACKGROUND</heading><p id="p0003" num="0003">An event can be detected from time-series data sequences using several techniques known in the art. Generally the time-series data sequences extracted using a sensor comprise unique signal patterns corresponding to the event. For example, the event in case of a vehicle may be an abrupt braking of the vehicle, rapid rise/fall in acceleration/deceleration of the vehicle, change in direction of the vehicle and the like. The time series data sequences may be processed using techniques known in the art, for recognizing the unique signal patterns and further identifying the event based on the unique signal patterns.</p><p id="p0004" num="0004">Referring to <figref idrefs="f0001">figure 1a and figure 1b</figref>, the time-series data sequences captured using the sensor are illustrated, wherein x-axis represents time in seconds and y-axis represents values of speed. The <figref idrefs="f0001">figure 1a</figref> shows a time-series data sequence representing speed of the vehicle. A window 102 of the time-series data sequence highlights an event related to the vehicle. The event may be a hard-stop event related to the vehicle. During the hard-stop event while brakes are applied to the vehicle running at high speeds, the speed of the vehicle may reduce drastically. The unique signal pattern present in the time-series data sequence, as illustrated in the window 102, may be identified and thus the hard-stop event related to the vehicle may be determined. <figref idrefs="f0001">Figure 1b</figref> shows a time-series data sequence representing speed of the vehicle in another case. Further, windows 104 highlight the unique signal patterns indicating the hard-stop events related to the vehicle, where speed of the vehicle reduces drastically.<!-- EPO <DP n="2"> --></p><heading id="h0004">SUMMARY</heading><p id="p0005" num="0005">This summary is provided to introduce aspects related to systems and methods for detecting an event from time-series data sequences and the aspects are further described below in the detailed description. This summary is not intended to identify essential features of subject matter nor is it intended for use in determining or limiting the scope of the subject matter.</p><p id="p0006" num="0006">In one implementation, a system for detecting an event from time-series data sequences is disclosed. The system comprises a processor and a memory coupled to the processor for executing a plurality of modules stored in the memory. The plurality of modules may comprise a pairing module, a matrix computing module, and a histogram generating and event determining (HGED) module. The pairing module may receive the time-series data sequences of variable lengths generated by a plurality of sensors, wherein the time-series data sequences may comprise timestamp information. The pairing module may sample the time-series data sequences at a uniform sampling rate, wherein the time-series data sequences may be sampled for generating sample points. The pairing module may generate a plurality of pairs of sample points using the sample points such that each sample point is paired with one another. Further, the matrix computing module may compute a distance matrix (D) and an angle matrix (A) for one or more pairs of the sample points of the plurality of pairs of sample points. Further, the HGED module may generate a two-dimensional (2D) shape histogram for the time-series data sequences using the distance matrix (D) and the angle matrix (A). The 2D shape histogram may be of constant dimension and may represent a global distribution of the plurality of pairs of sample points. The global distribution of the plurality of pairs of sample points is computed using the distance matrix (D) and the angle matrix (A). The HGED module further may concatenate the 2D shape histograms for one or more time-series data sequences based on the timestamp information to generate a concatenated shape histogram. Further, the HGED module may match the concatenated shape histogram with a pre-stored set of shape histograms to detect an event. The pre-stored set of shape histograms may comprise shape histograms corresponding to a relevant event.</p><p id="p0007" num="0007">In another implementation, a method for detecting an event from time-series data sequences is disclosed. The method may comprise a step of receiving the time-series data sequences of variable lengths generated by a plurality of sensors, wherein the time-series data<!-- EPO <DP n="3"> --> sequences may comprise timestamp information. The method may comprise sampling the time-series data sequences at a uniform sampling rate for generating sample points. The method may further comprise generating a plurality of pairs of sample points using the sample points. The plurality of pairs of sample points are generated by pairing each sample point with one another. The method may further comprise computing a distance matrix (D) and an angle matrix (A) for one or more pairs of the sample points of the plurality of pairs of sample points. The method may further comprise generating two-dimensional (2D) shape histogram for the time-series data sequence using the distance matrix (D) and the angle matrix (A). The 2D shape histogram is having a constant dimension, and the 2D shape histogram represents global distribution of the plurality of pairs of sample points, and wherein the global distribution of the plurality of pairs of sample points is computed using the distance matrix (D) and the angle matrix (A). The method may further comprise concatenating 2D shape histograms, based on the timestamp information, for one or more time-series data sequence generated by the plurality of sensors, to generate a concatenated shape histogram. The method may further comprise matching the concatenated shape histogram with a pre-stored set of shape histograms to detect an event, wherein the pre-stored set of shape histograms comprise shape histograms corresponding to a relevant event. Further, the receiving, the generating, the computing, the concatenating and the matching are performed by a processor.</p><p id="p0008" num="0008">Yet in another implementation, a non-transitory computer readable medium embodying a program executable in a computing device for detecting an event from time-series data sequences is disclosed. The program comprises a program code for receiving the time-series data sequences of variable lengths generated by a plurality of sensors, wherein the time-series data sequences comprise timestamp information. The program comprises a program code for sampling the time-series data sequences at a uniform sampling rate, wherein the time-series data sequences are sampled for generating sample points. The program further comprises a program code for generating a plurality of pairs of sample points using the sample points such that each sample point is paired with one another. The program further comprises a program code for computing a distance matrix (D) and an angle matrix (A) for one or more pairs of the sample points of the plurality of pairs of sample points. The program further comprises a program code for generating a two-dimensional (2D) shape histogram for the time-series data sequence using the distance matrix (D) and the angle matrix (A). The 2D<!-- EPO <DP n="4"> --> shape histogramis having a constant dimension and represents global distribution of the plurality of pairs of sample points, and wherein the global distribution of the plurality of pairs of sample points is computed using the distance matrix (D) and the angle matrix (A). The program further comprises a program code for concatenating 2D shape histograms for the time-series data sequences based on the timestamp information to generate a concatenated shape histogram. The program further comprises a program code for matching the concatenated shape histogram with a pre-stored set of shape histograms to detect an event.</p><heading id="h0005">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p0009" num="0009">The detailed description is described with reference to the accompanying figures. In the figures, the left-most digit(s) of a reference number identifies the figure in which the reference number first appears. The same numbers are used throughout the drawings to refer like features and components.
<ul><li><figref idrefs="f0002">Figure 2</figref> illustrates a network implementation of a system for detecting an event from time-series data sequences, in accordance with an embodiment of the present subject matter.</li><li><figref idrefs="f0003">Figure 3</figref> illustrates the system of <figref idrefs="f0002">Figure 2</figref>, in accordance with an embodiment of the present subject matter.</li><li><figref idrefs="f0004">Figure 4a</figref> illustrates a time-series data sequence S1 captured using a sensor 1 (pressure sensor), in accordance with an embodiment of the present subject matter.</li><li><figref idrefs="f0004">Figure 4b</figref> illustrates a time-series data sequence S2 captured using a sensor 2 (speed sensor), in accordance with an embodiment of the present subject matter.</li><li><figref idrefs="f0004">Figure 4c</figref> illustrates a time-series data sequence S3 captured using a sensor 3 (gear sensor), in accordance with an embodiment of the present subject matter.</li><li><figref idrefs="f0005">Figure 5</figref> illustrates a time-series data sequence S4 represented in two-dimensional (2D) Euclidean space.</li><li><figref idrefs="f0006">Figure 6a</figref> illustrates a time-series data sequence S5 captured using a sensor.</li><li><figref idrefs="f0006">Figure 6b</figref> illustrates the 2D shape histogram corresponding to the time-series data sequence S5.</li><li><figref idrefs="f0007">Figure 7a</figref> illustrates a time-series data sequence S6 captured using a sensor.</li><li><figref idrefs="f0007">Figure 7b</figref> illustrates the 2D shape histogram corresponding to the time-series data sequence S6.<!-- EPO <DP n="5"> --></li><li><figref idrefs="f0008">Figure 8</figref> shows a flowchart illustrating a method for detecting an event from time-series data sequences, in accordance with an embodiment of the present subject matter.</li></ul></p><heading id="h0006">DETAILED DESCRIPTION</heading><p id="p0010" num="0010">Systems and methods for detecting an event from time-series data sequences are described. The event may be detected from the time-series data sequences upon processing the time-series data sequences. In order to generate the time-series data sequences related to the event, a plurality of sensors may be used. The time-series data sequences generated by the sensors may comprise different waveform characteristics corresponding to the event. Further, the time-series data sequences may be of variable lengths and may also comprise timestamp information.</p><p id="p0011" num="0011">The time-series data sequences may be sampled at a uniform sampling rate. Further, the time-series data sequences may be sampled for generating sample points. Further, the sample points may be paired with one another to generate a plurality of pairs of sample points.</p><p id="p0012" num="0012">The time-series data sequences may be represented in a two-dimensional (2D) Euclidean space. The 2D Euclidean space may be used for computing Euclidean distances between the sample points of the plurality of pairs of sample points. The Euclidean distances may be used further for determining a distance matrix. The 2D Euclidean space may further be used for computing angles between the sample points of the plurality of pairs of sample points. The angles between the sample points may be used for determining an angle matrix.</p><p id="p0013" num="0013">The distance matrix and the angle matrix may be used for determining a global distribution of the plurality of pairs of sample points. The global distribution of the plurality of pairs of sample points may represent a 2D shape histogram, wherein the 2D shape histogram may be of constant dimension. The 2D shape histogram for the time-series data sequences may be concatenated using a linear concatenation technique for generating a concatenated shape histogram. Further, the timestamp information may be used for concatenating the 2D shape histograms.</p><p id="p0014" num="0014">The concatenated shape histogram may further be matched with a pre-stored set of shape histograms, using a Support Vector Machine (SVM) classifier, for recognizing the event. The pre-stored set of shape histograms may comprise 2D shape histograms associated with an identified category of the event.<!-- EPO <DP n="6"> --></p><p id="p0015" num="0015">While aspects of described system and method for detecting an event from time-series data sequences may be implemented in any number of different computing systems, environments, and/or configurations, the embodiments are described in the context of the following exemplary system.</p><p id="p0016" num="0016">Referring to <figref idrefs="f0002">Figure 2</figref>, a network implementation 200 of a system 202 for detecting an event from time-series data sequences is illustrated, in accordance with an embodiment of the present subject matter. In one embodiment, the system 202 may facilitate the detection of an event from time-series data sequences. At first, the system 202 may employ sensors to capture the time-series data sequences. The time-series data sequences may be of variable lengths. The time-series data sequences may be sampled at a uniform sampling rate, wherein the time-series data sequences may be sampled for generating sample points. The system 202 may compute a global distribution of the plurality of pairs of sample points. The global distribution of the plurality of pairs of sample points may represent a 2D shape histogram for a time-series data sequence, wherein the 2D shape histogram may be of constant dimension. The system 202 may generate a concatenated shape histogram using the 2D shape histogram for each time-series data sequence. The system 202 may generate the concatenated shape histogram using the linear concatenation technique. Finally, the system 202 may detect the event by matching the concatenated shape histogram with the pre-stored set of shape histograms. The pre-stored set of shape histograms may comprise 2D shape histograms corresponding to relevant events.</p><p id="p0017" num="0017">Although the present subject matter is explained considering that the system 202 is implemented for detecting the event from the time-series data sequences, it may be understood that the system 202 may also be implemented in a variety of computing systems, such as a laptop computer, a desktop computer, a notebook, a workstation, a mainframe computer, a server, a network server, a tablet, a mobile phone, and the like. In one embodiment, the system 202 may be implemented in a cloud-based environment. It will be understood that the system 202 may be accessed by multiple users through one or more user devices 204-1, 204-2...204-N, collectively referred to as user device 204 hereinafter, or applications residing on the user device 204. Examples of the user device 204 may include, but are not limited to, a portable computer with a webcam, a personal digital assistant with a<!-- EPO <DP n="7"> --> camera, a handheld device with a camera, and a digital camera. The user device 204 is communicatively coupled to the system 202 through a network 206.</p><p id="p0018" num="0018">In one implementation, the network 206 may be a wireless network, a wired network or a combination thereof. The network 206 can be implemented as one of the different types of networks, such as intranet, local area network (LAN), wide area network (WAN), the internet, and the like. The network 206 may either be a dedicated network or a shared network. The shared network represents an association of the different types of networks that use a variety of protocols, for example, Hypertext Transfer Protocol (HTTP), Transmission Control Protocol/Internet Protocol (TCP/IP), Wireless Application Protocol (WAP), and the like, to communicate with one another. Further the network 206 may include a variety of network devices, including routers, bridges, servers, computing devices, storage devices, and the like.</p><p id="p0019" num="0019">Referring now to <figref idrefs="f0003">Figure 3</figref>, the system 202 is illustrated in accordance with an embodiment of the present subject matter. In one embodiment, the system 202 may include at least one processor 302, an input/output (I/O) interface 304, and a memory 306. The at least one processor 302 may be implemented as one or more microprocessors, microcomputers, microcontrollers, digital signal processors, central processing units, state machines, logic circuitries, and/or any devices that manipulate signals based on operational instructions. Further, the at least one processor 302 may comprise a multi-core architecture. Among other capabilities, the at least one processor 302 is configured to fetch and execute computer-readable instructions or modules stored in the memory 306.</p><p id="p0020" num="0020">The I/O interface 304 may include a variety of software and hardware interfaces, for example, a web interface, a graphical user interface, and the like. The I/O interface 304 may allow the system 202 to interact with a user directly or through the user devices 204. Further, the I/O interface 304 may enable the system 202 to communicate with other computing devices, such as web servers and external data servers (not shown). The I/O interface 304 can facilitate multiple communications within a wide variety of networks and protocol types, including wired networks, for example, LAN, cable, etc., and wireless networks, such as WLAN, cellular, or satellite. The I/O interface 304 may include one or more ports for connecting a number of devices to one another or to another server.<!-- EPO <DP n="8"> --></p><p id="p0021" num="0021">The memory 306 may include any computer-readable medium or computer program product known in the art including, for example, volatile memory, such as static random access memory (SRAM) and dynamic random access memory (DRAM), and/or non-volatile memory, such as read only memory (ROM), erasable programmable ROM, flash memories, hard disks, optical disks, a compact disks (CDs), digital versatile disc or digital video disc (DVDs) and magnetic tapes. The memory 306 may include modules 308 and data 318.</p><p id="p0022" num="0022">The modules 308 include routines, programs, objects, components, data structures, etc., which perform particular tasks or implement particular abstract data types. In one implementation, the modules 308 may include a pairing module 310, a matrix computing module 312, a histogram generating and event determining (HGED) module 314, and other modules 316. The other modules 316 may include programs or coded instructions that supplement applications and functions of the system 202.</p><p id="p0023" num="0023">The data 318, amongst other things, serves as a repository for storing data processed, received, and generated by one or more of the modules 308. The data 318 may also include a system database 320, and other data 322. The other data 322 may include data generated as a result of the execution of one or more modules in the other modules 316.</p><p id="p0024" num="0024">In one implementation, at first, the sensors may be positioned across an environment for detecting events related to the environment. For example, the sensors may be positioned across a vehicle for determining the events related to the vehicle. The events related to the vehicle may comprise an abrupt braking of the vehicle (hard-stop event), rapid rise/fall in acceleration/deceleration of the vehicle, change in direction of the vehicle, and the like. The sensors may capture data related to the event. The data captured by the sensors may be represented as time series data sequences. The time-series data sequences may comprise timestamp information.</p><p id="p0025" num="0025">Further, the time-series data sequences may be sampled at a uniform sampling rate wherein the time-series data sequences may be sampled for generating sample points. The time-series data sequences captured by the sensors may be of variable lengths such that the time duration of the time-series data sequences may vary. Thus, the time-series data sequences captured by the sensors (more than one sensor) may be used for determining the event related to the vehicle. The event may be determined accurately as the time-series data sequences from multiple sensors may be used.<!-- EPO <DP n="9"> --></p><p id="p0026" num="0026">In an example, a time-series data sequence S1 captured using a sensor 1 (pressure sensor) for a hard-stop event related to the vehicle is shown in <figref idrefs="f0004">figure 4a</figref>. In <figref idrefs="f0004">figure 4a</figref>, x-axis represents time (seconds) and y-axis represents brake cylinder pressure (Pounds per Square Inch, PSI). The time-series data sequence S1 represents a brake cylinder pressure of the vehicle during the hard-stop event. Further, the time-series data sequence S1 may include missing signal values during certain time intervals.</p><p id="p0027" num="0027">In an example, a time-series data sequence S2 captured using a sensor 2 (speed sensor) for the hard-stop event related to the vehicle is shown in <figref idrefs="f0004">figure 4b</figref>. In <figref idrefs="f0004">figure 4b</figref>, x-axis represents time (seconds) and y-axis represents speed (Miles per Hour, MPH). The time-series data sequence S2 represents a wheel speed of the vehicle, during the hard-stop event. Further, the time-series data sequence S2 may include missing signal values during certain time intervals.</p><p id="p0028" num="0028">In an example, a time-series data sequence S3 captured using a sensor 3 (gear sensor) for a hard-stop event related to the vehicle is shown in <figref idrefs="f0004">figure 4c</figref>. In <figref idrefs="f0004">figure 4c</figref>, x-axis represents time (seconds) and y-axis represents a gear number (numbers, N). The time-series data sequence S3 represents a gear number related to the vehicle, during the hard-stop event. Further, the time-series data sequence S3 may include missing signal values during certain time intervals.</p><p id="p0029" num="0029">In an example, a signal pattern representing the hard-stop event of the vehicle may be determined using the sensor 1, the sensor 2, and the sensor 3 upon applying a predefined rule 1, as mentioned below, <maths id="math0001" num=""><math display="block"><mrow><mi mathvariant="normal">Rule</mi><mspace width="1em"/><mn mathvariant="normal">1</mn><mo>=</mo><mfenced open="{" close="}" separators=""><mfenced separators=""><mrow><mi mathvariant="normal">Sensor</mi><mspace width="1em"/></mrow><mn mathvariant="normal">1</mn><mrow><mspace width="1em"/><mi mathvariant="normal">is greater than</mi><mspace width="1em"/></mrow><msub><mi mathvariant="normal">s</mi><mn mathvariant="normal">1</mn></msub></mfenced><mo>∩</mo><mfenced separators=""><mrow><mi mathvariant="normal">Sensor</mi><mspace width="1em"/></mrow><mn mathvariant="normal">2</mn><mrow><mspace width="1em"/><mi mathvariant="normal">is greater than</mi><mspace width="1em"/></mrow><msub><mi mathvariant="normal">s</mi><mn mathvariant="normal">2</mn></msub></mfenced><mo>∩</mo><mfenced separators=""><mrow><mi mathvariant="normal">Sensor</mi><mspace width="1em"/></mrow><mn mathvariant="normal">3</mn><mrow><mspace width="1em"/><mi mathvariant="normal">is in</mi><mspace width="1em"/></mrow><mfenced open="[" close="]" separators=",,"><msub><mi mathvariant="normal">s</mi><mn mathvariant="normal">31</mn></msub><mn mathvariant="normal">.....</mn><msub><mi mathvariant="normal">s</mi><mrow><mn mathvariant="normal">3</mn><mo>⁢</mo><mi mathvariant="normal">m</mi></mrow></msub></mfenced></mfenced><mo>∩</mo><mfenced separators=""><mrow><mi mathvariant="normal">drop in sensor</mi><mspace width="1em"/></mrow><mn mathvariant="normal">2</mn><mrow><mspace width="1em"/><mi mathvariant="normal">is greater than</mi><mspace width="1em"/></mrow><msup><mrow><msub><mi mathvariant="normal">s</mi><mn mathvariant="normal">2</mn></msub></mrow><mrow><mo>*</mo></mrow></msup></mfenced></mfenced></mrow></math><img id="ib0001" file="imgb0001.tif" wi="145" he="13" img-content="math" img-format="tif"/></maths></p><p id="p0030" num="0030">Here, s<sub>1</sub> denotes a positive pressure threshold value, s<sub>2</sub> denotes a positive speed threshold value, [s<sub>31</sub>,.....,s<sub>3m</sub>] denotes the gear numbers, and s<sub>2</sub>* denotes a negative speed threshold. The positive pressure threshold value may refer to a maximum threshold value of the sensors and the negative speed threshold may refer to a minimum threshold value of the sensors.<!-- EPO <DP n="10"> --></p><p id="p0031" num="0031">In another example, extreme boundaries (left boundary and right boundary) of the signal pattern indicative of the event may be defined by a rule 2, as mentioned below, <maths id="math0002" num=""><math display="block"><mrow><mtable columnalign="left"><mtr><mtd><mi mathvariant="normal">Rule</mi><mspace width="1em"/><mn mathvariant="normal">2</mn><mo>=</mo></mtd><mtd><mi mathvariant="normal">Left boundary</mi><mo>:</mo><mfenced open="{" close="}" separators=""><mfenced separators=""><mi mathvariant="normal">Sensor</mi><mo>⁢</mo><mn mathvariant="normal">1</mn><mrow><mspace width="1em"/><mi mathvariant="normal">is less than</mi><mspace width="1em"/></mrow><msub><mi mathvariant="normal">s</mi><mn mathvariant="normal">1</mn></msub><mrow><mspace width="1em"/><mi mathvariant="normal">for consecutive</mi><mspace width="1em"/></mrow><msub><mi mathvariant="normal">t</mi><mn mathvariant="normal">1</mn></msub><mo>⁢</mo><mi mathvariant="normal">time</mi></mfenced><mo>∪</mo><mfenced><mi mathvariant="normal">c seconds before a critical point</mi></mfenced></mfenced></mtd></mtr><mtr><mtd><mspace width="1em"/></mtd><mtd><mi mathvariant="normal">Right boundary</mi><mo>:</mo><mfenced open="{" close="}" separators=""><mfenced separators=""><mi mathvariant="normal">Sensor</mi><mo>⁢</mo><mn mathvariant="normal">1</mn><mrow><mspace width="1em"/><mi mathvariant="normal">is less than d for consecutive e seconds</mi></mrow></mfenced><mo>∩</mo><mfenced separators=""><mi mathvariant="normal">sensor</mi><mo>⁢</mo><mn mathvariant="normal">2</mn><mrow><mspace width="1em"/><mi mathvariant="normal">is greater than f for consecutive g seconds</mi></mrow></mfenced><mo>∪</mo><mfenced separators=""><mn mathvariant="normal">35</mn><mrow><mspace width="1em"/><mi mathvariant="normal">sample points before the critical point</mi></mrow></mfenced></mfenced></mtd></mtr></mtable></mrow></math><img id="ib0002" file="imgb0002.tif" wi="157" he="36" img-content="math" img-format="tif"/></maths></p><p id="p0032" num="0032">Post capturing the time-series data sequences of variable lengths by the sensors, the system 202 may employ the pairing module 310 to receive the time-series data sequences of variable lengths. The pairing module 310 may further pair the sample points for generating the plurality of pairs of sample points. Each sample point may be paired with one another to generate the plurality of pairs of sample points. The number of pairs (P) of sample points generated for a time-series data sequence 'S' comprising 'L' number of sample points may be calculated using an below mentioned equation 1, <maths id="math0003" num="equation 1"><math display="block"><mrow><mi mathvariant="normal">P</mi><mo>=</mo><mmultiscripts><mrow><msub><mi mathvariant="normal">C</mi><mn mathvariant="normal">2</mn></msub></mrow><mprescripts/><none/><mi mathvariant="normal">L</mi></mmultiscripts></mrow></math><img id="ib0003" file="imgb0003.tif" wi="51" he="7" img-content="math" img-format="tif"/></maths></p><p id="p0033" num="0033">After determining the pairs of sample points, the matrix computing module 312 may represent the time-series data sequences in a two-dimensional (2D) Euclidean space, as shown in <figref idrefs="f0005">figure 5</figref>. According to <figref idrefs="f0005">figure 5</figref> an x-axis represents a time (t) of a time-series data sequence S4 and y-axis denotes value (w) of the time-series data sequence S4. The time-series data sequence S4 may comprise a pair of sample points generated between sample points 'q<sub>i</sub>' and 'q<sub>j</sub>'. The sample point 'q<sub>i</sub>' may be located at (w<sub>i</sub>, t<sub>i</sub>) and the sample point 'q<sub>j</sub>' may be located at (w<sub>j</sub>, t<sub>j</sub>) in the 2D Euclidean space. The matrix computing module 312 may compute the Euclidean distance (d) between the sample points 'q<sub>i</sub>' and 'q<sub>j</sub>' present in the pair of sample points 'q<sub>i</sub>- q<sub>j</sub>', in the 2D Euclidean space using a below mentioned equation 2, <maths id="math0004" num="equation 2"><math display="block"><mrow><mi mathvariant="normal">d</mi><mo>=</mo><msqrt><mrow><msup><mrow><mfenced separators=""><msub><mi>w</mi><mi>i</mi></msub><mo>-</mo><msub><mi>w</mi><mi>j</mi></msub></mfenced></mrow><mn>2</mn></msup><mo>+</mo><msup><mrow><mfenced separators=""><msub><mi>t</mi><mi>i</mi></msub><mo>-</mo><msub><mi>t</mi><mi>j</mi></msub></mfenced></mrow><mn>2</mn></msup></mrow></msqrt></mrow></math><img id="ib0004" file="imgb0004.tif" wi="88" he="9" img-content="math" img-format="tif"/></maths><!-- EPO <DP n="11"> --></p><p id="p0034" num="0034">Similarly, the matrix computing module 312 may compute the Euclidean distances for each pair of the plurality of pairs of the sample points. The Euclidean distances for each pair of the plurality of pairs of the sample points may be represented as a distance matrix.</p><p id="p0035" num="0035">Post computing the distance matrix, the matrix computing module 312 may normalize the distance matrix by dividing the Euclidean distances present in one or more rows of the distance matrix with a maximum Euclidean distance present in the one or more rows. The normalization of the distance matrix may convert the distance matrix into [0, 1] scale.</p><p id="p0036" num="0036">Further, the matrix computing module 312 may compute angles between the sample points of the pairs of sample points. For example, an angle 'θ' between the sample points 'q<sub>i</sub>' (origin point) and 'q<sub>j</sub>' may be computed, as shown in <figref idrefs="f0005">figure 5</figref>. Similarly, the angles between the sample points of each pair of the plurality of pairs may be computed. The angles between the sample points of each pair of the plurality of pairs may be represented as an angle matrix.</p><p id="p0037" num="0037">Post determining the distance matrix and the angle matrix, the matrix computing module 312 may quantize the Euclidean distances and the angles. The Euclidean distances and the angles may be quantized for splitting the Euclidean distances and the angles into bins. Thus, in an example, upon quantizing the Euclidean distances into 'm' levels, the Euclidean distances maybe represented as [do, d<sub>1</sub>] U [d<sub>1</sub>, d<sub>2</sub>] ... U [d<sub>m-1</sub>, d<sub>m</sub>]. Here [do, d<sub>1</sub>], [d<sub>1</sub>, d<sub>2</sub>], and [d<sub>m-1</sub>, d<sub>m</sub>] may represent distance bins. Similarly, in an example, upon quantizing the angles into 'n' levels the angles may be represented as [α<sub>0</sub>, α<sub>1</sub>] U [α<sub>1</sub>, α<sub>2</sub>] ... U [α<sub>n-1</sub>, α<sub>n</sub>]. Here [α<sub>0</sub>, α<sub>1</sub>] U [α<sub>1</sub>, α<sub>2</sub>] ... U [α<sub>n-1</sub>, α<sub>n</sub>] may represent angle bins.</p><p id="p0038" num="0038">After employing the matrix computing module 312, the system 202 may employ the histogram generating and event determining (HGED) module 314. The HGED module 314 may generate a two-dimensional (2D) shape histogram for the time-series data sequence. The 2D shape histogram may represent a global distribution of the plurality of pairs of sample points. The global distribution of the plurality of pairs of sample points may be computed using the distance matrix (D) and the angle matrix (A). The HGED module 314 may compute the global distribution of the plurality of pairs of sample points by computing a shape context of each sample point. The shape context may be defined by a distance-angle based distribution of each sample point with respect to other sample points. In an example, the HGED module 314 may compute the bin (p, q) of the shape context (h<sub>i</sub>) of a sample point 'q<sub>i</sub>' using a below mentioned equation 3,<!-- EPO <DP n="12"> --> <maths id="math0005" num="equation 3"><math display="block"><mrow><msub><mi>h</mi><mi>i</mi></msub><mfenced separators=","><mi>p</mi><mo>⁢</mo><mi>q</mi></mfenced><mo>=</mo><mrow><mstyle displaystyle="true"><mrow><munderover><mrow><mo>∑</mo></mrow><mrow><mi>j</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>j</mi><mo>≠</mo><mi>i</mi></mrow><mi>l</mi></munderover></mrow></mstyle><mrow><mi>δ</mi><mo>⁢</mo><mfenced separators=",,,,,"><msub><mi>D</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>⁢</mo><msub><mi>A</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mrow><mi>p</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mi>p</mi></msub><mo>⁢</mo><msub><mi>α</mi><mrow><mi>q</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>α</mi><mi>q</mi></msub></mfenced></mrow></mrow><mo>,</mo></mrow></math><img id="ib0005" file="imgb0005.tif" wi="129" he="17" img-content="math" img-format="tif"/></maths><br/>
Here, <maths id="math0006" num=""><math display="block"><mrow><mtable columnalign="left"><mtr><mtd><mi>δ</mi><mo>⁢</mo><mfenced separators=",,,,,"><msub><mi>D</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>⁢</mo><msub><mi>A</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mrow><mi>p</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mi>p</mi></msub><mo>⁢</mo><msub><mi>α</mi><mrow><mi>q</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>α</mi><mi>q</mi></msub></mfenced></mtd></mtr><mtr><mtd><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mn>1</mn></mtd><mtd><mi>if</mi><mspace width="1em"/><msub><mi>D</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>∈</mo><mfenced open="[" close="]" separators=","><msub><mi>d</mi><mrow><mi>p</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>d</mi><mi>p</mi></msub></mfenced><mo>,</mo><msub><mi>A</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>∈</mo><mfenced open="[" close="]" separators=","><msub><mi>α</mi><mrow><mi>q</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>⁢</mo><msub><mi>α</mi><mi>q</mi></msub></mfenced></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mi>otherwise</mi></mtd></mtr></mtable></mrow></mtd></mtr></mtable></mrow></math><img id="ib0006" file="imgb0006.tif" wi="95" he="22" img-content="math" img-format="tif"/></maths></p><p id="p0039" num="0039">The HGED module 314 may add the shape contexts of the sample points of the plurality of pairs of sample points for computing a cumulative shape histogram (h<sub>sum</sub>). The cumulative shape histogram may define the global distribution of the plurality of pairs of sample points. The bins of the cumulative shape histograms (h<sub>sum</sub>) may represent the count of the plurality of pairs of sample points. In one example, the bin (p, q) may represent the count of the plurality of pairs of sample points arranged within the Euclidean distance [d<sub>p-1</sub>, d<sub>p</sub>] and within the angle [α<sub>q-1</sub>, α<sub>q</sub>]. Further, the HGED module 314 may divide cumulative histogram (h<sub>sum</sub>) by a maximum entry for generating the 2D shape histogram. Further, the HGED module 314 may generate the 2D shape histogram corresponding to the each time-series data sequence generated by the plurality of sensors, wherein the 2D shape histogram may be of constant dimension.</p><p id="p0040" num="0040"><figref idrefs="f0006">Figure 6a</figref> illustrates an example of the time-series data sequence S5 and <figref idrefs="f0006">Figure 6b</figref> illustrates the 2D shape histogram corresponding to the time-series data sequence S5 generated by the system 202. Here, the number of distance bins (m) is considered as 40 and number of angle bins (n) is considered as 36.</p><p id="p0041" num="0041"><figref idrefs="f0007">Figure 7a</figref> illustrates an example of the time-series data sequence S6 and <figref idrefs="f0007">Figure 7b</figref> illustrates the 2D shape histogram corresponding to the time-series data sequence S6 generated by the system 202. Here, the number of distance bins (m) is considered as 40 and number of angle bins (n) is considered as 36.</p><p id="p0042" num="0042">Post generating the 2D shape histogram for the time-series data sequence generated by the plurality of sensors, the HGED module 314 may concatenate the 2D shape histogram for each time-series data sequence based on the timestamp information for generating a<!-- EPO <DP n="13"> --> concatenated shape histogram. Further, the 2D shape histograms for the time-series data sequences comprising proximate timestamp information may be concatenated for generating the concatenated shape histogram. The HGED module 314 may employ a linear concatenation technique for generating the concatenated shape histogram. The HGED module 314 may bring together the bins of the shape histograms and may increase the number of dimensions of the feature vector. In an example, the HGED module 314 may convert the distance matrix and the angle matrix of the 2D shape histogram corresponding to the time-series data sequence S5 into one-dimensional (1D) vectors. The HGED module 314 may also convert the distance matrix and the angle matrix of the 2D shape histogram corresponding to the time-series data sequence S6 into one-dimensional (1D) vectors. Further, the HGED module 314 may adjoin the 1D vectors of the time-series data sequence S5 with the 1D vectors of the time-series data sequence S6. The HGED module 314 may adjoin the 1D vectors for employing a linear concatenation technique. Upon employing the linear concatenation technique by the HGED module 314, a concatenated shape histogram may be generated by the HGED module 314.</p><p id="p0043" num="0043">Thus, the 2D shape histogram for the time-series data sequences derived from sensors employed in the vehicle/environment, may be concatenated by the HGED module 314. Concatenating the 2D shape histogram for the time-series data sequences may bring together the discriminating features of the 2D shape histogram for the time-series data sequences. Thus, concatenating the 2D shape histogram for the time-series data sequences may improve the accuracy of detecting the event related to the vehicle/environment.</p><p id="p0044" num="0044">Further, the HGED module 314 may match the concatenated shape histogram with a pre-stored set of shape histograms for detecting the event. The pre-stored set of shape histograms may comprise shape histograms corresponding to relevant events. In an example, the HGED module 314 may match the concatenated shape histogram with the pre-stored set of shape histograms using a Support Vector Machine (SVM) classifier. However, in a case, the HGED module 314 may use Radial Basis Function (RBF) kernel with the SVM classifier for matching the concatenated shape histogram with the pre-stored set of shape histograms. Upon determining a successful match of the concatenated shape histogram, the HGED module 314 may determine the event.</p><p id="p0045" num="0045">Referring now to <figref idrefs="f0008">Figure 8</figref>, the method for detecting an event from time-series data sequences, in accordance with an embodiment of the present subject matter. The method 800<!-- EPO <DP n="14"> --> may be described in the general context of computer executable instructions. Generally, computer executable instructions can include routines, programs, objects, components, data structures, procedures, modules, functions, etc., that perform particular functions or implement particular abstract data types. The method 800 may also be practiced in a distributed computing environment where functions are performed by remote processing devices that are linked through a communications network. In a distributed computing environment, computer executable instructions may be located in both local and remote computer storage media, including memory storage devices.</p><p id="p0046" num="0046">The order in which the method 800 is described is not intended to be construed as a limitation, and any number of the described method blocks can be combined in any order to implement the method 800 or alternate methods. Additionally, individual blocks may be deleted from the method 800 without departing from the spirit and scope of the subject matter described herein. Furthermore, the method 800 can be implemented in any suitable hardware, software, firmware, or combination thereof. However, for ease of explanation, in the embodiments described below, the method 800 may be considered to be implemented in the above described system 202.</p><p id="p0047" num="0047">At block 802, the time-series data sequences related to an event are received. Further, the step of receiving time-series data sequences related to the event may be performed by a processor.</p><p id="p0048" num="0048">At block 804, the time-series data sequences are sampled. The time-series data sequences are sampled for generating sample points. Further, the step of sampling the time-series data sequences may be performed by a processor.</p><p id="p0049" num="0049">At block 806, the pairs of sample points are generated. Further, each of the sample point may be paired with one another. Further, the step of generating pairs of sample points is performed by the processor.<!-- EPO <DP n="15"> --></p><p id="p0050" num="0050">At block 808, the distance matrix and the angle matrix are computed. Further the distance matrix and the angle matrix are computed in a 2D Euclidean space. Further, the step of computing the distance matrix and the angle matrix is performed by the processor.</p><p id="p0051" num="0051">At block 810, the 2D shape histogram for the time-series data sequences are generated, wherein the 2D shape histogram for the time-series data sequences represent global distribution of the plurality of pairs of sample points. The global distribution of the plurality of pairs of sample points is computed using the distance matrix (D) and the angle matrix (A). Further, the step of generating the 2D shape histograms is performed by the processor.</p><p id="p0052" num="0052">At block 812, the 2D shape histogram for the time-series data sequences are concatenated. Further, the 2D shape histogram for the time-series data sequences are concatenated using a linear concatenation technique for generating a concatenated shape histogram. Further, the step of concatenating the 2D shape histogram for the time-series data sequences is performed by the processor.</p><p id="p0053" num="0053">At block 814, the concatenated shape histogram is matched with a pre-stored set of histograms for determining the event. Further, the step of matching the concatenated shape histogram with the pre-stored shape histograms, for determining the event, is performed by the processor.</p><p id="p0054" num="0054">Although implementations for detecting an event from time-series data sequences have been described in language specific to structural features and/or methods, it is to be understood that the appended claims are not necessarily limited to the specific features or methods described. Rather, the specific features and methods are disclosed as examples of implementations for monitoring the user activities on the software application external to an organization.</p></description><claims mxw-id="PCLM90459479" lang="EN" load-source="patent-office"><!-- EPO <DP n="16"> --><claim id="c-en-0001" num="0001"><claim-text>A method for detecting an event from time-series data sequences, the method comprising:
<claim-text>receiving, by a processor, the time-series data sequences of variable lengths, generated by a plurality of sensors, wherein the time-series data sequences comprise timestamp information;</claim-text>
<claim-text>sampling the time-series data sequences at a uniform sampling rate for generating sample points;</claim-text>
<claim-text>generating, by the processor, a plurality of pairs of sample points using the sample points, wherein the plurality of pairs of sample points are generated by pairing each sample point with one another;</claim-text>
<claim-text>computing, by the processor, a distance matrix (D) and an angle matrix (A) for one or more pairs of the sample points of the plurality of pairs of sample points;</claim-text>
<claim-text>generating, by the processor, a two-dimensional (2D) shape histogram for the time-series data sequences using the distance matrix (D) and the angle matrix (A), wherein the 2D shape histogram have a constant dimension and the 2D shape histogram represents a global distribution of the plurality of pairs of sample points,;</claim-text>
<claim-text>concatenating, by the processor, the 2D shape histograms for one or more time-series data sequences based on the timestamp information to generate a concatenated shape histogram; and</claim-text>
<claim-text>matching, by the processor, the concatenated shape histogram with a pre-stored set of shape histograms to detect an event.</claim-text></claim-text></claim><claim id="c-en-0002" num="0002"><claim-text>The method of claim 1, wherein the distance matrix (D) is computed by calculating Euclidean distances between the sample points present in the pairs of the sample points, and wherein the Euclidean distances are computed in a two-dimensional Euclidean space.<!-- EPO <DP n="17"> --></claim-text></claim><claim id="c-en-0003" num="0003"><claim-text>The method of claim 1, wherein the angle matrix (A) is computed by calculating angles between the sample points present in the pairs of the sample points, and wherein the angles are computed in a two-dimensional Euclidean space.</claim-text></claim><claim id="c-en-0004" num="0004"><claim-text>The method of claim 2 further comprising normalizing the distance matrix (D) by dividing the Euclidean distances of one or more rows with a maximum Euclidean distance of the one or more rows.</claim-text></claim><claim id="c-en-0005" num="0005"><claim-text>The method of claim 1, wherein the 2D shape histograms for the one or more time-series data sequences comprising proximate timestamp information are concatenated to generate the concatenated shape histogram, and concatenating of the 2D shape histograms brings together discriminating features of the 2D shape histograms for the one or more time-series data sequences.</claim-text></claim><claim id="c-en-0006" num="0006"><claim-text>The method of claim 1, wherein the concatenated shape histogram is generated by converting the distance matrix (D) and the angle matrix (A) into one-dimensional vectors and merging the one-dimensional (1D) vectors.</claim-text></claim><claim id="c-en-0007" num="0007"><claim-text>The method of claim 1, wherein the concatenated shape histogram is matched with the pre-stored set of shape histograms using a Support Vector Machine (SVM) classifier.</claim-text></claim><claim id="c-en-0008" num="0008"><claim-text>The method of claim 1, wherein the pre-stored set of shape histograms comprise shape histograms corresponding to a relevant event.</claim-text></claim><claim id="c-en-0009" num="0009"><claim-text>A system for detecting an event from time-series data sequences, the system comprising:
<claim-text>a processor 302;<!-- EPO <DP n="18"> --></claim-text>
<claim-text>a memory 306 coupled to the processor 302, wherein the processor 302 is capable for executing a plurality of modules 308 stored in the memory, and wherein the plurality of modules 308 comprising:
<claim-text>a pairing module 310,
<claim-text>to receive the time-series data sequences of variable lengths generated by a plurality of sensors, wherein the time-series data sequences comprise timestamp information;</claim-text>
<claim-text>to sample the time-series data sequences at a uniform sampling rate for generating sample points;</claim-text>
<claim-text>to generate a plurality of pairs of sample points using the sample points such that each sample point is paired with one another; a matrix computing module 312,</claim-text>
<claim-text>to compute a distance matrix (D) and an angle matrix (A) for one or more pairs of the sample points of the plurality of pairs of sample points;</claim-text></claim-text>
<claim-text>a histogram generating and event determining (HGED) module 314,
<claim-text>to generate a two-dimensional (2D) shape histogram for the time-series data sequences using the distance matrix (D) and the angle matrix (A), wherein the 2D shape histogram have a constant dimension, and the 2D shape histogram represents global distribution of the plurality of pairs of sample points;</claim-text>
<claim-text>to concatenate the 2D shape histograms for one or more time-series data sequences based on the timestamp information to generate a concatenated shape histogram; and</claim-text>
<claim-text>to match the concatenated shape histogram with a pre-stored set of shape histograms to detect an event.</claim-text></claim-text></claim-text></claim-text></claim><claim id="c-en-0010" num="0010"><claim-text>The system of claim 9, wherein the distance matrix (D) is computed by calculating Euclidean distances between the sample points present in the pairs of the sample points, and wherein the Euclidean distances are computed in a two-dimensional Euclidean space.<!-- EPO <DP n="19"> --></claim-text></claim><claim id="c-en-0011" num="0011"><claim-text>The system of claim 9, wherein the angle matrix (A) is computed by calculating angles between the sample points present in the pairs of the sample points, and wherein the angles are computed in a two-dimensional Euclidean space.</claim-text></claim><claim id="c-en-0012" num="0012"><claim-text>The system of claim 10, wherein the matrix computing module 312 further normalizes the distance matrix (D) by dividing the Euclidean distances of one or more rows with a maximum Euclidean distance of the one or more rows.</claim-text></claim><claim id="c-en-0013" num="0013"><claim-text>The system of claim 9, wherein the time-series data sequences comprising proximate timestamp information are concatenated to generate the concatenated shape histogram, and concatenating the 2D shape histograms brings together discriminating features of the 2D shape histograms for the one or more time-series data sequences.</claim-text></claim><claim id="c-en-0014" num="0014"><claim-text>The system of claim 9, wherein the concatenated shape histogram is generated by converting the distance matrix (D) and the angle matrix (A) into one-dimensional vectors and merging the one-dimensional (1D) vectors.</claim-text></claim><claim id="c-en-0015" num="0015"><claim-text>The system of claim 9, wherein the pre-stored set of shape histograms comprise shape histograms corresponding to a relevant event.</claim-text></claim></claims><drawings mxw-id="PDW20422205" load-source="patent-office"><!-- EPO <DP n="20"> --><figure id="f0001" num="1a,1b"><img id="if0001" file="imgf0001.tif" wi="165" he="183" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="21"> --><figure id="f0002" num="2"><img id="if0002" file="imgf0002.tif" wi="165" he="184" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="22"> --><figure id="f0003" num="3"><img id="if0003" file="imgf0003.tif" wi="165" he="209" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="23"> --><figure id="f0004" num="4a,4b,4c"><img id="if0004" file="imgf0004.tif" wi="165" he="194" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="24"> --><figure id="f0005" num="5"><img id="if0005" file="imgf0005.tif" wi="165" he="137" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="25"> --><figure id="f0006" num="6a,6b"><img id="if0006" file="imgf0006.tif" wi="165" he="194" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="26"> --><figure id="f0007" num="7a,7b"><img id="if0007" file="imgf0007.tif" wi="165" he="194" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="27"> --><figure id="f0008" num="8"><img id="if0008" file="imgf0008.tif" wi="165" he="196" img-content="drawing" img-format="tif"/></figure></drawings><search-report-data><doc-page id="srep0001" file="srep0001.tif" wi="161" he="233" type="tif"/><doc-page id="srep0002" file="srep0002.tif" wi="161" he="233" type="tif"/><doc-page id="srep0003" file="srep0003.tif" wi="161" he="233" type="tif"/></search-report-data><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
