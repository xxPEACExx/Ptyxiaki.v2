<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2960861-A1" country="EP" doc-number="2960861" kind="A1" date="20151230" family-id="53723989" file-reference-id="293449" date-produced="20180826" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="160451820" ucid="EP-2960861-A1"><document-id><country>EP</country><doc-number>2960861</doc-number><kind>A1</kind><date>20151230</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-15174127-A" is-representative="YES"><document-id mxw-id="PAPP193866608" load-source="docdb" format="epo"><country>EP</country><doc-number>15174127</doc-number><kind>A</kind><date>20150626</date><lang>EN</lang></document-id><document-id mxw-id="PAPP193866609" load-source="patent-office" format="original"><country>EP</country><doc-number>15174127.9</doc-number><date>20150626</date><lang>EN</lang></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC162034774" ucid="KR-20140078722-A" load-source="docdb"><document-id format="epo"><country>KR</country><doc-number>20140078722</doc-number><kind>A</kind><date>20140626</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL-1988523064" load-source="docdb">G06T   7/00        20060101AFI20151117BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-1988524465" load-source="docdb">G06T   5/00        20060101ALI20151117BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-1988524489" load-source="docdb">H04N   9/77        20060101ALI20151117BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-1713522052" load-source="docdb" scheme="CPC">H04N   9/64        20130101 LI20180103BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1984701483" load-source="docdb" scheme="CPC">H04N  19/186       20141101 FI20151231BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT165546926" lang="DE" load-source="patent-office">VORRICHTUNG UND VERFAHREN ZUR BILDVERARBEITUNG IN EINER ELEKTRONISCHEN VORRICHTUNG</invention-title><invention-title mxw-id="PT165546927" lang="EN" load-source="patent-office">APPARATUS AND METHOD OF PROCESSING IMAGES IN AN ELECTRONIC DEVICE TO SELECTIVELY FILTER THE IMAGE DATA ACCORDING TO DETECTED PATTERNS</invention-title><invention-title mxw-id="PT165546928" lang="FR" load-source="patent-office">APPAREIL ET PROCÉDÉ DE TRAITEMENT D'IMAGES DANS UN DISPOSITIF ÉLECTRONIQUE</invention-title><citations><patent-citations><patcit mxw-id="PCIT335740285" load-source="docdb" ucid="US-20050094003-A1"><document-id format="epo"><country>US</country><doc-number>20050094003</doc-number><kind>A1</kind><date>20050505</date></document-id><sources><source name="SEA" category="X" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335743245" load-source="docdb" ucid="US-20070097391-A1"><document-id format="epo"><country>US</country><doc-number>20070097391</doc-number><kind>A1</kind><date>20070503</date></document-id><sources><source name="SEA" category="X" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335739172" load-source="docdb" ucid="US-20070211307-A1"><document-id format="epo"><country>US</country><doc-number>20070211307</doc-number><kind>A1</kind><date>20070913</date></document-id><sources><source name="SEA" category="A" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335742196" load-source="docdb" ucid="US-20090110305-A1"><document-id format="epo"><country>US</country><doc-number>20090110305</doc-number><kind>A1</kind><date>20090430</date></document-id><sources><source name="SEA" category="Y" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335739112" load-source="docdb" ucid="US-20120243791-A1"><document-id format="epo"><country>US</country><doc-number>20120243791</doc-number><kind>A1</kind><date>20120927</date></document-id><sources><source name="SEA" category="A" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335739985" load-source="docdb" ucid="US-5412423-A"><document-id format="epo"><country>US</country><doc-number>5412423</doc-number><kind>A</kind><date>19950502</date></document-id><sources><source name="SEA" category="A" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT405775049" load-source="docdb" ucid="US-5959693-A"><document-id format="epo"><country>US</country><doc-number>5959693</doc-number><kind>A</kind><date>19990928</date></document-id><sources><source name="SEA" category="XY" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335739414" load-source="docdb" ucid="US-8115840-B2"><document-id format="epo"><country>US</country><doc-number>8115840</doc-number><kind>B2</kind><date>20120214</date></document-id><sources><source name="SEA" category="A" created-by-npl="N"/></sources></patcit></patent-citations><non-patent-citations><nplcit><text>None</text><sources><source mxw-id="PNPL62475922" load-source="docdb" name="APP"/></sources></nplcit></non-patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR1103312973" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>SAMSUNG ELECTRONICS CO LTD</last-name><address><country>KR</country></address></addressbook></applicant><applicant mxw-id="PPAR1103303707" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>SAMSUNG ELECTRONICS CO., LTD</last-name></addressbook></applicant><applicant mxw-id="PPAR1101652803" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Samsung Electronics Co., Ltd</last-name><iid>101312277</iid><address><street>129, Samsung-ro Yeongtong-gu Suwon-si</street><city>Gyeonggi-Do 443-742</city><country>KR</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR1103319682" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>HAN DONGKYOON</last-name><address><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR1103321426" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>HAN, DONGKYOON</last-name></addressbook></inventor><inventor mxw-id="PPAR1101639668" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>HAN, DONGKYOON</last-name><address><street>Samsung Electronics Co., Ltd. 129 Samsung-ro Yeongtong-gu Suwon-si</street><city>443-742 Gyeonggi-do</city><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR1103320286" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>LEE YONGMAN</last-name><address><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR1103329919" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>LEE, YONGMAN</last-name></addressbook></inventor><inventor mxw-id="PPAR1101653755" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>LEE, YONGMAN</last-name><address><street>Samsung Electronics Co., Ltd. 129 Samsung-ro Yeongtong-gu Suwon-si</street><city>443-742 Gyeonggi-do</city><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR1103308877" load-source="docdb" sequence="3" format="epo"><addressbook><last-name>KIM SOOHYUNG</last-name><address><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR1103304789" load-source="docdb" sequence="3" format="intermediate"><addressbook><last-name>KIM, SOOHYUNG</last-name></addressbook></inventor><inventor mxw-id="PPAR1101646647" load-source="patent-office" sequence="3" format="original"><addressbook><last-name>KIM, SOOHYUNG</last-name><address><street>Samsung Electronics Co., Ltd. 129 Samsung-ro Yeongtong-gu Suwon-si</street><city>443-742 Gyeonggi-do</city><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR1103304779" load-source="docdb" sequence="4" format="epo"><addressbook><last-name>KIM JONGHO</last-name><address><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR1103314254" load-source="docdb" sequence="4" format="intermediate"><addressbook><last-name>KIM, JONGHO</last-name></addressbook></inventor><inventor mxw-id="PPAR1101641514" load-source="patent-office" sequence="4" format="original"><addressbook><last-name>KIM, JONGHO</last-name><address><street>Samsung Electronics Co., Ltd. 129 Samsung-ro Yeongtong-gu Suwon-si</street><city>443-742 Gyeonggi-do</city><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR1103326429" load-source="docdb" sequence="5" format="epo"><addressbook><last-name>PARK HYUNHEE</last-name><address><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR1103314940" load-source="docdb" sequence="5" format="intermediate"><addressbook><last-name>PARK, Hyunhee</last-name></addressbook></inventor><inventor mxw-id="PPAR1101639538" load-source="patent-office" sequence="5" format="original"><addressbook><last-name>PARK, Hyunhee</last-name><address><street>Samsung Electronics Co., Ltd. 129 Samsung-ro Yeongtong-gu Suwon-si</street><city>443-742 Gyeonggi-do</city><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR1103306856" load-source="docdb" sequence="6" format="epo"><addressbook><last-name>YI JIYOUNG</last-name><address><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR1103302942" load-source="docdb" sequence="6" format="intermediate"><addressbook><last-name>YI, Jiyoung</last-name></addressbook></inventor><inventor mxw-id="PPAR1101645806" load-source="patent-office" sequence="6" format="original"><addressbook><last-name>YI, Jiyoung</last-name><address><street>Samsung Electronics Co., Ltd. 129 Samsung-ro Yeongtong-gu Suwon-si</street><city>443-742 Gyeonggi-do</city><country>KR</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR1101645616" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Gover, Richard Paul</last-name><iid>101375265</iid><address><street>HGF Limited Saviour House 9 St Saviourgate</street><city>York YO1 8NQ</city><country>GB</country></address></addressbook></agent></agents></parties><international-convention-data><designated-states><ep-contracting-states><country mxw-id="DS660693238" load-source="docdb">AL</country><country mxw-id="DS660611125" load-source="docdb">AT</country><country mxw-id="DS660693252" load-source="docdb">BE</country><country mxw-id="DS660702056" load-source="docdb">BG</country><country mxw-id="DS660615066" load-source="docdb">CH</country><country mxw-id="DS660693329" load-source="docdb">CY</country><country mxw-id="DS660611126" load-source="docdb">CZ</country><country mxw-id="DS660690959" load-source="docdb">DE</country><country mxw-id="DS660693253" load-source="docdb">DK</country><country mxw-id="DS660693330" load-source="docdb">EE</country><country mxw-id="DS660615443" load-source="docdb">ES</country><country mxw-id="DS660702057" load-source="docdb">FI</country><country mxw-id="DS660702058" load-source="docdb">FR</country><country mxw-id="DS660693254" load-source="docdb">GB</country><country mxw-id="DS660693259" load-source="docdb">GR</country><country mxw-id="DS660693260" load-source="docdb">HR</country><country mxw-id="DS660611135" load-source="docdb">HU</country><country mxw-id="DS660615071" load-source="docdb">IE</country><country mxw-id="DS660693261" load-source="docdb">IS</country><country mxw-id="DS660702067" load-source="docdb">IT</country><country mxw-id="DS660693335" load-source="docdb">LI</country><country mxw-id="DS660690960" load-source="docdb">LT</country><country mxw-id="DS660611136" load-source="docdb">LU</country><country mxw-id="DS660690961" load-source="docdb">LV</country><country mxw-id="DS660690962" load-source="docdb">MC</country><country mxw-id="DS660785215" load-source="docdb">MK</country><country mxw-id="DS660785216" load-source="docdb">MT</country><country mxw-id="DS660615444" load-source="docdb">NL</country><country mxw-id="DS660611137" load-source="docdb">NO</country><country mxw-id="DS660615445" load-source="docdb">PL</country><country mxw-id="DS660693336" load-source="docdb">PT</country><country mxw-id="DS660615446" load-source="docdb">RO</country><country mxw-id="DS660693337" load-source="docdb">RS</country><country mxw-id="DS660615451" load-source="docdb">SE</country><country mxw-id="DS660693338" load-source="docdb">SI</country><country mxw-id="DS660785217" load-source="docdb">SK</country><country mxw-id="DS660785218" load-source="docdb">SM</country><country mxw-id="DS660615072" load-source="docdb">TR</country></ep-contracting-states><ep-extended-states><ep-extended-state-data><country>BA</country></ep-extended-state-data><ep-extended-state-data><country>ME</country></ep-extended-state-data></ep-extended-states></designated-states></international-convention-data></bibliographic-data><abstract mxw-id="PA166480190" lang="EN" load-source="patent-office"><p id="pa01" num="0001">Disclosed are an electronic device and a method of encoding and decoding colour images in an electronic device which includes a controller arranged to analyse pixel data of an image, determine a pixel pattern based on the analysed pixel data, and encode the image according to the determined pixel pattern.
<img id="iaf01" file="imgaf001.tif" wi="112" he="91" img-content="drawing" img-format="tif"/></p></abstract><abstract mxw-id="PA166760002" lang="EN" source="EPO" load-source="docdb"><p>Disclosed are an electronic device and a method of encoding and decoding colour images in an electronic device which includes a controller arranged to analyse pixel data of an image, determine a pixel pattern based on the analysed pixel data, and encode the image according to the determined pixel pattern.</p></abstract><description mxw-id="PDES98404891" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><heading id="h0001"><b>BACKGROUND OF THE INVENTION</b></heading><heading id="h0002"><u>1. Field of the Invention</u></heading><p id="p0001" num="0001">The present invention relates to an apparatus and method of encoding and decoding colour images in an electronic device.</p><heading id="h0003"><u>2. Description of the Related Art</u></heading><p id="p0002" num="0002">Digital image data includes Red (R), Green (G), and Blue (B) colour components or luminance (Y) and a plurality of colour difference components (chrominance (C)). Colour difference components may be produced from differences between the luminance signal (Y) representing the brightness of a video on an electronic device and the three basic colours signals, in which case the differences may be three colour difference components: (RY), (GY) and (BY). The three basic colours may be reproduced by using the two colour difference components, (RY) and (BY).</p><p id="p0003" num="0003">A digital image may be formed with a ratio of the luminance Y and the colour difference components (B-Y and R-Y), 4:n:m, where the number, '4' denotes a sampling rate of a standard frequency 13.5 MHz, for converting analog TV signals into digital signals, and 'n' and 'm' denote the respective colour difference components. There may be sampling schemes considering ratios of luminance and colour difference components, e.g., 4:4:4:, 4:2:2, and 4:1:1. The 4:4:4 scheme indicates that three components channels are sampled at 13.5 MHz. The 4:2:2 scheme indicates that when the Y signal is sampled every line at 13.5 MHz, the colour difference<!-- EPO <DP n="2"> --> signals are sampled every two lines at 6.75 MHz. The 4:1:1 scheme indicates that when the Y signal is sampled every line at 13.5 MHz, the colour difference signals are sampled every four lines at 3.37 MHz.</p><p id="p0004" num="0004">Conventional electronic devices reduce the rates of colour difference components to be less than the rate of a luminance component in a digital image including, for example, a luminance component, first colour difference component and second colour difference component. As such, the number of colour difference components is reduced compared to the rate of the luminance component. In that case, although the size of image data may be reduced, the capability of displaying images also decreases. Accordingly, there is a need in the art for an improved method and apparatus for encoding and decoding images in an electronic device, such that the integrity of an image display is maintained.</p><heading id="h0004"><b>SUMMARY OF THE INVENTION</b></heading><p id="p0005" num="0005">Accordingly, an aim of certain embodiments of the present invention is to provide an apparatus and method that codes colour difference data of pixels of a unit block, according to pixel patterns, when encoding a digital image that may include a luminance component, first colour difference component and second colour difference component.</p><p id="p0006" num="0006">In accordance with a first aspect of the present invention, a method of processing images in an electronic device includes analysing pixel data of an image, determining a pixel pattern based on the analysed pixel data, and encoding the image according to the determined pixel pattern. The method may further comprise outputting the analysed pixel data.<!-- EPO <DP n="3"> --></p><p id="p0007" num="0007">The analysed pixel data may comprise luminance data, first colour difference data and second colour difference data; and the analysis may be based on one or more of luminance data, first colour difference data and second colour difference data and the encoding comprises reconfiguring the luminance data, first colour difference data and second colour difference data, according to the determined pixel pattern.</p><p id="p0008" num="0008">The first colour difference data may be indicated by Cb; and the second colour difference data may be indicated by Cr. The encoding may comprise encoding the Cb and Cr data according to the determined pixel pattern.</p><p id="p0009" num="0009">The method may further comprise: converting, when the image is Red, Green, Blue, RGB, data, colours from the RGB data to YCbCr data.</p><p id="p0010" num="0010">Outputting the analysed pixel data may comprise: selecting luminance pixels of a block unit Ya, Yb, Yc and Yd; obtaining absolute values Abs (Ya-Yb), Abs (Yc-Yd), Abs (Ya-Yc), Abs (Yb-Yd), Abs (Ya-Yd) and Abs (Yb-Yc) from the Ya, Yb, Yc and Yd pixels; and comparing the absolute values with a threshold and outputting the analysed pixel data.</p><p id="p0011" num="0011">Determining the pixel pattern may comprise: analysing the analysed pixel data and determining the pixel pattern; and outputting flag data according to the determined pixel pattern.</p><p id="p0012" num="0012">Encoding the image may comprise: encoding first data by calculating an average of Cb pixels corresponding to a combination of pixels less than a first threshold according to the determined pixel pattern, and creating first encoded data CB1 and second encoded data CB2;<!-- EPO <DP n="4"> --> encoding second data by calculating an average of Cr pixels corresponding to a combination of pixels less than a second threshold according to the determined pixel pattern, and creating first encoded data CR1 and second encoded data CR2; inserting the flag data into CB1, CB2, CR1, and CR2; and creating combined encoded data by combining Ya, Yb, Yc, Yd, CB1, CB2, CR1 and CR2 and the flag data.</p><p id="p0013" num="0013">Inserting the flag data may comprise: inserting the flag data into the Least Significant Bit, LSB, of CB1, CB2, CR1 and CR2.</p><p id="p0014" num="0014">The method may further comprise: analysing, when displaying the image, flag data in an encoded image and verifying a pattern; and decoding first colour difference data and second colour difference data according to the verified pattern.</p><p id="p0015" num="0015">The method may further comprise: displaying the decoded image by converting, when a display is a Red, Green, Blue, RGB, display, the decoded luminance data, first colour difference data and second colour difference data, to RGB data.</p><p id="p0016" num="0016">In accordance with a second aspect of the present invention, an electronic device includes a controller arranged to analyse pixel data of an image, determine a pixel pattern, and encode the image according to the determined pixel pattern. The determination of a pixel pattern may be based on the analysed pixel data. The electronic device may further comprise a display, functionally connected to the controller, that displays the image.</p><p id="p0017" num="0017">The pixel data may comprise luminance data, first colour difference data and second<!-- EPO <DP n="5"> --> colour difference data; and the controller may be further arranged to analyse one or more of luminance data, first colour difference data and second colour difference data, determine a pixel pattern based on the analysis, and reconfigure the luminance data, first colour difference data and second colour difference data, according to the determined pixel pattern.</p><p id="p0018" num="0018">The first colour difference data may be indicated by Cb; the second colour difference data may be indicated by Cr; and the controller may be further arranged to analyse luminance pixel values of a preset unit block, determine a pixel pattern of the unit block, and encode the Cb and Cr data according to the determined pixel pattern.</p><p id="p0019" num="0019">The controller may comprise: a pixel analysis unit arranged to analyse luminance pixel values of a unit block and output the analysed pixel data; a pattern determining unit arranged to determine a pixel pattern corresponding to the analysed pixel data and output flag data of the determined pixel pattern; and an encoding unit arranged to compress and encode the Cb and Cr data to the determined pixel pattern and create encoded data including the flag data, luminance data, and the compressed, encoded Cb and Cr data.</p><p id="p0020" num="0020">The controller may further comprise: a colour space conversion unit arranged to convert, when the image is Red, Green, Blue, RGB, data, colours from RGB data to YCbCr data.</p><p id="p0021" num="0021">The pixel analysis unit may comprise: a plurality of absolute value calculators arranged to calculate absolute values Abs (Ya-Yb), Abs (Yc-Yd), Abs (Ya-Yc), Abs (Yb-Yd), Abs (Ya-Yd) and Abs (Yb-Yc) from Ya, Yb, Yc and Yd data forming a unit block of luminance data; and a plurality of comparators arranged to compare the absolute values with a threshold and output<!-- EPO <DP n="6"> --> analysed pixel data.</p><p id="p0022" num="0022">The pattern determining unit may be further arranged to analyse the analysed pixel data, determine a pixel pattern based on the analysis, and output flag data according to the determined pixel pattern.</p><p id="p0023" num="0023">The encoding unit may comprise: a CB encoding unit arranged to calculate an average of Cb pixels corresponding to a combination of pixels less than a first threshold according to the determined pixel pattern, and create first encoded data CB1 and second encoded data CB2; a CR encoding unit arranged to calculate an average of Cr pixels corresponding to a combination of pixels less than a second threshold according to the determined pixel pattern, and create first encoded data CR1 and second encoded data CR2; a flag inserting unit arranged to insert the flag data into CB1, CB2, CR1, and CR2; and a combination unit arranged to combine Ya, Yb, Yc, Yd, CB1, CB2, CR1 and CR2 and flag data to create combined encoded data.</p><p id="p0024" num="0024">The flag inserting unit may be further arranged to insert the flag data into a Least Significant Bit, LSB, of CB1, CB2, CR1 and CR2.</p><p id="p0025" num="0025">The controller may comprise: a pattern determining unit arranged to analyse, when displaying the image, flag data in an encoded image and verify a pattern; and a decoding unit arranged to restore first colour difference data and second colour difference data according to the verified pattern.</p><p id="p0026" num="0026">The controller may comprise: a colour space conversion unit arranged to convert, when a<!-- EPO <DP n="7"> --> display is a Red, Green, Blue, RGB, display, luminance data, first colour difference data and second colour difference data, output from the decoding unit, to RGB data.</p><p id="p0027" num="0027">Another aspect of the invention provides a computer program comprising instructions arranged, when executed, to implement a method in accordance with any one of the above-described aspects. A further aspect provides machine-readable storage storing such a program.</p><heading id="h0005"><b>BRIEF DESCRIPTION OF THE DRAWINGS</b></heading><p id="p0028" num="0028">The above and other aspects, features and advantages of the present invention will become more apparent from the following detailed description taken in conjunction with the accompanying drawings, in which:
<ul><li><figref idrefs="f0001">FIG. 1</figref> illustrates a network environment 100 including an electronic device 101 according to various embodiments of the present invention;</li><li><figref idrefs="f0002">FIG. 2</figref> illustrates a schematic block diagram of an electronic device for processing images according various embodiments of the present invention;</li><li><figref idrefs="f0003 f0004 f0005 f0006">FIGS. 3A to 3D</figref> illustrate diagrams that describes configurations of pixels for an image in an electronic device according to various embodiments of the present invention;</li><li><figref idrefs="f0007">FIG. 4</figref> illustrates examples of a pattern of pixels in a unit block in an electronic device according to various embodiments of the present invention;</li><li><figref idrefs="f0008">FIG. 5</figref> is a block diagram of an image- processing module for analysing values of pixels in a unit block, determining the pixel pattern based on the pixel analyses, and encoding colour difference data according to the determined pixel pattern in an electronic device according to various embodiments of the present invention;<!-- EPO <DP n="8"> --></li><li><figref idrefs="f0009">FIG. 6</figref> illustrates a configuration of pixels in a unit block in an electronic device according to various embodiments of the present invention;</li><li><figref idrefs="f0010 f0011 f0012">FIGS. 7A to 7C</figref> illustrate a process of analysing values of pixels in a unit block in an electronic device according to various embodiments of the present invention;</li><li><figref idrefs="f0013">FIG. 8</figref> illustrates patterns of a unit block according to analysed pixel data in an electronic device according to various embodiments of the present invention;</li><li><figref idrefs="f0014 f0015 f0016">FIGS. 9A to 9C</figref> illustrate a process of configuring encoded data of a unit block in an electronic device according to various embodiments of the present invention;</li><li><figref idrefs="f0017">FIG. 10</figref> illustrates a process of encoding and decoding images in an electronic device according to various embodiments of the present invention;</li><li><figref idrefs="f0018">FIG. 11</figref> is a schematic block diagram of an electronic device according to various embodiments of the present invention;</li><li><figref idrefs="f0019">FIG. 12</figref> illustrates a method of processing a colour image in an electronic device according to various embodiments of the present invention;</li><li><figref idrefs="f0020">FIGS. 13A</figref> and <figref idrefs="f0021">13B</figref> illustrate a method of analysing pixel values in an electronic device according to various embodiments of the present invention;</li><li><figref idrefs="f0022">FIG. 14</figref> illustrates a method of determining a pixel pattern in an electronic device according to various embodiments of the present invention;</li><li><figref idrefs="f0023">FIG. 15</figref> illustrates a method of encoding images in an electronic device according to various embodiments of the present invention;</li><li><figref idrefs="f0024">FIG. 16</figref> illustrates a method of encoding images and decoding encoded images, according to pixel patterns, in an electronic device according to various embodiments of the present invention;</li><li><figref idrefs="f0025">FIG. 17</figref> illustrates a method of decoding a encoded image in an electronic device<!-- EPO <DP n="9"> --> according to various embodiments of the present invention; and</li><li><figref idrefs="f0026">FIGS. 18A</figref> and <figref idrefs="f0027">18B</figref> illustrate images encoded according to pixel patterns in an electronic device, by comparison with each other, according to various embodiments of the present invention.</li></ul></p><heading id="h0006"><b>DETAILED DESCRIPTION OF EMBODIMENTS OF THE INVENTION</b></heading><p id="p0029" num="0029">Hereinafter, embodiments of the present invention will be described with reference to the accompanying drawings. Although specific embodiments are illustrated in the drawings and related detailed descriptions are discussed, the present invention may have various modifications and several embodiments. However, the present invention is not limited thereto and it should be understood that the present invention includes all changes and/or equivalents and substitutes included in the scope of the appended claims. In connection with descriptions of the drawings, similar components are designated by the same reference numeral. A detailed description of related known configurations or functions incorporated herein will be omitted for the sake of clarity and conciseness.</p><p id="p0030" num="0030">The terms "include" or "includes" which may be used in describing various embodiments of the present invention refer to the existence of a corresponding disclosed function, operation or component which can be used in various embodiments of the present invention and does not limit one or more additional functions, operations, or components. In various embodiments of the present invention, the terms such as "include" or "have" may be construed to denote a certain characteristic, number, step, operation, constituent element, component or a combination thereof, but may not be construed to exclude the existence of or a possibility of addition of one or more other characteristics, numbers, steps, operations, constituent elements, components or<!-- EPO <DP n="10"> --> combinations thereof.</p><p id="p0031" num="0031">Throughout the description and claims of this specification, the words "comprise" and "contain" and variations of the words, for example "comprising" and "comprises", means "including but not limited to", and is not intended to (and does not) exclude other components, integers or steps.</p><p id="p0032" num="0032">Features, integers or characteristics described in conjunction with a particular aspect, embodiment or example of the invention are to be understood to be applicable to any other aspect, embodiment or example described herein unless incompatible therewith.</p><p id="p0033" num="0033">It will be also be appreciated that, throughout the description and claims of this specification, language in the general form of "X for Y" (where Y is some action, activity or step and X is some means for carrying out that action, activity or step) encompasses means X adapted or arranged specifically, but not exclusively, to do Y.</p><p id="p0034" num="0034">In various embodiments of the present invention, the expressions "or" or "at least one of A or/and B" include any or all of combinations of words listed together. For example, the expression "A or B" or "at least A or/and B" includes A, includes B, or includes both A and B.</p><p id="p0035" num="0035">The expression "1", "2", "first", or "second" used in various embodiments of the present invention may modify various components of the various embodiments but does not limit the corresponding components. For example, the above expressions do not limit the sequence and/or importance of the components. The expressions may be used for distinguishing one<!-- EPO <DP n="11"> --> component from other components. For example, a first user device and a second user device indicate different user devices although both are user devices. For example, without departing from the scope of the present invention, a first structural element may be referred to as a second structural element, and the second structural element also may be referred to as the first structural element.</p><p id="p0036" num="0036">When it is stated that a component is "coupled to" or "connected to" another component, the component may be directly coupled or connected to another component or a new component may exist between the component and another component. In contrast, when it is stated that a component is "directly coupled to" or "directly connected to" another component, a new component does not exist between the component and another component.</p><p id="p0037" num="0037">The terms used in describing various embodiments of the present invention are only examples for describing a specific embodiment and do not limit the various embodiments of the present invention. Singular forms are intended to include plural forms unless the context clearly indicates otherwise.</p><p id="p0038" num="0038">Unless defined differently, all terms used herein, which include technical terminologies or scientific terminologies, have the same meaning as that understood by a person skilled in the art to which the present invention pertains. Such terms as those defined in a generally used dictionary are to be interpreted to have the same meanings as the contextual meanings in the relevant field of art, and are not to be interpreted to have ideal or excessively formal meanings unless clearly defined in the present description.<!-- EPO <DP n="12"> --></p><p id="p0039" num="0039">An electronic device according to various embodiments of the present invention may include an image processing function able to encode colour difference data in accordance with pattern of pixels when processing image configured with pixel data, first colour difference data and second colour difference data.</p><p id="p0040" num="0040">For example, the electronic device may be one or a combination of a smart phone, a tablet Personal Computer (PC), a mobile phone, a video phone, an e-book reader, a desktop PC, a laptop PC, a netbook computer, a Personal Digital Assistant (PDA), a camera, and a wearable device such as a Head-Mounted-Device (HMD) including electronic glasses, electronic clothes, and electronic bracelet, an electronic necklace, an electronic appcessary, an electronic tattoo, and a smart watch.</p><p id="p0041" num="0041">According to some embodiments, the electronic device may be a smart home appliance having a projection function. The smart home appliance includes at least one of a TeleVision (TV), a Digital Video Disk (DVD) player, an audio player, an air conditioner, a cleaner, an oven, a microwave oven, a washing machine, an air cleaner, a set-top box, a TV box such as Samsung HomeSync™, Apple TV™, or Google TV™, game consoles, an electronic dictionary, an electronic key, a camcorder, and an electronic frame.</p><p id="p0042" num="0042">According to some embodiments, the electronic device may include at least one of various types of medical devices such as Magnetic Resonance Angiography (MRA), Magnetic Resonance Imaging (MRI), Computed Tomography (CT), a scanner, an ultrasonic device and the like), a navigation device, a Global Positioning System (GPS) receiver, an Event Data Recorder (EDR), a Flight Data Recorder (FDR), a vehicle infotainment device, electronic equipment for a<!-- EPO <DP n="13"> --> ship such as a navigation device or a gyro compass, avionics, a security device, a head unit for a vehicle, an industrial or home robot, an Automatic Teller Machine (ATM) of financial institutions, and a Point Of Sale (POS) device of shops.</p><p id="p0043" num="0043">According to some embodiments, the electronic device may include at least one of furniture or a part of a building/structure, an electronic board, an electronic signature receiving device, a projector, and various types of measuring devices such as a water meter, an electricity meter, a gas meter, and a radio wave meter including a projection function. The electronic device according to various embodiments of the present invention may be one or a combination of the above- described various devices, and may be a flexible device. It is apparent to those skilled in the art that the electronic device according to various embodiments of the present invention is not limited to the above- described devices.</p><p id="p0044" num="0044">Hereinafter, the term "user" used in various embodiments may refer to a person who uses the electronic device or a device such as an artificial intelligence device which uses an electronic device.</p><p id="p0045" num="0045"><figref idrefs="f0001">FIG. 1</figref> illustrates a network environment 100 including an electronic device 101 according to various embodiments of the present invention. Referring to <figref idrefs="f0001">FIG. 1</figref>, the electronic device 101 includes a bus 110, a processor 120, a memory 130, an input/output interface 140, a display 150, a communication interface 160, and an image-processing module 170.</p><p id="p0046" num="0046">The bus 110 is a circuit connecting and transmitting communication between the above-described components.<!-- EPO <DP n="14"> --></p><p id="p0047" num="0047">The processor 120 receives commands from other components of the electronic device 101 such as the memory 130, the input/output interface 140, the display 150, the communication interface 160, or the projecting management module 170 through the bus 110, analyses the received commands, and executes calculation or data processing according to the analysed commands.</p><p id="p0048" num="0048">The memory 130 stores commands or data received from the processor 120 or other components of the electronic device 101, or generated by the processor 120 or other components. The memory 130 includes a kernel 131, middleware 132, an Application Programming Interface (API) 133, and an application 134. Each of the aforementioned programming modules may be implemented by software, firmware, hardware, or a combination of two or more thereof.</p><p id="p0049" num="0049">The kernel 131 controls or manages system resources such as the bus 110, the processor 120, or the memory 130 used for executing an operation or function implemented by the other programming modules. The kernel 131 provides an interface for accessing individual components of the electronic device 101 from the middleware 132, the API 133, or the application 134 to control or manage the components.</p><p id="p0050" num="0050">The middleware 132 performs a relay function of allowing the API 133 or the application 134 to communicate with the kernel 131 to exchange data. In operation requests received from the application 134, the middleware 132 performs a control for the operation requests, such as scheduling or load balancing, by assigning a priority by which system resources of the electronic device 101 can be used, to the application 134.<!-- EPO <DP n="15"> --></p><p id="p0051" num="0051">The API 133 is an interface by which the application 134 can control a function provided by the kernel 131 or the middleware 132 and includes, for example, at least one interface or function for a file control, window control, image processing, or character control.</p><p id="p0052" num="0052">According to various embodiments, the application 134 includes a Short Message Service (SMS)/Multimedia Messaging Service (MMS), email, calendar, alarm application, health care such as for measuring quantity of exercise or blood sugar, or environment information application such as for providing information on barometric pressure, humidity or temperature. Additionally or alternatively, the application 134 may be related to an information exchange between the electronic device 101 and an external electronic device, such as a notification relay application for transferring particular information to the external electronic device or a device management application for managing the external electronic device.</p><p id="p0053" num="0053">For example, the notification relay application includes a function of transmitting notification information generated by another application of the electronic device 101 to the external electronic device 104. Additionally or alternatively, the notification relay application receives notification information from, for example, the external electronic device 104 and provides the received notification information to the user. The device management application manages at least a part of the functions of the external electronic device 104 communicating with the electronic device 101, an application executed in the external electronic device 104, and a service such as call or message service provided by the external electronic device 104.</p><p id="p0054" num="0054">According to various embodiments, the application 134 is designated according to an<!-- EPO <DP n="16"> --> attribute or type of the external electronic device 104. For example, when the external electronic device 104 is an MP3 player, the application 134 is related to music reproduction. Similarly, when the external electronic device 104 is a mobile medical device, the application 134 is related to health care. According to an embodiment, the application 134 includes at least one of an application designated to the electronic device 101 and an application received from an external electronic device, such as the server 106 or electronic device 104.</p><p id="p0055" num="0055">The input/output interface 140 transmits a command or data input from the user through an input/output device such as a sensor, keyboard, or touch screen to the processor 120, the memory 130, the communication interface 160, or the display control module 170 through the bus 110. For example, the input/output interface 140 provides data on a user's touch input through a touch screen to the processor 120, and outputs a command or data received, through the bus 110, from the processor 120, the memory 130, the communication interface 160, or the projecting management module 170 through the input/output device such as a speaker or a display.</p><p id="p0056" num="0056">The display 150 displays various pieces of information to the user.</p><p id="p0057" num="0057">The communication interface 160 connects communication between the electronic device 101 and the external device. For example, the communication interface 160 accesses a network 162 through wireless or wired communication to communicate with the external device. The wireless communication includes at least one of, for example, WiFi, BlueTooth® (BT), Near Field Communication (NFC), a Global Positioning System (GPS), and cellular communication such as Long Term Evolution (LTE), LTE-Advanced (LTE-A), Code Division Multiple Access<!-- EPO <DP n="17"> --></p><p id="p0058" num="0058">(CDMA), Wideband CDMA (WCDMA), Universal Mobile Telecommunications Service (UMTS), WiBro or Global System for Mobile Communications (GSM). The wired communication includes at least one of a Universal Serial Bus (USB), a High Definition Multimedia Interface (HDMI), Recommended Standard 232 (RS-232), and a Plain Old Telephone Service (POTS).</p><p id="p0059" num="0059">According to an embodiment, the network 162 is a telecommunication network including at least one of a computer network, Internet, Internet of Things, and a telephone network. A protocol such as transport layer, data link layer, or physical layer protocol for communication between the electronic device 101 and the external device may be supported by at least one of the application 134, the API 133, the middleware 132, the kernel 131, and the communication interface 160.</p><p id="p0060" num="0060">According to an embodiment, at least one of functions performed by the electronic device 101 can be performed by the external device. For example, the server 106 includes an image processing server module corresponding to the image-processing module 170, and the server 106 can process at least one of functions relating to a user using the image processing server module and transmit result to the electronic device 101.</p><p id="p0061" num="0061"><figref idrefs="f0002">FIG. 2</figref> illustrates a schematic block diagram of an electronic device 200 (e.g., electronic device 101 shown in <figref idrefs="f0001">FIG. 1</figref>) for processing images according various embodiments of the present invention. The electronic device 200 includes a controller 210, a storage 220, a display 230, an input unit 240 and a communication unit 250. Referring to <figref idrefs="f0001">FIG. 1</figref>, the controller 210 may be a processor (e.g., Application Processor (AP), a hardware module, a software module, and<!-- EPO <DP n="18"> --> firmware, which are controlled by the processor, or a combination thereof. According to an embodiment, the controller 210 includes control logic corresponding to at least part of the functions of the image-processing module 170, executed by the processor 120. The controller 210 includes a pixel analysis module 213, a pattern-determining module 215, and a coding module 217 that performs encoding, in order to process the colour image from the image-processing module 170.</p><p id="p0062" num="0062">The controller 210 determines a pixel pattern of an image by analysing pixel data of the image, and encodes the image according to the determined pixel pattern. An example of the image is a video shown on the display 230. The image includes elements such as objects including one or more persons, places or things.</p><p id="p0063" num="0063">The pixel data includes at least one of luminance data, first colour difference data and second colour difference data, which may be YCbCr representing a colour space. In that case, the luminance data may be Y representing a luminance signal. For example, the first colour difference data may be Cb representing the colour difference signal of blue, and the second colour difference data may be Cr representing the colour difference signal of red.</p><p id="p0064" num="0064">According to an embodiment, the controller 210 determines a pixel pattern of an image by analysing one of luminance data, first colour difference data or second colour difference data, as a unit of a block (unit block), and encodes the first colour difference data Cb or second colour difference data Cr, according to the determined pixel pattern. For example, the data used to analyse a pixel pattern as a unit block may be luminance data, and the data encoded according to the determined pixel pattern may be Cb and Cr.<!-- EPO <DP n="19"> --></p><p id="p0065" num="0065">According to an embodiment, in operation of the controller 210, the pixel analysis module 213 analyses luminance data in the size of a unit block and creates pixel analysis data. The pattern-determining module 215 determines a pixel pattern corresponding to the pixel analysis data and outputs flag data of the determined pixel pattern. The encoding module 217 compresses and encodes Cb and Cr data according to the determined pattern, and creates encoded data including the Cb and Cr data compressed and encoded, the flag data, and the luminance data.</p><p id="p0066" num="0066">According to an embodiment, the controller 210 may further include a colour space conversion module which can convert an image format of the image before the process of the pixel analysis module 213. The colour space conversion module receives RGB image as an input image and converts the input image to a YCbCr image.</p><p id="p0067" num="0067">According to an embodiment, the storage 220 stores images encoded by the controller 210. The storage 220 stores flag data in a Table. For example, the flag data may be used to determine a pixel pattern in the controller 210 according to the analysed pixel data. The encoded data including flag data corresponding to the determined pixel pattern may be stored in the storage 220.</p><p id="p0068" num="0068">The flag data may be information with results by analysing a pixel pattern and may be used to analyse the pixel pattern.</p><p id="p0069" num="0069">According to an embodiment, the controller 210 controls the display 230 to display still<!-- EPO <DP n="20"> --> or moving images. The controller 210 receives input images through the input unit 240, such as RGB data or YCbCr data. The input unit 240 includes a colour space converter for converting RGB data to YCbCr 444 data.</p><p id="p0070" num="0070"><figref idrefs="f0003 f0004 f0005 f0006">FIGS. 3A to 3D</figref> illustrate configurations of pixels for an image in an electronic device according to various embodiments of the present invention.</p><p id="p0071" num="0071">Referring to <figref idrefs="f0003 f0004 f0005 f0006">FIGS. 3A to 3D</figref>, images are formed with luminance pixels and chrominance pixels.</p><p id="p0072" num="0072">According to an embodiment, an image may be a component image and may be formed with luminance Y and colour difference signals such as Cb and Cr. The colour resolution of an image may be represented with 4:n:m, in which '4' denotes a sampling rate of a standard frequency 13.5 MHz, for converting analog TV signals into digital signals, and 'n' and 'm' denote the rates of the corresponding colour difference signals, Cb and Cr, respectively. For YCbCr 4nm, '4' denotes the number of Y pixels sorted by a unit block. YCbCr 4nm may be YCbCr 444, YCbCr 422 or YCbCr 420. When YCrCb 4nm is restored, the decoder restores colour difference data Cb and Cr to RGB data by using Y data. According to various embodiments, YCbCr 4nm may be a unit block. As shown in <figref idrefs="f0003 f0004 f0005 f0006">FIGS, 3A to 3D</figref>, 'H' denotes horizontal chrominance resolution, 'V' denotes vertical chrominance resolution and 'T' denotes total chrominance resolution.</p><p id="p0073" num="0073">As shown in <figref idrefs="f0003">FIG. 3A</figref>, <figref idrefs="f0007">4:4:4</figref> indicates that three component channels are identically sampled at 13.5 MHz. The colour resolution of 4:4:4 indicates that the pixels of luminance Y and<!-- EPO <DP n="21"> --> colour difference signals Cb and Cr have the same rate.</p><p id="p0074" num="0074">As shown in <figref idrefs="f0004">FIG. 3B</figref>, <figref idrefs="f0007">4</figref>:<figref idrefs="f0002">2:2</figref> indicates that when the Y signal is sampled every line at 13.5 MHz, the colour difference signals are sampled every two lines as horizontal lines at 6.75 MHz. The colour resolution 4:2:2 indicates that the respective rates of pixels of colour difference signals Cb and Cr are a half of those of luminance Y pixel.</p><p id="p0075" num="0075">As shown in <figref idrefs="f0005">FIG. 3C</figref>, 4:4:0 indicates that when the Y signal is sampled every line at 13.5 MHz, the colour difference signals are sampled every two lines as vertical lines at 6.75 MHz. The colour resolution 4:4:0 indicates that the respective rates of pixels of colour difference signals Cb and Cr are a half of those of luminance Y pixel.</p><p id="p0076" num="0076">As shown in <figref idrefs="f0006">FIG. 3D</figref>, 4:2:0 indicates that when the Y signal is sampled every line at 13.5 MHz, the colour difference signals are sampled every two lines as horizontal lines at 6.75 MHz and every two lines as vertical lines at 6.75 MHz. The colour resolution of 4:2:0 indicates that the respective rates of pixels of colour difference signals Cb and Cr are a quarter of that of luminance Y pixel.</p><p id="p0077" num="0077">An image of a colour resolution shown in <figref idrefs="f0004">FIG. 3B</figref> and/or <figref idrefs="f0005">FIG. 3C</figref> may be less than that of 4:4:4 shown in <figref idrefs="f0003">FIG. 3A</figref>. The electronic device according to various embodiments displays images in various forms. Since the images shown in <figref idrefs="f0004 f0005 f0006">FIGS. 3B to 3D</figref> are formed in such a manner that the rates of pixels of colour difference signals are less than those of the luminance Y, the images may be displayed in a relatively low quality representation according to pixel patterns. For example, user interface images and graphic images may have an abrupt change at the<!-- EPO <DP n="22"> --> boundaries according to objects forming the image. In that case, when the pixels of colour difference signals are reduced with the pixel pattern shown in <figref idrefs="f0004">FIG. 3B</figref> or <figref idrefs="f0005">3C</figref>, the boundaries of the image may not be clearly displayed.</p><p id="p0078" num="0078">The electronic device according to various embodiments of the present invention encodes colour difference signals, shown in <figref idrefs="f0004">FIG. 3B</figref> or <figref idrefs="f0005">3C</figref>, by using a method that determines a pixel pattern of a unit block by analysing pixels in a size of a unit block, and encodes pixels of colour difference signals according to the determined pixel pattern. The controller 210 encodes pixels of a colour difference signal according to a pixel pattern of a unit block, thereby reducing blur at the boundaries of an image displayed on the display 230 and thus displaying the image with sharp boundaries.</p><p id="p0079" num="0079"><figref idrefs="f0007">FIG. 4</figref> illustrates examples of a pattern of pixels in a unit block in an electronic device according to various embodiments of the present invention.</p><p id="p0080" num="0080">Referring to <figref idrefs="f0007">FIG. 4</figref>, pixels of a unit block (e.g., 4 pixels) may have different values (e.g., sizes, and may have unique patterns according to values of the pixels. For example, when an encoding process is performed to convert a unit block of 4 pixels into 2 pixels (e.g., an image of resolution 4:4:4 is encoded to an image of resolution 4:2:2), the controller 210 compares values of pixels of a unit block with a preset threshold, respectively, analyses the comparison results, and determines patterns of pixels in unit blocks.</p><p id="p0081" num="0081">After analysing pixels of a unit block, the controller 210 determines a pattern of pixels that have values greater than a threshold and a pattern of pixels that have values less than the<!-- EPO <DP n="23"> --> threshold, within the unit block. The values of pixels within the unit block may be properly encoded according to the determined pattern. The unit block for analysing patterns may use luminance pixels or colour difference pixels. In an electronic device according to various embodiments of the present invention, luminance pixels are used to determine patterns. The controller 210 determines pixel patterns of a unit block using luminance pixels and encodes colour difference pixels of a unit block corresponding to the determined pattern.</p><p id="p0082" num="0082">Reference numerals 411 to 415 of <figref idrefs="f0007">FIG. 4</figref> are examples of a pattern as pixels with similar values are located in the top and bottom in a unit block. In that case, the controller 210 creates flag data pattern 0. The controller 210 creates first encoding data (e.g., CB1, CR1) by calculating (a+b)/2 from colour difference pixels of a corresponding unit block and second encoding data (e.g., CB2, CR2) by calculating (c+d)/2 from colour difference pixels of a corresponding unit block.</p><p id="p0083" num="0083">Reference numerals 421 and 423 of <figref idrefs="f0007">FIG. 4</figref> are examples of a pattern as pixels with similar values are located in the left-hand side and right-hand side of a unit block. In that case, the controller 210 creates flag data pattern 1. The controller 210 creates first encoding data (e.g., CB1, CR1) by calculating (a+c)/2 from colour difference pixels of a corresponding unit block and second encoding data (e.g., CB2, CR2) by calculating (b+d)/2 from colour difference pixels of a corresponding unit block.</p><p id="p0084" num="0084">Reference numerals 431 and 433 of <figref idrefs="f0007">FIG. 4</figref> are examples of a pattern as pixels with similar values are diagonally located in a unit block. In that case, the controller 210 creates flag data pattern 2. The controller 210 creates first encoding data (e.g., CB1, CR1) by calculating<!-- EPO <DP n="24"> --> (a+d)/2 from colour difference pixels of a corresponding unit block and second encoding data (e.g., CB2, CR2) by calculating (b+c)/2 from colour difference pixels of a corresponding unit block.</p><p id="p0085" num="0085">Reference numerals 441 to 447 of <figref idrefs="f0007">FIG. 4</figref> are examples of a pattern as three of the four pixels with a value and the other pixel with another value are located in a unit block. As shown at reference numeral 441, when one of the four pixels, a, has a value, and the other three, b, c, and d, have another value, the controller 210 creates flag data pattern 3. The controller 210 creates first encoding data (e.g., CB1, CR1) by the value of a pixel from colour difference pixels of a corresponding unit block and second encoding data (e.g., CB2, CR2) by calculating (b+c+d)/3 from colour difference pixels of a corresponding unit block.</p><p id="p0086" num="0086">As shown at reference numeral 443, when one of the four pixels, b, has a value, and the other three, a, c, and d, have another value, the controller 210 creates flag data pattern 4. The controller 210 creates first encoding data (e.g., CB1, CR1) by the value of pixel b from colour difference pixels of a corresponding unit block and second encoding data (e.g., CB2, CR2) by calculating (a+c+d)/3 from colour difference pixels of a corresponding unit block. As shown at reference numeral 447, when one of the four pixels, c, has a value, and the other three, a, b, and d, have another value, the controller 210 creates flag data pattern 6.</p><p id="p0087" num="0087">The controller 210 creates first encoding data (e.g., CB1, CR1) by the value of pixel c from colour difference pixels of a corresponding unit block and second encoding data (e.g., CB2, CR2) by calculating (a+b+d)/3 from colour difference pixels of a corresponding unit block. As shown at reference numeral 445, when one of the four pixels, d, has a value, and the other three,<!-- EPO <DP n="25"> --> a, b, and c, have another value, the controller 210 creates flag data pattern 5. The controller 210 creates first encoding data (e.g., CB1, CR1) by the value of pixel d from colour difference pixels of a corresponding unit block and second encoding data (e.g., CB2, CR2) by calculating (a+b+c)/3 from colour difference pixels of a corresponding unit block.</p><p id="p0088" num="0088">According to another embodiment, when the pixel values of the unit block have the patterns indicated by reference numerals 441 to 447, the controller 210 creates first encoding data (e.g., CB1 and CR1) by calculating the average of three pixels with a value and sets the other pixel's value to second encoding data (e.g., CB2, CR2).</p><p id="p0089" num="0089"><figref idrefs="f0008">FIG. 5</figref> is a block diagram of an image-processing module for analysing values of pixels in a unit block, determining the pixel pattern based on the pixel analyses, and encoding colour difference data according to the determined pixel pattern in an electronic device according to various embodiments of the present invention.</p><p id="p0090" num="0090">Referring to <figref idrefs="f0008">FIG. 5</figref>, the input may be an RGB image or a YCbCr image. When an RGB image is input, a colour space conversion module 211 converts the RGB image into a YCbCr image. To this end, the colour space conversion module 211 performs colour space conversion based on the following Equation 1). <maths id="math0001" num="(1)"><math display="block"><mrow><mtable columnalign="left"><mtr><mtd><mi mathvariant="normal">Y</mi><mo>=</mo><mn mathvariant="normal">0.29900</mn><mo>*</mo><mi mathvariant="normal">R</mi><mo>+</mo><mn mathvariant="normal">0.58700</mn><mo>*</mo><mi mathvariant="normal">G</mi><mo>+</mo><mn mathvariant="normal">0.11400</mn><mo>*</mo><mi mathvariant="normal">B</mi></mtd></mtr><mtr><mtd><mtable><mtr><mtd><mrow><mi mathvariant="normal">Cb</mi><mo>=</mo><mn mathvariant="normal">0.16874</mn><mo>*</mo><mi mathvariant="normal">R</mi><mo>+</mo><mn mathvariant="normal">0.33126</mn><mo>*</mo><mi mathvariant="normal">G</mi><mo>+</mo><mn mathvariant="normal">0.50000</mn><mo>*</mo><mi mathvariant="normal">B</mi></mrow></mtd></mtr><mtr><mtd><mi mathvariant="normal">Cr</mi><mo>=</mo><mn mathvariant="normal">0.50000</mn><mo>*</mo><mi mathvariant="normal">R</mi><mo>+</mo><mn mathvariant="normal">0.41869</mn><mo>*</mo><mi mathvariant="normal">G</mi><mo>+</mo><mn mathvariant="normal">0.08131</mn><mo>*</mo><mi mathvariant="normal">B</mi></mtd></mtr></mtable></mtd></mtr></mtable></mrow></math><img id="ib0001" file="imgb0001.tif" wi="93" he="24" img-content="math" img-format="tif"/></maths><!-- EPO <DP n="26"> --></p><p id="p0091" num="0091">The colour space conversion module 211 performs colour conversion from the RGB image into a YCbCr image of 4:4:4 resolution, as shown in <figref idrefs="f0009">FIG. 6</figref>.</p><p id="p0092" num="0092"><figref idrefs="f0009">FIG. 6</figref> illustrates a configuration of pixels in a unit block of a YCbCr image by a colour space conversion module 211 in an electronic device according to various embodiments of the present invention. A YCbCr image of 4:4:4 resolution has a mapping structure with Y, Cb and Cr pixels in a unit block (e.g., 4 pixels). The colour space conversion module 211 analyses values of Y, Cb and Cr pixels based on a unit block, determines a pixel pattern, and encodes pixels according to the pixel pattern. During the process, since the Y most affects the recovery of the image, it is preferable that the pixel size remains unchanged in an encoding process. In addition, pixels of a unit block for analysing pixel values may use the Y pixel.</p><p id="p0093" num="0093">Referring back to <figref idrefs="f0008">FIG. 5</figref>, the pixel analysis module 213 analyses pixel values of a unit block by using YCbCr images output from or input to the colour space conversion module 211.</p><p id="p0094" num="0094"><figref idrefs="f0010 f0011 f0012">FIGS. 7A to 7C</figref> illustrate a process of analysing pixel values of a unit block in an electronic device according to various embodiments of the present invention.</p><p id="p0095" num="0095"><figref idrefs="f0010">FIG. 7A</figref> illustrates an arrangement of pixels in a unit block, and may be a configuration of a unit block of luminance pixels. <figref idrefs="f0011">FIG. 7B</figref> illustrates a method of operating pixels of a unit block shown in <figref idrefs="f0010">FIG. 7A</figref> by the pixel analysis module 213 illustrated in <figref idrefs="f0008">FIG. 5</figref>.</p><p id="p0096" num="0096">For pixels a and b indicated by reference numeral 721 in <figref idrefs="f0011">FIG. 7B</figref>, the pixel analysis module 213 calculates a difference between values of pixels a and b, compares the absolute value<!-- EPO <DP n="27"> --> of the difference with a threshold, and outputs the comparison result as '0' or '1.' For pixels c and d indicated by reference numeral 723 in <figref idrefs="f0011">FIG. 7B</figref>, the pixel analysis module 213 calculates a difference between values of pixels c and d, compares the absolute value of the difference with a threshold, and outputs the comparison result as '0' or '1.' For pixels a and c indicated by reference numeral 725 in <figref idrefs="f0011">FIG. 7B</figref>, the pixel analysis module 213 calculates a difference between values of pixels a and c, compares the absolute value of the difference with a threshold, and outputs the comparison result as '0' or '1.' For pixels b and d indicated by reference numeral 727, the pixel analysis module 213 calculates a difference between values of pixels b and d, compares the absolute value of the difference with a threshold, and outputs the comparison result as '0' or '1.' For pixels a and d indicated by reference numeral 731, the pixel analysis module 213 calculates a difference between values of pixels a and d, compares the absolute value of the difference with a threshold, and outputs the comparison result as '0' or '1.' For pixels b and c indicated by reference numeral 733, the pixel analysis module 213 calculates a difference between values of pixels b and c, compares the absolute value of the difference with a threshold, and outputs the comparison result as '0' or '1.'</p><p id="p0097" num="0097">The pixel analysis module 213 includes six absolute value calculators and the corresponding comparators. Each of the absolute value calculators may use same threshold, and according to another embodiment, the thresholds of the absolute value calculators may be different form each other. The absolute value calculators and the corresponding comparators analyse pixel data of the respective pixels based on the following Equation (2) and output the pixel data as shown in <figref idrefs="f0012">FIG. 7C</figref>. <maths id="math0002" num="(2)"><math display="block"><mrow><mi>Abs</mi><mo>⁢</mo><mfenced separators=""><mi>Ya</mi><mo>-</mo><mi>Yb</mi></mfenced><mo>&gt;</mo><mi>threshold value</mi></mrow></math><img id="ib0002" file="imgb0002.tif" wi="53" he="6" img-content="math" img-format="tif"/></maths><!-- EPO <DP n="28"> --> <maths id="math0003" num=""><math display="block"><mrow><mtable><mtr><mtd><mi>Abs</mi><mo>⁢</mo><mfenced separators=""><mi>Yc</mi><mo>-</mo><mi>Yd</mi></mfenced><mo>&gt;</mo><mi>threshold value</mi></mtd></mtr><mtr><mtd><mi>Abs</mi><mo>⁢</mo><mfenced separators=""><mi>Ya</mi><mo>-</mo><mi>Yc</mi></mfenced><mo>&gt;</mo><mi>threshold value</mi></mtd></mtr><mtr><mtd><mi>Abs</mi><mo>⁢</mo><mfenced separators=""><mi>Yb</mi><mo>-</mo><mi>Yd</mi></mfenced><mo>&gt;</mo><mi>threshold value</mi></mtd></mtr><mtr><mtd><mi>Abs</mi><mo>⁢</mo><mfenced separators=""><mi>Ya</mi><mo>-</mo><mi>Yd</mi></mfenced><mo>&gt;</mo><mi>threshold value</mi></mtd></mtr><mtr><mtd><mi>Abs</mi><mo>⁢</mo><mfenced separators=""><mi>Yb</mi><mo>-</mo><mi>Yc</mi></mfenced><mo>&gt;</mo><mi>threshold value</mi></mtd></mtr></mtable></mrow></math><img id="ib0003" file="imgb0003.tif" wi="125" he="52" img-content="math" img-format="tif"/></maths></p><p id="p0098" num="0098">The analysed pixel data calculated by Equation (2) has a data structure of 6 bits shown in <figref idrefs="f0012">FIG. 7C</figref>.</p><p id="p0099" num="0099"><figref idrefs="f0013">FIG. 8</figref> illustrates examples of pattern categorization corresponding to analysed pixel data of 6 bits output from the pixel analysis module 213. As shown in <figref idrefs="f0013">FIG. 8</figref>, although values of analysed pixel data differ from each other, their patterns are identical to each other. For example, pattern 0 of the patterns shown in <figref idrefs="f0007">FIG. 4</figref> is created when analysed pixel data are 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, and 15. Pattern 1 is created when analysed pixel data are 16, 17, 18, 19, 32, 33, 34, 35, 48, 49, 50, and 51. Pattern 2 is created when analysed pixel data are 20, 24, 28, 36, 40, 44, 52, 56, and 60. In addition, when pixel data of a unit block are 21, 23, 26, 27, 29, 30, 31, 38, 39, 41, 43, 45, 46, 47, 53, 54, 55, 58, 59, 51, 62, and 63, the pixel data is classified as the other patterns except of Patterns 0, 1, and 2 shown in <figref idrefs="f0007">FIG. 4</figref>.</p><p id="p0100" num="0100">Referring back to <figref idrefs="f0008">FIG. 5</figref>, the pattern-determining module 215 determines a pixel pattern of a unit block by using analysed pixel data output from the pixel analysis module 213. When values of analysed pixel data differ from each other but their pixel pattern has the same structure, the pixel data is determined as having the same flag data because when the colour difference data is encoded, the encoded data can be stored along with the pattern information.<!-- EPO <DP n="29"> --></p><p id="p0101" num="0101">For example, when the analysed pixel data are 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, and 15, the data can be set as the flag data of the same value. To this end, the storage 220 includes a flag table where values of analysed pixel data are mapped to pixel patterns as shown in <figref idrefs="f0013">FIG. 8</figref>. When the analysed pixel data is entered, the pattern- determining module 215 determines flag data of a pixel pattern corresponding to the analysed pixel data. The flag data may be determined to have a size of 4 bits. In that case, the number of pixel patterns of a unit block may be 16. Although the embodiment is described based on the flag data of 4 bits, it should be understood that the size of flag data may increase when the pixel pattern is subdivided.</p><p id="p0102" num="0102">The encoding module 217 encodes colour difference data according to the determined pixel pattern, and creates encoded data including the encoded colour difference data, luminance data and flag data. The encoding module 217 includes a colour difference encoding unit for encoding colour difference data CB and CR of a unit block corresponding to the pixel patterns, a flag inserting unit for inserting flag data to the encoded colour difference data, and a combination unit for combining the encoded colour difference data and the luminance data of a unit block.</p><p id="p0103" num="0103">The encoding module 217 encodes colour difference data according to the determined pixel pattern. The process of encoding colour difference data may be performed based on a unit block. For example, if a unit block is formed with four pixels, the encoding module 217 encodes colour difference pixel of four pixels, Cba-Cbd and Cra-Crd, to colour difference pixel of two pixels, CB1-CB2 and CR1-CR2. This encoding scheme takes the averages of pixel values of the same pattern and then creates encoded colour difference data. For example, when pixels have pattern 0, the flag data is "0000."<!-- EPO <DP n="30"> --></p><p id="p0104" num="0104">The encoding module 217 calculates the average of colour difference pixels Cba and Cbb and the average of colour difference pixels, Cra and Crb, and creates the encoded colour difference data CB1 and CR1, respectively. The encoding module 217 also calculates the average of colour difference pixels Cbc and Cbd and the average of colour difference pixels, Crc and Crd, and creates the encoded colour difference data CB2 and CR2, respectively. Flag data is then inserted into the encoded colour difference data CB1-CB2 and CR1-CR2. In that case, the colour difference data may be configured as shown in the following Table 1.
<tables id="tabl0001" num="0001"><table frame="all"><title><u>Table 1</u></title><tgroup cols="9"><colspec colnum="1" colname="col1" colwidth="10mm"/><colspec colnum="2" colname="col2" colwidth="19mm"/><colspec colnum="3" colname="col3" colwidth="19mm"/><colspec colnum="4" colname="col4" colwidth="19mm"/><colspec colnum="5" colname="col5" colwidth="19mm"/><colspec colnum="6" colname="col6" colwidth="19mm"/><colspec colnum="7" colname="col7" colwidth="19mm"/><colspec colnum="8" colname="col8" colwidth="19mm"/><colspec colnum="9" colname="col9" colwidth="14mm"/><thead><row><entry valign="middle"/><entry valign="middle">b7</entry><entry valign="middle">b6</entry><entry valign="middle">b5</entry><entry valign="middle">b4</entry><entry valign="middle">b3</entry><entry valign="middle">b2</entry><entry valign="middle">b1</entry><entry valign="middle">b0</entry></row></thead><tbody><row><entry valign="middle">B1</entry><entry valign="middle">(a7+b7)/2</entry><entry valign="middle">(a6+b6)/2</entry><entry valign="middle">(a5+b5)/2</entry><entry valign="middle">(a4+b4)/2</entry><entry valign="middle">(a3+b3)/2</entry><entry valign="middle">(a2+b2)/2</entry><entry valign="middle">(a1+b1)/2</entry><entry valign="middle">Flag 3</entry></row><row><entry valign="middle">B2</entry><entry valign="middle">(c7+d7)/2</entry><entry valign="middle">(c6+d6)/2</entry><entry valign="middle">(c5+d5)/2</entry><entry valign="middle">(c4+d4)/2</entry><entry valign="middle">(c3+d3)/2</entry><entry valign="middle">(c2+d2)/2</entry><entry valign="middle">(c1+d1)/2</entry><entry valign="middle">Flag 2</entry></row><row><entry valign="middle">R1</entry><entry valign="middle">(a7+b7)/2</entry><entry valign="middle">(a6+b6)/2</entry><entry valign="middle">(a5+b5)/2</entry><entry valign="middle">(a4+b4)/2</entry><entry valign="middle">(a3+b3)/2</entry><entry valign="middle">(a2+b2)/2</entry><entry valign="middle">(a1+b1)/2</entry><entry valign="middle">Flag 1</entry></row><row><entry valign="middle">R2</entry><entry valign="middle">(c7+d7)/2</entry><entry valign="middle">(c6+d6)/2</entry><entry valign="middle">(c5+d5)/2</entry><entry valign="middle">(c4+d4)/2</entry><entry valign="middle">(c3+d3)/2</entry><entry valign="middle">(c2+d2)/2</entry><entry valign="middle">(c1+d1)/2</entry><entry valign="middle">Flag 0</entry></row></tbody></tgroup></table></tables></p><p id="p0105" num="0105"><figref idrefs="f0014 f0015 f0016">FIGS. 9A to 9C</figref> illustrate a process of configuring encoded data of a unit block in an electronic device according to various embodiments of the present invention. Referring to <figref idrefs="f0014">FIG. 9A</figref>, the encoding module 217 creates encoded data by combining luminance data of a unit block and encoded colour difference data CB and CR. <figref idrefs="f0014 f0015 f0016">FIGS. 9A to 9C</figref> illustrate configurations of encoded data of a unit block. The luminance data remains with pixel data of a unit block of 4<!-- EPO <DP n="31"> --> pixels, the encoded colour difference data CB is converted to encoded colour difference data of two pixels, CB1 and CB2, and encoded colour difference data CR includes encoded colour difference data of two pixels, CR1 and CR2. Flag data as pixel pattern information is inserted into the Least Significant Bit (LSB) of the encoded colour difference data CB1-CB2 and CR1-CR2.</p><p id="p0106" num="0106">As shown in <figref idrefs="f0014">FIG. 9A</figref>, the controller 210 then stores an encoded image in the storage 220 illustrated in <figref idrefs="f0002">FIG. 2</figref>. The storage efficiency of the storage 220 may be enhanced by encoding the colour difference data. The controller 210 transmits the images encoded as shown in <figref idrefs="f0014 f0015 f0016">FIGS. 9A to 9C</figref> to an external device through the communication unit 250 or another module. For example, the controller 210 includes a graphic processor that transmits the encoded image to the display 230. In that case, the transmission rate may be enhanced by encoding the image.</p><p id="p0107" num="0107">As shown in <figref idrefs="f0014">FIG. 9A</figref>, the encoded image may be created as colour difference data are encoded, as a unit block, according to the pixel pattern. When the image includes outlines or boundaries of objects, the pixel pattern may be detected in various forms according to objects. The controller 210 determines a pixel pattern corresponding to the outlines or boundaries of objects in the image, and encodes colour difference data according to the determined pixel pattern. When the controller 210 decodes an image formed with the structure shown in <figref idrefs="f0014 f0015 f0016">FIGS. 9A to 9C</figref>, the controller 210 verifies a pixel pattern according to flag data and decodes pixels according to the verified pixel pattern.</p><p id="p0108" num="0108">For example, when pattern flag is "0000", the controller 210 restores values of pixels a and b of a unit block to CB1 and CR1, and values of pixels c and d of a unit block to CB2 and<!-- EPO <DP n="32"> --></p><p id="p0109" num="0109">CR2. When pattern flag is "0001", the controller 210 restores values of pixels a and c of a unit block to CB1 and CR1, and values of pixels b and d of a unit block to CB2 and CR2. The controller 210 decodes the colour difference data of a unit block to data of 4 pixels by using the encoded colour difference data that correspond to the pixel patterns respectively.</p><p id="p0110" num="0110">When the loss of the quality of image is imperceptible (i.e., visually lossless), part of the luminance data, such as the LSB, is also used to store additional information. Unlike the configuration shown <figref idrefs="f0014">FIG. 9A</figref>, as shown in <figref idrefs="f0015">FIGS. 9B</figref> and <figref idrefs="f0016">9C</figref>, additional information may be stored in part of colour difference data and luminance data.</p><p id="p0111" num="0111">Referring to <figref idrefs="f0015">FIG. 9B</figref>, flag data may be stored in the LSB location of the colour difference data and luminance data. The storage order of bits does not need to be the order shown in <figref idrefs="f0015">FIG. 9B</figref>. That is, the encoder for analysing a pixel pattern and the decoder for decoding the pattern may store data in a storage order of bits that are preset as a rule.</p><p id="p0112" num="0112"><figref idrefs="f0016">FIG. 9C</figref> illustrates a structure of encoded data that is identical to that of <figref idrefs="f0015">FIG. 9B</figref> except that the order of bits differs from that of <figref idrefs="f0015">FIG. 9B</figref>. The flags between <figref idrefs="f0016">FIG. 9C</figref> and <figref idrefs="f0015">FIG. 9B</figref> are identical to each other in that they replace LSB values of colour difference data, but are different from each other in terms of their storage orders. Flags including pixel pattern information may be placed before every byte, as shown in <figref idrefs="f0016">FIG. 9C</figref>, or alternatively may all be placed before the entire bit sequence. This arrangement simplifies the design of an encoder or decoder.</p><p id="p0113" num="0113"><figref idrefs="f0017">FIG. 10</figref> illustrates a process of encoding and decoding images in an electronic device according to various embodiments of the present invention.<!-- EPO <DP n="33"> --></p><p id="p0114" num="0114">Referring to <figref idrefs="f0017">FIG. 10</figref>, the controller 210 includes the coder 217 (also referred to as a coding module or an encoding module) for encoding an image or colour images, and a decoder 293 (also referred to as a decoding module or a decoding module) for decoding the encoded images. The embodiment of <figref idrefs="f0017">FIG. 10</figref> may be an image-processing module 170 shown in <figref idrefs="f0001">FIG. 1</figref>. The image-processing module 170 may be included in the controller 210 or may be configured as a separate component. The colour image encoded or decoded may be a YCbCr image.</p><p id="p0115" num="0115">When the colour space conversion module 211 receives an RGB image, the colour space conversion module 211 coverts the RGB image to a YCbCr image with 4:4:4 resolution, such as by using Equation (1) or a conversion scheme set by the corresponding rule. The pixel analysis module 213 receives the 4:4:4 YCbCr image from the colour space conversion module 211 or a 4:4:4 YCbCr image directly from outside the space conversion module 211.</p><p id="p0116" num="0116">The pixel analysis module 213 analyses luminance pixels of a unit block from the 4:4:4 YCbCr image and outputs the analysed pixel data. The pixel analysis module 213 obtains a difference of pixels ab, cd, ac, bd, ad, and bc (4C2=6) from luminance pixels of 4 pixels (a-d), compares the absolute values of the differences with a threshold, and outputs the comparison results as analysed pixel data. The analysed pixel data may be data of 6 bits.</p><p id="p0117" num="0117">The pattern-determining module 215 analyses the analysed pixel data and determines a pixel pattern. For example, the storage 220 includes a flag table for pixel patterns corresponding to the analysed pixel data and the pattern-determining module 215 selects the appropriate flag data of the corresponding pixel pattern from the flag table according to the analysed pixel data.<!-- EPO <DP n="34"> --></p><p id="p0118" num="0118">The encoding module 217 creates encoded colour difference data CB1-CB2 and CR1-CR2 of colour difference data Cb and Cr according to the determined pixel pattern. The encoded colour difference data CB1-CB2 and CR1-CR2 is used to calculate an average of pixels that have similar pixel values according to pixel patterns and the average may be determined as the encoded colour difference data. The flag data determined by the pattern-determining module 215 is inserted to a lower bit (e.g. the least significant bit) of the encoded colour difference data. The encoding module 217 then combines the encoded colour difference data (including flag data) and corresponding luminance data of a unit block, and creates the encoded data as shown in <figref idrefs="f0014 f0015 f0016">FIGS. 9A to 9C</figref>. The encoding module 217 outputs the last encoded data to other modules or external devices through the communication unit 250. The encoding module 217 may also store the last encoded data in the storage 220.</p><p id="p0119" num="0119">The images encoded as illustrated in <figref idrefs="f0014 f0015 f0016">FIGS. 9A to 9C</figref> are displayed as follows. The controller 210 or the display 230 with a decoder decodes encoded images. In the following description, for the sake of convenience, the decoding process is explained based on the controller 210. The controller 210 accesses encoded images in the storage 220 or receives encoded images from other modules or external devices. When the pattern verifying module 291 receives the encoded image, the pattern verifying module 291 analyses flag data from the encoded image shown in <figref idrefs="f0014 f0015 f0016">FIGS. 9A to 9C</figref> and verifies a pixel pattern.</p><p id="p0120" num="0120">The decoding module 293 decodes corresponding pixels according to the verified pixel pattern. The colour difference data of the encoded image may be created as data of 4 pixels is encoded to 2 pixels. The decoding module 293 restores the encoded colour difference data of 2<!-- EPO <DP n="35"> --> pixels to colour difference data of 4 pixels. When the decoding module 293 decodes colour difference data Cb and Cr, the decoding module 293 decodes 4 pixel values according to pixel patterns. For example, when an encoded image is pattern 0, the decoding module 293 restores Cba and Cbb pixels to encoded CB1 data, Cbc and Cbd pixels to encoded CB2 data, Cra and Crb pixels to encoded CR1 data, and Crc and Crd pixels to encoded CR2 data. When an encoded image is pattern 1, the decoding module 293 restores Cba and Cbc pixels to encoded CB1 data, Cbb and Cbd pixels to encoded CB2 data, Cra and Crc pixels to encoded CR1 data, and Crb and Crd pixels to encoded CR2 data.</p><p id="p0121" num="0121">The decoded YCbCr image may be displayed on the display 230. In addition, when the YCbCr image is converted to an RGB image, the colour space conversion module 295 converts the YCbCr image to an RGB image based on the following Equation (3). <maths id="math0004" num="(3)"><math display="block"><mrow><mtable columnalign="left"><mtr><mtd><mi mathvariant="normal">R</mi><mo>=</mo><mi mathvariant="normal">Y</mi><mo>+</mo><mn mathvariant="normal">1.402</mn><mo>*</mo><mi mathvariant="normal">Cr</mi></mtd></mtr><mtr><mtd><mi mathvariant="normal">G</mi><mo>=</mo><mi mathvariant="normal">Y</mi><mo>-</mo><mn mathvariant="normal">0.334</mn><mo>*</mo><mi mathvariant="normal">Cb</mi><mo>-</mo><mn mathvariant="normal">0.713</mn><mo>*</mo><mi mathvariant="normal">Cr</mi></mtd></mtr><mtr><mtd><mi mathvariant="normal">B</mi><mo>=</mo><mi mathvariant="normal">Y</mi><mo>+</mo><mn mathvariant="normal">1.772</mn><mo>*</mo><mi mathvariant="normal">Cr</mi></mtd></mtr></mtable></mrow></math><img id="ib0004" file="imgb0004.tif" wi="124" he="33" img-content="math" img-format="tif"/></maths></p><p id="p0122" num="0122">As described above, the electronic device according to various embodiments of the present invention performs analysis based on luminance data of an image and encodes colour difference data, while maintaining the luminance data. The electronic device according to various embodiments analyses luminance data of an image along with colour difference data, or performs analysis in linear combination with weights. When the loss of the quality of image by luminance data is imperceptible (i.e., visually lossless), the luminance data may be also included<!-- EPO <DP n="36"> --> in objects to be encoded. When image data is encoded by combining the luminance data and colour difference data or by using colour difference data, patterns that are from among the combinations shown in <figref idrefs="f0013">FIG. 8</figref> but do not correspond to patterns shown in <figref idrefs="f0007">FIG. 4</figref> may be encoded.</p><p id="p0123" num="0123"><figref idrefs="f0018">FIG. 11</figref> is a block diagram of an electronic device according to various embodiments of the present invention.</p><p id="p0124" num="0124">The electronic device 1101 configures all or a part of the electronic device 101 illustrated in <figref idrefs="f0001">FIG. 1</figref>. Referring to <figref idrefs="f0018">FIG. 11</figref>, the electronic device 1101 includes one or more Application Processors (APs) 1110, a communication module 1120, a Subscriber Identification Module (SIM) card 1124, a memory 1130, a sensor module 1140, an input device 1150, a display module 1160, an interface 1170, an audio module 1180, a camera module 1191, a power- managing module 1195, a battery 1196, an indicator 1197, and a motor 1198.</p><p id="p0125" num="0125">The AP 1110 operates an Operating System (OS) or an application program so as to control a plurality of hardware or software component elements connected to the AP 1110 and executes various data processing and calculations including multimedia data. The AP 1110 may be implemented by a System on Chip (SoC). According to an embodiment, the processor 1110 may further include a Graphic Processing Unit (GPU).</p><p id="p0126" num="0126">The AP 1110 includes the image- processing module 170, the elements of <figref idrefs="f0002">FIG. 2</figref> for encoding the colour difference data according to the pixel pattern in a colour image of 4:4:4 colour resolution, and the elements of <figref idrefs="f0017">FIG. 10</figref> for restoring the encoded colour difference data according to the pixel pattern.<!-- EPO <DP n="37"> --></p><p id="p0127" num="0127">The communication module 1120 transmits/receives data in communication between different electronic devices such as the electronic device 104 and the server 106 connected to the electronic device 1101 through a network. In <figref idrefs="f0018">FIG. 11</figref>, the communication module 1120 includes a cellular module 1121, a Wi-Fi module 1123, a BlueTooth® (BT) module 1125, a GPS module 1127, a Near Field Communication (NFC) module 1128, and a Radio Frequency (RF) module 1129.</p><p id="p0128" num="0128">The cellular module 1121 provides a voice, a call, a video call, SMS, or an Internet service through a communication network. The cellular module 1121 distinguishes and authenticates electronic devices within a communication network by using a Subscriber Identification Module (SIM card 1124). According to an embodiment, the cellular module 1121 performs at least some of the functions that can be provided by the AP 1110, such as the multimedia control functions.</p><p id="p0129" num="0129">According to an embodiment, the cellular module 1121 includes a Communication Processor (CP). The cellular module 1121 may be implemented by, for example, an SoC. Although the components such as the cellular module 1121, the memory 1130, and the power-managing module 1195 are illustrated as components separate from the AP 1110 in <figref idrefs="f0018">FIG. 11</figref>, the AP 1110 includes at least some of the aforementioned components. According to an embodiment, the AP 1110 or the cellular module 1121 loads a command or data received from at least one of a non-volatile memory and other components connected to each of the AP 1110 and the cellular module 1121 to a volatile memory and processes the loaded command or data. The AP 1110 or the cellular module 1121 stores data received from at least one of other components or generated<!-- EPO <DP n="38"> --> by at least one of other components in a non-volatile memory.</p><p id="p0130" num="0130">Each of the Wi-Fi module 1123, the BT module 1125, the GPS module 1127, and the NFC module 1128 includes, for example, a processor for processing data transmitted/received through the corresponding module. Although the cellular module 1121, the Wi-Fi module 1123, the BT module 1125, the GPS module 1127, and the NFC module 1128 are illustrated as blocks separate from each other in <figref idrefs="f0014 f0015 f0016">FIG. 9</figref>, at least two of the cellular module 1121, the Wi-Fi module 1123, the BT module 1125, the GPS module 1127, and the NFC module 1128 may be included in one Integrated Chip (IC) or one IC package according to one embodiment. For example, at least some of the processors corresponding to the cellular module 1121, the Wi-Fi module 1123, the BT module 1125, the GPS module 1127, and the NFC module 1128 may be implemented by one SoC.</p><p id="p0131" num="0131">The RF module 1129 transmits/receives data such as an RF signal. The RF module 1129 includes, for example, a transceiver, a Power Amp Module (PAM), a frequency filter, and a Low Noise Amplifier (LNA). The RF module 1129 may further include a component for transmitting/receiving electronic waves over a free air space in wireless communication, such as a conductor or a conducting wire. Although the cellular module 1121, the WiFi module 1123, the BT module 1125, the GPS module 1127, and the NFC module 1128 share one RF module 1129 in <figref idrefs="f0018">FIG. 11</figref>, at least one of the modules may transmit/receive an RF signal through a separate RF module according to one embodiment.</p><p id="p0132" num="0132">The SIM card 1124 is inserted into a slot formed in a particular portion of the electronic device, and includes unique identification information such as an Integrated Circuit Card<!-- EPO <DP n="39"> --> IDentifier (ICCID) or subscriber information such as an International Mobile Subscriber Identity (IMSI).</p><p id="p0133" num="0133">The memory 1130 includes an internal memory 1132 or an external memory 1134. The internal memory 1132 includes, for example, at least one of a volatile memory such as a Random Access Memory (RAM), a dynamic RAM (DRAM), a static RAM (SRAM), and a synchronous dynamic RAM (SDRAM), and a non-volatile Memory such as a Read Only Memory (ROM), a One- Time Programmable ROM (OTPROM), a Programmable ROM (PROM), an Erasable and Programmable ROM (EPROM), an Electrically Erasable and Programmable ROM (EEPROM), a mask ROM, a flash ROM, a NAND flash memory, and a NOR flash memory.</p><p id="p0134" num="0134">According to an embodiment, the internal memory 1132 may be a Solid State Drive (SSD). The external memory 1134 may further include a flash drive such as a Compact Flash (CF), a Secure Digital (SD), a Micro Secure Digital (Micro-SD), a Mini Secure Digital (Mini-SD), an extreme Digital (xD), or a memory stick. The external memory 1134 may be functionally connected to the electronic device 1101 through various interfaces. According to an embodiment, the electronic device 1101 may further include a storage device such as a hard drive.</p><p id="p0135" num="0135">The sensor module 1140 measures a physical quantity or detects an operation state of the electronic device 101, and converts the measured or detected information to an electronic signal. The sensor module 1140 includes a gesture sensor 1140A, a gyro sensor 1140B, an atmospheric pressure (barometric) sensor 1140C, a magnetic sensor 1140D, an acceleration sensor 1140E, a grip sensor 1140F, a proximity sensor 1140G, a colour sensor 1140H (for example, Red, Green,<!-- EPO <DP n="40"> --> and Blue (RGB) sensor) 1140H, a biometric sensor 1140I, a temperature/humidity sensor 1140J, an illumination (light) sensor 1140K, and a Ultra Violet (UV) sensor 1140M.</p><p id="p0136" num="0136">Additionally or alternatively, the sensor module 1140 may include an E-nose sensor, an Electromyography (EMG) sensor, an Electroencephalogram (EEG) sensor, an Electrocardiogram (ECG) sensor, an InfraRed (IR) sensor, an iris sensor, and a fingerprint sensor (not illustrated). The sensor module 1140 may further include a control circuit for controlling one or more sensors included in the sensor module 1140.</p><p id="p0137" num="0137">The input device 1150 includes a touch panel 1152, a (digital) pen sensor 1154, a key 1156, and an ultrasonic input device 1158. For example, the touch panel 1152 recognizes a touch input in at least one of a capacitive, resistive, infrared, and acoustic wave type. The touch panel 1152 may further include a control circuit. In the capacitive type, the touch panel 1152 can recognize proximity as well as a direct touch. The touch panel 1152 may further include a tactile layer that provides a tactile reaction to the user.</p><p id="p0138" num="0138">The (digital) pen sensor 1154 may be implemented, for example, using a method identical or similar to a method of receiving a touch input of the user, or using a separate recognition sheet. The key 1156 includes, for example, a physical button, an optical key, or a key pad. The ultrasonic input device 1158 detects an acoustic wave by a microphone 1188 of the electronic device 1101 through an input means generating an ultrasonic signal to identify data and performs wireless recognition.</p><p id="p0139" num="0139">According to an embodiment, the electronic device 1101 receives a user input from an<!-- EPO <DP n="41"> --> external device connected to the electronic device 1101 by using the communication module 1120.</p><p id="p0140" num="0140">The display module 1160 includes a panel 1162, a hologram unit 1164, and a projector 1166. The panel 1162 may be, for example, a Liquid Crystal Display (LCD) or an Active Matrix Organic Light Emitting Diode (AM-OLED), and is implemented to be flexible, transparent, or wearable. The panel 1162 may be configured by the touch panel 1152 and one module. The hologram unit 1164 projects a stereoscopic image in the air by using interference of light. The projector 1166 projects light on a screen to display an image, wherein the screen may be located inside or outside the electronic device 1101. According to an embodiment, the display 1160 may further include a control circuit for controlling the panel 1162, the hologram unit 1164, and the projector 1166.</p><p id="p0141" num="0141">The interface 1170 includes, for example, a High-Definition Multimedia Interface (HDMI) 1172, a Universal Serial Bus (USB) 1174, an optical interface 1176, and a D-subminiature (D-sub) 1178, and is included in the communication interface 160 illustrated in <figref idrefs="f0001">FIG. 1</figref>. Additionally or alternatively, the interface 1190 may include a Mobile High-definition Link (MHL) interface, a Secure Digital (SD) card/Multi-Media Card (MMC), or an Infrared Data Association (IrDA) standard interface.</p><p id="p0142" num="0142">The audio module 1180 bi-directionally converts a sound and an electronic signal. At least some components of the audio module 1180 may be included in the input/output interface 140 illustrated in <figref idrefs="f0001">FIG. 1</figref>. The audio module 1180 processes sound information input or output through, for example, a speaker 1182, receiver 1184, earphones 1186, or the microphone 1188.<!-- EPO <DP n="42"> --></p><p id="p0143" num="0143">The camera module 1191 photographs a still image and video. According to an embodiment, the camera module 1191 includes one or more image sensors such as a front or back sensor, an Image Signal Processor (ISP) or a flash such as a Light-Emitting Diode (LED) or xenon lamp.</p><p id="p0144" num="0144">The power-managing module 1195 manages power of the electronic device 1101 and includes, for example, a Power Management Integrated Circuit (PMIC), a charger Integrated Circuit (IC), or a battery gauge.</p><p id="p0145" num="0145">The PMIC may be mounted to, for example, an integrated circuit or a SoC semiconductor. A charging method may be divided into wired and wireless methods. The charger IC charges a battery and prevents over voltage or over current from flowing from a charger. According to an embodiment, the charger IC includes a charger IC for at least one of the wired charging method and the wireless charging method. The wireless charging method includes, for example, a magnetic resonance method, a magnetic induction method and an electromagnetic wave method, and additional circuits for wireless charging may be added, such as a coil loop, a resonant circuit, or a rectifier.</p><p id="p0146" num="0146">The battery gauge measures a remaining quantity of the battery 1196, a voltage, a current, or a temperature during charging. The battery 1196 stores or generates electricity and supplies power to the electronic device 1101 by using the stored or generated electricity. The battery 1196 includes a rechargeable battery or a solar battery.<!-- EPO <DP n="43"> --></p><p id="p0147" num="0147">The indicator 1197 displays particular statuses of the electronic device 101 or a part of the electronic device 101, for example, a booting status, a message status, and a charging status.</p><p id="p0148" num="0148">The motor 1198 converts an electrical signal to a mechanical vibration. Although not illustrated, the electronic device 101 may include a GPU for supporting a module TV, such as media data according to a standard of Digital Multimedia Broadcasting (DMB), Digital Video Broadcasting (DVB), or media flow.</p><p id="p0149" num="0149">Each of the components of the electronic device according to various embodiments of the present invention may be implemented by one or more components and the name of the corresponding component may vary depending on a type of the electronic device. The electronic device according to various embodiments of the present invention includes all of, at least one of, or additional components to the above-described components. Some of the components of the electronic device may be combined to form a single entity, and thus may equivalently execute functions of the corresponding components before being combined.</p><p id="p0150" num="0150">The electronic device according to various embodiments of the present invention includes a controller for analysing pixel data of an image, determining a pixel pattern, and encoding the image according to the determined pixel pattern, and a display, functionally connected to the controller, for displaying the image.</p><p id="p0151" num="0151">The pixel data includes luminance data, first colour difference data and second colour difference data. The controller analyses one or more of luminance data, first colour difference data and second colour difference data, determines a pixel pattern based on the analysis, and reconfigures<!-- EPO <DP n="44"> --> the luminance data, first colour difference data and second colour difference data according to the determined pixel pattern.</p><p id="p0152" num="0152">The first colour difference data is indicated by Cb and the second colour difference data is indicated by Cr. The controller analyses luminance pixel values of a preset unit block, determines a pixel pattern of the unit block, and encodes the Cb and Cr according to the determined pixel pattern.</p><p id="p0153" num="0153">The controller includes a pixel analysis unit for analysing luminance pixel values of a unit block and outputting the analysed pixel data, a pattern determining unit for determining a pixel pattern corresponding to the analysed pixel data and outputting flag data of the determined pixel pattern, and an encoding unit for compressing and encoding Cb and Cr data to the determined pixel pattern and creating encoded data including the flag data, luminance data, and the compressed, encoded Cb and Cr data. When the image is RGB data, the controller includes a colour space conversion unit for converting colours from RGB data to YCbCr data.</p><p id="p0154" num="0154">The pixel analysis unit includes a plurality of absolute value calculators for calculating absolute values Abs (Ya-Yb), Abs (Yc-Yd), Abs (Ya-Yc), Abs (Yb-Yd), Abs (Ya-Yd) and Abs (Yb-Yc) from Ya-Yd data forming unit data of luminance data, and a plurality of comparators for comparing the absolute values with a threshold and outputting analysed pixel data.</p><p id="p0155" num="0155">The pattern determining unit analyses the analysed pixel data, determines a pixel pattern based on the analysis, and outputs flag data according to the determined pixel pattern.<!-- EPO <DP n="45"> --></p><p id="p0156" num="0156">The encoding unit includes a CB encoding unit for calculating an average of Cb pixels corresponding to a combination of pixels less than the threshold according to the determined pixel pattern, and creating first encoded data CB1 and second encoded data CB2, a Cr encoding unit for calculating an average of Cr pixels corresponding to a combination of pixels having values less than the threshold according to the determined pixel pattern, and creating first encoded data CR1 and second encoded data CR2, a flag inserting unit for inserting the flag data to CB1-CB2 and CR1-CR2, and a combination unit for combining Ya-Yd, CB1, CB2, CR1 and CR2 and flag data to create encoded data. The flag inserting unit inserts the flag data to the LSB of CB1, CB2, CR1 and CR2.</p><p id="p0157" num="0157">The controller further includes a pattern determining unit for analysing, when displaying an image, flag data in an encoded image and verifying a pattern, a decoding unit for restoring first colour difference data and second colour difference data according to the verified pattern, and a colour space conversion unit for converting, when the display is an RGB display, luminance data, first colour difference data and second colour difference data, output from the decoding unit, to RGB data.</p><p id="p0158" num="0158"><figref idrefs="f0019">FIG. 12</figref> illustrates a method of processing a colour image in an electronic device according to various embodiments of the present invention.</p><p id="p0159" num="0159">Referring to <figref idrefs="f0019">FIG. 12</figref>, when an image processing application is executed, the controller 210 detects the execution and performs an image processing function in step 1211, such as processing a colour image of luminance data and colour difference data. The image processing function may be for encoding colour difference data of the colour image of 4:4:4 resolution in a<!-- EPO <DP n="46"> --> preset size. For example, the image is a YCbCr image and the image processing function is for encoding colour difference data of 4 pixels to a colour difference of 2 pixels. When the image is an RGB image, the controller 210 ascertains that the RGB image requires a colour conversion in step 1213 and coverts the RGB image to an YCbCr image by using a scheme expressed by Equation (1) in step 1215.</p><p id="p0160" num="0160">The YCbCr image may be a colour image of 4:4:4 resolution, which indicates that the pixels of luminance Y and colour difference signals Cb and Cr have the same rate. The colour resolution of 4:2:2 shown in <figref idrefs="f0004">FIG. 3B</figref> and the colour resolution of 4:4:0 shown in <figref idrefs="f0005">FIG. 3C</figref> indicate that the respective rates of pixels of colour difference signals Cb and Cr are half of those of luminance Y pixel. However, since colour images where the rates of luminance data and colour difference data differ from each other have the rates of pixels of colour difference signals less than the rate of the luminance pixels, the colour images may be displayed in a relatively low quality according to pixel patterns.</p><p id="p0161" num="0161">In order to encode colour difference pixels with a rate that differs from that of luminance pixel, a method may be used that analyses pixels in terms of a unit block, determines a pixel pattern of the unit block, and encodes pixels of colour difference signals according to the determined pixel pattern. For example, the controller 210 encodes pixels of colour difference signals according to a pixel pattern of a unit block, thereby reducing blur at the boundaries of an image displayed on the display 230 and displaying sharp boundaries.</p><p id="p0162" num="0162">The controller 210 analyses specific data such as luminance data Y in a YCbCr image of 4:4:4 colour resolution based on a unit block, creates analysed pixel data, determines a pixel<!-- EPO <DP n="47"> --> pattern of a unit block corresponding to the created, analysed pixel data, and encodes colour difference data according to the determined pixel pattern. The pixel pattern may be detected in different forms according to locations of an object in an image. For example, when the outline or boundary of an object is located widthwise, lengthwise, or diagonally, the pixel patterns in the unit block may be determined as different pattern categories. The remainder of the method of <figref idrefs="f0019">FIG. 12</figref> will be provided in the description of <figref idrefs="f0020 f0021">FIGS. 13A-13B</figref> and <figref idrefs="f0022 f0023 f0024 f0025">14-17</figref>, as follows.</p><p id="p0163" num="0163"><figref idrefs="f0020">FIGS. 13A</figref> and <figref idrefs="f0021">13B</figref> illustrate a method of analysing pixel values in an electronic device according to various embodiments of the present invention.</p><p id="p0164" num="0164">Referring to <figref idrefs="f0020">FIG. 13A</figref>, a YCbCr image of 4:4:4 resolution has a structure where Y, Cb and Cb pixels are mapped with a size of a unit block (e.g., 4 pixels). The values of Y, Cb or Cb pixels are analysed in a size of a unit block to determine a pixel pattern and then pixels are encoded according to the pixel pattern. During the process, since the Y mostly affects the recovery of an image, it is preferable that the pixel size remains the same size in an encoding process. When colour difference information plays an important function according to image property or luminance information is restored to be visually lossless, part of the luminance (Y) image information may be used for the purpose of storing pattern information. In addition, pixels of a unit block to analyse pixel values may use Y pixels. The controller 210 selects luminance data of a unit block in order to determine a pixel pattern in step 1311.</p><p id="p0165" num="0165">The controller 210 operates values of luminance pixels in a unit block in step 1313. During this process, the pixel analysis module 213 analyses pixel values of a unit block by using a YCbCr image output/input from/to the colour space conversion module 211 shown in <figref idrefs="f0009">FIG. 6</figref>.<!-- EPO <DP n="48"> --> The arrangement of luminance pixels in a unit block has a structure shown in <figref idrefs="f0010">FIG. 7A</figref>. The controller 210 operates values of luminance pixels in a unit block through the method shown in <figref idrefs="f0011">FIG. 7B</figref>.</p><p id="p0166" num="0166">The controller 210 calculates a difference between two pixel values in a unit block and the absolute value of the difference, by using Equation (2), in step 1313. The controller 210 compares the absolute value of the difference with a threshold in step 1315, and outputs the comparison result as '0' or '1' in step 1317. The analysed pixel data calculated by using Equation (2) may be data of 6 bits with a structure shown in <figref idrefs="f0012">FIG. 7C</figref>.</p><p id="p0167" num="0167">Referring to <figref idrefs="f0021">FIG. 13B</figref>, the controller 210 selects luminance data of a unit block in order to determine a pixel pattern in step 1331, operates pixel values of luminance data and colour difference data in step 1333, compares the calculated pixel values with corresponding thresholds respectively in step 1335, and outputs the analysed pixel data in step 1337.</p><p id="p0168" num="0168">The pixel pattern may be analysed based on the luminance pixel value as shown in <figref idrefs="f0020">FIG. 13A</figref> or by using the luminance pixel value and colour difference pixel values as shown in <figref idrefs="f0021">FIG. 13B</figref>. For example, in the method shown in <figref idrefs="f0021">FIG. 13B</figref>, a pixel value may be determined considering luminance and colour difference or based on a linear combination of luminance and colour difference. The method shown in <figref idrefs="f0021">FIG. 13B</figref> may also be applied to the operation 213 shown in <figref idrefs="f0008">FIG. 5</figref>. Referring back to <figref idrefs="f0019">FIG. 12</figref>, the controller 210 analyses pixel values by using the methods shown in <figref idrefs="f0020">FIGS. 13A</figref> and <figref idrefs="f0021">13B</figref> in step 1217, and determines a pixel pattern corresponding to the analysed pixel data in step 1219.<!-- EPO <DP n="49"> --></p><p id="p0169" num="0169"><figref idrefs="f0022">FIG. 14</figref> illustrates a method of determining a pixel pattern in an electronic device according to various embodiments of the present invention.</p><p id="p0170" num="0170">Referring to <figref idrefs="f0022">FIG. 14</figref>, although values of analysed pixel data of 6 bits differ from each other, the pattern categorization has the identical pattern for the analysed pixel data. For example, as shown in <figref idrefs="f0007">FIG. 4</figref>, pixel pattern 0 may be created when analysed pixel data are 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, or 15, and pixel pattern 1 may be created when analysed pixel data are 16, 17, 18, 19, 32, 33, 34, 35, 48, 49, 50, or 51. When analysed pixel data have different values but an identical pixel pattern structure, the analysed pixel data may be determined as identical flag data. To this end, the storage 220 includes a flag table for mapping between analysed pixel data and pixel patterns.</p><p id="p0171" num="0171">When analysed pixel data is created, the controller 210 determines a pixel pattern corresponding to the analysed pixel data in step 1411, and generates flag data corresponding to the determined pixel pattern in step 1413. The flag data may be determined to be 4 bits in size. In that case, the number of pixel patterns of a unit block may be 16. Although the embodiment describes pixel patterns generated based on 4 bits of flag data, it should be understood that the size of flag data may increase when the pixel pattern is subdivided.</p><p id="p0172" num="0172">Referring back to <figref idrefs="f0019">FIG. 12</figref>, after generating the flag data, the controller 210 encodes colour difference data according to the determined pixel pattern and creates encoded data including the encoded colour difference data, luminance data and flag data in step 1221.</p><p id="p0173" num="0173"><figref idrefs="f0023">FIG. 15</figref> illustrates a method of encoding images in an electronic device according to<!-- EPO <DP n="50"> --> various embodiments of the present invention.</p><p id="p0174" num="0174">Referring to <figref idrefs="f0023">FIG. 15</figref>, the controller 210 encodes colour difference data Cb and Cr according to the determined pixel pattern in steps 1511 and 1513. Specifically, the colour difference data may be encoded, according to a pixel pattern, based on a unit block. For a unit block of 4 pixels, the controller 210 encodes colour difference pixels of 4 pixels, Cba-Cbd, to colour difference pixels of 2 pixels, CB1-CB2, according to a pixel pattern in step 1511. The controller 210 encodes colour difference pixels of 4 pixels, Cra-Crd, to colour difference pixels of 2 pixels, CR1-CR2, according to a pixel pattern in step 1513. The encoding method is performed in such a manner as to obtain an average of pixel values according to the pattern and to create encoded colour difference data from the average.</p><p id="p0175" num="0175">For example, for pattern 0, the controller 210 calculates an average of colour difference pixels Cba and Cbb and the average of colour difference pixels, Cra and Crb, and creates the encoded colour difference data CB1 and CR1, respectively. The controller 210 may also calculate the average of colour difference pixels Cbc and Cbd and the average of colour difference pixels, Crc and Crd, and create the encoded colour difference data CB2 and CR2, respectively. The controller 210 inserts flag data into the encoded colour difference data CB1-CB2 and CR1-CR2 in step 1515, in which case the colour difference data may be configured as shown in Table 1.</p><p id="p0176" num="0176">The controller 210 creates encoded data by combining luminance data of a unit block and encoded colour difference data CB and CR in step 1517 (where the code may be the flag).<!-- EPO <DP n="51"> --></p><p id="p0177" num="0177"><figref idrefs="f0014 f0015 f0016">FIGS. 9A to 9C</figref> illustrate configurations of encoded data of a unit block. Referring back to <figref idrefs="f0019">FIG. 12</figref>, after creating the encoded data of structures shown in <figref idrefs="f0014 f0015 f0016">FIGS. 9A to 9C</figref>, the controller 210 stores the encoded image in the storage 220 or transmits the encoded image to other modules or external devices through the communication unit in step 1223. The image processing operation is repeated until the image has been processed or a user's request for terminating the image process is made. When the controller 210 detects an image process termination in step 1225, the controller 210 terminates the image processing procedure.</p><p id="p0178" num="0178">The controller 210 determines a pixel pattern corresponding to outlines or boundaries of an object in the image, and creates an encoded image of colour difference data encoded according to the determined pixel pattern. When the controller 210 decodes the encoded image, the controller 210 verifies a pixel pattern according to flag data and decodes the pixels according to the verified pixel pattern.</p><p id="p0179" num="0179"><figref idrefs="f0024">FIG. 16</figref> illustrates a method of encoding images and decoding encoded images, according to pixel patterns, in an electronic device according to various embodiments of the present invention.</p><p id="p0180" num="0180">Referring to <figref idrefs="f0024">FIG. 16</figref>, when a function for encoding YCbCr image is executed, the controller 210 detects the encoding function in step 1611 and encodes a colour image in step 1613. The process of encoding a colour image in step 1613 may be performed according to the procedure shown in <figref idrefs="f0019">FIG. 12</figref>.</p><p id="p0181" num="0181">When a function of displaying the encoded image, the controller 210 detects the<!-- EPO <DP n="52"> --> displaying function in step 1651, accesses an encoded image of one of the structures shown in <figref idrefs="f0014 f0015 f0016">FIGS. 9A to 9C</figref> in step 1653, verifies pattern flag to verify a pixel pattern in step 1655, and decodes the image according to the verified pixel pattern in step 1657.</p><p id="p0182" num="0182"><figref idrefs="f0025">FIG. 17</figref> illustrates a method of decoding an encoded image in an electronic device according to various embodiments of the present invention.</p><p id="p0183" num="0183">Referring to <figref idrefs="f0025">FIG. 17</figref>, the controller 210 determines a pixel pattern of a unit block corresponding to the flag data in step 1711, restores Cba-Cbd pixels by using CB1 and CB2 according to the verified pixel pattern in step 1713, and Cra-Crd pixels by using CR1 and CR2 according to the verified pixel pattern in step 1715. The controller 210 creates Ya-Yd of a unit block, decoded Cba-Cbd and Cra - Crd pixels in step 1717.</p><p id="p0184" num="0184">Referring back to <figref idrefs="f0024">FIG. 16</figref>, the controller 210 restores the colour difference data of 2 pixels, decoded in step 1657, to colour difference data of 4 pixels corresponding to a pixel pattern. For example, for an encoded image of pattern 0, the controller 210 restores Cba and Cbb pixels to CB1 data, Cbc and Cbd pixels to CB2 data, Cra and Crb pixels to CR1 data, and Crc and Crd pixels to CR2 data, in step 1657. In addition, for an encoded image of pattern 1, the controller 210 restores Cba and Cbc pixels to CB1 data, Cbb and Cbd pixels to CB2 data, Cra and Crc pixels to CR1 data, and Crb and Crd pixels to CR2 data.</p><p id="p0185" num="0185">When the display 230 displays RGB images, the controller 210 detects the displayed image in step 1659, performs colour conversion for the YCbCr image by a method expressed by Equation (3), and displays the decoded YCbCr image on the display 230 in step 1663. When the<!-- EPO <DP n="53"> --> controller 210 detects a termination in step 1665, the controller 210 terminates the encoding and decoding procedure.</p><p id="p0186" num="0186"><figref idrefs="f0026">FIGS. 18A</figref> and <figref idrefs="f0027">18B</figref> illustrate images encoded according to pixel patterns in an electronic device, by comparison with each other, according to various embodiments of the present invention. Referring to <figref idrefs="f0026 f0027 f0028">FIGS. 18A to 18C</figref>, the images indicated by reference numerals 1811, 1831 and 1851 are examples of an original image, images 1813, 1833 and 1853 are examples of a conventional YCbCr 422 image of colour resolution 4:2:2, and images 1815, 1835 and 1855 are examples of an enhanced YCbCr 422 image as colour difference data is encoded according to a pixel pattern. The enhanced YCbCr images 1815, 1835 and 1855 display objects with sharper boundaries and outlines than conventional YCbCr 422 images 1813, 1833 and 1853.</p><p id="p0187" num="0187">A method of processing images in an electronic device according to various embodiments of the present invention includes analysing pixel data of an image and outputting the analysed pixel data, determining a pixel pattern based on the analysed pixel data, and encoding the image according to the determined pixel pattern.</p><p id="p0188" num="0188">The analysed pixel data includes at least one of luminance data, first colour difference data and second colour difference data. The first colour difference data is Cb. The second colour difference data is Cr.</p><p id="p0189" num="0189">When the image is RGB data, the image processing method converts colours from the RGB data to YCbCr data.<!-- EPO <DP n="54"> --></p><p id="p0190" num="0190">The output of the analysed pixel data includes selecting luminance pixels of a unit block, Ya and Yd, obtaining absolute values Abs (Ya-Yb), Abs (Yc-Yd), Abs (Ya-Yc), Abs (Yb-Yd), Abs (Ya-Yd) and Abs (Yb-Yc) from the Ya-Yd pixels, and comparing the absolute values with a threshold and outputting the analysed pixel data.</p><p id="p0191" num="0191">The determination of a pixel pattern includes analysing the analysed pixel data and determining the pixel pattern, and outputting flag data according to the determined pixel pattern.</p><p id="p0192" num="0192">The process of encoding the image includes encoding CB by calculating an average of Cb pixels corresponding to a combination of pixels less than the threshold according to the determined pixel pattern, and creating first encoded data CB1 and second encoded data CB2, encoding Cr by calculating an average of Cr pixels corresponding to a combination of pixels less than the threshold according to the determined pixel pattern, and creating first encoded data CR1 and second encoded data CR2, inserting the flag data to CB1-CB2 and CR1-CR2, and creating encoded data by combining Ya-Yd, CB1, CB2, CR1 and CR2 and flag data. The process of inserting the flag data includes inserting the flag data into the LSB of CB1, CB2, CR1 and CR2.</p><p id="p0193" num="0193">An image processing method according to various embodiments of the present invention further includes analysing, when displaying an image, flag data in an encoded image and verifying a pattern, and decoding first colour difference data and second colour difference data according to the verified pattern.</p><p id="p0194" num="0194">The image processing method further includes displaying the decoded image by converting, when the display is an RGB display, the decoded luminance data, first colour<!-- EPO <DP n="55"> --> difference data and second colour difference data, to RGB data.</p><p id="p0195" num="0195">As described above, the electronic device according to various embodiments of the present invention analyses, when processing a colour image, pixel values of the colour image, determines the pixel pattern, and encodes the colour difference data according to the determined pixel pattern. The electronic device detects a pixel pattern that differs from the pixel pattern according to the outline or boundary of image and displays the encoded image with a clear boundary or outline.</p><p id="p0196" num="0196">In the embodiments of the present invention, the terminology '∼ module' refers to a 'unit' including hardware, software, firmware or a combination thereof. For example, the terminology '∼ module' is interchangeable with '∼ unit,' '∼ logic,' '∼ logical block,' '∼ component,' '∼ circuit,' etc. A 'module' may be the least unit or a part of an integrated component. A 'module' may be the least unit or a part thereof that can perform one or more functions. A 'module' may be implemented in mechanical or electronic mode. For example, 'modules' according to the embodiments of the present invention may be implemented with at least one of an Application Specific Integrated Circuit (ASIC) chip, Field-Programmable Gate Arrays (FPGAs) and a programmable-logic device that can perform functions that have been known or will be developed.</p><p id="p0197" num="0197">At least part of the programming module 300 may be implemented by instructions stored in computer-readable storage media. If the instructions are executed by one or more processors, the processors can perform the functions respectively. An example of the computer-readable storage media may be a memory 220. At least part of the programming module may be<!-- EPO <DP n="56"> --> implemented by the processor 210. At least part of the programming module may include module, programs, routines, sets of instructions and/or processes., in order to perform one or more functions.</p><p id="p0198" num="0198">Examples of computer-readable media include: magnetic media, such as hard disks, floppy disks, and magnetic tape, optical media such as CD-ROM disks and DVDs; magnetooptical media, such as floptical disks, and hardware devices that are specially configured to store and perform program instructions (programming modules), such as ROM, RAM, and flash memory. Examples of program instructions include machine code, such as produced by a compiler, and files containing higher level code that may be executed by the computer using an interpreter. The described hardware devices may be configured to act as one or more software modules in order to perform the operations and methods described above, or vice versa.</p><p id="p0199" num="0199">Further, it will be appreciated that embodiments of the present invention can be realized in the form of hardware, software or a combination of hardware and software. Any such software may be stored in the form of volatile or non-volatile storage, for example a storage device like a ROM, whether erasable or rewritable or not, or in the form of memory, for example RAM, memory chips, device or integrated circuits or on an optically or magnetically readable medium, for example a CD, DVD, magnetic disk or magnetic tape or the like. It will be appreciated that the storage devices and storage media are embodiments of machine-readable storage that are suitable for storing a program or programs comprising instructions that, when executed, implement embodiments of the present invention.</p><p id="p0200" num="0200">Accordingly, embodiments provide a program comprising code for implementing<!-- EPO <DP n="57"> --> apparatus or a method as claimed in any one of the claims of this specification and a machine-readable storage storing such a program. Still further, such programs may be conveyed electronically via any medium, for example a communication signal carried over a wired or wireless connection and embodiments suitably encompass the same.</p><p id="p0201" num="0201">Modules or programming modules according to the present invention may include one or more components described above, remove part of the components described above, or include new components. The operations performed by modules, programming modules, or the other components, according to the present invention, may be executed in serial, parallel, repetitive or heuristic fashion. Part of the operations can be executed in any other order, skipped, or executed with additional operations.</p><p id="p0202" num="0202">Although certain embodiments of the invention have been described in detail above, it should be understood that many variations and modifications of the basic inventive concept herein described, which may be apparent to those skilled in the art, will still fall within the scope of the invention as defined in the appended claims.</p></description><claims mxw-id="PCLM90459842" lang="EN" load-source="patent-office"><!-- EPO <DP n="58"> --><claim id="c-en-0001" num="0001"><claim-text>A method of processing images in an electronic device comprising:
<claim-text>analysing pixel data of an image;</claim-text>
<claim-text>determining a pixel pattern based on the analysed pixel data; and</claim-text>
<claim-text>encoding the image according to the determined pixel pattern.</claim-text></claim-text></claim><claim id="c-en-0002" num="0002"><claim-text>The method of claim 1, wherein the analysed pixel data comprises luminance data, first colour difference data and second colour difference data; and<br/>
wherein the analysis is based on one or more of luminance data, first colour difference data and second colour difference data and the encoding comprises reconfiguring the luminance data, first colour difference data and second colour difference data, according to the determined pixel pattern.</claim-text></claim><claim id="c-en-0003" num="0003"><claim-text>The method of claim 2, wherein:
<claim-text>the first colour difference data is blue difference chroma component Cb; and</claim-text>
<claim-text>the second colour difference data is red difference chroma component Cr; and</claim-text>
<claim-text>wherein the encoding comprises encoding the Cb and Cr data according to the determined pixel pattern.</claim-text></claim-text></claim><claim id="c-en-0004" num="0004"><claim-text>The method of claim 3, further comprising:
<claim-text>converting, when the image is Red, Green, Blue, RGB, data, colours from the RGB data to YCbCr data.</claim-text><!-- EPO <DP n="59"> --></claim-text></claim><claim id="c-en-0005" num="0005"><claim-text>The method of any one of claims 2 to 4, wherein outputting the analysed pixel data comprises:
<claim-text>selecting luminance pixels of a block unit Ya, Yb, Yc and Yd;</claim-text>
<claim-text>obtaining absolute values Abs (Ya-Yb), Abs (Yc-Yd), Abs (Ya-Yc), Abs (Yb-Yd), Abs (Ya-Yd) and Abs (Yb-Yc) from the Ya, Yb, Yc and Yd pixels; and</claim-text>
<claim-text>comparing the absolute values with a threshold and outputting the analysed pixel data.</claim-text></claim-text></claim><claim id="c-en-0006" num="0006"><claim-text>The method of any one of claims 2 to 5, wherein determining the pixel pattern comprises:
<claim-text>analysing the analysed pixel data and determining the pixel pattern; and</claim-text>
<claim-text>outputting flag data according to the determined pixel pattern.</claim-text></claim-text></claim><claim id="c-en-0007" num="0007"><claim-text>The method of any one of claims 2 to 6, wherein encoding the image comprises:
<claim-text>encoding first data by calculating an average of Cb pixels corresponding to a combination of pixels less than a first threshold according to the determined pixel pattern, and creating first encoded data CB1 and second encoded data CB2;</claim-text>
<claim-text>encoding second data by calculating an average of Cr pixels corresponding to a combination of pixels less than a second threshold according to the determined pixel pattern, and creating first encoded data CR1 and second encoded data CR2;</claim-text>
<claim-text>inserting the flag data into CB 1, CB2, CR1, and CR2; and</claim-text>
<claim-text>creating combined encoded data by combining Ya, Yb, Yc, Yd, CB1, CB2, CR1 and CR2 and the flag data.</claim-text></claim-text></claim><claim id="c-en-0008" num="0008"><claim-text>The method of claim 7, wherein inserting the flag data comprises:<!-- EPO <DP n="60"> -->
<claim-text>inserting the flag data into the Least Significant Bit, LSB, of CB1, CB2, CR1 and CR2.</claim-text></claim-text></claim><claim id="c-en-0009" num="0009"><claim-text>The method of any one of claims 1 to 8, further comprising:
<claim-text>analysing, when displaying the image, flag data in an encoded image and verifying a pattern; and</claim-text>
<claim-text>decoding first colour difference data and second colour difference data according to the verified pattern.</claim-text></claim-text></claim><claim id="c-en-0010" num="0010"><claim-text>The method of claim 9, further comprising:
<claim-text>displaying the decoded image by</claim-text>
<claim-text>converting, when a display is a Red, Green, Blue, RGB, display, the decoded luminance data, first colour difference data and second colour difference data, to RGB data.</claim-text></claim-text></claim><claim id="c-en-0011" num="0011"><claim-text>An electronic device comprising a controller, the electronic device being arranged to implement the method of any one of the preceding claims.</claim-text></claim><claim id="c-en-0012" num="0012"><claim-text>The electronic device of claim 11, the controller comprises:
<claim-text>a pixel analysis unit arranged to analyse luminance pixel values of a unit block and output the analysed pixel data;</claim-text>
<claim-text>a pattern determining unit arranged to determine a pixel pattern corresponding to the analysed pixel data and output flag data of the determined pixel pattern;</claim-text>
<claim-text>an encoding unit arranged to compress and encode the Cb and Cr data to the determined pixel pattern and create encoded data including the flag data, luminance data, and the compressed, encoded Cb and Cr data; and<!-- EPO <DP n="61"> --></claim-text>
<claim-text>a colour space conversion unit arranged to convert, when the image is Red, Green, Blue, RGB, data, colours from RGB data to YCbCr data.</claim-text></claim-text></claim><claim id="c-en-0013" num="0013"><claim-text>The electronic device of claim 12, wherein the pixel analysis unit comprises:
<claim-text>a plurality of absolute value calculators arranged to calculate absolute values Abs (Ya-Yb), Abs (Yc-Yd), Abs (Ya-Yc), Abs (Yb-Yd), Abs (Ya-Yd) and Abs (Yb-Yc) from Ya, Yb, Yc and Yd data forming a unit block of luminance data; and</claim-text>
<claim-text>a plurality of comparators arranged to compare the absolute values with a threshold and output analysed pixel data.</claim-text></claim-text></claim><claim id="c-en-0014" num="0014"><claim-text>The electronic device of claim 12, wherein the encoding unit comprises:
<claim-text>a CB encoding unit arranged to calculate an average of Cb pixels corresponding to a combination of pixels less than a first threshold according to the determined pixel pattern, and create first encoded data CB1 and second encoded data CB2;</claim-text>
<claim-text>a CR encoding unit arranged to calculate an average of Cr pixels corresponding to a combination of pixels less than a second threshold according to the determined pixel pattern, and create first encoded data CR1 and second encoded data CR2;</claim-text>
<claim-text>a flag inserting unit arranged to insert the flag data into CB1, CB2, CR1, and CR2; and</claim-text>
<claim-text>a combination unit arranged to combine Ya, Yb, Yc, Yd, CB1, CB2, CR1 and CR2 and flag data to create combined encoded data.</claim-text></claim-text></claim><claim id="c-en-0015" num="0015"><claim-text>The electronic device of claim 12, wherein the controller comprises:
<claim-text>a pattern determining unit arranged to analyse, when displaying the image, flag data in an encoded image and verify a pattern;<!-- EPO <DP n="62"> --></claim-text>
<claim-text>a decoding unit arranged to restore first colour difference data and second colour difference data according to the verified pattern; and</claim-text>
<claim-text>a colour space conversion unit arranged to convert, when a display is a Red, Green, Blue, RGB, display, luminance data, first colour difference data and second colour difference data, output from the decoding unit, to RGB data.</claim-text></claim-text></claim></claims><drawings mxw-id="PDW20422553" load-source="patent-office"><!-- EPO <DP n="63"> --><figure id="f0001" num="1"><img id="if0001" file="imgf0001.tif" wi="135" he="199" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="64"> --><figure id="f0002" num="2"><img id="if0002" file="imgf0002.tif" wi="165" he="206" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="65"> --><figure id="f0003" num="3A"><img id="if0003" file="imgf0003.tif" wi="111" he="189" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="66"> --><figure id="f0004" num="3B"><img id="if0004" file="imgf0004.tif" wi="111" he="189" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="67"> --><figure id="f0005" num="3C"><img id="if0005" file="imgf0005.tif" wi="111" he="189" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="68"> --><figure id="f0006" num="3D"><img id="if0006" file="imgf0006.tif" wi="111" he="189" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="69"> --><figure id="f0007" num="4"><img id="if0007" file="imgf0007.tif" wi="153" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="70"> --><figure id="f0008" num="5"><img id="if0008" file="imgf0008.tif" wi="165" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="71"> --><figure id="f0009" num="6"><img id="if0009" file="imgf0009.tif" wi="79" he="183" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="72"> --><figure id="f0010" num="7A"><img id="if0010" file="imgf0010.tif" wi="100" he="169" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="73"> --><figure id="f0011" num="7B"><img id="if0011" file="imgf0011.tif" wi="146" he="194" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="74"> --><figure id="f0012" num="7C"><img id="if0012" file="imgf0012.tif" wi="146" he="141" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="75"> --><figure id="f0013" num="8"><img id="if0013" file="imgf0013.tif" wi="165" he="165" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="76"> --><figure id="f0014" num="9A"><img id="if0014" file="imgf0014.tif" wi="125" he="194" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="77"> --><figure id="f0015" num="9B"><img id="if0015" file="imgf0015.tif" wi="125" he="194" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="78"> --><figure id="f0016" num="9C"><img id="if0016" file="imgf0016.tif" wi="125" he="194" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="79"> --><figure id="f0017" num="10"><img id="if0017" file="imgf0017.tif" wi="145" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="80"> --><figure id="f0018" num="11"><img id="if0018" file="imgf0018.tif" wi="157" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="81"> --><figure id="f0019" num="12"><img id="if0019" file="imgf0019.tif" wi="157" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="82"> --><figure id="f0020" num="13A"><img id="if0020" file="imgf0020.tif" wi="97" he="182" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="83"> --><figure id="f0021" num="13B"><img id="if0021" file="imgf0021.tif" wi="97" he="190" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="84"> --><figure id="f0022" num="14"><img id="if0022" file="imgf0022.tif" wi="104" he="115" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="85"> --><figure id="f0023" num="15"><img id="if0023" file="imgf0023.tif" wi="107" he="160" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="86"> --><figure id="f0024" num="16"><img id="if0024" file="imgf0024.tif" wi="165" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="87"> --><figure id="f0025" num="17"><img id="if0025" file="imgf0025.tif" wi="113" he="158" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="88"> --><figure id="f0026" num="18A"><img id="if0026" file="imgf0026.tif" wi="134" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="89"> --><figure id="f0027" num="18B"><img id="if0027" file="imgf0027.tif" wi="136" he="194" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="90"> --><figure id="f0028" num="18C"><img id="if0028" file="imgf0028.tif" wi="141" he="233" img-content="drawing" img-format="tif"/></figure></drawings><search-report-data><doc-page id="srep0001" file="srep0001.tif" wi="157" he="233" type="tif"/><doc-page id="srep0002" file="srep0002.tif" wi="157" he="233" type="tif"/></search-report-data><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
