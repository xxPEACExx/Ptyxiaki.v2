<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2960874-A1" country="EP" doc-number="2960874" kind="A1" date="20151230" family-id="51410099" file-reference-id="313851" date-produced="20180826" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="160451807" ucid="EP-2960874-A1"><document-id><country>EP</country><doc-number>2960874</doc-number><kind>A1</kind><date>20151230</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-15173036-A" is-representative="YES"><document-id mxw-id="PAPP193866582" load-source="patent-office" format="original"><country>EP</country><doc-number>15173036.3</doc-number><date>20150620</date><lang>EN</lang></document-id><document-id mxw-id="PAPP193866583" load-source="docdb" format="epo"><country>EP</country><doc-number>15173036</doc-number><kind>A</kind><date>20150620</date><lang>EN</lang></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC162032518" ucid="GB-201411295-A" load-source="docdb"><document-id format="epo"><country>GB</country><doc-number>201411295</doc-number><kind>A</kind><date>20140625</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL-1988520799" load-source="docdb">G07D   7/20        20060101AFI20151020BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-1988521566" load-source="docdb">G06K   9/32        20060101ALI20151020BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-1988525798" load-source="docdb">G06K   9/20        20060101ALI20151020BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-1649372920" load-source="docdb" scheme="CPC">G07D   7/2008      20130101 LI20180416BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1649372921" load-source="docdb" scheme="CPC">G06K   9/00463     20130101 LI20180416BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1984696855" load-source="docdb" scheme="CPC">G06K   9/52        20130101 LI20151231BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1984699217" load-source="docdb" scheme="CPC">G06K   9/00885     20130101 LI20151231BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1984700694" load-source="docdb" scheme="CPC">G06K   9/00483     20130101 FI20151231BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT165546887" lang="DE" load-source="patent-office">DIGITALES IDENTITÄTSDOKUMENTEN-BILDKORREKTURVERFAHREN, SYSTEM UND COMPUTERPROGRAMM</invention-title><invention-title mxw-id="PT165546888" lang="EN" load-source="patent-office">IDENTITY DOCUMENT DIGITAL IMAGE CORRECTION METHOD, SYSTEM AND COMPUTER PROGRAM</invention-title><invention-title mxw-id="PT165546889" lang="FR" load-source="patent-office">PROCÉDÉ SYSTÈME ET PROGRAMME INFORMATIQUE POUR LA CORRECTION DE L'IMAGE NUMÉRIQUE D'UN DOCUMENT D'IDENTITÉ</invention-title><citations><patent-citations><patcit mxw-id="PCIT415277568" load-source="docdb" ucid="DE-102006051710-A1"><document-id format="epo"><country>DE</country><doc-number>102006051710</doc-number><kind>A1</kind><date>20070503</date></document-id><sources><source name="SEA" category="XI" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT415277569" load-source="docdb" ucid="EP-2624224-A1"><document-id format="epo"><country>EP</country><doc-number>2624224</doc-number><kind>A1</kind><date>20130807</date></document-id><sources><source name="SEA" category="XI" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT415277567" load-source="docdb" ucid="US-20130034290-A1"><document-id format="epo"><country>US</country><doc-number>20130034290</doc-number><kind>A1</kind><date>20130207</date></document-id><sources><source name="SEA" category="XA" created-by-npl="N"/></sources></patcit></patent-citations><non-patent-citations><nplcit><text>CIFAS 2012 FRAUD TRENDS, 17 January 2013 (2013-01-17)</text><sources><source mxw-id="PNPL57906942" load-source="docdb" name="APP"/></sources></nplcit><nplcit><text>FRAUD TYPOLOGIES AND VICTIMS OF FRAUD - LITERATURE REVIEW, 2009</text><sources><source mxw-id="PNPL57906943" load-source="docdb" name="APP"/></sources></nplcit></non-patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR1103335567" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>IDSCAN BIOMETRICS LTD</last-name><address><country>GB</country></address></addressbook></applicant><applicant mxw-id="PPAR1103302599" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>IDSCAN BIOMETRICS LIMITED</last-name></addressbook></applicant><applicant mxw-id="PPAR1101647237" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>IDscan Biometrics Limited</last-name><iid>101518653</iid><address><street>Aegon House 13 Lanark Square Cross Harbour Canary Wharf</street><city>London E14 9QD</city><country>GB</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR1103342305" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>THOMPSON TAMLYN</last-name><address><country>GB</country></address></addressbook></inventor><inventor mxw-id="PPAR1103310972" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>Thompson, Tamlyn</last-name></addressbook></inventor><inventor mxw-id="PPAR1101640414" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Thompson, Tamlyn</last-name><address><street>Aegon House Lanark Square Cross Harbour Canary Wharf</street><city>London, E14 9QD</city><country>GB</country></address></addressbook></inventor><inventor mxw-id="PPAR1103336632" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>ZEIDAN ZAHER</last-name><address><country>GB</country></address></addressbook></inventor><inventor mxw-id="PPAR1103313972" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>Zeidan, Zaher</last-name></addressbook></inventor><inventor mxw-id="PPAR1101650007" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>Zeidan, Zaher</last-name><address><street>Aegon House Lanark Square Cross Harbour Canary Wharf</street><city>London, E14 9QD</city><country>GB</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR1101645939" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>McBride, Peter Hill</last-name><suffix>et al</suffix><iid>101529156</iid><address><street>Scintilla Intellectual Property Ltd The Centrum Building 38 Queen Street</street><city>Glasgow G1 3DX</city><country>GB</country></address></addressbook></agent></agents></parties><international-convention-data><designated-states><ep-contracting-states><country mxw-id="DS660693066" load-source="docdb">AL</country><country mxw-id="DS660690816" load-source="docdb">AT</country><country mxw-id="DS660693072" load-source="docdb">BE</country><country mxw-id="DS660785149" load-source="docdb">BG</country><country mxw-id="DS660615263" load-source="docdb">CH</country><country mxw-id="DS660692613" load-source="docdb">CY</country><country mxw-id="DS660690817" load-source="docdb">CZ</country><country mxw-id="DS660693073" load-source="docdb">DE</country><country mxw-id="DS660692614" load-source="docdb">DK</country><country mxw-id="DS660692627" load-source="docdb">EE</country><country mxw-id="DS660614952" load-source="docdb">ES</country><country mxw-id="DS660785150" load-source="docdb">FI</country><country mxw-id="DS660785151" load-source="docdb">FR</country><country mxw-id="DS660693074" load-source="docdb">GB</country><country mxw-id="DS660692628" load-source="docdb">GR</country><country mxw-id="DS660693079" load-source="docdb">HR</country><country mxw-id="DS660690818" load-source="docdb">HU</country><country mxw-id="DS660615264" load-source="docdb">IE</country><country mxw-id="DS660693080" load-source="docdb">IS</country><country mxw-id="DS660785152" load-source="docdb">IT</country><country mxw-id="DS660692629" load-source="docdb">LI</country><country mxw-id="DS660610941" load-source="docdb">LT</country><country mxw-id="DS660690823" load-source="docdb">LU</country><country mxw-id="DS660610942" load-source="docdb">LV</country><country mxw-id="DS660610943" load-source="docdb">MC</country><country mxw-id="DS660701675" load-source="docdb">MK</country><country mxw-id="DS660701676" load-source="docdb">MT</country><country mxw-id="DS660690824" load-source="docdb">NL</country><country mxw-id="DS660614953" load-source="docdb">NO</country><country mxw-id="DS660615265" load-source="docdb">PL</country><country mxw-id="DS660610945" load-source="docdb">PT</country><country mxw-id="DS660690825" load-source="docdb">RO</country><country mxw-id="DS660610946" load-source="docdb">RS</country><country mxw-id="DS660690826" load-source="docdb">SE</country><country mxw-id="DS660610951" load-source="docdb">SI</country><country mxw-id="DS660614954" load-source="docdb">SK</country><country mxw-id="DS660615266" load-source="docdb">SM</country><country mxw-id="DS660701677" load-source="docdb">TR</country></ep-contracting-states><ep-extended-states><ep-extended-state-data><country>BA</country></ep-extended-state-data><ep-extended-state-data><country>ME</country></ep-extended-state-data></ep-extended-states></designated-states></international-convention-data></bibliographic-data><abstract mxw-id="PA166480177" lang="EN" load-source="patent-office"><p id="pa01" num="0001">Identity document digital image correction method comprising the steps of:<br/>
identifying the type, class and issue of a presented identity document from a plurality of features in a digital image thereof;<br/>
retrieving from a reference identity document repository, information about a reference authentic version of an identity document of the same type, class and issue as the presented identity document;<br/>
allowing a user to select at least two features in the digital image of the presented identity document<br/>
calculating the distance between the two selected features;<br/>
determining from the information retrieved about the reference authentic version of the identity document, the distance between corresponding features in the reference authentic version of the identity document;<br/>
calculating a scaling factor γ<sub>x,y</sub> from the ratio of the distance between the two selected features in the presented identity document and the distance between corresponding features in the reference authentic version of the identity document;<br/>
applying the scaling factor to a one or more measurements of features in the digital image of the presented identity document.
<img id="iaf01" file="imgaf001.tif" wi="78" he="104" img-content="drawing" img-format="tif"/></p></abstract><abstract mxw-id="PA166759989" lang="EN" source="EPO" load-source="docdb"><p>Identity document digital image correction method comprising the steps of: 
identifying the type, class and issue of a presented identity document from a plurality of features in a digital image thereof; 
retrieving from a reference identity document repository, information about a reference authentic version of an identity document of the same type, class and issue as the presented identity document; 
allowing a user to select at least two features in the digital image of the presented identity document 
calculating the distance between the two selected features; 
determining from the information retrieved about the reference authentic version of the identity document, the distance between corresponding features in the reference authentic version of the identity document; 
calculating a scaling factor ³ x,y  from the ratio of the distance between the two selected features in the presented identity document and the distance between corresponding features in the reference authentic version of the identity document; 
applying the scaling factor to a one or more measurements of features in the digital image of the presented identity document.</p></abstract><description mxw-id="PDES98404878" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><heading id="h0001"><u>Field of the Invention</u></heading><p id="p0001" num="0001">The present invention relates to a correction method, system and computer program for a digital image of an identity document acquired by a digital camera, for use in, without limitation, an identity document verification system.</p><heading id="h0002"><u>Background to the Invention</u></heading><p id="p0002" num="0002">The UK Home Office Identity Fraud Steering Committee defines identity fraud as "when a false identity or someone else's identity details are used to support unlawful activity, or when someone avoids obligation/liability by falsely claiming that he/she was the victim of identity fraud" (National Fraud Authority, Fraud Typologies and Victims of Fraud - Literature Review 2009). Identity fraud usually entails the use of fraudulent, counterfeit or forged identity documents such as a passport or a driving licence. For the sake of clarity, the term "identity document" will be used henceforth to mean documentation provided by a user to support their claim to a specified identity</p><p id="p0003" num="0003">Identity crimes are one of the fastest growing types of fraud in the UK. The UK's Fraud prevention service found that identity fraud accounted for roughly 50% of all frauds recorded in 2012; and that there had been a 9 per cent increase in identity frauds, compared with 2011 (<nplcit id="ncit0001" npl-type="s"><text>CIFAS 2012 Fraud Trends, 17 Jan 2013</text></nplcit>). To counter the growth in identity fraud, a number of methods have been developed to improve the security of identity documents. In an ironic parallel with the above-mentioned growth in identity fraud, heightened security concerns and associated security awareness has led to the need for individuals to present identity documents (ID's) in increasing numbers of situations. This has led to a growing need for new identity document equipment that can rapidly read, verify, and analyze many different types of passports, documents of value, identity and security documents which employ the above-mentioned new materials and printing techniques.<!-- EPO <DP n="2"> --></p><p id="p0004" num="0004">In the past, digital images of presented identity documents were acquired by flat-bed scanners or specialised passport/identity card scanners. The digital images were then processed by specialised identity verification software (e.g. IDScan Document Expert System [Trade Mark]) to ascertain from specific features in the digital image, whether the presented identity document was authentic. However, this identity document verification technology, was inherently dependent on a fixed and rather inflexible infrastructure of scanners etc., which does not address the needs of the increasing demands for identity verification solutions in a wide diversity of settings.</p><p id="p0005" num="0005">However, the emergence of digital cameras in mobile phone devices and the rapid growth and global adoption of mobile phone technologies, have provided an alternative, more flexible solution to the challenges of identity document verification.</p><heading id="h0003"><u>Summary of the Invention</u></heading><p id="p0006" num="0006">According to the invention there is provided an identity document digital image correction method comprising the steps of:
<ul><li>identifying the type, class and issue of a presented identity document from a plurality of features in a digital image thereof;</li><li>retrieving from a reference identity document repository, information about a reference authentic version of an identity document of the same type, class and issue as the presented identity document;</li><li>allowing a user to select at least two features in the digital image of the presented identity document</li><li>calculating the distance between the two selected features;</li><li>determining from the information retrieved about the reference authentic version of the identity document, the distance between corresponding features in the reference authentic version of the identity document;</li><li>calculating a scaling factor γ<sub>x,y</sub> from the ratio of the distance between the two selected features in the presented identity document and the distance between corresponding features in the reference authentic version of the identity document;<!-- EPO <DP n="3"> --></li><li>applying the scaling factor to a one or more measurements of features in the digital image of the presented identity document.</li></ul></p><p id="p0007" num="0007">Preferably, the step of calculating the distance between the two selected features comprises the step of calculating a first distance in a substantially vertical direction and a second distance in a substantially horizontal direction;<br/>
the step of determining from the information retrieved about the reference authentic version of the identity document, the distance between corresponding features in the reference authentic version of the identity document, comprises the step of determining a first distance between the corresponding features in a substantially vertical direction and a second distance between the corresponding features in a substantially horizontal direction; and<br/>
the step of calculating a scaling factor γ<sub>x,y</sub> from the ratio of the distance between the two selected features in the presented identity document and the distance between corresponding features in the reference authentic version of the identity document, comprises calculating<br/>
a first ratio between the first distances in the presented identity document and the reference authentic version of the identity document, and<br/>
a second ratio between the second distances in the presented identity document and the reference authentic version of the identity document.</p><p id="p0008" num="0008">According to a second aspect of the invention there is provided an identity document digital image correction system comprising means adapted to carry out the steps of the identity document digital image correction method of the first aspect.</p><p id="p0009" num="0009">According to a third aspect of the invention there is provided an Identity document digital image correction computer program, tangibly embodied on a computer readable medium, the computer program product including instructions for causing a computer to execute the identity document digital image correction method of the first aspect.</p><heading id="h0004"><u>Description of the Invention</u></heading><!-- EPO <DP n="4"> --><p id="p0010" num="0010">An embodiment of the identity document digital image correction method is herein described, by way of example of only, with reference to the accompanying figures in which:
<ul><li><figref idrefs="f0001">Figure 1</figref> is a flowchart of the identity document digital image correction method of the preferred embodiment.</li></ul></p><p id="p0011" num="0011">A digital scanner comprises a glass plate onto which a document is placed. The scanner image acquisition system (mirrors, lens, filter and CCD array) make up the scan head mounted at a fixed distance from the glass plate. In use, the scan head is moved slowly across the document by a belt that is attached to a stepper motor. The image of the document is reflected by one or more mirrors onto a lens. The lens focuses the image through a filter on the CCD array. Scanner Resolution is the measurement of the resolving power of the scanner's optics and is expressed as dots per inch (dpi), but it is more accurately described as pixels per inch (ppi). A scanner's sensor takes an analog image and digitizes it line by line. Thus, a scanner's resolution is determined by
<ol><li>(a) the number of sensors in a single row (x-direction sampling rate) of the CCD or CIS array; and</li><li>(b) the precision of the stepper motor (y-direction sampling rate).</li></ol></p><p id="p0012" num="0012">Thus, the number of pixels acquired in a image of a scanned object is defined by height multiplied by width multiplied by a certain pixel density (ppi). For example, a 5x7 photograph scanned at 300 DPI would produce a digital image that is 1500 pixels wide and 2100 pixels in height. Since the distance between a document placed on the scanner's glass plate and the scan head; and the scanner's resolution (pixel density) is known, it is possible to work out the distance between individual elements within the digital image of the scanned document.</p><p id="p0013" num="0013">In contrast, digital camera resolution is normally measured by the total number of pixels it can capture (e.g. 10 MP, or 10,000,000 pixels). Similarly, since the distance may vary between an object being photographed and the corresponding digital camera, it can be difficult to ascribe a meaningful ppi resolution figure for a resulting digital image. In a conventional scanner, the angle with which a scanned item is presented to the scan head is fixed in one dimension by the necessity of<!-- EPO <DP n="5"> --> placing the scanned item on the glass plate of the scanner. However, when acquiring a digital image of an object with a digital camera, the object may be positioned at any angle to the digital camera. Consequently, the resulting digital image may be subject to perspective distortion (so that the apparent relative distances between elements of the digital image may differ from what might otherwise be expected).</p><p id="p0014" num="0014">Identity documents typically comprise a number of visible features which may be used to assess the authenticity of the identity document. These features may include, without limitation, details of the issuing source, the name/surname of the owner, the nationality/city of residence of the owner, a photograph and signature of the owner, an issue date, a stamp of an issuing authority, an expiration date, an identity document number. The specific features included in an identity document and their positioning relative to each other may vary markedly from one identity document to the next, depending on a variety of factors, including type (passport, driving licence, identity card etc.), country, issue date etc.</p><p id="p0015" num="0015">The pattern of these features effectively forms signature with which a digital image of a presented identity document can be compared against digital images of known, authentic identity documents of the same type, class and issuance etc. The digital images of known, authentic identity documents are typically obtained by conventional scanners. Since as mentioned above, images obtained from scanners differ from those obtained from digital cameras, in terms of their metrics for resolution and capability for determining distance between individual features in the images. Thus, in assessing the authenticity of a presented identity document, it is necessary to determine the exact distance between individual items in the image obtained by a digital camera of the identity document. This information will be used as a basis for the comparison of the image of the presented identity document and the image of the reference authentic identity document.</p><p id="p0016" num="0016">Referring to <figref idrefs="f0001">Figure 1</figref>, a preferred embodiment of the identity document digital image correction method comprises a first step of identifying 10 the type, class and issue of a presented identity document from a plurality of features in a digital image thereof. The preferred embodiment then retrieves 12 (from a reference identity<!-- EPO <DP n="6"> --> document repository [not shown]) information about a reference authentic version of an identity document of the same type, class and issue as the presented identity document. The information includes details of distances recorded in physical measurement units between individual features in the reference authentic version of the identity document.</p><p id="p0017" num="0017">Following this, the preferred embodiment comprises a next step of allowing 14 a user to select at least two features in the digital image of the presented identity document, to act as two anchor points (p<sub>1</sub>, p<sub>2</sub>)<sup>pres</sup> for subsequent calculations. Preferably, the anchor points (p<sub>1</sub>, p<sub>2</sub>)<sup>pres</sup> should be spaced as far apart as possible in both the horizontal and vertical axes. Indeed, ideally, the anchor points (p<sub>1</sub>, p<sub>2</sub>)<sup>pres</sup> should ideally be located at the diagonally opposed corners of the presented identity document. The purpose of selecting anchor points with the greatest spacing apart is to facilitate compensation for perspective (and/or other) image deformation in the digital image of the presented identity document. The preferred embodiment comprises a next step of calculating 16 the distance (in terms of the number of pixels) between the two anchor points (p<sub>1</sub>, p<sub>2</sub>)<sup>pres</sup> in both the horizontal and vertical directions. For the sake of clarity, this distance will henceforth be known as the presented anchor point intervening distance <maths id="math0001" num=""><math display="inline"><mrow><mfenced separators=""><msubsup><mi>α</mi><mrow><mi>x</mi><mo>,</mo><mi>y</mi></mrow><mi mathvariant="italic">pres</mi></msubsup><mo>=</mo><msubsup><mfenced open="|" close="|" separators=""><msub><mi>p</mi><mn>1</mn></msub><mo>-</mo><msub><mi>p</mi><mn>2</mn></msub></mfenced><mrow><mi>x</mi><mo>,</mo><mi>y</mi></mrow><mi mathvariant="italic">pres</mi></msubsup></mfenced></mrow></math><img id="ib0001" file="imgb0001.tif" wi="43" he="8" img-content="math" img-format="tif" inline="yes"/></maths></p><p id="p0018" num="0018">The preferred embodiment then determines 18 from the information retrieved about the reference authentic version of the identity document, the distance (in physical measurement units) between corresponding features/anchor points in the reference authentic version of the identity document. For the sake of clarity, this distance will henceforth be known as the authentic anchor point intervening distance <maths id="math0002" num=""><math display="inline"><mrow><mfenced separators=""><msubsup><mi>α</mi><mrow><mi>x</mi><mo>,</mo><mi>y</mi></mrow><mi mathvariant="italic">auth</mi></msubsup><mo>=</mo><msubsup><mfenced open="|" close="|" separators=""><msub><mi>p</mi><mn>1</mn></msub><mo>-</mo><msub><mi>p</mi><mn>2</mn></msub></mfenced><mrow><mi>x</mi><mo>,</mo><mi>y</mi></mrow><mi mathvariant="italic">auth</mi></msubsup></mfenced><mn>.</mn></mrow></math><img id="ib0002" file="imgb0002.tif" wi="45" he="7" img-content="math" img-format="tif" inline="yes"/></maths></p><p id="p0019" num="0019">The preferred embodiment then calculates 20 a scaling factor γ<sub>x,y</sub> (in both the x and y dimensions) from the ratio of the presented anchor point intervening distance and the authentic anchor point intervening distance <maths id="math0003" num=""><math display="block"><mrow><msub><mi>γ</mi><mrow><mi>x</mi><mo>,</mo><mi>y</mi></mrow></msub><mo>=</mo><mfrac><mrow><msubsup><mi>α</mi><mrow><mi>x</mi><mo>,</mo><mi>y</mi></mrow><mi mathvariant="italic">pres</mi></msubsup></mrow><mrow><msubsup><mi>α</mi><mrow><mi>x</mi><mo>,</mo><mi>y</mi></mrow><mi mathvariant="italic">auth</mi></msubsup></mrow></mfrac></mrow></math><img id="ib0003" file="imgb0003.tif" wi="26" he="14" img-content="math" img-format="tif"/></maths><!-- EPO <DP n="7"> --></p><p id="p0020" num="0020">The preferred embodiment then applies 22 the scaling factor to pixel-based measurements of features in the digital image of the presented identity document and converts the pixel-based measurements into their physical distance measurement equivalents. These physical distance measurements can be compared 24 with corresponding measurements of features in the authentic version of the identity document. The results of the comparison are used to assess 26 the authenticity of the presented identity document.</p><p id="p0021" num="0021">Modifications and alterations may be made to the above invention without departing from the scope of the arranged.</p></description><claims mxw-id="PCLM90459828" lang="EN" load-source="patent-office"><!-- EPO <DP n="8"> --><claim id="c-en-0001" num="0001"><claim-text>Identity document digital image correction method comprising the steps of:
<claim-text>identifying 10 the type, class and issue of a presented identity document from a plurality of features in a digital image thereof;</claim-text>
<claim-text>retrieving 12 from a reference identity document repository, information about a reference authentic version of an identity document of the same type, class and issue as the presented identity document;</claim-text>
<claim-text>allowing 14 a user to select at least two features in the digital image of the presented identity document</claim-text>
<claim-text>calculating 16 the distance between the two selected features;</claim-text>
<claim-text>determining 18 from the information retrieved about the reference authentic version of the identity document, the distance between corresponding features in the reference authentic version of the identity document;</claim-text>
<claim-text>calculating 20 a scaling factor γ<sub>x,y</sub> from the ratio of the distance between the two selected features in the presented identity document and the distance between corresponding features in the reference authentic version of the identity document;</claim-text>
<claim-text>applying 22 the scaling factor to a one or more measurements of features in the digital image of the presented identity document.</claim-text></claim-text></claim><claim id="c-en-0002" num="0002"><claim-text>The identity document digital image correction method as claimed in Claim 1 wherein<br/>
the step of calculating 16 the distance between the two selected features comprises the step of calculating a first distance in a substantially vertical direction and a second distance in a substantially horizontal direction;<br/>
the step of determining 18 from the information retrieved about the reference authentic version of the identity document, the distance between corresponding features in the reference authentic version of the identity document, comprises the step of determining a first distance between the corresponding features in a substantially vertical direction and a second distance between the corresponding features in a substantially horizontal direction; and<br/>
the step of calculating 20 a scaling factor γ<sub>x,y</sub> from the ratio of the distance between the two selected features in the presented identity document and the<!-- EPO <DP n="9"> --> distance between corresponding features in the reference authentic version of the identity document, comprises calculating<br/>
a first ratio between the first distances in the presented identity document and the reference authentic version of the identity document, and<br/>
a second ratio between the second distances in the presented identity document and the reference authentic version of the identity document.</claim-text></claim><claim id="c-en-0003" num="0003"><claim-text>Identity document digital image correction system comprising means adapted to carry out the steps of the identity document digital image correction method of Claim 1.</claim-text></claim><claim id="c-en-0004" num="0004"><claim-text>An identity document digital image correction computer program, tangibly embodied on a computer readable medium, the computer program product including instructions for causing a computer to execute the identity document digital image correction method as claimed in Claim 1.</claim-text></claim><claim id="c-en-0005" num="0005"><claim-text>The identity document digital image correction method substantially as described and illustrated in the accompanying drawings.</claim-text></claim></claims><drawings mxw-id="PDW20422540" load-source="patent-office"><!-- EPO <DP n="10"> --><figure id="f0001" num="1"><img id="if0001" file="imgf0001.tif" wi="164" he="224" img-content="drawing" img-format="tif"/></figure></drawings><search-report-data><doc-page id="srep0001" file="srep0001.tif" wi="162" he="233" type="tif"/><doc-page id="srep0002" file="srep0002.tif" wi="162" he="233" type="tif"/></search-report-data><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
