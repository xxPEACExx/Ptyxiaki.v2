<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2960812-A1" country="EP" doc-number="2960812" kind="A1" date="20151230" family-id="51211155" file-reference-id="316602" date-produced="20180824" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="160451465" ucid="EP-2960812-A1"><document-id><country>EP</country><doc-number>2960812</doc-number><kind>A1</kind><date>20151230</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-14306017-A" is-representative="YES"><document-id mxw-id="PAPP193865898" load-source="docdb" format="epo"><country>EP</country><doc-number>14306017</doc-number><kind>A</kind><date>20140627</date><lang>EN</lang></document-id><document-id mxw-id="PAPP193865899" load-source="patent-office" format="original"><country>EP</country><doc-number>14306017.6</doc-number><date>20140627</date><lang>EN</lang></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC162027057" ucid="EP-14306017-A" load-source="docdb"><document-id format="epo"><country>EP</country><doc-number>14306017</doc-number><kind>A</kind><date>20140627</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL-1988521915" load-source="docdb">G06F  17/30        20060101AFI20140917BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-1613213052" load-source="docdb" scheme="CPC">G06F  17/30843     20130101 FI20180727BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1613213053" load-source="docdb" scheme="CPC">G06F  17/30657     20130101 LI20180726BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1613213054" load-source="docdb" scheme="CPC">G06Q  50/01        20130101 LI20180726BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT165545861" lang="DE" load-source="patent-office">Verfahren und Vorrichtung zum Erzeugen eines Zusammenfassungsvideos</invention-title><invention-title mxw-id="PT165545862" lang="EN" load-source="patent-office">Method and apparatus for creating a summary video</invention-title><invention-title mxw-id="PT165545863" lang="FR" load-source="patent-office">Procédé et appareil de création d'un résumé vidéo</invention-title><citations><patent-citations><patcit mxw-id="PCIT335962067" load-source="docdb" ucid="US-20090164904-A1"><document-id format="epo"><country>US</country><doc-number>20090164904</doc-number><kind>A1</kind><date>20090625</date></document-id><sources><source name="SEA" category="I" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335962068" load-source="docdb" ucid="US-20100287475-A1"><document-id format="epo"><country>US</country><doc-number>20100287475</doc-number><kind>A1</kind><date>20101111</date></document-id><sources><source name="SEA" category="I" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335962069" load-source="docdb" ucid="US-8566315-B1"><document-id format="epo"><country>US</country><doc-number>8566315</doc-number><kind>B1</kind><date>20131022</date></document-id><sources><source name="SEA" category="I" created-by-npl="N"/></sources></patcit></patent-citations><non-patent-citations><nplcit><text>None</text><sources><source mxw-id="PNPL57937298" load-source="docdb" name="APP"/></sources></nplcit></non-patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR1103341142" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>THOMSON LICENSING</last-name><address><country>FR</country></address></addressbook></applicant><applicant mxw-id="PPAR1103321982" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>THOMSON LICENSING</last-name></addressbook></applicant><applicant mxw-id="PPAR1101651622" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Thomson Licensing</last-name><iid>101463287</iid><address><street>1-5 Rue Jeanne d'Arc</street><city>92130 Issy-Les-Moulineaux</city><country>FR</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR1103323991" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>GUEGAN MARIE</last-name><address><country>FR</country></address></addressbook></inventor><inventor mxw-id="PPAR1103341029" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>Guegan, Marie</last-name></addressbook></inventor><inventor mxw-id="PPAR1101650598" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Guegan, Marie</last-name><address><street>c/o Technicolor R&amp;D France 975 Avenue des Champs Blancs CS 17616</street><city>35576 Cesson-Sévigné</city><country>FR</country></address></addressbook></inventor><inventor mxw-id="PPAR1103341135" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>SCHMOUKER PHILIPPE</last-name><address><country>FR</country></address></addressbook></inventor><inventor mxw-id="PPAR1103316789" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>SCHMOUKER, PHILIPPE</last-name></addressbook></inventor><inventor mxw-id="PPAR1101644265" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>SCHMOUKER, PHILIPPE</last-name><address><street>c/o Technicolor R&amp;D France 975 Avenue des Champs Blancs CS 17616</street><city>35576 Cesson-Sévigné</city><country>FR</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR1101647761" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Huchet, Anne</last-name><iid>101463286</iid><address><street>Technicolor 1-5 rue Jeanne d'Arc</street><city>92130 Issy-Les-Moulineaux</city><country>FR</country></address></addressbook></agent></agents></parties><international-convention-data><designated-states><ep-contracting-states><country mxw-id="DS660783442" load-source="docdb">AL</country><country mxw-id="DS660610416" load-source="docdb">AT</country><country mxw-id="DS660783444" load-source="docdb">BE</country><country mxw-id="DS660687705" load-source="docdb">BG</country><country mxw-id="DS660690342" load-source="docdb">CH</country><country mxw-id="DS660606541" load-source="docdb">CY</country><country mxw-id="DS660610417" load-source="docdb">CZ</country><country mxw-id="DS660685430" load-source="docdb">DE</country><country mxw-id="DS660783445" load-source="docdb">DK</country><country mxw-id="DS660606542" load-source="docdb">EE</country><country mxw-id="DS660685042" load-source="docdb">ES</country><country mxw-id="DS660687706" load-source="docdb">FI</country><country mxw-id="DS660687735" load-source="docdb">FR</country><country mxw-id="DS660783446" load-source="docdb">GB</country><country mxw-id="DS660783447" load-source="docdb">GR</country><country mxw-id="DS660783448" load-source="docdb">HR</country><country mxw-id="DS660606543" load-source="docdb">HU</country><country mxw-id="DS660690347" load-source="docdb">IE</country><country mxw-id="DS660783449" load-source="docdb">IS</country><country mxw-id="DS660687736" load-source="docdb">IT</country><country mxw-id="DS660606544" load-source="docdb">LI</country><country mxw-id="DS660685439" load-source="docdb">LT</country><country mxw-id="DS660610418" load-source="docdb">LU</country><country mxw-id="DS660685440" load-source="docdb">LV</country><country mxw-id="DS660685441" load-source="docdb">MC</country><country mxw-id="DS660610565" load-source="docdb">MK</country><country mxw-id="DS660610566" load-source="docdb">MT</country><country mxw-id="DS660610427" load-source="docdb">NL</country><country mxw-id="DS660685047" load-source="docdb">NO</country><country mxw-id="DS660610428" load-source="docdb">PL</country><country mxw-id="DS660685048" load-source="docdb">PT</country><country mxw-id="DS660610429" load-source="docdb">RO</country><country mxw-id="DS660685447" load-source="docdb">RS</country><country mxw-id="DS660610430" load-source="docdb">SE</country><country mxw-id="DS660685448" load-source="docdb">SI</country><country mxw-id="DS660690348" load-source="docdb">SK</country><country mxw-id="DS660690349" load-source="docdb">SM</country><country mxw-id="DS660610579" load-source="docdb">TR</country></ep-contracting-states><ep-extended-states><ep-extended-state-data><country>BA</country></ep-extended-state-data><ep-extended-state-data><country>ME</country></ep-extended-state-data></ep-extended-states></designated-states></international-convention-data></bibliographic-data><abstract mxw-id="PA166479835" lang="EN" load-source="patent-office"><p id="pa01" num="0001">An automated creation of a summary video based on video segments (155) extracted from several videos (135) by using a social network of viewers (100) and a social curve (150) specified by a user (105) in order to select and order the video segments (170). A social network of viewers (100) (influence scores, experts) may be used to establish metrics for video segments (165). A social curve (150) may be defined with respect to the video segment metrics (165) to allow for the automatic creation of a summary video (175).
<img id="iaf01" file="imgaf001.tif" wi="88" he="116" img-content="drawing" img-format="tif"/></p></abstract><abstract mxw-id="PA166759647" lang="EN" source="EPO" load-source="docdb"><p>An automated creation of a summary video based on video segments (155) extracted from several videos (135) by using a social network of viewers (100) and a social curve (150) specified by a user (105) in order to select and order the video segments (170). A social network of viewers (100) (influence scores, experts) may be used to establish metrics for video segments (165). A social curve (150) may be defined with respect to the video segment metrics (165) to allow for the automatic creation of a summary video (175).</p></abstract><description mxw-id="PDES98404536" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><heading id="h0001">FIELD OF INVENTION</heading><p id="p0001" num="0001">The present disclosure generally relates to the automatic creation of a video summary based on a keyword search and social network analysis.</p><heading id="h0002">BACKGROUND</heading><p id="p0002" num="0002">With the prevalence of online content sharing, collaboration, and social media, many users are continuously uploading media content (e.g., pictures and video) to the Internet. In some instances, several users attending a single event may upload several hundreds of pieces of content from various devices to several different online content sharing and social websites. In other instances, many different users may provide content around similar ideas or concepts that are actively being discussed.</p><p id="p0003" num="0003">Once this content is uploaded, communities of users may comment on the various pieces of content, where some content may be seen more popular or viewed at a higher frequency than others. At times, some users may scour the various pieces of content from a single event or content that discuss similar ideas and/or subjects to manually create a new aggregated piece of content, such as a video mix, to form summary of an event, idea, or subject, for example. Since this manual process may be long and burdensome, there is a need for the automatic creation of video summaries around an event, idea, subject, etc.</p><p id="p0004" num="0004">However, one drawback from an automatic creation of a video summary from potentially hundreds of pieces of content is that there may be little control in the selection of quality content and/or content created by known users that is used to create the video summary. Therefore, there is a need for the ability to automatically create a video mix summary from a set of videos that also enable the user to define the types of content to be included in the video mix, where the types of content may be based on varying metrics that may be defined by a video summary system, the user, or within a social network of users.</p><heading id="h0003">BRIEF SUMMARY</heading><p id="p0005" num="0005">Some embodiments provide a method and apparatus for creating a summary video based on a social network analysis via a social network of users. Some embodiments provide for receiving a keyword query from a user wishing to create a summary video from several videos. Comments, which may or may not be synchronized to the video timeline, related to the several videos may be<!-- EPO <DP n="2"> --> retrieved based on the keyword query. Pre-selected video segments may then be provided based on the retrieved comments. Social metrics may then be assigned to the pre-selected video segments. A social curve for the video summary may then be received by the user, and a summary video based on the social curve can then be created, where the summary video is a combination of a set of pre-selected video segments.</p><p id="p0006" num="0006">The preceding Summary is intended to serve as a brief introduction to some embodiments of the present disclosure. It is not meant to be an introduction or overview of all inventive subject matter disclosed in this document. The Detailed Description that follows and the Drawings (or "Figures" or "FIGs.") that are referred to in the Detailed Description will further describe some of the embodiments described in the Summary as well as other embodiments. Accordingly, to understand all the embodiments described by this document, a full review of the Summary, Detailed Description and the Drawings is needed.</p><heading id="h0004">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p0007" num="0007">The novel features of the disclosure are set forth throughout this specification. However, for purpose of explanation, some embodiments are set forth in the following drawings.
<ul><li><figref idrefs="f0001"><b>Fig. 1</b></figref> illustrates a block diagram of an exemplary system for implementing an application for automatically creating a summary video according to one embodiment of the present disclosure;</li><li><figref idrefs="f0002"><b>Fig. 2</b></figref> illustrates an exemplary social curve used by some embodiments;</li><li><figref idrefs="f0003"><b>Fig. 3</b></figref> illustrates a flow chart of an exemplary process used in some embodiments for creating a summary video according to the present disclosure;</li><li><figref idrefs="f0004"><b>Fig. 4</b></figref> illustrates an exemplary block diagram of a system for implementing a summary video creation process according to some embodiments of the present disclosure;</li><li><figref idrefs="f0005"><b>Fig. 5</b></figref> illustrates a schematic block diagram of an exemplary computer system with which some embodiments may be implemented.</li></ul></p><heading id="h0005">DETAILED DESCRIPTION</heading><p id="p0008" num="0008">In the following detailed description, numerous details, examples, and embodiments are set forth and described. However, it will be clear and apparent to one skilled in the art that the disclosure is not limited to the embodiments set forth, and that the disclosed embodiments may be practiced without some of the specific details and examples discussed.<!-- EPO <DP n="3"> --></p><p id="p0009" num="0009">Throughout this disclosure several terms may be used to refer to different aspects of the automatic video summary creation process according to the present disclosure. A video segment refers to a continuous interval in a video (e.g., source video). Any reference to the term video is meant to convey a video signal with all its synchronized audio signals as a whole, where a video may also include animations, GIFs, and other similar multimedia content. A viewer is a user who posted one or more comments on one or more videos. Viewers may be organized into a social network in some embodiments. A comment is a document that is attached to a particular viewer and may be characterized by a set of text tags or keywords. Some comments may also be synchronized with a video's timeline, meaning that for each of these synchronized comments, there is a known link to a video segment. The user is the person who wants to build the summary video using video segments from all other videos. A social curve is a curve specifying the social score aspects of the video summary that is being built.</p><p id="p0010" num="0010">Some embodiments of the present disclosure provide a system and method that allows users to automatically generate a video summary from several videos, hereinafter source videos, based on video segments extracted from the several videos. The video summary can be produced automatically by a user specifying a keyword query and a social curve aligned to the desired video summary's timeline. To accomplish this, some embodiments may use textual data that is synchronized with the source videos' timelines. This data may be viewer comments that discuss particular time points or time periods in the source videos. A social network of these viewers may also be utilized in order to better select, rank, and/or order video segments to be included in the video summary.</p><p id="p0011" num="0011">For example, a web site that hosts videos and viewer comments associated with these videos may be a platform for executing the system and methods of the present disclosure. On such a video hosting platform, registered users may have the possibility to post comments in the feed of videos. Theses commenters may also explicitly specify the time point in the video that is being discussed. For example, the comment, "LOL 3:24," may be provided to indicate that the commentator saw something funny at minute 3'24".</p><p id="p0012" num="0012">Based on the several comments found on a video hosting website, a social network of viewers may be built based on viewers who co-comment on the same videos, viewers who subscribed or follow other viewers, friendship links, number of comments by a viewer, number of up-votes/down-votes received on comments by the viewer, etc. An exemplary implementation of how a video summary may be accomplished according to the present disclosure will now be<!-- EPO <DP n="4"> --> described in reference to <figref idrefs="f0001"><b>Fig. 1</b></figref><b>.</b></p><p id="p0013" num="0013"><figref idrefs="f0001"><b>Fig. 1</b></figref> illustrates a block diagram of an exemplary system for automatically creating a summary video according to one embodiment of the present disclosure. <figref idrefs="f0001"><b>Fig. 1</b></figref> includes a social network of viewers 100, a user 105, a search module 110, a social network module 115, a scoring module 120, a sort module 125, and an editing module 130. The various inputs and outputs illustrated in <figref idrefs="f0001"><b>Fig. 1</b></figref> include a set of videos 135 from one or more video hosting platforms, comments 140 made on the set of videos 135, keyword search queries 145 and a social curve 150 provided by the user, pre-selected video segments with 155, comment and social score pairings 160, video segment and social score pairings 165, ordered lists of video segments 170, and the summary video 175 provided by the system.</p><p id="p0014" num="0014">The system of the present disclosure may make use of one or more video hosting platforms that provide videos with a corresponding viewer comment thread, where some comments may be synchronized to the timeline of the video. A user 105 that wants to build a video summary from a set of videos 135 may use the video hosting platform's traditional search engine to select a set of videos 135 about a particular subject and/or event, for example. In this search, keywords that may be in the description of the videos or in the video tags and/or titles may be searched.</p><p id="p0015" num="0015">The user 105 may then continue to the process of pre-selecting a set of video segments using a search module 110. This may be accomplished by the search module 110 via a keyword search query 145 that matches comments that may or may not be synchronized to the timelines in the set of videos. Specifically, the search module 110 returns a set of matched comments and the video segments 155 based on the keyword search query 145.</p><p id="p0016" num="0016">A social network module 115 may analyze a social network of viewers 100 and assign a scoring metric to each viewer (e.g., influence scores, expert scores, etc.). The scoring metric may interchangeably be referred to as a social score throughout this disclosure. The social network may be built by considering viewers 100 that have commented on the set of videos, or only viewers 100 who commented on the subset of pre-selected video segments 155. As a result of this social network module 115, each comment (not necessarily a synchronized comment) may be assigned the social score 160 of its viewer. In another embodiment, the social score 160 may be associated to each comment rather than to its creator and is evaluated as a function (e.g., weighted function) of its creator's social score and of the comment's own score. The final comment score 160 or metric may be evaluated according to its position within the discussion thread it belongs to (e.g. lead comment, response comment, ending comment, etc.), the length of the discussion thread, the number of<!-- EPO <DP n="5"> --> comments that have been later posted and relating to this comment, the number of viewers who co-commented on the same videos, viewers who subscribed or follow other viewers, friendship links, number of comments by a viewer, number of up-votes/down-votes received on comments by the viewer, etc. One of ordinary skill in the art will recognize that various appropriate methods may be used to ascertain any type of metric to video segments and/or comments based on the available data points provided within a video hosting platform.</p><p id="p0017" num="0017">The scoring module 120 may then aggregate the social scores 160 of comments for each pre-selected video segment 155 and compute a social score for the video segment 165. For example, a video segment social score 165 for any particular pre-selected video segment 155 may be the sum, the median or the mean of the scores 160 or of a part of the scores 160 (e.g., a function applied on the best 50%, or the worst 67%, or the part of the scores 160 that is in the range of the best 40%-90%.)</p><p id="p0018" num="0018">The user 105 may also pre-define a social curve 150 using a graphical interface, for example. <figref idrefs="f0002"><b>Fig. 2</b></figref> illustrates an exemplary social curve 200 where a social score 205 is mapped on a y-axis and a time duration 210 of the video summary to be created is mapped along the x-axis. Using a social curve interface, the user 150 may pre-define the preferred duration 205 of the video summary, and draw freehand the general shape (i.e. social curve 200) of social score the user 105 wants to use for the video summary. The social curve 200 enables the user to alternate between video segments that were commented on by important people in the social network of viewers 100 and others that were not commented on by known and/or highly rated people within the social network of viewers 100.</p><p id="p0019" num="0019">The sort module 125 may then use the social curve 150 provided by the user 105 and order the pre-selected video segments 165 so as to concur with the social curve 150. For example, a higher value of the curve should indicate a video segment with a higher social score. The sort module 125 may also discard video segments in cases where the video segments are too numerous or too long. The sort module 125 then returns an ordered list of selected video segments 170 for the final video summary.</p><p id="p0020" num="0020">The ordering of video segments may be conducted in various ways. For example, a user 105 provides the desired social curve 150, where the curve dictates the duration of the summary video along the x-axis. Then each video segment 165 may be compared with the social score specified by the social curve 150 at a corresponding time along the time axis. The analysis may be integrated over the duration of the considered video segments. The video segments 165 that best fit<!-- EPO <DP n="6"> --> the integrated social curve level 205 (e.g., exact value ± delta/difference) are then identified. When several video segments are identified as fitting the social curve 150, one of the video segments 165 may be selected at random or based on a defined selection criteria for selecting one out of many potential video segments. The sorting may be an optimization where the goal may be to minimize the area under the absolute value of the social curve 200 minus the social curve of the ordered video segments 170. An additional regularization parameter may assist in controlling the length of the selected video segments 165.</p><p id="p0021" num="0021">Another exemplary method for selecting one of the matching video segments 165 is to select the video segment that best fits the curve displacement or, when several video segments 165 are best fits for the curve, selecting one of the best fits at random. In some embodiments, if the curve is sharp (high valued derivatives), the shortest video clips may be selected. If the curve is flat, a few short video segments and a longer video segment may be selected.</p><p id="p0022" num="0022">Eventually, the editing module 130 takes the ordered list of video segments 170 and builds the final video summary 175. The editing module 130 may add transitions between video sequences so both the audio signal and the video signal between two video segments transition smoothly. For example, fading techniques may be applied from segment to segment.</p><p id="p0023" num="0023"><figref idrefs="f0003"><b>Fig. 3</b></figref> illustrates a flow chart of an exemplary process 300 used in some embodiments for creating a summary video according to the present disclosure. The process 300 may begin by receiving (at step 310) a keyword query from a user. The process 300 may then retrieve (at step 320) all comments that are relevant to the keyword query using a search module 110 similar to the one described in <figref idrefs="f0001"><b>Fig. 1</b></figref><b>.</b> Some or all of the retrieved comments may be synchronized comments that identify a time or segment of the video for which the comment corresponds to. Then the module 110 returns (at step 330) video segments that are related to the comments. For comments that are not synchronized comments, the entire video may be treated as a single video segment. Synchronized comments that identify a time may treat a pre-defined duration of the video as a video segment, where the video segment begins at the identified time and ends at a pre-defined duration. Synchronized comments that identify a complete segment (e.g., identify a start and end time or duration) will return the appropriate portion as a video segment in step 330.</p><p id="p0024" num="0024">Using a social network of viewers, the process 300 may then infer a social metric or score for each viewer and assign (at step 340) the social metric to each viewer's comments. The process 300 may then use a scoring module to assign (at step 350) a social metric to each pre-selected video segment from step 330 based on the social metrics of the video segment's related<!-- EPO <DP n="7"> --> comments assigned at step 340.</p><p id="p0025" num="0025">The process 300 then receives (at step 360) a social curve (e.g., 200) specified by a user for the video summary to be created. This social curve specifies the alternation between high scored and low-scored parts of the video summary. The process 300 may then use a sort module to return (at step 370) an ordered list of the selected video segments based on the social metrics of the video segments so that the order of video segments follow the social curve received at 360. Finally, the process 300 may create (at step 380) a summary video using an editing module via the ordered list of video segments from 370.</p><p id="p0026" num="0026">One of ordinary skill in the art will recognize that process 300 may be performed in various appropriate ways without departing from the scope of the disclosure. For instance, the process may not be performed as one continuous series of operations in some embodiments. In addition, the process may be implemented using several sub-processes or as part of a larger macro-process. Furthermore, various processes may be performed concurrently, sequentially, or some combination of sequentially and concurrently. Moreover, the operations of the process may be performed in different orders.</p><p id="p0027" num="0027"><figref idrefs="f0004"><b>Fig. 4</b></figref> illustrates an exemplary block diagram of a system 400 for implementing a summary video creation process or engine according to some embodiments of the present disclosure. The system 400 includes a server 410 and one or more electronic devices such as smart phones 420, personal computers (PCs) (e.g., desktops or laptops) 430, and tablets 440. The server 410 provides support for the summary video creation processes and/or engine according to the present disclosure as well as for hosting videos used in the video summary and/or the summary video itself via the Internet 450. In some embodiments, users may access the summary video engine on the server 410 and provide a keyword search query and social curve via a browser or application on the electronic devices.</p><p id="p0028" num="0028">In some embodiments, the above-described operations may be implemented as on a particular machine such as a desktop computer, laptop, handheld device (e.g. smartphone or tablet), one or more servers accessible via the Internet, or any combination of such devices. Many of the processes and modules described may also be implemented as software processes that are specified as at least one set of instructions recorded on a non-transitory computer readable storage medium. When these instructions are executed by one or more computational elements (e.g., microprocessors, microcontrollers, Digital Signal Processors ("DSPs"), Application-Specific ICs ("ASICs"), Field Programmable Gate Arrays ("FPGAs"), etc.) the instructions cause the computational element(s) to<!-- EPO <DP n="8"> --> perform actions specified in the instructions.</p><p id="p0029" num="0029"><figref idrefs="f0005"><b>Fig. 5</b></figref> illustrates a schematic block diagram of a computer system 500 with which some embodiments of the disclosure may be implemented. For example, the system described above in reference to <figref idrefs="f0001"><b>Fig. 1</b></figref> may be at least partially implemented using computer system 500. As another example, the processes described in reference to <figref idrefs="f0003"><b>Fig. 3</b></figref> may be at least partially implemented using sets of instructions that are executed using computer system 500.</p><p id="p0030" num="0030">Computer system 500 may be implemented using various appropriate devices. For instance, the computer system may be implemented using one or more personal computers ("PC"), servers, mobile devices (e.g., a Smartphone), tablet devices, and/or any other appropriate devices. The various devices may work alone (e.g., the computer system may be implemented as a single PC) or in conjunction (e.g., some components of the computer system may be provided by a mobile device while other components are provided by a tablet device).</p><p id="p0031" num="0031">Computer system 500 may include a bus 510, at least one processing element 520, a system memory 530, a read-only memory ("ROM") 540, other components (e.g., a graphics processing unit) 550, input devices 560, output devices 570, permanent storage devices 580, and/or a network connection 590. The components of computer system 500 may be electronic devices that automatically perform operations based on digital and/or analog input signals.</p><p id="p0032" num="0032">Bus 510 may represent all communication pathways among the elements of computer system 500. Such pathways may include wired, wireless, optical, and/or other appropriate communication pathways. For example, input devices 560 and/or output devices 570 may be coupled to the system 500 using a wireless connection protocol or system. The processor 520 may, in order to execute the processes of some embodiments, retrieve instructions to execute and data to process from components such as system memory 530, ROM 540, and permanent storage device 580. Such instructions and data may be passed over bus 510.</p><p id="p0033" num="0033">ROM 540 may store static data and instructions that may be used by processor 520 and/or other elements of the computer system. Permanent storage device 580 may be a read-and-write memory device. This device may be a non-volatile memory unit that stores instructions and data even when computer system 500 is off or unpowered. Permanent storage device 580 may include a mass-storage device (such as a magnetic or optical disk and its corresponding disk drive, flash memory/storage, SIM cards, etc).</p><p id="p0034" num="0034">Computer system 500 may use a removable storage device and/or a destination storage device as the permanent storage device. System memory 530 may be a volatile read-and-write<!-- EPO <DP n="9"> --> memory, such as a random access memory ("RAM"). The system memory may store some of the instructions and data that the processor uses at runtime. The sets of instructions and/or data used to implement some embodiments may be stored in the system memory 530, the permanent storage device 580, and/or the read-only memory 540. For example, the various memory units may include instructions for authenticating a client-side application at the server-side application in accordance with some embodiments. Other components (e.g. 550) may perform various other functions. These functions may include interfacing with various communication devices, systems, and/or protocols.</p><p id="p0035" num="0035">Input devices 560 may enable a user to communicate information to the computer system and/or manipulate various operations of the system. The input devices may include keyboards, cursor control devices, audio input devices and/or video input devices. Output devices 570 may include printers, displays, and/or audio devices. Some or all of the input and/or output devices may be wirelessly or optically connected to the computer system.</p><p id="p0036" num="0036">Finally, as shown in <figref idrefs="f0005"><b>Fig. 5</b></figref><b>,</b> computer system 500 may be coupled to a network through a network adapter 590. For example, computer system 500 may be coupled to a web server on the Internet such that a web browser executing on computer system 500 may interact with the web server as a user interacts with an interface that operates in the web browser.</p><p id="p0037" num="0037">As used in this specification and any claims of this application, the terms "computer", "server", "processor", and "memory" all refer to electronic devices. These terms exclude people or groups of people. As used in this specification and any claims of this application, the term "non-transitory storage medium" is entirely restricted to tangible, physical objects that store information in a form that is readable by electronic devices. These terms exclude any wireless or other ephemeral signals.</p><p id="p0038" num="0038">It should be recognized by one of ordinary skill in the art that any or all of the components of computer system 500 may be used in conjunction with the disclosed embodiments. Moreover, one of ordinary skill in the art will appreciate that many other system configurations may also be used in conjunction with the disclosed embodiments or components of the embodiments.</p><p id="p0039" num="0039">Moreover, while the examples shown may illustrate many individual modules as separate elements, one of ordinary skill in the art would recognize that these modules may be combined into a single functional block or element. One of ordinary skill in the art would also recognize that a single module may be divided into multiple modules.</p><p id="p0040" num="0040">While the disclosure has been described with reference to numerous specific details, one of ordinary skill in the art will recognize that the disclosure can be embodied in other specific<!-- EPO <DP n="10"> --> forms without departing from the scope of the disclosure. For example, several embodiments were described above by reference to particular features and/or components. However, one of ordinary skill in the art will realize that other embodiments might be implemented with other types of features and components, and that the disclosure is not to be limited by the foregoing illustrative details.</p></description><claims mxw-id="PCLM90459472" lang="EN" load-source="patent-office"><!-- EPO <DP n="11"> --><claim id="c-en-0001" num="0001"><claim-text>A method for creating summary video comprising:
<claim-text>retrieving (320) comments from a plurality of videos based on a query;</claim-text>
<claim-text>returning (330) video segments based on the retrieved comments;</claim-text>
<claim-text>assigning (350) social metrics to the video segments;</claim-text>
<claim-text>receiving (360) a social curve for the video summary; and</claim-text>
<claim-text>creating (380) a summary video based on the social curve, wherein the summary video is a combination of a set of the video segments.</claim-text></claim-text></claim><claim id="c-en-0002" num="0002"><claim-text>The method of claim 1, wherein the comments are synchronized comments that refer to a particular time or segment of a corresponding video.</claim-text></claim><claim id="c-en-0003" num="0003"><claim-text>The method of claim 1 or 2 further comprising assigning (340) a social metric to the comments, wherein the social metric of the video segments is based on the assigned metrics to the comments.</claim-text></claim><claim id="c-en-0004" num="0004"><claim-text>The method of claim 1 or 2 further comprising returning (370) an ordered list of video segments, wherein the ordered list of video segments corresponds to the social curve.</claim-text></claim><claim id="c-en-0005" num="0005"><claim-text>The method of claims 1 through 4, wherein the assigned social metric of the video segments is based on a viewer's social activity, wherein the viewer is the creator of the comment that corresponds to the video segment.</claim-text></claim><claim id="c-en-0006" num="0006"><claim-text>The method of claims 1 through 5, wherein the assigned social metric of the video segments is further based on a function of a creator social metric and a comment social metric.</claim-text></claim><claim id="c-en-0007" num="0007"><claim-text>The method of claim 6, wherein the comment social metric is based on a comment position within a discussion thread of the video associated with comment.</claim-text></claim><claim id="c-en-0008" num="0008"><claim-text>The method of claim 6, wherein the comment social metric is based on a length of a discussion thread of the video associated with comment.<!-- EPO <DP n="12"> --></claim-text></claim><claim id="c-en-0009" num="0009"><claim-text>The method of claim 6, wherein the comment social metric is based on a number of comments relating back to the comments.</claim-text></claim><claim id="c-en-0010" num="0010"><claim-text>The method of claim 1, wherein the social curve defines the length of the summary video and a required social metric for each video segment spanning the timeline of the summary video.</claim-text></claim><claim id="c-en-0011" num="0011"><claim-text>The method of claim 1 or 10, wherein a video segment is chosen at random for incorporation into the summary video when one or more videos conforms to a particular slot along the social curve.</claim-text></claim><claim id="c-en-0012" num="0012"><claim-text>The method of claim 1 or 10, wherein a video segment is chosen based on a length of video when the social curve contains sharp or flat regions along the curve.</claim-text></claim><claim id="c-en-0013" num="0013"><claim-text>The method of claims 1 through 12, wherein the video summary introduces transition between video segments in the set of video segments.</claim-text></claim><claim id="c-en-0014" num="0014"><claim-text>An apparatus configured to create a summary video from a plurality of videos, <b>characterized in that</b> said summary video is generated by the method according to any one of claims 1 to 13.</claim-text></claim></claims><drawings mxw-id="PDW20422199" load-source="patent-office"><!-- EPO <DP n="13"> --><figure id="f0001" num="1"><img id="if0001" file="imgf0001.tif" wi="165" he="218" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="14"> --><figure id="f0002" num="2"><img id="if0002" file="imgf0002.tif" wi="164" he="155" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="15"> --><figure id="f0003" num="3"><img id="if0003" file="imgf0003.tif" wi="139" he="224" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="16"> --><figure id="f0004" num="4"><img id="if0004" file="imgf0004.tif" wi="125" he="188" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="17"> --><figure id="f0005" num="5"><img id="if0005" file="imgf0005.tif" wi="165" he="143" img-content="drawing" img-format="tif"/></figure></drawings><search-report-data><doc-page id="srep0001" file="srep0001.tif" wi="159" he="233" type="tif"/><doc-page id="srep0002" file="srep0002.tif" wi="159" he="233" type="tif"/></search-report-data><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
