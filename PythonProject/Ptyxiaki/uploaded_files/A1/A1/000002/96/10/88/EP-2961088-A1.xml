<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2961088-A1" country="EP" doc-number="2961088" kind="A1" date="20151230" family-id="53487191" file-reference-id="312929" date-produced="20180824" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="160451244" ucid="EP-2961088-A1"><document-id><country>EP</country><doc-number>2961088</doc-number><kind>A1</kind><date>20151230</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-15172033-A" is-representative="YES"><document-id mxw-id="PAPP193865456" load-source="patent-office" format="original"><country>EP</country><doc-number>15172033.1</doc-number><date>20150615</date><lang>EN</lang></document-id><document-id mxw-id="PAPP193865457" load-source="docdb" format="epo"><country>EP</country><doc-number>15172033</doc-number><kind>A</kind><date>20150615</date><lang>EN</lang></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC162028720" ucid="US-201414312031-A" load-source="docdb"><document-id format="epo"><country>US</country><doc-number>201414312031</doc-number><kind>A</kind><date>20140623</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL-1988520621" load-source="docdb">H04H  60/12        20080101ALI20151015BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-1988521120" load-source="docdb">H04H  40/36        20080101AFI20151015BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-1988524338" load-source="docdb">H04H  20/26        20080101ALI20151015BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-1763875296" load-source="docdb" scheme="CPC">H04H  40/36        20130101 LI20170919BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1763875297" load-source="docdb" scheme="CPC">H04H  20/22        20130101 LI20170919BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1984701174" load-source="docdb" scheme="CPC">G10H   1/18        20130101 FI20151224BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT165545198" lang="DE" load-source="patent-office">SYSTEM UND VERFAHREN ZUR MISCHUNG VON MULTIKANALSIGNALEN</invention-title><invention-title mxw-id="PT165545199" lang="EN" load-source="patent-office">SYSTEM AND METHOD FOR BLENDING MULTI-CHANNEL SIGNALS</invention-title><invention-title mxw-id="PT165545200" lang="FR" load-source="patent-office">SYSTÈME ET PROCÉDÉ DE MÉLANGE DE SIGNAUX MULTICANAUX</invention-title><citations><patent-citations><patcit mxw-id="PCIT335744305" load-source="docdb" ucid="JP-2010193117-A"><document-id format="epo"><country>JP</country><doc-number>2010193117</doc-number><kind>A</kind><date>20100902</date></document-id><sources><source name="SEA" category="A" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335739717" load-source="docdb" ucid="US-20070293167-A1"><document-id format="epo"><country>US</country><doc-number>20070293167</doc-number><kind>A1</kind><date>20071220</date></document-id><sources><source name="SEA" category="X" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT397009497" load-source="docdb" ucid="US-20130003894-A1"><document-id format="epo"><country>US</country><doc-number>20130003894</doc-number><kind>A1</kind><date>20130103</date></document-id><sources><source name="SEA" category="XI" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335740025" load-source="docdb" ucid="US-6490551-B2"><document-id format="epo"><country>US</country><doc-number>6490551</doc-number><kind>B2</kind><date>20021203</date></document-id><sources><source name="APP" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335738893" load-source="docdb" ucid="WO-2001011809-A1"><document-id format="epo"><country>WO</country><doc-number>2001011809</doc-number><kind>A1</kind><date>20010215</date></document-id><sources><source name="SEA" category="X" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335745815" load-source="docdb" ucid="WO-2013075138-A1"><document-id format="epo"><country>WO</country><doc-number>2013075138</doc-number><kind>A1</kind><date>20130523</date></document-id><sources><source name="SEA" category="X" created-by-npl="N"/></sources></patcit></patent-citations><non-patent-citations><nplcit><text>LAUBER ET AL.: "Error concealment for compressed digital audio", PROCEEDINGS OF THE 111 TH AES CONVENTION, NEW YORK, September 2001 (2001-09-01)</text><sources><source mxw-id="PNPL57906833" load-source="docdb" name="APP"/></sources></nplcit></non-patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR1103328737" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>NXP BV</last-name><address><country>NL</country></address></addressbook></applicant><applicant mxw-id="PPAR1103311686" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>NXP B.V.</last-name></addressbook></applicant><applicant mxw-id="PPAR1101653544" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>NXP B.V.</last-name><iid>100810158</iid><address><street>High Tech Campus 60</street><city>5656 AG Eindhoven</city><country>NL</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR1103313958" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>GAUTAMA TEMUJIN</last-name><address><country>GB</country></address></addressbook></inventor><inventor mxw-id="PPAR1103312433" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>Gautama, Temujin</last-name></addressbook></inventor><inventor mxw-id="PPAR1101652312" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Gautama, Temujin</last-name><address><street>c/o NXP Semiconductors, Intellectual Property &amp; Licensing, Red Central 60 High Street</street><city>Redhill, Surrey RH1 1SH</city><country>GB</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR1101645765" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Terblanche, Candice Jane</last-name><iid>101487770</iid><address><street>NXP Semiconductors Intellectual Property and Licensing Red Central 60 High Street</street><city>Redhill, Surrey RH1 1SH</city><country>GB</country></address></addressbook></agent></agents></parties><international-convention-data><designated-states><ep-contracting-states><country mxw-id="DS660604346" load-source="docdb">AL</country><country mxw-id="DS660607231" load-source="docdb">AT</country><country mxw-id="DS660604356" load-source="docdb">BE</country><country mxw-id="DS660682425" load-source="docdb">BG</country><country mxw-id="DS660681845" load-source="docdb">CH</country><country mxw-id="DS660782356" load-source="docdb">CY</country><country mxw-id="DS660607232" load-source="docdb">CZ</country><country mxw-id="DS660681942" load-source="docdb">DE</country><country mxw-id="DS660604357" load-source="docdb">DK</country><country mxw-id="DS660782357" load-source="docdb">EE</country><country mxw-id="DS660684532" load-source="docdb">ES</country><country mxw-id="DS660682426" load-source="docdb">FI</country><country mxw-id="DS660682431" load-source="docdb">FR</country><country mxw-id="DS660681947" load-source="docdb">GB</country><country mxw-id="DS660604358" load-source="docdb">GR</country><country mxw-id="DS660681948" load-source="docdb">HR</country><country mxw-id="DS660782358" load-source="docdb">HU</country><country mxw-id="DS660681846" load-source="docdb">IE</country><country mxw-id="DS660604367" load-source="docdb">IS</country><country mxw-id="DS660682432" load-source="docdb">IT</country><country mxw-id="DS660604368" load-source="docdb">LI</country><country mxw-id="DS660681949" load-source="docdb">LT</country><country mxw-id="DS660607233" load-source="docdb">LU</country><country mxw-id="DS660681950" load-source="docdb">LV</country><country mxw-id="DS660681955" load-source="docdb">MC</country><country mxw-id="DS660607234" load-source="docdb">MK</country><country mxw-id="DS660607235" load-source="docdb">MT</country><country mxw-id="DS660604369" load-source="docdb">NL</country><country mxw-id="DS660681957" load-source="docdb">NO</country><country mxw-id="DS660604370" load-source="docdb">PL</country><country mxw-id="DS660682433" load-source="docdb">PT</country><country mxw-id="DS660604375" load-source="docdb">RO</country><country mxw-id="DS660682434" load-source="docdb">RS</country><country mxw-id="DS660604376" load-source="docdb">SE</country><country mxw-id="DS660681851" load-source="docdb">SI</country><country mxw-id="DS660681958" load-source="docdb">SK</country><country mxw-id="DS660681963" load-source="docdb">SM</country><country mxw-id="DS660607236" load-source="docdb">TR</country></ep-contracting-states><ep-extended-states><ep-extended-state-data><country>BA</country></ep-extended-state-data><ep-extended-state-data><country>ME</country></ep-extended-state-data></ep-extended-states></designated-states></international-convention-data></bibliographic-data><abstract mxw-id="PA166479614" lang="EN" load-source="patent-office"><p id="pa01" num="0001">Embodiments of systems and methods for blending multi-channel signals are described. In one embodiment, a method for blending multi-channel signals involves computing component signals from the multi-channel signals, cross-fading the component signals based on different temporal rates to generate cross-faded component signals and generating a blended multi-channel signal based on the cross-faded component signals. Other embodiments are also described.
<img id="iaf01" file="imgaf001.tif" wi="165" he="100" img-content="drawing" img-format="tif"/></p></abstract><abstract mxw-id="PA166759426" lang="EN" source="EPO" load-source="docdb"><p>Embodiments of systems and methods for blending multi-channel signals are described. In one embodiment, a method for blending multi-channel signals involves computing component signals from the multi-channel signals, cross-fading the component signals based on different temporal rates to generate cross-faded component signals and generating a blended multi-channel signal based on the cross-faded component signals. Other embodiments are also described.</p></abstract><description mxw-id="PDES98404315" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><p id="p0001" num="0001">Embodiments of the invention relate generally to signal processing systems and methods, and, more particularly, to systems and methods for processing multi-channel signals.</p><p id="p0002" num="0002">Digital transmission systems can be used to replace traditional analog transmission systems. For example, in digital radio broadcasts, signals are encoded in the digital domain, as opposed to traditional analog broadcasts using Amplitude modulation (AM) or frequency modulation (FM) systems. The received and decoded digital audio signals have a number of advantages over their analog counterparts, such as a better sound quality, and a better robustness to radio interferences (multi-path interference, co-channel noise, etc.).</p><p id="p0003" num="0003">However, some digital transmission systems are used in combination with analog transmission systems. For example, many radio stations that transmit digital radio also transmit the same program in an analog manner (e.g., in AM or FM). When the reception quality of a digital signal (e.g., an encoded digital audio signal) degrades, the received or encoded signal may contain one or more bit errors. If the bit errors are still present after error detection and error correction have been applied, the corresponding audio frame may not be decodable, and thus, are partially or completely "corrupted." One method of dealing with bit errors is to mute the audio output for a certain period of time (e.g., during one or more frames). Other methods use more advanced error concealment strategies as described in <patcit id="pcit0001" dnum="US6490551B"><text>Wiese at el., U.S. Patent number 6,490,551</text></patcit>. In these strategies, the corrupted signal sections are detected, after which they are replaced by signal sections from the same channel or an adjacent channel. The signal sections may be replaced completely or only one or more frequency bands may be replaced. Another approach involves noise substitution, where an audio frame may be replaced by a noise frame, the spectral envelope of which may be matched to that expected from the audio frame, as described in<nplcit id="ncit0001" npl-type="s"><text> Lauber et al, "Error concealment for compressed digital audio," In Proceedings of the 111th AES Convention, New York, September 2001</text></nplcit>.<!-- EPO <DP n="2"> --></p><p id="p0004" num="0004">When two broadcasts of the same content are available (e.g., one digital audio broadcast and one analog audio broadcast or two digital/analog broadcasts of the same program), there is a possibility for a corresponding receiver to switch or cross-fade from one broadcast to the other, for example, when the reception of one broadcast is worse than the reception of another broadcast. Cross-fading between different signals (e.g., different broadcasts) is also referred to as signal blending. However, two multi-channel signals, e.g., a Digital Audio Broadcasting (DAB) stereo signal and an FM stereo signal, can have different stereo information, due to processing that has been performed as a result of bad reception quality. Therefore, when a blending operation from one multi-channel signal to the other multi-channel signal is performed, there can be artifacts as a consequence, especially when there are frequent transitions from one multi-channel signal to the other multi-channel signal and back.</p><p id="p0005" num="0005">Embodiments of systems and methods for blending multi-channel signals are described. In ea first aspect, a method for blending multi-channel signals involves computing component signals from the multi-channel signals, cross-fading the component signals based on different temporal rates to generate cross-faded component signals and generating a blended multi-channel signal based on the cross-faded component signals. By cross-fading component signals of multi-channel signals based on different temporal rates, artifacts caused by signal blending be reduced. Other embodiments are also described.</p><p id="p0006" num="0006">Computing the component signals from the multi-channel signals may comprise computing the component signals such that each of the component signals is selected from the group consisting of: a combination of a plurality of channels of the multi-channel signal; a signal that contains a plurality of features extracted from the multi-channel signal in the time domain or in the frequency domain; and a filtered version of the multi-channel signal. Cross-fading the component signals based on the different temporal rates may comprise: computing a plurality of mixing factors based on the different temporal rates; and mixing the component signals based on the mixing factors.</p><p id="p0007" num="0007">In a second aspect, a system for blending multi-channel signals includes a component signals calculation unit configured to compute component signals from<!-- EPO <DP n="3"> --> the multi-channel signals, a signal cross-fading unit configured to cross-fade the component signals based on different temporal rates to generate cross-faded component signals, and a signal processing unit configured to generate a blended multi-channel signal based on the cross-faded component signals.</p><p id="p0008" num="0008">Each of the component signals may be selected from the group consisting of: a combination of a plurality of channels of the multi-channel signal; a signal that contains a plurality of features extracted from the multi-channel signal in the time domain or in the frequency domain; and a filtered version of the multi-channel signal. The signal cross-fading unit may be further configured to: compute a plurality of mixing factors based on the different temporal rates; and mix the component signals based on the mixing factors. The component signals calculation unit may be further configured to compute a sum signal and a difference signal from each of the multi-channel signals.</p><p id="p0009" num="0009">The signal cross-fading unit may be further configured to: calculate a first mixing factor based on a first temporal rate; and calculate a second mixing factor based on a second temporal rate such that a transition rate of the first mixing factor is faster than a transition rate of the second mixing factor; mix the sum signals based on the first mixing factor; and mix the difference signals based on the second mixing factor. The multi-channel signals may comprise a first stereo audio signal and a second stereo audio signal that carries the same audio content as the first stereo audio signal, wherein the component signals calculation unit may be further configured to: compute a first sum signal and a first difference signal from the first stereo audio signal; and compute a second sum signal and a second difference signal from the second stereo audio signal, wherein the signal cross-fading unit is further configured to: cross-fade the first and second sum signals based on a first temporal rate to generate a cross-faded sum signal; and cross-fade the first and second difference signals based on a second temporal rate to generate a cross-faded difference signal, wherein the second temporal rate is different from the first temporal rate, wherein the signal processing unit may be further configured to: generate a blended stereo audio signal based on the cross-faded sum signal and the cross-faded difference signal.</p><p id="p0010" num="0010">In a third aspect, a computer-readable storage medium contains program instructions for blending multi-channel signals. Execution of the program<!-- EPO <DP n="4"> --> instructions by one or more processors causes the one or more processors to perform steps include computing component signals from the multi-channel signals, cross-fading the component signals based on different temporal rates to generate cross-faded component signals and generating a blended multi-channel signal based on the cross-faded component signals.</p><p id="p0011" num="0011">In a fourth aspect, there is provided an article of manufacture comprising at least one non-transitory, tangible machine readable storage medium containing executable machine instructions for blending multi-channel signals, wherein execution of the program instructions by one or more processors causes the one or more processors to perform steps comprising: computing component signals from the multi-channel signals; cross-fading the component signals based on different temporal rates to generate cross-faded component signals; and generating a blended multi-channel signal based on the cross-faded component signals.</p><p id="p0012" num="0012">Computing the component signals from the multi-channel signals may comprise computing the component signals such that each of the component signals is selected from the group consisting of: a combination of a plurality of channels of the multi-channel signal; a signal that contains a plurality of features extracted from the multi-channel signal in the time domain or in the frequency domain; and a filtered version of the multi-channel signal. Cross-fading the component signals based on the different temporal rates may comprise: computing a plurality of mixing factors based on the different temporal rates; and mixing the component signals based on the mixing factors.</p><p id="p0013" num="0013">Computing the component signals from the multi-channel signals may comprise computing a sum signal and a difference signal from each of the multi-channel signals. Computing the mixing factors based on the different temporal rates may comprise: calculating a first mixing factor based on a first temporal rate; and calculating a second mixing factor based on a second temporal rate such that a transition rate of the first mixing factor is faster than a transition rate of the second mixing factor, and wherein mixing the component signals based on the mixing factors comprises: mixing the sum signals based on the first mixing factor; and mixing the difference signals based on the second mixing factor.<!-- EPO <DP n="5"> --></p><p id="p0014" num="0014">Generating the blended multi-channel signal based on the cross-faded component signals may comprise: generating the blended multi-channel signal based on the sum of the cross-faded component signals and the difference between the cross-faded component signals. The blended multi-channel signal may comprise a plurality of channels, wherein generating the blended multi-channel signal based on the cross-faded component signals may comprise: generating each channel of the multi-channel signal based on a combination of the cross-faded component signals. The multi-channel signals may comprise two stereo audio signals. Cross-fading the component signals based on the different temporal rates may comprise: generating at least one of the different temporal rates as a function of the difference between stereo components of the two stereo audio signals. The two stereo audio signals may comprise a frequency modulation (FM) stereo audio signal and a Digital Audio Broadcasting (DAB) stereo audio signal that carries the same audio content as the FM stereo audio signal. The steps may further comprise delaying the component signals such that the component signals are synchronized.</p><p id="p0015" num="0015">Other aspects and advantages of embodiments of the present invention will become apparent from the following detailed description, taken in conjunction with the accompanying drawings, depicted by way of example of the principles of the invention.
<ul><li><figref idrefs="f0001">Fig. 1</figref> is a schematic block diagram of a signal blending device in accordance with an embodiment of the invention.</li><li><figref idrefs="f0002">Fig. 2</figref> depicts an embodiment of the signal blending device depicted in <figref idrefs="f0001">Fig. 1</figref>.</li><li><figref idrefs="f0003">Fig. 3</figref> shows some examples of mixing factors that can be used for the signal blending device depicted in <figref idrefs="f0002">Fig. 2</figref>.</li><li><figref idrefs="f0004">Fig. 4</figref> is a process flow diagram of a method for blending multi-channel signals in accordance with an embodiment of the invention.</li></ul></p><p id="p0016" num="0016">Throughout the description, similar reference numbers may be used to identify similar elements.</p><p id="p0017" num="0017">It will be readily understood that the components of the embodiments as generally described herein and illustrated in the appended figures could be<!-- EPO <DP n="6"> --> arranged and designed in a wide variety of different configurations. Thus, the following detailed description of various embodiments, as represented in the figures, is not intended to limit the scope of the present disclosure, but is merely representative of various embodiments. While the various aspects of the embodiments are presented in drawings, the drawings are not necessarily drawn to scale unless specifically indicated.</p><p id="p0018" num="0018">The described embodiments are to be considered in all respects only as illustrative and not restrictive. The scope of the invention is, therefore, indicated by the appended claims rather than by this detailed description. All changes which come within the meaning and range of equivalency of the claims are to be embraced within their scope.</p><p id="p0019" num="0019">Reference throughout this specification to features, advantages, or similar language does not imply that all of the features and advantages that may be realized with the present invention should be or are in any single embodiment. Rather, language referring to the features and advantages is understood to mean that a specific feature, advantage, or characteristic described in connection with an embodiment is included in at least one embodiment. Thus, discussions of the features and advantages, and similar language, throughout this specification may, but do not necessarily, refer to the same embodiment.</p><p id="p0020" num="0020">Furthermore, the described features, advantages, and characteristics of the invention may be combined in any suitable manner in one or more embodiments. One skilled in the relevant art will recognize, in light of the description herein, that the invention can be practiced without one or more of the specific features or advantages of a particular embodiment. In other instances, additional features and advantages may be recognized in certain embodiments that may not be present in all embodiments of the invention.</p><p id="p0021" num="0021">Reference throughout this specification to "one embodiment," "an embodiment," or similar language means that a particular feature, structure, or characteristic described in connection with the indicated embodiment is included in at least one embodiment. Thus, the phrases "in one embodiment," "in an embodiment," and similar language throughout this specification may, but do not necessarily, all refer to the same embodiment.<!-- EPO <DP n="7"> --></p><p id="p0022" num="0022"><figref idrefs="f0001">Fig. 1</figref> is a schematic block diagram of a signal blending device 100 in accordance with an embodiment of the invention. The signal blending device can be used to perform signal blending on a number of multi-channel signals, which carry the same content (e.g., the same broadcasting program), to generate a blended multi-channel signal. Alternatively, the signal blending device is also referred to as a signal cross-fading device. Each multi-channel signal typically has two channels, a right channel and a left channel. However, the multi-channel signals may include additional channels. The signal blending device can handle two or more multi-channel signals. In some embodiments, the signal blending device performs signal blending on at least a digital multi-channel signal and an analog multi-channel signal, which may be an Amplitude modulation (AM) signal or a frequency modulation (FM) signal. In some embodiments, the signal blending device performs signal blending on two stereo audio signals. For example, the signal blending device performs signal blending on an FM stereo audio signal and a DAB stereo audio signal that carries the same audio content as the FM stereo audio signal.</p><p id="p0023" num="0023">In the embodiment depicted in <figref idrefs="f0001">Fig. 1</figref>, the signal blending device 100 includes a component signals calculation unit 102, a signal cross-fading unit 104 and a signal processing unit 106. The signal blending device can be implemented in hardware, such as a processor or a receiver circuit and/or software (e.g., computer instructions) stored in a computer-readable storage medium (e.g., memory, cache, disk). Although the signal blending device is shown in <figref idrefs="f0001">Fig. 1</figref> as including certain components, in some embodiments, the signal blending device may include more components to implement additional functionalities. For example, the signal blending device may include an analog-to-digital converter (ADC) that is used to convert an analog multi-channel signal into a digital multi-channel signal.</p><p id="p0024" num="0024">The component signals calculation unit 102 of the signal blending device 100 is configured to compute component signals from received multi-channel signals, which can be used to carry the same content. In some embodiments, the component signals calculation unit computes a sum signal and a difference signal from each of the multi-channel signals. In one embodiment, the component signals calculation unit generates a sum signal based on the sum of multi-channel<!-- EPO <DP n="8"> --> components of a multi-channel signal and generates a difference signal based on the difference between the multi-channel components of the multi-channel signal. In some embodiments, the component signals calculation unit includes an optional delay device that is used to synchronize received multi-channel signals.</p><p id="p0025" num="0025">A component signal of a multi-channel signal can be a combination (e.g., sum or difference) of multiple channels of the multi-channel signal. A component signal of a multi-channel signal can also be a signal that contains a certain type of features, which may be extracted from the multi-channel signal in the time domain or in the frequency domain. A component signal of a multi-channel signal can also be a filtered version of the multi-channel signal (in which case the component signal is also a multi-channel signal) or of a component signal thereof.</p><p id="p0026" num="0026">The signal cross-fading unit 104 of the signal blending device 100, which can be also referred to as a signal mixing unit, is configured to cross-fade the component signals from the component signals calculation unit 102 based on different temporal rates to generate cross-faded component signals (e.g., a cross-faded sum signal and a cross-faded difference signal). By cross-fading component signals of multi-channel signals based on different temporal rates, artifacts caused by signal blending can be reduced. In some embodiments, the signal cross-fading unit computes a number of mixing factors based on the different temporal rates and mixes the component signals based on the mixing factors. In one embodiment, the signal cross-fading unit calculates a first mixing factor based on a first temporal rate and a second mixing factor based on a second temporal rate such that the transition rate of the first mixing factor is faster than the transition rate of the second mixing factor. In this embodiment, the signal cross-fading unit mixes the sum signals based on the first mixing factor and mixes the difference signals based on the second mixing factor.</p><p id="p0027" num="0027">The signal processing unit 106 of the signal blending device 100 is configured to generate a blended multi-channel signal based on the cross-faded component signals from the signal cross-fading unit 104. In some embodiments, the signal processing unit generates the blended multi-channel signal based on the sum of the cross-faded component signals and the difference between the cross-faded component signals. The blended multi-channel signal may include a number of multi-channel components. In one embodiment, the signal processing<!-- EPO <DP n="9"> --> unit generates a first channel of the multi-channel signal based on the sum of the cross-faded component signals and generates a second channel of the multi-channel signal based on the difference between the cross-faded component signals.</p><p id="p0028" num="0028">In some embodiments, the signal blending device 100 is used to perform signal blending or cross-fading on stereo audio signals. <figref idrefs="f0002">Fig. 2</figref> depicts an embodiment of the signal blending device 100 depicted in <figref idrefs="f0001">Fig. 1</figref> that performs signal blending on stereo audio signals. In the embodiment depicted in <figref idrefs="f0002">Fig. 2</figref>, the stereo signals are simulcast signals in which the same audio content is received from multiple broadcasts and the two stereo signals are available simultaneously to the signal blending device. For example, one stereo signal is an FM or AM signal and the other stereo signal is a Digital Audio Broadcasting (DAB) signal that carries the same audio content as the FM signal. The left and right channels of a DAB stereo transmission are encoded separately (or at least, for the most part), and a stereo signal is expected to remain a stereo one as the reception quality degrades. However, when the reception quality of an FM transmission degrades, the received audio signal is often changed into a monophonic (mono) signal, which exploits the fact that FM is transmitted as a sum signal and a difference signal, rather than a left channel signal and a right channel signal.</p><p id="p0029" num="0029">In the embodiment depicted in <figref idrefs="f0002">Fig. 2</figref>, the signal blending device 200 includes a component signals calculation unit 202, a signal cross-fading unit or signal mixing unit 204 and a signal processing unit 206. The signal blending device 200 depicted in <figref idrefs="f0002">Fig. 2</figref> can be used in a hybrid radio device that simultaneously receives an FM and a digital radio broadcast of the same program. The signal blending device cross-fades the sum and difference signals of both stereo signals using different temporal rates. The signal blending device may cross-fade the sum signals quickly but may cross-fade the difference signals more slowly. Consequently, a more gradual/slower transition of the stereo content can be achieved during a blending operation and artifacts in the stereo image generated during the blending operation can be reduced. The signal blending device depicted in <figref idrefs="f0002">Fig. 2</figref> is one possible embodiment of the signal blending device 100 depicted in <figref idrefs="f0001">Fig. 1</figref>. However, the signal blending device 100 depicted in <figref idrefs="f0001">Fig. 1</figref> is not limited to the embodiment shown in <figref idrefs="f0002">Fig. 2</figref>. In some embodiments, the<!-- EPO <DP n="10"> --> signal blending device may include an analog-to-digital converter (ADC) that is used to convert an analog multi-channel signal into a digital multi-channel signal.</p><p id="p0030" num="0030">The component signals calculation unit 202 is configured to generate sum signals and difference signals from received two stereo audio signals. In the embodiment depicted in <figref idrefs="f0002">Fig. 2</figref>, the two stereo audio signals include a primary signal, which is represented by left and right channel signals, (L1, R1), and a secondary signal, which is represented by left and right channel signals, (L2, R2), respectively. The component signals calculation unit includes a first component signals calculation module 210 configured to generate a sum signal, "S1," and a difference signal, "D1," from the primary stereo audio signal, (L1, R1), and a second component signals calculation module 212 configured to generate a sum signal, "S2," and a difference signal, "D2," of the secondary stereo audio signal, (L2, R2). The sum signals (S1 and S2) and the difference signals (D1 and D2) are computed based on the sum of the stereo signals, (L1, R1), (L2, R2), and the difference between the stereo signals. In some embodiments, the sum signal, S1, and the difference signal, D1, are expressed as: <maths id="math0001" num="(1)"><math display="block"><mrow><mi>S</mi><mo>⁢</mo><mn>1</mn><mo>=</mo><mfrac><mrow><mi>L</mi><mo>⁢</mo><mn>1</mn><mo>+</mo><mi>R</mi><mo>⁢</mo><mn>1</mn></mrow><mn>2</mn></mfrac><mo>,</mo></mrow></math><img id="ib0001" file="imgb0001.tif" wi="90" he="9" img-content="math" img-format="tif"/></maths> <maths id="math0002" num="(2)"><math display="block"><mrow><mi>D</mi><mo>⁢</mo><mn>1</mn><mo>=</mo><mfrac><mrow><mi>L</mi><mo>⁢</mo><mn>1</mn><mo>-</mo><mi>R</mi><mo>⁢</mo><mn>1</mn></mrow><mn>2</mn></mfrac><mo>,</mo></mrow></math><img id="ib0002" file="imgb0002.tif" wi="91" he="9" img-content="math" img-format="tif"/></maths><br/>
where L1 represents the left channel signal of the primary stereo audio signal, R1 represents the right channel signal of the primary stereo audio signal, S1 represents the sum signal of the left channel signal and the right channel signal of the primary stereo audio signal, and D1 represents the difference signal of the left channel signal and the right channel signal of the primary stereo audio signal. In some embodiments, the sum signal, S2, and the difference signal, D2, are expressed as: <maths id="math0003" num="(3)"><math display="block"><mrow><mi>S</mi><mo>⁢</mo><mn>2</mn><mo>=</mo><mfrac><mrow><mi>L</mi><mo>⁢</mo><mn>2</mn><mo>+</mo><mi>R</mi><mo>⁢</mo><mn>2</mn></mrow><mn>2</mn></mfrac><mo>,</mo></mrow></math><img id="ib0003" file="imgb0003.tif" wi="90" he="9" img-content="math" img-format="tif"/></maths> <maths id="math0004" num="(4)"><math display="block"><mrow><mi>D</mi><mo>⁢</mo><mn>2</mn><mo>=</mo><mfrac><mrow><mi>L</mi><mo>⁢</mo><mn>2</mn><mo>-</mo><mi>R</mi><mo>⁢</mo><mn>2</mn></mrow><mn>2</mn></mfrac><mo>,</mo></mrow></math><img id="ib0004" file="imgb0004.tif" wi="91" he="9" img-content="math" img-format="tif"/></maths><br/>
<!-- EPO <DP n="11"> -->where L2 represents the left channel signal of the secondary stereo audio signal, R2 represents the right channel signal of the secondary stereo audio signal, S2 represents the sum signal of the left channel signal and the right channel signal of the secondary stereo audio signal, and D2 represents the difference signal of the left channel signal and the right channel signal of the secondary stereo audio signal.</p><p id="p0031" num="0031">In the embodiment depicted in <figref idrefs="f0002">Fig. 2</figref>, the component signals calculation unit 202 includes an optional delay unit 208. The delay unit is configured to delay the sum signals and the difference signals that are generated by the component signals calculation unit. In the embodiment depicted in <figref idrefs="f0002">Fig. 2</figref>, the delay unit includes four delay modules 214, 216, 218, 220 configured to delay each of the sum signals and the difference signals of the primary and secondary stereo audio signals, (L1, R1), (L2, R2), respectively. Specifically, the first and second delay modules 214, 216 have the same delay time, "Δ1," while the third and fourth delay modules 218, 220 have the same delay time, "Δ2." In some embodiments, the delay unit sets the delay time/duration such that the primary and secondary signals, (L1, R1), (L2, R2), are synchronized. The delay time may be predefined or estimated previously.</p><p id="p0032" num="0032">The signal cross-fading unit or the signal mixing unit 204 is configured to mix the delayed sum signals and the delayed difference signals from the delay unit 208, to generate cross-faded sum and difference signals. In the embodiment depicted in <figref idrefs="f0002">Fig. 2</figref>, the signal cross-fading unit 204 includes a first mixing factor generation unit 222, a first mixer 226, a second mixing factor generation unit 224 and a second mixer 228. The first mixing factor generation unit 222 is configured to generate a first mixing factor, "gS." The first mixer 226 is configured to mix the sum signals, S1, S2, with the mixing factor, gS, to generate a cross-faded sum signal, "Sx." The second mixing factor generation unit 224 is configured to generate a first mixing factor, "gD." The second mixer 228 is configured to mix the difference signals, D1, D2, with the mixing factor, gD to generate a cross-faded difference signal, "Dx." The mixing factors, gS, gD, are in the range between 0 and 1. In some embodiments, the cross-faded sum signal, Sx, and the cross-faded difference signal, Dx, are expressed as:<!-- EPO <DP n="12"> --> <maths id="math0005" num="(5)"><math display="block"><mrow><mi mathvariant="italic">Sx</mi><mo>=</mo><mi mathvariant="italic">gS</mi><mn>.</mn><mi>S</mi><mo>⁢</mo><mn>1</mn><mo>+</mo><mfenced separators=""><mn>1</mn><mo>-</mo><mi mathvariant="italic">gS</mi></mfenced><mo>⋅</mo><mi>S</mi><mo>⁢</mo><mn>2</mn><mo>,</mo></mrow></math><img id="ib0005" file="imgb0005.tif" wi="103" he="6" img-content="math" img-format="tif"/></maths> <maths id="math0006" num="(6)"><math display="block"><mrow><mi mathvariant="italic">Dx</mi><mo>=</mo><mi mathvariant="italic">gD</mi><mn>.</mn><mi>D</mi><mo>⁢</mo><mn>1</mn><mo>+</mo><mfenced separators=""><mn>1</mn><mo>-</mo><mi mathvariant="italic">gD</mi></mfenced><mo>⋅</mo><mi>D</mi><mo>⁢</mo><mn>2</mn><mo>,</mo></mrow></math><img id="ib0006" file="imgb0006.tif" wi="105" he="6" img-content="math" img-format="tif"/></maths><br/>
where gS and gD represent the mixing factors, S 1 and S2 represent the sum signals, and D1 and D2 represent the difference signals. In some embodiments, the mixing factors, gS and gD, are set to 1 or 0 when the signal cross-fading unit does not perform any signal blending operation. If the mixing factors, gS and gD, are set to 1, the output signal (Sx, Dx) of the signal cross-fading unit is equal to the sum, S1, and the difference, D1, of the primary stereo audio signal (L1, R1). If the mixing factors, gS and gD, are set to 0, the output signal (Sx, Dx) of the signal cross-fading unit is equal to the sum, S2, and the difference, D2, of the secondary stereo audio signal (L2, R2).</p><p id="p0033" num="0033">In some embodiments, the signal cross-fading unit 204 performs a blending operation from the primary stereo audio signal, (L1, R1), to the secondary stereo audio signal, (L2, R2), or vice versa. When a blending operation from the primary stereo audio signal, (L1, R1), to the secondary stereo audio signal, (L2, R2), is initiated, the mixing factors, gS and gD, change from 1 to 0. If the change of the mixing factors, gS and gD, is instantaneous, the result of the blending operation switches from the primary stereo audio signal, (L1, R1), to the secondary stereo audio signal, (L2, R2) so that the output of the signal cross-fading unit 204 is transitioned from the primary stereo audio signal, (L1, R1), to the secondary stereo audio signal, (L2, R2). When the mixing factors, gS and gD, change differently over time, the mono and stereo content are changed differently, which may be used to reduce artifacts in the stereo image during a blending operation.</p><p id="p0034" num="0034"><figref idrefs="f0003">Fig. 3</figref> shows some examples of the mixing factors, gS and gD, of the signal cross-fading unit 204 of the signal blending device 200 depicted in <figref idrefs="f0002">Fig. 2</figref>. As shown in <figref idrefs="f0003">Fig. 3</figref>, each of the mixing factors, gS and gD, are a function of time. Before the blending operation, the mixing factors, gS and gD, are both 1, due to which the output before the blending operation is the primary stereo audio signal. The initiation of the blending operation is represented by the solid vertical line. During the blending operation, the mixing factors, gS, decreases rapidly to 0, due to which the mono information (sum signal) changes rapidly from that of the<!-- EPO <DP n="13"> --> primary stereo audio to that of the secondary stereo audio signal. The mixing factor, gD, decreases slowly over time, such that the stereo image changes slowly from that of the primary stereo audio signal to that of the secondary stereo audio signal, and consequently, stereo artifacts are reduced.</p><p id="p0035" num="0035">Turning back to <figref idrefs="f0002">Fig. 2</figref>, in some embodiments, each of the mixing factors, gS and gD, of the signal cross-fading unit change over time according to the following transition scheme: <maths id="math0007" num="(7)"><math display="block"><mrow><mi>g</mi><mo>⁢</mo><mfenced open="[" close="]" separators=""><mi>k</mi><mo>+</mo><mn>1</mn></mfenced><mo>=</mo><mi mathvariant="normal">α</mi><mo>⁢</mo><mi>g</mi><mfenced open="[" close="]"><mi>k</mi></mfenced><mo>+</mo><mfenced separators=""><mn>1</mn><mo>-</mo><mi mathvariant="normal">α</mi></mfenced><mo>⁢</mo><mi mathvariant="italic">gTarget</mi><mo>,</mo></mrow></math><img id="ib0007" file="imgb0007.tif" wi="110" he="6" img-content="math" img-format="tif"/></maths><br/>
where g represents either the mixing factor, gS or gD, gTarget represents a target mixing factor, k presents the sample index, and α represents a smoothing coefficient or an exponential smoothing constant, which is in the range between 0 and 1. In an embodiment, the target mixing factor, gTarget, is set to 0 if the primary stereo audio signal, (L1, R1), is blended to the secondary stereo audio signal, (L2, R2) so that the output of the signal cross-fading unit 204 is transitioned/switched from the primary stereo audio signal, (L1, R1), to the secondary stereo audio signal, (L2, R2). In an embodiment, the target mixing factor, gTarget, is set to 1 if the secondary stereo audio signal, (L2, R2), is blended to the primary stereo audio signal, (L1, R1) so that the output of the signal cross-fading unit 204 is transitioned/switched from the secondary stereo audio signal, (L2, R2), to the primary stereo audio signal, (L1, R1). In some embodiments, the smoothing coefficient, α, for calculating the mixing factor, gS, is different from the smoothing coefficient, α, for calculating the mixing factor, gD.</p><p id="p0036" num="0036">In some embodiments, the time-scale of the transition (i.e., the change rate with respect to time) of the smoothing coefficient, α, for calculating the mixing factor, gS, or gD, is controlled by a temporal rate or time constant, "τ." In an embodiment, the exponential smoothing constant, α, is expressed as: <maths id="math0008" num="(8)"><math display="block"><mrow><mi mathvariant="normal">α</mi><mo>=</mo><mi>exp</mi><mfenced><mfrac><mrow><mo>-</mo><mn>1</mn></mrow><mrow><mi mathvariant="normal">τ</mi><mo>⁢</mo><msub><mi>f</mi><mi>s</mi></msub></mrow></mfrac></mfenced><mo>,</mo></mrow></math><img id="ib0008" file="imgb0008.tif" wi="112" he="12" img-content="math" img-format="tif"/></maths><br/>
where α represents the exponential smoothing constant, <i>f<sub>s</sub></i> represents the sampling rate and τ represents the temporal rate. The temporal rate, τ, for calculating the<!-- EPO <DP n="14"> --> smoothing coefficient, α, can be fixed or variable. In some embodiments, the temporal rate, τ, for calculating the smoothing coefficient, α, that is used for calculating the mixing factor, gS, is different from the temporal rate, τ, for calculating the smoothing coefficient, α, that is used for calculating the mixing factor, gD. In some embodiments, the temporal rate, τ, is a function of the difference between stereo components of the received stereo audio signals. In an embodiment, the temporal rate, τ, for the cross-fading of the difference signals, D1, D2, (i.e., for calculating the mixing factor, gD,) is a function of the ratio (referred to as the power ratio) between the powers/magnitudes of the difference signals, D1, D2, possibly weighted in frequency. In this embodiment, the temporal rate, τ, is relatively small if the power ratio is close to unity, and the temporal rate, τ, is relatively large if the power ratio is further away from unity. The cross-fading of the difference signals is fast when the stereo content in the primary and secondary stereo audio signals is comparable in power while the cross-fading of the difference signals is slow when there is a difference in stereo content in the primary and secondary stereo audio signals.</p><p id="p0037" num="0037">The signal processing unit 208 is configured to generate a cross-faded stereo audio signal, (Lx, Dx), from the cross-faded sum and difference signals, Sx, Dx, from the signal cross-fading unit 204. In some embodiments, the cross-faded left channel signal and the cross-faded right channel signal are expressed as: <maths id="math0009" num="(9)"><math display="block"><mrow><mi mathvariant="italic">Lx</mi><mo>=</mo><mfrac><mrow><mi mathvariant="italic">Sx</mi><mo>+</mo><mi mathvariant="italic">Dx</mi></mrow><mn>2</mn></mfrac><mo>,</mo></mrow></math><img id="ib0009" file="imgb0009.tif" wi="100" he="10" img-content="math" img-format="tif"/></maths> <maths id="math0010" num="(10)"><math display="block"><mrow><mi mathvariant="italic">Rx</mi><mo>=</mo><mfrac><mrow><mi mathvariant="italic">Sx</mi><mo>-</mo><mi mathvariant="italic">Dx</mi></mrow><mn>2</mn></mfrac><mo>,</mo></mrow></math><img id="ib0010" file="imgb0010.tif" wi="102" he="10" img-content="math" img-format="tif"/></maths><br/>
where Lx represents the cross-faded left channel signal, Rx represents the cross-faded right channel signal, Sx represents the cross-faded sum signal, and Dx represents the cross-faded difference signal.</p><p id="p0038" num="0038"><figref idrefs="f0004">Fig. 4</figref> is a process flow diagram of a method for blending multi-channel signals in accordance with an embodiment of the invention. At block 402, component signals are computed from the multi-channel signals. At block 404, the component signals are cross-faded based on different temporal rates to generate cross-faded component signals. At block 406, a blended multi-channel signal is generated based on the cross-faded component signals.<!-- EPO <DP n="15"> --></p><p id="p0039" num="0039">Although the operations of the method herein are shown and described in a particular order, the order of the operations of the method may be altered so that certain operations may be performed in an inverse order or so that certain operations may be performed, at least in part, concurrently with other operations. In another embodiment, instructions or sub-operations of distinct operations may be implemented in an intermittent and/or alternating manner.</p><p id="p0040" num="0040">It should also be noted that at least some of the operations for the methods may be implemented using software instructions stored on a computer useable storage medium for execution by a computer. As an example, an embodiment of a computer program product includes a computer useable storage medium to store a computer readable program that, when executed on one or more processors, causes the one or more processors to perform operations, as described herein.</p><p id="p0041" num="0041">In addition, embodiments of at least portions of the invention can take the form of a computer program product accessible from a computer-usable or computer-readable medium providing program code for use by or in connection with a processor, a computer or any instruction execution system. For the purposes of this description, a computer-usable or computer readable medium can be any apparatus that can contain, store, communicate, propagate, or transport the program for use by or in connection with the instruction execution system, apparatus, or device. The computer-useable or computer-readable medium can be an electronic, magnetic, optical, electromagnetic, infrared, or semiconductor system (or apparatus or device), or a propagation medium. Examples of a computer-readable medium include a semiconductor or solid state memory, magnetic tape, a removable computer diskette, a random access memory (RAM), a read-only memory (ROM), a rigid magnetic disc, and an optical disc. Current examples of optical discs include a compact disc with read only memory (CD-ROM), a compact disc with read/write (CD-R/W), a digital video disc (DVD), and a Blu-ray disc.</p><p id="p0042" num="0042">In the above description, although specific embodiments of the invention that have been described or depicted include several components described or depicted herein, other embodiments of the invention may include fewer or more components to implement less or more features.<!-- EPO <DP n="16"> --></p><p id="p0043" num="0043">Furthermore, although specific embodiments of the invention have been described and depicted, the invention is not to be limited to the specific forms or arrangements of parts so described and depicted. The scope of the invention is to be defined by the claims appended hereto and their equivalents.</p></description><claims mxw-id="PCLM90459246" lang="EN" load-source="patent-office"><!-- EPO <DP n="17"> --><claim id="c-en-0001" num="0001"><claim-text>An article of manufacture comprises at least one non-transitory, tangible machine readable storage medium containing executable machine instructions for blending multi-channel signals, wherein execution of the program instructions by one or more processors causes the one or more processors to perform steps comprising:
<claim-text>computing component signals from the multi-channel signals;</claim-text>
<claim-text>cross-fading the component signals based on different temporal rates to generate cross-faded component signals; and</claim-text>
<claim-text>generating a blended multi-channel signal based on the cross-faded component signals.</claim-text></claim-text></claim><claim id="c-en-0002" num="0002"><claim-text>The article of manufacture of claim 1, wherein computing the component signals from the multi-channel signals comprises computing the component signals such that each of the component signals is selected from the group consisting of:
<claim-text>a combination of a plurality of channels of the multi-channel signal;</claim-text>
<claim-text>a signal that contains a plurality of features extracted from the multi-channel signal in the time domain or in the frequency domain; and</claim-text>
<claim-text>a filtered version of the multi-channel signal.</claim-text></claim-text></claim><claim id="c-en-0003" num="0003"><claim-text>The article of manufacture of claim 1, wherein cross-fading the component signals based on the different temporal rates comprises:
<claim-text>computing a plurality of mixing factors based on the different temporal rates; and</claim-text>
<claim-text>mixing the component signals based on the mixing factors.</claim-text></claim-text></claim><claim id="c-en-0004" num="0004"><claim-text>The article of manufacture of claim 3, wherein computing the component signals from the multi-channel signals comprises computing a sum signal and a difference signal from each of the multi-channel signals.<!-- EPO <DP n="18"> --></claim-text></claim><claim id="c-en-0005" num="0005"><claim-text>The article of manufacture of claim 4, wherein computing the mixing factors based on the different temporal rates comprises:
<claim-text>calculating a first mixing factor based on a first temporal rate; and</claim-text>
<claim-text>calculating a second mixing factor based on a second temporal rate such that a transition rate of the first mixing factor is faster than a transition rate of the second mixing factor,</claim-text>
<claim-text>and wherein mixing the component signals based on the mixing factors comprises:
<claim-text>mixing the sum signals based on the first mixing factor; and</claim-text>
<claim-text>mixing the difference signals based on the second mixing factor.</claim-text></claim-text></claim-text></claim><claim id="c-en-0006" num="0006"><claim-text>The article of manufacture of claim 4, wherein generating the blended multi-channel signal based on the cross-faded component signals comprises:
<claim-text>generating the blended multi-channel signal based on the sum of the cross-faded component signals and the difference between the cross-faded component signals.</claim-text></claim-text></claim><claim id="c-en-0007" num="0007"><claim-text>The article of manufacture of claim 1, wherein the blended multi-channel signal comprises a plurality of channels, wherein generating the blended multi-channel signal based on the cross-faded component signals comprises:
<claim-text>generating each channel of the multi-channel signal based on a combination of the cross-faded component signals.</claim-text></claim-text></claim><claim id="c-en-0008" num="0008"><claim-text>The article of manufacture of claim 1, wherein the multi-channel signals comprise two stereo audio signals.</claim-text></claim><claim id="c-en-0009" num="0009"><claim-text>The article of manufacture of claim 8, wherein cross-fading the component signals based on the different temporal rates comprises:
<claim-text>generating at least one of the different temporal rates as a function of the difference between stereo components of the two stereo audio signals.</claim-text></claim-text></claim><claim id="c-en-0010" num="0010"><claim-text>The article of manufacture of claim 8, wherein the two stereo audio signals comprise a frequency modulation (FM) stereo audio signal and a Digital Audio<!-- EPO <DP n="19"> --> Broadcasting (DAB) stereo audio signal that carries the same audio content as the FM stereo audio signal.</claim-text></claim><claim id="c-en-0011" num="0011"><claim-text>The article of manufacture of claim 1, wherein the steps further comprise delaying the component signals such that the component signals are synchronized.</claim-text></claim><claim id="c-en-0012" num="0012"><claim-text>A system for blending multi-channel signals, the system comprising:
<claim-text>a component signals calculation unit configured to compute component signals from the multi-channel signals;</claim-text>
<claim-text>a signal cross-fading unit configured to cross-fade the component signals based on different temporal rates to generate cross-faded component signals; and</claim-text>
<claim-text>a signal processing unit configured to generate a blended multi-channel signal based on the cross-faded component signals.</claim-text></claim-text></claim><claim id="c-en-0013" num="0013"><claim-text>The system of claim 12, wherein each of the component signals is selected from the group consisting of:
<claim-text>a combination of a plurality of channels of the multi-channel signal;</claim-text>
<claim-text>a signal that contains a plurality of features extracted from the multi-channel signal in the time domain or in the frequency domain; and</claim-text>
<claim-text>a filtered version of the multi-channel signal.</claim-text></claim-text></claim><claim id="c-en-0014" num="0014"><claim-text>The system of claim 12, wherein the multi-channel signals comprise a first stereo audio signal and a second stereo audio signal that carries the same audio content as the first stereo audio signal, wherein the component signals calculation unit is further configured to:
<claim-text>compute a first sum signal and a first difference signal from the first stereo audio signal; and</claim-text>
<claim-text>compute a second sum signal and a second difference signal from the second stereo audio signal,</claim-text>
<claim-text>wherein the signal cross-fading unit is further configured to:
<claim-text>cross-fade the first and second sum signals based on a first temporal rate to generate a cross-faded sum signal; and<!-- EPO <DP n="20"> --></claim-text>
<claim-text>cross-fade the first and second difference signals based on a second temporal rate to generate a cross-faded difference signal, wherein the second temporal rate is different from the first temporal rate,</claim-text>
<claim-text>wherein the signal processing unit is further configured to:</claim-text></claim-text>
<claim-text>generate a blended stereo audio signal based on the cross-faded sum signal and the cross-faded difference signal.</claim-text></claim-text></claim><claim id="c-en-0015" num="0015"><claim-text>A method for blending multi-channel signals, the method comprising:
<claim-text>computing component signals from the multi-channel signals;</claim-text>
<claim-text>cross-fading the component signals based on different temporal rates to generate cross-faded component signals; and</claim-text>
<claim-text>generating a blended multi-channel signal based on the cross-faded component signals.</claim-text></claim-text></claim></claims><drawings mxw-id="PDW20421981" load-source="patent-office"><!-- EPO <DP n="21"> --><figure id="f0001" num="1"><img id="if0001" file="imgf0001.tif" wi="111" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="22"> --><figure id="f0002" num="2"><img id="if0002" file="imgf0002.tif" wi="145" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="23"> --><figure id="f0003" num="3"><img id="if0003" file="imgf0003.tif" wi="148" he="199" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="24"> --><figure id="f0004" num="4"><img id="if0004" file="imgf0004.tif" wi="139" he="131" img-content="drawing" img-format="tif"/></figure></drawings><search-report-data><doc-page id="srep0001" file="srep0001.tif" wi="160" he="233" type="tif"/><doc-page id="srep0002" file="srep0002.tif" wi="160" he="233" type="tif"/></search-report-data><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
