<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2960904-A1" country="EP" doc-number="2960904" kind="A1" date="20151230" family-id="53489800" file-reference-id="313470" date-produced="20180824" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="160451427" ucid="EP-2960904-A1"><document-id><country>EP</country><doc-number>2960904</doc-number><kind>A1</kind><date>20151230</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-15171781-A" is-representative="YES"><document-id mxw-id="PAPP193865822" load-source="docdb" format="epo"><country>EP</country><doc-number>15171781</doc-number><kind>A</kind><date>20150612</date><lang>EN</lang></document-id><document-id mxw-id="PAPP193865823" load-source="patent-office" format="original"><country>EP</country><doc-number>15171781.6</doc-number><date>20150612</date><lang>EN</lang></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC162035445" ucid="US-201414317861-A" load-source="docdb"><document-id format="epo"><country>US</country><doc-number>201414317861</doc-number><kind>A</kind><date>20140627</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL-1988520269" load-source="docdb">H04N   5/04        20060101ALI20150930BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-1988521503" load-source="docdb">G10L  25/78        20130101ALN20150930BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-1988523809" load-source="docdb">G10L  21/055       20130101AFI20150930BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-1988524858" load-source="docdb">G11B  27/00        20060101ALI20150930BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-1988526503" load-source="docdb">G11B  20/00        20060101ALN20150930BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-1988527469" load-source="docdb">G10L  21/047       20130101ALN20150930BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-1923982138" load-source="docdb" scheme="CPC">H04N  21/4398      20130101 LI20160627BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1923983130" load-source="docdb" scheme="CPC">H04S   3/008       20130101 LI20160627BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1923984279" load-source="docdb" scheme="CPC">H04N  21/4307      20130101 LI20160627BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1923987898" load-source="docdb" scheme="CPC">H04N   5/77        20130101 LI20160627BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1923988196" load-source="docdb" scheme="CPC">H04N   9/806       20130101 LI20160627BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1967009154" load-source="docdb" scheme="CPC">G10L  21/055       20130101 LI20160222BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1967010560" load-source="docdb" scheme="CPC">G10L  21/047       20130101 LA20160222BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1967010691" load-source="docdb" scheme="CPC">H04S2400/11        20130101 LA20160222BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1967012022" load-source="docdb" scheme="CPC">H04N  21/2368      20130101 LI20160222BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1967012403" load-source="docdb" scheme="CPC">G11B  27/005       20130101 LI20160222BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1967015930" load-source="docdb" scheme="CPC">G10L  25/78        20130101 LA20160222BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1984697885" load-source="docdb" scheme="CPC">H04N   5/04        20130101 LI20160106BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1984698053" load-source="docdb" scheme="CPC">H04N   5/76        20130101 LI20151231BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1984702024" load-source="docdb" scheme="CPC">G11B  27/10        20130101 FI20151231BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT165545747" lang="DE" load-source="patent-office">VERFAHREN UND VORRICHTUNG ZUR SYNCHRONISATION VON AUDIO- UND VIDEOSIGNALEN</invention-title><invention-title mxw-id="PT165545748" lang="EN" load-source="patent-office">METHOD AND APPARATUS FOR SYNCHRONIZING AUDIO AND VIDEO SIGNALS</invention-title><invention-title mxw-id="PT165545749" lang="FR" load-source="patent-office">PROCÉDÉ ET APPAREIL DE SYNCHRONISATION DE SIGNAUX AUDIO ET VIDÉO</invention-title><citations><patent-citations><patcit mxw-id="PCIT375624845" load-source="docdb" ucid="EP-2509073-A1"><document-id format="epo"><country>EP</country><doc-number>2509073</doc-number><kind>A1</kind><date>20121010</date></document-id><sources><source name="SEA" category="XI" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335962024" load-source="docdb" ucid="KR-20030024770-A"><document-id format="epo"><country>KR</country><doc-number>20030024770</doc-number><kind>A</kind><date>20030326</date></document-id><sources><source name="SEA" category="A" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT375624844" load-source="docdb" ucid="US-6232540-B1"><document-id format="epo"><country>US</country><doc-number>6232540</doc-number><kind>B1</kind><date>20010515</date></document-id><sources><source name="SEA" category="IA" created-by-npl="N"/></sources></patcit></patent-citations><non-patent-citations><nplcit><text>ALEXIS MOINET: "Slowdio: Audio Time-Scaling for Slow Motion Sports Videos", 26 September 2013 (2013-09-26), Faculty of Engineering of the University of Mons, pages 1 - 208, XP055213714, Retrieved from the Internet &lt;URL:http://tcts.fpms.ac.be/publications/phds/moinet/slowdio.pdf&gt; [retrieved on 20150916]</text><sources><source mxw-id="PNPL57937265" load-source="docdb" name="SEA" category="XI"/></sources></nplcit><nplcit><text>G.V. RAMANA RAO; J. SRICHLAN: "Word Boundary Detection Using Pitch Variations", FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE, 1996</text><sources><source mxw-id="PNPL62034755" load-source="docdb" name="APP"/></sources></nplcit><nplcit><text>GIN-DER WU; CHIN-TENG LIN: "A Recurrent Neural Fuzzy Network for Word Boundary Detection in Variable Noise-Level Environments", IEEE TRANSACTIONS ON SYSTEMS, MAN AND CYBERNETICS, PART B: CYBERNETICS, vol. 31, no. 1, 2001, XP011056945</text><sources><source mxw-id="PNPL75512809" load-source="docdb" name="APP"/></sources></nplcit><nplcit><text>H. NEY ET AL.: "The RWTH Large Vocabulary Continuous Speech Recognition System", IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP, 1998</text><sources><source mxw-id="PNPL62034757" load-source="docdb" name="APP"/></sources></nplcit><nplcit><text>JONGSEO SOHN ET AL.: "A statistical model-based voice activity detection", SIGNAL PROCESSING LETTERS, IEEE, January 1999 (1999-01-01)</text><sources><source mxw-id="PNPL62034758" load-source="docdb" name="APP"/></sources></nplcit><nplcit><text>JORDI BONADA: "Audio Time-Scale Modification in the Context of Professional Audio Post-production", 2002, BARCELONA, pages 1 - 84, XP055214222, Retrieved from the Internet &lt;URL:http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.75.8526&amp;rep=rep1&amp;type=pdf&gt; [retrieved on 20150917]</text><sources><source mxw-id="PNPL57937270" load-source="docdb" name="SEA" category="XI"/></sources></nplcit><nplcit><text>LUCAS PARRA ET AL.: "On-line Convolutive Blind Source Separation of Non-Stationary Signals", JOURNAL OF VLSI SIGNAL PROCESSING SYSTEMS FOR SIGNAL, IMAGE AND VIDEO TECHNOLOGY, vol. 26, no. 1-2, August 2000 (2000-08-01), pages 39 - 46, XP002203215</text><sources><source mxw-id="PNPL75512810" load-source="docdb" name="APP"/></sources></nplcit><nplcit><text>MAKINO, SHOJI ET AL.: "Blind Source Separation of Convolutive Mixtures of Speech in Frequency Domain", IEICE TRANSACTIONS ON FUNDAMENTALS OF ELECTRONICS, COMMUNICATIONS AND COMPUTER SCIENCES, vol. E88-A, July 2005 (2005-07-01)</text><sources><source mxw-id="PNPL62034760" load-source="docdb" name="APP"/></sources></nplcit><nplcit><text>MUKAI, RYO ET AL.: "Robust real-time blind source separation for moving speakers in a room", ICASSP 20</text><sources><source mxw-id="PNPL62034761" load-source="docdb" name="APP"/></sources></nplcit></non-patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR1103342467" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>NOKIA TECHNOLOGIES OY</last-name><address><country>FI</country></address></addressbook></applicant><applicant mxw-id="PPAR1103309524" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>NOKIA TECHNOLOGIES OY</last-name></addressbook></applicant><applicant mxw-id="PPAR1101649238" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Nokia Technologies Oy</last-name><iid>101515657</iid><address><street>Karaportti 3</street><city>02610 Espoo</city><country>FI</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR1103327907" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>VILERMO MIIKKA</last-name><address><country>FI</country></address></addressbook></inventor><inventor mxw-id="PPAR1103316516" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>VILERMO, MIIKKA</last-name></addressbook></inventor><inventor mxw-id="PPAR1101653857" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>VILERMO, MIIKKA</last-name><address><street>Selmankuja 5</street><city>37200 Siuro</city><country>FI</country></address></addressbook></inventor><inventor mxw-id="PPAR1103333244" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>TAMMI MIKKO</last-name><address><country>FI</country></address></addressbook></inventor><inventor mxw-id="PPAR1103304014" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>TAMMI, MIKKO</last-name></addressbook></inventor><inventor mxw-id="PPAR1101648552" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>TAMMI, MIKKO</last-name><address><street>Kohmankaari 1 C 13</street><city>33310 Tampere</city><country>FI</country></address></addressbook></inventor><inventor mxw-id="PPAR1103312207" load-source="docdb" sequence="3" format="epo"><addressbook><last-name>LEHTINIEMI ARTO</last-name><address><country>FI</country></address></addressbook></inventor><inventor mxw-id="PPAR1103314848" load-source="docdb" sequence="3" format="intermediate"><addressbook><last-name>LEHTINIEMI, ARTO</last-name></addressbook></inventor><inventor mxw-id="PPAR1101649107" load-source="patent-office" sequence="3" format="original"><addressbook><last-name>LEHTINIEMI, ARTO</last-name><address><street>Lomarantatie 17</street><city>33880 Lempäälä</city><country>FI</country></address></addressbook></inventor><inventor mxw-id="PPAR1103325985" load-source="docdb" sequence="4" format="epo"><addressbook><last-name>LAAKSONEN LASSE</last-name><address><country>FI</country></address></addressbook></inventor><inventor mxw-id="PPAR1103308082" load-source="docdb" sequence="4" format="intermediate"><addressbook><last-name>LAAKSONEN, LASSE</last-name></addressbook></inventor><inventor mxw-id="PPAR1101646026" load-source="patent-office" sequence="4" format="original"><addressbook><last-name>LAAKSONEN, LASSE</last-name><address><street>Näsilinnankatu 23 B 28</street><city>33210 Tampere</city><country>FI</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR1101651426" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Nokia Corporation</last-name><iid>101452932</iid><address><street>Intellectual Property Department Karakaari 7</street><city>02610 Espoo</city><country>FI</country></address></addressbook></agent></agents></parties><international-convention-data><designated-states><ep-contracting-states><country mxw-id="DS660689047" load-source="docdb">AL</country><country mxw-id="DS660609976" load-source="docdb">AT</country><country mxw-id="DS660689049" load-source="docdb">BE</country><country mxw-id="DS660684694" load-source="docdb">BG</country><country mxw-id="DS660687134" load-source="docdb">CH</country><country mxw-id="DS660609338" load-source="docdb">CY</country><country mxw-id="DS660609977" load-source="docdb">CZ</country><country mxw-id="DS660689050" load-source="docdb">DE</country><country mxw-id="DS660609347" load-source="docdb">DK</country><country mxw-id="DS660609348" load-source="docdb">EE</country><country mxw-id="DS660606332" load-source="docdb">ES</country><country mxw-id="DS660684707" load-source="docdb">FI</country><country mxw-id="DS660684708" load-source="docdb">FR</country><country mxw-id="DS660689183" load-source="docdb">GB</country><country mxw-id="DS660609349" load-source="docdb">GR</country><country mxw-id="DS660689184" load-source="docdb">HR</country><country mxw-id="DS660609978" load-source="docdb">HU</country><country mxw-id="DS660687139" load-source="docdb">IE</country><country mxw-id="DS660689185" load-source="docdb">IS</country><country mxw-id="DS660684709" load-source="docdb">IT</country><country mxw-id="DS660609350" load-source="docdb">LI</country><country mxw-id="DS660684639" load-source="docdb">LT</country><country mxw-id="DS660609983" load-source="docdb">LU</country><country mxw-id="DS660684640" load-source="docdb">LV</country><country mxw-id="DS660684641" load-source="docdb">MC</country><country mxw-id="DS660783261" load-source="docdb">MK</country><country mxw-id="DS660783262" load-source="docdb">MT</country><country mxw-id="DS660606333" load-source="docdb">NL</country><country mxw-id="DS660684710" load-source="docdb">NO</country><country mxw-id="DS660606334" load-source="docdb">PL</country><country mxw-id="DS660687140" load-source="docdb">PT</country><country mxw-id="DS660606335" load-source="docdb">RO</country><country mxw-id="DS660687141" load-source="docdb">RS</country><country mxw-id="DS660606336" load-source="docdb">SE</country><country mxw-id="DS660687142" load-source="docdb">SI</country><country mxw-id="DS660783263" load-source="docdb">SK</country><country mxw-id="DS660783264" load-source="docdb">SM</country><country mxw-id="DS660609359" load-source="docdb">TR</country></ep-contracting-states><ep-extended-states><ep-extended-state-data><country>BA</country></ep-extended-state-data><ep-extended-state-data><country>ME</country></ep-extended-state-data></ep-extended-states></designated-states></international-convention-data></bibliographic-data><abstract mxw-id="PA166479797" lang="EN" load-source="patent-office"><p id="pa01" num="0001">A method, apparatus and computer program product are provided to synchronize audio signals with video images that are replayed with a modified motion. In a method, a trajectory is determined for each audio object of an audio signal. The method also determines each of the audio objects to be a transient or non-transient object. The method also causes a respective audio object to be differently extended depending upon whether the audio object is determined to be a transient object or a non-transient object, thereby synchronizing video signals that are to be played back with a predefined motion. The method causes the respective audio object to be differently extended by splitting the transient object into transient segments, inserting silent segments therebetween and maintaining the trajectories of the transient object and/or by repeating the non-transient object with a trajectory that varies based on the predefined motion of the video signals.
<img id="iaf01" file="imgaf001.tif" wi="78" he="97" img-content="drawing" img-format="tif"/></p></abstract><abstract mxw-id="PA166759609" lang="EN" source="EPO" load-source="docdb"><p>A method, apparatus and computer program product are provided to synchronize audio signals with video images that are replayed with a modified motion. In a method, a trajectory is determined for each audio object of an audio signal. The method also determines each of the audio objects to be a transient or non-transient object. The method also causes a respective audio object to be differently extended depending upon whether the audio object is determined to be a transient object or a non-transient object, thereby synchronizing video signals that are to be played back with a predefined motion. The method causes the respective audio object to be differently extended by splitting the transient object into transient segments, inserting silent segments therebetween and maintaining the trajectories of the transient object and/or by repeating the non-transient object with a trajectory that varies based on the predefined motion of the video signals.</p></abstract><description mxw-id="PDES98404498" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><heading id="h0001">TECHNOLOGICAL FIELD</heading><p id="p0001" num="0001">An example embodiment of the present invention relates generally to the synchronization of audio and video signals and, in one embodiment, relates to maintaining synchronization between the audio and video signals in an instance in which a video signals are replayed with modified motion, such as in slow motion.</p><heading id="h0002">BACKGROUND</heading><p id="p0002" num="0002">It is sometimes desirable to replay a sequence of video images in slow motion. For example, a user may provide input that specifies the extent to which the replayed video images should be slowed. In instances in which mono audio signals have been captured and are associated with the video images, the replay of the audio signals may correspondingly be slowed to the same extent that the replay of the video images is slowed.</p><p id="p0003" num="0003">Increasingly, however, stereo or multi-channel audio signals are captured and associated with a sequence of video images. In an instance in which video images that are associated with stereo or multi-channel audio signals are replayed in slow motion, it may be somewhat problematic to properly replay the stereo or multi-channel audio signals in a manner that maintains synchronization with the slowed video images. In this regard, synchronization may apply not only to the relative timing of the audio signals and the video images, but also to the synchronization of the direction associated with the audio signals relative to the location of the source of the audio signals within the video images.</p><p id="p0004" num="0004">The replay of audio signals at a slower speed in conjunction with video images that are displayed in slow motion may be problematic as stereo or multi-channel audio signals generally sound unnatural when played at a different speed. In order to permit the audio signals to sound more natural, the audio signals may be played at standard speed, but the audio signals will then be out of synchronization relative to the corresponding video images that are replayed in slow motion. Various techniques have been developed in an effort to facilitate changes in the audio playback speed, but these techniques may only provide audio signals with reasonable quality in instances in which the audio signals and the corresponding video images are slowed to about half speed and generally do not maintain synchronization with audio signals that continue to sound natural in instances in which the audio signals and the corresponding video images are slowed to a greater degree.<!-- EPO <DP n="2"> --></p><heading id="h0003">BRIEF SUMMARY</heading><p id="p0005" num="0005">A method, apparatus and computer program product are provided in accordance with an example embodiment in order to facilitate synchronization of audio signals with corresponding video images that are replayed with a modified motion, such as in slow motion. In this regard, the method, apparatus and computer program product of an example embodiment may maintain the audio signals in synchronization with the corresponding video images, both in terms of time and direction. Further, the method, apparatus and computer program product of an example embodiment may permit the audio signals associated with video images that are replayed with the modified motion to maintain synchronization with the video images in a manner that still permits the audio signals to sound relatively natural. A method, apparatus of computer program product are also provided in accordance with another example embodiment to associate audio signals with at least a part of a video image that is stationary and/or to correspondingly remove audio signals that are associated with a part of a video image that has been removed.</p><p id="p0006" num="0006">In an example embodiment, a method is provided that includes determining a trajectory for each of one or more audio objects of an audio signal. The method of this embodiment also includes determining each of the audio objects to be a transient object or a non-transient object. For example, the transient and non-transient objects may include speech and non-speech objects, respectively. The method of this example embodiment also includes causing, with a processor, an audio object to be differently extended depending upon whether the audio object is determined to be a transient object or a non-transient object so as to synchronize a video signal that is to be played back in a predefined motion, such as slow motion. In this regard, the method may cause the audio object to be differently extended, in an instance in which the audio object is determined to be a transient object, by splitting the transient object into transient segments, inserting silent segments between the transient segments and maintaining the trajectories of the transient object. The method of this embodiment may also cause the audio object to be differently extended, in an instance in which the audio object is determined to be a non-transient object, by repeating the non-transient object with a trajectory that varies over time in correspondence to the predefined motion of the video signal.</p><p id="p0007" num="0007">The method of an example embodiment may also include determining a level for each of the one or more audio objects. In this embodiment, the method may cause the audio object to be differently extended by maintaining the level of the transient object and repeating the non-transient object at a level that varies over time in correspondence to the predefined motion of the video signal. The method of an example embodiment may insert silent<!-- EPO <DP n="3"> --> segments between the transient segments by inserting silent segments that have a length that corresponds to the predefined motion of the video signal. In this embodiment, a first speed of the audio and video signals may be a multiple of the predefined motion speed at which the video signal is to be played back. As such, the method may insert silent segments that have a length that is selected such that the silent segments in combination with a corresponding transient segment have a collective length that is the multiple of a length of the corresponding transient segment at the first speed. In an instance in which the first speed of the audio and video signals is a multiple of the predefined motion speed at which the video signal is to be played back, the method may repeat the non-transient objects by repeating a non-transient object to have a resulting length that is the multiple of the length of the non-transient object at the first speed. The method of an example embodiment may also include causing the audio object to be rendered after having been differently extended.</p><p id="p0008" num="0008">In another example embodiment, an apparatus is provided that includes at least one processor and at least one memory storing computer program code with the at least one memory and the stored computer program code being configured, with the at least one processor, to cause the apparatus to at least determine a trajectory for each of one or more audio objects of an audio signal and to determine each of the audio objects to be a transient object or a non-transient object. For example, the transient and non-transient objects may include speech and non-speech objects, respectively. The at least one memory and the stored computer program code are also configured, with the at least one processor, to cause the apparatus of this example embodiment to cause an audio object to be differently extended depending upon whether the audio object is determined to be a transient or a non-transient object so as to synchronize video signal that is to be played back in a predefined motion, such as in slow motion. In this regard, the at least one memory and the stored computer program code may be configured, with the at least one processor, to cause the apparatus to cause the audio object to be differently extended, in an instance in which the audio object is determined to be a transient object, by splitting the transient object into transient segments, inserting silent segments between the transient segments and maintaining the trajectories of the transient object. The at least one memory and the stored computer program code may also be configured, with the at least one processor, to cause the apparatus to cause the audio object to be differently extended, in an instance in which the audio object is determined to be a non-transient object, by repeating the non-transient object with a trajectory that varies over time in correspondence to the predefined motion of the video signal.</p><p id="p0009" num="0009">The at least one memory and the stored computer program code may be further configured, with the at least one processor, to cause the apparatus of an example embodiment<!-- EPO <DP n="4"> --> to determine a level for each of the one or more objects. In this regard, the at least one memory and the stored computer program code may be configured, with the at least one processor, to cause the apparatus to cause the audio object to be differently extended by maintaining the level of the transient object and repeating the non-transient object with a level that varies over time in correspondence to the predefined motion of the video signal. The at least one memory and the stored computer program code may be configured, with the at least one processor, to cause the apparatus of an example embodiment to insert silent segments between the transient segments by inserting silent segments that have a length that corresponds to the predefined motion of the video signal. In this embodiment, the first speed of the audio and video signals may be a multiple of the predefined motion speed at which the video signal are to be played back. As such, the at least one memory and the stored computer program code may be configured, with the at least one processor, to cause the apparatus of this example embodiment to insert silent segments that have a length as selected such that the silent segments in combination with a corresponding transient segment have a collective length that is the multiple of a length and the corresponding transient segment at the first speed. In an instance in which the first speed of the audio and video signals is a multiple of the predefined motion speed at which the video signal is to be played back, the at least one memory and the stored computer program code may be configured, with the at least one processor to cause the apparatus of an example embodiment to repeat the non-transient objects so to have a resulting length that is the multiple of a length of the non-transient object at the first speed. In an example embodiment, the at least one memory and the stored computer program code may be further configured, with the at least one processor, to cause the apparatus to cause the audio object to be rendered after having been differently extended.</p><p id="p0010" num="0010">In a further example embodiment, a computer program product is provided that includes at least one computer-readable storage medium having computer-executable program code instructions stored therein with the computer-executable program code instructions including program code instructions to, when executed by at least one processor, cause the determination of a trajectory for each of one or more audio objects of an audio signal. The computer-executable program code instructions of this example embodiment also include program code instructions to determine each of the audio objects to be a transient object or a non-transient object and to cause an audio object to be differently extended depending upon whether the audio object is determined to be a transient object or a non-transient object so as to synchronize video signal that is to be played back in a predefined motion, such as in slow motion. In regards to causing the audio object to be differently extended, the computer-executable program code instructions may include program code instructions in an instance in<!-- EPO <DP n="5"> --> which the audio object is determined to be a transient object to split the transient object into transient segments, insert in silent segments between the transient segments and maintain the trajectory of the transient object. The computer-executable program code instructions for causing the audio object to be differently extended may also include program code instructions in an instance in which the audio object is determined to be a non-transient object to repeat the non-transient object with a trajectory that varies over time in correspondence to the predefined motion of the video signal.</p><p id="p0011" num="0011">In yet another example of embodiment, an apparatus is provided that includes means, such as a processor, processing circuitry or the like, for determining a trajectory for each of one or more audio objects of an audio signal. The apparatus of this example embodiment also includes means, such as a processor, processing circuitry or the like, for determining each of the audio objects to be a transient object or a non-transient object. The apparatus of this example embodiment also includes means, such as a processor, processing circuitry or the like, for causing an audio object to be differently extended depending upon whether the audio object is determined to be a transient object or a non-transient object so as to synchronize video signal that is to be played back in a predefined motion, such as in slow motion. In this regard, the means for causing the audio object to be differently extended may include, in an instance in which the audio object is determined to be a transient object, means, such as a processor, processing circuitry or the like, for splitting the transient object into transient segments, means, such as a processor, processing circuitry or the like, for inserting silent segments between the transient segments and means, such as a processor, processing circuitry or the like, for maintaining the trajectories of the transient object. The means for causing the audio object to be differently extended may also include means, such as a processor, processing circuitry or the like, for repeating the non-transient object with a trajectory that varies over time in correspondence with the predefined motion of the video signal.</p><p id="p0012" num="0012">In an example embodiment, a method is provided that includes separating an audio signal into one or more audio objects and determining a trajectory for each of the one or more audio objects. The method of this example embodiment also includes associating, with a processor, at least a portion of the visual image with one or more audio objects and determining the trajectory of the one or more audio objects at a time at which the at least a portion of the visual image was captured. The method of this example embodiment also includes causing the visual image and the audio objects to be rendered with the one or more audio objects being rendered in accordance with the trajectory at the time at which the at least the portion of visual image was captured.<!-- EPO <DP n="6"> --></p><p id="p0013" num="0013">In an embodiment to which the visual image includes a still image, the method may determine the trajectory of the one or more audio objects at the time at which at least a portion of visual image was captured by determining the trajectory of the one or more audio objects at the time at which the still image was captured. In an embodiment to which the visual image comprises a series of images and the at least a portion of visual image includes a stationary part of the series of images, the method may determine the trajectory of the one or more audio objects at the time at which at least a portion of visual images was captured by determining the trajectory of the one or more audio objects at the time at which the stationary part of the series of images was captured. In this example embodiment in which the series of images also includes one or more moving parts, the method may further include correlating the trajectory of one or more audio objects to the one or more moving parts. In this example embodiment, the one or more audio objects that are associated with the stationary part of the series of images may include all audio objects other than the one or more audio objects correlated to the one or more moving parts to this series of images. In response to removal of a part of the series of images, the method of this example embodiment may remove the one or more audio objects correlated to the part of the series of images that is removed.</p><p id="p0014" num="0014">In another example embodiment, an apparatus is provided that includes at least one processor and at least one memory storing computer program code with the at least one memory and stored computer code being configured, with the at least one processor, to cause the apparatus to at least separate an audio signal into one or more audio objects and to determine a trajectory for each of the one or more audio objects. The at least one memory and stored computer program code are configured, with the at least one processor, to cause the apparatus of this example embodiment to associate at least a portion of the visual image with one or more audio objects and to determine the trajectory of the one or more audio objects at the time at which the at least a portion of visual image was captured. The at least one memory and stored computer program code may be configured, with the at least one processor, to cause the apparatus of this example embodiment to cause a visual image and the audio objects to be rendered with the one or more audio objects being rendered in accordance to the trajectory at the time at which the at least a portion of the visual image was captured.</p><p id="p0015" num="0015">In a further example embodiment, a computer program product is provided that includes at least one computer-readable storage medium having computer-executable program code portions stored therein with the computer-executable program code instructions including program code instructions to, when executed by at least one processor, cause an audio signal to be separated into one or more audio objects and to determine a trajectory for each of the one or more audio objects. The computer-executable program code instructions of<!-- EPO <DP n="7"> --> this example embodiment may also include program code instructions to, when executed by the at least one processor, cause the association of at least a portion of a visual image with one or more audio objects and to determine the trajectory of the one or more audio objects at the time at which the at least a portion of visual image was captured. The computer-executable program code instructions of this example embodiment may also include program code instructions to, when executed by the at least one processor, cause the visual image and the audio objects to be rendered with the one or more audio objects being rendered in accordance with the trajectory at the time at which the at least a portion of visual image was captured.</p><p id="p0016" num="0016">In yet another example embodiment, an apparatus is provided at that includes means, such as a processor, processing circuitry or the like, for separating an audio signal into one or more audio objects and means, such as a processor, processing circuitry or the like, for determining a trajectory for each of the one or more audio objects. The apparatus of this example embodiment also includes means, such as a processor, processing circuitry or the like, for associating at least a portion of the visual image with one or more audio objects and means, such as a processor, processing circuitry or the like, for determining the trajectory of the one or more audio objects at a time at which the at least a portion of visual image was captured. The apparatus of this example embodiment may also include means, such as a processor, processing circuitry or the like, for causing the visual image and the audio objects to be rendered with the one or more audio objects being rendered in accordance with the trajectory at the time at which the at least a portion of the visual image was captured.</p><heading id="h0004">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p0017" num="0017">Having thus described aspects of the present disclosure in general terms, reference will now be made to the accompanying drawings, which are not necessarily drawn to scale, and wherein:
<ul><li><figref idrefs="f0001">Figure 1</figref> is a flowchart of operations performed in accordance with an example embodiment of the present invention;</li><li><figref idrefs="f0002">Figure 2</figref> is a more detailed flow diagram of an embodiment of the operations depicted in the flowchart of <figref idrefs="f0001">Figure 1</figref>;</li><li><figref idrefs="f0003">Figure 3</figref> is a black diagram of an apparatus that may be specifically configured in accordance with an example embodiment of the present invention;</li><li><figref idrefs="f0004">Figure 4</figref> is a representation of a speech audio object and a non-speech audio object at standard speed;<!-- EPO <DP n="8"> --></li><li><figref idrefs="f0005">Figure 5</figref> is a representation of a speech audio object and a non-speech audio object that have there been differently extended in accordance with an example embodiment of the present invention;</li><li><figref idrefs="f0006">Figure 6</figref> is a representation of a speech audio object and a non-speech audio object that have there been differently extended in accordance with another example embodiment of the present invention;</li><li><figref idrefs="f0007">Figure 7</figref> is a representation of a sequence of images at standard speed;</li><li><figref idrefs="f0007">Figure 8</figref> is a representation of a sequence of images from which both the audio objects of the audio signal and the corresponding video signals are played back in slow motion in accordance with an example embodiment of the present invention;</li><li><figref idrefs="f0008">Figure 9</figref> is a representation of a series of images in which the audio signals are not slowed and are, instead, played back at standard speed while the video signals are played back in slow motion;</li><li><figref idrefs="f0009">Figure 10</figref> is a flowchart illustrating operations performed in accordance with another example embodiment of the present invention;</li><li><figref idrefs="f0010">Figure 11</figref> is a more detailed flow diagram of an example embodiment of the operations depicted in the flowchart of <figref idrefs="f0009">Figure 10</figref> in which the visual image comprises a still photograph;</li><li><figref idrefs="f0011">Figure 12</figref> is a more detailed flow diagram of an example embodiment of the operations depicted in the flowchart of <figref idrefs="f0009">Figure 10</figref> in which the visual image comprises a cinemagraph; and</li><li><figref idrefs="f0012">Figure 13</figref> is a more detailed flow diagram of an example embodiment of the operations depicted in the flowchart of <figref idrefs="f0009">Figure 10</figref> in which the audio object(s) that correlate with a part of the visual image that has been removed are also removed in accordance with an example embodiment of the present invention.</li></ul></p><heading id="h0005">DETAILED DESCRIPTION</heading><p id="p0018" num="0018">Some embodiments of the present invention will now be described more fully hereinafter with reference to the accompanying drawings, in which some, but not all, embodiments of the invention are shown. Indeed, various embodiments of the invention may be embodied in many different forms and should not be construed as limited to the embodiments set forth herein; rather, these embodiments are provided so that this disclosure will satisfy applicable legal requirements. Like reference numerals refer to like elements throughout. As used herein, the terms "data," "content," "information," and similar terms<!-- EPO <DP n="9"> --> may be used interchangeably to refer to data capable of being transmitted, received and/or stored in accordance with embodiments of the present invention. Thus, use of any such terms should not be taken to limit the spirit and scope of embodiments of the present invention.</p><p id="p0019" num="0019">Additionally, as used herein, the term 'circuitry' refers to (a) hardware-only circuit implementations (for example, implementations in analog circuitry and/or digital circuitry); (b) combinations of circuits and computer program product(s) comprising software and/or firmware instructions stored on one or more computer readable memories that work together to cause an apparatus to perform one or more functions described herein; and (c) circuits, such as, for example, a microprocessor(s) or a portion of a microprocessor(s), that require software or firmware for operation even if the software or firmware is not physically present. This definition of 'circuitry' applies to all uses of this term herein, including in any claims. As a further example, as used herein, the term 'circuitry' also includes an implementation comprising one or more processors and/or portion(s) thereof and accompanying software and/or firmware. As another example, the term 'circuitry' as used herein also includes, for example, a baseband integrated circuit or applications processor integrated circuit for a mobile phone or a similar integrated circuit in a server, a cellular network device, other network device, and/or other computing device.</p><p id="p0020" num="0020">As defined herein, a "computer-readable storage medium," which refers to a non-transitory physical storage medium (for example, volatile or non-volatile memory device), can be differentiated from a "computer-readable transmission medium," which refers to an electromagnetic signal.</p><p id="p0021" num="0021">A method, apparatus and computer program product are provided in accordance with an example embodiment of the present invention in order to maintain synchronization, such as both in time and direction, between audio signals and video signals as the video signals are played with modified motion, such as in slow motion. Additionally, a method, apparatus and computer program product are provided in accordance with an example embodiment in order to synchronize the trajectory of the audio signals with a source of the audio signals within an image, such as a still photograph or a stationary part of a cinemagraph, by identifying a single trajectory for the audio signals that would otherwise have a trajectory that moves over time. Further, a method, apparatus and computer program product are provided in accordance with an example embodiment to permit the audio signals associated with a part of an image that is removed to also be removed. As such, the example embodiments of the method, apparatus and computer program product provide for improved synchronization of the audio and video signals under a variety of conditions, thereby<!-- EPO <DP n="10"> --> correspondingly improving the user experience when viewing and listening to the resulting video and audio, respectively.</p><p id="p0022" num="0022">As shown in <figref idrefs="f0001">Figure 1</figref> and in more detail in <figref idrefs="f0002">Figure 2</figref>, a flowchart depicting the operations performed in accordance with an example embodiment of the present invention is depicted. In the example embodiment of <figref idrefs="f0001">Figure 1</figref>, audio signals are synchronized with the video signals even as the replay of the video signals has been modified, such as by being slowed down, such as even in instances in which the video is replayed in slow motion. The operations depicted in <figref idrefs="f0001">Figures 1</figref> and <figref idrefs="f0002">2</figref> and described below may be performed by a variety of electronic devices including, for example, audio and video playback devices, televisions, cameras and computing devices, such as tablet computers, portable laptop computers, personal computer, a computer workstation, mobile telephones, smartphones, personal digital systems (PDAs), gaming devices electronic books, positioning devices (for example, global positioning system (GPS) devices) or any combination of the aforementioned, and other types of video and audio communications systems, both mobile and fixed.</p><p id="p0023" num="0023">Regardless of the type of device that is configured to perform the operations set forth by <figref idrefs="f0001">Figures 1</figref> and <figref idrefs="f0002">2</figref>, the device may include or otherwise be associated with an apparatus that is specifically configured to perform the operations of <figref idrefs="f0001">Figures 1</figref> and <figref idrefs="f0002">2</figref>. In this regard, <figref idrefs="f0003">Figure 3</figref> depicts an apparatus 70 in accordance with an example embodiment that may be specifically configured to perform the operations of <figref idrefs="f0001">Figures 1</figref> and <figref idrefs="f0002">2</figref>. As shown, the apparatus of <figref idrefs="f0003">Figure 3</figref> may include or otherwise be in communication with a processor 72 and a memory device 74, and optionally a user interface 76 and a communication interface 78. In some embodiments, the processor (and/or co-processors or any other processing circuitry assisting or otherwise associated with the processor) may be in communication with the memory device via a bus for passing information among components of the apparatus. The memory device may be non-transitory and may include, for example, one or more volatile and/or non-volatile memories. In other words, for example, the memory device may be an electronic storage device (for example, a computer readable storage medium) comprising gates configured to store data (for example, bits) that may be retrievable by a machine (for example, a computing device like the processor). The memory device may be configured to store information, data, content, applications, instructions, or the like for enabling the apparatus to carry out various functions in accordance with an example embodiment of the present invention. For example, the memory device could be configured to buffer input data for processing by the processor. Additionally or alternatively, the memory device could be configured to store instructions for execution by the processor.<!-- EPO <DP n="11"> --></p><p id="p0024" num="0024">As noted above, the apparatus 70 may be embodied by any of a variety of electronic devices, such as an audio/video playback device. However, in some embodiments, the apparatus may be embodied as a chip or chip set. In other words, the apparatus may comprise one or more physical packages (for example, chips) including materials, components and/or wires on a structural assembly (for example, a circuit board). The structural assembly may provide physical strength, conservation of size, and/or limitation of electrical interaction for component circuitry included thereon. The apparatus may therefore, in some cases, be configured to implement an embodiment of the present invention on a single chip or as a single "system on a chip." As such, in some cases, a chip or chipset may constitute means for performing one or more operations for providing the functionalities described herein.</p><p id="p0025" num="0025">The processor 72 may be embodied in a number of different ways. For example, the processor may be embodied as one or more of various hardware processing means such as a coprocessor, a microprocessor, a controller, a digital signal processor (DSP), a processing element with or without an accompanying DSP, or various other processing circuitry including integrated circuits such as, for example, an ASIC (application specific integrated circuit), an FPGA (field programmable gate array), a microcontroller unit (MCU), a hardware accelerator, a special-purpose computer chip, or the like. As such, in some embodiments, the processor may include one or more processing cores configured to perform independently. A multi-core processor may enable multiprocessing within a single physical package. Additionally or alternatively, the processor may include one or more processors configured in tandem via the bus to enable independent execution of instructions, pipelining and/or multithreading.</p><p id="p0026" num="0026">In an example embodiment, the processor 72 may be configured to execute instructions stored in the memory device 74 or otherwise accessible to the processor. Alternatively or additionally, the processor may be configured to execute hard coded functionality. As such, whether configured by hardware or software methods, or by a combination thereof, the processor may represent an entity (for example, physically embodied in circuitry) capable of performing operations according to an embodiment of the present invention while configured accordingly. Thus, for example, when the processor is embodied as an ASIC, FPGA or the like, the processor may be specifically configured hardware for conducting the operations described herein. Alternatively, as another example, when the processor is embodied as an executor of software instructions, the instructions may specifically configure the processor to perform the algorithms and/or operations described herein when the instructions are executed. However, in some cases, the processor may be a<!-- EPO <DP n="12"> --> processor of a specific device (for example, an audio/video playback device) configured to employ an embodiment of the present invention by further configuration of the processor by instructions for performing the algorithms and/or operations described herein. The processor may include, among other things, a clock, an arithmetic logic unit (ALU) and logic gates configured to support operation of the processor.</p><p id="p0027" num="0027">The apparatus 70 of an example embodiment may optionally also include or otherwise be in communication with a user interface 76. The user interface may include one or more inputs, such as an input that defines the speed at which the audio and video signals are to be replayed as described below. As such, the user interface may include a touch screen display, a keyboard, a mouse, a joystick or other input/output mechanisms. In some embodiments, the user interface, such as a display, speakers, or the like, may also be configured to provide audio and video output to the user. In an embodiment in which the apparatus includes a user interface, the user interface is in communication with the processor 72 such that an indication of the user input may be provided to the processor. However, even in an instance in which the apparatus does not include a user interface, the apparatus, such as the processor, is configured to receive the input defining the speed at which the audio and video signals are to be replayed. In an example embodiment in which the apparatus does include the user interface, however, the processor may comprise user interface circuitry configured to control at least some functions of one or more input/output mechanisms. The processor and/or user interface circuitry comprising the processor may be configured to control one or more functions of one or more input/output mechanisms through computer program instructions (for example, software and/or firmware) stored on a memory accessible to the processor (for example, memory device 74, and/or the like).</p><p id="p0028" num="0028">The apparatus 70 of the illustrated embodiment may also optionally include a communication interface 78 that may be any means such as a device or circuitry embodied in either hardware or a combination of hardware and software that is configured to receive and/or transmit data from/to a communications device in communication with the apparatus. For example, the communication interface may be configured to receive audio and video signals from various sources and/or to provide synchronized audio and video signals to various output devices, such as an external display and speakers. In this regard, the communication interface may include, for example, an antenna (or multiple antennas) and supporting hardware and/or software for enabling communications with a wireless communication network. Additionally or alternatively, the communication interface may include the circuitry for interacting with the antenna(s) to cause transmission of signals via the<!-- EPO <DP n="13"> --> antenna(s) or to handle receipt of signals received via the antenna(s). In some environments, the communication interface may alternatively or also support wired communication.</p><p id="p0029" num="0029">As shown in block 10 of <figref idrefs="f0001">Figure 1</figref>, the apparatus 70 may include means, such as the processor 72 or the like, for determining a trajectory for each of one or more, e.g., a plurality of, audio objects of an audio signal. As shown in <figref idrefs="f0002">Figure 2</figref> in more detail, the audio signals of an example embodiment may be stereo or multichannel audio signals that have been captured by an image capturing device 30, such as a camera, a video recorder, a mobile device, such as a smartphone, a personal digital assistant (PDA) or the like, or a computing device, such as a tablet computer, a personal computer, a laptop computer or the like. Regardless of the manner in which the image capturing device is embodied, the image capturing device may include a camera 32 for capturing video signals and a plurality of microphones 34 for capturing the corresponding audio signals, such as stereo or multichannel audio signals.</p><p id="p0030" num="0030">Following the capture of the audio and video signals, the audio and video signals of the embodiment depicted in <figref idrefs="f0002">Figure 2</figref> may be multiplexed as indicated by block 36. As shown, the image capturing device 30 may include circuitry, such as a processor, a multiplexor or the like, for multiplexing the audio and video signals prior to provision of the audio and video signals to a playback device 40, such as an audio/video playback device or other electronic device as described above. Alternatively, the image capturing device may separately provide the audio and video signals to the playback device without their having been multiplexed.</p><p id="p0031" num="0031">The audio and video signals may be provided by the image capturing device 30 to the playback device 40 directly, such as via direct connection, or via a network connection as depicted by network 38. Additionally or alternatively, the audio and video signals that have been captured by the image capturing device may be stored, such as by the image capturing device, by a storage device within the network, by the playback device or otherwise, and then subsequently provided to the playback device, such as upon demand.</p><p id="p0032" num="0032">In the illustrated embodiment in which the audio and video signals have been multiplexed, upon receipt by the playback device 40, the audio and video signals may be de-multiplexed by a processor, a demultiplexor or the like as shown at block 52. In an instance in which the audio and video signals have not been multiplexed, however, the playback device need not perform demultiplexing. In the illustrated embodiment, the playback device is also configured to receive input, such as from the user, indicating that the video is to be replayed with modified motion, such as in slow motion, and, in some instances, identifying the degree to which the replay of the video signals is to be modified, e.g., slowed. In this<!-- EPO <DP n="14"> --> regard, the audio and video signals are described herein to be replayed in slow motion by way of example. However, the the audio and video signals may be replayed in accordance with any of various predefined motion. The predefined motion causes the audio and video signals to be replayed at a speed that differs from a first speed, such as the standard speed, at which the audio and video signals are played, such as in slow motion as described below by way of example but not of limitation. For example, the slow motion replay may be defined in terms of the multiple of the slow motion speed at which the video signals are to be played back relative to the standard speed of the audio and video signals. For example, the standard speed may be 2 times, 3 times or more relative to the slow motion speed at which the video signals are to be replayed. In an instance in which an input is provided indicative of the video signals being replayed in slow motion, the playback device, such as a processor or the like, may engage slow motion playback at block 50 which correspondingly causes both the audio and video signals to be processed and subsequently played back at the designated slow motion speed. For example, the de-multiplexed video signals may be played back at standard speed in the absence of a slow motion input, but are played back in slow motion at the designated slow motion speed in response to the slow motion input as indicated by block 54. Additionally, in an instance in which there is no slow motion input and the video signals are to be replayed at standard speed, the de-multiplexed audio signals may also be provided to the speakers 46 for replay at standard speed. However, in an instance in which slow motion input is provided, the audio signals may be further processed as described below in order to maintain synchronization with the video signals.</p><p id="p0033" num="0033">As depicted in block 56 of <figref idrefs="f0002">Figure 2</figref>, in an instance in which the audio and video signals are to be replayed in slow motion, the apparatus 70 embodied by the playback device 40, such as the processor 72 or the like, may be configured to initially separate the audio signals into one or more audio objects. The processor may be configured to separate the audio signals into audio objects in a variety of manners, such as described by<nplcit id="ncit0001" npl-type="s"><text> Makino, Shoji et al., "Blind Source Separation of Convolutive Mixtures of Speech in Frequency Domain", IEICE TRANSACTIONS on Fundamentals of Electronics, Communications and Computer Sciences, Vol.E88-A (July 2005</text></nplcit>); <nplcit id="ncit0002" npl-type="s"><text>Mukai, Ryo et al., "Robust real-time blind source separation for moving speakers in a room", ICASSP 20 </text></nplcit>and/or <nplcit id="ncit0003" npl-type="s"><text>Lucas Parra et al., "On-line Convolutive Blind Source Separation of Non-Stationary Signals", Journal of VLSI signal processing systems for signal, image and video technology, August 2000, Volume 26, Issue 1-2, pp 39-46</text></nplcit>.</p><p id="p0034" num="0034">As shown in block 10 of <figref idrefs="f0001">Figure 1</figref> and is also depicted in block 56 of <figref idrefs="f0002">Figure 2</figref>, the apparatus 70 may include means, such as the processor 72 or the like, for determining a<!-- EPO <DP n="15"> --> trajectory for each of the one or more audio objects of an audio signal. The trajectories of the audio objects are the time dependent directions from which the audio objects appear to originate. Thus, the trajectory of an audio object may vary over the course of time if the source of the audio signal is in motion. The processor may be configured to determine the trajectories of the audio objects in various manners including those described by <nplcit id="ncit0004" npl-type="s"><text>Makino, Shoji et al., "Blind Source Separation of Convolutive Mixtures of Speech in Frequency Domain", IEICE TRANSACTIONS on Fundamentals of Electronics, Communications and Computer Sciences, Vol.E88-A (July 2005</text></nplcit>);<nplcit id="ncit0005" npl-type="s"><text> Mukai, Ryo et al., "Robust real-time blind source separation for moving speakers in a room", ICASSP 20 </text></nplcit>and/or <nplcit id="ncit0006" npl-type="s"><text>Lucas Parra et al., "On-line Convolutive Blind Source Separation of Non-Stationary Signals", Journal of VLSI signal processing systems for signal, image and video technology, August 2000, Volume 26, Issue 1-2, pp 39-46</text></nplcit>.</p><p id="p0035" num="0035">The apparatus 70 may also optionally include means, such as the processor 72 or the like, for determining a level for each of the one or more audio objects of the audio signal, as depicted by block 12 of <figref idrefs="f0001">Figure 1</figref> and also by block 56 of <figref idrefs="f0002">Figure 2</figref>. The level of an audio object may also be time dependent and, as such, may vary over the course of time. While the processor may be configured to determine the level of an audio object in various manners, the processor of an example embodiment may determine the energy, e.g., the average energy, of the audio object in each of a plurality of time segments with the energy, in turn, defining the level of the audio object during the respective time segment. The time segments may have a variety of different lengths, but, in one embodiment, may be 20 milliseconds.</p><p id="p0036" num="0036">For each audio object of an audio signal, the apparatus 70 may include means, such as the processor 72 or the like, for determining each audio object to be either a transient object or a non-transient object. See block 14 of <figref idrefs="f0001">Figure 1</figref>. In this regard, a transient object is an audio object that has substantial variance over a relatively short period of time, such as a short duration tone, a click-type signal or a noise burst, while a non-transient object is an audio object that has little variance over a period of time. In this regard, the amount of variance that distinguishes a transient object from a non-transient object may be predefined, along with the time period over which the variance is determined. In an example embodiment, the transient and non-transient objects include speech and non-speech objects, respectively. Thus, the apparatus, such as the processor, may be configured to determine each of the audio objects as either a speech object or a non-speech object, such as shown in blocks 58 of <figref idrefs="f0002">Figure 2</figref> and as described, for example, by <nplcit id="ncit0007" npl-type="b"><text>Jongseo Sohn, et al., "A statistical model-based voice activity detection", Signal Processing Letters, IEEE (Jan. 1999</text></nplcit>).<!-- EPO <DP n="16"> --></p><p id="p0037" num="0037">In an example embodiment, the apparatus 70, such as the processor 72, may be configured to determine each audio object to be either a transient object or a non-transient object by identifying each transient object and by then classifying all remaining objects, that is, all audio objects that have not been identified to be a transient object, to be non-transient objects. As many, if not most or all, audio signals that are not continuous possess some transients, the apparatus, such as the processor, of an example embodiment may determine an audio object having at least a predefined threshold amount of transient features to be a transient object. The predefined threshold amount of transient features may be defined in various manners, such as a predefined percent of the audio object being comprised of transient features and/or a predefined magnitude of the transient features. The apparatus, such as the processor, of this example embodiment may determine those audio objects that are not determined to be transient objects to be non-transient objects, or the apparatus, such as the processor, may be configured to determine those audio objects that have less than the predefined threshold amount of transient features to be non-transient objects.</p><p id="p0038" num="0038">The apparatus 70 of an example embodiment also includes means, such as the processor 72 or the like, for causing respective audio objects, such as the transient and non-transient objects, to be differently extended so as to continue to be synchronized with the video signals that are to be played back in slow motion. With respect to a transient object and as shown in block 16 of <figref idrefs="f0001">Figure 1</figref>, the apparatus may include means, such as the processor 72 or the like, for splitting the transient objects into transient segments. The processor may be configured to split a transient object into segments in various manners, but, in an example embodiment, the transient objects are split into segments that have a length of one word or one sentence. A transient object may be split into segments having a length of one word or one sentence in various manners such as described by <nplcit id="ncit0008" npl-type="s"><text>G.V. Ramana Rao and J. Srichland, "Word Boundary Detection Using Pitch Variations", Fourth International Conference on Spoken Language (1996</text></nplcit>); <nplcit id="ncit0009" npl-type="s"><text>H. Ney, et al., "The RWTH Large Vocabulary Continuous Speech Recognition System", IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (1998</text></nplcit>); <nplcit id="ncit0010" npl-type="s"><text>Gin-Der Wu and Chin-Teng Lin, "A Recurrent Neural Fuzzy Network for Word Boundary Detection in Variable Noise-Level Environments", IEEE Transactions on Systems, Man and Cybernetics, Part B: Cybernetics, Volume 31, Issue 1 (2001</text></nplcit>). Additionally or alternatively, the processor may be configured to split a transient object into segments with the segments being defined by relatively higher level(s) separated by relatively lower level(s).</p><p id="p0039" num="0039">After splitting the transient objects into transient segments, the apparatus 70 may include means, such as the processor 72 or the like, for inserting silent periods between the<!-- EPO <DP n="17"> --> transient segments. See block 18 of <figref idrefs="f0001">Figure 1</figref>. In this regard, the processor may be configured to insert silent segments that have a length that corresponds to the slow motion of the video signals. In this regard, the slow motion speed at which the video signals are to be played back may be a multiple of the standard speed of the audio and video signals. As such, the processor may be configured to insert silent segments that have a length that is selected such that the silent segments in combination with the corresponding transient segment have a collective length that is the multiple of the length of the corresponding transient segment at the standard speed. For example, in an instance in which the standard speed is 3 times the slow motion speed at which the video signals are to be played back, the processor may be configured to insert silent segments that are twice the length of the corresponding transient segment such that the silent segments in combination with the corresponding transient segment have a length that is 3 times the length of the corresponding transient segment at standard speed.</p><p id="p0040" num="0040">As shown at block 20 of <figref idrefs="f0001">Figure 1</figref>, the apparatus 70 of an example embodiment may also include means, such as the processor 72 or the like, for maintaining the trajectories of the transient objects and, in an example embodiment, also maintaining the levels of the transient objects. Thus, each transient object and, in turn, each transient segment of each transient object will appear to originate from the same direction when replayed in slow motion speed as in standard speed and to be replayed at the same level in slow motion speed as in standard speed.</p><p id="p0041" num="0041">Alternatively, in an instance in which the audio object is determined to be a non-transient object, the apparatus 70 of an example embodiment may include means, such as the processor 72 or the like, for repeating the non-transient object with a trajectory that varies over time in correspondence to the slow motion of the video signals. See block 22 of <figref idrefs="f0001">Figure 1</figref>. By way of example in which the standard speed of the audio and video signals is a multiple, such as 3 times, of the slow motion speed at which the video signals are to be played back, the processor may be configured to repeat the non-transient objects such that each non-transient object has a resulting length, after having been repeated, that is the multiple of the length of the respective non-transient object at the standard speed. For example, in an instance in which the standard speed is 3 times the slow motion speed, the processor may be configured to repeat the non-transient object such that the resulting length, after having been repeated, is 3 times the length of the respective non-transient object at the standard speed. As described below, the trajectory of the non-transient object is also lengthened by the multiple such that the trajectory associated with each portion of the non-transient object extends longer, such as 3 times longer in an instance in which the standard speed is 3 times the slow<!-- EPO <DP n="18"> --> motion speed, once the non-transient object has been repeated. See also block 60 of <figref idrefs="f0002">Figure 2</figref> which describes the manner in which the playback device 40, such as the processor, causes the transient and non-transient objects to be differently extended to be synchronized with the video signals that are to be played back in slow motion.</p><p id="p0042" num="0042">As shown in block 24 of <figref idrefs="f0001">Figure 1</figref> and block 62 of <figref idrefs="f0002">Figure 2</figref>, the apparatus 70 of an example embodiment may also include means, such as the processor 72, the user interface 76 or the like, for causing the respective audio objects, such as the transient and non-transient objects, to be rendered after having been differently extended. The transient and non-transient objects may be rendered in various manners, such as by panning for speakers or pursuant to a head related transfer function (HRTF) for headphones. As shown in <figref idrefs="f0002">Figure 2</figref>, for example, the transient and non-transient objects may then be provided to the speakers, headphones or other audio output devices 46 in accordance with the trajectories and levels that have been defined in the process that differently extending the transient and non-transient objects. As such, the resulting audio signals may be presented in synchronization with the video images presented in slow motion upon the display 44 to the user 42.</p><p id="p0043" num="0043">By way of example, <figref idrefs="f0004">Figure 4</figref> depicts a transient object, such as a speech audio object, and a non-transient object, such as a non-speech audio object, at standard speed. Along with the depiction of the speech and non-speech audio objects, the trajectory and level of the speech and non-speech objects at standard speed are shown. The speech object includes three words such that in an embodiment in which a speech object is split in speech segments that are each one word in length, the speech object includes three speech segments, namely, Word1, Word2 and Word3.</p><p id="p0044" num="0044">Referring now to <figref idrefs="f0005">Figure 5</figref>, the transient and non-transient objects, such as the speech and non-speech objects, are depicted following synchronization of the transient and non-transient objects with video signals that are to be played in slow motion. In this regard, the standard speed of the audio and video signals shown in <figref idrefs="f0004">Figure 4</figref> is 3 times the slow motion speed of the video signals that are to be played back in slow motion in <figref idrefs="f0005">Figure 5</figref>. In this example embodiment, the transient object, that is, the speech object, has been split into three transient segments and silent segments have been inserted after each speech segment such that the combination of a speech segment and the silent segments inserted thereafter has a length that is 3 times the length of the respective speech segment at standard speed. In this regard, it is noted that the silent segments inserted following Word2 and Word3 are shorter than the silent segments inserted after Word1 since Word2 and Word3 are also shorter than Word1. As also shown in <figref idrefs="f0005">Figure 5</figref>, the trajectory and the level associated with each speech segment remains the same at slow motion speed as at standard speed, such as indicated by the<!-- EPO <DP n="19"> --> directional arrows in regards to the trajectory. As illustrated, the silent segments do not have an associated trajectory and level as the silent segments do not generate any audible sound. As a result of the manner in which the non-transient objects are differently extended, the non-speech object is repeated over time in a manner that corresponds to the slow motion of the video signals. For example, in an instance in which the standard speed is 3 times the slow motion speed, the non-speech object is repeated so as to have a resulting length that is 3 times the length of the non-speech object at standard speed. As also shown in <figref idrefs="f0005">Figure 5</figref>, the trajectory of the non-transient object, such as the non-speech object, varies over time in correspondence to the slow motion of the video signals. In this regard, the trajectory of the non-speech signals varies in the same manner as the trajectory varies at standard speed, but the variance in the trajectory is stretched over the longer time period across which the non-transient object is repeated. Thus, the trajectory that is determined for the non-speech signal at each point in time or each segment in time at standard speed is extended by the same multiple, such as 3 times, that the standard speed is in comparison to the slow motion speed.</p><p id="p0045" num="0045">Similarly, the level of the non-transient object, such as the non-speech object, varies over time in correspondence to the slow motion of the video signals. As described above in conjunction with the trajectory of the non-speech signals, the level of the non-speech signal in slow motion speed may follow the same pattern as the level at standard speed, but the level at slow motion speed is stretched relative to the level at standard speed by the multiple that the standard speed is to the slow motion speed. While the level of the non-speech signal may be extended by the multiple so as to follow the same continuous and smooth curve as the level at standard speed, the level at standard speed may be divided into a plurality of segments with each segment extending for a predefined period of time, such as 20 milliseconds. During a respective period of time, the average level of the non-speech signal at standard speed may be determined. Thereafter, at slow motion speed, the level associated with each segment of the non-speech signal may be extended or multiplied by the multiple, such as 3 times, such that the same plurality of discrete levels are associated with the extended representation of the non-speech signal, albeit with each level extending longer, such as 3 times, relative to the corresponding level at standard speed. As noted above, the level of the extended non-speech signal may be changed from segment to segment more gradually than that depicted in <figref idrefs="f0005">Figure 5</figref> and, in some embodiments, a non-speech object may be repeated with some overlap so as to mask the boundaries between the repeated non-speech objects.</p><p id="p0046" num="0046">As described above in conjunction with the embodiment of <figref idrefs="f0005">Figure 5</figref>, the speech object and the non-speech object may each be extended in a manner independent of the other. In some embodiments, however, some parts of the speech object may leek into the non-speech<!-- EPO <DP n="20"> --> object such that the replay of the non-speech object may be influenced by and/or include aspects of the speech object. Conversely, in some embodiments, some parts of the non-speech object may leek into the speech object such that the replay of the speech object may be influenced by and/or include aspects of the non-speech object. In order to mask the leakage between the speech and non-speech objects, the apparatus 70, such as the processor 72, of an example embodiment may be configured to synchronize the segments of the speech object, e.g., Word 1, Word 2 and Word 3, with the non-speech object during replay in slow motion.</p><p id="p0047" num="0047">As shown in <figref idrefs="f0006">Figure 6</figref>, for example, the non-speech object may be repeated a number of times dependent upon the slow motion of the video. By way of example, in an instance in which the video is replayed in slow motion such that the standard speed is three times the speed in slow motion, the non-speech object may be repeated three times. Thus, the non-speech object may be repeated beginning at equally spaced initial times t<sub>1</sub>, t<sub>2</sub> and t<sub>3</sub> as shown in <figref idrefs="f0006">Figure 6</figref>. In this example embodiment, the apparatus 70, such as the processor 72, the user interface 76 or the like, may be configured to cause the segments of the speech object to be replayed concurrent with different instances of the non-speech objects and at a time relative to the initial time of the respective non-speech object that is consistent with, e.g., equal to, the offset, if any, of the segment of the particular speech object from the beginning of the non-speech object at standard speed. With reference to <figref idrefs="f0004">Figure 4</figref> which depicts the speech object and the non-speech object at standard speed, the first segment of the speech object, e.g., Word 1, begins with no offset from the start time to, while the second and third segments of the speech object, e.g., Word 2 and Word 3, begin at offsets of Δ<sub>1</sub> and Δ<sub>1</sub>+Δ<sub>2</sub>, respectively. In slow motion, the apparatus, such as the processor, the user interface or the like, may be configured in this example embodiment to replay the first segment of the speech object beginning at the start time t<sub>1</sub> with no offset, to replay the second segment of the speech object with the same offset of Δ<sub>1</sub> relative to the initial time t<sub>2</sub> of the second instance of the non-speech object and to replay the third segment of the speech object with the same offset Δ<sub>1</sub>+Δ<sub>2</sub> relative to the initial time t<sub>3</sub> of the third instance of the non-speech object. Thus, leakage between the speech and non-speech objects may be masked.</p><p id="p0048" num="0048">By differently extending the transient and non-transient objects in slow motion, the transient objects may continue to be synchronized with the sources of the transient objects, such as the sources of the speech signal, as the video signals are correspondingly slowed. By maintaining the synchronization, not only in time, but also in trajectory, the resulting slow motion audio and video signals will still appear natural to a viewer even though there are silent segments between the transient segments. In this regard, the transient objects cannot generally be repeated in the same manner as the non-transient objects without sounding<!-- EPO <DP n="21"> --> unnatural. Thus, the silent segments are inserted between transient segments to maintain synchronization while preserving the more natural sound of the transient segments, albeit now at a more deliberate or halting pace when replayed in slow motion. However, the non-transient objects are generally not as dependent upon synchronization to a particular source of the non-transient audio signals, such as a source of a non-speech signal, and a user may, instead, pace more value upon the non-transient objects being continuous without interruptions by silent segments in the same manner in which the transient objects are separated by silent segments. By differently extending the transient and non-transient objects, the resulting audio and video signals may be replayed in slow motion in a manner that remains synchronized and improves the user experience, such as by being more natural sounding.</p><p id="p0049" num="0049">By way of example, <figref idrefs="f0007">Figure 7</figref> depicts a series of three video images replayed at standard speed with the corresponding audio signals superimposed thereupon. As shown, the person walking from the left to the right says "Hello there! My name is Miikka.", while the automobile makes a "VROOM" noise and moves from the right to the left.</p><p id="p0050" num="0050">In an instance in which the video images are replayed in slow motion at half speed such that standard speed is 2 times the slow motion speed, the resulting video images are depicted in <figref idrefs="f0007">Figure 8</figref>. As also shown, the audio signals have been processed in accordance with an example embodiment of the present invention such that the speech objects are differently extended relative to the non-transient objects. In this regard, the speech objects are split into speech segments, each being one word in length, with silent segments inserted between the speech segments. As such, the speech segments remain synchronized with the video images in slow motion, both in terms of time and direction of the speech segments relative to the source of the audio signal. The noise made by the automobile, however, is a non-transient object, that is, a non-speech object, and, as such, is repeated with a trajectory and level that varies over time in correspondence to the slow motion of the video signals. As represented by <figref idrefs="f0007">Figure 8</figref>, the speech and non-speech signals therefore remain synchronized with the slow motion video signals, both in terms of time and trajectory. In contrast, if the audio signals were not differently extended as described pursuant to an embodiment of the present invention, but were, instead, simply repeated 2 times, the audio signals would not be in synchronization with the slow motion video signals at any time other than the first and last video images as shown, for example, in <figref idrefs="f0008">Figure 9</figref>. Thus, the method, apparatus 70 and computer program product of an example embodiment facilitate the synchronization of audio and video signals as the audio and video signals are replayed in slow motion.<!-- EPO <DP n="22"> --></p><p id="p0051" num="0051">In another example embodiment, a method, apparatus 70 and computer program product are provided to define the trajectory of the audio signals associated with at least a portion of a visual image that is stationary such that the audio signals that originate with the stationary portion of a visual image also remain fixed in position, even though the trajectory of the audio signals that were captured may have moved over time. In this embodiment and as illustrated in <figref idrefs="f0009">Figure 10</figref>, the apparatus may include means, such as the processor 70 or the like, for separating the audio signal that had been captured along with a corresponding video signal into one or more, e.g., a plurality of, audio objects. See block 80. For each of the one or more audio objects, the apparatus may also include means, such as the processor or the like, for determining a trajectory of the respective audio object and, in one embodiment, for also determining a level of the respective audio object. See block 82 of <figref idrefs="f0009">Figure 10</figref>.</p><p id="p0052" num="0052">In addition to capturing the audio signals, a visual image may also be captured by a camera 32 or other image capturing device. The image capturing device may capture a still image that is provided to a camera application 100, along with the time at which the still image is captured as shown in the more detailed flow diagram of <figref idrefs="f0010">Figure 11</figref>. Alternatively, the camera may capture a series of images that form a cinemagraph as shown in the more detailed flow diagram of <figref idrefs="f0011">Figure 12</figref>. In an instance in which the camera captures a cinemagraph, the apparatus 70, such as the processor 72, may separate the portions of the video images that are in motion from the portions of the video images that are still or stationary. See blocks 104 and 106 of <figref idrefs="f0011">Figure 12</figref>. In addition to capturing the video images, the camera may also determine the time at which each image was captured such that the time associated with the capture of the image that includes a stationary portion may be determined, such as by the processor.</p><p id="p0053" num="0053">As shown in block 84 of <figref idrefs="f0009">Figure 10</figref>, the apparatus 70 may also include means, such as the processor 72 or the like, for associating at least a portion of a visual image with one or more audio objects. In an instance in which the visual image is a still image as depicted in the embodiment of <figref idrefs="f0010">Figure 11</figref>, each of the audio objects captured concurrent with the capture of the still image may be associated with the visual image. However, in an instance in which the visual image comprises a cinemagraph, such as in accordance with the embodiment of <figref idrefs="f0011">Figure 12</figref>, the processor may be configured to associate at least a portion of the visual image, e.g., a stationary portion of the visual image, with one or more respective audio objects by initially correlating the trajectory of one or more audio objects to one or more of the moving parts of the visual image. In this regard, the apparatus, such as the processor, may correlate the trajectory of one or more audio objects to the one or more moving parts of a visual image by identifying those audio objects having a trajectory that cause the respective audio object to<!-- EPO <DP n="23"> --> appear to originate at the same location within the image as the moving part and to thereafter move in correspondence with the moving part from one image to the next. More particularly and as shown in <figref idrefs="f0011">Figure 12</figref>, the apparatus, such as the processor, may be configured to determine a trajectory for each moving part of an image such that the trajectories of the audio objects may be compared to the trajectories of the moving parts of the image so as to identify the trajectories of the audio objects that match the trajectories of the moving parts of the image. In this embodiment relating to a cinemagraph, the one or more respective audio objects that are associated with the stationary party of the series of images may include all of the audio objects other than the one or more audio objects correlated to or otherwise matched with the one or more moving parts of the series of images.</p><p id="p0054" num="0054">As shown in block 86 of <figref idrefs="f0009">Figure 10</figref>, the apparatus 70 of this embodiment may also include means, such as the processor 72 or the like, for determining the trajectory of the one or more respective audio objects at a time at which at least a portion of the visual image, e.g., a stationary portion of the visual image, was captured. As shown in block 96 of <figref idrefs="f0010">Figure 11</figref>, in an instance in which the visual image is a still image, the apparatus, such as the processor, may be configured to determine the trajectory of the one or more respective audio objects that have been associated with the still image to be the trajectory of the one or more respective audio objects at the time at which the still image was captured, thereby effectively freezing the trajectory value. Alternatively, as shown in block 108 of <figref idrefs="f0011">Figure 12</figref>, in an instance in which the visual image comprises a series of images and at least a portion of the visual image includes a stationary part, the apparatus, such as the processor, may be configured to determine the trajectory of the one or more respective audio objects at the time at which at least a portion of the visual image, such as the one or more stationary parts of the visual image, was captured by determining the trajectory of the one or more respective audio objects at the time at which the stationary part(s) of the series of images was captured.</p><p id="p0055" num="0055">As shown in block 88 of <figref idrefs="f0009">Figure 10</figref>, the apparatus 70 of this example embodiment may also include means, such as the processor 72, the user interface 76 or the like, for causing the visual image and the audio objects to be rendered with the one or more respective audio objects being rendered in accordance with the trajectory at the time at which the at least a portion of the visual image was captured. The audio and video signals may be rendered in various manners, such as by panning for speakers or pursuant to HRTF for headphones. In the context of a still image, for example, as shown in block 98 of <figref idrefs="f0010">Figure 11</figref>, the visual image and the audio objects may be rendered with the audio objects being rendered in accordance with the trajectory at the time at which the still image was captured. In an instance in which a cinemagraph is captured as shown in <figref idrefs="f0011">Figure 12</figref>, a visual image and the audio objects may be<!-- EPO <DP n="24"> --> rendered with the audio objects associated with the stationary part of the series of images being rendered in accordance with the trajectory of the audio objects associated with the stationary part of the series of images at the time at which the image that includes the stationary part of the series of images was captured. See block 110 of <figref idrefs="f0011">Figure 12</figref>. As shown in block 102 of <figref idrefs="f0010">Figure 11</figref> and block 112 of <figref idrefs="f0011">Figure 12</figref>, the audio and video signals may then be multiplexed prior to storage, play back or the like. As such, the method, apparatus and computer program product of this example embodiment may permit audio and video signals to be synchronized even though the audio signals that are captured may be in motion and the image or at least a portion of the image is stationary such that the audio signals associated with a still image or a stationary part of a cinemagraph also appear to be fixed in a position that corresponds to the still image or the stationary part of the cinemagraph.</p><p id="p0056" num="0056">In another example embodiment, a method, apparatus 70 and computer program product are provided in which the audio signals associated with a part of a visual image that is removed are also removed such that the resulting combination of the audio and video signals is consistent. As such, the apparatus of this example embodiment may include means, such as the processor 72 or the like, for removing one or more audio objects in response to the removal of a part of the series of images with the one or more audio objects that are removed being correlated to the part of the series of images that is removed. As described above in conjunction with the embodiment of <figref idrefs="f0011">Figure 12</figref>, the one or more audio objects may be correlated to the part of the series of images that is removed based upon a determination that the trajectory of the one or more audio signals corresponds to the location of the part of the visual image that is removed, such as by corresponding to the trajectory of the part of the visual image that is removed, such that the one or more audio objects appear to originate from the part of the visual image that is removed. As shown in <figref idrefs="f0012">Figure 13</figref>, for example, the image captured by a camera 32 or other image capturing device may include a part that is removed by a camera application as shown in block 114 and the apparatus, such as the processor, may determine the trajectory, that is, the location, of the part of the visual image that is removed as shown in block 116.</p><p id="p0057" num="0057">The apparatus 70 of this example embodiment, such as the processor 72, may also be configured to compare the trajectories of the audio objects to the trajectory of the part of the visual image that has been removed and to identify the audio objects having trajectories that match the trajectory of the part of the visual image that has been removed. See block 118 of <figref idrefs="f0012">Figure 13</figref>. The audio objects that have trajectories that match the trajectory of the part of the visual image that has been removed may also be removed from the audio signal such that the remaining audio objects may be rendered in accordance with a desired audio format and<!-- EPO <DP n="25"> --> consistent with the trajectories of the respective audio objects as shown in block 120, such as by panning for speakers or pursuant to HRTF for headphones. The rendered audio signals and the video signals may then be multiplexed to generate an image in which part of the video image that was captured has been removed and the audio signals that correspond to the removed part of the captured video image have also been removed. See block 122. As such, the resulting audio and video signals remain synchronized in this example embodiment notwithstanding the removal of a part of the video image that was captured.</p><p id="p0058" num="0058">As described above, <figref idrefs="f0001">Figures 1</figref>, <figref idrefs="f0002">2</figref> and <figref idrefs="f0009 f0010 f0011 f0012">10-13</figref> illustrates flowcharts of an apparatus 70, method and computer program product according to example embodiments of the invention. It will be understood that each block of the flowcharts, and combinations of blocks in the flowcharts, may be implemented by various means, such as hardware, firmware, processor, circuitry, and/or other communication devices associated with execution of software including one or more computer program instructions. For example, one or more of the procedures described above may be embodied by computer program instructions. In this regard, the computer program instructions which embody the procedures described above may be stored by a memory device 74 of an apparatus employing an embodiment of the present invention and executed by a processor 72 of the apparatus. As will be appreciated, any such computer program instructions may be loaded onto a computer or other programmable apparatus (for example, hardware) to produce a machine, such that the resulting computer or other programmable apparatus implements the functions specified in the flowchart blocks. These computer program instructions may also be stored in a computer-readable memory that may direct a computer or other programmable apparatus to function in a particular manner, such that the instructions stored in the computer-readable memory produce an article of manufacture the execution of which implements the function specified in the flowchart blocks. The computer program instructions may also be loaded onto a computer or other programmable apparatus to cause a series of operations to be performed on the computer or other programmable apparatus to produce a computer-implemented process such that the instructions which execute on the computer or other programmable apparatus provide operations for implementing the functions specified in the flowchart blocks.</p><p id="p0059" num="0059">Accordingly, blocks of the flowcharts support combinations of means for performing the specified functions and combinations of operations for performing the specified functions for performing the specified functions. It will also be understood that one or more blocks of the flowcharts, and combinations of blocks in the flowcharts, can be implemented by special purpose hardware-based computer systems which perform the specified functions, or combinations of special purpose hardware and computer instructions.<!-- EPO <DP n="26"> --></p><p id="p0060" num="0060">In some embodiments, certain ones of the operations above may be modified or further amplified. Furthermore, in some embodiments, additional optional operations may be included. Modifications, additions, or amplifications to the operations above may be performed in any order and in any combination.</p><p id="p0061" num="0061">Many modifications and other embodiments of the inventions set forth herein will come to mind to one skilled in the art to which these inventions pertain having the benefit of the teachings presented in the foregoing descriptions and the associated drawings. Therefore, it is to be understood that the inventions are not to be limited to the specific embodiments disclosed and that modifications and other embodiments are intended to be included within the scope of the appended claims. Moreover, although the foregoing descriptions and the associated drawings describe example embodiments in the context of certain example combinations of elements and/or functions, it should be appreciated that different combinations of elements and/or functions may be provided by alternative embodiments without departing from the scope of the appended claims. In this regard, for example, different combinations of elements and/or functions than those explicitly described above are also contemplated as may be set forth in some of the appended claims. Although specific terms are employed herein, they are used in a generic and descriptive sense only and not for purposes of limitation.</p></description><claims mxw-id="PCLM90459434" lang="EN" load-source="patent-office"><!-- EPO <DP n="27"> --><claim id="c-en-0001" num="0001"><claim-text>A method comprising:
<claim-text>determining a trajectory for each of one or more audio objects of an audio signal;</claim-text>
<claim-text>determining each of the audio objects to be a transient object or a non-transient object; and</claim-text>
<claim-text>causing a respective audio object to be differently extended depending upon whether the audio object is determined to be a transient object or a non-transient object so as to synchronize a video signal that is to be played back in a predefined motion, wherein causing the respective audio object to be differently extended comprises:
<claim-text>in an instance in which the respective audio object is determined to be a transient object, splitting the transient object into transient segments, inserting silent segments between the transient segments and maintaining the trajectories of the transient object; and</claim-text>
<claim-text>in an instance in which the respective audio object is determined to be a non-transient object, repeating the non-transient object with a trajectory that varies over time in correspondence to the predefined motion of the video signal.</claim-text></claim-text></claim-text></claim><claim id="c-en-0002" num="0002"><claim-text>The method according to claim 1, further comprising determining a level for each of the one or more audio objects, wherein causing the respective audio object to be differently extended comprises maintaining the level of the transient object and repeating the non-transient object with a level that varies over time in correspondence to the predefined motion of the video signal.</claim-text></claim><claim id="c-en-0003" num="0003"><claim-text>The method according to any of claims 1 and 2, wherein inserting silent segments between the transient segments comprises inserting silent segments that have a length that corresponds to the predefined motion of the video signal.</claim-text></claim><claim id="c-en-0004" num="0004"><claim-text>The method as claimed in any preceding claim, wherein a first speed of the audio and video signals is a multiple of the predefined motion speed at which the video signal is to be played back, and wherein inserting silent segments comprises inserting silent segments that have a length that is selected such that the silent segments in combination with a corresponding transient segment have a collective length that is the multiple of a length of the corresponding transient segment at the first speed.</claim-text></claim><claim id="c-en-0005" num="0005"><claim-text>The method as claimed in any preceding claim, wherein a first speed of the audio and video signals is a multiple of the predefined motion speed at which the video signal<!-- EPO <DP n="28"> --> is to be played back, and wherein repeating the non-transient object comprises repeating a respective non-transient object to have a resulting length that is the multiple of the length of the respective non-transient object at the first speed.</claim-text></claim><claim id="c-en-0006" num="0006"><claim-text>The method as claimed in any preceding claim, wherein the transient and non-transient objects comprise speech and non-speech objects, respectively.</claim-text></claim><claim id="c-en-0007" num="0007"><claim-text>The method as claimed in any preceding claim, further comprising causing the respective audio object to be rendered after having been differently extended.</claim-text></claim><claim id="c-en-0008" num="0008"><claim-text>The method as claimed in claim 1, wherein the method further comprising:
<claim-text>separating the audio signal into the one or more audio objects;</claim-text>
<claim-text>determining the trajectory for each of the one or more audio objects;</claim-text>
<claim-text>associating at least a portion of a visual image with one or more respective audio objects;</claim-text>
<claim-text>determining the trajectory of the one or more respective audio objects at a time at which the at least a portion of the visual image was captured; and</claim-text>
<claim-text>causing the visual image and the audio objects to be rendered with the one or more respective audio objects being rendered in accordance with the trajectory at the time at which the at least a portion of the visual image was captured.</claim-text></claim-text></claim><claim id="c-en-0009" num="0009"><claim-text>The method as claimed in claim 8, wherein the visual image comprises a still image, and wherein determining the trajectory of the one or more respective audio objects at the time at which at least a portion of the visual image was captured comprises determining the trajectory of the one or more respective audio objects at the time at which the still image was captured.</claim-text></claim><claim id="c-en-0010" num="0010"><claim-text>The method as claimed in any of claims 8 and 9, wherein the visual image comprises a series of images, wherein the at least a portion of the visual image comprises a stationary part of the series of images, and wherein determining the trajectory of the one or more respective audio objects at the time at which at least a portion of the visual image was captured comprises determining the trajectory of the one or more respective audio objects at the time at which the stationary part of the series of images was captured.</claim-text></claim><claim id="c-en-0011" num="0011"><claim-text>The method as claimed in claim 10, wherein the series of images also includes one or more moving parts, wherein the method further comprises correlating the trajectory of one or more audio objects to the one or more moving parts.<!-- EPO <DP n="29"> --></claim-text></claim><claim id="c-en-0012" num="0012"><claim-text>The method as claimed in claim 11, wherein the one or more respective audio objects that are associated with the stationary part of the series of images comprises all audio objects other than the one or more audio objects correlated to the one or more moving parts of the series of images.</claim-text></claim><claim id="c-en-0013" num="0013"><claim-text>The method as claimed in any of claims 10 to 12, further comprising removing of a part of the series of images that is correlated to the part of the series of images being removed.</claim-text></claim><claim id="c-en-0014" num="0014"><claim-text>The method as claimed in any preceding claim, further comprising:
<claim-text>providing a plurality of microphones for capturing the audio signal; and</claim-text>
<claim-text>determining the one or more audio objects based on the captured audio signal.</claim-text></claim-text></claim><claim id="c-en-0015" num="0015"><claim-text>An apparatus configured to perform the method of any of claims 1 to 14.</claim-text></claim></claims><drawings mxw-id="PDW20422161" load-source="patent-office"><!-- EPO <DP n="30"> --><figure id="f0001" num="1"><img id="if0001" file="imgf0001.tif" wi="165" he="210" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="31"> --><figure id="f0002" num="2"><img id="if0002" file="imgf0002.tif" wi="165" he="205" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="32"> --><figure id="f0003" num="3"><img id="if0003" file="imgf0003.tif" wi="165" he="172" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="33"> --><figure id="f0004" num="4"><img id="if0004" file="imgf0004.tif" wi="165" he="196" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="34"> --><figure id="f0005" num="5"><img id="if0005" file="imgf0005.tif" wi="165" he="168" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="35"> --><figure id="f0006" num="6"><img id="if0006" file="imgf0006.tif" wi="153" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="36"> --><figure id="f0007" num="7,8"><img id="if0007" file="imgf0007.tif" wi="165" he="184" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="37"> --><figure id="f0008" num="9"><img id="if0008" file="imgf0008.tif" wi="165" he="151" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="38"> --><figure id="f0009" num="10"><img id="if0009" file="imgf0009.tif" wi="108" he="216" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="39"> --><figure id="f0010" num="11"><img id="if0010" file="imgf0010.tif" wi="165" he="156" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="40"> --><figure id="f0011" num="12"><img id="if0011" file="imgf0011.tif" wi="165" he="167" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="41"> --><figure id="f0012" num="13"><img id="if0012" file="imgf0012.tif" wi="165" he="167" img-content="drawing" img-format="tif"/></figure></drawings><search-report-data><doc-page id="srep0001" file="srep0001.tif" wi="158" he="233" type="tif"/><doc-page id="srep0002" file="srep0002.tif" wi="158" he="233" type="tif"/><doc-page id="srep0003" file="srep0003.tif" wi="158" he="233" type="tif"/><doc-page id="srep0004" file="srep0004.tif" wi="158" he="233" type="tif"/></search-report-data><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
