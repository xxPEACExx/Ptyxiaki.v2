<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2960753-A1" country="EP" doc-number="2960753" kind="A1" date="20151230" family-id="53483733" file-reference-id="312929" date-produced="20180824" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="160451524" ucid="EP-2960753-A1"><document-id><country>EP</country><doc-number>2960753</doc-number><kind>A1</kind><date>20151230</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-15173410-A" is-representative="YES"><document-id mxw-id="PAPP193866016" load-source="docdb" format="epo"><country>EP</country><doc-number>15173410</doc-number><kind>A</kind><date>20150623</date><lang>EN</lang></document-id><document-id mxw-id="PAPP193866017" load-source="patent-office" format="original"><country>EP</country><doc-number>15173410.0</doc-number><date>20150623</date><lang>EN</lang></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC162033915" ucid="KR-20140076781-A" load-source="docdb"><document-id format="epo"><country>KR</country><doc-number>20140076781</doc-number><kind>A</kind><date>20140623</date></document-id></priority-claim><priority-claim mxw-id="PPC162478052" ucid="KR-20150085230-A" load-source="docdb"><document-id format="epo"><country>KR</country><doc-number>20150085230</doc-number><kind>A</kind><date>20150616</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL-1988521081" load-source="docdb">G06F   3/0354      20130101ALI20151104BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-1988523597" load-source="docdb">G06F   3/03        20060101AFI20151104BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-1988527570" load-source="docdb">G06F   3/041       20060101ALI20151104BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-1713531303" load-source="docdb" scheme="CPC">G06F   3/0412      20130101 LI20180103BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1713531789" load-source="docdb" scheme="CPC">G06F   3/0321      20130101 LI20180103BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1984017948" load-source="docdb" scheme="CPC">G06F   3/042       20130101 LI20151224BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1984018862" load-source="docdb" scheme="CPC">G09G   5/10        20130101 LI20151224BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1984019663" load-source="docdb" scheme="CPC">G06F   3/0304      20130101 LI20151224BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1984022216" load-source="docdb" scheme="CPC">G09G   5/02        20130101 LI20151224BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1984024460" load-source="docdb" scheme="CPC">G06F   3/03545     20130101 FI20160109BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT165546038" lang="DE" load-source="patent-office">OPTISCHE BERÜHRUNGSANZEIGEVORRICHTUNG UND VERFAHREN ZU IHRER ANSTEUERUNG</invention-title><invention-title mxw-id="PT165546039" lang="EN" load-source="patent-office">OPTICAL TOUCH DISPLAY DEVICE AND DRIVING METHOD THEREOF</invention-title><invention-title mxw-id="PT165546040" lang="FR" load-source="patent-office">DISPOSITIF D'AFFICHAGE TACTILE ET OPTIQUE ET PROCEDE DE COMMANDE CORRESPONDANT</invention-title><citations><patent-citations><patcit mxw-id="PCIT389722131" load-source="docdb" ucid="US-20100141785-A1"><document-id format="epo"><country>US</country><doc-number>20100141785</doc-number><kind>A1</kind><date>20100610</date></document-id><sources><source name="SEA" category="XI" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT389722132" load-source="docdb" ucid="US-20100164912-A1"><document-id format="epo"><country>US</country><doc-number>20100164912</doc-number><kind>A1</kind><date>20100701</date></document-id><sources><source name="SEA" category="XI" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT389722133" load-source="docdb" ucid="US-20120044168-A1"><document-id format="epo"><country>US</country><doc-number>20120044168</doc-number><kind>A1</kind><date>20120223</date></document-id><sources><source name="SEA" category="XI" created-by-npl="N"/></sources></patcit></patent-citations><non-patent-citations><nplcit><text>None</text><sources><source mxw-id="PNPL62638812" load-source="docdb" name="APP"/></sources></nplcit></non-patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR1103324021" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>LG DISPLAY CO LTD</last-name><address><country>KR</country></address></addressbook></applicant><applicant mxw-id="PPAR1103316168" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>LG DISPLAY CO., LTD.</last-name></addressbook></applicant><applicant mxw-id="PPAR1101646984" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>LG Display Co., Ltd.</last-name><iid>101331551</iid><address><street>128 Yeoui-daero Youngdungpo-gu</street><city>Seoul 150-721</city><country>KR</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR1103339021" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>KIM JUNG HEE</last-name><address><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR1103315725" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>KIM, JUNG HEE</last-name></addressbook></inventor><inventor mxw-id="PPAR1101643032" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>KIM, JUNG HEE</last-name><address><street>106-1201, Yeoksam Prugio (Yeoksam Prugio Apt., Yeoksam-dong) 332, Eonju-ro, Gangnam-gu</street><city>135-796 Seoul</city><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR1103327360" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>KIM KI DUK</last-name><address><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR1103341557" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>KIM, KI DUK</last-name></addressbook></inventor><inventor mxw-id="PPAR1101653014" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>KIM, KI DUK</last-name><address><street>1011-1502, Chaekhyangki Maeul Dongmun Goodmorning Hill., Dongpae-ri, Gyoha-up</street><city>413-833 Paju-si, Gyeonggi-do</city><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR1103327767" load-source="docdb" sequence="3" format="epo"><addressbook><last-name>HWANG JONG HEE</last-name><address><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR1103335491" load-source="docdb" sequence="3" format="intermediate"><addressbook><last-name>HWANG, JONG HEE</last-name></addressbook></inventor><inventor mxw-id="PPAR1101653013" load-source="patent-office" sequence="3" format="original"><addressbook><last-name>HWANG, JONG HEE</last-name><address><street>603-801, Dongbu-kunyoung, Hugok Maeul 6 Danji, 1050, Ilsan-dong, Ilsanseo-gu</street><city>411-310 Goyang-si, Gyeonggi-do</city><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR1103324695" load-source="docdb" sequence="4" format="epo"><addressbook><last-name>OH SEUNG SEOK</last-name><address><country>KR</country></address></addressbook></inventor><inventor mxw-id="PPAR1103303261" load-source="docdb" sequence="4" format="intermediate"><addressbook><last-name>OH, SEUNG SEOK</last-name></addressbook></inventor><inventor mxw-id="PPAR1101642262" load-source="patent-office" sequence="4" format="original"><addressbook><last-name>OH, SEUNG SEOK</last-name><address><street>201, (Seogyo-dong) 9-17, Donggyo-ro 18-gil, Mapo-gu</street><city>121-842 Seoul</city><country>KR</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR1101643577" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Viering, Jentschura &amp; Partner</last-name><iid>101265175</iid><address><street>Am Brauhaus 8</street><city>01099 Dresden</city><country>DE</country></address></addressbook></agent></agents></parties><international-convention-data><designated-states><ep-contracting-states><country mxw-id="DS660685833" load-source="docdb">AL</country><country mxw-id="DS660688600" load-source="docdb">AT</country><country mxw-id="DS660687159" load-source="docdb">BE</country><country mxw-id="DS660611172" load-source="docdb">BG</country><country mxw-id="DS660611602" load-source="docdb">CH</country><country mxw-id="DS660686452" load-source="docdb">CY</country><country mxw-id="DS660686453" load-source="docdb">CZ</country><country mxw-id="DS660692755" load-source="docdb">DE</country><country mxw-id="DS660687160" load-source="docdb">DK</country><country mxw-id="DS660687161" load-source="docdb">EE</country><country mxw-id="DS660783742" load-source="docdb">ES</country><country mxw-id="DS660611173" load-source="docdb">FI</country><country mxw-id="DS660611174" load-source="docdb">FR</country><country mxw-id="DS660692756" load-source="docdb">GB</country><country mxw-id="DS660687162" load-source="docdb">GR</country><country mxw-id="DS660692757" load-source="docdb">HR</country><country mxw-id="DS660686454" load-source="docdb">HU</country><country mxw-id="DS660611607" load-source="docdb">IE</country><country mxw-id="DS660687179" load-source="docdb">IS</country><country mxw-id="DS660611195" load-source="docdb">IT</country><country mxw-id="DS660687180" load-source="docdb">LI</country><country mxw-id="DS660692758" load-source="docdb">LT</country><country mxw-id="DS660688601" load-source="docdb">LU</country><country mxw-id="DS660692771" load-source="docdb">LV</country><country mxw-id="DS660692772" load-source="docdb">MC</country><country mxw-id="DS660688602" load-source="docdb">MK</country><country mxw-id="DS660688611" load-source="docdb">MT</country><country mxw-id="DS660611196" load-source="docdb">NL</country><country mxw-id="DS660611608" load-source="docdb">NO</country><country mxw-id="DS660611197" load-source="docdb">PL</country><country mxw-id="DS660783743" load-source="docdb">PT</country><country mxw-id="DS660611198" load-source="docdb">RO</country><country mxw-id="DS660783744" load-source="docdb">RS</country><country mxw-id="DS660611207" load-source="docdb">SE</country><country mxw-id="DS660606943" load-source="docdb">SI</country><country mxw-id="DS660611609" load-source="docdb">SK</country><country mxw-id="DS660611610" load-source="docdb">SM</country><country mxw-id="DS660687181" load-source="docdb">TR</country></ep-contracting-states><ep-extended-states><ep-extended-state-data><country>BA</country></ep-extended-state-data><ep-extended-state-data><country>ME</country></ep-extended-state-data></ep-extended-states></designated-states></international-convention-data></bibliographic-data><abstract mxw-id="PA166479894" lang="EN" load-source="patent-office"><p id="pa01" num="0001">An optical touch display device which is advantageous in high-speed driving, large-area touch sensing, and multi-touch sensing because of use of an image map and which can improve touch sensing performance and a driving method thereof are provided. The optical touch display device includes a display device configured to display a display image based on input source image data and an image map for touch sensing, an optical touch pen configured to detect map information of the image map displayed on the display device, and a position detector configured to detect position information (coordinate information) on a screen based on the map information.
<img id="iaf01" file="imgaf001.tif" wi="78" he="98" img-content="drawing" img-format="tif"/></p></abstract><abstract mxw-id="PA166759706" lang="EN" source="EPO" load-source="docdb"><p>An optical touch display device which is advantageous in high-speed driving, large-area touch sensing, and multi-touch sensing because of use of an image map and which can improve touch sensing performance and a driving method thereof are provided. The optical touch display device includes a display device configured to display a display image based on input source image data and an image map for touch sensing, an optical touch pen configured to detect map information of the image map displayed on the display device, and a position detector configured to detect position information (coordinate information) on a screen based on the map information.</p></abstract><description mxw-id="PDES98404595" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><heading id="h0001"><b><u>CROSS REFERENCE TO RELATED APPLICATIONS</u></b></heading><p id="p0001" num="0001">This application claims the benefit of the Korean Patent Application Nos. <patcit id="pcit0001" dnum="KR1020140076781"><text>10-2014-0076781 filed on June 23, 2014</text></patcit>, and <patcit id="pcit0002" dnum="KR1020150085230"><text>10-2015-0085230 filed on June 16, 2015</text></patcit>, which are hereby incorporated by reference for all purposes as if fully set forth herein.</p><heading id="h0002"><b><u>BACKGROUND OF THE INVENTION</u></b></heading><heading id="h0003"><b><u>Field of the Invention</u></b></heading><p id="p0002" num="0002">The present invention relates to an optical touch display device, and more particularly, to an optical touch display device which is advantageous in high-speed driving, large-area touch sensing, and multi-touch sensing because of use of an image map and which can improve touch sensing performance and a driving method thereof.</p><heading id="h0004"><b><u>Discussion of the Related Art</u></b></heading><p id="p0003" num="0003">Instead of a mouse or a keyboard which was used as an input unit of a flat panel display device in the past, a touch screen device in which a user can input information directly to a screen using a finger or a pen has been used.</p><p id="p0004" num="0004">A touch screen device is applied to monitors of a navigation apparatus, an industrial terminal, a notebook computer, banking automation equipment, a game machine, and the like; portable terminals such as a mobile phone, an MP3, a PDA, a PMP, a PSP, a portable game machine, a DMB receiver, and a tablet PC; and household electrical appliances such as a refrigerator, a microwave oven, and a washing machine, and has been used more widely with a merit that it can be easily manipulated by any one.</p><p id="p0005" num="0005">Various types of touch screens have been developed and used such as a resistive type, an electro-magnetic type, an infrared type, and a capacitive type.<!-- EPO <DP n="2"> --></p><p id="p0006" num="0006"><figref idrefs="f0001">FIG. 1</figref> is a diagram schematically illustrating an infrared type touch screen device according to the related art.</p><p id="p0007" num="0007">Referring to <figref idrefs="f0001">FIG. 1</figref>, the infrared type touch screen device according to the related art includes an infrared LED disposed on one side surface of a waveguide formed of reinforced glass or plastics, a projector disposed under the waveguide and configured to emitting a display beam, and an infrared camera disposed under the waveguide.</p><p id="p0008" num="0008">When a user touches a screen displayed on the entire surface of the waveguide, infrared rays totally reflected in the waveguide are refracted to the bottom of the waveguide and the infrared rays are received using the infrared camera, whereby the touch is sensed. At this time, an angle at which the infrared rays are sensed is calculated to detect a touched position.</p><p id="p0009" num="0009">Since such an infrared type touch screen device has to include the infrared camera, there is a problem in that the number of manufacturing processes and the manufacturing costs increase and the size and thickness of the device increase.</p><p id="p0010" num="0010">Capacitive type touch devices can be classified into an in-cell type in which a touch device is incorporated in cells of a display panel, an on-cell type in which a touch device is formed on a display panel, and an add-on type in which a touch screen is particularly coupled to the top of a display device. In recent years, the in-cell type touch screen having a merit in beautiful design and slimness has been used more and more.</p><p id="p0011" num="0011"><figref idrefs="f0001">FIG. 2</figref> is a diagram schematically illustrating an in-cell type touch display device according to the related art.</p><p id="p0012" num="0012">Referring to <figref idrefs="f0001">FIG. 2</figref>, the in-cell touch type display device according to the related art includes a display panel, a gate driver (not illustrated), a data driver (not illustrated), and a touch driver (not illustrated).<!-- EPO <DP n="3"> --></p><p id="p0013" num="0013">Plural sub-pixels are formed in the display panel, and a touch screen is formed by plural touch electrodes 10. Here, the touch electrodes 10 are formed in the display panel 1 along with the sub-pixels. Common electrodes formed to supply a common voltage Vcom to the sub-pixels are used as the touch electrodes 10.</p><p id="p0014" num="0014">The plural touch electrodes 10 include plural drive electrodes 12 (TX electrodes) supplied with a touch driving signal (TC signal) and plural reception electrodes 14 (RX electrodes) for sensing a touch. The plural reception electrodes 14 can be formed in the form of single wires to have a bar shape from the upper end to the lower end of the display panel 1. The plural drive electrodes 12 can be grouped by a predetermined number of pixels.</p><p id="p0015" num="0015">Plural drive electrode lines 20 supplying a touch drive signal to the plural drive electrodes 12 are formed in the display panel 1. The plural drive electrodes 12 formed in the same horizontal line are connected by the drive electrode line 20. In addition, plural reception electrode lines 30 sensing capacitance of the plural reception electrodes 14 are formed.</p><p id="p0016" num="0016">The touch driver includes a touch driving integrated circuit (IC) and a touch sensing integrated circuit (IC). The touch driving IC is connected to the plural drive electrode lines 20 to supply a touch driving signal to the plural drive electrodes 12. The touch sensing IC is connected to the plural reception electrode lines 30 to senses a touch signal.</p><p id="p0017" num="0017">In such an in-cell touch type display device according to the related art, since the plural drive electrode lines 20 and the plural reception electrode lines 30 have to be formed to cross each other in order to use common electrodes in the display panel as the touch electrodes 10, there is a problem in that the number of manufacturing processes increases.<!-- EPO <DP n="4"> --></p><p id="p0018" num="0018">In the in-cell touch type, the drive electrodes 12 and the distance between the electrodes is small because the reception electrodes 14 are formed on the same plane, and parasitic capacitance increases because the plural drive electrode lines 20 and the plural reception electrode lines 30 are formed in cells. There is a problem in that the larger of the screen of the display panel becomes, the greater the parasitic capacitance becomes geometrically and the sensing performance of the touch sensing IC is lowered when the parasitic capacitance becomes greater. Accordingly, an increase in size of the in-cell touch type display device is restricted.</p><heading id="h0005"><b><u>SUMMARY OF THE INVENTION</u></b></heading><p id="p0019" num="0019">The invention is made to solve the above-mentioned problems and an object thereof is to provide an optical touch display device capable of sensing a large-area touch and a driving method thereof.</p><p id="p0020" num="0020">Another object of the invention is to provide an optical touch display device which is advantageous in multi-touch sensing using an image map and which can improve touch sensing performance and a driving method thereof.</p><p id="p0021" num="0021">In addition to the above-mentioned technical object of the invention, other features and advantages of the invention will be described below or will be apparently understood by those skilled in the art from the description and explanation. The present invention provides an optical touch display device and a method of driving an optical touch display device in accordance with the independent claims. Further embodiments are described in the dependent claims.</p><p id="p0022" num="0022">According to an aspect of the invention, there is provided an optical touch display device including: a display device configured to display a display image based on input source image data and an image map for touch sensing; an optical touch pen configured<!-- EPO <DP n="5"> --> to detect map information of the image map displayed on the display device; and a position detector configured to detect position information (coordinate information) on a screen based on the map information.</p><p id="p0023" num="0023">According to another aspect of the invention, there is provided a method of driving an optical touch display device, including: arranging source image data of sub-pixels in the unit of frames and generating an image map for touch sensing; generating corrected image data by subtracting image data of the image map from the source image data; alternately displaying an image based on the corrected image data and the image map; and sensing map information of a specific position on the image map using an optical touch pen having an optical camera built therein.</p><p id="p0024" num="0024">According to still another aspect of the invention, there is provided a method of driving an optical touch display device, including: mapping position information for touch sensing onto image data supplied to sub-pixels; sensing map information of a specific position on an image map using an optical touch pen having an optical camera built therein; and detecting a coordinate touched by the optical touch pen using the position information matched onto the map information.</p><p id="p0025" num="0025">In the optical touch display device and the driving method thereof according to the invention, it is possible to perform displaying of a screen and sensing of a touch with high-speed driving using an image map.</p><p id="p0026" num="0026">In the optical touch display device and the driving method thereof according to the invention, it is possible to perform large-area touch sensing and multi-touch sensing using an image map.</p><p id="p0027" num="0027">In the optical touch display device and the driving method thereof according to the invention, it is possible to improve touch sensing performance using an image map.<!-- EPO <DP n="6"> --></p><p id="p0028" num="0028">Other features and advantages of the invention may be newly understood from embodiments of the invention.</p><p id="p0029" num="0029">It is to be understood that both the foregoing general description and the following detailed description of the present invention are exemplary and explanatory and are intended to provide further explanation of the invention as claimed.</p><heading id="h0006"><b><u>BRIEF DESCRIPTION OF THE DRAWINGS</u></b></heading><p id="p0030" num="0030">The accompanying drawings, which are included to provide a further understanding of the invention and are incorporated in and constitute a part of this application, illustrate embodiment(s) of the invention and together with the description serve to explain the principle of the invention. In the drawings:
<ul><li><figref idrefs="f0001">FIG. 1</figref> is a diagram schematically illustrating an infrared type touch screen device according to the related art.</li><li><figref idrefs="f0001">FIG. 2</figref> is a diagram schematically illustrating an in-cell touch type display device according to the related art.</li><li><figref idrefs="f0002">FIG. 3</figref> is a diagram schematically illustrating an optical touch display device according to an embodiment of the invention.</li><li><figref idrefs="f0002">FIG. 4</figref> is a diagram illustrating a display panel illustrated in <figref idrefs="f0002">FIG. 3</figref>.</li><li><figref idrefs="f0003">FIG. 5A</figref> is a diagram illustrating an optical touch pen of the optical touch display device according to the embodiment of the invention.</li><li><figref idrefs="f0003">FIG. 5B</figref> is a diagram illustrating an optical touch pen of an optical touch display device according to another embodiment of the invention.</li><li><figref idrefs="f0004">FIG. 6</figref> is a diagram schematically illustrating an optical touch display device according to another embodiment of the invention.</li><li><figref idrefs="f0004">FIG. 7</figref> is a diagram illustrating a display panel illustrated in <figref idrefs="f0004">FIG. 6</figref>.<!-- EPO <DP n="7"> --></li><li><figref idrefs="f0005">FIG. 8</figref> is a diagram illustrating a state in which a display image and an image map are alternately displayed.</li><li><figref idrefs="f0006">FIG. 9</figref> is a diagram illustrating a method of preventing distortion of a display image due to a color map.</li><li><figref idrefs="f0006">FIG. 10</figref> is a diagram illustrating a color map.</li><li><figref idrefs="f0007">FIG. 11</figref> is a diagram illustrating a method of reducing interference between color patterns constituting a color map.</li><li><figref idrefs="f0008">FIG. 12</figref> is a diagram illustrating an example in which a color map is generated.</li><li><figref idrefs="f0009">FIG. 13</figref> is a diagram illustrating another example in which a color map is generated.</li><li><figref idrefs="f0010">FIG. 14</figref> is a diagram illustrating another example in which a gray map is generated.</li><li><figref idrefs="f0011">FIG. 15</figref> is a diagram illustrating another example in which a pattern map is generated.</li><li><figref idrefs="f0012">FIG. 16</figref> is a diagram illustrating a state in which a display image and a pattern map are alternately displayed.</li><li><figref idrefs="f0012">FIG. 17</figref> is a diagram illustrating a method of preventing distortion of a display image due to a pattern map.</li><li><figref idrefs="f0013">FIGS. 18</figref> and <figref idrefs="f0014">19</figref> are diagrams illustrating a method of driving the optical touch display device according to the embodiment of the invention.</li><li><figref idrefs="f0015">FIG. 20</figref> is a diagram illustrating an example in which position information is generated using a display image.</li><li><figref idrefs="f0016">FIG. 21</figref> is a diagram illustrating a method of preventing distortion of an image when position information is included in source image data.</li></ul><!-- EPO <DP n="8"> --></p><heading id="h0007"><b><u>DETAILED DESCRIPTION OF EXEMPLARY EMBODIMENTS</u></b></heading><p id="p0031" num="0031">Reference will now be made in detail to the exemplary embodiments of the present invention, examples of which are illustrated in the accompanying drawings. Wherever possible, the same reference numbers will be used throughout the drawings to refer to the same or like parts. In the following description of the present invention, if detailed description of elements or functions known in the art of the present invention is not related to the subject matter of the present invention, the detailed description will be omitted.</p><p id="p0032" num="0032">Advantages and features of the invention and methods for achieving the advantages or features will be apparent from embodiments described below in detail with reference to the accompanying drawings. However, the invention is not limited to the embodiments but can be modified in various forms. The embodiments are merely for completing disclosure of the invention and are provided to completely inform those skilled in the art of the scope of the invention. The scope of the invention is defined by only the appended claims.</p><p id="p0033" num="0033">Shapes, sizes, ratios, angles, number of pieces, and the like illustrated in the drawings for the purpose of explaining the embodiments of the invention are exemplary and thus the invention is not limited to the illustrated items. Like reference numerals in the entire specification denote like elements. When it is determined that detailed description of known techniques involved in the invention makes the gist of the invention obscure, the detailed description thereof will not be made. When "include," "have", "be constituted", and the like are mentioned in the specification, another element may be added unless "only" is used. A singular expression of an element includes two or more elements unless differently mentioned.<!-- EPO <DP n="9"> --></p><p id="p0034" num="0034">In analyzing elements, an error range is included even when explicit description is not made.</p><p id="p0035" num="0035">For example, when temporal relationships are described using "after", "subsequent to", "next", "before", and the like, such expression may include temporal discontinuity unless "immediately" or "directly" is used.</p><p id="p0036" num="0036">Terms "first", "second", and the like can be used to describe various elements, but the elements should not be limited to the terms. The terms are used only to distinguish an element from another. Therefore, a first element may be a second element within the technical spirit of the invention.</p><p id="p0037" num="0037">Features of the embodiments of the invention can be coupled or combined partially or on the whole and can be technically interlinked and driven in various forms. The embodiments may be put into practice independently or in combination.</p><p id="p0038" num="0038">Hereinafter, a display device with a touch screen assembled thereto and a driving method thereof according to embodiments of the invention will be described in detail with reference to the accompanying drawings. Like reference numerals all over the specification denote like elements. In the following explanation, detailed description of configurations and functions widely known in the art and not associated with the core configuration of the invention will not be made.</p><p id="p0039" num="0039">In an optical touch display device and a driving method thereof according to an embodiment of the invention, an image map including plural pieces of map information is constituted and the image map is alternately inserted and displayed between display images. The map information of the image map is detected using an optical touch pen and position information (coordinate information) of a position touched with the pen is detected based on the map information. Accordingly, it is possible to achieve touch sensing without constructing a physical touch screen into the display device.<!-- EPO <DP n="10"> --></p><p id="p0040" num="0040">The inventors of the present invention propose various types of image maps.</p><p id="p0041" num="0041">A color map in which coordinates are constituted by plural colors is proposed as an example of the image map.</p><p id="p0042" num="0042">A gray map in which coordinates are constituted by plural gray scales of an image is proposed as another example of the image map.</p><p id="p0043" num="0043">A pattern map in which coordinates are constituted by predetermined patterns is proposed as still another example of the image map.</p><p id="p0044" num="0044">As still another example of the image map, position information (coordinate information) is included in source image data to constitute an image map using a display image itself.</p><p id="p0045" num="0045">A method of detecting position information (coordinate information) of a position touched with a pen using the image maps is proposed.</p><p id="p0046" num="0046"><figref idrefs="f0002">FIG. 3</figref> is a diagram schematically illustrating an optical touch display device according to an embodiment of the invention. <figref idrefs="f0002">FIG. 4</figref> is a diagram illustrating a display panel illustrated in <figref idrefs="f0002">FIG. 3</figref>.</p><p id="p0047" num="0047">Referring to <figref idrefs="f0002">FIGS. 3 and 4</figref>, the optical touch display device according to the embodiment of the invention includes a display device 100, an optical touch pen 200, and a position detector 300.</p><p id="p0048" num="0048">The display device 100 includes a display panel 110 on which an image is displayed and a drive circuit unit. The drive circuit unit includes a gate driver 120, a data driver 130, and a timing controller 140.</p><p id="p0049" num="0049">A liquid crystal display panel can be used as the display panel 110. However, the display panel 110 is not limited to the liquid crystal display panel and an organic electroluminescence display panel may be used. In the following description, it is assumed that a liquid crystal display panel is used as the display panel 110.<!-- EPO <DP n="11"> --></p><p id="p0050" num="0050">The gate driver 120, the data driver 130, and the timing controller 140 may be constituted by individual IC chips or may be constituted by a single IC chip. On the other hand, the gate driver 120 may be integrated on a lower substrate (TFT array substrate) of the display panel 110 in an amorphous silicon gate (ASG) manner or a gate-in-panel manner.</p><p id="p0051" num="0051">The display panel 110 includes an upper substrate (color filter array substrate), a lower substrate (TFT array substrate), and a liquid crystal layer interposed between the upper substrate and the lower substrate.</p><p id="p0052" num="0052">R, G, B color filters for converting light incident from sub-pixels into color light to display a color image are formed on the upper substrate. Plural gate lines and plural data lines are formed to cross each other on the lower substrate, whereby plural sub-pixels are defined.</p><p id="p0053" num="0053">Plural pixels are arranged in a matrix shape and each pixel includes three sub-pixels (RGB) or four sub-pixels (RGBW). TFTs as switching elements, storage capacitors, pixel electrodes, and common electrodes are formed on the lower substrate.</p><p id="p0054" num="0054">Alignment of liquid crystal is adjusted by an electric field based on a data voltage of a pixel electrode and a common voltage Vcom supplied to the common electrode. In this way, transmittance of light emitted from a backlight unit is adjusted using the alignment of the liquid crystal to display an image.</p><p id="p0055" num="0055"><figref idrefs="f0003">FIG. 5A</figref> is a diagram illustrating an optical touch pen of the optical touch display device according to the embodiment of the invention.</p><p id="p0056" num="0056">Referring to <figref idrefs="f0002 f0003">FIGS. 3 to 5A</figref>, an optical touch pen 200 includes an optical unit 210, a battery 220, and a transmission unit 230. The optical touch pen 200 is a portable unit and thus is supplied with driving power from the battery 220 built therein.</p><p id="p0057" num="0057">The optical unit 210 is constituted by an optical camera including a charge coupled device (CCD) sensor or a CMOS image sensor (CID). When the optical touch pen<!-- EPO <DP n="12"> --> 200 approaches or touches the display panel 110, map information (such as color information, gray information, pattern information, or image information) of an image map displayed on the display panel 110 is recognized by the optical unit 210.</p><p id="p0058" num="0058">The map information of the image map recognized by the optical unit 210 is input to the transmission unit 230. The transmission unit 230 transmits the map information of the image map to the position detector 300 in a wireless communication manner.</p><p id="p0059" num="0059">The position detector 300 detects a position approached or touched by the optical touch pen 200 on the display panel 110 based on the map information received from the transmission unit 230 of the optical touch pen 200.</p><p id="p0060" num="0060">A color map of the image map is generated by combining plural color patterns, and the color patterns have different colors. That is, each color pattern has unique color information and positions of the color patterns are set in advance on the color map.</p><p id="p0061" num="0061">The position detector 300 includes a lookup table in which position information of the map patterns on the image map is stored. For example, position information of the color patterns on the color map is provided in the form of a lookup table. The color information in the lookup table corresponding to the color information received by the optical touch pen 200 is checked.</p><p id="p0062" num="0062">By checking the position information of the color area detected by the optical touch pen 200, it is possible to detect the position of the color recognized by the optical touch pen 200 on the color map. That is, it is possible to detect a position approached or touched by the optical touch pen 200 on the display panel 110. Thereafter, the position detector 300 transmits the detected position information to the display device 100 in a wireless communication manner.<!-- EPO <DP n="13"> --></p><p id="p0063" num="0063">The display device 100 displays a part corresponding to the position information on the display panel 110 based on the position information received from the position detector 300. For example, a part corresponding to the position information is displayed as a mouse point on the display panel 110.</p><p id="p0064" num="0064">For this purpose, the timing controller 140 generates position image data corresponding to the position information, adds the position image data corresponding to the position information to display image data to be displayed on the screen, and transmits the resultant to the data driver 130.</p><p id="p0065" num="0065">The data driver 130 converts the image data, in which the display image data and the position image data are combined, into an analog data voltage and supplies the analog data voltage to the plural data lines formed on the display panel 110 to display an image on the screen.</p><p id="p0066" num="0066">On the other hand, the timing controller 140 generates image map image data based on the image map and supplies the generated image map image data to the data driver 130.</p><p id="p0067" num="0067">The display image data for displaying an image on the screen and the image map image data for displaying the image map on the screen can alternately be generated for each frame and can be supplied to the data driver 130.</p><p id="p0068" num="0068">For example, the display image data for displaying an image on the screen and the image map image data for displaying the image map on the screen may be alternately generated for each 1/2 frame and may be supplied to the data driver 130.</p><p id="p0069" num="0069">For example, the display image data for displaying an image on the screen may be supplied to the data driver 130 during two or four frames and then the image map image data for displaying the image map on the screen may be supplied thereto during one frame.<!-- EPO <DP n="14"> --></p><p id="p0070" num="0070">The position detector 300 is described above as an independent unit, which is only one of various embodiments of the invention.</p><p id="p0071" num="0071">As described above, the invention proposes various types of image maps. The color map in which coordinates are constituted by plural colors, the gray map in which coordinates are constituted by gray scales of an image, a pattern map in which coordinates are constituted by predetermined patterns, and a method of generating an image map using a display image itself in which position information is included in the source image data. The color map, the gray map, and the pattern map are displayed alternately along with a source image. On the other hand, when the source image data includes position information, the source image and the image map are not distinguished and an image including position information is displayed in one frame. The specific configuration of the image map will be described later with reference to <figref idrefs="f0005 f0006 f0007 f0008 f0009 f0010 f0011 f0012 f0013 f0014 f0015 f0016">FIGS. 8 to 21</figref>.</p><p id="p0072" num="0072"><figref idrefs="f0004">FIG. 6</figref> is a diagram schematically illustrating an optical touch display device according to another embodiment of the invention. <figref idrefs="f0004">FIG. 7</figref> is a diagram illustrating a display panel illustrated in <figref idrefs="f0004">FIG. 6</figref>.</p><p id="p0073" num="0073">In the optical touch display device according to another embodiment of the invention, the position detector 300 can be built in the display device 100.</p><p id="p0074" num="0074">When the display panel 110 is approached or touched by the optical touch pen 200, information (color information) of the image map displayed on the display panel 110 is recognized using the optical unit 210. In the following description, it is assumed that the color map is used as the image map. The color information of the color map recognized by the optical unit 210 is input to the transmission unit 230. The transmission unit 230 transmits the color information (or color information of each block when the screen is segmented into plural blocks) of each pixel included in the color map to the position detector 300 of the display device 100 in a wireless communication manner.<!-- EPO <DP n="15"> --></p><p id="p0075" num="0075">The position detector 300 built in the display device 100 detects a position approached or touched by the optical touch pen 200 on the display panel 110 based on the color information received from the transmission unit 230 of the optical touch pen 200.</p><p id="p0076" num="0076"><figref idrefs="f0003">FIG. 5B</figref> is a diagram illustrating an optical touch pen of the optical touch display device according to another embodiment of the invention. For example, referring to <figref idrefs="f0003">FIG. 5B</figref>, the position detector 300 may be built in the optical touch pen 200.</p><p id="p0077" num="0077">The position detector 300 built in the optical touch pen 200 detects a position approached or touched by the optical touch pen 200 on the display panel 110 based on the detected color information. The detected position information is transmitted to the display device 100 in a wireless communication manner.</p><p id="p0078" num="0078">The processes after the optical touch pen 200 detects the position approached or touched on the screen are equal or similar to those described above with reference to <figref idrefs="f0002 f0003">FIGS. 3 to 5A</figref>.</p><p id="p0079" num="0079">A specific embodiment for achieving touch sensing using a color map will be described below.</p><p id="p0080" num="0080"><figref idrefs="f0005">FIG. 8</figref> is a diagram illustrating a state in which a display image and an image map are alternately displayed. <figref idrefs="f0006">FIG. 9</figref> is a diagram illustrating a method of preventing distortion of a display image due to a color map.</p><p id="p0081" num="0081">Referring to <figref idrefs="f0005">FIGS. 8</figref> and <figref idrefs="f0006">9</figref>, in alternately displaying a display image to be displayed and a color map on the screen of the display device, the display image and the color map can alternately be displayed for each frame.</p><p id="p0082" num="0082">However, the invention is not limited to this example, but the display image and the color map may alternately be displayed for each 1/2 frame in alternately displaying the display image and the color map. For example, the display image may be displayed during two to four frames and then the color map may be displayed during one frame.<!-- EPO <DP n="16"> --></p><p id="p0083" num="0083">Since the color map has independent colors regardless of the display image, interference occurs in the display image due to the color map and distortion may occur in the image actually displayed on the screen.</p><p id="p0084" num="0084">In the invention, in order to prevent the distortion of the display image due to the color map, the source image data is not displayed without any change, but an image corrected by reflecting the interference due to the color map in the source image is displayed. That is, the display image in which the interference due to the color map has been corrected is displayed.</p><p id="p0085" num="0085">For this purpose, the timing controller 140 corrects the source image data of the sub-pixels based on the generated color map data. The image data of a sub-pixel of which luminance increases due to the color map data is corrected to decrease in luminance, and the image data of a sub-pixel of which luminance decreases is corrected to increase in luminance. In addition to the luminance, the color components of the sub-pixels are corrected based on the color map data. Accordingly, even when a color map frame is inserted between the frames of the display image, distortion (flicker and color break-up) does not occur in the image actually displayed on the screen.</p><p id="p0086" num="0086">For example, the source image data of the pixels can be corrected such that a luminance difference between the display image and the color map is equal to or less than 10%.</p><p id="p0087" num="0087">For example, the color map can be generated such that a luminance difference between the display image and the color map is equal to or less than 10%. That is, in the step of generating a color map, the color map can be generated based on the display image such that a luminance difference from the display image is equal to or less than 10%. Accordingly, even when a color map frame is inserted between the frames of the display<!-- EPO <DP n="17"> --> image, distortion (flicker and color break-up) does not occur in the image actually displayed on the screen.</p><p id="p0088" num="0088"><figref idrefs="f0006">FIG. 10</figref> is a diagram illustrating a color map. <figref idrefs="f0007">FIG. 11</figref> is a diagram illustrating a method of reducing interference between color patterns constituting a color map.</p><p id="p0089" num="0089">Referring to <figref idrefs="f0006">FIGS. 10</figref> and <figref idrefs="f0007">11</figref>, when the display device displays an image with a resolution of full-HD class (1920×1080) and one color pattern is constituted by 10×10 pixels, a color map having total 20,736 color patterns by 192×108 combinations. That is, the screen can be segmented into 20,736 touch blocks to detect a touched position.</p><p id="p0090" num="0090">Here, 20,736 different colors are required to distinguish the color patterns and a color map having 20,736 color patterns using plural colors (for example, two or three colors) can be constituted in a two-dimensional space.</p><p id="p0091" num="0091">When two colors of neighboring wavelength bands among red, green, and blue colors are used, mutual interference may occur. Accordingly, a color map is generated using colors of wavelength bands not causing mutual interference.</p><p id="p0092" num="0092">For example, when blue and green are used, wavelength bands overlapping each other may exist. When green and red are used, wavelength bands overlapping each other may also exist. In this way, when the wavelength bands of two colors overlap in this way, position information based on independent colors cannot be generated and thus a color map should be generated using two colors of which the wavelength bands do not overlap each other. In the invention, for example, a color map having 20,736 color patterns is generated using two colors of blue and red.</p><p id="p0093" num="0093"><figref idrefs="f0008">FIG. 12</figref> is a diagram illustrating an example in which a color map is generated.</p><p id="p0094" num="0094">Referring to <figref idrefs="f0008">FIG. 12</figref>, two colors are rendered in a two-dimensional space to generate a color map. At this time, one color area (touch block) is set to have a constant<!-- EPO <DP n="18"> --> block size (for example, 10×10 pixels). The entire color areas are segmented in the form of tiles (area segmentation) to generate a color map having 20,736 independent color areas.</p><p id="p0095" num="0095">Two colors are rendered in a two-dimensional space to generate a color map using an orthogonal coordinate system. For example, three colors may be rendered in a two-dimensional space to generate a color map using Legendre polynomials.</p><p id="p0096" num="0096">However, the invention is not limited to this example, but a color map may be generated using gray coordinates instead of generating a color map using plural colors.</p><p id="p0097" num="0097">The independent color areas, that is, the color patterns, can be labelled to distinguish position information of the color patterns. Regarding the labels assigned to the color patterns, 1 to 20,736 may be sequentially assigned to the first color pattern to the final color pattern to give position information to the color patterns.</p><p id="p0098" num="0098"><figref idrefs="f0009">FIG. 13</figref> is a diagram illustrating another example in which a color map is generated.</p><p id="p0099" num="0099">Referring to <figref idrefs="f0009">FIG. 13</figref>, two colors are rendered in a two-dimensional space to generate a color map. At this time, one color area (touch block) is set to have a constant block size (10×10 pixels). The entire color areas are segmented in the form of tiles (area segmentation) to generate a color map having 20,736 independent color areas.</p><p id="p0100" num="0100">The independent color areas, that is, the color patterns, are labelled. Thereafter, the labeled color patterns are shuffled in a random manner to rearrange the color patterns. The rearranged color patterns are uniquely labeled and thus position information of the color patterns can be distinguished from each other. When the color patterns constituting the color map are randomly rearranged, it is possible to reduce the distortion of a display image due to the color map.<!-- EPO <DP n="19"> --></p><p id="p0101" num="0101"><figref idrefs="f0010">FIG. 14</figref> is a diagram illustrating another example in which a gray map is generated. Referring to <figref idrefs="f0010">FIG. 14</figref>, position information can be expressed by gray scales without using plural colors.</p><p id="p0102" num="0102">Specifically, gray patterns having different gray scales are rendered in a two-dimensional space to generate a gray map. At this time, one gray pattern (touch block) is set to have a constant block size (10×10 pixels). The entire gray patterns are segmented in the form of tiles (area segmentation) to generate a gray map having a predetermined number of independent gray patterns.</p><p id="p0103" num="0103">The independent gray patterns are labelled. Accordingly, the position information of the gray patterns can be distinguished. For example, regarding the labels assigned to the gray patterns, 1 to 20,736 may be sequentially assigned to the first gray pattern to the final gray pattern to give position information to the gray patterns.</p><p id="p0104" num="0104"><figref idrefs="f0011">FIG. 15</figref> is a diagram illustrating another example in which a pattern map is generated. <figref idrefs="f0012">FIG. 16</figref> is a diagram illustrating a state in which a display image and a pattern map are alternately displayed.</p><p id="p0105" num="0105">Referring to <figref idrefs="f0011">FIGS. 15</figref> and <figref idrefs="f0012">16</figref>, different shapes of patterns are dispersed in a two-dimensional space to generate a pattern map. The independent pattern areas can be labeled to distinguish the position information of the pattern areas. The first pattern area and the final pattern area are sequentially labeled to give position information to the respective pattern areas.</p><p id="p0106" num="0106">Here, a pattern map is independent of a display image. It is possible to display position information of a screen by generating a pattern map using patterns with sizes (for example, 100 <i>µ</i>m<sup>2</sup>) which are not recognized with a viewer's eyes. It is possible to detect the position information of a position touched by a pen by inserting a special pattern map between display images in this way.<!-- EPO <DP n="20"> --></p><p id="p0107" num="0107">In alternately displaying a display image to be displayed and a pattern map on the screen of the display device, the display image and the pattern map can alternately be displayed for each frame.</p><p id="p0108" num="0108">However, the invention is not limited to this example, but the display image and the pattern map may alternately be displayed for each 1/2 frame in alternately displaying the display image and the pattern map. For example, the display image may be displayed during two to four frames and then the pattern map may be displayed during one frame.</p><p id="p0109" num="0109"><figref idrefs="f0012">FIG. 17</figref> is a diagram illustrating a method of preventing distortion of a display image due to a pattern map.</p><p id="p0110" num="0110">Referring to <figref idrefs="f0012">FIG. 17</figref>, in order to prevent the distortion of the display image due to the pattern map, the source image data is not displayed without any change, but an image corrected by reflecting the interference due to the pattern map in the source image is displayed. That is, the display image in which the interference due to the color map has been corrected is displayed.</p><p id="p0111" num="0111">For this purpose, the timing controller 140 corrects the source image data of the sub-pixels based on the generated pattern map data. The image data of a sub-pixel of which luminance increases due to the pattern map data is corrected to decrease in luminance, and the image data of a sub-pixel of which luminance decreases is corrected to increase in luminance. In addition to the luminance, the color components of the sub-pixels can be corrected based on the pattern map data.</p><p id="p0112" num="0112">Accordingly, even when a pattern map frame is inserted between the display image frames, distortion (flicker and color break-up) does not occur in the image actually displayed on the screen.</p><p id="p0113" num="0113">For example, the source image data of the pixels can be corrected such that a luminance difference between the display image and the pattern map is equal to or less than<!-- EPO <DP n="21"> --> 10%. For example, the pattern map can be generated such that a luminance difference between the display image and the pattern map is equal to or less than 10%. Accordingly, even when a pattern map is inserted between the display images, distortion (flicker and color break-up) does not occur in the image actually displayed on the screen.</p><p id="p0114" num="0114"><figref idrefs="f0013">FIGS. 18</figref> and <figref idrefs="f0014">19</figref> are diagrams illustrating a method of driving the optical touch display device according to the embodiment of the invention. <figref idrefs="f0013">FIG. 18</figref> illustrates driving of the display device for touch sensing using an image map. <figref idrefs="f0014">FIG. 19</figref> illustrates driving of the optical touch pen.</p><p id="p0115" num="0115">Referring to <figref idrefs="f0013">FIGS. 18</figref> and <figref idrefs="f0014">19</figref>, it is first checked whether a touch function is used (S10). When a touch function is not used, an image map for touch sensing is not generated and an image is displayed on the display panel using an input source image (S100).</p><p id="p0116" num="0116">On the other hand, when a touch function is used, the timing controller generates an image map (S20). Here, the color map illustrated in <figref idrefs="f0008">FIGS. 12</figref> and <figref idrefs="f0009">13</figref> may be generated as the image map. When a color map is used as the image map, the color map can be generated by rendering two colors in a two-dimensional space and sequentially labels plural color areas as illustrated in <figref idrefs="f0008">FIG. 12</figref>. For example, when a color map is used as an image map, the color map can be generated by rendering two colors in a two-dimensional space, labeling plural color areas, and shuffling the labeled color areas in a random manner.</p><p id="p0117" num="0117">The gray map illustrated in <figref idrefs="f0010">FIG. 14</figref> may be used as the image map.</p><p id="p0118" num="0118">The pattern map illustrated in <figref idrefs="f0012">FIG. 17</figref> may be used as the image map.</p><p id="p0119" num="0119">Subsequently, source image data input from the outside is arranged for each frame (S30).</p><p id="p0120" num="0120">Thereafter, in order to prevent distortion of a display image due to the image map, the image data is corrected by subtracting image data of the image map from the source image data (S40). That is, the image data to be displayed on the screen is corrected.<!-- EPO <DP n="22"> --> That is, corrected image data is generated by subtracting the image data of the image map from the source image data of the sub-pixels.</p><p id="p0121" num="0121">Thereafter, the corrected image data and the image data of the image map are alternately output (S50).</p><p id="p0122" num="0122">Then, the display image and the image map are alternately displayed on the screen of the display panel (S60). That is, the display image based on the corrected image data and the image of the image map are alternately displayed.</p><p id="p0123" num="0123">Here, the display image and the image map can be alternately displayed for each frame or for each 1/2 frame. However, the invention is not limited to these examples, but the display image may be displayed during two to four frames and then the image map may be displayed during one frame.</p><p id="p0124" num="0124">Thereafter, as illustrated in <figref idrefs="f0014">FIG. 19</figref>, the use of the touch function is transmitted to the display device using the optical touch pen (S70).</p><p id="p0125" num="0125">Then, map information (such as color information, gray information, or pattern information) of the image map is sensed using the optical touch pen (S72).</p><p id="p0126" num="0126">When the optical touch pen approaches or touches the display panel, map information (such as color information, gray information, or pattern information) of the image map displayed on the display panel is recognized by the optical unit.</p><p id="p0127" num="0127">Then, the map information (such as color information, gray information, or pattern information) of the image map of the image map recognized by the optical unit 210 is transmitted to the position detector located in the outside via the transmission unit (S74).</p><p id="p0128" num="0128">For example, as illustrated in <figref idrefs="f0003">FIG. 5B</figref>, when the position detector 300 is disposed in the optical touch pen, map information in a lookup table corresponding to the map information of the color area, the gray area, or the pattern area is checked using the<!-- EPO <DP n="23"> --> lookup table on which the color area, the gray are, or the pattern area on the image map is recorded.</p><p id="p0129" num="0129">Thereafter, the position information of the corresponding map information (such as color information, gray information, or pattern information) of the image map is detected from the lookup table.</p><p id="p0130" num="0130">Then, the detected position information, that is, the position information of the position touched by the touch pen 200, is transmitted to the display device (S74).</p><p id="p0131" num="0131">Subsequently, referred to <figref idrefs="f0013">FIG. 18</figref> again, the position information of the image map is received by the display device (S80).</p><p id="p0132" num="0132">Thereafter, the position touched by the optical touch pen 200 is displayed on the screen based on the received position information (S90). That is, the display device 100 displays a part corresponding to the position information on the display panel 110 based on the position information received from the position detector 300.</p><p id="p0133" num="0133">For example, a mouse point is displayed at the position touched by the optical touch pen 200. For this purpose, the timing controller 140 generates position image data corresponding to the position information. In order to display the touched position on the screen, position image data corresponding to the position information is added to the image data and the resultant is transmitted to the data driver 130.</p><p id="p0134" num="0134">The data driver 130 converts image data including the position information of the position touched by the optical touch pen 200 into an analog data voltage and supplies the sub-pixels. Accordingly, it is possible to display a part touched by the optical touch pen 200 on the screen.</p><p id="p0135" num="0135"><figref idrefs="f0015">FIG. 20</figref> is a diagram illustrating an example in which position information is generated using a display image.<!-- EPO <DP n="24"> --></p><p id="p0136" num="0136">Referring to <figref idrefs="f0015">FIG. 20</figref>, an image is displayed and a touch is detected by including position information in source image data is displayed.</p><p id="p0137" num="0137">For this purpose, the sub-pixels are uniquely labeled. At this time coordinate values for touch sensing are mapped onto the labels. That is, a coordinate touched by the optical touch pen 200 can be detected using the position information matched with the source image data of the sub-pixels.</p><p id="p0138" num="0138">When the source image data of plural sub-pixels are the same as the analysis result of the source image data, the source image data of the plural sub-pixels are changed and all the sub-pixels are made to have unique position information using the changed image data.</p><p id="p0139" num="0139">When the entire screen is sky-blue, the source image data of the sub-pixels are changed to express 20,736 different sky-blue colors. Thereafter, the position information of the sub-pixels are mapped such that all the sub-pixels have unique position information.</p><p id="p0140" num="0140">The source image data of the sub-pixels are changed such that changes in color and luminance of the sub-pixels are the minimum. The image data of the sub-pixels can be corrected such that a luminance difference from the source image data of the sub-pixels is equal to or less than 10%. The image data of the sub-pixels can be corrected such that a color difference from the source image data of the sub-pixels is equal to or less than 10%.</p><p id="p0141" num="0141">For example, when the source image data of two sub-pixels are the same, the two sub-pixels can have unique position information by changing the source image data of one sub-pixel. Here, the color or luminance of the second sub-pixel can be changed to be different from that of the first sub-pixel among the two sub-pixels.</p><p id="p0142" num="0142">For example, when the source image data of three sub-pixels are the same, the three sub-pixels can have unique position information by changing the source image data<!-- EPO <DP n="25"> --> of two sub-pixels. Here, the color of the second sub-pixel can be changed to be different from that of the first sub-pixel among the three sub-pixels. The luminance of the third sub-pixel can be changed to be different from that of the first sub-pixel.</p><p id="p0143" num="0143">On the other hand, the source image data is changed for each sub-pixel, but the invention is not limited to this configuration and the source image data may be changed for each pixel.</p><p id="p0144" num="0144"><figref idrefs="f0016">FIG. 21</figref> is a diagram illustrating a method of preventing distortion of an image when position information is included in source image data.</p><p id="p0145" num="0145">Referring to <figref idrefs="f0016">FIG. 21</figref>, in order to reduce image distortion when position information is included in the source image data to form an image map using a display image, the image data of the sub-pixels can be changed such that two neighboring frames have a compensatory relationship.</p><p id="p0146" num="0146">For example, the source image data of the sub-pixels can be changed such that the first frame and the second frame compensate for the image distortion. The source image data of the sub-pixels can be changed such that the third frame and the fourth frame can mutually compensate for the image distortion. However, the invention is not limited to this example, but the source image data of the sub-pixels can be changed such three or more frames can mutually compensate for image distortion.</p><p id="p0147" num="0147">In the optical touch display device and the driving method thereof according to the embodiment of the invention, an image map having plural pieces of independent position information (coordinate information) is generated, and the image map is alternately inserted between display images and is displayed. It is possible to achieve touch sensing without constituting a physical touch screen in the display device by detecting position information of an image map using an optical touch pen.<!-- EPO <DP n="26"> --></p><p id="p0148" num="0148">A touched position of the optical touch pen can be displayed based on the position information.</p><p id="p0149" num="0149">The image map includes a color map in which coordinates constituted by plural colors, a gray map in which coordinates are constituted by gray-scales, or a pattern map in which coordinates are constituted by predetermined patterns.</p><p id="p0150" num="0150">Plural colors are rendered in a two-dimensional space to generate the color map, and the display image and the color map are alternately displayed.</p><p id="p0151" num="0151">The color map is generated using two colors of blue and red.</p><p id="p0152" num="0152">A screen (entire sub-pixels) is segmented in the form of constant tiles to form plural color areas, and each of the color areas has unique position information.</p><p id="p0153" num="0153">The plural color areas are sequentially labeled in labeling the color areas.</p><p id="p0154" num="0154">The plural labeled color areas are randomly shuffled and rearranged.</p><p id="p0155" num="0155">Corrected image data is generated by subtracting the image data of the image map from the source image data of the sub-pixels and the display image based on the corrected image data and the image map are alternately displayed.</p><p id="p0156" num="0156">Gray patterns having different gray scales are rendered in a two-dimensional space to generate a gray map, and the display image and the gray pam are alternately displayed.</p><p id="p0157" num="0157">A screen is segmented in the form of constant tiles to form plural gray areas, and each of the gray areas has unique position information.</p><p id="p0158" num="0158">Patterns having different shapes are dispersed in a two-dimensional space to generate a pattern map, and the display image and the pattern map are alternately displayed.</p><p id="p0159" num="0159">A screen is segmented in the form of constant tiles to form plural pattern areas, and each of the pattern areas has unique position information.<!-- EPO <DP n="27"> --></p><p id="p0160" num="0160">Position information for touch sensing is mapped onto image data supplied to sub-pixels, and the coordinate touched by the optical touch pen is detected using the position information matched with the image data of the sub-pixels.</p><p id="p0161" num="0161">When the source image data of plural sub-pixels are the same as the analysis result of the source image data supplied to the sub-pixels, the source image data of one or more sub-pixels is changed.</p><p id="p0162" num="0162">The source image data of each sub-pixel is changed such that plural neighboring frames have a compensatory relationship.</p><p id="p0163" num="0163">The position detector includes a lookup table in which position information of the color areas on the image map is described, and detects the position approached or touched by the optical touch pen on the screen of the display device by checking the position information based on the color information.</p><p id="p0164" num="0164">The image map is generated such that the luminance difference from the display image is equal to or less than 10%.</p><p id="p0165" num="0165">The method of driving an optical touch display device according to the embodiment of the invention includes: arranging source image data of sub-pixels for each frame and generating an image map for touch sensing; generating corrected image data by subtracting image data of the image map from the source image data; alternately displaying an image based on the corrected image data and the image map; and sensing map information of a specific position on the image map using an optical touch pen having an optical camera built therein.</p><p id="p0166" num="0166">The method of driving an optical touch display device further includes sensing position information of a position touched by the optical touch pen on the screen of the display device based on the map information.<!-- EPO <DP n="28"> --></p><p id="p0167" num="0167">A touched position is displayed on the display screen based on the position information.</p><p id="p0168" num="0168">The method of driving an optical touch display device according to the embodiment of the invention includes: mapping position information for touch sensing onto image data supplied to sub-pixels; sensing map information of a specific position on the image map using an optical touch pen having an optical camera built therein; and detecting a coordinate touched by the optical touch pen using the position information matched with the map information.</p><p id="p0169" num="0169">The method of driving an optical touch display device further includes analyzing source image data supplied to the sub-pixels and changing the source image data of one or more sub-pixels when the source image data of two or more sub-pixels are the same.</p><p id="p0170" num="0170">The source image data of the sub-pixels are changed such that plural neighboring frames have a compensatory relationship.</p><p id="p0171" num="0171">In the optical touch display device and the driving method thereof according to the embodiment of the invention, it is possible to enable displaying of an image and sensing of a touch with high-speed driving using the above-mentioned image map.</p><p id="p0172" num="0172">In the optical touch display device and the driving method thereof according to the embodiment of the invention, it is possible to enable sensing of a large-area touch and sensing of a multi-touch using the above-mentioned image map.</p><p id="p0173" num="0173">Since physical touch electrodes are not formed and thus factors such as a decrease in touch sensing performance due to parasitic capacitance are removed in a capacitive type, it is possible to improve touch sensing performance.</p><p id="p0174" num="0174">It will be understood by those skilled in the art that the invention can be modified in various forms without changing the technical spirit or essential features thereof.<!-- EPO <DP n="29"> --></p><p id="p0175" num="0175">Accordingly, it should be understood that the above-mentioned embodiments are exemplary in all terms and are not restrictive. The scope of the invention is defined not by the above-mentioned detailed description, but by the appended claims. It should be analyzed that all changes and modifications derived from the meanings and the scope of the claims and equivalent concepts thereof are included in the scope of the invention.</p></description><claims mxw-id="PCLM90459535" lang="EN" load-source="patent-office"><!-- EPO <DP n="30"> --><claim id="c-en-0001" num="0001"><claim-text>An optical touch display device comprising:
<claim-text>a display device configured to display a display image based on input source image data and an image map for touch sensing;</claim-text>
<claim-text>an optical touch pen configured to detect map information of the image map displayed on the display device; and</claim-text>
<claim-text>a position detector configured to detect position information on a screen based on the map information.</claim-text></claim-text></claim><claim id="c-en-0002" num="0002"><claim-text>The optical touch display device according to claim 1, wherein a touched position of the optical touch pen is displayed based on the position information.</claim-text></claim><claim id="c-en-0003" num="0003"><claim-text>The optical touch display device according to claim 1 or 2, wherein corrected image data is generated by subtracting image data of the image map from the source image data of each sub-pixel, and<br/>
wherein the display image based on the corrected image data and the image map are alternately displayed.</claim-text></claim><claim id="c-en-0004" num="0004"><claim-text>The optical touch display device according to any one of claims 1 to 3, wherein the image map includes a color map in which coordinates are constituted by a plurality of colors, a gray map in which coordinates are constituted by gray scales, or a pattern map in which coordinates are constituted by predetermined patterns.<!-- EPO <DP n="31"> --></claim-text></claim><claim id="c-en-0005" num="0005"><claim-text>The optical touch display device according to claim 4, wherein the color map is generated by rendering the plurality of colors in a two-dimensional space, and<br/>
wherein the display image and the color map are alternately displayed.</claim-text></claim><claim id="c-en-0006" num="0006"><claim-text>The optical touch display device according to claim 5, wherein a screen is segmented in the form of predetermined tiles to form a plurality of color areas, and<br/>
wherein each of the plurality of color areas has specific position information.</claim-text></claim><claim id="c-en-0007" num="0007"><claim-text>The optical touch display device according to claim 4, wherein the gray map is generated by rendering gray patterns having different gray scales in a two-dimensional space, and<br/>
wherein the display image and the gray map are alternately displayed.</claim-text></claim><claim id="c-en-0008" num="0008"><claim-text>The optical touch display device according to claim 7, wherein a screen is segmented in the form of predetermined tiles to form a plurality of gray areas, and<br/>
wherein each of the plurality of gray areas has specific position information.</claim-text></claim><claim id="c-en-0009" num="0009"><claim-text>The optical touch display device according to claim 4, wherein the pattern map is generated by dispersing different patterns in a two-dimensional space, and<br/>
wherein the display image and the pattern map are alternately displayed.</claim-text></claim><claim id="c-en-0010" num="0010"><claim-text>The optical touch display device according to claim 9, wherein a screen is segmented in the form of predetermined tiles to form a plurality of pattern areas, and<br/>
wherein each of the plurality of pattern areas has specific position information.<!-- EPO <DP n="32"> --></claim-text></claim><claim id="c-en-0011" num="0011"><claim-text>The optical touch display device according to any one of claims 1 to 10, wherein position information for touch sensing is mapped onto the image data supplied to each sub-pixel, and<br/>
wherein a coordinate which is touched by the optical touch pen is detected using the position information mapped onto the image data of the sub-pixels.</claim-text></claim><claim id="c-en-0012" num="0012"><claim-text>The optical touch display device according to any one of claims 1 to 11, wherein the position detector includes a lookup table in which position information of the color areas on the image map is recorded, and detects a position approached or touched by the optical touch pen on the screen of the display device by checking the position information corresponding to the color areas.</claim-text></claim><claim id="c-en-0013" num="0013"><claim-text>A method of driving an optical touch display device, comprising:
<claim-text>mapping position information for touch sensing onto image data supplied to sub-pixels;</claim-text>
<claim-text>sensing map information of a specific position on an image map using an optical touch pen having an optical camera built therein; and</claim-text>
<claim-text>detecting a coordinate touched by the optical touch pen using the position information matched onto the map information.</claim-text></claim-text></claim><claim id="c-en-0014" num="0014"><claim-text>The method of driving an optical touch display device according to claim 13, further comprising:
<claim-text>analyzing source image data supplied to the sub-pixels; and</claim-text>
<claim-text>changing the source image data of one or more sub-pixels when the source image data of two or more sub-pixels are the same.</claim-text><!-- EPO <DP n="33"> --></claim-text></claim><claim id="c-en-0015" num="0015"><claim-text>The method of driving an optical touch display device according to claim 14, wherein the source image data is changed such that neighboring frames have a compensatory relationship.</claim-text></claim></claims><drawings mxw-id="PDW20422258" load-source="patent-office"><!-- EPO <DP n="34"> --><figure id="f0001" num="1,2"><img id="if0001" file="imgf0001.tif" wi="126" he="182" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="35"> --><figure id="f0002" num="3,4"><img id="if0002" file="imgf0002.tif" wi="126" he="182" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="36"> --><figure id="f0003" num="5A,5B"><img id="if0003" file="imgf0003.tif" wi="126" he="141" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="37"> --><figure id="f0004" num="6,7"><img id="if0004" file="imgf0004.tif" wi="126" he="183" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="38"> --><figure id="f0005" num="8"><img id="if0005" file="imgf0005.tif" wi="126" he="158" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="39"> --><figure id="f0006" num="9,10"><img id="if0006" file="imgf0006.tif" wi="108" he="135" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="40"> --><figure id="f0007" num="11"><img id="if0007" file="imgf0007.tif" wi="126" he="135" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="41"> --><figure id="f0008" num="12"><img id="if0008" file="imgf0008.tif" wi="83" he="120" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="42"> --><figure id="f0009" num="13"><img id="if0009" file="imgf0009.tif" wi="83" he="120" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="43"> --><figure id="f0010" num="14"><img id="if0010" file="imgf0010.tif" wi="83" he="120" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="44"> --><figure id="f0011" num="15"><img id="if0011" file="imgf0011.tif" wi="83" he="120" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="45"> --><figure id="f0012" num="16,17"><img id="if0012" file="imgf0012.tif" wi="124" he="178" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="46"> --><figure id="f0013" num="18"><img id="if0013" file="imgf0013.tif" wi="124" he="158" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="47"> --><figure id="f0014" num="19"><img id="if0014" file="imgf0014.tif" wi="100" he="111" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="48"> --><figure id="f0015" num="20"><img id="if0015" file="imgf0015.tif" wi="100" he="130" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="49"> --><figure id="f0016" num="21"><img id="if0016" file="imgf0016.tif" wi="109" he="108" img-content="drawing" img-format="tif"/></figure></drawings><search-report-data><doc-page id="srep0001" file="srep0001.tif" wi="161" he="233" type="tif"/><doc-page id="srep0002" file="srep0002.tif" wi="161" he="233" type="tif"/></search-report-data><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
