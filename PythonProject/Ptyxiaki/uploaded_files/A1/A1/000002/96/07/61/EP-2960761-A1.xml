<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2960761-A1" country="EP" doc-number="2960761" kind="A1" date="20151230" family-id="51368526" file-reference-id="283033" date-produced="20180824" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="160451516" ucid="EP-2960761-A1"><document-id><country>EP</country><doc-number>2960761</doc-number><kind>A1</kind><date>20151230</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-13875412-A" is-representative="YES"><document-id mxw-id="PAPP193866000" load-source="docdb" format="epo"><country>EP</country><doc-number>13875412</doc-number><kind>A</kind><date>20131223</date><lang>ZH</lang></document-id><document-id mxw-id="PAPP193866001" load-source="patent-office" format="original"><country>EP</country><doc-number>13875412.2</doc-number><date>20131223</date><lang>ZH</lang></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC162035565" ucid="CN-2013090207-W" linkage-type="W" load-source="docdb"><document-id format="epo"><country>CN</country><doc-number>2013090207</doc-number><kind>W</kind><date>20131223</date></document-id></priority-claim><priority-claim mxw-id="PPC162035155" ucid="CN-201310058995-A" load-source="docdb"><document-id format="epo"><country>CN</country><doc-number>201310058995</doc-number><kind>A</kind><date>20130225</date></document-id></priority-claim><priority-claim mxw-id="PPC162031972" ucid="CN-201310185771-A" load-source="docdb"><document-id format="epo"><country>CN</country><doc-number>201310185771</doc-number><kind>A</kind><date>20130517</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL-1951074025" load-source="docdb">G06F   3/048       20060101AFI20160412BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-1877534886" load-source="docdb" scheme="CPC">G06F   3/0237      20130101 LI20161112BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1877534887" load-source="docdb" scheme="CPC">G06F   3/04886     20130101 FI20161112BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1877534888" load-source="docdb" scheme="CPC">G06F   3/04883     20130101 LI20161112BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1877534889" load-source="docdb" scheme="CPC">G06F   3/04845     20130101 LI20161110BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1877534890" load-source="docdb" scheme="CPC">G06F   3/0482      20130101 LI20161110BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1877534891" load-source="docdb" scheme="CPC">G06F   3/04847     20130101 LI20161110BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT165546014" lang="DE" load-source="patent-office">VERFAHREN, SYSTEM UND VORRICHTUNG ZUR TEXTEINGABE IN AUFEINANDERFOLGENDEN FOLIEN</invention-title><invention-title mxw-id="PT165546015" lang="EN" load-source="patent-office">METHOD, SYSTEM AND DEVICE FOR INPUTTING TEXT BY CONSECUTIVE SLIDE</invention-title><invention-title mxw-id="PT165546016" lang="FR" load-source="patent-office">PROCÉDÉ, SYSTÈME ET DISPOSITIF POUR ENTRER DU TEXTE PAR DIAPOSITIVE CONSÉCUTIVE</invention-title></technical-data><parties><applicants><applicant mxw-id="PPAR1103323558" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>SHANGHAI CHULE COOTEK INFORMATION TECHNOLOGY CO LTD</last-name><address><country>CN</country></address></addressbook></applicant><applicant mxw-id="PPAR1103330327" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>SHANGHAI CHULE (COOTEK) INFORMATION TECHNOLOGY CO., LTD.</last-name></addressbook></applicant><applicant mxw-id="PPAR1101653583" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Shanghai Chule (Cootek) Information Technology Co., Ltd.</last-name><iid>101361132</iid><address><street>A2060, the 2nd Building No. 555, Dongchuan Road Minhuang District</street><city>Shanghai 200241</city><country>CN</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR1103329335" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>ZHANG KAN</last-name><address><country>CN</country></address></addressbook></inventor><inventor mxw-id="PPAR1103336398" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>ZHANG, KAN</last-name></addressbook></inventor><inventor mxw-id="PPAR1101654090" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>ZHANG, KAN</last-name><address><street>A2060 the 2nd Building No.555 Dongchuan Road Minhang District</street><city>Shanghai 200241</city><country>CN</country></address></addressbook></inventor><inventor mxw-id="PPAR1103323136" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>WANG JIALIANG</last-name><address><country>CN</country></address></addressbook></inventor><inventor mxw-id="PPAR1103326624" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>WANG, JIALIANG</last-name></addressbook></inventor><inventor mxw-id="PPAR1101653122" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>WANG, JIALIANG</last-name><address><street>A2060 the 2nd Building No.555 Dongchuan Road Minhang District</street><city>Shanghai 200241</city><country>CN</country></address></addressbook></inventor><inventor mxw-id="PPAR1103344984" load-source="docdb" sequence="3" format="epo"><addressbook><last-name>WU JINGSHEN</last-name><address><country>CN</country></address></addressbook></inventor><inventor mxw-id="PPAR1103309517" load-source="docdb" sequence="3" format="intermediate"><addressbook><last-name>WU, JINGSHEN</last-name></addressbook></inventor><inventor mxw-id="PPAR1101639871" load-source="patent-office" sequence="3" format="original"><addressbook><last-name>WU, JINGSHEN</last-name><address><street>A2060 the 2nd Building No.555 Dongchuan Road Minhang District</street><city>Shanghai 200241</city><country>CN</country></address></addressbook></inventor><inventor mxw-id="PPAR1103327097" load-source="docdb" sequence="4" format="epo"><addressbook><last-name>WANG HANXIONG</last-name><address><country>CN</country></address></addressbook></inventor><inventor mxw-id="PPAR1103314602" load-source="docdb" sequence="4" format="intermediate"><addressbook><last-name>WANG, Hanxiong</last-name></addressbook></inventor><inventor mxw-id="PPAR1101641371" load-source="patent-office" sequence="4" format="original"><addressbook><last-name>WANG, Hanxiong</last-name><address><street>A2060 the 2nd Building No.555 Dongchuan Road Minhang District</street><city>Shanghai 200241</city><country>CN</country></address></addressbook></inventor><inventor mxw-id="PPAR1103331313" load-source="docdb" sequence="5" format="epo"><addressbook><last-name>XIE HAICHAO</last-name><address><country>CN</country></address></addressbook></inventor><inventor mxw-id="PPAR1103306378" load-source="docdb" sequence="5" format="intermediate"><addressbook><last-name>XIE, Haichao</last-name></addressbook></inventor><inventor mxw-id="PPAR1101651751" load-source="patent-office" sequence="5" format="original"><addressbook><last-name>XIE, Haichao</last-name><address><street>A2060 the 2nd Building No.555 Dongchuan Road Minhang District</street><city>Shanghai 200241</city><country>CN</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR1101641707" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Kolster Oy Ab</last-name><iid>101363959</iid><address><street>Iso Roobertinkatu 23 PO Box 148</street><city>00121 Helsinki</city><country>FI</country></address></addressbook></agent></agents></parties><international-convention-data><pct-or-regional-filing-data ucid="CN-2013090207-W"><document-id><country>CN</country><doc-number>2013090207</doc-number><kind>W</kind><date>20131223</date><lang>ZH</lang></document-id></pct-or-regional-filing-data><pct-or-regional-publishing-data ucid="WO-2014127671-A1"><document-id><country>WO</country><doc-number>2014127671</doc-number><kind>A1</kind><date>20140828</date><lang>ZH</lang></document-id></pct-or-regional-publishing-data><designated-states><ep-contracting-states><country mxw-id="DS660688458" load-source="docdb">AL</country><country mxw-id="DS660783701" load-source="docdb">AT</country><country mxw-id="DS660688463" load-source="docdb">BE</country><country mxw-id="DS660685689" load-source="docdb">BG</country><country mxw-id="DS660692621" load-source="docdb">CH</country><country mxw-id="DS660688464" load-source="docdb">CY</country><country mxw-id="DS660606851" load-source="docdb">CZ</country><country mxw-id="DS660686223" load-source="docdb">DE</country><country mxw-id="DS660688465" load-source="docdb">DK</country><country mxw-id="DS660688466" load-source="docdb">EE</country><country mxw-id="DS660611038" load-source="docdb">ES</country><country mxw-id="DS660685690" load-source="docdb">FI</country><country mxw-id="DS660685695" load-source="docdb">FR</country><country mxw-id="DS660686224" load-source="docdb">GB</country><country mxw-id="DS660688515" load-source="docdb">GR</country><country mxw-id="DS660686225" load-source="docdb">HR</country><country mxw-id="DS660606852" load-source="docdb">HU</country><country mxw-id="DS660692622" load-source="docdb">IE</country><country mxw-id="DS660688516" load-source="docdb">IS</country><country mxw-id="DS660685696" load-source="docdb">IT</country><country mxw-id="DS660688517" load-source="docdb">LI</country><country mxw-id="DS660686226" load-source="docdb">LT</country><country mxw-id="DS660783702" load-source="docdb">LU</country><country mxw-id="DS660685697" load-source="docdb">LV</country><country mxw-id="DS660686243" load-source="docdb">MC</country><country mxw-id="DS660783703" load-source="docdb">MK</country><country mxw-id="DS660783704" load-source="docdb">MT</country><country mxw-id="DS660783705" load-source="docdb">NL</country><country mxw-id="DS660606853" load-source="docdb">NO</country><country mxw-id="DS660783706" load-source="docdb">PL</country><country mxw-id="DS660688518" load-source="docdb">PT</country><country mxw-id="DS660611527" load-source="docdb">RO</country><country mxw-id="DS660688523" load-source="docdb">RS</country><country mxw-id="DS660783707" load-source="docdb">SE</country><country mxw-id="DS660686245" load-source="docdb">SI</country><country mxw-id="DS660606854" load-source="docdb">SK</country><country mxw-id="DS660606859" load-source="docdb">SM</country><country mxw-id="DS660611047" load-source="docdb">TR</country></ep-contracting-states><ep-extended-states><ep-extended-state-data><country>BA</country></ep-extended-state-data><ep-extended-state-data><country>ME</country></ep-extended-state-data></ep-extended-states></designated-states></international-convention-data></bibliographic-data><abstract mxw-id="PA166479886" lang="EN" load-source="patent-office"><p id="pa01" num="0001">This invention relates to a method for continuous sliding gesture-based input text, comprising: detecting whether a continuous sliding gesture based input mode is triggered in response to an input of a user; detecting and recording a trajectory of a sliding gesture of a user on a touch-screen and inputting a corresponding word; and predicting a possible word based on a context and another input of the user and updating the layout of a keyboard according to at least one of the results of the prediction. The invention also relates to a system that implements the method, as well as a corresponding device. The method, system and device increase input efficiency and achieve smart prediction and smart arrangement of candidate words in an area of the keyboard.<img id="iaf01" file="imgaf001.tif" wi="78" he="68" img-content="drawing" img-format="tif"/></p></abstract><abstract mxw-id="PA166759698" lang="EN" source="EPO" load-source="docdb"><p>This invention relates to a method for continuous sliding gesture-based input text, comprising: detecting whether a continuous sliding gesture based input mode is triggered in response to an input of a user; detecting and recording a trajectory of a sliding gesture of a user on a touch-screen and inputting a corresponding word; and predicting a possible word based on a context and another input of the user and updating the layout of a keyboard according to at least one of the results of the prediction. The invention also relates to a system that implements the method, as well as a corresponding device. The method, system and device increase input efficiency and achieve smart prediction and smart arrangement of candidate words in an area of the keyboard.</p></abstract><description mxw-id="PDES98404587" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><heading id="h0001">TECHNICAL FIELD</heading><p id="p0001" num="0001">The present invention relates to information input to electronic devices and, in particular, to sliding gesture-based information input to touch-screen electronic devices. More specifically, the invention relates to methods, system and device for continuous sliding gesture-based text input.</p><heading id="h0002">BACKGROUND</heading><p id="p0002" num="0002">Referring to <figref idrefs="f0001">FIG. 1</figref>, a conventional touch-screen electronic device usually has a text area 110 that displays input text or a popup message and a keyboard area 120 allowing a use's text input. In addition, an area 130 which presents candidate words will also generally appear around keyboard area 120 during the user's input. In order to achieve an optimal balance between screen usage efficiency and the user's visual experience, area 130 is typically disposed on top of keyboard area 120 and is so configured that the candidate words are laterally arranged one by one. The conventional touch-screen input techniques allow for selection of only one word by a single input (defined hereinafter as a touch that a finger or an input instrument, such as a stylus, makes since it comes into contact with the screen until it leaves the screen). For example, in such techniques, a tapping or other motion is allowed to cause the input of a single word, and even with a conventional touch-screen keyboard which allows text input by sliding gestures, a sliding trajectory completed in one motion can only be parsed as one word. This leads to a great reduction in information input efficiency, increased operating complexity, and significant user inconveniences. Therefore, there is a great need in the field of information input to touch-screen electronic devices for enabling the input of a sequence of words or a complete sentence through a single input</p><heading id="h0003">SUMMARY</heading><p id="p0003" num="0003">The present invention addresses the above-described disadvantages of the prior art by presenting methods, system and device for continuous sliding gesture-based text input, which offer the benefits of a significant increase in input efficiency, allowing input of multiple successively consecutive words or even a whole sentence of text by a single continuous sliding gesture, capability of smart word prediction and arrangement, and flexible adaptation to various keyboard layouts, even including those defined by the user.</p><p id="p0004" num="0004">According to an aspect of embodiments of the present invention, there is provided a method for continuous sliding gesture-based text input, comprising: predicting a possible word based on a context and an input of a user; displaying at least one of the results of the prediction in a key area of a keyboard; and detecting and recording a trajectory of a sliding gesture of the user on a touch-screen, inputting a corresponding word and updating the layout of the keyboard.<!-- EPO <DP n="2"> --></p><p id="p0005" num="0005">According to an aspect of embodiments of the present invention, the prediction of the possible word includes one or a combination of: predicting a current possible word being input; predicting the current possible word when part, but not all, of its letters has been input by the user; predicting a related word of the current possible word; correcting an input of the user and predicting the current possible word based on the results of the correction; predicting one or more next words to be input by the user; and prediction based on one or more of word use frequencies, the user's input preference, language models, syntax rules, context and other relevant statistical information.</p><p id="p0006" num="0006">More specifically, predicting the one or more next words includes one or a combination of: when letters input by the user have come to constitute a complete word, predicting the one or more next words based on a default one of the results of the prediction of the current word; and when a user has input and selected a word, predicting the one or more next words based on the selected word.</p><p id="p0007" num="0007">According to an aspect of embodiments of the present invention, displaying the at least one of the results of the prediction in the key area of the keyboard includes: word processing according to system-predefined word display and arrangement rules, including, for example, one or more of: letter correspondence-based display; inter-word distance and word length-based display; touch point position and sliding gesture trajectory-based display; and word use frequency, user input preference, language models, syntax rules, context and other relevant statistical information-based display. Specifically, the letter correspondence-based display may include: first letter correspondence-based display, wherein the first letter comprises a first letter or a first phonetic alphabet; or correspondence to a next letter to be input, for example, a next letter or a next phonetic alphabet The inter-word distance and word length-based display may include: determining whether target display regions of at least two words are excessively close to each other and, if true, only displaying one of the at least two words with a highest priority level or adjusting the target display region of each other one of the at least two words with a lower priority level. The inter-word distance and word length-based display may include: determining whether a length of a word affects another word to be displayed at an adjacent target display region and, if true, only displaying one of the two words with a high priority level or adjusting the target display region of the other of the two words with a low priority level. The touch point position and sliding gesture trajectory-based display may include: determining whether a target display region of a word is to be blocked by a current touch point and, if true, not displaying the word or adjusting its target display region. The touch point position and sliding gesture trajectory-based display may include: determining whether target display regions of at least two words are to be overlapped or blocked by a trajectory of a current touch point and, if true, for each of the at least two words, further determining, according to their priority levels, whether to display it or adjust its target display region, such that it will not be overlapped or blocked by a possible subsequent extension of the trajectory.<!-- EPO <DP n="3"> --></p><p id="p0008" num="0008">According to an aspect of embodiments of the present invention, displaying the at least one of the results of the prediction in the key area of the keyboard may further include: displaying at least one of words that have been processed in the key area of the keyboard or in predetermined region(s) of associated key(s). The predetermined region may be located above, at the top left of, at the top right of, under, at the bottom left of, or at the bottom right of the associated key, or at any position that is spaced apart from the associated key by a distance not exceeding a system-predefined distance threshold. In particular, displaying the at least one of the words that have been processed in the key area of the keyboard may further include one or a combination of: displaying the at least one of the words also in a candidate-word area; displaying at least one of the results of the prediction of the current possible word in the candidate-word area or a user-defined input area and displaying each of at least one of the results of the prediction of the one or more next possible words in a predetermined region of an associated key; and updating displayed content in the key area of the keyboard in a real-time manner according to an input of the user.</p><p id="p0009" num="0009">According to an aspect of embodiments of the present invention, the method may further comprise providing the user with an indication in the form of a multimedia action, for example, one or a combination of a visual indication, an auditory indication and a vibration. The indication may be provided, for example, for indicating empty prediction results, or for indicating a word of which a related word is to be input, or for notify the input of a word, or for prompting the user to trigger the continuous sliding gesture-based input mode, or for notify that the continuous sliding gesture-based input mode has been triggered, or for indicating displayed predicted next possible words.</p><p id="p0010" num="0010">According to an aspect of embodiments of the present invention, the method may further comprise detecting whether the continuous sliding gesture based input mode is triggered in response to an input of a user.</p><p id="p0011" num="0011">According to an aspect of embodiments of the present invention, detecting and recording the user's sliding gesture trajectory on the touch-screen and inputting the corresponding word may include: determining whether the sliding gesture trajectory meets a system-predefined word selection criterion. The word selection criterion may include: a touch point being located in a system-predefined, associated effective region of the word, for example, a region where the word is displayed or a region spaced apart from the word by a distance not exceeding a system-predefined distance threshold. The word selection criterion may further include: selecting a word by a sliding gesture, for example, selection by a sliding gesture crossing the word from one side to another side, or selection of a related word of the word by the sliding gesture. In particular, the selection of the related word may include: making a sliding gesture from a region where the word is displayed to a predetermined region, for example, a region of a space key, the candidate-word area, or another designated region; displaying related words of the concerned word in vicinity of the predetermined region; and selecting a corresponding one of the related words based on a predetermined operation of<!-- EPO <DP n="4"> --> the user and replacing the word with the selected one of the related words. The word selection criterion may further include simultaneous multiple touch points.</p><p id="p0012" num="0012">According to an aspect of embodiments of the present invention, detecting and recording the user's sliding gesture trajectory on the touch-screen and inputting the corresponding word may include: inputting the word meeting the word selection criterion to a text area, for example, directly inputting the selected word around the location of a cursor in the text area, or in the user-defined input area.</p><p id="p0013" num="0013">According to an aspect of embodiments of the present invention, updating the keyboard layout may include one or a combination of: displaying predicted words in the key area of the keyboard according to a current touch point of the user; in the event of a change occurring in the current touch point, recalculating and rearranging target display regions of the predicted words; determining whether the number of obtained words to be displayed exceeds a maximum displayable word number; determining whether the words are located on a trajectory of a possible sliding gesture of the user and, if there is overlapping or blockage, only displaying one of the words with a highest priority level; determining whether a word to be displayed conflicts with words that have been displayed and displaying the predicted words according to the results of the determination; calculating associated effective regions of the words; determining whether the current touch point is located within the effective region of a word to be displayed; and processing a word unsuitable to be immediately displayed, for example, cancelling its display or rearranging it The rearrangement may include: incrementally moving an initial target display region of the word to other regions of an associated key of the word; and if the word becomes suitable to be displayed within a predetermined number of increments, displaying it in the key area, otherwise, cancelling its display.</p><p id="p0014" num="0014">According to an aspect of embodiments of the present invention, the continuous sliding gesture based input mode may be triggered by one or more of: a sliding gesture starting from the space key; a sliding gesture starting from an arbitrarily designated key; a sliding gesture starting from a sensitive point located away from the key area; a user-defined motion made around a displayed word; a predetermined motion made in an arbitrarily designated region; a predetermined action taken on a corresponding electronic device, for example, shaking it; and a sliding command input through other means, for example, voice input means, optical sensing input means, infrared sensing input means and pressure sensing input means. The user-defined motion may include one or a combination of: drawing a circle around the word, upward sliding, downward sliding, sliding to the left, sliding to the right, sliding along a predetermined direction from one side of the word to another side thereof, long pressing, drawing a predetermined pattern, and dragging the word to a predetermined region, for example, dragging the word the region of the space key. The predetermined motion may include one or a combination of: tapping, long pressing, drawing a predetermined pattern, and sliding along a predetermined direction, in a designated region. The designated region may include a region of the displayed word or a region spaced apart from<!-- EPO <DP n="5"> --> the displayed word by a designated distance. The designated region may be a round, square, or oval region. The predetermined action may include shaking the electronic device.</p><p id="p0015" num="0015">According to an aspect of embodiments of the present invention, the method may further include: input word cancellation, for example, cancellation of only an immediately previously input word, or a user-defined number of previously input words, or all previously input word, by a predetermined action, for example, making a sliding gesture from an area of the keyboard to the space key, or to a user-defined area, or beyond the keyboard.</p><p id="p0016" num="0016">According to an aspect of embodiments of the present invention, the continuous sliding gesture based input mode may be exited when the occurrence of a system-predefined exit triggering event is detected. The exit triggering event may include one or a combination of: the user terminating the touch, the user making a sliding gesture to a predetermined area, absence of a possible next word, and the user selecting a predetermined word.</p><p id="p0017" num="0017">According to an aspect of embodiments of the present invention, the method may further include performing an anti-blockage treatment, for example, keyboard duplication, word relocation and word rearrangement, on word information displayed in the keyboard area during the continuous sliding gesture based input</p><p id="p0018" num="0018">According to another aspect of embodiments of the present invention, there is provided another method for continuous sliding gesture-based input text, comprising: detecting whether a continuous sliding gesture based input mode is triggered in response to an input of a user; detecting and recording a trajectory of the sliding gesture of the user on a touch-screen and inputting a corresponding word; and predicting a possible word, for example, a current possible word being input, based on a context and another input of the user and updating a keyboard layout according to at least one of the results of the prediction.</p><p id="p0019" num="0019">According to still another aspect of embodiments of the present invention, there is provided a system for continuous sliding gesture-based input text, comprising at least: a dictionary database, adapted to store word information; a user interaction module adapted to process an interaction with a user; a display module, adapted to provide the user with displayed content; and an analysis and processing module, in communication with the dictionary database, user interaction module and display module, wherein, the user interaction module records information input in an area of a keyboard and transmits it to the analysis and processing module; the analysis and processing module receives the information and an event transmitted from the user interaction module, sorts and processes the information and event, obtains a list of words from the dictionary database based on selection rules, and passes the obtained list on to the display module, and the display module displays and arranges the words obtained from the analysis and processing module according to system-defined word display and arrangement rules in a key area of the keyboard and feeds information about the results of the display back to the analysis and processing module.<!-- EPO <DP n="6"> --></p><p id="p0020" num="0020">According to a further aspect of embodiments of the present invention, there is provided an electronic device, comprising at least a user interaction means and a processor, characterized in that the user interaction means acquires information about an operation of the user and feeds output information back to the user, and in that the processor is adapted to implement a method as defined above based on the acquired information about the operation of the user.</p><p id="p0021" num="0021">As described above, the methods, system and device according to the present invention can predict a series of candidate words or word combinations based on the context and the user's input preference and arrange them around corresponding keys of the keyboard according to predefined display rules. In addition, the user is allowed to make a sliding gesture, i.e., a single operation, consecutively over the desired ones of the words or word combinations displayed in the keyboard to input multiple words, which can form a complete sentence or even a block of text. Moreover, the arrangement of the words or word combinations is flexibly adaptive to various keyboard layouts, for example, a QWERTY-based or other full-alphabet layout, a half-QWERTY layout, an alphanumeric keypad layout, and even a layout defined by the user. All of these achieve an effective increase in input efficiency and entail "smart" word prediction and arrangement</p><heading id="h0004">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p0022" num="0022"><ul><li><figref idrefs="f0001">FIG. 1</figref> is a diagram schematically illustrating a conventional touch-screen electronic device.</li><li><figref idrefs="f0001">FIG. 2</figref> depicts a schematic illustration of an electronic device suitable for a method for continuous sliding gesture based text input according to the present invention.</li><li><figref idrefs="f0002">FIG. 3</figref> depicts a flowchart graphically illustrating an embodiment of the method of the present invention.</li><li><figref idrefs="f0002">FIG. 4</figref> is a flow chart illustrating an embodiment of step S1 of the method of the present invention of <figref idrefs="f0002">FIG. 3</figref>.</li><li><figref idrefs="f0003">FIG. 5</figref> is a flow chart illustrating an embodiment of step 120 of <figref idrefs="f0002">FIG. 4</figref>.</li><li><figref idrefs="f0003">FIGS 6</figref> and <figref idrefs="f0004">7</figref> schematically illustrate an embodiment of touch point position and sliding gesture trajectory based display.</li><li><figref idrefs="f0004">FIG. 8</figref> is a schematic illustration of words arranged in a half-QWERTY keyboard in accordance with a specific embodiment of the present invention.</li><li><figref idrefs="f0005">FIG. 9</figref> is a schematic illustration of words arranged in an alphanumeric keypad in accordance with an embodiment of the present invention.</li><li><figref idrefs="f0005">FIG. 10</figref> is a flowchart graphically illustrating an embodiment of step S2 of the method of the present invention of <figref idrefs="f0002">FIG. 3</figref>.</li><li><figref idrefs="f0006">FIGS. 11</figref> and <figref idrefs="f0007">12</figref> schematically illustrate different embodiments of updating the keyboard layout in the method of the present invention.<!-- EPO <DP n="7"> --></li><li><figref idrefs="f0008">FIG. 13</figref> schematically illustrates an embodiment of an effective region associated with a word and/or word combination in the method of the present invention.</li><li><figref idrefs="f0009">FIG. 14</figref> schematically illustrates an embodiment of anti-blockage by keyboard duplication in the method of the present invention.</li><li><figref idrefs="f0010">FIG. 15</figref> schematically illustrates an embodiment of anti-blockage by word relocation in the method of the present invention.</li><li><figref idrefs="f0010">FIG. 16</figref> is a schematic illustrating a system for continuous sliding gesture based text input constructed in accordance with the present invention.</li><li><figref idrefs="f0011">FIGS. 17A</figref>, <figref idrefs="f0012">17B</figref>, <figref idrefs="f0012">17C</figref> and <figref idrefs="f0013">17D</figref> are schematics illustrating user manipulation in a first example of the present invention.</li><li><figref idrefs="f0014">FIGS. 18A</figref> and <figref idrefs="f0015">18B</figref> are schematics illustrating user manipulation in a second example of the present invention.</li><li><figref idrefs="f0016">FIG. 19</figref> is a schematic illustrating user manipulation in a fourth example of the present invention.</li><li><figref idrefs="f0017">FIG. 20</figref> is a schematic illustrating user manipulation in a fifth example of the present invention.</li><li><figref idrefs="f0018">FIGS. 21A</figref>, <figref idrefs="f0019">21B</figref>, <figref idrefs="f0020">21C, 21D</figref>, <figref idrefs="f0021">21E</figref> and <figref idrefs="f0022">21F</figref> are schematics illustrating user manipulation in a sixth example of the present invention.</li><li><figref idrefs="f0022">FIGS. 22A</figref>, <figref idrefs="f0023">22B</figref>, <figref idrefs="f0023">22C</figref>, <figref idrefs="f0024">22D</figref>, <figref idrefs="f0024">22E</figref> and <figref idrefs="f0025">22F</figref> are schematics illustrating user manipulation in a seventh example of the present invention.</li></ul></p><heading id="h0005">DETAILED DESCRIPTION</heading><p id="p0023" num="0023">The features of the present invention will become more apparent from the detailed description of specific embodiments set forth below.</p><p id="p0024" num="0024"><figref idrefs="f0001">FIG. 2</figref> depicts a schematic illustration of an electronic device suitable for a method for continuous sliding gesture based text input according to the present invention. The electronic device includes at least a user interaction means 100, a processor 200 and a memory 300.</p><p id="p0025" num="0025">A user may transmit input information to means 100 by at least one of: a tapping, sliding or other motion made by a stylus, finger or other means for making such motions; or voice from a microphone or other voice transmitter. Upon reception of the user's input information, means 100 relays the information to processor 200 for processing and feeds output information from processor 200 back to the user. Mean 100 may employ a single component for both information input and output, for example, a touch-sensitive screen or other sensitive screen for use in electronic devices, equipped with a keyboard. The keyboard may have a QWERTY-based or other full-alphabet layout, a half-QWERTY layout, an alphanumeric keypad layout, or even a layout defined by the user. Alternatively, mean 100 may also use discrete components for respectively performing the input and output functions.<!-- EPO <DP n="8"> --></p><p id="p0026" num="0026">Processor 200 may include, but not limited to, a microprocessor, a programmable logic device, an integrated circuit chip or other similar device. Processor 200 is configured to process the user's input information transmitted from means 100 and to generate and feed an output signal to means 100. In addition, processor 200 may also interact with memory 300, including obtaining data from memory 300 and writing or updating data therein.</p><p id="p0027" num="0027">Memory 300 may store: basic programs for routine operations of the electronic device such as an operating system and software; computer instructions for executing the embodiments of the method of the present invention described below; word-related information for use in the embodiments of the method of the present invention. The word-related information may include words, information about associations between the words and their related words, use frequencies of the words and other data. As used herein and hereafter, a word of a language to which the text being input belongs is intended to refer to a sequence consisting of one or more smallest recognized elements of the language and associated with a certain meaning or pronunciation, for example, a word of one or more letters of English, French, German or other alphabetic languages or a single character or phrase of Chinese, Korean, Japanese or other non-alphabetic languages.</p><p id="p0028" num="0028">The electronic device may be implemented as any electronic device allowing text input based on a sensitive screen, including but not limited to, touch-screen mobile phones, touch-screen computers and touch-screen e-books.</p><p id="p0029" num="0029">Referring to <figref idrefs="f0002">FIG. 3</figref>, an embodiment of the method of the present invention used in the aforesaid electronic device may at least include the steps of:
<ul><li>(S1) predicting a possible word based on a context and/or information obtained from an interaction with the user and displaying at least one word of the results of the prediction in a key area of a keyboard;</li><li>(S2) detecting an input of the user, activating a continuous sliding gesture based input mode when the input meets a system-predefined triggering criterion, and proceeding to step S3; and</li><li>(S3) detecting and recording a trajectory of a sliding gesture of the user on a touch screen, inputting a corresponding word and updating the layout of the keyboard.</li></ul></p><p id="p0030" num="0030">It is noted that the collection of these steps is provided merely as a preferred embodiment of the present invention, and that any separation or combination of them is considered with no impact on the conception of the invention. In other embodiments, the method may further include one or more steps prior to or after those described above to provide additional technical features.</p><p id="p0031" num="0031">For example, the method may also include: (S4) in the event of the user's input not meeting the criterion, displaying and inputting word information only according to system-predefined word display and arrangement rules.</p><p id="p0032" num="0032">Alternatively, another embodiment of the method of the invention used in the electronic device may include the steps of: (S11) detecting an input of<!-- EPO <DP n="9"> --> the user, activating the continuous sliding gesture based input mode when the user's input meets the triggering criterion, and proceeding to step S12; (S12) detecting and recording a trajectory of a sliding gesture of the user on the touch screen and inputting a corresponding word; and (S13) predicting a possible word based both on the context and an input of the user and updating the keyboard layout according to at least one of the prediction results.</p><p id="p0033" num="0033">Still alternatively, in another embodiment of the invention, the method may include: (S111) predicting possible next words based on a context and/or information obtained from an interaction with the user and displaying at least one of the words in the keyboard area; (S112) detecting an input of the user and activating the continuous sliding gesture based input mode when the input meets the triggering criterion; (S113) detecting and recording a trajectory of a sliding gesture of the user on the touch screen and, when the trajectory enters or approaches a system-predefined effective region associated with a displayed word, inputting the word in a text area; (S114) predicting possible next words based on a new context and/or a word just having been input and displaying at least one of the words in the keyboard area; and (S115) repeating steps S113 and S114 and exiting the continuous sliding gesture based input mode until a system-predefined exit criterion is met</p><p id="p0034" num="0034">The inventive method will be described in greater detail below with reference to exemplary embodiments and the drawing pertaining thereto.</p><p id="p0035" num="0035">The method is initiated with at least one letter input by the user in any possible manner through means 100. The input information then serves as the basis for predicting a possible word, and at least one of the results of the prediction is subsequently displayed in the key area of the keyboard.</p><p id="p0036" num="0036">The possible word prediction may at least include: predicting a current possible word being input by the user; and predicting a next possible word to be input by the user.</p><p id="p0037" num="0037">In one specific embodiment, the current word prediction includes predicting the word when part, but not all, of its letters, has been input For example, upon the user having input "wh", "what", "who", "where", etc. may be predicted as candidates of the possible word currently being input</p><p id="p0038" num="0038">In another specific embodiment, the current word prediction may further include: predicting a related word of the current word, wherein the related word may be a word syntactically or semantically related to the current word. Specifically, for instance, in response to "request" having being input by the user, words with syntactic or semantic relevance to the word "require", such as its forms in different tenses, synonyms, antonyms and its forms in different parts of speech, for example, "required", "requires", "demand", "answer" and "require-ment", may be predicted as candidates of the current word. In another instance, after the user has input "smart", words syntactically or semantically related to the word "smart", such as its comparative degree form, superlative form, synonyms, antonyms and its forms in different parts of speech will be predicted as candidates, for example, "smarter", "smartest", "wise", "dull" and "smartly". In still another<!-- EPO <DP n="10"> --> instance, responding to "mouse" having been input by the user, words syntactically or semantically related to the word "mouse", such as its plural form, synonyms and its possessive form will be predicted, for example, "mice", "rat" and "mouse's".</p><p id="p0039" num="0039">In still another specific embodiment, the current word prediction may further include: correcting a current input of the user and predicting the current word based on the results of the correction. Specifically, when there is an accidental mistake in the user's current input or a spelling mistake in a word constituted by letters that have been input by the user, for example, "car" mistakenly input as "csr" due to pressing of a wrong key or "conference" misspelled as "confarence", a correction of the user's current input will be conducted first and the prediction of the current possible word will be performed based on the results of the correction.</p><p id="p0040" num="0040">In one specific embodiment, the next word prediction may include: when letters input by the user have come to constitute a complete word, predicting the next word based on a default one of the results of the prediction of the current word. For example, when the user has input "what", the word "what" may be taken as a default result of the predicted candidates "what", "whatever", "whatsit", "whatsoever" and "wheat", and "can", "do", "is" and "to" may be predicted as the candidates of the next word.</p><p id="p0041" num="0041">In another specific embodiment, the next word prediction may further include: when the user has input and selected a word, predicting the next word based on the selected word. For example, upon the user having input and selected the word "how", "are", "do" and "can" will be predicted as the candidates of the next word.</p><p id="p0042" num="0042">In other embodiments, the possible word prediction may include predicting only the current word, or only the next word, or both current and next words.</p><p id="p0043" num="0043">Additionally, the possible word prediction may further include: predicting the current word, or one next word, or several next words.</p><p id="p0044" num="0044">The possible word prediction must take into account the context, and the prediction results may change with the context. For instances, in case of a previously input word "yesterday", when the user has input "it", the next word prediction results may be "was", "did" and the like, and in case of a previously input word "now", in response to "it" input by the user, the results may alternatively be "is", "does" and the like; and in case of a previously input word "I", when the user has input "s", the current word prediction results may be "see", "sing", "sleep" and the like, and in case of previously input words "I played", in response to "s" input by the user, the results may alternatively be "some", "skating" and the like. Further, the possible word prediction may also take into account one or more of word use frequency, the user's input preference, language models, syntax rules and other relevant statistical information.</p><p id="p0045" num="0045">With the prediction results having been obtained, at least one word of the results is displayed in the key area of the keyboard. The prediction results<!-- EPO <DP n="11"> --> may be a single word or a combination of several words. In specific implementations, the prediction results may also be empty, i.e., not including any word. In this case, nothing about the prediction results will be displayed in the key area. In specific embodiments, the event of the prediction results being empty may also be associated with an indication in the form of visual or auditory indication or vibration.</p><p id="p0046" num="0046">In one embodiment, the display of the at least one word of the prediction results is accomplished in a manner that is distinct from the conventional methods. In the conventional methods, candidate words are displayed in an area located away from the key area of the keyboard. This requires the user to move both the operating instrument for input or selection and the line of sight to move forth and back between the key area and the candidate-word area throughout the whole input process. For example, the user's line of sight needs to stay on the key area so as to facilitate the operating instrument to touch one or more keys in the area. However, when to select a candidate word, the user has to move both the line of sight and operating instrument to the candidate-word area to fulfill the selection task. This approach leads to great reduction in the input efficiency. In addition, as it requires the user to switch between operations in the key and candidate-word areas, it also results in an increase in the operating complexity and tends to get the user tired.</p><p id="p0047" num="0047">In light of this, the inventors of the present invention have developed word display and arrangement rules to process the prediction results such that at least one word of the processed results is directly displayed in the key area. This eliminates the need for moving the line of sight and operating instrument forth and back between the key and candidate-word areas and allows the user to do input and word selection directly in the same key area, thereby achieving more rapid and smooth text input, significantly increasing the input efficiency, relieving the user's fatigue caused by moving the line of sight and operating instrument forth and back, and providing the user with a more comfortable inputting experience.</p><p id="p0048" num="0048">Specifically, referring to <figref idrefs="f0002">FIG. 4</figref>, one embodiment of displaying the at least one word of the processed results in the key area of the keyboard may include:
<ul><li>(120) obtaining words and/or word combinations based on the prediction results and processing the obtained words and/or word combinations according to the system-predefined rules; and</li><li>(140) displaying the processed words and/or word combinations in the key area of the keyboard.</li></ul></p><p id="p0049" num="0049">In specific embodiments, referring to <figref idrefs="f0003">FIG. 5</figref>, obtaining the words and/or word combinations from the prediction results and processing the obtained words and/or word combinations according to the system-predefined rules may further include the steps of:
<ul><li>(1201) obtaining a list of words and/or word combinations;<!-- EPO <DP n="12"> --></li><li>(1202) for each of the words and/or word combinations, parsing its target display region according to their coordinate information;</li><li>(1203) analyzing the words and/or word combinations according to the system-predefined rules to obtain words and/or word combinations to be displayed and their target display regions, wherein if a word and/or word combination satisfies the system-predefined rules, it is displayed in step (140) in a predetermined region of a key in the key area associated therewith; otherwise, a rearrangement mode is activated to recreate a list of displayable words and/or word combinations, followed by the display of the rearranged words and/or word combinations in predetermined regions of respective keys associated therewith in step (140).</li></ul></p><p id="p0050" num="0050">More specifically, the word display and arrangement rules may at least include one or a combination of: (i) letter correspondence-based display; (ii) inter-word distance or word length-based display; (iii) touch point position or sliding gesture trajectory-based display; and (iv) word use frequency, user input preference, language models, syntax rules, context and other relevant statistical information-based display.</p><p id="p0051" num="0051">In one specific embodiment of the present invention, the letter correspondence may include first letter correspondence. More specifically, the first letter correspondence-based display may include, but not limited to, if a word or word combination belongs to an alphabetic language, displaying it in a predetermined region of a key corresponding to its first letter, or else, if the word or word combination belongs to a non-alphabetic language, displaying it in a predetermined region of a key corresponding to its first phonetic alphabet. For example, the word "morning" is displayed at the location of the key "m", and "<img id="ib0001" file="imgb0001.tif" wi="10" he="5" img-content="character" img-format="tif" inline="yes"/>" at the location of the key "T".</p><p id="p0052" num="0052">In one specific embodiment of the present invention, the letter correspondence may further include correspondence to a next letter to be input by the user. The next letter correspondence-based display may include, but not limited to, if a word or word combination belongs to an alphabetic language, displaying its candidates in predetermined regions of keys corresponding to candidates of the next letter predicted based on letters that have been input and on the word or word combination itself, or else, if the word or word combination belongs to a non-alphabetic language, predicting candidates of a next phonetic alphabet to be input based on an analysis performed on phonetic alphabets that have been input as well as the word or word combination itself according to the language of the text being input and displaying candidates of the word or word combination in predetermined regions of keys corresponding to the candidates of the next phonetic alphabet For example, if the text being input in French, upon "jab" have been input, the predicted candidate word "jabiru" will be displayed in a predetermined region of the possible next key "i", "jable" in a predetermined region of the possible next key "l", and "jabot" in a predetermined region of "o".</p><p id="p0053" num="0053">When the user is performing an operation in the keyboard area of the touch screen with a finger or an input instrument like a stylus, before the finger or input instrument is lifted off, there will be inevitably a blind area in the user's angular<!-- EPO <DP n="13"> --> field of view around the location where the finger or an input instrument contacts the screen. Therefore, irregularly scattering the obtained words and/or word combinations in the key area of the keyboard will cause visual confusion and make the user have no idea of what to do next, and in worse cases, unable to perform subsequent operations. On the other hand, the irregular scattering may unintentionally activate an undesired word, which may cause an operation fault, when the user is making a sliding gesture from one word to another.</p><p id="p0054" num="0054">In order to provide better operating experience and a more convenient input approach, the display and arrangement of the words and/or word combinations in the key area according to the present invention takes into account multiple factors, including the number, positional relationships and lengths of the displayed words and/or word combinations, a position of a touch point and a trajectory of a sliding gesture, thereby achieving reasonable presentation of words that are possibly desired by the user and allowing the user to consecutively input multiple words, a whole sentence, or even a paragraph of text based on a continuous sliding gesture.</p><p id="p0055" num="0055">In one specific embodiment of the present invention, the inter-word distance or word length-based display may include, but not limited to: if the parsed display regions of at least two of the words and/or word combinations are excessively close to each other, for each of the words and/or word combinations, determining, according to its priority level, whether to display it or not, such that, for example, only a word and/or word combination with a highest priority level is displayed, and the display region of each word and/or word combination with a lower priority level is changed; and if a length of a word and/or word combination affects the display of another word and/or word combination with an adjacent display region, determining according to their priority levels whether the word and/or word combination is displayed or whether its display region is to be changed.</p><p id="p0056" num="0056">In one specific embodiment of the present invention, the touch point position or sliding gesture trajectory-based display may include, but not limited to: if the parsed target display region of a word and/or word combination is determined to be blocked by a current touch point, not displaying the word and/or word combination or adjusting its display region; if the parsed target display regions of at least two words and/or word combinations are to be overlapped or blocked by a trajectory associated with the current touch point, for each of the words and/or word combinations, determining, according to its priority level, whether to display it or not, or whether to adjust its display region to make the region not to be overlapped or blocked by a possible subsequent extension of the trajectory.</p><p id="p0057" num="0057">More specifically, in the embodiment shown in <figref idrefs="f0003">FIGS. 6</figref> and <figref idrefs="f0004">7</figref>, a display region A of a word A and a display region B of a word B are both located in a coordinate system centered at the position of a touch point O and have their sides parallel to the x and y axes. While these regions are illustrated and described as rectangles herein as an example and for simplicity, they can assume any shape suitable to be implemented, such as rectangular, square, round, oval, etc.. In addition,<!-- EPO <DP n="14"> --> according to practical needs, the display regions may have different shapes or sizes. Further, the size of a display region may be determined by a parameter of the word, for example its length.</p><p id="p0058" num="0058">The process may begin with the ascertainment of whether there is overlap between regions A and B. If true, it is known that words A and B will be unrecognizable to the user due to their partial or entire overlapping. Otherwise, the process proceeds to determine, after words A and B are displayed in the display regions, whether the user's selection of word A will conflict with the selection of word B.</p><p id="p0059" num="0059">Afterward, a calculation may be performed to obtain positions of regions A and B relative to the touch point. When regions A and B are located in different quadrants of the coordinate system centered at point O, they are considered not to cause such a conflict. In other words, in this case, after words A and B have appeared in their display regions in the key area, the selection of them will requires the user's motions from point O toward different directions, which will not cause any conflict. Otherwise, further effort is needed to find whether a conflict will occur due to the relative positional relationship between regions A and B. More specifically, it may be first ascertained that whether a center point oa of region A and a center point ob of region B are situated upper and lower than the x axis, and also on the right and left of the y axis, respectively, followed by calculation of a difference between a horizontal or vertical distance from points oa to O and half of a width or length of region A, as well as a difference between a horizontal or vertical distance from points ob to O and half of a width or length of region B. For example, if points oa and ob are on opposite sides of each of the axes x and y, concurrently with the horizontal and vertical distances between points oa and O being greater than halves of the width and length of region A, respectively, and also with the horizontal and vertical distances between points ob and O being greater than halves of the width and length of region A, respectively, regions A and B will be considered to reside on diagonally opposing quadrants of the coordinate system and not to cause a conflict. In addition, if points oa and ob are positioned on the same side of the axis x and opposite sides of the axis y, with the horizontal distance between points oa and O being greater than half of the width of region A and with the horizontal distance between points ob and O being greater than half of the width of region B, regions A and B will be considered to be located in adjacent two quadrants on the same side of the axis y and also not to cause a conflict. Further, conditions for regions A and B to be located in adjacent two quadrants on the same side of the axis x may be determined in the same way.</p><p id="p0060" num="0060">If part or whole of region A is located in the same quadrant as part or whole of region B, further determination is needed.</p><p id="p0061" num="0061">For example, in this case, an interval between the regions can be compared with a predetermined non-conflicting distance threshold to determine whether a conflict will occur. Referring to <figref idrefs="f0003">FIG. 6</figref>, a length L indicated at 500 is compared to the predetermined non-conflicting distance threshold LT. If L&gt;LT or L&gt;=LT, then regions A and B are considered not mutually conflicting, and versa visa. The aforementioned interval may be the length L indicated at 500 in <figref idrefs="f0003">FIG. 6</figref>,<!-- EPO <DP n="15"> --> or a linear, horizontal or vertical distance between the center points of regions A and B, or a linear, horizontal or vertical distance from any other point associated with region A or B to any other point associated with region B or A. The non-conflicting distance threshold may be a preset constant value, a user-defined constant value, or a variable which is a function of a variety of parameters such as a size or resolution of the touch-screen of the electronic device, use frequencies of candidate words and the context. In other embodiments, the user's input behaviors may be analyzed to determine the non-conflicting distance threshold as a dynamic value consistent with the user's input preference.</p><p id="p0062" num="0062">As a further example, an angle may be compared with a predetermined non-conflicting angle threshold to determine whether the regions are mutually conflicting. Referring to <figref idrefs="f0004">FIG. 7</figref>, a difference between angles ßa and ßb is compared to the predetermined non-conflicting angle threshold ßT. For example, if the difference between angles ßa and ßb is greater than or equal to ßT, then regions A and B will be considered not mutually conflicting, and versa visa. The angle compared to the threshold may be an angle delimited by a line segment between the touch point and any point associated with region A and a line segment between the touch point and any point associated with region B. The non-conflicting angle threshold may be set according to system parameters, or defined by the user, or a dynamic variable which is a function of various parameters such as a size or resolution of the touch-screen of the electronic device, use frequencies of candidate words, the context and the user's input preference.</p><p id="p0063" num="0063">Further, the determination of whether a conflict exists between regions A and B may also be accomplished by a combination of the foregoing interval-based and angle-based approaches, or by an alternative approach.</p><p id="p0064" num="0064">In one specific embodiment of the invention, display priority levels of the words/word combinations may be determined based on their use frequencies, the user's input preference, language models, syntax rules, context and other relevant statistical information. This may include, but not limited to: more prioritized display of a word/or word combination: with a higher use frequency; more consistent with the user's input preference (e.g., previously input word groups, phrases and sentences may be memorized and selectively statistically analyzed, and those with a highest use frequency may be selected as ones preferred by the user and then compared with the the word/or word combination to determine the consistence); more consistent with the syntax rules; more consistent with the context or the other relevant statistical information.</p><p id="p0065" num="0065">In practical applications, the word display and arrangement rules may be selectively used or used in various combinations according to needs of the applications. For example, the rules may be one or more of: first letter correspondence based display above a letter key of the keyboard; inter-word distance or word length-based display; and touch point position or sliding gesture trajectory-based display.</p><p id="p0066" num="0066">Further, when the number of the rules is greater than two, they may also be prioritized to achieve a word display and arrangement approach more favorable to the user.<!-- EPO <DP n="16"> --></p><p id="p0067" num="0067">With the words and/or word combinations to be displayed and their display regions having been obtained, step (140) is performed. In specific embodiments, displaying the words and/or word combinations in the key area of the keyboard may be implemented as any of:
<ul><li>(1401) displaying them in their display regions in the key area of the keyboard; and</li><li>(1402) displaying them in their display regions in the key area of the keyboard and also in a candidate-word area.</li></ul></p><p id="p0068" num="0068">Specifically, displaying the words and/or word combinations in their display regions in the key area of the keyboard may be implemented as displaying them in predetermined regions of their respective associated keys. For example, each predetermined region may be located above, at the top left of, at the top right of, under, at the bottom left of or at the bottom right of the respective associated key, or at any position that is spaced apart therefrom by a distance not exceeding a system-predefined threshold.</p><p id="p0069" num="0069">In other embodiments, the results of the current word prediction may be displayed in the candidate-word area or a user-defined input area, with those of the next word prediction being displayed in the key area of the keyboard, in order to provide the user with an additional option. Once a default result of the current word prediction results is just the one desired by the user, the user may directly select any word and/or word combination of the next word prediction results, and the system may automatically combine the default result with the selected word and/or word combination and output them together, thus achieving a more rapid and convenient output approach.</p><p id="p0070" num="0070">Furthermore, displaying the at least one word of the processed results in the key area of the keyboard may further include: updating displayed content in the key area in a real-time fashion in response to an input of the user so as to closely associate the displayed content with the user's current input, thereby allowing the user to perform a subsequent operation based on the fed-back, displayed content and providing the user with more input conveniences. For example, when the user's current input has not yet constituted a complete word, in response to at least one letter subsequently input by the user, the possible word prediction may be done to update the displayed content in the key area by displaying at least one word of the prediction results therein.</p><p id="p0071" num="0071">It will be appreciated by those skilled in the art that, the conception of the present invention is not limited to any specific keyboard layout. The aforementioned keyboard layout may be a QWERTY-based or other full-alphabet layout, a half-QWERTY layout, an alphanumeric keypad layout, or even a layout defined by the user. <figref idrefs="f0004">FIGS. 8</figref> and <figref idrefs="f0005">9</figref> schematically show the display of predicted possible next words in key areas of a half-QWERTY keyboard and an alphanumeric keypad layout in accordance with respective embodiments of the present invention.</p><p id="p0072" num="0072">After that, step S2 is performed to detect an input of the user and activate the continuous sliding gesture based input mode if the input meets a system-predefined<!-- EPO <DP n="17"> --> triggering criterion. Referring to <figref idrefs="f0005">FIG. 10</figref>, in a specific embodiment of the present invention, step S2 may further include the steps of:
<ul><li>(210) receiving an input of the user and performing an analysis to determine whether a motion or event embodied in the user' input meets the system-predefined triggering criterion;</li><li>(220) if true, activating the continuous sliding gesture based input mode and proceeding to step S3; and</li><li>(230) otherwise, performing step S4 to input and display word information according to the system-predefined word display and arrangement rules.</li></ul></p><p id="p0073" num="0073">In one embodiment, the triggering criterion may include one or more of, and may further include one or more of substantial equivalents and various possible alternatives of:
<ul><li>(2101) a sliding gesture starting from a space key;</li><li>(2102) a sliding gesture starting from an arbitrarily designated key;</li><li>(2103) a sliding gesture starting from a sensitive point located away from the key area;</li><li>(2104) a user-defined motion made around a displayed word, wherein the motion may be, for example, at least one or a combination of drawing a circle around the word, upward sliding, downward sliding, sliding to the left, sliding to the right, sliding along a predetermined direction from one side of the word to another side thereof, long pressing, drawing a predetermined pattern and dragging the word to a predetermined region, and wherein dragging the word to the predetermined region may include dragging the word to a region of the space key or of another designated key;</li><li>(2105) a predetermined motion made in an arbitrarily designated region, e.g., tapping, long pressing, drawing a predetermined pattern, sliding along a predetermined direction, etc., wherein the designated region may include a region of a displayed word or a region spaced apart from the word by a designated distance and may assume any designated shape, e.g., round, square, rectangular, oval, etc.;</li><li>(2106) a predetermined action taken on the electronic device, e.g., shaking the electronic device; and</li><li>(2107) a sliding command input through other means, e.g., voice input means or optical, infrared or pressure sensing input means.</li></ul></p><p id="p0074" num="0074">In addition, activating the continuous sliding gesture based input mode may further comprise performing a multimedia action to prompt the user to perform a subsequent operation, including an operation for triggering the continuous sliding gesture based input mode. For example the message "Slide here for selection" or "Slide to this point to start the continuous sliding gesture based input mode" may be displayed over the space key, or in the candidate-word area, or in another designated area to prompt the user to do what is being requested to perform the subsequent action. Additionally, another multimedia action may also<!-- EPO <DP n="18"> --> be performed to notify the user that the continuous sliding gesture based input mode has been triggered. The multimedia actions may include one or more of:
<ul><li>(2111) generating a predefined sound or vibration;</li><li>(2112) highlighted display of possible next words;</li><li>(2113) zoomed displayed of possible next words;</li><li>(2114) display of possible next words in a different color; and</li><li>(2115) display of indication information in a predetermined area of the keyboard, for example, over the space key or in the candidate-word area. The indication information may be implemented as text information, numeric information, image information, or any combination them.</li></ul></p><p id="p0075" num="0075">After the continuous sliding gesture based input mode has been activated, step S3 is performed to input a corresponding word according to the user's sliding gesture trajectory, followed by updating of the keyboard layout.</p><p id="p0076" num="0076">In one specific embodiment, inputting a corresponding word according to the user's sliding gesture trajectory may include: detecting and recording the user's sliding gesture trajectory on the touch screen, determining whether there is a corresponding word meeting a system-predefined word selection criterion, and inputting the word meeting the system-predefined word selection criterion to a text area.</p><p id="p0077" num="0077">The word selection criterion may include one or more of:
<ul><li>(310) a trajectory entering a system-predefined effective region associated with a displayed word and/or word combination;</li><li>(311) a sliding gesture over a word and/or word combination; and</li><li>(312) simultaneous multiple touch points.</li></ul></p><p id="p0078" num="0078">In one specific embodiment, the effective region associated with the displayed word and/or word combination may include, but not limited to, a region where the word and/or word combination is displayed, or a region spaced apart from the word and/or word combination by a distance not exceeding a system-predefined distance threshold. In this case, upon the system having detecting the entry of the trajectory in the effective region, the corresponding word and/or word combination is determined as meeting the word selection criterion.</p><p id="p0079" num="0079">In one specific embodiment, item (311) may include: a trajectory of the sliding gesture crossing the word and/or word combination from one side to another side. The two sides may be the same side or different sides.</p><p id="p0080" num="0080">Compared to the conventional input methods in which candidate words are arranged one by one and selected by taps, in the embodiments of the present invention, predicted words are displayed in the key area of the keyboard and thus allows selection by manipulating two-dimensional regions rather than the taps on one-dimensional points. This lowers the user' operating error rate and hence results in an improvement in both the text input accuracy and efficiency.<!-- EPO <DP n="19"> --></p><p id="p0081" num="0081">In another specific embodiment, item (311) may further include: selection of a related word of the word and/or word combination by a sliding gesture. Specifically, this may include:
<ul><li>(3111) making a sliding gesture from a region of the word/word combination to a predetermined region;</li><li>(3112) displaying related words, which may be words having syntactic or semantic relevance to the word/word combination, in vicinity of the predetermined region; and</li><li>(3113) selecting a corresponding one of the related words, based on a specific operation of the user, and replacing the word/word combination with the selected one of the related words.</li></ul></p><p id="p0082" num="0082">As an example, upon the user have made a sliding gesture from a word and/or word combination to the space key region, related words of the word and/or word combination may be displayed around the space key, which may be words and/or word combinations syntactically or semantically related to the concerned word and/or word combination, such as, for example, its forms in dif ferent tenses, voices and/or parts of speech, singular or plural form, possessive form, synonyms and/or antonyms. After that, the user may continue the gesture to the right or left without the finger being lifted toward a desired one of the displayed words. Upon reaching the desired word, the user may select it by a predetermined operation, for example, maintaining the finger over the word for a predetermined time, making another gesture, or pressing another auxiliary key. Af terward, when the user further extends the sliding gesture toward another word, the aforesaid word/word combination will be replaced by the selected related word. Additionally, the related words may also be displayed in the candidate-word area or another designated area. Further, when it has been determined based on the context or other factors that it is more reasonable to input a related word but not the aforesaid word/word combination, an event may be generated around the word/word combination, for example, display of an indication symbol, or highlighted or zoomed display, or display in another color, so as to provide an indication about this.</p><p id="p0083" num="0083">In one specific embodiment, item (312) may include: simultaneous pressing of the space key and a key over which the word/word combination is displayed.</p><p id="p0084" num="0084">Inputting the word meeting the system-predefined word selection criterion to the text area may be implemented as directly inputting the selected word around the location of a cursor in the text area, or as inputting the selected word in the user-defined input area, or as inputting the selected word in the user-defined input area and concurrently providing an indication around the cursor location in the text area. The user-defined input area may be a candidate-word area or another designated area, for example, an area located around the cursor location in the text area. In one specific embodiment, text that has been input in the user-defined input area may be transferred into the text area at the time when<!-- EPO <DP n="20"> --> it is detected that the continuous sliding gesture based input mode has been exited or upon reception of a command for making this occur from the user.</p><p id="p0085" num="0085">In the continuous sliding gesture based input mode, with the user continuing the sliding gesture, corresponding words may be successively selected and the displayed context in the key area of the keyboard may also be updated accordingly. In one specific embodiment, the updating of the keyboard layout may include: predicting a next possible word to be input based both on a context and on a current touch point of the user; and displaying at least one word of the results of the prediction in the key area of the keyboard.</p><p id="p0086" num="0086">Specifically, in the continuous sliding gesture based input mode, since all touch points are located within the key area, at various positions, though, it is required to take into account the user's current touch point during the process of displaying the at least one word of the results of the prediction in the key area of the keyboard, such that in the event of a change occurring in the current touch point, the display region of the at least one word will be recalculated and rearranged to still allow the user to select a subsequent word, i.e., performing consecutive text input In addition, as there may have been some words displayed in the key area, additional considerations are needed to prevent a word to be subsequently displayed from conflicting with one or more of the ones having been displayed.</p><p id="p0087" num="0087">Referring to <figref idrefs="f0006">FIG. 11</figref>, in one embodiment, target display regions in the key area, of words and/or word combinations may be first acquired, for example, by arranging them according to their letter correspondence and then recording their coordinate positions. The words and/or word combinations may then be sorted according to their priority levels which may be obtained from the context and other factors. Next, for each of the words and/or word combinations, based on the position of a touch point, an analysis may be conducted to determine whether it will be located on a possible subsequent extension of the user's sliding gesture. If there are at least two words and/or word combinations are determined to be overlapped or blocked thereby, only a word and/or word combination with a highest priority level may be displayed. In this process, the sorting and acquiring steps may also be implemented in a reverse order, or if a computing capacity allows, at the same time.</p><p id="p0088" num="0088">In a further embodiment, in the event of a temporarily stationary touch point, as shown in <figref idrefs="f0007">FIG. 12</figref>, step S3201 may be first performed to determine whether the number of words and/or word combinations whose target display regions have been acquired exceeds a maximum displayable word number. If true, the number of the words and/or word combinations may be adjusted. Otherwise, a subsequent step is performed. The maximum displayable word number may be configured, for example, according to a screen size, resolution, or practical needs. For example, when the maximum displayable word number is 10, only the first ten of the words and/or word combinations are displayed, while the remainder is not.</p><p id="p0089" num="0089">Additionally, step S3201 may also include acquiring initial target display regions of the words and/or word combinations, for example, based on the<!-- EPO <DP n="21"> --> above-described letter correspondence rule. As shown in <figref idrefs="f0008">FIG. 13</figref>, a default initial target display region of the word "how" may be located above its corresponding key "H".</p><p id="p0090" num="0090">Step S3201 may further include calculating effective regions associated with the respective words and/or word combinations. Referring to <figref idrefs="f0008">FIG. 13</figref>, each of the words or word combinations may be provided with an accurate-touch area D1 and a wrong-touch area D2. When a touch point is located within accurate-touch area D1, it may directly trigger the selection of a corresponding word displayed in this area. Wrong-touch area D2 is provided to prevent the user's wrong selection of undesired words possibly displayed in the area due to keyboard layout updating caused by the user who is making a sliding gesture. Wrong-touch area D2 may be overlapped in part or in whole by accurate-touch area D1, or encompass accurate-touch area D1, or be adjustable according to its relative position to the keyboard. For example, when the wrong-touch area D2 is located around an edge of the keyboard, it may be partially overlapped by accurate-touch area D1 at a portion nearer to the keyboard edge while extending beyond accurate-touch area D1 at the other portions.</p><p id="p0091" num="0091">In step S3202, whether there is a conflict between a current word and/or word combination to be displayed and words and/or word combinations that have been displayed in the key area may be determined. If true, the process loops to step S3210 and, otherwise, to the next step.</p><p id="p0092" num="0092">In step S3203, whether the current touch point is situated within the effective region associated with the word and/or word combination to be displayed may be determined. For example, if the touch point is located apart from wrong-touch area D2 of the word and/or word combination, it is known that the display of the word and/or word combination will not be blocked by the touch point, and the word and/or word combination is accordingly displayed. The process then returns to the beginning of the step. Otherwise, if the touch point is within the wrong-touch area of the word and/or word combination, as it is thereby known that the display of the word and/or word combination will be blocked by the touch point or a wrong selection will occur which can confuse the user, the process loops to step S3210.</p><p id="p0093" num="0093">Step S3210 is performed to handle a word and/or word combination improper to be displayed immediately. In this step, for example, the display of the word and/or word combination may be cancelled, or alternatively, the word and/or word combination may be rearranged. The rearrangement may include, for example, incrementally moving the initial target display region of the word and/or word combination to other regions of the associated key thereof, and repeatedly performing the above-described corresponding determining step. If it becomes suitable to be displayed in the key area within a predetermined number of increments, it will be displayed. Otherwise, its display is cancelled.</p><p id="p0094" num="0094">In other embodiments, step S3 may further include: input word cancellation when a predetermined action is taken.<!-- EPO <DP n="22"> --></p><p id="p0095" num="0095">The predetermined action may include one or more of: (a) making a sliding gesture from an area of the keyboard to the space key; (b) making a sliding gesture from an area of the keyboard to a user-defined area; (c) and making a sliding gesture beyond the keyboard.</p><p id="p0096" num="0096">The cancellation may be any of: (i) cancellation of only an immediately previously input word; (ii) cancellation of a user-defined number of previously input words; and (iii) cancellation of all previously input word.</p><p id="p0097" num="0097">In other embodiments, detecting and recording the user's sliding gesture trajectory on the touch screen in step S3 may further include sliding gesture trajectory display in at least one of the following manners: displaying the whole sliding gesture trajectory; or displaying only a portion of the sliding gesture trajectory produced in an immediately previous user-defined time frame and causing it to gradually disappear from the screen when its display time has exceeded a user-defined threshold.</p><p id="p0098" num="0098">In other embodiments, inputting the corresponding word meeting the word selection criterion in step 3 in the text area may further include indicating the input of the word by at least one of: an animation event, for example, the word and/or word combination floating upward and then gradually vanishing; a vibration; and a sound.</p><p id="p0099" num="0099">Step S3 may be repeated until the satisfaction of a system-predefined criterion for triggering the exit of the continuous sliding gesture based input mode has been detected. The criterion may be, for example, the user terminating the touch, a sliding gesture to a predetermined area, absence of a possible next word, or the user selecting a predetermined word.</p><p id="p0100" num="0100">As can be seen from the above description, according to the embodiments of the present invention, after the system has completed the input of a word in the text area, it is still available for detecting the user's continuation of the sliding gesture, predicting possible next words and displaying them in the key area of the keyboard. As such, the user can successively input multiple words or even a whole sentence without the need to terminate the gesture. The present invention features the advantage of allowing input of multiple words or a whole sentence in each operation, over the conventional word-by-word input approaches.</p><p id="p0101" num="0101">Upon a failure in activating the continuous sliding gesture based input mode, step S4 is performed to display and input word information according to the system-predefined word display and arrangement rules. In one specific embodiment, displaying and inputting word information according to the system-predefined word display and arrangement rules may include arranging only words and/or word combinations obtained from a dictionary database in the key area of the keyboard according to the system-predefined word display and arrangement rules. Reference may be made to the above description for specific implementations of the display of the words and/or word combinations in the key area of the keyboard.<!-- EPO <DP n="23"> --></p><p id="p0102" num="0102">In other embodiments, the method of the present invention may further include the steps of: during the user's continuous sliding gesture based input, performing an anti-blockage treatment on word information displayed on the keyboard area. The treatment may include one or more of:
<ul><li>(610) referring to <figref idrefs="f0009">FIG. 14</figref>, keyboard duplication, specifically including: in the event of the finger sliding over a word in the key area of the keyboard and then staying thereon without being lifted for a duration exceeding a system-predefined time limit, displaying a reduced duplicate of the key area in vicinity thereof and providing the duplicate with an indicator that indicates the position of a current touch point of the finger;</li><li>(620) referring to <figref idrefs="f0010">FIG. 15</figref>, word relocation, specifically including: in the event of the finger sliding over a word in the key area and then staying thereon without being lifted for a duration exceeding a system-predefined time limit, updating the candidate-word area in the keyboard area such that all words in the key area are displayed in the candidate-word area, wherein the words are displayed in the updated candidate-word area along a certain direction with their vertical positions therein respectively corresponding to their original vertical positions in the key area, and wherein the selected word is not displayed in the candidate-word area; and</li><li>(630) word rearrangement, specifically including: in the event of the finger sliding over a word in the key area and then staying thereon without being lifted for a duration exceeding a system-predefined time limit, in the course of words in the key area being updated, if a default target display region of a word is spaced from the touch point of the finger by a distance that is less than a system-predefined distance threshold, the word is displayed and arranged in a region located in vicinity of the touch point of the finger, specifically, above, left to or right thereto, and spaced therefrom by a distance greater than the system-predefined distance.</li></ul></p><p id="p0103" num="0103">It shall be appreciated by those skilled in the art that the method of the present invention is not limited to any specific language. For example, the embodiments of the present invention may be applied to languages, including, but not limited to, one or more of: Chinese, English, Japanese, French, German, Italian, Korean, Spanish, Portuguese, Russian, Belgian, Dutch, Arabic, Cyrillic, Greek, Indonesian, Malay, Filipino, Albanian, Basque, Bosnian, Bulgarian, Catalan, Croatian, Czech, Danish, Estonian, Finnish, Galician, Hebrew, Hungarian, Icelandic, Lithuanian, Kazakh, Khmer, Laotian, Latvian, Macedonian, Malagasy, Maori, Marathi, Norwegian, Persian, Polish, Romanian, Serbian, Slovak, Slovenian, Swedish, Thai, Turkish, Uighur, Ukrainian and Vietnamese.</p><p id="p0104" num="0104">The present invention also provides a system for continuous sliding gesture based text input. The system may be implemented either as a physical apparatus or as a functional module based on a software program. Referring to <figref idrefs="f0010">FIG. 16</figref>, in one specific embodiment, the system comprises: a dictionary database 810, adapted to store word information; user interaction module 820, adapted to process interactions with the user and record and transmit information input in the keyboard area to an analysis and processing module 830; analysis and processing<!-- EPO <DP n="24"> --> module 830, adapted to receive the information and an event from the user interaction module, sort and process the information and event, interact with dictionary database 810 to obtain therefrom a list of words and/or word combinations according to certain selection rules, and pass the obtained list on to a display module 840; and display module 840, adapted to display and arrange the words and/or word combinations obtained from analysis and processing module 830 according to the system-defined word display and arrangement rules in the key area of the keyboard and feed information about the results of the display, including information about word number, positions and coordinates, back to the analysis and processing module.</p><p id="p0105" num="0105">Specifically, the information recorded by user interaction module 820 may include at least one of: (8201) a tapping, lifting or moving event occurring at a single touch point; (8202) a tapping, lifting or moving event occurring at multiple touch points; (8203) coordinate information; and (8204) a sliding gesture trajectory.</p><p id="p0106" num="0106">The selection rules on which the analysis and processing module is based to obtain the list of words may include one or more of: word use frequency, context, the user's previous inputs, language models, syntax rules and other relevant statistical information.</p><p id="p0107" num="0107">In one specific embodiment, analysis and processing module 830 is configured to perform the steps of:
<ul><li>(8301) receiving the information and event from user interaction module 820 and performing an analysis to ascertain whether the action or event meets a system-predefined criterion for triggering a continuous sliding gesture based input mode;</li><li>(8302) if true, performing the steps of:
<ol><li>(i) transmitting information of a current touch point or trajectory to display module 840; and</li><li>(ii) sending the words and/or word combinations obtained from dictionary database 810 to display module 840 which responsively updates words displayed on the keyboard layout;</li></ol></li><li>(8303) otherwise, transmitting only the words obtained from dictionary database 810 to the display module 840 which responsively displays the words in the key area of the keyboard according to system-predefined word display and arrangement rules;</li><li>(8304) determining whether a word or word combination meets a system-predefined word selection criterion based on the information fed back from display module 840 in combination with a trajectory of a current moving or sliding gesture of the user;</li><li>(8305) if true, detecting a trajectory of a sliding gesture of the user, and transmitting a word confirmed by the user to an input area or directly causing it to be displayed around a cursor;<!-- EPO <DP n="25"> --></li><li>(8306) otherwise, producing no output;</li><li>(8307) repeating steps 8301 to 8306 until receiving a gesture termination event from user interaction module 820.</li></ul></p><p id="p0108" num="0108">In one specific embodiment, display module 840 displays and arranges the words received from analysis and processing module 830 in the key area of the keyboard according to the system-predefined word display and arrangement rules, and feeds information about the results of the display, including information about word number, positions and coordinates, back to analysis and processing module 840. More specifically, to this end, display module 840 may perform the following steps:
<ul><li>(8401) receiving a list of words or word combinations transmitted from analysis and processing module 830;</li><li>(8402) for each of the words or word combinations, parsing its target display region according to its coordinate;</li><li>(8403) if a current word or word combination satisfies the system-predefined word display and arrangement rules, displaying it in a predetermined region of a key in the key area associated therewith;</li><li>(8404) otherwise, activating a rearrangement mode to screen the words that have not been displayed and thereby recreate a list of displayable words; and</li><li>(8405) transmitting information about the number of words and coordinates of the positions of the words back to analysis and processing module 830 after each rearrangement</li></ul></p><p id="p0109" num="0109">The predetermined region may be located above, at the top left of, at the top right of, under, at the bottom left of, or at the bottom right of the associated key, or at any position that is spaced apart from the associated key by a distance not exceeding a system-predefined distance threshold.</p><p id="p0110" num="0110">The word display and arrangement rules may include one or a combination of: (i) letter correspondence-based display of a word in a corresponding region in the key area; (ii) inter-word distance and word length-based display; (iii) touch point position and sliding gesture trajectory-based display; and (iv) word use frequency, user input preference, language models, syntax rules, context and other relevant statistical information-based display.</p><p id="p0111" num="0111">The principles of the present invention will be readily apparent upon a reading of the following description of several examples.</p><heading id="h0006">EXAMPLE 1</heading><p id="p0112" num="0112">Referring to <figref idrefs="f0011 f0012 f0013">FIGS. 17A to 17D</figref>, a complete process of continuous word input initiated with a sliding gesture starting from a space key includes the steps of:
<ol><li>(1) inputting the word "Good" by a tapping or sliding motion, thereby causing the display of related words of "Good", i.e., "morning", "day", "boy" and<!-- EPO <DP n="26"> --> "afternoon", as shown in <figref idrefs="f0011">FIG.17A</figref>, in the keyboard area according to the inventive rules;</li><li>(2) the finger sliding from the space key to an identification region of the word "morning", i.e., touching the space key and then moving to the location marked by the dashed-line circle in <figref idrefs="f0012">FIG. 17B</figref>, such that the word "morning" is selected and displayed in a candidate-word box, an area in which a word is temporarily held in a "standby" state before it is finally input in the text area;</li><li>(3) the word combination "Good morning" serving as the basis for predicting and electing several possible next words, shown as "everyone", "kiss" and "to" in <figref idrefs="f0012">FIG. 17B</figref>, the inventive rules-based display of which updates the displayed content on the keyboard;</li><li>(4) the finger continuing sliding forwardly to an identification region of the word "everyone", i.e., continuing moving to the location marked by the dashed-line circle in <figref idrefs="f0012">FIG. 17C</figref> with being lifted, such that the word "everyone" is selected and displayed in the candidate-word box;</li><li>(5) the word combination "Good morning everyone" again serving as the basis for the prediction and election of new possible next words, shown as "who", "has" and "is" in <figref idrefs="f0012">FIG. 17C</figref>, followed by another updating of the displayed content;</li><li>(6) the finger still being allowed to slide to other desired words to select them, i.e., repeating steps (2) to (5);</li><li>(7) the finger being lifted, i.e., the touch being terminated, which stops the input and thereby causes the transfer of the words in the candidate-word box to the text area, as shown in <figref idrefs="f0013">FIG. 17D</figref>.</li></ol></p><heading id="h0007">EXAMPLE 2</heading><p id="p0113" num="0113"><figref idrefs="f0014 f0015">FIGS. 18A to 18B</figref> show a process for triggering the continuous sliding gesture based input mode by tapping a word displayed above a letter key and dragging it into a region of the space key. The process involves the following steps.
<ol><li>(1) At first, as shown in <figref idrefs="f0014">FIG. 18A</figref>, the continuous sliding gesture based input mode is triggered by tapping the screen within the identification region of the word "morning", i.e., the location marked by the dashed-line circle in the figure, and dragging the word to the region of the space key. This also causes the selection of the word "morning", which is then displayed in the candidate-word box.</li><li>(2) The word combination "Good morning" in the candidate-word box serves as the basis for predicting and selecting several possible next words, shown as "everyone", "kiss" and "to" in <figref idrefs="f0015">FIG. 18B</figref>, and the displayed content on the key-board is accordingly updated to these word.</li><li>(3) If the user's sliding gesture is not terminated and is further extended to the identification region of the word "everyone", i.e., the location marked by the dashed-line circle in <figref idrefs="f0015">FIG. 18B</figref>, the word "everyone" will be selected<!-- EPO <DP n="27"> --> and displayed in the candidate-word box. Before the gesture is terminated, further desired words can be input by repeating steps (2) to (3).</li><li>(4) Otherwise, if the touch is terminated after step (2), in order to further input the word "everyone", it is required to perform again step (1) to tap the word "everyone" and drag it into the region of the space key.</li></ol></p><heading id="h0008">EXAMPLE 3</heading><p id="p0114" num="0114">The continuous sliding gesture based input mode is triggered by one of several actions taken around a word displayed above a letter key, including:
<ol><li>(1) drawing a circle or any other predetermined pattern, for example, a triangle, cross or tick, which will cause the selection of the words, as well as its display in the candidate-word box, and after which, the word is transferred to the text area if the touch is terminated, or another word in the updated content is subsequently selected if the gesture is continued to its identification region;</li><li>(2) upward or downward sliding, or sliding to left or right, which will cause the selection of the words, as well as its display in the candidate-word box, and after which, the word is transferred to the text area if the touch is terminated, or another word in the updated content is subsequently selected if the gesture is continued to its identification region;</li><li>(3) a forth-and-back sliding motion, for example, a left-right-left motion or such a motion made along any direction, which passes through the region where the word is displayed twice; and</li><li>(4) a user-defined motion, e.g., a certain gesture.</li></ol></p><heading id="h0009">EXAMPLE 4</heading><p id="p0115" num="0115">Referring to <figref idrefs="f0016">FIG. 19</figref>, the continuous sliding gesture based input mode is triggered by a sliding gesture starting from a user-defined sensitive point 1901 in the keyboard to a word displayed around a letter key.</p><heading id="h0010">EXAMPLE 5</heading><p id="p0116" num="0116">With the space key or another user-defined key being touch, a word displayed around a letter key is input to the text area by simply tapping it. Successive input of other words is possible by repeating this operation, as shown in <figref idrefs="f0017">FIG. 20</figref>.</p><heading id="h0011">EXAMPLE 6</heading><p id="p0117" num="0117">Referring to <figref idrefs="f0018 f0019 f0020">FIGS. 21A to 21D</figref>, in response to at least one letter arbitrarily input by the user, prediction of possible next words and/or word combinations is performed by the system and the key area of the keyboard is updated in a real-time fashion with the predicted words.
<ol><li>(1) Upon the user having input "wh", words associated with these input letter, such as "who", "what", "where" and "which", as shown in <figref idrefs="f0018">FIG. 21A</figref>, are displayed in the key area according to the inventive rules.<!-- EPO <DP n="28"> --></li><li>(2) The word "what" is selected, and the continuous sliding gesture based input mode is concurrently triggered, when the finger makes a sliding gesture from the space key and upward into the identification region of "what", as shown in <figref idrefs="f0019">FIG. 21B</figref>. More specifically, the finger taps the space key and then slides to the location marked by the dashed-line circle, thereby causing the selection of the "what" and its display in the candidate-word box. At the same time, the continuous sliding gesture based input mode is triggered, allowing input of subsequent words by continuously extending the sliding gesture with the finger being lifted off the screen.</li><li>(3) Associated words of the "what" in the candidate-word box, shown in as "can", "is" and "do" in <figref idrefs="f0020">FIG. 21C</figref>, are then predicted based thereon and displayed according to the inventive rules to replace the word currently being presented in the key area.</li><li>(4) With the sliding gesture proceeding without being lifted into the identification region of the word "can", i.e., the location marked by the dashed-line circle in <figref idrefs="f0020">FIG. 21D</figref>, "can" is also selected and displayed in the candidate-word box.</li><li>(5) Based on the word combination "what can" in the candidate-word box, the prediction of possible next words, i.e., "I", "he" and "you" shown in <figref idrefs="f0021">FIG. 21E</figref>, is conducted and the predicted words update the displayed content in the key area.</li><li>(6) The finger is still allowed to slide to other desired words to select them, i.e., repeating steps (2) to (5).</li><li>(7) After the finger is lifted, i.e., the touch being terminated, the input is stopped and the words in the candidate-word box are transferred to the text area, as shown in <figref idrefs="f0022">FIG. 21F</figref>.</li></ol></p><heading id="h0012">EXAMPLE 7</heading><p id="p0118" num="0118">Referring to <figref idrefs="f0022 f0023">FIGS. 22A to 22B</figref>, in the context of the Chinese language, the system predicts possible next Chinese characters or words based on an input of letter(s) by the user and updates the key area of the keyboard with the results of the prediction in a real-time fashion.
<ol><li>(1) Based on "tian" input by the user, characters or words resulting from a prediction, e.g., "<img id="ib0002" file="imgb0002.tif" wi="6" he="5" img-content="character" img-format="tif" inline="yes"/>" , "<img id="ib0003" file="imgb0003.tif" wi="5" he="5" img-content="character" img-format="tif" inline="yes"/>", "<img id="ib0004" file="imgb0004.tif" wi="6" he="5" img-content="character" img-format="tif" inline="yes"/>" and "<img id="ib0005" file="imgb0005.tif" wi="6" he="5" img-content="character" img-format="tif" inline="yes"/>", as shown in <figref idrefs="f0022">FIG. 22A</figref> are displayed according to the inventive rules in the candidate-word box. At the same time, words associated with the default result "<img id="ib0006" file="imgb0002.tif" wi="6" he="5" img-content="character" img-format="tif" inline="yes"/>" are displayed around letter keys that correspond to the first phonetic alphabets of the respective subsequent characters of the words. As a result, for example, "<img id="ib0007" file="imgb0007.tif" wi="10" he="5" img-content="character" img-format="tif" inline="yes"/>" is displayed around the letter key "Q", "<img id="ib0008" file="imgb0008.tif" wi="11" he="5" img-content="character" img-format="tif" inline="yes"/>" around "J"', "<img id="ib0009" file="imgb0009.tif" wi="15" he="5" img-content="character" img-format="tif" inline="yes"/>" around "L", and "<img id="ib0010" file="imgb0010.tif" wi="10" he="5" img-content="character" img-format="tif" inline="yes"/>" around "X". In addition, as "tian" can also be construed as the pinyin of the Chinese word "<img id="ib0011" file="imgb0011.tif" wi="11" he="5" img-content="character" img-format="tif" inline="yes"/>", this word is also displayed around the corresponding letter key "T".</li><li>(2) Assuming that the word "<img id="ib0012" file="imgb0007.tif" wi="10" he="5" img-content="character" img-format="tif" inline="yes"/>" is desired by the user, a circle can be drawn around the word to trigger the continuous sliding gesture based input mode and simultaneously, as shown in <figref idrefs="f0023">FIG. 22B</figref>, and cause "<img id="ib0013" file="imgb0007.tif" wi="10" he="5" img-content="character" img-format="tif" inline="yes"/>" to be selected and displayed in the candidate-word box.<!-- EPO <DP n="29"> --></li><li>(3) Based on the word "<img id="ib0014" file="imgb0007.tif" wi="10" he="5" img-content="character" img-format="tif" inline="yes"/>" displayed in the candidate-word box, possible next characters or words, e.g., "<img id="ib0015" file="imgb0015.tif" wi="6" he="5" img-content="character" img-format="tif" inline="yes"/>", "<img id="ib0016" file="imgb0016.tif" wi="6" he="5" img-content="character" img-format="tif" inline="yes"/>", "<img id="ib0017" file="imgb0017.tif" wi="11" he="5" img-content="character" img-format="tif" inline="yes"/>" and "<img id="ib0018" file="imgb0018.tif" wi="6" he="5" img-content="character" img-format="tif" inline="yes"/>" as shown in <figref idrefs="f0023">FIG. 22C</figref>, are predicted and displayed to update the content in the key area. During this process, although "<img id="ib0019" file="imgb0019.tif" wi="6" he="5" img-content="character" img-format="tif" inline="yes"/>" is also a result of the prediction, as the current touch point of the user is located over the letter key "Q", trajectories of extension of the user's sliding gesture to "<img id="ib0020" file="imgb0018.tif" wi="6" he="5" img-content="character" img-format="tif" inline="yes"/>", "<img id="ib0021" file="imgb0015.tif" wi="6" he="5" img-content="character" img-format="tif" inline="yes"/>" and "<img id="ib0022" file="imgb0017.tif" wi="11" he="5" img-content="character" img-format="tif" inline="yes"/>" may be overlapped or blocked by the trajectory of extension to "<img id="ib0023" file="imgb0019.tif" wi="6" he="5" img-content="character" img-format="tif" inline="yes"/>", and also since it has a priority level that is low-er than those of "<img id="ib0024" file="imgb0018.tif" wi="6" he="5" img-content="character" img-format="tif" inline="yes"/>", "<img id="ib0025" file="imgb0015.tif" wi="6" he="5" img-content="character" img-format="tif" inline="yes"/>" and "<img id="ib0026" file="imgb0017.tif" wi="11" he="5" img-content="character" img-format="tif" inline="yes"/>", "<img id="ib0027" file="imgb0019.tif" wi="6" he="5" img-content="character" img-format="tif" inline="yes"/>" is not displayed.</li><li>(4) With the gesture proceeding, for example, into the identification region of "<img id="ib0028" file="imgb0015.tif" wi="6" he="5" img-content="character" img-format="tif" inline="yes"/>", i.e., the location marked by the dashed line in <figref idrefs="f0024">FIG. 22D</figref>, without the finger being lifted off the screen, "<img id="ib0029" file="imgb0015.tif" wi="6" he="5" img-content="character" img-format="tif" inline="yes"/>" is selected and further displayed in the candidate-word box.</li><li>(5) The phrase "<img id="ib0030" file="imgb0030.tif" wi="15" he="5" img-content="character" img-format="tif" inline="yes"/>" in the candidate-word box can serves as the basis for predicting and electing possible next characters or words, .e.g., "<img id="ib0031" file="imgb0031.tif" wi="14" he="5" img-content="character" img-format="tif" inline="yes"/>", "<img id="ib0032" file="imgb0032.tif" wi="6" he="5" img-content="character" img-format="tif" inline="yes"/>", "<img id="ib0033" file="imgb0018.tif" wi="6" he="5" img-content="character" img-format="tif" inline="yes"/>" and "<img id="ib0034" file="imgb0019.tif" wi="6" he="5" img-content="character" img-format="tif" inline="yes"/>", followed by updating the content displayed in the key area according to the inventive rules.</li><li>(6) The finger is still allowed to slide to other desired words to select them, i.e., repeating steps (3) to (5).</li><li>(7) Upon the finger being lifted, i.e., the touch being terminated, the input operation is ceased and the phrase in the candidate-word box are transferred to the text area, as shown in <figref idrefs="f0025">FIG. 22F</figref>.</li></ol></p><p id="p0119" num="0119">These examples are provided merely for the purpose of facilitating the understanding of the subject matter of the present invention and shall in no way be construed as limiting the scope of thereof. As a matter of course, all substantive equivalents of the embodiments disclosed above, as well as all other easily imaginable embodiments also fall within the scope of the subject matter of the present invention. Wherein the embodiments disclosed above also include all those implicitly disclosed thereby.</p><p id="p0120" num="0120">As described above, the methods, system and device according to the present invention can predict a series of candidate words or word combinations based on the context and the user's input preference and arrange them around corresponding keys of the keyboard according to predefined display rules. In addition, the user is allowed to make a sliding gesture, i.e., a single operation, consecutively over the desired ones of the words or combinations displayed in the keyboard to input multiple words, which can form a complete sentence or even a block of text. Moreover, the arrangement of the words or combinations is flexibly adaptive to various keyboard layouts, for example, a QWERTY-based or other full-alphabet layout, a half-QWERTY layout, an alphanumeric keypad layout, and even a layout defined by the user. All of these achieve an effective increase in input efficiency and entail "smart" word prediction and arrangement</p><p id="p0121" num="0121">Further, according to the present invention, words and/or word combinations obtained from the dictionary database are processed according to the system-predefined word display and arrangement rules, thereby enabling the positioning of predicted next words possibly to be input by the user around corresponding<!-- EPO <DP n="30"> --> keys in the keyboard. This allows the user to perform rapid selection of candidate words and continuous text input in a convenient and smooth way without the need to switch operations between the keys and candidate-word area. Therefore, in addition to a great improvement in the input efficiency, the user can further have more comfortable inputting experience.</p><p id="p0122" num="0122">While the invention has been described herein with reference to specific embodiments thereof, it is apparent that many changes and variations can be made without departing from the scope or spirit of the invention. Therefore, the description and drawings are, accordingly, to be regarded as illustrative rather than restrictive.</p></description><claims mxw-id="PCLM90459527" lang="EN" load-source="patent-office"><!-- EPO <DP n="31"> --><claim id="c-en-0001" num="0001"><claim-text>A method for continuous sliding gesture-based input text, comprising:
<claim-text>detecting whether a continuous sliding gesture based input mode is triggered in response to an input of a user;</claim-text>
<claim-text>detecting and recording a trajectory of the sliding gesture of the user on a touch-screen and inputting a corresponding word; and</claim-text>
<claim-text>predicting a possible word based on a context and another input of the user and updating a keyboard layout according to at least one of the results of the prediction.</claim-text></claim-text></claim><claim id="c-en-0002" num="0002"><claim-text>The method of claim 1, further comprising predicting a possible word and displaying at least one of the results of the prediction on a key area of the keyboard, before the detection of whether the continuous sliding gesture based input mode is triggered.</claim-text></claim><claim id="c-en-0003" num="0003"><claim-text>The method of claim 1 or 2, wherein the prediction of the possible word comprises predicting a current possible word being input.</claim-text></claim><claim id="c-en-0004" num="0004"><claim-text>The method of claim 3, wherein predicting the current possible word comprises predicting the word when part, but not all, of its letters has been input.</claim-text></claim><claim id="c-en-0005" num="0005"><claim-text>The method of claim 3, wherein predicting the current possible word comprises predicting a related word thereof.</claim-text></claim><claim id="c-en-0006" num="0006"><claim-text>The method of claim 3, wherein predicting the current possible word comprises correcting a current input of the user and predicting the current possible word based on the results of the correction.</claim-text></claim><claim id="c-en-0007" num="0007"><claim-text>The method of claim 1 or 2, wherein the prediction of the possible word comprises predicting one or more next possible words to be input by the user.</claim-text></claim><claim id="c-en-0008" num="0008"><claim-text>The method of claim 7, wherein predicting the one or more next possible words comprises, when letters input by the user have come to constitute a complete word, predicting the one or more next possible words based on a default one of the results of the prediction of the current possible word.</claim-text></claim><claim id="c-en-0009" num="0009"><claim-text>The method of claim 7, wherein predicting the one or more next possible words comprises, when the user has input and selected a word, predicting the one or more next possible words based on the selected word.</claim-text></claim><claim id="c-en-0010" num="0010"><claim-text>The method of claim 1 or 2, wherein the prediction of the possible word further comprises prediction according to one or more of word use frequency, the user's input preference, language models, syntax rules, and other relevant statistical information.</claim-text></claim><claim id="c-en-0011" num="0011"><claim-text>The method of claim 1, wherein updating the displayed con-tent in the key area of the keyboard according to the at least one of the results<!-- EPO <DP n="32"> --> of the prediction comprises: displaying the at least one of the results of the prediction in the key area of the keyboard.</claim-text></claim><claim id="c-en-0012" num="0012"><claim-text>The method of claim 11 or 2, wherein displaying the at least one of the results of the prediction in the key area of the keyboard comprises: word processing according to system-predefined word display and arrangement rules.</claim-text></claim><claim id="c-en-0013" num="0013"><claim-text>The method of claim 12, wherein the system-predefined word display and arrangement rules comprises one or a combination of: letter correspondence-based display; inter-word distance and word length-based display; touch point position and sliding gesture trajectory-based display; and word use frequency, user input preference, language models, syntax rules, context and other relevant statistical information-based display.</claim-text></claim><claim id="c-en-0014" num="0014"><claim-text>The method of claim 13, wherein the letter correspondence-based display comprises first letter correspondence-based display.</claim-text></claim><claim id="c-en-0015" num="0015"><claim-text>The method of claim 14, wherein the first letter comprises a first letter or a first phonetic alphabet.</claim-text></claim><claim id="c-en-0016" num="0016"><claim-text>The method of claim 13, wherein the letter correspondence comprises correspondence to a next letter to be input by the user.</claim-text></claim><claim id="c-en-0017" num="0017"><claim-text>The method of claim 16, wherein the next letter comprises a next letter or a next phonetic alphabet.</claim-text></claim><claim id="c-en-0018" num="0018"><claim-text>The method of claim 13, wherein the inter-word distance and word length-based display comprises determining whether target display regions of at least two words are excessively close to each other and, if true, only displaying one of the at least two words with a highest priority level or adjusting the target display region of each other one of the at least two words with a lower priority level.</claim-text></claim><claim id="c-en-0019" num="0019"><claim-text>The method of claim 13, wherein the inter-word distance and word length-based display comprises determining whether a length of a word affects another word to be displayed at an adjacent target display region and, if true, only displaying one of the two words with a high priority level or adjusting the target display region of the other of the two words with a low priority level.</claim-text></claim><claim id="c-en-0020" num="0020"><claim-text>The method of claim 13, wherein the touch point position and sliding gesture trajectory-based display comprises determining whether a target display region of a word is to be blocked by a current touch point and, if true, not displaying the word or adjusting its target display region.</claim-text></claim><claim id="c-en-0021" num="0021"><claim-text>The method of claim 13, wherein the touch point position and sliding gesture trajectory-based display comprises determining whether target display regions of at least two words are to be overlapped or blocked by a trajectory of a current touch point and, if true, for each of the at least two words, further determining, according to their priority levels, whether to display it or<!-- EPO <DP n="33"> --> adjust its target display region, such that it will not be overlapped or blocked by a possible subsequent extension of the trajectory.</claim-text></claim><claim id="c-en-0022" num="0022"><claim-text>The method of claim 13, further comprising: prioritizing multiple ones of the word display and arrangement rules.</claim-text></claim><claim id="c-en-0023" num="0023"><claim-text>The method of claim 12, wherein displaying the at least one of the results of the prediction in the key area of the keyboard further comprises: displaying at least one of words that have been processed in the key area of the keyboard.</claim-text></claim><claim id="c-en-0024" num="0024"><claim-text>The method of claim 23, wherein displaying the at least one of the words that have been processed in the key area of the keyboard comprises: displaying each of the at least one of the words in a predetermined region of an associated key.</claim-text></claim><claim id="c-en-0025" num="0025"><claim-text>The method of claim 24, wherein the predetermined region is located above, at the top left of, at the top right of, under, at the bottom left of, or at the bottom right of the associated key, or at any position that is spaced apart from the associated key by a distance not exceeding a system-predefined distance threshold.</claim-text></claim><claim id="c-en-0026" num="0026"><claim-text>The method of claim 24, wherein displaying the at least one of the words that have been processed in the key area of the keyboard further comprises: displaying the at least one of the words also in a candidate-word area.</claim-text></claim><claim id="c-en-0027" num="0027"><claim-text>The method of claim 24, wherein displaying the at least one of the words that have been processed in the key area of the keyboard comprises: displaying at least one of the results of the prediction of the current possible word in the candidate-word area or a user-defined input area and displaying each of at least one of the results of the prediction of the one or more next possible words in a predetermined region of an associated key.</claim-text></claim><claim id="c-en-0028" num="0028"><claim-text>The method of claim 24, wherein displaying the at least one of the words that have been processed in the key area of the keyboard further comprises: updating displayed content in the key area of the keyboard in a real-time manner according to an input of the user.</claim-text></claim><claim id="c-en-0029" num="0029"><claim-text>The method of claim 11 or 2, wherein in the event of the results of the prediction being empty, an indication is given in the form of one or a combination of a visual indication, an auditory indication and a vibration.</claim-text></claim><claim id="c-en-0030" num="0030"><claim-text>The method of claim 1, wherein detecting and recording the user's sliding gesture trajectory on the touch-screen and inputting the corresponding word comprise: determining whether the trajectory meets a system-predefined word selection criterion.</claim-text></claim><claim id="c-en-0031" num="0031"><claim-text>The method of claim 30, wherein the word selection criterion comprises: a touch point being located in a system-predefined, associated effective region of the word.</claim-text></claim><claim id="c-en-0032" num="0032"><claim-text>The method of claim 31, wherein the associated effective region comprises a region where the word is displayed, or a region spaced<!-- EPO <DP n="34"> --> apart from the word by a distance not exceeding a system-predefined distance threshold.</claim-text></claim><claim id="c-en-0033" num="0033"><claim-text>The method of claim 30, wherein the word selection criterion comprises: selection of a word by a sliding gesture.</claim-text></claim><claim id="c-en-0034" num="0034"><claim-text>The method of claim 33, wherein the sliding gesture comprises a sliding gesture crossing the word from one side to another side.</claim-text></claim><claim id="c-en-0035" num="0035"><claim-text>The method of claim 33, wherein the selection comprises selecting a related word of the word by the sliding gesture.</claim-text></claim><claim id="c-en-0036" num="0036"><claim-text>The method of claim 35, wherein the selection of the related word comprises: making a sliding gesture from a region where the word is displayed to a predetermined region; displaying related words in vicinity of the predetermined region; and selecting a corresponding one of the related words based on a predetermined operation of the user and replacing the word with the selected one of the related words.</claim-text></claim><claim id="c-en-0037" num="0037"><claim-text>The method of claim 36, wherein the predetermined region is one or a combination of: a region of a space key, the candidate-word area, and another designated region.</claim-text></claim><claim id="c-en-0038" num="0038"><claim-text>The method of claim 37, wherein the word of which a related word is to be displayed is provided with an indication in one or more of the following forms: an indication symbol, highlighted display, display in a different color and zoom display.</claim-text></claim><claim id="c-en-0039" num="0039"><claim-text>The method of claim 30, wherein the word selection criterion comprises: simultaneous multiple touch points.</claim-text></claim><claim id="c-en-0040" num="0040"><claim-text>The method of claim 1, wherein detecting and recording the user's sliding gesture trajectory on the touch-screen and inputting the corresponding word comprise: inputting the word meeting the word selection criterion to a text area.</claim-text></claim><claim id="c-en-0041" num="0041"><claim-text>The method of claim 40, wherein inputting the word meeting the word selection criterion to the text area comprises: directly inputting the selected word around the location of a cursor in the text area, or in the user-defined input area.</claim-text></claim><claim id="c-en-0042" num="0042"><claim-text>The method of claim 40, wherein the input of the word is provided with an indication in one or more of the following forms: an animation event, a vibration and a sound.</claim-text></claim><claim id="c-en-0043" num="0043"><claim-text>The method of claim 1, wherein updating the keyboard layout comprises: displaying predicted words in the key area of the keyboard according to a current touch point of the user.</claim-text></claim><claim id="c-en-0044" num="0044"><claim-text>The method of claim 1, wherein updating the keyboard layout further comprises: in the event of a change occurring in the current touch point, recalculating and rearranging target display regions of the predicted words.<!-- EPO <DP n="35"> --></claim-text></claim><claim id="c-en-0045" num="0045"><claim-text>The method of claim 1, wherein updating the keyboard layout further comprises: determining whether the number of obtained words to be displayed exceeds a maximum displayable word number.</claim-text></claim><claim id="c-en-0046" num="0046"><claim-text>The method of claim 1, wherein updating the keyboard layout further comprises: determining whether the words are located on a trajectory of a possible sliding gesture of the user and, if there is overlapping or blockage, only displaying one of the words with a highest priority level.</claim-text></claim><claim id="c-en-0047" num="0047"><claim-text>The method of claim 1, wherein updating the keyboard layout further comprises: determining whether a word to be displayed conflicts with words that have been displayed and displaying the predicted words according to the results of the determination.</claim-text></claim><claim id="c-en-0048" num="0048"><claim-text>The method of claim 1, wherein updating the keyboard layout further comprises: calculating associated effective regions of the words; and determining whether the current touch point is located within the effective region of a word to be displayed.</claim-text></claim><claim id="c-en-0049" num="0049"><claim-text>The method of claim 1, wherein updating the keyboard layout further comprises: processing a word unsuitable to be immediately displayed.</claim-text></claim><claim id="c-en-0050" num="0050"><claim-text>The method of claim 49, wherein processing the word unsuitable to be immediately displayed comprises: cancelling its display or rear-ranging it.</claim-text></claim><claim id="c-en-0051" num="0051"><claim-text>The method of claim 50, wherein the rearrangement comprises: incrementally moving an initial target display region of the word to other regions of an associated key of the word; and if the word becomes suitable to be displayed within a predetermined number of increments, displaying it in the key area, otherwise, cancelling its display.</claim-text></claim><claim id="c-en-0052" num="0052"><claim-text>The method of claim 1, wherein the continuous sliding gesture based input mode is triggered by one or more of: a sliding gesture starting from the space key; a sliding gesture starting from an arbitrarily designated key; a sliding gesture starting from a sensitive point located away from the key area; a user-defined motion made around a displayed word; a predetermined motion made in an arbitrarily designated region; a predetermined action taken on a corresponding electronic device; and a sliding command input through other means.</claim-text></claim><claim id="c-en-0053" num="0053"><claim-text>The method of claim 52, wherein the user-defined motion comprises one or a combination of: drawing a circle around the word, upward sliding, downward sliding, sliding to the left, sliding to the right, sliding along a predetermined direction from one side of the word to another side thereof, long pressing, drawing a predetermined pattern, and dragging the word to a predetermined region.</claim-text></claim><claim id="c-en-0054" num="0054"><claim-text>The method of claim 53, wherein dragging the word to the predetermined region comprises dragging the word the region of the space key.<!-- EPO <DP n="36"> --></claim-text></claim><claim id="c-en-0055" num="0055"><claim-text>The method of claim 52, wherein the predetermined motion comprises one or a combination of: tapping, long pressing, drawing a predetermined pattern, and sliding along a predetermined direction, in a designated region.</claim-text></claim><claim id="c-en-0056" num="0056"><claim-text>The method of claim 55, wherein the designated region comprises a region of the displayed word or a region spaced apart from the displayed word by a designated distance.</claim-text></claim><claim id="c-en-0057" num="0057"><claim-text>The method of claim 55, wherein the designated region is a round, square, or oval region.</claim-text></claim><claim id="c-en-0058" num="0058"><claim-text>The method of claim 52, wherein the predetermined action comprises: shaking the electronic device.</claim-text></claim><claim id="c-en-0059" num="0059"><claim-text>The method of claim 52, wherein the other equipment comprises one or a combination of: voice input means, optical sensing input means, infrared sensing input means and pressure sensing input means.</claim-text></claim><claim id="c-en-0060" num="0060"><claim-text>The method of claim 1, further comprising: providing an indication, in the form of a multimedia action, for prompting the user to perform an operation to trigger the continuous sliding gesture based input mode.</claim-text></claim><claim id="c-en-0061" num="0061"><claim-text>The method of claim 1, further comprising: providing an indication, in the form of a multimedia action, for notifying that the continuous sliding gesture based input mode has been triggered.</claim-text></claim><claim id="c-en-0062" num="0062"><claim-text>The method of claim 61, wherein the multimedia action comprises one or a combination of: generating a predefined sound or vibration; highlighted display of possible next words; zoomed displayed of possible next words; display of possible next words in a different color; display of indication information in a predetermined area of the keyboard.</claim-text></claim><claim id="c-en-0063" num="0063"><claim-text>The method of claim 1, further comprising: input word cancellation by a predetermined action.</claim-text></claim><claim id="c-en-0064" num="0064"><claim-text>The method of claim 63, wherein the predetermined action comprises one or a combination of: making a sliding gesture from an area of the keyboard to the space key; making a sliding gesture from an area of the keyboard to a user-defined area; and making a sliding gesture beyond the keyboard.</claim-text></claim><claim id="c-en-0065" num="0065"><claim-text>The method of claim 63, wherein the cancellation may be any of: cancellation of only an immediately previously input word; cancellation of a user-defined number of previously input words; and cancellation of all previously input word.</claim-text></claim><claim id="c-en-0066" num="0066"><claim-text>The method of claim 1, further comprising sliding gesture trajectory display implemented as: displaying the whole sliding gesture trajectory; or displaying only a portion of the sliding gesture trajectory produced in an immediately previous user-defined time frame and causing it to gradually disappear from the screen when its display time has exceeded a user-defined threshold.<!-- EPO <DP n="37"> --></claim-text></claim><claim id="c-en-0067" num="0067"><claim-text>The method of claim 1, wherein the continuous sliding gesture based input mode is exited when the occurrence of a system-predefined exit triggering event is detected.</claim-text></claim><claim id="c-en-0068" num="0068"><claim-text>The method of claim 67, wherein the exit triggering event comprises one or a combination of: the user terminating the touch, the user making a sliding gesture to a predetermined area, absence of a possible next word, and the user selecting a predetermined word.</claim-text></claim><claim id="c-en-0069" num="0069"><claim-text>The method of claim 1, further comprising: displaying and inputting word information according to a common rule.</claim-text></claim><claim id="c-en-0070" num="0070"><claim-text>The method of claim 1, wherein the method is suitable for use with one or more of the following keyboard layouts: full-alphabet, half-QWERTY, alphanumeric keypad and user-defined.</claim-text></claim><claim id="c-en-0071" num="0071"><claim-text>The method of claim 1, wherein the method is suitable for use with one or more of the following languages: Chinese, English, Japanese, French, German, Italian, Korean, Spanish, Portuguese, Russian, Belgian, Dutch, Arabic, Cyrillic, Greek, Indonesian, Malay, Filipino, Albanian, Basque, Bosnian, Bulgarian, Catalan, Croatian, Czech, Danish, Estonian, Finnish, Galician, Hebrew, Hungarian, Icelandic, Lithuanian, Kazakh, Khmer, Laotian, Latvian, Macedonian, Malagasy, Maori, Marathi, Norwegian, Persian, Polish, Romanian, Serbian, Slovak, Slovenian, Swedish, Thai, Turkish, Uighur, Ukrainian and Vietnamese.</claim-text></claim><claim id="c-en-0072" num="0072"><claim-text>The method of claim 1, further comprising performing an anti-blockage treatment on word information displayed in the keyboard area during the continuous sliding gesture based input.</claim-text></claim><claim id="c-en-0073" num="0073"><claim-text>The method of claim 72, wherein the anti-blockage treatment comprises one or a combination of: keyboard duplication, word relocation and word rearrangement.</claim-text></claim><claim id="c-en-0074" num="0074"><claim-text>A method for continuous sliding gesture-based input text, comprising:
<claim-text>predicting a possible word based on a context and an input of a user;</claim-text>
<claim-text>displaying at least one of the results of the prediction in a key area of a keyboard; and</claim-text>
<claim-text>detecting and recording a trajectory of a sliding gesture of the user on a touch screen, inputting a corresponding word and updating the layout of the keyboard.</claim-text></claim-text></claim><claim id="c-en-0075" num="0075"><claim-text>The method of claim 74, further comprising: detecting whether a continuous sliding gesture based input mode is triggered in response to an input of a user.</claim-text></claim><claim id="c-en-0076" num="0076"><claim-text>The method of claim 74, wherein the prediction of the possible word comprises predicting a current possible word being input.<!-- EPO <DP n="38"> --></claim-text></claim><claim id="c-en-0077" num="0077"><claim-text>The method of claim 76, wherein predicting the current possible word comprises predicting the word when part, but not all, of its letters has been input.</claim-text></claim><claim id="c-en-0078" num="0078"><claim-text>The method of claim 76, wherein predicting the current possible word comprises predicting a related word thereof.</claim-text></claim><claim id="c-en-0079" num="0079"><claim-text>The method of claim 76, wherein predicting the current possible word comprises correcting a current input of the user and predicting the current possible word based on the results of the correction.</claim-text></claim><claim id="c-en-0080" num="0080"><claim-text>The method of claim 74, wherein the prediction of the possible word comprises predicting one or more next possible words to be input by the user.</claim-text></claim><claim id="c-en-0081" num="0081"><claim-text>The method of claim 80, wherein predicting the one or more next possible words comprises: when letters input by the user have come to constitute a complete word, predicting the one or more next possible words based on a default one of the results of the prediction of the current possible word.</claim-text></claim><claim id="c-en-0082" num="0082"><claim-text>The method of claim 80, wherein predicting the one or more next possible words comprises, when the user has input and selected a word, predicting the one or more next possible words based on the selected word.</claim-text></claim><claim id="c-en-0083" num="0083"><claim-text>The method of claim 74, wherein the prediction of the possible word further comprises prediction according to one or more of word use frequency, the user's input preference, language models, syntax rules, and other relevant statistical information.</claim-text></claim><claim id="c-en-0084" num="0084"><claim-text>The method of claim 74, wherein displaying the at least one of the results of the prediction in the key area of the keyboard comprises:
<claim-text>word processing according to system-predefined word display and arrangement rules.</claim-text></claim-text></claim><claim id="c-en-0085" num="0085"><claim-text>The method of claim 84, wherein the system-predefined word display and arrangement rules comprises one or a combination of: letter correspondence-based display; inter-word distance and word length-based display; touch point position and sliding gesture trajectory-based display; and word use frequency, user input preference, language models, syntax rules, context and other relevant statistical information-based display.</claim-text></claim><claim id="c-en-0086" num="0086"><claim-text>The method of claim 85, wherein the letter correspondence-based display comprises first letter correspondence-based display.</claim-text></claim><claim id="c-en-0087" num="0087"><claim-text>The method of claim 86, wherein the first letter comprises a first letter or a first phonetic alphabet.</claim-text></claim><claim id="c-en-0088" num="0088"><claim-text>The method of claim 85, wherein the letter correspondence comprises correspondence to a next letter to be input by the user.</claim-text></claim><claim id="c-en-0089" num="0089"><claim-text>The method of claim 88, wherein the next letter comprises a next letter or a next phonetic alphabet.<!-- EPO <DP n="39"> --></claim-text></claim><claim id="c-en-0090" num="0090"><claim-text>The method of claim 85, wherein the inter-word distance and word length-based display comprises: determining whether target display regions of at least two words are excessively close to each other and, if true, only displaying one of the at least two words with a highest priority level or adjusting the target display region of each other one of the at least two words with a lower priority level.</claim-text></claim><claim id="c-en-0091" num="0091"><claim-text>The method of claim 85, wherein the inter-word distance and word length-based display comprises determining whether a length of a word affects another word to be displayed at an adjacent target display region and, if true, only displaying one of the two words with a high priority level or adjusting the target display region of the other of the two words with a low priority level.</claim-text></claim><claim id="c-en-0092" num="0092"><claim-text>The method of claim 85, wherein the touch point position and sliding gesture trajectory-based display comprises determining whether a target display region of a word is to be blocked by a current touch point and, if true, not displaying the word or adjusting its target display region.</claim-text></claim><claim id="c-en-0093" num="0093"><claim-text>The method of claim 85, wherein the touch point position and sliding gesture trajectory-based display comprises determining whether target display regions of at least two words are to be overlapped or blocked by a trajectory of a current touch point and, if true, for each of the at least two words, further determining, according to their priority levels, whether to display it or adjust its target display region, such that it will not be overlapped or blocked by a possible subsequent extension of the trajectory.</claim-text></claim><claim id="c-en-0094" num="0094"><claim-text>The method of claim 85, further comprising: prioritizing multiple ones of the word display and arrangement rules.</claim-text></claim><claim id="c-en-0095" num="0095"><claim-text>The method of claim 84, wherein displaying the at least one of the results of the prediction in the key area of the keyboard further comprises: displaying at least one of words that have been processed in the key area of the keyboard.</claim-text></claim><claim id="c-en-0096" num="0096"><claim-text>The method of claim 95, wherein displaying the at least one of the words that have been processed in the key area of the keyboard comprises: displaying each of the at least one of the words in a predetermined region of an associated key.</claim-text></claim><claim id="c-en-0097" num="0097"><claim-text>The method of claim 96, wherein the predetermined region is located above, at the top left of, at the top right of, under, at the bottom left of, or at the bottom right of the associated key, or at any position that is spaced apart from the associated key by a distance not exceeding a system-predefined distance threshold.</claim-text></claim><claim id="c-en-0098" num="0098"><claim-text>The method of claim 95, wherein displaying the at least one of the words that have been processed in the key area of the keyboard further comprises: displaying the at least one of the words also in a candidate-word area.</claim-text></claim><claim id="c-en-0099" num="0099"><claim-text>The method of claim 95, wherein displaying the at least one of the words that have been processed in the key area of the keyboard comprises:<!-- EPO <DP n="40"> --> displaying at least one of the results of the prediction of the current possible word in the candidate-word area or a user-defined input area and displaying each of at least one of the results of the prediction of the one or more next possible words in a predetermined region of an associated key.</claim-text></claim><claim id="c-en-0100" num="0100"><claim-text>The method of claim 95, wherein displaying the at least one of the words that have been processed in the key area of the keyboard further comprises: updating displayed content in the key area of the keyboard in a real-time manner according to an input of the user.</claim-text></claim><claim id="c-en-0101" num="0101"><claim-text>The method of claim 74, wherein in the event of the results of the prediction being empty, an indication is given in the form of one or a combination of a visual indication, an auditory indication and a vibration.</claim-text></claim><claim id="c-en-0102" num="0102"><claim-text>A system for continuous sliding gesture-based input text, comprising at least: a dictionary database, adapted to store word information; a user interaction module adapted to process an interaction with a user; a display module, adapted to provide the user with displayed content; and an analysis and processing module, in communication with the dictionary database, user interaction module and display module,<br/>
wherein the user interaction module records information input in an area of a keyboard and transmits it to the analysis and processing module,<br/>
wherein the analysis and processing module receives the information and an event transmitted from the user interaction module, sorts and processes the information and event, obtains a list of words from the dictionary database based on selection rules, and passes the obtained list on to the display module, and<br/>
wherein the display module displays and arranges the words obtained from the analysis and processing module according to system-defined word display and arrangement rules in a key area of the keyboard and feeds information about the results of the display back to the analysis and processing module.</claim-text></claim><claim id="c-en-0103" num="0103"><claim-text>The system of claim 102, wherein the information recorded by the user interaction module comprises at least one of: a tapping, lifting or moving event occurring at a single touch point; a tapping, lifting or moving event occurring at multiple touch points; and coordinate information; and a sliding gesture trajectory.</claim-text></claim><claim id="c-en-0104" num="0104"><claim-text>The system of claim 102, wherein the selection rules on which the analysis and processing module is based to obtain the list of words comprises one or more of: word use frequency, context, the user's previous inputs, language models, syntax rules and other relevant statistical information.</claim-text></claim><claim id="c-en-0105" num="0105"><claim-text>The system of claim 102, wherein the reception, sortation and processing of the analysis and processing module of the information and event received from the user interaction module comprises: the analysis and processing module receiving the information and event transmitted from the user interaction module and determining whether a current action or the event meets<!-- EPO <DP n="41"> --> a system-predefined criterion for triggering a continuous sliding gesture based input mode.</claim-text></claim><claim id="c-en-0106" num="0106"><claim-text>The system of claim 105, wherein the reception, sortation and processing of the analysis and processing module of the information and event received from the user interaction module further comprises: if the system-predefined criterion for triggering the continuous sliding gesture based input mode is met, transmitting information about a current touch point or trajectory, as well as the words obtained from the dictionary database, to the display module which responsively updates the layout of the keyboard according to sys-tem-predefined word display and arrangement rules; and if the sys-tem-predefined criterion for triggering the continuous sliding gesture based input mode is not met, transmitting only the words obtained from the dictionary database to the display module which responsively displays the words according to system-predefined word display and arrangement rules.</claim-text></claim><claim id="c-en-0107" num="0107"><claim-text>The system of claim 102, wherein the reception, sortation and processing of the analysis and processing module of the information and event received from the user interaction module further comprises: determining whether a word meets a system-predefined word selection criterion based on the information about the results of the display fed back from the display module in combination with a trajectory of a current moving or sliding gesture of the user.</claim-text></claim><claim id="c-en-0108" num="0108"><claim-text>The system of claim 107, wherein the reception, sortation and processing of the analysis and processing module of the information and event received from the user interaction module further comprises: if the system-predefined word selection criterion is met, detecting a trajectory of a sliding gesture of the user, and transmitting the word meeting the word selection criterion to an input area or directly causing it to be displayed around a cursor; otherwise, producing no output.</claim-text></claim><claim id="c-en-0109" num="0109"><claim-text>The system of claim 102, wherein the information about the results of the display comprises one or more of: the number, display positions and coordinates of the display positions, of displayed words.</claim-text></claim><claim id="c-en-0110" num="0110"><claim-text>The system of claim 102, wherein the word display and arrangement rules comprises one or a combination of: letter correspondence-based display of a word in a corresponding region in the key area; inter-word distance and word length-based display; touch point position and sliding gesture trajectory-based display; and word use frequency, user input preference, language models, syntax rules, context and other relevant statistical information-based display.</claim-text></claim><claim id="c-en-0111" num="0111"><claim-text>An electronic device, comprising at least a user interaction means and a processor, <b>characterized in that</b> the user interaction means acquires information about an operation of the user and feeds output information back to the user, and <b>in that</b> the processor is adapted to implement the method as defined in claim 1 or 74 based on the acquired information about the operation of the user.<!-- EPO <DP n="42"> --></claim-text></claim><claim id="c-en-0112" num="0112"><claim-text>The electronic device of claim 111, wherein the user interaction means is a touch screen or another sensitive screen for use in electronic devices, equipped with a keyboard.</claim-text></claim><claim id="c-en-0113" num="0113"><claim-text>The electronic device of claim 111, wherein the keyboard has one or more of the following layouts: full-alphabet, half-QWERTY, alphanumeric keypad and user-defined.</claim-text></claim><claim id="c-en-0114" num="0114"><claim-text>The electronic device of claim 111, further comprising a memory for store word information.</claim-text></claim></claims><drawings mxw-id="PDW20422250" load-source="patent-office"><!-- EPO <DP n="43"> --><figure id="f0001" num="1,2"><img id="if0001" file="imgf0001.tif" wi="145" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="44"> --><figure id="f0002" num="3,4"><img id="if0002" file="imgf0002.tif" wi="155" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="45"> --><figure id="f0003" num="5,6"><img id="if0003" file="imgf0003.tif" wi="155" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="46"> --><figure id="f0004" num="7,8"><img id="if0004" file="imgf0004.tif" wi="155" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="47"> --><figure id="f0005" num="9,10"><img id="if0005" file="imgf0005.tif" wi="164" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="48"> --><figure id="f0006" num="11"><img id="if0006" file="imgf0006.tif" wi="164" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="49"> --><figure id="f0007" num="12"><img id="if0007" file="imgf0007.tif" wi="164" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="50"> --><figure id="f0008" num="13"><img id="if0008" file="imgf0008.tif" wi="164" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="51"> --><figure id="f0009" num="14"><img id="if0009" file="imgf0009.tif" wi="164" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="52"> --><figure id="f0010" num="15,16"><img id="if0010" file="imgf0010.tif" wi="158" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="53"> --><figure id="f0011" num="17A"><img id="if0011" file="imgf0011.tif" wi="158" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="54"> --><figure id="f0012" num="17B,17C"><img id="if0012" file="imgf0012.tif" wi="158" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="55"> --><figure id="f0013" num="17D"><img id="if0013" file="imgf0013.tif" wi="158" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="56"> --><figure id="f0014" num="18A"><img id="if0014" file="imgf0014.tif" wi="158" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="57"> --><figure id="f0015" num="18B"><img id="if0015" file="imgf0015.tif" wi="158" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="58"> --><figure id="f0016" num="19"><img id="if0016" file="imgf0016.tif" wi="158" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="59"> --><figure id="f0017" num="20"><img id="if0017" file="imgf0017.tif" wi="158" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="60"> --><figure id="f0018" num="21A"><img id="if0018" file="imgf0018.tif" wi="165" he="176" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="61"> --><figure id="f0019" num="21B"><img id="if0019" file="imgf0019.tif" wi="165" he="176" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="62"> --><figure id="f0020" num="21C,21D"><img id="if0020" file="imgf0020.tif" wi="154" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="63"> --><figure id="f0021" num="21E"><img id="if0021" file="imgf0021.tif" wi="154" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="64"> --><figure id="f0022" num="21F,22A"><img id="if0022" file="imgf0022.tif" wi="154" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="65"> --><figure id="f0023" num="22B,22C"><img id="if0023" file="imgf0023.tif" wi="154" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="66"> --><figure id="f0024" num="22D,22E"><img id="if0024" file="imgf0024.tif" wi="154" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="67"> --><figure id="f0025" num="22F"><img id="if0025" file="imgf0025.tif" wi="154" he="233" img-content="drawing" img-format="tif"/></figure></drawings><search-report-data><doc-page id="srep0001" file="srep0001.tif" wi="165" he="233" type="tif"/><doc-page id="srep0002" file="srep0002.tif" wi="165" he="233" type="tif"/></search-report-data><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
