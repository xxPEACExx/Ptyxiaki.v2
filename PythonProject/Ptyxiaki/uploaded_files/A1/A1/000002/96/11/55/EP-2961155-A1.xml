<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2961155-A1" country="EP" doc-number="2961155" kind="A1" date="20151230" family-id="51410006" file-reference-id="311210" date-produced="20180824" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="160451187" ucid="EP-2961155-A1"><document-id><country>EP</country><doc-number>2961155</doc-number><kind>A1</kind><date>20151230</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-15173066-A" is-representative="YES"><document-id mxw-id="PAPP193865342" load-source="docdb" format="epo"><country>EP</country><doc-number>15173066</doc-number><kind>A</kind><date>20150622</date><lang>EN</lang></document-id><document-id mxw-id="PAPP193865343" load-source="patent-office" format="original"><country>EP</country><doc-number>15173066.0</doc-number><date>20150622</date><lang>EN</lang></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC162030361" ucid="GB-201411165-A" load-source="docdb"><document-id format="epo"><country>GB</country><doc-number>201411165</doc-number><kind>A</kind><date>20140624</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL-1988519869" load-source="docdb">H04N   5/232       20060101AFI20150925BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-1984697870" load-source="docdb" scheme="CPC">G06T   1/0007      20130101 LI20151224BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1984698894" load-source="docdb" scheme="CPC">H04N   5/23296     20130101 LI20160106BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1984705386" load-source="docdb" scheme="CPC">G06T   3/40        20130101 FI20151224BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT165545027" lang="DE" load-source="patent-office">EIN VERFAHREN UND GERÄT ZUR AUFNAHME UND ZUR BETRACHTUNG VON BILDERN</invention-title><invention-title mxw-id="PT165545028" lang="EN" load-source="patent-office">A METHOD AND AN APPARATUS FOR IMAGE CAPTURING AND VIEWING</invention-title><invention-title mxw-id="PT165545029" lang="FR" load-source="patent-office">PROCÉDÉ ET SYSTÈME POUR CAPTURER ET VISUALISER UNE IMAGE</invention-title><citations><patent-citations><patcit mxw-id="PCIT371138670" load-source="docdb" ucid="EP-2866433-A1"><document-id format="epo"><country>EP</country><doc-number>2866433</doc-number><kind>A1</kind><date>20150429</date></document-id><sources><source name="SEA" category="P" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335961709" load-source="docdb" ucid="US-20120194707-A1"><document-id format="epo"><country>US</country><doc-number>20120194707</doc-number><kind>A1</kind><date>20120802</date></document-id><sources><source name="SEA" category="Y" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335961710" load-source="docdb" ucid="US-20120257072-A1"><document-id format="epo"><country>US</country><doc-number>20120257072</doc-number><kind>A1</kind><date>20121011</date></document-id><sources><source name="SEA" category="Y" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT371138669" load-source="docdb" ucid="US-20140211070-A1"><document-id format="epo"><country>US</country><doc-number>20140211070</doc-number><kind>A1</kind><date>20140731</date></document-id><sources><source name="SEA" category="P" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT371138667" load-source="docdb" ucid="WO-2013047481-A1"><document-id format="epo"><country>WO</country><doc-number>2013047481</doc-number><kind>A1</kind><date>20130404</date></document-id><sources><source name="SEA" category="XY" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT371138668" load-source="docdb" ucid="WO-2013190880-A1"><document-id format="epo"><country>WO</country><doc-number>2013190880</doc-number><kind>A1</kind><date>20131227</date></document-id><sources><source name="SEA" category="XYI" created-by-npl="N"/></sources></patcit></patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR1103338229" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>NOKIA TECHNOLOGIES OY</last-name><address><country>FI</country></address></addressbook></applicant><applicant mxw-id="PPAR1103316272" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>NOKIA TECHNOLOGIES OY</last-name></addressbook></applicant><applicant mxw-id="PPAR1101645084" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Nokia Technologies Oy</last-name><iid>101515657</iid><address><street>Karaportti 3</street><city>02610 Espoo</city><country>FI</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR1103332486" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>TARVAINEN TOMI</last-name><address><country>FI</country></address></addressbook></inventor><inventor mxw-id="PPAR1103312871" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>TARVAINEN, TOMI</last-name></addressbook></inventor><inventor mxw-id="PPAR1101646741" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>TARVAINEN, TOMI</last-name><address><street>Keltarousku 8</street><city>02730 Espoo</city><country>FI</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR1101642124" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Nokia Corporation</last-name><iid>101452932</iid><address><street>Intellectual Property Department Karakaari 7</street><city>02610 Espoo</city><country>FI</country></address></addressbook></agent></agents></parties><international-convention-data><designated-states><ep-contracting-states><country mxw-id="DS660605363" load-source="docdb">AL</country><country mxw-id="DS660782076" load-source="docdb">AT</country><country mxw-id="DS660605365" load-source="docdb">BE</country><country mxw-id="DS660683619" load-source="docdb">BG</country><country mxw-id="DS660681193" load-source="docdb">CH</country><country mxw-id="DS660605127" load-source="docdb">CY</country><country mxw-id="DS660782077" load-source="docdb">CZ</country><country mxw-id="DS660605366" load-source="docdb">DE</country><country mxw-id="DS660605128" load-source="docdb">DK</country><country mxw-id="DS660605129" load-source="docdb">EE</country><country mxw-id="DS660681072" load-source="docdb">ES</country><country mxw-id="DS660683620" load-source="docdb">FI</country><country mxw-id="DS660681194" load-source="docdb">FR</country><country mxw-id="DS660605371" load-source="docdb">GB</country><country mxw-id="DS660605130" load-source="docdb">GR</country><country mxw-id="DS660605372" load-source="docdb">HR</country><country mxw-id="DS660782078" load-source="docdb">HU</country><country mxw-id="DS660681073" load-source="docdb">IE</country><country mxw-id="DS660605139" load-source="docdb">IS</country><country mxw-id="DS660681199" load-source="docdb">IT</country><country mxw-id="DS660605140" load-source="docdb">LI</country><country mxw-id="DS660683621" load-source="docdb">LT</country><country mxw-id="DS660603714" load-source="docdb">LU</country><country mxw-id="DS660683622" load-source="docdb">LV</country><country mxw-id="DS660683627" load-source="docdb">MC</country><country mxw-id="DS660603715" load-source="docdb">MK</country><country mxw-id="DS660603716" load-source="docdb">MT</country><country mxw-id="DS660681074" load-source="docdb">NL</country><country mxw-id="DS660681196" load-source="docdb">NO</country><country mxw-id="DS660681091" load-source="docdb">PL</country><country mxw-id="DS660683628" load-source="docdb">PT</country><country mxw-id="DS660782079" load-source="docdb">RO</country><country mxw-id="DS660683629" load-source="docdb">RS</country><country mxw-id="DS660681092" load-source="docdb">SE</country><country mxw-id="DS660681200" load-source="docdb">SI</country><country mxw-id="DS660681197" load-source="docdb">SK</country><country mxw-id="DS660681198" load-source="docdb">SM</country><country mxw-id="DS660603717" load-source="docdb">TR</country></ep-contracting-states><ep-extended-states><ep-extended-state-data><country>BA</country></ep-extended-state-data><ep-extended-state-data><country>ME</country></ep-extended-state-data></ep-extended-states></designated-states></international-convention-data></bibliographic-data><abstract mxw-id="PA166479557" lang="EN" load-source="patent-office"><p id="pa01" num="0001">The invention relates to a method, comprising receiving a file storing at least image data and information on a focus point; generating a zoom effect for an image being represented by said image data, said zoom effect comprising image frames having a same resolution, wherein each image frame comprises a more zoomed content of the image than the previous image frame starting from a first frame comprising a full content of the image, proceeding towards the focus point and ending to a last frame comprising a portion of the content of the image. Further, there is a method comprising capturing an image by an imaging device, said imaging device being focused on a focus point in said image; determining an end point of a zoom; saving in a file the image data, an information on the focus point and an information of the end point of a zoom. The invention also relates to technical equipment for implementing a method.
<img id="iaf01" file="imgaf001.tif" wi="150" he="102" img-content="drawing" img-format="tif"/></p></abstract><abstract mxw-id="PA166759369" lang="EN" source="EPO" load-source="docdb"><p>The invention relates to a method, comprising receiving a file storing at least image data and information on a focus point; generating a zoom effect for an image being represented by said image data, said zoom effect comprising image frames having a same resolution, wherein each image frame comprises a more zoomed content of the image than the previous image frame starting from a first frame comprising a full content of the image, proceeding towards the focus point and ending to a last frame comprising a portion of the content of the image. Further, there is a method comprising capturing an image by an imaging device, said imaging device being focused on a focus point in said image; determining an end point of a zoom; saving in a file the image data, an information on the focus point and an information of the end point of a zoom. The invention also relates to technical equipment for implementing a method.</p></abstract><description mxw-id="PDES98404258" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><heading id="h0001"><u>Technical Field</u></heading><p id="p0001" num="0001">The present embodiments relate to a method for capturing images and viewing images. The embodiments also relate to an apparatus and a computer program product for capturing images and viewing images.</p><heading id="h0002"><u>Background</u></heading><p id="p0002" num="0002">This section is intended to provide a background or context to the invention that is recited in the claims. The description herein may include concepts that could be pursued, but are not necessarily ones that have been previously conceived or pursued. Therefore, unless otherwise indicated herein, what is described in this section is not prior art to the description and claims in this application and is not admitted to be prior art by inclusion in this section.</p><p id="p0003" num="0003">Today, there are imaging technologies in great variety of devices. Because of this, photographing has become one of the popular ways to share memories, moments or stories between people. There are different kinds of applications giving a possibility to photographers to enhance the message the image provides, for example enhancing colours or modifying objects with different functions.</p><p id="p0004" num="0004">However, there is a need for an improved solution that gives a photographer a possibility to express his/her message with the image.</p><heading id="h0003"><u>Summary</u></heading><p id="p0005" num="0005">Now there has been invented an improved method and technical equipment implementing the method, by which the above problems are alleviated. Various aspects of the invention include a method, an apparatus and a computer readable medium comprising a computer program stored therein, which are characterized by what is stated in the independent claims. Various embodiments of the invention are disclosed in the dependent claims.<!-- EPO <DP n="2"> --></p><p id="p0006" num="0006">According to a first aspect there is provided a method, comprising receiving a file storing image data and information on a used focus point; generating a zoom effect for an image being represented by said image data, said zoom effect comprising sequential image frames having a same resolution, wherein each image frame comprises a more zoomed view of the image than the previous image frame starting from a first frame comprising substantially a full content of the image, proceeding towards the focus point and ending to a last frame comprising a portion of the content of the image.</p><p id="p0007" num="0007">According to a second aspect, there is provided an apparatus comprising at least one processor, memory including computer program code, the memory and the computer program code configured to, with the at least one processor, cause the apparatus to perform at least the following: receiving a file storing image data and information on a used focus point; generating a zoom effect for an image being represented by said image data, said zoom effect comprising sequential image frames having a same resolution, wherein each image frame comprises a more zoomed view of the image than the previous image frame starting from a first frame comprising substantially a full content of the image proceeding towards the focus point and ending to a last frame comprising a portion of the content of the image.</p><p id="p0008" num="0008">According to a third aspect, there is provided a computer program product embodied on a non-transitory computer readable medium, comprising computer program code configured to, when executed on at least one processor, cause an apparatus or a system to receive a file storing image data and information on a used focus point; to generate a zoom effect for an image being represented by said image data, said zoom effect comprising sequential image frames having a same resolution, wherein each image frame comprises a more zoomed view of the image than the previous image frame starting from a first frame comprising substantially a full content of the image, proceeding towards the focus point and ending to a last frame comprising a portion of the content of the image.</p><p id="p0009" num="0009">According to an embodiment the last frame is determined by an elapsed time being set automatically or by a user from the start of the zoom.</p><p id="p0010" num="0010">According to an embodiment, the file being received comprises also information on an end point of zoom, wherein the last frame comprises such portion of the content that corresponds the end point of the zoom.<!-- EPO <DP n="3"> --></p><p id="p0011" num="0011">According to an embodiment the image frames are rendered to a display device.</p><p id="p0012" num="0012">According to an embodiment a video file is generated of said image frames.</p><p id="p0013" num="0013">According to an embodiment the resolution of the frames is selected to be the same or less than the resolution of the area near the focus point.</p><p id="p0014" num="0014">According to an embodiment the file is received from an imaging device.</p><p id="p0015" num="0015">According to an embodiment at least one of the information on the focus point and the end point of the zoom is stored to a metadata of the file.</p><p id="p0016" num="0016">According to a fourth aspect, there is provided a method comprising capturing an image by an imaging device, said imaging device being focused on a focus point in said image; determining an end point of a zoom; and saving in a file the image data, an information on the focus point and an information of the end point of a zoom.</p><p id="p0017" num="0017">According to a fifth aspect, there is provided an apparatus comprising at least one processor, memory including computer program code, the memory and the computer program code configured to, with the at least one processor, cause the apparatus to perform at least the following: capturing an image by an imaging device, said imaging device being focused on a focus point in said image; determining an end point of a zoom; and saving in a file the image data, an information on the focus point and an information of the end point of a zoom.</p><p id="p0018" num="0018">According to a sixth aspect, there is provided a computer program product embodied on a non-transitory computer readable medium, comprising computer program code configured to, when executed on at least one processor, cause an apparatus or a system to capture an image by an imaging device, said imaging device being focused on a focus point in said image; determine an end point of a zoom; and save in a file the image data, an information on the focus point and an information of the end point of a zoom.</p><p id="p0019" num="0019">According to an embodiment the focus point is e.g. the center point of the area, for which the camera focused for the captured image for example based on continuous-auto-focus, face detection or touch-to-focus etc.<!-- EPO <DP n="4"> --></p><p id="p0020" num="0020">According to an embodiment the end point of a zoom is determined automatically by a zooming coefficient and the information on the focus point.</p><p id="p0021" num="0021">According to an embodiment the end point of a zoom is determined by an area falling within certain pixels.</p><p id="p0022" num="0022">According to an embodiment the end point of a zoom is determined automatically based on a certain object in the image.</p><p id="p0023" num="0023">According to an embodiment the end point of a zoom is received as a user input.</p><p id="p0024" num="0024">According to an embodiment the user input comprises an area in the image that is to be zoomed.</p><heading id="h0004"><u>Description of the Drawings</u></heading><p id="p0025" num="0025">In the following, various embodiments of the invention will be described in more detail with reference to the appended drawings, in which
<dl id="dl0001" compact="compact"><dt>Fig. 1</dt><dd>shows a simplified block chart of an apparatus according to an embodiment;</dd><dt>Fig. 2</dt><dd>shows a layout of an apparatus according to an embodiment;</dd><dt>Fig. 3</dt><dd>shows a system configuration according to an embodiment;</dd><dt>Fig. 4</dt><dd>shows an example of an image;</dd><dt>Fig. 5</dt><dd>shows an example of a generating a zoom effect for an image;</dd><dt>Fig. 6</dt><dd>shows a flowchart of a method according to an embodiment; and</dd><dt>Fig. 7</dt><dd>shows a flowchart of a method according to an embodiment.</dd></dl></p><heading id="h0005"><u>Description of Example Embodiments</u></heading><!-- EPO <DP n="5"> --><p id="p0026" num="0026"><figref idrefs="f0001">Figures 1 and 2</figref> illustrate an apparatus according to an embodiment. The apparatus 50 is an electronic device for example a mobile terminal or a user equipment of a wireless communication system. The embodiments disclosed in this application can be implemented within any electronic device or apparatus which is able to process image data, such as still images, alternatively also video images. The apparatus 50 may comprise a housing 30 for incorporating and protecting the device. The apparatus 50 may further comprise a display 32 in the form of a liquid crystal display or LED (Light Emitting Diodes) display. According to an embodiment, the display may be any suitable display technology suitable to display an image or video. The apparatus 50 may further comprise a keypad 34. According to an embodiment, any suitable data or user interface mechanism may be employed. For example, the user interface may be implemented as a virtual keyboard or data entry system as part of a touch-sensitive display. The apparatus may comprise a microphone 36 or any suitable audio input which may be a digital or analogue signal input. The apparatus 50 may further comprise an audio output device, which may be any of the following: an earpiece 38, a speaker or an analogue audio or digital audio output connection. The apparatus 50 may also comprise a battery (according to another embodiment, the device may be powered by any suitable mobile energy device, such as solar cell, fuel cell or clockwork generator). The apparatus may further comprise a camera 42 capable of recording or capturing images and/or video, or may be connected to one. The camera 42 may be capable of recording or detecting individual frames which are then passed to the codec 54 or controller for processing. According to an embodiment, the apparatus may receive the image data for processing from another device prior to transmission and/or storage. According to an embodiment, the apparatus 50 may receive either wirelessly or by a wired connection the image for processing. The camera 42 comprises an image sensor for converting an optical image into an electronic signal. The image sensor may be a CCD (Charge-Coupled Device) sensor or a CMOS (Complementary metal-oxide-semiconductor) sensor.</p><p id="p0027" num="0027">According to an embodiment, the apparatus 50 may further comprise an infrared port for short range line of sight communication to other devices. According to an embodiment, the apparatus 50 may further comprise any suitable short range communication solution such as for example a Bluetooth wireless connection or a USB/firewire wired solution.</p><p id="p0028" num="0028">The apparatus 50 may comprise a controller 56 or processor for controlling the apparatus. The controller 56 may be connected to memory 58 which, according to<!-- EPO <DP n="6"> --> an embodiment, may store both data in the form of image and audio data and/or may also store instructions for implementation on the controller 56. The controller 56 may further be connected to codec circuitry 54 suitable for carrying out coding and decoding or audio and/or video data or assisting in coding and decoding carried out by the controller 56.</p><p id="p0029" num="0029">The apparatus 50 may further comprise a card reader 48 and a smart card 46, for example a UICC and UICC reader for providing user information and being suitable for providing authentication information for authentication and authorization of the user at a network.</p><p id="p0030" num="0030">The apparatus 50 may comprise radio interface circuitry 52 connected to the controller and suitable for generating wireless communication signals for example for communication with a cellular communications network, a wireless communications system or a wireless local area network. The apparatus 50 may further comprise an antenna 44 connected to the radio interface circuitry 52 for transmitting radio frequency signals generated at the radio interface circuitry 52 to other apparatus(es) and for receiving radio frequency signals from other apparatus(es).</p><p id="p0031" num="0031"><figref idrefs="f0002">Figure 3</figref> shows a system configuration comprising a plurality of apparatuses, networks and network elements according to an embodiment. The system 10 comprises multiple communication devices which can communicate through one or more networks. The system 10 may comprise any combination of wired or wireless networks including, but not limited to a wireless cellular telephone network (such as a GSM, UMTS, CDMA network, etc.), a wireless local area network (WLAN), such as defined by any of the IEEE 802.x standards, a Bluetooth personal area network, an Ethernet local area network, a token ring local area network, a wide area network, and the internet.</p><p id="p0032" num="0032">The system 10 may include both wired and wireless communication devices or apparatus 50 suitable for implementing present embodiments. For example, the system shown in <figref idrefs="f0002">Figure 3</figref> shows a mobile telephone network 11 and a representation of the internet 28. Connectivity to the internet 28 may include, but is not limited to, long range wireless connections, short range wireless connections, and various wired connections including, but not limited to, telephone lines, cable lines, power lines, and similar communication pathways.<!-- EPO <DP n="7"> --></p><p id="p0033" num="0033">The example communication devices shown in the system 10 may include but are not limited to, an electronic device or apparatus 50, a combination of a personal digital assistant (PDA) and a mobile telephone 14, a PDA 16, an integrated messaging device (IMD) 18, a desktop computer 20, a notebook computer 22, a digital camera. The apparatus 50 may be stationary or mobile when carried by an individual who is moving. The apparatus 50 may also be located in a mode of transport.</p><p id="p0034" num="0034">Some of further apparatus may send and receive calls and messages and communicate with service providers through a wireless connection 25 to a base station 24. The base station 24 may be connected to a network server 26 that allows communication between the mobile telephone network 11 and the internet 28. The system may include additional communication devices and communication devices of various types.</p><p id="p0035" num="0035">The communication devices may communicate using various transmission technologies including, but not limited to, code division multiple access (CDMA), global systems for mobile communications (GSM), universal mobile telephone system (UMTS), time divisional multiple access (TDMA), frequency division multiple access (FDMA), transmission control protocol-internet protocol (TCP-IP), short messaging service (SMS), multimedia messaging service (MMS), email, instant messaging service (IMS), Bluetooth, IEEE 802.11 and any similar wireless communication technology. A communications device involved in implementing various embodiments of the present invention may communicate using various media including, but not limited to, radio infrared, laser, cable connections or any suitable connection.</p><p id="p0036" num="0036">For many camera devices, it is known to automatically zoom a picture for a predetermined time after a snap, to help the photographer to check if the image is sharp. For example, a publication <patcit id="pcit0001" dnum="US2012257072A"><text>US 2012257072</text></patcit> discloses a smart-zoom that is based on a focus point in the image. Some of the known solutions record view finder frames and turn it to video so that the viewing experience is not "dead" by the moment before the picture is live. This problem with this and the other methods of capturing the emotion from the moment is the fact that the resulted still image is still "dead".<!-- EPO <DP n="8"> --></p><p id="p0037" num="0037">The present embodiments are targeted to a solution where viewer of an image is given indication of what part of the image a photographer considered interesting. This can be achieved by zooming the image towards a focus point, which creates an effect of watching a video. In particular, the present embodiments are targeted to very high resolution image sensors, such as in PureView cameras, which makes it possible to zoom a picture so that the zoomed picture is not pixelized.</p><p id="p0038" num="0038">In order to implement such a solution, a file that stores image data and information on a focus point is received by an application. According to an embodiment, the file comprises also information on an end point of a zoom. The end point of a zoom can be defined to be an area in the image content that is desired to be the zoomed content, i.e. the portion of the image content that is shown in a zoomed view. If the image size is 10000x7000, then the zoomed portion of the image content can represented by an area within pixels (x1, y1, x2, y2). Alternatively, the zoomed portion of the image content can be represented by an area within pixels (x, y, width, height), wherein the area is defined with upper left corner, and width and height). Yet, alternatively the zoomed portion of the image content can be represented by an area having a focus point (x, y) and where the zooming coefficient is k.</p><p id="p0039" num="0039">The application may be located on an imaging device, on a client device, on a server device, or on any other image processing device. The application obtains the information on the focus point and uses the information for creating a zoom effect for the image that is represented by the image data. The zoom effect is generated of image frames that have a same resolution. The image frames comprises image data in such a manner that each image frame comprises a more zoomed view of the image than the previous image starting from a frame containing a full content of the image and ending to a last frame containing a portion of the content of the image, which portion - according to an embodiment - corresponds an area near to the focus point. According to another embodiment, the last frame contains such portion of the image content that corresponds the end point of the zoom. The end point of the zoom may have been determined automatically or manually.</p><p id="p0040" num="0040">According to an embodiment, the file comprising at least the image data and the information on the focus point is received from a camera device. The image may have been captured by said camera device being targeted to a view and focused by a focus point. According to an embodiment, the focus point is determined automatically by the camera device. According to an embodiment, the focus point is<!-- EPO <DP n="9"> --> determined manually by the photographer selecting a certain location or point in the view by using a user interface of the camera. Also information on the end point of the zoom may be determined. The determination may be based on automatic determination based on a certain object in the view or manual determination made by the photographer.</p><p id="p0041" num="0041">The image being captured by the camera is stored as an image file. In addition to the image data, the file stores information on the focus point and the end point of the zoom if available. This information can be stored as a metadata of the file. The captured image can be shared to another user having the application for generating the zoom effect, or processed in said camera device having said application for generating the zoom effect. When viewing the image, the viewing application enables automatic zooming of the picture from a full screen towards the focus point.</p><p id="p0042" num="0042">According to an embodiment, the application is a video maker that generates e.g. a MPEG (Moving Picture Experts Group) video of the image frames, which video thus shows the zooming process. According to an embodiment, the video showing the zooming process is generated at the time the image is captured and stored.</p><p id="p0043" num="0043">Instead of video maker, the viewing application may be a still image viewer that is configured to decode the still image representation of the image frames generating the zoom effect. According to an embodiment, the viewing application may simply read the focus point information from the metadata of the image file and automatically performing a smooth zoom from full view to the focus point. Such an operation looks like a video for a viewing user.</p><p id="p0044" num="0044">The camera device may have higher resolution than what is needed for viewing the zoomed image, so that the resolution of the image in the zooming will be constant without pixelization. Pixelization occurs when a image of low resolution is zoomed, and single pixels are seen as squares. For example, if the images from the camera device have resolution of 10000*7000 pixels, and the zoomed image has resolution of 1000*700 pixels, the resolution of zoom effect may be 1000*700 pixels at the maximum. This prevents the pixelization.</p><p id="p0045" num="0045">The embodiments from a photographer's (i.e. user's) point of view is illustrated in <figref idrefs="f0003">Figure 4</figref>. A user has a camera device targeted to a view 400 that is to be captured by the camera device. The view 400 is displayed on a viewer of the camera device<!-- EPO <DP n="10"> --> to give the user a possibility to adjust the imaging settings. On the viewer is also shown a focus point 410 that is determined automatically by the camera device or zoomed by the user. For example, if the user defines a target zoom area manually zooming to a certain level, the currently visible view can be set to be the end point of the zoom in addition to the focus point 410.</p><p id="p0046" num="0046">The focus point 410 points to a certain area or object or part of an object in the view 400. When the user taps (or selects, activates, presses) the capturing button, the camera captures the picture of the view 400. In addition to this, the camera roll viewer continues to zoom gently towards the focus point 410 of the capture without any further user action. The user can tap the view (or a capturing button) any time to stop the zooming to have the end point for the zoom, which makes the camera viewer to return to the full view 400. The image can then be stored with the information on the focus point with or without the information on the end point of the zoom. The image can also be shared for further use.</p><p id="p0047" num="0047">The image is then received by an application that generates the smooth zoom effect. This is illustrated in <figref idrefs="f0004">Figure 5</figref> in a simplified manner. The zoom effect is generated so that the image is split into frames 500, 510, 520 having a same resolution. Each image frame 510, 520 comprises a more zoomed view than the previous image 500, 510 starting from a full image 500 and ending to an image 520 showing an area near to the focus point. This means that the first frame 500 comprises the full content of the image, while the last frame 520 comprises a zoomed portion of the image content. The last frame can be determined according to a focus point, for example a certain area around the focus point. The last frame can also be determined according to an end point of a zoom and the information on the focus point. According to an embodiment, the last frame is selected to contain a certain object, e.g. a face.</p><p id="p0048" num="0048">This representation of frames 500, 510, 520 may be stored as a video, as a video clip (for example 6-10 seconds) showing the zooming process from the full view 500 towards the focus point 520. After or together with the storing, the image can also be shared to other users. When sharing, the user may add a caption to the image. This caption is also stored to a metadata of the image file and displayed with the image when viewed.<!-- EPO <DP n="11"> --></p><p id="p0049" num="0049">An embodiment from an image viewer's point of view is disclosed also with reference to <figref idrefs="f0004">Figure 5</figref>. The viewer opening the stored or shared image uses a viewing application for opening the image. Depending on the format how the image was stored, the image is viewed accordingly. For example, the image as a video clip is shown as a video showing the zooming process from a full view to the focus point. Alternatively, the image as a still image is shown by reading the information on the focus point, and the performing a smooth zoom from a full view to the focus point by the viewing application while the viewing user is viewing the image. In both cases, the image viewing begins from the full view 500. Then the image is slightly zoomed towards the content 520 that is indicated by the focus point with or without the information on the end point of the zoom. Between the full content 500 and the zoomed content 520, there are several "frames" 510 that comprise ever closer-getting content.</p><p id="p0050" num="0050">A method according to an embodiment is illustrated in <figref idrefs="f0005">Figure 6</figref>. In the method, a file storing at least image data and information on a focus point is received 610. Then a zoom effect for an image being represented by said image data is generated. The zoom effect comprises image frames having a same resolution, wherein each image frame comprises a more zoomed view of the image than the previous image frame starting from a frame that contains the full content of image and ending to a frame containing a portion of the content of the image, which portion may e.g. correspond an area near to the focus point.</p><p id="p0051" num="0051">As said, the last frame of the zooming effect can be selected automatically to be the frame comprising a portion of the image content, which portion corresponds the area near to the focus point or an area defined by an information on the end point of a zoom. The automatic selection of the last frame for the zooming effect can further be expanded so that the last frame is a frame that contains a certain object of the image. For example, by utilizing known object recognition algorithms, a frame that contains a face is automatically selected as the last frame and the zooming effect is ended there.</p><p id="p0052" num="0052">An image capturing method is illustrated in <figref idrefs="f0006">Figure 7</figref>. In the method the image is captured 710 by an imaging device, said imaging device being focused on a focus point in said image. An end point of a zoom is determined 720, and the image data, an information on the focus point and an information of the end point of a zoom are saved in a file.<!-- EPO <DP n="12"> --></p><p id="p0053" num="0053">The present embodiments provide a solution that gives a photographer a possibility to express his/her message with the image even more allowing details to be dug out from the photos and making the otherwise still image "live" hence amplify the experience.</p><p id="p0054" num="0054">It is appreciated that the methods illustrated in <figref idrefs="f0005">Figure 6</figref> and <figref idrefs="f0006">7</figref> can be implemented in a same apparatus, or in different apparatuses, that captures the image. The apparatus comprises at least one processor, memory including computer program code, the memory and the computer program code configured to, with the at least one processor, cause the apparatus to perform at least the method shown in <figref idrefs="f0005">Figure 6</figref> or <figref idrefs="f0006">Figure 7</figref>. An apparatus according to an embodiment comprises processing means and memory means and means for performing the method shown in <figref idrefs="f0005">Figure 6</figref> and/or <figref idrefs="f0006">Figure 7</figref>.</p><p id="p0055" num="0055">The various embodiments of the invention can be implemented with the help of computer program code that resides in a memory and causes the relevant apparatuses to carry out the invention. For example, a device may comprise circuitry and electronics for handling, receiving and transmitting data, computer program code in a memory, and a processor that, when running the computer program code, causes the device to carry out the features of an embodiment. Yet further, a network device like a server may comprise circuitry and electronics for handling, receiving and transmitting data, computer program code in a memory, and a processor that, when running the computer program code, causes the network device to carry out the features of an embodiment.</p><p id="p0056" num="0056">It is obvious that the present invention is not limited solely to the above-presented embodiments, but it can be modified within the scope of the appended claims.</p></description><claims mxw-id="PCLM90459188" lang="EN" load-source="patent-office"><!-- EPO <DP n="13"> --><claim id="c-en-0001" num="0001"><claim-text>A method, comprising:
<claim-text>- receiving a file storing at least image data and information on a used focus point;</claim-text>
<claim-text>- generating a zoom effect for an image being represented by said image data, said zoom effect comprising image frames having a same resolution, wherein each image frame comprises a more zoomed content of the image than the previous image frame starting from a first frame comprising substantially a full content of the image, proceeding towards the focus point and ending to a last frame comprising a portion of the content of the image.</claim-text></claim-text></claim><claim id="c-en-0002" num="0002"><claim-text>The method according to claim 1, wherein the last frame is determined by an elapsed time from the start of the zoom, which time is automatically or manually set.</claim-text></claim><claim id="c-en-0003" num="0003"><claim-text>The method according to claim 1 or 2, wherein the file being received comprises also information on an end point of zoom, wherein the last frame comprises such portion of the content that corresponds the end point of the zoom.</claim-text></claim><claim id="c-en-0004" num="0004"><claim-text>The method according to any of the claims 1 to 3, further comprising rendering the image frames to a display device.</claim-text></claim><claim id="c-en-0005" num="0005"><claim-text>The method according any of the claims 1 to 4, further comprising generating a video file of said image frames.</claim-text></claim><claim id="c-en-0006" num="0006"><claim-text>The method according to any of the previous claims 1 to 5, wherein the resolution of the frames is selected to be the same or less than the resolution of the area near the focus point.</claim-text></claim><claim id="c-en-0007" num="0007"><claim-text>The method according to any of the previous claims 1 to 6, wherein the file is received from an imaging device.</claim-text></claim><claim id="c-en-0008" num="0008"><claim-text>The method according to any of the previous claims 3 to 7, wherein at least one of the information on the focus point and the end point of the zoom is stored to a metadata of the file.<!-- EPO <DP n="14"> --></claim-text></claim><claim id="c-en-0009" num="0009"><claim-text>An apparatus comprising at least one processor, memory including computer program code, the memory and the computer program code configured to, with the at least one processor, cause the apparatus to perform at least the following:
<claim-text>- receiving a file storing image data and information on a used focus point;</claim-text>
<claim-text>- generating a zoom effect for an image being represented by said image data, said zoom effect comprising image frames having a same resolution, wherein each image frame comprises a more zoomed content of the image than the previous image frame starting from a first frame comprising substantially a full content of the image, proceeding towards the focus point and ending to a last frame comprising a portion of the content of the image.</claim-text></claim-text></claim><claim id="c-en-0010" num="0010"><claim-text>The apparatus according to claim 9, wherein the file being received comprises also information on an end point of zoom, wherein the last frame comprises such portion of the content that corresponds the end point of the zoom.</claim-text></claim><claim id="c-en-0011" num="0011"><claim-text>The apparatus according to claim 9 or 10, further comprising computer program code to cause the apparatus to render the image frames to a display device.</claim-text></claim><claim id="c-en-0012" num="0012"><claim-text>The apparatus according to claim 9 or 10 or 11, further comprising computer program code to cause the apparatus to generate a video file of said image frames.</claim-text></claim><claim id="c-en-0013" num="0013"><claim-text>The apparatus according to any of the previous claims 9 to 12, wherein the resolution of the frames is selected to be the same or less than the resolution of the area near the focus point.</claim-text></claim><claim id="c-en-0014" num="0014"><claim-text>The apparatus according to any of the previous claims 9 to 13, wherein the file is received from an imaging device.</claim-text></claim><claim id="c-en-0015" num="0015"><claim-text>The apparatus according to any of the previous claims 10 to 14, wherein at least one of the information on the focus point and the end point of the zoom is stored to a metadata of the file.</claim-text></claim><claim id="c-en-0016" num="0016"><claim-text>A computer program product embodied on a non-transitory computer readable medium, comprising computer program code configured to, when executed on at least one processor, cause an apparatus or a system to perform the steps of the method as claimed in any of the claims 1 to 8.</claim-text></claim></claims><drawings mxw-id="PDW20421924" load-source="patent-office"><!-- EPO <DP n="15"> --><figure id="f0001" num="1,2"><img id="if0001" file="imgf0001.tif" wi="139" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="16"> --><figure id="f0002" num="3"><img id="if0002" file="imgf0002.tif" wi="157" he="225" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="17"> --><figure id="f0003" num="4"><img id="if0003" file="imgf0003.tif" wi="141" he="188" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="18"> --><figure id="f0004" num="5"><img id="if0004" file="imgf0004.tif" wi="160" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="19"> --><figure id="f0005" num="6"><img id="if0005" file="imgf0005.tif" wi="165" he="167" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="20"> --><figure id="f0006" num="7"><img id="if0006" file="imgf0006.tif" wi="165" he="167" img-content="drawing" img-format="tif"/></figure></drawings><search-report-data><doc-page id="srep0001" file="srep0001.tif" wi="156" he="233" type="tif"/><doc-page id="srep0002" file="srep0002.tif" wi="156" he="233" type="tif"/></search-report-data><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
