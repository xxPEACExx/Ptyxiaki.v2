<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2961184-A1" country="EP" doc-number="2961184" kind="A1" date="20151230" family-id="47714825" file-reference-id="287615" date-produced="20180824" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="160451158" ucid="EP-2961184-A1"><document-id><country>EP</country><doc-number>2961184</doc-number><kind>A1</kind><date>20151230</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-15171650-A" is-representative="NO"><document-id mxw-id="PAPP193865284" load-source="patent-office" format="original"><country>EP</country><doc-number>15171650.3</doc-number><date>20120806</date><lang>EN</lang></document-id><document-id mxw-id="PAPP193865285" load-source="docdb" format="epo"><country>EP</country><doc-number>15171650</doc-number><kind>A</kind><date>20120806</date><lang>EN</lang></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC162029469" ucid="EP-12824321-A" linkage-type="3" load-source="docdb"><document-id format="epo"><country>EP</country><doc-number>12824321</doc-number><kind>A</kind><date>20120806</date></document-id></priority-claim><priority-claim mxw-id="PPC162028770" ucid="US-201161523413-P" load-source="docdb"><document-id format="epo"><country>US</country><doc-number>201161523413</doc-number><kind>P</kind><date>20110815</date></document-id></priority-claim><priority-claim mxw-id="PPC162027149" ucid="US-201161538876-P" load-source="docdb"><document-id format="epo"><country>US</country><doc-number>201161538876</doc-number><kind>P</kind><date>20110925</date></document-id></priority-claim><priority-claim mxw-id="PPC162036010" ucid="US-201161559166-P" load-source="docdb"><document-id format="epo"><country>US</country><doc-number>201161559166</doc-number><kind>P</kind><date>20111114</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL-1988521738" load-source="docdb">H04N  21/81        20110101AFI20150831BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-1988526829" load-source="docdb">H04N  21/84        20110101ALI20150831BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-1897318000" load-source="docdb" scheme="CPC">H04N  21/8173      20130101 LI20160910BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1897318001" load-source="docdb" scheme="CPC">H04N  21/42201     20130101 LI20160909BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1897318002" load-source="docdb" scheme="CPC">H04M   3/567       20130101 LI20160909BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1897318003" load-source="docdb" scheme="CPC">H04N  21/4786      20130101 LI20160909BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1897318004" load-source="docdb" scheme="CPC">H04N  21/42203     20130101 LI20160909BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1897318005" load-source="docdb" scheme="CPC">H04N  21/42202     20130101 LI20160909BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1897318006" load-source="docdb" scheme="CPC">H04N   7/15        20130101 LI20160909BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1957281005" load-source="docdb" scheme="CPC">G06F   3/04817     20130101 LI20160321BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1957281219" load-source="docdb" scheme="CPC">H04N  21/278       20130101 LI20160317BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1957282048" load-source="docdb" scheme="CPC">H04N  21/47202     20130101 LI20160317BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1957282448" load-source="docdb" scheme="CPC">H04N  21/235       20130101 LI20160317BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1957286545" load-source="docdb" scheme="CPC">H04N  21/4334      20130101 LI20160317BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1957286898" load-source="docdb" scheme="CPC">H04N  21/84        20130101 LI20160321BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1957287656" load-source="docdb" scheme="CPC">H04N  21/44222     20130101 LI20160317BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1957288277" load-source="docdb" scheme="CPC">H04N  21/4788      20130101 FI20160321BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987763638" load-source="docdb" scheme="CPC">H04N  21/25891     20130101 LI20150604BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987764754" load-source="docdb" scheme="CPC">H04N  21/632       20130101 LI20150417BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987767707" load-source="docdb" scheme="CPC">H04N  21/44218     20130101 LI20140807BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987767853" load-source="docdb" scheme="CPC">H04N  21/472       20130101 LI20140807BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987769364" load-source="docdb" scheme="CPC">H04N  21/42204     20130101 LI20150417BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987769812" load-source="docdb" scheme="CPC">H04L  67/141       20130101 LI20150611BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987772568" load-source="docdb" scheme="CPC">H04L  51/36        20130101 LI20150622BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987777721" load-source="docdb" scheme="CPC">H04N  21/64784     20130101 LI20150611BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987778655" load-source="docdb" scheme="CPC">H04L  51/046       20130101 LI20150416BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987780996" load-source="docdb" scheme="CPC">H04N  21/8545      20130101 LI20150604BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987782550" load-source="docdb" scheme="CPC">H04N  21/482       20130101 LI20150608BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987782630" load-source="docdb" scheme="CPC">H04N  21/4722      20130101 LI20150618BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987783166" load-source="docdb" scheme="CPC">H04N  21/41407     20130101 LI20150416BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987784124" load-source="docdb" scheme="CPC">H04N  21/4627      20130101 LI20140807BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987784631" load-source="docdb" scheme="CPC">H04N  21/4668      20130101 LI20150613BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987784884" load-source="docdb" scheme="CPC">H04N  21/23418     20130101 LI20150604BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987785092" load-source="docdb" scheme="CPC">H04L  65/4076      20130101 LI20150521BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987788420" load-source="docdb" scheme="CPC">H04N  21/4758      20130101 LI20150521BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987788910" load-source="docdb" scheme="CPC">H04N  21/2393      20130101 LI20150611BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987790428" load-source="docdb" scheme="CPC">H04N  21/4886      20130101 LI20150521BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987793672" load-source="docdb" scheme="CPC">H04L  67/104       20130101 LI20150611BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987795703" load-source="docdb" scheme="CPC">H04N  21/42208     20130101 LI20150416BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987798220" load-source="docdb" scheme="CPC">H04N  21/4312      20130101 LI20150604BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987798753" load-source="docdb" scheme="CPC">G06F   3/04842     20130101 LI20150521BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987798848" load-source="docdb" scheme="CPC">H04N  21/478       20130101 LI20150604BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987799559" load-source="docdb" scheme="CPC">H04L  65/403       20130101 LI20150618BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT165544940" lang="DE" load-source="patent-office">VERFAHREN UND SYSTEME ZUR ERZEUGUNG UND VERWALTUNG VON SITZUNGEN MIT MEHREREN TEILNEHMERN</invention-title><invention-title mxw-id="PT165544941" lang="EN" load-source="patent-office">METHODS AND SYSTEMS FOR CREATING AND MANAGING MULTI PARTICIPANT SESSIONS</invention-title><invention-title mxw-id="PT165544942" lang="FR" load-source="patent-office">PROCÉDÉS ET SYSTÈMES DE CRÉATION ET DE GESTION DE SESSIONS MULTI-PARTICIPANT</invention-title><citations><patent-citations><patcit mxw-id="PCIT401696640" load-source="docdb" ucid="EP-2252055-A1"><document-id format="epo"><country>EP</country><doc-number>2252055</doc-number><kind>A1</kind><date>20101117</date></document-id><sources><source name="SEA" category="XI" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335961669" load-source="docdb" ucid="US-20070280638-A1"><document-id format="epo"><country>US</country><doc-number>20070280638</doc-number><kind>A1</kind><date>20071206</date></document-id><sources><source name="APP" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT401696639" load-source="docdb" ucid="US-20080034392-A1"><document-id format="epo"><country>US</country><doc-number>20080034392</doc-number><kind>A1</kind><date>20080207</date></document-id><sources><source name="SEA" category="XI" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335961671" load-source="docdb" ucid="US-20080141303-A1"><document-id format="epo"><country>US</country><doc-number>20080141303</doc-number><kind>A1</kind><date>20080612</date></document-id><sources><source name="SEA" category="A" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335961673" load-source="docdb" ucid="US-20110173300-A1"><document-id format="epo"><country>US</country><doc-number>20110173300</doc-number><kind>A1</kind><date>20110714</date></document-id><sources><source name="APP" created-by-npl="N"/></sources></patcit></patent-citations><non-patent-citations><nplcit><text>H. SCHNEIDERMAN; T. KANADE: "A Statistical Method for 3D Object Detection Applied to Faces and Cars", IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR 2000, 2000</text><sources><source mxw-id="PNPL57937127" load-source="docdb" name="APP"/></sources></nplcit><nplcit><text>PAUL VIOLA: "Robust Real-Time Face Detection", INTERNATIONAL JOURNAL OF COMPUTER VISION, vol. 57, no. 2, 2004, pages 137 - 154</text><sources><source mxw-id="PNPL57937128" load-source="docdb" name="APP"/></sources></nplcit><nplcit><text>YAO-JIUNN CHEN: "Simple Face-detection Algorithm Based on Minimum Facial Features", THE 33RD ANNUAL CONFERENCE OF THE IEEE INDUSTRIAL ELECTRONICS SOCIETY (IECON, 5 November 2007 (2007-11-05)</text><sources><source mxw-id="PNPL63646563" load-source="docdb" name="APP"/></sources></nplcit></non-patent-citations></citations></technical-data><related-documents><relation type="previously-filed-application"><child-doc ucid="EP-15171650-A"><document-id load-source="patent-office" format="epo"><country>EP</country><doc-number>15171650</doc-number><kind>A</kind><date>20120806</date></document-id><document-id load-source="patent-office" format="original"><country>EP</country><doc-number>15171650.3</doc-number><date>20120806</date></document-id></child-doc><parent-doc ucid="IB-2012054016-W"><document-id load-source="patent-office" format="epo"><country>IB</country><doc-number>2012054016</doc-number><kind>W</kind><date>20120806</date></document-id><document-id load-source="patent-office" format="original"><country>WO</country><doc-number>PCT/IB2012/054016</doc-number><date>20120806</date></document-id></parent-doc></relation><relation type="division"><child-doc ucid="EP-15171650-A"><document-id load-source="patent-office" format="epo"><country>EP</country><doc-number>15171650</doc-number><kind>A</kind><date>20120806</date></document-id><document-id load-source="patent-office" format="original"><country>EP</country><doc-number>15171650.3</doc-number><date>20120806</date></document-id></child-doc><parent-doc ucid="EP-12824321-A"><document-id load-source="patent-office" format="epo"><country>EP</country><doc-number>12824321</doc-number><kind>A</kind><date>20120806</date></document-id><document-id load-source="patent-office" format="original"><country>EP</country><doc-number>12824321.9</doc-number><date>20120806</date></document-id></parent-doc></relation></related-documents><parties><applicants><applicant mxw-id="PPAR1103314050" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>COMIGO LTD</last-name><address><country>IL</country></address></addressbook></applicant><applicant mxw-id="PPAR1103330100" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>COMIGO LTD.</last-name></addressbook></applicant><applicant mxw-id="PPAR1101642409" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Comigo Ltd.</last-name><iid>101445817</iid><address><street>P.O. Box 1241</street><city>4511201 Hod-HaSharon</city><country>IL</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR1103323646" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>MORAN DOV</last-name><address><country>IL</country></address></addressbook></inventor><inventor mxw-id="PPAR1103322212" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>MORAN, DOV</last-name></addressbook></inventor><inventor mxw-id="PPAR1101650490" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>MORAN, DOV</last-name><address><street>5 Shahal Street</street><city>4438040 Kfar Saba</city><country>IL</country></address></addressbook></inventor><inventor mxw-id="PPAR1103328383" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>LENTZITZKY MOTTY</last-name><address><country>IL</country></address></addressbook></inventor><inventor mxw-id="PPAR1103321833" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>LENTZITZKY, Motty</last-name></addressbook></inventor><inventor mxw-id="PPAR1101647218" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>LENTZITZKY, Motty</last-name><address><street>11 Akiva Street</street><city>4326006 RaAnana</city><country>IL</country></address></addressbook></inventor><inventor mxw-id="PPAR1103339836" load-source="docdb" sequence="3" format="epo"><addressbook><last-name>TEICHER MORDECHAI</last-name><address><country>IL</country></address></addressbook></inventor><inventor mxw-id="PPAR1103312609" load-source="docdb" sequence="3" format="intermediate"><addressbook><last-name>TEICHER, MORDECHAI</last-name></addressbook></inventor><inventor mxw-id="PPAR1101651195" load-source="patent-office" sequence="3" format="original"><addressbook><last-name>TEICHER, MORDECHAI</last-name><address><street>6 Mordechai Gur Street</street><city>4533440 Hod-HaSharon</city><country>IL</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR1101642834" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Dennemeyer &amp; Associates S.A.</last-name><iid>101427789</iid><address><street>Poccistrasse 11</street><city>80336 München</city><country>DE</country></address></addressbook></agent></agents></parties><international-convention-data><designated-states><ep-contracting-states><country mxw-id="DS660603578" load-source="docdb">AL</country><country mxw-id="DS660680666" load-source="docdb">AT</country><country mxw-id="DS660603579" load-source="docdb">BE</country><country mxw-id="DS660604853" load-source="docdb">BG</country><country mxw-id="DS660604753" load-source="docdb">CH</country><country mxw-id="DS660781926" load-source="docdb">CY</country><country mxw-id="DS660680675" load-source="docdb">CZ</country><country mxw-id="DS660603580" load-source="docdb">DE</country><country mxw-id="DS660781927" load-source="docdb">DK</country><country mxw-id="DS660781928" load-source="docdb">EE</country><country mxw-id="DS660682900" load-source="docdb">ES</country><country mxw-id="DS660604854" load-source="docdb">FI</country><country mxw-id="DS660604754" load-source="docdb">FR</country><country mxw-id="DS660603581" load-source="docdb">GB</country><country mxw-id="DS660781929" load-source="docdb">GR</country><country mxw-id="DS660603582" load-source="docdb">HR</country><country mxw-id="DS660680676" load-source="docdb">HU</country><country mxw-id="DS660680680" load-source="docdb">IE</country><country mxw-id="DS660781930" load-source="docdb">IS</country><country mxw-id="DS660604759" load-source="docdb">IT</country><country mxw-id="DS660781931" load-source="docdb">LI</country><country mxw-id="DS660604859" load-source="docdb">LT</country><country mxw-id="DS660680811" load-source="docdb">LU</country><country mxw-id="DS660604860" load-source="docdb">LV</country><country mxw-id="DS660604861" load-source="docdb">MC</country><country mxw-id="DS660680812" load-source="docdb">MK</country><country mxw-id="DS660680813" load-source="docdb">MT</country><country mxw-id="DS660604862" load-source="docdb">NL</country><country mxw-id="DS660604760" load-source="docdb">NO</country><country mxw-id="DS660604867" load-source="docdb">PL</country><country mxw-id="DS660680681" load-source="docdb">PT</country><country mxw-id="DS660603583" load-source="docdb">RO</country><country mxw-id="DS660680682" load-source="docdb">RS</country><country mxw-id="DS660604868" load-source="docdb">SE</country><country mxw-id="DS660682901" load-source="docdb">SI</country><country mxw-id="DS660604761" load-source="docdb">SK</country><country mxw-id="DS660604869" load-source="docdb">SM</country><country mxw-id="DS660781932" load-source="docdb">TR</country></ep-contracting-states></designated-states></international-convention-data></bibliographic-data><abstract mxw-id="PA166479528" lang="EN" load-source="patent-office"><p id="pa01" num="0001">The present invention relates to a method for selecting at least one interactive application, comprising: identifying a plurality of interactive applications which are available to a client terminal of a user; identifying a media content item being currently presented on said client terminal; automatically identifying at least one media content characteristic of said media content item, wherein each of said at least one media content characteristic is one of: a genre, a length, a rating, an age rating, a language, an origin country, a production source, a production date and indirect advertising content; automatically selecting a group of said plurality of interactive applications according to said at least one media content characteristic; and instructing a presentation of icons corresponding to members of said group on a display of said client terminal concurrently with presenting said media content item.</p></abstract><abstract mxw-id="PA166759340" lang="EN" source="EPO" load-source="docdb"><p>The present invention relates to a method for selecting at least one interactive application, comprising: identifying a plurality of interactive applications which are available to a client terminal of a user; identifying a media content item being currently presented on said client terminal; automatically identifying at least one media content characteristic of said media content item, wherein each of said at least one media content characteristic is one of: a genre, a length, a rating, an age rating, a language, an origin country, a production source, a production date and indirect advertising content; automatically selecting a group of said plurality of interactive applications according to said at least one media content characteristic; and instructing a presentation of icons corresponding to members of said group on a display of said client terminal concurrently with presenting said media content item.</p></abstract><description mxw-id="PDES98404229" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><heading id="h0001"><u>FIELD AND BACKGROUND</u></heading><p id="p0001" num="0001">The present disclosure, in some embodiments thereof, relates to methods and systems of communication and, more particularly, but not exclusively, to methods and systems for enabling and enriching communication between television viewers, for example, through the creation of multi participant sessions, interactive content presentation, and video chat.</p><p id="p0002" num="0002">People socialize within a shared social space. Often this socialization occurs in the context of listening to music, watching a television program, or watching a movie within the home. The fellowship engendered by this experience changes when some of the members of the social group move away or otherwise become remote from the heart of the group.</p><p id="p0003" num="0003">During the last few years, various developments have been made to provide television (TV) services that socially connect between users that watch a common video content in different location. For example, services have recently been proposed in which users can store, share and discover bookmarks that point to multimedia clips taken from television and other video programming. The bookmarks, which can be created and shared through a user's set top box or other client device, are analogous to web-based social bookmarks that are offered by on-line services such as del.icio.us, for example. Such social TV services allow users to share clips from programs with friends and tag bookmarks for easy access. Users gain information on what friends are interested in and the producers of the tagged or bookmarked programs gain information about their viewers.</p><p id="p0004" num="0004">Another example is Chatter application program of Splashcast™ and Hulu™ that allows social network users to add comments to video content which is available at Hulu's website. This program allows social network users to comment about a show via micro comments which are synced to a video file or a stream. In this program user micro comments can be seen by future users that will access the video file or stream.</p><p id="p0005" num="0005">Another solution is described in <patcit id="pcit0001" dnum="US20070280638A"><text>U.S. Patent Application No. 2007/0280638</text></patcit> that teaches a system (such as an extension to a social television<!-- EPO <DP n="2"> --> system) that extracts and stores content and/or commentary from an experiential data stream as a presentation for later playback. The presentation can be given to another to share the experience of viewing the experiential data stream with the creator of the presentation. The presentation can be read and processed by any standard playback device (such as a DVD player, an MP3 player, a tape player etc.). The presentation is predefined and constrained to enable it to be used by commonly used playback devices. In the context of a social television system the disclosed technology provides a way for people to interact naturally while watching a TV program and to share their reactions asynchronously, and later obtaining responses in context from people watching at different times.</p><p id="p0006" num="0006">Interactive television (TV) has already been deployed in various forms. The electronic program guide (EPG) is one example, where the TV viewer is able to use the remote control to control the display of programming information such as TV show start times and duration, as well as brief synopses of TV shows. The viewer can navigate around the EPG, sorting the listings, or selecting a specific show or genre of shows to watch or tune to at a later time.</p><p id="p0007" num="0007">Another example is the WebTV interactive system produced by Microsoft, wherein web links, information about the show or story, shopping links, and so on are transmitted to the client terminal through the vertical blanking interval of the TV signal. Other examples of interactive TV include television delivered via the internet protocol (IP) to a personal computer (PC), where true interactivity can be provided, but typically only a subset of full interactivity is implemented. For the purposes of this patent application, full interactivity is defined as fully customizable screens and options that are integrated with the original television display, with interactive content being updated on the fly based on viewer preferences, demographics, other similar viewer's interactions, and the programming content being viewed. The user interface for such a fully interactive system should also be completely flexible and customizable.</p><p id="p0008" num="0008">During the last years various technologies for the reception and transmission of audio-video signals by users at different locations, for communication between people in real-time have been developed.</p><p id="p0009" num="0009">These technologies have been integrated into various operating systems and browsers for usage on different client terminals, such as cellular phones, tablets,<!-- EPO <DP n="3"> --> laptops, and Internet Protocol television (IPTV).</p><p id="p0010" num="0010">For example, <patcit id="pcit0002" dnum="US20110173300A"><text>U.S. Patent Application Pub. No. 2011/0173300</text></patcit> describes techniques for a protocol that provides for a TV viewing experience with interaction by allowing for social collaboration of non-co-located TV viewers and integrating the TV viewing experience with social networking concepts and interactive multimedia communication. The protocol enables a digital video distribution system (e.g., IPTV) to provide a user with presence, channel, and grouping information regarding other users in the IPTV system and available video content. The protocol also enables users of the IPTV system to interact using real-time and/or non-real time communication.</p><heading id="h0002"><u>SUMMARY OF THE DISCLOSURE</u></heading><p id="p0011" num="0011">According to some embodiments of the present disclosure, there is provided a method of creating a multi participant session among a plurality of viewers of media content. The method comprises automatically identifying which media content is currently presented on a plurality of client terminals of a plurality of subscribers, receiving, from a first of the plurality of subscribers, a first selection indicative of a template of a multi participant session object and a second selection indicative of a group from the plurality of subscribers, creating a multi participant session object adapted for simultaneous presentation with the media content according to the first and second selections, and establishing a multi participant session among at least one member of the group and the first subscriber using the multi participant session object.</p><p id="p0012" num="0012">Optionally, the method further comprises forwarding a message indicative of the media content to a social network provider to update a respective user profile accordingly.</p><p id="p0013" num="0013">Optionally, the establishing comprises generating an interactive user interface according to the multi participant session object and selecting at least some of the plurality of client terminals to present the interactive user interface.</p><p id="p0014" num="0014">Optionally, the method further comprises forwarding the interactive user interface to a remote controlling device via one of the plurality of client terminals and presenting the interactive user interface on a display of the remote controlling device.</p><p id="p0015" num="0015">Optionally, the method further comprises updating the multi participant session object according to a plurality of user inputs from the at least some client terminals.<!-- EPO <DP n="4"> --></p><p id="p0016" num="0016">Optionally, the method further comprises generating a plurality of interactive user interfaces, each designated to another of the plurality of subscribers, according to the multi participant session object and forwarding each the interactive user interface to another of a plurality of remote controlling devices via one of the plurality of client terminals to present the plurality of interactive user interfaces on displays of the plurality of remote controlling devices simultaneously.</p><p id="p0017" num="0017">Optionally, the creating comprises sending to each member of the group an invitation to watch the media content in parallel to a participation in the multi participant session.</p><p id="p0018" num="0018">Optionally, the method further comprises presenting a plurality of templates of multi participant session objects to the first subscriber to facilitate the first selection; wherein the plurality of templates are selected from a template repository.</p><p id="p0019" num="0019">Optionally, the method further comprises updating the template repository with a new template based on the multi participant session object.</p><p id="p0020" num="0020">More optionally, the plurality of templates are selected according to at least one characteristic of the first subscriber.</p><p id="p0021" num="0021">More optionally, the plurality of templates are selected according to at least one characteristic of at least one member of the group.</p><p id="p0022" num="0022">More optionally, the plurality of templates are selected according to at least one characteristic of at least one subscriber of the plurality of subscribers which is socially connected to the first subscriber.</p><p id="p0023" num="0023">Optionally, the method further comprises automatically generating at least some of the plurality of templates according an analysis of at least one electronic program guides (EPG).</p><p id="p0024" num="0024">More optionally, the plurality of templates are selected according to at least one characteristic of the media content.</p><p id="p0025" num="0025">Optionally, the multi participant session is a social interactive activity selected from a group consisting of a poll, a chat, a game, a gambling mechanism, a quiz.</p><p id="p0026" num="0026">More optionally, the creating comprises receiving user content from the subscriber and creating the multi participant session object so as to present the user content on the interactive user interface as at least one of a question, a bid, and a set of possible answers to a question.<!-- EPO <DP n="5"> --></p><p id="p0027" num="0027">Optionally, the creating comprises identifying at least one characteristic of the media content and creating the multi participant session object to match the media content.</p><p id="p0028" num="0028">Optionally, the creating comprises identifying at least one characteristic of a member of the group and creating the multi participant session according to the at least one characteristic.</p><p id="p0029" num="0029">Optionally, the method further comprises identifying at least one of the plurality of subscribers which is socially connected to the first subscriber and presenting the at least one subscriber to the first subscriber to facilitate the second selection.</p><p id="p0030" num="0030">Optionally, the media content is a broadcast presented on the at least some client terminals.</p><p id="p0031" num="0031">Optionally, the media content is video on demand (VOD) content selected by the first subscriber.</p><p id="p0032" num="0032">Optionally, the media content is locally stored on a respective aid client terminal or a memory device connected thereto.</p><p id="p0033" num="0033">Optionally, the method further comprises capturing a plurality of images of each member of the group and of the first subscriber during the multi participant session, the updating comprises presenting the plurality of images using a respective the interactive user interface on the plurality of client terminals.</p><p id="p0034" num="0034">More optionally, the updating comprises presenting promotional content using a respective the interactive user interface on the plurality of client terminals.</p><p id="p0035" num="0035">More optionally, the method further comprises selecting the promotional content based on analysis of a member from a group consisting of the number of members in the group, a characteristic of the media content, and a characteristic of at least one member of the group.</p><p id="p0036" num="0036">More optionally, the method further comprises selecting the promotional content according to a combination of characteristics of a plurality of members of the group.</p><p id="p0037" num="0037">Optionally, the method further comprises receiving, from the first subscriber, a request to fund at least one right to access the media content and billing the first subscriber for a usage of the at least one right to access the media content by at least one member of the group.<!-- EPO <DP n="6"> --></p><p id="p0038" num="0038">Optionally, the method further comprises establishing a plurality of sub multi participant session subscribers among sub groups of the group.</p><p id="p0039" num="0039">According to other embodiments of the disclosure a method is taught for selecting at least one interactive application for presentation. The method may comprise: identifying a plurality of interactive applications which are available for presentation on a client terminal of a user; automatically identifying a media content item being currently presented on the client terminal; automatically identifying at least one media content characteristic of the media content; selecting a group of the plurality of interactive applications which are tagged as suitable for media content having the at least one media content characteristic; and presenting members of the group on a display of the client terminal in relation to the media content item.</p><p id="p0040" num="0040">Optionally, the plurality of interactive applications are locally stored on the client terminal.</p><p id="p0041" num="0041">Optionally, the plurality of interactive applications comprises a record defining at least one suitable media content characteristic.</p><p id="p0042" num="0042">Optionally, at least one media content characteristic comprises at least one member of a group consisting of: a genre, a length, a rating, an age rating, a language, an origin country, a production source, a production date, indirect advertising content and/or the like.</p><p id="p0043" num="0043">Optionally, the automatically identifying at least one content characteristic comprises acquiring the at least one content characteristic via a network from a database storing a plurality of media content records each having a respective the at least one content characteristic.</p><p id="p0044" num="0044">Optionally, the media content item is a broadcasted content, the automatically identifying a media content item comprises detecting a currently presented channel on the client terminal and analyzing at least one electronic program guide (EPG) to identify currently aired media content on the currently presented channel.</p><p id="p0045" num="0045">Optionally, the media content item is a video on demand (VOD) item, the automatically identifying a media content item comprises detecting requesting the at least one media content characteristic from the source of the VOD item.</p><p id="p0046" num="0046">Optionally, automatically identifying a media content item comprises identifying a currently presented scene of the media content item; wherein the automatically identifying at least one media content characteristic of the media<!-- EPO <DP n="7"> --> comprises automatically identifying at least one scene characteristic; wherein members of the group are tagged as suitable for a scene having the at least one scene characteristic and the presenting being performed in relation to the scene.</p><p id="p0047" num="0047">Optionally, each the plurality of interactive applications is associated with at least one suitable media content characteristic; the selecting comprises matching between the at least one suitable media content characteristic of at least some of the plurality of interactive applications and the at least one media content characteristic.</p><p id="p0048" num="0048">Optionally,, the selecting comprises matching the at least one media content characteristic with records of a dataset documenting at least one suitable media content characteristic per each the interactive application.</p><p id="p0049" num="0049">Optionally the method further comprises allowing a plurality of users to perform at least one of tagging the plurality of interactive applications and updating a database storing a plurality of media content records about a plurality of media content items.</p><p id="p0050" num="0050">Optionally, the selecting comprises identifying which media content item is currently watched by at least one friend of the user and selecting the group according thereto.</p><p id="p0051" num="0051">Optionally the method further comprises automatically identifying a new media content item that is currently presented on the client terminal, automatically identifying at least one new media content characteristic of the new media content, selecting a new group of the plurality of interactive applications which are tagged as suitable for media content having the at least one new media content characteristic, and presenting members of the new group on a display of the client terminal in relation to the new media content item.</p><p id="p0052" num="0052">Optionally the method further comprises detecting at least one current viewing pattern on the client terminal and selecting an additional group of the plurality of interactive applications which are tagged as suitable for the viewing pattern; wherein the presenting comprises presenting members of the additional group on the display.</p><p id="p0053" num="0053">Optionally, the at least one current viewing pattern is selected from a group consisting of: the period the user watches the media content item, at least one additional media content previously watched by the user, a frequency of recent zapping by the user, a volume level at which the media content item being played, a display setting at which the media content item being played, and current time.<!-- EPO <DP n="8"> --></p><p id="p0054" num="0054">Optionally, the plurality of interactive applications are stored on the client terminal.</p><p id="p0055" num="0055">Optionally, the plurality of interactive applications are stored on a remote terminal.</p><p id="p0056" num="0056">Optionally, the plurality of interactive applications include commercial applications which contain a commercial content.</p><p id="p0057" num="0057">Another aspect of the disclosure is to present a computer readable medium comprising computer executable instructions adapted to perform a method such as described herein.</p><p id="p0058" num="0058">According to another embodiment of the disclosure, a system is introduced for selecting at least one interactive application for presentation. The system may comprise a database of a plurality of media content records each indicative of at least one media content characteristic of one of a plurality of media content items; a central unit which receives a request with an identifier of media content presented by a client terminal and forwards respective the at least one media content characteristic from the plurality of media content records in response to the request; a client module hosted by the client terminal and manages a plurality of applications which are available for use on the client terminal, the client module receives the at least one media content characteristic, selects accordingly a group from the plurality of applications, and presents the group to a user of the client terminal.</p><p id="p0059" num="0059">Optionally, the system further comprises an updating module which analyzes a plurality of web pages to extract respective the at least one media content characteristic for at least one of updating the plurality of media content records and adding a plurality of new media content records.</p><p id="p0060" num="0060">Still another aspect of the disclosure is to teach a method of selecting at least one interactive application for presentation, comprising: identifying a plurality of interactive applications which are available for presentation on a client terminal of a user; extracting metadata of a media content item currently presented on the client terminal, the metadata comprises at least one media content characteristic of the media content; and selecting a group of the plurality of interactive applications which are tagged as suitable for media content having the at least one media content characteristic by using the metadata; and presenting members of the group on a display of the client terminal in relation to the media content item.<!-- EPO <DP n="9"> --></p><p id="p0061" num="0061">Another method is taught for selecting at least one interactive application for presentation, comprising: a) identifying a plurality of interactive applications which are available for presentation on a client terminal of a user; b) automatically identifying one of a plurality of scenes of a media content item currently presented on the client terminal; c) automatically identifying at least one scene characteristic of the currently presented scene; d) selecting a group of the plurality of interactive applications which are tagged as suitable for a scene having the at least one scene characteristic; and e) presenting members of the group on a display of the client terminal in relation to the scene; and repeating the b)-e) for each one of the plurality of scenes.</p><p id="p0062" num="0062">Still another method is taught for selecting at least one interactive application for presentation, comprising: identifying a plurality of interactive applications which are available for presentation on a client terminal of a user; automatically identifying at least one current viewing pattern of the user; selecting a group of the plurality of interactive applications which are tagged as suitable for the at least one current viewing pattern; and presenting members of the group on a display of the client terminal.</p><p id="p0063" num="0063">Optionally, the at least one current viewing pattern is selected from a group consisting of: the period the user watches a media content item currently presented on the client terminal, at least one media content previously watched by the user, a frequency of recent zapping on the client terminal, a volume level at which the media content item being played on the client terminal, a display setting at which the media content item being played on the client terminal, and a current time.</p><p id="p0064" num="0064">According to other embodiments of the present disclosure, there is provided a method for managing a multi participant video session. The method comprises establishing a multi participant video session between a plurality of participants of a plurality of camera enabled client terminals which are connected to a network, monitoring a participation level of each one of the plurality of participants in the multi participant video session, and automatically halting the multi participant video session if respective the participation level of one of the plurality of participants is below a minimum.<!-- EPO <DP n="10"> --></p><p id="p0065" num="0065">Optionally, the method further comprises identifying media content currently displayed on at least one of the plurality of camera enabled client terminals and adjusting accordingly at least one of the minimum and the monitoring.</p><p id="p0066" num="0066">Optionally, the method further comprises identifying social connection between the plurality of participants and adjusting accordingly at least one of the minimum and the monitoring.</p><p id="p0067" num="0067">Optionally, the method further comprises identifying a characteristic of at least one of the plurality of participants and adjusting accordingly at least one of the minimum and the monitoring.</p><p id="p0068" num="0068">Optionally, the method further comprises identifying an operation action pertaining to a display of media content on at least one of the plurality of camera enabled client terminals and adjusting accordingly at least one of the minimum and the monitoring.</p><p id="p0069" num="0069">Optionally, the monitoring comprises capturing a plurality of image sequences each using the camera of another the camera enabled client terminal and analyzing each the plurality of image sequences to estimate a respective the participation level.</p><p id="p0070" num="0070">More optionally, the analyzing comprises detecting at least one of presence and absence of a face of a respective the participant in the respective image sequence, the detecting being performed according to at least one reference facial feature associated with the respective participant.</p><p id="p0071" num="0071">More optionally, the analyzing comprises detecting at least one of presence and absence of a face gazing at a display of a respective the camera enabled client terminal.</p><p id="p0072" num="0072">More optionally, the analyzing comprises detecting at least one of presence and absence of any face in the respective image sequence.</p><p id="p0073" num="0073">Optionally, the halting comprises terminating the multi participant video session.</p><p id="p0074" num="0074">Optionally, the halting comprises displaying an interactive notice which is indicative of the halting and allowing at least one of the plurality of participants to manually instruct the resuming of the multi participant video session.</p><p id="p0075" num="0075">Optionally, the method further comprises proceeding with the monitoring during the halting and automatically resuming the multi participant video session if<!-- EPO <DP n="11"> --> respective the participation level of each one of the plurality of participants is above the minimum.</p><p id="p0076" num="0076">According to some embodiments of the present disclosure, there is provided a system for managing a multi participant video session. The system comprises a central unit which establishes a multi participant video session between a plurality of participants of a plurality of camera enabled client terminals which are connected to a network and a plurality of client modules each installed in another of the plurality of camera enabled client terminals and monitors a participation level one of the plurality of participants in the multi participant video session. The central unit automatically terminating the multi participant video session if it receives from one of the plurality of client modules a message which is indicative that respective the participation level of one of the plurality of participants is below a minimum.</p><p id="p0077" num="0077">Optionally, the plurality of camera enabled client terminals are selected from a group consisting of: Internet Protocol televisions (IPTVs), set top boxes, mobile communication devices, telephones, tablets, computers and the like.</p><p id="p0078" num="0078">According to some embodiments of the present disclosure, there is provided a method for establishing a multi participant video session. The method comprises receiving a request to establish a multi participant video session between a plurality of participants of a plurality of camera enabled client terminals which are connected to a network, delaying the initiation of the multi participant video session until a presence indication indicative of a presence of one of the plurality of participants in a space imaged by a respective the camera enabled client terminal is received from each one of the plurality of camera enabled client terminals, and establishing the multi participant video session between the plurality of participants via the plurality of camera enabled client terminals when the delaying is over.</p><p id="p0079" num="0079">Optionally, the delaying further comprises: capturing a plurality of image sequences, each using another of the plurality of camera enabled client terminals, analyzing each the image sequence to automatically detect the presence of one of the plurality of participants, and ceasing the delaying when the presence of one of each one of the plurality of participants is detected according to the analysis.</p><p id="p0080" num="0080">Optionally, the analyzing comprises identifying a face of a respective the participant in a respective the image sequence to detect the presence thereof a space imaged by a respective the camera enabled client terminal.<!-- EPO <DP n="12"> --></p><p id="p0081" num="0081">More optionally, the delaying further comprises: maintaining the delaying as long as an absence of a face of a respective the participant in identified in a respective the image sequence.</p><p id="p0082" num="0082">Optionally, the presence indication is generated manually by a participant selection.</p><p id="p0083" num="0083">Unless otherwise defined, all technical and/or scientific terms used herein have the same meaning as commonly understood by one of ordinary skill in the art to which the disclosure pertains. Although methods and materials similar or equivalent to those described herein can be used in the practice or testing of embodiments of the disclosure, exemplary methods and/or materials are described below. In case of conflict, the patent specification, including definitions, will control. In addition, the materials, methods, and examples are illustrative only and are not intended to be necessarily limiting.</p><p id="p0084" num="0084">Implementation of the method and/or system of embodiments of the disclosure can involve performing or completing selected tasks manually, automatically, or a combination thereof. Moreover, according to actual instrumentation and equipment of embodiments of the method and/or system of the disclosure, several selected tasks could be implemented by hardware, by software or by firmware or by a combination thereof using an operating system.</p><p id="p0085" num="0085">For example, hardware for performing selected tasks according to embodiments of the disclosure could be implemented as a chip or a circuit. As software, selected tasks according to embodiments of the disclosure could be implemented as a plurality of software instructions being executed by a computer using any suitable operating system. In an exemplary embodiment of the disclosure, one or more tasks according to exemplary embodiments of method and/or system as described herein are performed by a data processor, such as a computing platform for executing a plurality of instructions. Optionally, the data processor includes a volatile memory for storing instructions and/or data and/or a non-volatile storage, for example, a magnetic hard-disk and/or removable media, for storing instructions and/or data. Optionally, a network connection is provided as well. A display and/or a user input device such as a keyboard or mouse are optionally provided as well.<!-- EPO <DP n="13"> --></p><heading id="h0003"><u>BRIEF DESCRIPTION OF THE DRAWINGS</u></heading><p id="p0086" num="0086">Some embodiments of the disclosure are herein described, by way of example only, with reference to the accompanying drawings. With specific reference now to the drawings in detail, it is stressed that the particulars shown are by way of example and for purposes of illustrative discussion of embodiments of the disclosure. In this regard, the description taken with the drawings makes apparent to those skilled in the art how embodiments of the disclosure may be practiced.</p><p id="p0087" num="0087">In the drawings:
<ul><li><figref idrefs="f0001">FIG. 1</figref> is a schematic illustration of a system for creating and managing a multi participant session among viewers of common media content, and for dynamically selecting interactive applications from a plurality of interactive applications which are made available to user(s) of a client terminal, according to some embodiments of the present disclosure;</li><li><figref idrefs="f0002 f0003">FIGS. 2A - 2D</figref> are images of a broadcasted media content with different overlays of multi participant session interactive windows, according to some embodiments of the present disclosure; and</li><li><figref idrefs="f0004">FIG. 3</figref> is a flowchart of a method of creating a multi participant session among a plurality of viewers that watch common media content, according to some embodiments of the present disclosure.</li><li><figref idrefs="f0005">FIG. 4</figref> is a flowchart of a method of selecting and/or filtering interactive applications, according to some embodiments of the present disclosure;</li><li><figref idrefs="f0006">FIG. 5</figref> is a method of dynamically selecting one or more interactive applications adapted for a media content scene which currently presented and/or selected to be presented, according to some embodiments of the present disclosure; and</li><li><figref idrefs="f0006">FIG. 6</figref> is a method of dynamically selecting one or more of the interactive applications which are made available to user(s) of a client terminal based on current viewing pattern characteristics, according to some embodiments of the present disclosure.</li><li><figref idrefs="f0007">FIG. 7</figref> is a schematic illustration of a system for establishing and/or managing a multi participant video session among participants who use camera enhanced remote client terminals, according to some embodiments of the present disclosure;<!-- EPO <DP n="14"> --></li><li><figref idrefs="f0008">FIG. 8</figref> is a flowchart of a method for establishing a multi participant video session, according to some embodiments of the present disclosure; and</li><li><figref idrefs="f0008">FIG. 9</figref> is a flowchart of a method for managing a multi participant video session, according to some embodiments of the present disclosure.</li></ul></p><heading id="h0004"><u>DESCRIPTION OF EMBODIMENTS OF THE DISCLOSURE</u></heading><p id="p0088" num="0088">The present disclosure, in some embodiments thereof, relates to methods and systems of communication and, more particularly, but not exclusively, to a methods and systems of communication between television viewers.</p><p id="p0089" num="0089">According to some embodiments of the present disclosure there are provided methods and systems of creating a multi participant session among a plurality of viewers of common media content based on a multi participant session object created by one of the viewers, optionally based on a selected template. These embodiments allow a user, referred to herein as a session initiator, or a module, to select and adjust a template of a multi participant session, such as a multi participant game, a poll, and a custom made gamble. Such a user adapted multi participant session may be custom made, either manually or automatically, to a certain media content, for example to characters in a reality TV show, characteristics of a certain group of viewers, optionally socially connected, or any member thereof and/or session initiator preferences.</p><p id="p0090" num="0090">Optionally, the system includes a central unit which manages the multi participant sessions and a plurality of client modules which are installed in client terminals, such as set top boxes, designated devises and/or television sets, for example as described above. The central unit optionally manages a database of subscribers, optionally socially connected, and a set of templates, optionally dynamically updated by subscribers and/or system operator(s). In use, the central unit receives media content indication indicative of media content currently presented on the client terminal of the session initiator. The central unit further receives a selection indicative of a template of a multi participant session object and another selection indicative of a group from the subscribers, for example friends of the session initiator. This allows creating a multi participant session object that is adapted for the selected group according to the template and using the multi participant session object to establish a<!-- EPO <DP n="15"> --> multi participant session pertaining to the media content among member(s) of the group and the session initiator.</p><p id="p0091" num="0091">Optionally, the template is selected by the session initiator from a dynamic set of templates. The template or the dynamic set of templates may be updated according to the session initiator, the members of the selected group, one or more characteristics of the common media content, and/or the airtime left for a broadcasted media content.</p><p id="p0092" num="0092">According to some embodiments of the present disclosure, a participant of a multi participant session may watch audio and/or video feeds which are captured by client terminals of other participants of the multi participant session. In such a manner, the experience of watching the common media content for one participant is enhanced by the inputs of other participants. In such embodiments, audio and/or video chats may be established among sub groups of multi participant session participants, for example as described below.</p><p id="p0093" num="0093">According to some embodiments of the present disclosure, promotional content is presented to participants of the multi participant session. The promotional content may be designated for a group, for example based on a combination of characteristics of a number of participants and/or includes offers for a group purchase, for example as described below.</p><p id="p0094" num="0094">Before explaining at least one embodiment of the disclosure in detail, it is to be understood that the disclosure is not necessarily limited in its application to the details of construction and the arrangement of the components and/or methods set forth in the following description and/or illustrated in the drawings and/or the Examples. The disclosure is capable of other embodiments or of being practiced or carried out in various ways.</p><p id="p0095" num="0095">Reference is now made to <figref idrefs="f0001">FIG. 1</figref>, which is a schematic illustration of a system for creating and managing a multi participant session among viewers of common media content, such as a broadcasted content, video on demand (VOD) content, locally stored content, recorded content, and/or a stream, according to some embodiments of the present disclosure. The media content may be a movie, a TV show, promotional content, a series, and/or the like. The viewers may be referred to herein as participants. The multi participant session may be a poll, a chat, a game, a gambling mechanism, and/or a quiz, such as a trivia quiz that is selected and/or generated according to the<!-- EPO <DP n="16"> --> inputs of one of the viewers, for example the initiator of the multi participant session, as described below.</p><p id="p0096" num="0096">The multi participant sessions, as further described below, may be implemented using multi participant session objects managed by a central unit 103, which is optionally implemented on one or more web servers. Each multi participant session object may include instructions for generating an interactive user interface that is presented on the display of a plurality of client terminals and receives inputs from the users thereof, for example as described below. The interactive user interfaces are optionally overlays, each with dynamic graphical user interface (GUI), which are presented on top of media content that is broadcasted over the internet and/or a communication network such as a cable network and/or satellite services, provided as VOD content or a stream over the internet and/or a communication network such as a cable network and/or satellite services and/or locally recorded at one or more client terminals. For example, the multi participant session object may allow generating a plurality of interactive window displays which are presented on the screens of the client terminals 102. For example, <figref idrefs="f0002">FIGs. 2A and 2B</figref> are exemplary overlays 222, 212 which are displayed over broadcasted media content. In <figref idrefs="f0002">FIG. 2A</figref> the overlay is of an interactive window that presents options to the subscriber that participates in a multi participant session of a poll type and in <figref idrefs="f0002">FIG. 2B</figref> the overlay depicts an outcome of such a poll 214, an indication of which subscriber currently watches the media content 215, and a set if buttons for facilitating calling a subscriber 216, receiving information about the system 217 and/or to initiate a new multi participant session 218.</p><p id="p0097" num="0097">According to some embodiments of the present disclosure, an interactive window display may be forwarded by the client terminal 102 to a screen of a remote controlling device, such as a designated remote control device and/or a cellular phone, such as a Smartphone that functions as a cellular device, for example using a designated installed app. In such an embodiment, the interactive window display may be displayed only on the remote controlling device and/or both on the remote controlling device and on the screen of the client terminal 103. Optionally, while some interactive window displays are played on the screen of the remote control, for example audio and/or video chats, others are displayed on the screen which is connected to the client terminal and/or of the client terminal, for example the current<!-- EPO <DP n="17"> --> outcome of a poll and/or video feeds of watching subscribers, for example as described below.</p><p id="p0098" num="0098">In an exemplary case, the remote controlling device communicates with a client terminal 102, such as a set top box, over Wi-Fi or other proprietary connection. The client terminal 102 is connected to and controls a TV set. The remote controlling device is connected to the central unit 103 through the client terminal 102.</p><p id="p0099" num="0099">The client terminal 102 controls a flow of content received from the central unit 103 and from other sources, such as IPTV, terrestrial broadcasts, satellite/cable broadcast and the like. The client terminal 103 may route certain content to the remote controlling device and other to the TV set. For example, content that is tagged as social is routed directly to the client terminal 102. Notification may be routed to remote controlling device directly without popping out on the screen and interfering with the media content that is being watched. Optionally, when a number of subscribers (viewers) watch the same media content on the same TV set and logged to the system, each viewer is presented with respective interactive windows so that they can participate in different multi participant sessions simultaneously, each using her remote controlling device. In such an embodiment, the remote controlling device of a user A may be used to communicate with the remote controlling device of user B through one or more client terminals in real time interactive manner.</p><p id="p0100" num="0100">Optionally, the system 100 includes a plurality of client modules 101 which are installed in a plurality of client terminals 102. The client module 101 may be implemented as a software component executed by the hosting client terminal 102, for example an application from an app store, an add-on, and/or a standalone application and/or a hardware component that is installed in the hosting client terminal 102, for example an integrated circuit (IC). The client terminal 102 may be a set-top-box (STB), which is connected to a screen, such as a television (TV) 109, an Internet Protocol television (IPTV), also known as a smart TV and/or Connected TV, and/or a computing unit, such as a laptop, a desktop, a Smartphone, a cellular device, a tablet and/or any other device that can be used for providing internet TV service. Optionally, the client module 101 may establish a communication with the central unit 103 using a proxy device, such as a cellular device that communicates with the client terminal 101 and/or the like. In such a manner, the client module 101 may forward and/or receive<!-- EPO <DP n="18"> --> data to and/or from the central unit 103 even when the client terminal is not connected to the central unit 103. For example, if the client terminal 102 is a set top box which has low free bandwidth, say, a cellular connection with the central unit 103 may be established via a cellular device.</p><p id="p0101" num="0101">Optionally, the central unit 103 is connected to each one of the client terminals 102 via a network 105, such as the Internet and/or an Ethernet and/or WLAN. In such an embodiment, the multi participant sessions are managed by the central unit 103. The display is optionally common in all the client terminals 102 and/or adjusted according the subscribers preferences in each client terminal and/or by the viewer which has initiated the multi participant session, for example as described below. As used herein, a subscriber is an identified viewer which is connected to the system 100, for example logged on and/or otherwise monitored.</p><p id="p0102" num="0102">It should be noted that though in the description of this present application the multi participant sessions may be managed and/or processed by a central unit, the management and/or the processing may be performed by one or more of the client modules 101. For example, a multi participant session may be managed by the client module 101 which has been used to initiate it. In such embodiments, the communication between different client modules 101 is performed over peer to peer connections and/or schemes.</p><p id="p0103" num="0103">Optionally, the central unit 103 includes and/or is connected to a database 104 that allows storing and updating information pertaining to the multi participant sessions, for example as described below.</p><p id="p0104" num="0104">In use, subscribers log into the system 100 using their client terminals 102, either manually or automatically. Optionally, the central unit 103 monitors the logged subscribers to determine which one is currently available to participate in a multi participant session. Optionally, the central unit 103 manages a subscriber profile record per subscriber. The subscriber profile records are optionally stored in the database 104. The subscriber profile record may include a connected or not-connected status indicator, a unique identification (ID), preferences, one or more social network IDs, a history log indicative of the subscriber's participation in previously held multi participant sessions, a history log indicative of multi participant sessions the subscriber initiated, a history log indicative of media content the subscriber may have watched and/or the like.<!-- EPO <DP n="19"> --></p><p id="p0105" num="0105">Optionally, the client modules 101 monitor the media content that is watched by the subscribers and forward the data to the central unit 103. For example, the content indications are provided via a push mechanism, such as cloud to device message (C2DM), by a pull mechanism wherein the central unit 103 polls information pertaining to the currently presented media content, and/or by a notification mechanism wherein the client module 101 sequentially notifies the central unit 103, for example every number of seconds and/or when the subscriber changes the presented media content. In such a manner, as further described below, a subscriber which views a certain media content may receive information about other subscribers, for example subscribers which are socially connected thereto. The information may teach which subscriber currently watches and/or have watched the certain media content. For example, <figref idrefs="f0003">FIG. 2C</figref> depicts an interactive window that presents information about which media content is watched by friends and optionally their availability to participate in a multi participant session. This interactive window optionally allows the subscriber to select friends for a multi participant session. Optionally, each client module 101 communicates with the central unit 103 to forward information about the media content respective subscriber currently watches and to receive and display similar information about other subscribers. Optionally, the central unit 103 is connected to a social network server. In such an embodiment, the system 100 may automatically update a status of the subscriber with an indication of the media content she is currently watches, for example "I am currently watch Dexter" a profile image of the subscriber with an icon of the media content she is currently watches, for example adds a visual tag of a show to the profile image, and/or issues a twit with the media content he is currently watches, for example "I am currently watching Dexter". In another example, the central unit 103 is connected to the cellular service provider of the subscriber, providing it with an indication about the media content that is currently watched by the subscriber. This allows the service provider to update accordingly the waiting tone of the subscriber and/or any other dynamic content cellular service.</p><p id="p0106" num="0106">Additionally or alternately, per subscriber, social connections are extracted from a social network that is managed by the system 100 and/or third party social networks, such as Facebook™, Twitter™, Myspace™, and/or the like. Optionally, a social graph which may define the social connections among the subscribers is stored and managed in the database 104, for example linked to the aforementioned subscriber<!-- EPO <DP n="20"> --> profile records. In such a manner, each client module 101 may present to a subscriber which one of her friends is currently logged onto the system 100, and optionally which media content they watch on their client terminals 102. For example, the profile pictures of socially connected subscribers which are logged into the system 100 are presented on the display of the client terminal 102 of the certain user, each optionally together with an icon indicative of watched media content. This icon may be extracted from a visual electronic program guide (EPG) or fetched by the client 102 from the central unit 103.</p><p id="p0107" num="0107">Optionally, a number of subscribers may be logged as viewers that share a single client terminal 102, for example watch a movie and/or a television show together while being at the same room. In such an embodiment, as further described below, a GUI, such as an interactive window, of multi participant session object that is presented thereto may be adjusted according to a combined profile that is based on characteristics of all the viewers.</p><p id="p0108" num="0108">Optionally, a central unit 103 synchronizes the commonly watched media content at all participants of a multi participant session. For example, the media content may be synchronized by distributing a reference, such as an image for matching, a timeframe from a certain identifiable tag, and/or the like. In such a manner, a broadcast of certain media content may be synchronized with a respective VOD file and/or a recorded copy thereof. The synchronizing may be performed by the client modules 101, optionally automatically and/or upon request from the respective participant.</p><p id="p0109" num="0109">Reference is also made to <figref idrefs="f0004">FIG. 3</figref>, which is a flowchart of a method 200 of creating a multi participant session among a plurality of viewers that watch common media content, according to some embodiments of the present disclosure. First, as shown at 201, a request to initiate a multi participant session for certain media content is sent from one of the client terminals 102 to the central unit 103. For example, a respective initiation comment is received from a subscriber, which may be referred to herein as a session initiator, on a GUI that is displayed on the screen of one of the client terminals 102, such as an interactive window display. Optionally, the request is forwarded from the client terminal 101 to the central unit 103.</p><p id="p0110" num="0110">Then, as shown at 202, templates of different multi participant session types are selected and presented to the session initiator. Optionally, as shown in <figref idrefs="f0004">FIG. 3</figref>, the<!-- EPO <DP n="21"> --> plurality of templates are selected by the central unit 103 and forwarded to the session initiator. The templates are optionally presented in a GUI that is displayed on the screen of the client terminal 102.</p><p id="p0111" num="0111">Optionally, the templates are selected from a template dataset, which may be hosted by the database 104. For example, the templates are selected according to one or more of the following:
<ol><li>1. The identity and/or the number of the session initiator(s) which are identified as viewers on the client terminal from which the request is received.</li><li>2. The identity of one or more friends of the session initiator(s), which are currently logged to the system 100 and available for participating in a multi participant session.</li><li>3. The number of session initiator(s) which are identified as viewers.</li><li>4. The genre of the media content that is currently watched, for example whether it is a movie, a contest, a sport game, a TV series, a reality show and/or the like and/or Drama, Action, Horror, and/or the like.</li><li>5. The type of the media content that is currently watched by the session initiator(s). For example, the type of the media content may be broadcasted content, VOD content, and/or local storage content.</li><li>6. The airtime left for the media content.</li></ol></p><p id="p0112" num="0112">As described above, a multi participant session may be of various multi participant session types, for example a poll, a chat with one or more subscribers, a game, such as a board game and/or a role-play game, a gambling mechanism, a riddle and/or a quiz, such as a trivia quiz. Each template may be adapted to a certain multi participant session type.</p><p id="p0113" num="0113">Optionally, the templates are adapted according to one or more characteristics of the media content that is commonly watched by the participants. For example, a base quiz template may be adjusted automatically to fit a certain genre (i.e. open questions in a documentary and closed question in a reality show) and/or to the airtime left for the media content (i.e. less questions if the airtime of the media content is about to end soon). For example, as shown at <figref idrefs="f0003">FIG. 2D</figref>, the template is implemented as an interactive window that allows the subscriber to select one or more questions for her multi participant session, for example for a poll. The subscriber is presented with a number of predefined questions, for example previously uploaded by one of the<!-- EPO <DP n="22"> --> subscribers and/or by the operator. Optionally, templates are created by the operator of the system 100, for example for promotional uses and/or to fit contemporary trends. For example, before or during the finals of a reality show, a template that includes a poll pertaining to the finalists is added by the operator. Optionally, templates are created automatically by the system 100, for example according to a textual analysis of electronic program guides (EPGs), and/or the like. For example, when the last episode of a reality show is detected according to textual analysis of an EPG, a template that includes a quiz with questions from previously created multi participant session objects is automatically generated. In another example, the templates are created automatically according to a textual analysis of a media content webpage, such as a show website and/or a respective Facebook™ page.</p><p id="p0114" num="0114">Now, as shown at 204, the session initiator selects a template to create a multi participant session object, as shown at 205.</p><p id="p0115" num="0115">Optionally, as shown at 206, the multi participant session object is adjusted. Optionally, as shown at 207, the multi participant session object is a content aware object that is adjusted according to the media content which is currently watched and/or selected by the session initiator and/or currently watched by subscribers which are socially connected thereto, for example friends and/or followed peers in a social network, such as Facebook™, twitter™ or the like. Optionally, as shown at 205, the multi participant session object is adjusted according to media content from several channels. For example, a multi participant session object with a gambling mechanism may be updated according to data from a number of different channels that broadcast a number of sport games held simultaneously.</p><p id="p0116" num="0116">Additionally or alternately, as shown at 208 and 209, the multi participant session object is adjusted according to the inputs of the session initiator. For example, if the template is a template of a quiz, the multi participant session object may be adjusted by one or more questions and optionally potential answers which are selected and/or provided by the session initiator. In another example, if the multi participant session object is based on a template of a poll, the session initiator may select and/or provide one or more questions and candidates. In another example, if the multi participant session object is based on a template of a Sport gamble (i.e. football, basketball, and/or soccer), the user (or the system 100, as described above) may create a social gamble on "who will win?" and/or "what will be the score?" and optionally<!-- EPO <DP n="23"> --> define few options for the session initiator to select from. Then, a user can send it to invitees, for example some of his friends, with a time limit to vote. After the invitees have voted, an interactive window displays, during the game, which participant has most chances to win the bet and at the end of the game which participant won, and optionally with statistic that combines previous outcomes. In another example, the multi participant session object is based on a template of a reality show. The user may add an option that allows participants of a certain multi participant session to place bets on who will win a certain mission, such as an immunity mission in The Survivor™ style show, who will be dismissed from the reality show, who will get most of the votes (i.e. the public's favorite in American idol) and/or who will win the title in a beauty contest. Optionally, the session initiator selects avatars and/or nicknames for the invitees. Optionally, each invitee may adjust the avatar and/or the nickname thereof.</p><p id="p0117" num="0117">As shown at 210, the session initiator selects a group from the subscribers of the system 100, for instance from the subscriber profile records in the database 104, for participation in the multi participant session. In such an embodiment, as shown at 211, the multi participant session object may be according to the subscribers which are selected by the session initiator. Optionally, in use, as described above, the client module 101 generates a display which indicates to the session initiator which of her friends is currently logged into the system 100 and allows her to add any of these subscribers to the selected group. The central unit 204 receives one or more indicators pertaining to the subscribers of the selected group and sends each member of the group an invitation to watch the media content that is currently watched by the user (i.e. if he does not already watches it) and an invitation to participate in the personalized interactive session.</p><p id="p0118" num="0118">Optionally, the multi participant session object is adjusted according to the selected subscribers. For example, the multi participant session object is adjusted to fit the number of selected subscribers. In another example, if the template is a template of a quiz, questions are selected according to the multi participant session history or preferences of each subscriber, for example from his subscriber profile record (i.e. questions which previously presented thereto).</p><p id="p0119" num="0119">Optionally, the multi participant session object is adjusted according to selections of the selected subscribers and/or information pertaining thereto. In such an<!-- EPO <DP n="24"> --> embodiment, teams may be built up according to subscribers' preferences and/or selections. These teams can be managed by the multi participant session object, for example for determining a winning team in a quiz according to answers of its participants and/or the like.</p><p id="p0120" num="0120">Optionally, as shown at 212, the created multi participant session objects may be converted to new templates and stored in the database 104. In such a manner, a session initiator may use multi participant sessions objects which were previously created by other session initiators. This addition may be performed in real time, allowing subscriber to share, with his friends, multi participant session objects which were recently created for a certain broadcast she currently watches, such as a live broadcast.</p><p id="p0121" num="0121">Now, as shown at 213, a multi participant session is established among the session initiator and a plurality of invited subscribers who accepted the invitations, which may be referred to herein as invitees. The multi participant session is optionally established when interactive windows which display common content are generated, according to the multi participant session object, on the displays of client terminals of the invited subscribers. The interactive windows are optionally displayed as overlays on the display of the common media content.</p><p id="p0122" num="0122">As shown at 214, during the multi participant session, a plurality of inputs from the session initiator and the plurality of invited subscribers are received. These inputs are used to update the interactive multi participant session object, as shown at 214. For example, answers to a poll or a quiz are updated. In such embodiments, the subscriber may type a textual message and/or make a selection on his client terminal, for example by using an interactive window that is presented thereto. The textual message and/or selection is forwarded to the central unit 103 which updates, accordingly, the respective interactive multi participant session object and the interactive windows which are presented to other participants. The inputs may be votes, for example like/dislike indication pertaining to a show, a character, a team, a participant, and/or the like.</p><p id="p0123" num="0123">Optionally, data from other multi participant session objects which are related to the watched content may be combined into the multi participant session object. For example, the overall rating of a certain figure of a show may be calculated and<!-- EPO <DP n="25"> --> presented. Statistics such as how many of friends and/or subscribers voted and/or who voted may also be presented on the interactive windows.</p><p id="p0124" num="0124">According to some embodiments of the present disclosure, a sequence of images of each one of the participants of the multi participant session, for example a live video feed, is captured and presented to all other participants. In such an embodiment, some or all of the client terminals 101 comprise an imaging device, such as a camera or an image sensor. Optionally, the video feeds are processed as part of the multi participant session. For example, winning or losing image processing effects may be added to video feeds of winning and/or losing participants and/or according to a combination of the participants' preferences and a progress in media content that is displayed to all participants. The progress in the media content is optionally identified by analyzing a textual content of a website that publishes information pertaining to the media content, for example a sport website that publishes scores in real time. In another example, each participant is instructed to perform a certain gesture, such as a wave gesture, and video feed is processed to identify the certain gesture. This allows creating a mixture that presents some or all of the participants creating a "crowd wave" together.</p><p id="p0125" num="0125">According to some embodiments of the present disclosure, promotional content, which is adapted to a group of participants of a multi participant session, is presented during the multi participant session. As described above, a multi participant session object may allow a group of subscribers to interact while watching common media content, for example a chat multi participant session and/or the like. This interaction is optionally performed using interactive windows which are presented to participants. Optionally, promotional content that is adapted to the participants is presented in some or all of the interactive windows and/or respective client terminals. For example, the promotional content may be selected according characteristics of the group, for example an average age, gender, a geographic location and/or an analysis of any other characteristic thereof, for example based on information that is extracted from their social network profiles. Optionally, the promotional content includes group shopping coupon(s) and/or offer(s). For example, an offer to purchase a plurality of gym subscriptions in a discounted rate, such as a gym subscription per participant, is offered to the participants. Optionally, the promotional content is selected according to the commonly watched content. For example, basketball games subscription may be<!-- EPO <DP n="26"> --> suggested in a discounted rate for all members in the group and/or a number of proximate sits for a sport game and/or a theater movie is suggested to the participants. In another example, a table in a restaurant may be offered to the group, for example for celebrating an outcome of a commonly watched game and/or a social event, such as a birthday of one of the participants. Optionally, the promotional content is arrived from an external advertisement (ad) server, such as 110 in <figref idrefs="f0001">FIG. 1</figref></p><p id="p0126" num="0126">According to some embodiments of the present disclosure, the system 100, or a similar service, allows a subscriber, such as the session initiator, to fund the right to watch media content together with for one or more remotely located subscribers, for example to purchase or subsidize, optionally tentatively the right to access and use, for example play, media content. This allows the subscriber to invite his friends to watch media content she paid or partly paid for, without any debit or with a reduced debit. In these embodiments VOD objects may actually be used as push objects which are sent to a subscriber and not a pull object that the access thereto is initiated by the subscriber. In use, the subscriber selects media content and uses the client module 102 to send invitation(s) to one or more subscribers. The invitations are optionally sent via the central unit 103, which instructs a respective billing mechanism, such as a billing server, to bill the subscriber when the invitees accept the invitations and/or access the media content. In such embodiments, the VOD service provider and/or the system 100 may offer subscribers with a special price for group watching. For example, a right to watch certain media content on a plurality of client terminals, optionally simultaneously, or substantially simultaneously, may be offered in a discounted rate in relation to the purchase of a plurality of separate and independent rights to watch the certain media content. Optionally, invitations to certain media content are sent with invitations to participate in a multi participant session that is related to the certain media content. As described above, a multi participant session object may define a gamble or a contest among participants. Optionally, the losing contestant(s) of the defined gamble or contest receive the automatically debited for the right for watching media content together with for one or more remotely located subscribers.</p><p id="p0127" num="0127">According to some embodiments of the present disclosure, a participant of a multi participant session, such as a chat, for example audio and/or video chat, may initiate a sub multi participant session, for example another audio and/or video chat, with a selected sub group of one or more participants from the multi participant<!-- EPO <DP n="27"> --> session. In such a manner, communication between sub groups may be held among a certain sub group of participants without members of another sub group of the multi participant session, for example a complementary sub group. Optionally, such a sub multi participant session may be initiated using the GUI of the client module 102, for example using the interactive window of the multi participant session object. In such an embodiment, a participant of a multi participant session that is related to a football match between team A and team B may establish a sub multi participant session wherein he can discuss with participants which cheer team A without letting participants which cheer team B to participate. The sub multi participant sessions are optionally held on separate media channels which are simultaneously managed by a proxy, for example the central unit 103. Additionally or alternatively, sub multi participant sessions are simultaneously established over P2P connections.</p><p id="p0128" num="0128">Optionally, a decoy video is displayed for participants of the multi participant session which are not participants of the sub multi participant session. The decoy video may be recorded and replayed as long as the sub multi participant session is taking place. In such a manner, participants may communicate in a manner that does not allow other participants to notice.</p><p id="p0129" num="0129">Other aspects of the present disclosure, in some embodiments thereof, relate to interactive content and, more particularly, but not exclusively, to methods and systems of enriching interactive content presentation.</p><p id="p0130" num="0130">According to an aspect of some embodiments of the present disclosure there are provided methods and systems of dynamically selecting interactive applications from a repository of interactive applications which are available to a user, for example stored on a client terminal, based on the media content item that is currently watched by the user.</p><p id="p0131" num="0131">For example, one of the methods is implemented by automatically identifying a media content item that is currently presented on a client terminal, for example according to an EPG and/or information from the media content source and automatically identifying one or more media content characteristics of this media content, for example requesting the information from a central unit that accesses a database of media content records. This allows selecting a group of available interactive applications which are tagged as suitable for media content items that have<!-- EPO <DP n="28"> --> such media content characteristics and presenting the members of the group on a display in relation to the media content item.</p><p id="p0132" num="0132">According to an aspect of some embodiments of the present disclosure there are provided methods and systems of dynamically selecting interactive applications which are suitable to a scene of a media content that is presented to the user. In such an embodiment, records that document scene characteristics may be used to match a group of interactive applications from a repository of interactive applications which are available to a user, for example stored on a client terminal.</p><p id="p0133" num="0133">According to an aspect of some embodiments of the present disclosure there are provided methods and systems of dynamically selecting interactive applications from a repository of interactive applications which are available to a user, for example stored on a client terminal, based on current viewing pattern of a user.</p><p id="p0134" num="0134">Before explaining at least one embodiment of the disclosure in detail, it is to be understood that the disclosure is not necessarily limited in its application to the details of construction and the arrangement of the components and/or methods set forth in the following description and/or illustrated in the drawings and/or the Examples. The disclosure is capable of other embodiments or of being practiced or carried out in various ways.</p><p id="p0135" num="0135">Referring back now to <figref idrefs="f0001">FIG. 1</figref>, the system 100 may be used for dynamically selecting a group of interactive applications from a plurality of interactive applications which are made available to one or more user(s) of a client terminal, such as a customer premises equipment (CPE), for example a set-top-box or an internet protocol television (IPTV), based one or more characteristics of media content which currently presented and/or selected to be presented to the user(s), according to some embodiments of the present disclosure. Such a system allows presenting user(s) of a client terminal 102 with interactive applications which are relevant to currently presented and/or selected media content and avoiding overwhelming these users with redundant interactive applications which are not suitable for the content media item.</p><p id="p0136" num="0136">The media content may be a broadcasted content, a video on demand (VOD) content, a locally stored content, a recorded content, and/or a stream, for example a movie, a TV show, promotional content, a series, and/or the like. An interactive application may be any application designed to by presented before, after and/or in parallel to a media content item, including, but not limited to an internet app, a poll, a<!-- EPO <DP n="29"> --> chat, a game, a gambling mechanism, a data overlay that is adapted to the media content item, a data overlay that is adapted to another media content item and/or a quiz. The interactive applications may be locally installed on the client terminals and/or remotely installed on a network node, such as a server and accessed via the network 105. An interactive application may be implemented by an object, for example an app, which is downloaded to the hosting client terminal 102. This object may include instructions for generating an interactive user interface that is presented on the display of the client terminal and receives inputs from the user(s) thereof. The interactive user interface is optionally an overlay with a dynamic graphical user interface (GUI) that is presented in conjunction with of media content that is broadcasted over the internet and/or a communication network such as a cable network and/or satellite services, provided as VOD content or a stream over the internet and/or a communication network such as a cable network and/or satellite services and/or locally recorded at one or more client terminals.</p><p id="p0137" num="0137">Optionally, the system 100 includes a plurality of client modules 101 which are installed in the client terminals 102. The client module 101 may be implemented as a software component executed by the hosting client terminal 102, for example an application from an app store, an add-on, and/or a standalone application and/or a hardware component that is installed in the hosting client terminal 102, for example an integrated circuit (IC). The client terminal 102 may be a set-top-box (STB), which is connected to a screen, such as a television (TV) 109, an IPTV, also known as a smart TV and/or a connected TV, and/or a computing unit, such as a laptop, a desktop, a Smartphone, a cellular device, a tablet and/or any other device that can be used for providing internet TV service. Optionally, the client module 101 may establish a communication with the central unit 103 using a proxy device, such as a cellular device that communicates with the client terminal 102 and/or the like. In such a manner, the client module 101 may forward to and/or receive data from the central unit 103 even when the client terminal is not connected to the central unit 103. For example, if the client terminal 102 is a set top box which has low free bandwidth, a cellular connection with the central unit 103 may be established via a cellular device. Optionally, the central unit 103 is connected to each one of the client terminals 102 via a network 105, such as the Internet and/or an Ethernet and/or WLAN.<!-- EPO <DP n="30"> --></p><p id="p0138" num="0138">Optionally, the central unit 103 includes and/or connected to a database 104 that allows storing a plurality of media content records, each having a media content identification (ID) and a plurality of media content characteristics which are indicative of a genre, a length, a rating, an age rating, a language, an origin country, a production source, a production date, indirect advertising content and/or the like.</p><p id="p0139" num="0139">As further described below, the media content records allow the central unit 103, for example a matching module, to reply to requests for media content characteristics where each request is indicative of a certain media content with plurality of media content characteristics, for example as described below.</p><p id="p0140" num="0140">Optionally, each client module 101 is set to monitor the media content that is watched by a user in run time and forwards a request for media content characteristics with the ID of the currently watched media content item and/or the selected media content item to the central unit. For example, the characteristics request is sent via a push mechanism, such as cloud to device message (C2DM), by a pull mechanism wherein the central unit 103 polls information pertaining to the currently presented and/or selected media content, and/or by a notification mechanism wherein the client module 101 sequentially notifies the central unit 103, for example every number of seconds and/or when the subscriber changes the presented media content. In such a manner, as further described below, a client terminal of a user which views certain media content may receive a response indicative of media content characteristics of the certain media content.</p><p id="p0141" num="0141">Optionally, the central unit 103 includes an updating module which manages one or more web crawlers for updating existing plurality of media content records and/or adding new plurality of media content records, for example based on an analysis of electronic program guides (EPGs). In such an embodiment, the system 100 may automatically record the date each media content record was last updated. Optionally, the central unit 103 allows user to update and/or add media content records, for example using a user interface that is presented thereto, for example via a interactive application that is hosted by the client terminal and/or accessed thereto.</p><p id="p0142" num="0142">Reference is also made to <figref idrefs="f0005">FIG. 4</figref>, which is a flowchart of a method 400 of selecting and/or filtering interactive applications from a plurality of interactive applications which are available to a user and/or a client terminal, according to some embodiments of the present disclosure.<!-- EPO <DP n="31"> --></p><p id="p0143" num="0143">As shown at 402, the client module 101 identifies, optionally automatically, a media content item that is currently presented and/or selected to be presented on the hosting client terminal 102. As used herein, a selected to be presented media content item may be an ordered media content item, a recorded media content item, and/or the like. The media content item is optionally received from a signal source such as an Ethernet cable, a satellite dish, a coaxial cable (see cable television), a telephone line including digital subscriber line (DSL) connections, broadband over power line, or even an ordinary very high frequency (VHF) or ultrahigh frequency (UHF) antenna. The media content item may be a video on demand item that is played on the client terminal, a file played from a memory and/or a stream received from a portal. Content, in this context, could mean any or all of video, audio, Internet webpages, interactive games, or other possibilities. The identification may be performed by analyzing the stream, the file, and/or the broadcast that includes the media content item, for instance by decoding a data channel and/or the like. Optionally, identification may be performed by detecting the broadcast source of the media content, for example the identification of the broadcasted channel, and identifying the media content that is currently broadcasted by analyzing one or more electronic program guides (EPG) in light of the current time. Optionally, identification may be performed by acquiring a real time data from a server in a cloud pertaining to media content, such as broadcasted content, IPTV, local files, VOD files, and/or the like. The cloud server optionally notifies that the client terminal which application(s) to choose and present. The client module 101 optionally allows one or more available applications to receive push notifications which are distributed with certain media content or media content type and to be launched when the system recognizes that such media content is currently been broadcasted.</p><p id="p0144" num="0144">As further described below, the decision of which applications to launch, show, and/or expose is not only based on the content but also based on the characteristics of the user who is currently watching the media content and/or friends which are currently watching the same media content. For example, if the subscriber watches a football match alone, she can get one type of applications and if the subscriber watches it with my friends a different set of applications is received.</p><p id="p0145" num="0145">This allows identifying one or more media content characteristics of the selected and/or currently played media content item. Optionally, as shown at 403, the<!-- EPO <DP n="32"> --> client module 101 sends an identifier of the media content item as a request and/or a query to receive from the central unit 103 the content media content characteristics thereof. Additionally or alternatively, the client module 101 sends a general request for the content media content characteristics of the selected and/or currently played media content item, without having information about the selected and/or currently played media content item. In such an embodiment, the information may be gathered from a third party, for example, a content provider, such as a VOD server, based on the identity of the client terminal 102, for example its internet protocol (IP) address.</p><p id="p0146" num="0146">The central unit 103, optionally as shown at 404, reviews the database 104 to identify a media content record of the selected and/or currently watched media content based on the identifier. As shown at 405, at least the media content characteristics from the media content record are now forwarded to the client module 101 as a response to the request.</p><p id="p0147" num="0147">As shown at 406, the client module 101 manages and/or accesses a dataset which includes entries and/or records indicative of a plurality of interactive applications available for presentation on a respective hosting client terminal 102. An available interactive application is optionally an application available for use by user(s) of the client terminal 102 without a registration process and/or an installation process. For instance, the interactive applications dataset lists the interactive applications which have been purchased, downloaded, and/or selected by the user and/or have been licensed to the user. Additionally or alternatively, the interactive applications dataset lists the interactive applications which are available for purchase by the user(s) of the client terminal 102. Additionally or alternatively, the interactive applications dataset lists the interactive applications which have been downloaded to, installed on and/or otherwise associated with the client terminal 102. The records and/or entries of the interactive applications dataset may be provided to the client module 101 upon demand and/or accessed by a pull request. Additionally or alternatively, the interactive applications dataset lists the interactive applications which are selected to the user(s) of the client terminal 102 based on one or more characteristics thereof, for example demographic data, user identifier, usage history and statistical analysis.</p><p id="p0148" num="0148">Optionally, each record and/or entry, for brevity referred to herein as an interactive application record, documents one or more suitable media content<!-- EPO <DP n="33"> --> characteristics of a respective interactive application. The suitable media content characteristics are indicative of properties of media content items to which the respective interactive application is suitable and/or not suitable, for example a genre, a length, a rating, an age rating, a language, an origin country, a production source, a production date, and/or the like. For example, the suitable media content characteristics of a sport gambling interactive application may be a genre = sport, a length = any, a rating=10/10, an age rating = 18&lt;, a language = English, an origin country = USA, and/or a production source = ESPN/NBC sports/FOX sports. In another example, the suitable media content characteristics of a trivia interactive application may be a genre = documentary, a length = any, an age rating = 12&lt;, and/or an origin country = any.</p><p id="p0149" num="0149">The suitable media content characteristics of the records in the interactive applications dataset and the media content characteristics of the selected and/or currently watched media content may be matched by the client module 101 to identify a group of interactive applications which are suitable for the selected and/or currently presented media content, as shown at 407. Each one of the suitable media content characteristics and/or the media content characteristics may be weighted. For example, the client module 101 matches between the media content characteristics from the respective media content record and the suitable media content characteristics of the interactive applications documented in the interactive application records. The group is either filtered from the interactive applications dataset and/or selected accordingly.</p><p id="p0150" num="0150">Optionally, the media content characteristics from the respective media content record is matched with the suitable media content characteristics of interactive applications from an app store 110. This allows presenting to the user with interactive applications which are suitable for the media content she is currently watching.</p><p id="p0151" num="0151">As shown at 408, indication of the members of the group is now presented on a display of the client terminal. For example, icons of the interactive application are presented to the user. Optionally, one or more members of the groups are automatically launched to be presented with the selected and/or currently presented media content and/or added to a dynamic menu.</p><p id="p0152" num="0152">The process depicted in 401-408 is optionally continuously repeated whenever the user changes the media content items she watches. In such a manner, interactive applications, which are presented to the user, are dynamically adapt to the media<!-- EPO <DP n="34"> --> content he consumes. For example, sport related interactive applications may be replaced with current matters interactive applications when the user switches from watching a soccer game to watching the news.</p><p id="p0153" num="0153">Optionally, the media content records and/or the interactive application records are updated by the operator of the system 100.</p><p id="p0154" num="0154">Additionally or alternatively, the media content records and/or the interactive application records are updated automatically by an updating module of the system 100. Such an updating may be performed using crawlers which crawl in interactive application data pages presented in records of EPG(s) and/or app store(s) and a semantic analysis module which analyzes the crawled content to extract media content characteristics and/or suitable media content characteristics in an automatic manner. Additionally or alternatively, the media content records and/or the interactive application records are updated by users of the system 100, for example via a graphical user interface that is available via the client terminals 102. The updating may be performed using window(s) that allow the user to input manually the media content characteristics and/or the suitable media content characteristics.</p><p id="p0155" num="0155">According to some embodiments of the present disclosure, media content items and/or interactive applications are tagged with one or more media content characteristics and/or suitable media content characteristics. In such an embodiment, the media content items and/or interactive applications are set with a metadata field that can be used for matching therebetween. For example, each one of the media content item files and/or interactive application modules may include a record with the respective metadata. This allows a client module to select and/or filter a group of interactive applications without using the central unit 103 and/or other network entities. Optionally, the software development kit (SDK) of the interactive applications allows developers to set suitable media content characteristics therefore.</p><p id="p0156" num="0156">According to some embodiments of the present disclosure, media content items are directly associated with interactive applications and/or <i>vice versa.</i> In such embodiments, an application developer can register her applications for a specific media content item, for example a broadcasted show, for example by specifying EPG name and/or time and/or date and the system 100. In such an embodiment, the media content record of the media content item includes identifier(s) of one or more interactive applications. This allows the client module 101 to add the respective<!-- EPO <DP n="35"> --> interactive applications to the selected group when the respective media content item is presented or about to be presented on the client terminal 102. Alternatively, the interactive application records includes a media content item identifier that may be matched with the identifier of the selected and/or currently presented media content to determine whether the client module 101 has to add the respective interactive application to the selected group. In such an embodiment, interactive application which are designated for a certain show may be selected automatically when the show is aired or about to the aired.</p><p id="p0157" num="0157">According to some embodiments of the present disclosure, interactive applications are selected to be suggested to the user according to friends of the user which also watch the currently presented media content item and/or about to watch the currently presented media content item. For example, a chat application may be automatically launched and/or added to the interactive application suggested to the user if one or more of her friends currently watch the same content. Optionally, the interactive applications are commercial applications which contain a commercial content.</p><p id="p0158" num="0158">According to some embodiments of the present disclosure, interactive applications are selected to be suggested to the user according media content characteristics which are acquired from external sources, such as a clock, an EPG, a web page which includes media content items description, a media center system and/or the like.</p><p id="p0159" num="0159">Reference is now also made to <figref idrefs="f0006">FIG. 5</figref>, which is a method of dynamically selecting one or more of the interactive applications which are made available to user(s) of a client terminal based one or more characteristics of a media content scene which currently and/or selected to be presented to the user(s), according to some embodiments of the present disclosure. Block 406 is optionally as described above; however, blocks 302-305 describe operations for providing a user with an experience wherein the interactive applications which are suggested thereto and/or automatically launched are dynamically changed according to characteristics of the scene that is currently presented thereto.</p><p id="p0160" num="0160">As shown at 302, the scene is identified. For example, the identification may be according to the time elapsed since the media content has been aired and/or played. Additionally or alternatively, the identification may be according to the tags which are<!-- EPO <DP n="36"> --> added to the media content item. Now, as shown at 303, one or more scene characteristics of the identified scene are identified. A scene characteristic may be the scene timing, for example, an opening scene a closing scene and/or the like, a rating, an age rating, a language, a visual content related characteristic, for example related to objects depicted or not depicted in the scene, an audible content related characteristic, for example define whether a monolog, dialog and/or a background music are played, and/or the like. Optionally, in order to facilitate the acquiring of scene characteristics, each of the aforementioned media content records defines one or more scene characteristics per scene. This information may be acquired by a request sent to the central unit 103, for example as described above and/or according to tags which are added to the media content.</p><p id="p0161" num="0161">Now, as shown at 304, the scene characteristics of the currently presented scene are matched with the suitable media content characteristics of the interactive applications. Then, the one or more matched interactive applications are automatically presented to the user, for example launched and/or added to a dynamic menu as described above. Optionally, the process depicted in blocks 302-305 is repeated for all the scenes of the media content item. This allows a dynamic adaption of the interactive applications which are suggested to the user per scene.</p><p id="p0162" num="0162">Reference is now also made to <figref idrefs="f0006">FIG. 6</figref>, which is a method of dynamically selecting one or more of the interactive applications which are made available to user(s) of a client terminal based on current viewing pattern characteristics, according to some embodiments of the present disclosure. Blocks 406 and 408 are optionally as described above; however, new blocks 601-602 describe operations for providing a user with an experience wherein his viewing patterns effect the interactive applications which are suggested thereto and/or automatically launched to be presented thereto. In such an embodiment, the client module 101 monitors the viewing habits of the user. For example, the client module 101 identifies any of the following viewing patterns:
<ol><li>1. The period the user watches a media content item. This information may be gathered by monitoring the content that is displayed on or via the client terminal and/or by querying a respective display unit.</li><li>2. The media content item(s) the user watched before the currently presented media content item, for example during the last hour. This information may be<!-- EPO <DP n="37"> --> gathered by monitoring the content that is displayed on or via the client terminal and/or by querying a respective display unit.</li><li>3. The frequency of recent zapping of the user, for example the zapping frequency in last minutes, for example the last 5, 10, 15, and/or 30 minutes or any intermediate length. This information may be gathered by monitoring the content that is displayed on or via the client terminal and/or by querying a respective display unit.</li><li>4. The volume level at which the media content item(s) are played. This information may be gathered by querying or monitoring a respective display unit.</li><li>5. The display setting at which the media content item(s) are played. This information may be gathered by querying or monitoring a respective display unit.</li><li>6. The time of the day and/or the year, the day in the week. This information may be acquired from an integral and/or external clock module.</li></ol></p><p id="p0163" num="0163">In order to select interactive applications, which are adapted to the current viewing pattern of the user, each interactive application is tagged with suitable viewing pattern characteristics. These characteristics may be indicative of a suitable range of periods and/or suitable range of zapping frequencies and/or one or more suitable media content characteristics for matching with the characteristics of the media content item(s) the user watched before the currently presented media content item. This allows, as shown at 602, matching between the current viewing pattern and a group of the interactive applications. Optionally, this group of the interactive applications is added to group of interactive applications that is identified according to the media content characteristics, for example as described above. Optionally, some members of this group and the group of interactive applications which is identified according to the media content characteristics are selected according to a relative suitability which may be determined based on weights which are given to different media content and/or viewing pattern characteristics.</p><p id="p0164" num="0164">Still further aspects of the present disclosure, in some embodiments thereof, relate to visual communication and, more particularly, but not exclusively, to methods and systems for establishing multi participant video chat.<!-- EPO <DP n="38"> --></p><p id="p0165" num="0165">According to some embodiments of the present disclosure, there are provided methods and systems for establishing a multi participant video session between participants where a video sequence of each one of them is captured in real time and is ready to be transmitted to other participants. In these embodiments, the actual presence of the participant in an imaged space is verified and/or a manual indication is required. For example, the method delays the initiation of the multi participant video session until presence indications are acquired from all participants.</p><p id="p0166" num="0166">According to some embodiments of the present disclosure, there are provided methods and systems for managing a multi participant video session between participants based on their level of participation in the multi participant video session. In such embodiment, a multi participant video session may be halt and/or terminated, when the level of participation of one of the participants decreases below a certain minimum. Optionally, the level of participation, the halting, and/or terminating, may be determined and/or adjusted according to social connections among the participants, characteristics of one of more of the participants and/or the media content that is currently watched by the participants. For brevity, halting and terminating may be referred to herein interchangeably.</p><p id="p0167" num="0167">Systems according to the present disclosure may be implemented by a central unit which manages the multi participant video session(s) and/or a plurality of client modules which are installed in camera enhanced client terminals, optionally as described below.</p><p id="p0168" num="0168">Before explaining at least one embodiment of the disclosure in detail, it is to be understood that the disclosure is not necessarily limited in its application to the details of construction and the arrangement of the components and/or methods set forth in the following description and/or illustrated in the drawings and/or the Examples. The disclosure is capable of other embodiments or of being practiced or carried out in various ways.</p><p id="p0169" num="0169">Reference is now made to <figref idrefs="f0007">FIG. 7</figref>, which is a schematic illustration of a system 700 for establishing and/or managing a plurality of multi participant video sessions each among participants who use camera enhanced remote client terminals 702 which are connected to a network 705 based on participation level of each one of the participants in the multi participant video session, according to some embodiments of the present disclosure. The participation level may be evaluated by an analysis of<!-- EPO <DP n="39"> --> activity in the imaged spaces, for example in front of the camera enhanced remote client terminals 702 and/or by detecting the presence of the participants in these spaces and/or the absence of the participants from these spaces. The multi participant video session may be any communication between participants in real-time which involves the reception and/or transmission of video depicting the participants at different locations and optionally audio signals of the voice of the participants, for example a video chat, video telephony, and/or the like.</p><p id="p0170" num="0170">The multi participant video sessions, as further described below, may be implemented and/or managed by a central unit 703, which is optionally implemented on one or more web servers and/or a plurality of client modules 701 which are installed on the client terminals 702. During the multi participant video session, a user interface, such as a dynamic graphical user interface (GUI), is presented to each one of the participants, optionally on top of media content that is presented on the display of the respective client terminal.</p><p id="p0171" num="0171">It should be noted that though in the specification of this present application the multi participant video sessions are described as managed and/or processed by the central unit 703, the management and/or the processing may be performed by one or more of the client modules 701. For example, a multi participant video session is managed by the client module 701 which has been used to initiate it. In such embodiments, the communication between different client modules 701 may be performed over peer to peer connections and/or schemes.</p><p id="p0172" num="0172">The client module 701 may be implemented as a software component executed by the hosting client terminal 702, for example an application from an app store, an add-on, and/or a standalone application and/or a hardware component that is installed in the hosting client terminal 702, for example an integrated circuit (IC). The client terminal 702 may be a set-top-box (STB), which is connected to a screen, such as a television (TV) 709, an Internet Protocol television (IPTV), also known as a smart TV and/or Connected TV, and/or a computing unit, such as a laptop, a desktop, a Smartphone, a cellular device, a tablet and/or any other device that can be used for providing internet TV service.</p><p id="p0173" num="0173">Optionally, the central unit 703 is connected to the client modules 701 in each one of the client terminals 702 via the network 705, such as the Internet and/or an Ethernet and/or WLAN. In such an embodiment, the multi participant video session is<!-- EPO <DP n="40"> --> managed by the central unit 703. Optionally, the central unit 703 includes and/or connected to a database 704 that allows storing and updating information pertaining to the multi participant video sessions.</p><p id="p0174" num="0174">Reference is now also made to <figref idrefs="f0008">FIG. 8</figref> which is a flowchart 800 of a method for establishing a multi participant video session, according to some embodiments of the present disclosure. The method is optionally implemented by an entity managing the multi participant video session, for example one of the client terminals 702 or the central unit 703.</p><p id="p0175" num="0175">First, as shown at 801, a request to establish a multi participant video session between participants via camera enabled client terminals which are connected to the network 705 is received 705. As used herein, camera enabled client terminal is a client terminal connected to and/or integrated with a camera, for example any imaging device, for example a complementary metal oxide semiconductor CMOS based sensor, a charge coupled device (CCD) based sensor, an internet camera, and/or an integrated camera or an image sensor of a client terminal. The request may be an outcome of a user selection, for example a user which clicks on an icon indicative of a multi participant video session and/or one or more requested participants from a list that is presented on the display of his camera enabled client terminal 702. The requests are optionally received via the network 705 from the client modules 701. Each request may define the identity of the participants who should participate in the established multi participant video session. Optionally, as shown at 802, one or more messages which include a request to join the multi participant video session are forwarded to the camera enabled client terminals of the requested participants, for example as network messages.</p><p id="p0176" num="0176">Now, as shown at 803, the initiation of the multi participant video session is delayed until a presence indication and/or a participation level indication indicative of a presence of one of the participants in an imaged space, for example in front of a camera enabled client terminal is received from each one of the camera enabled client terminals to which a request has been sent.</p><p id="p0177" num="0177">The presence indication and/or the participation level indication are optionally received from the client module 701. Optionally, the forwarding of the indication to a managing entity, such as the central unit 703, is performed in response to a user<!-- EPO <DP n="41"> --> selection, for example in response to a user clicking on a button indicative of accepting a request to join a multi participant video session.</p><p id="p0178" num="0178">Optionally, the forwarding of the presence indication to the managing entity is performed in response to an automatic detection of a presence of a participant in front of the camera of the respective camera enabled client terminal 702. For example, each client module 701, which receives a request to join a multi participant video session, captures a sequence of images using the respective camera and processes the image to detect the presence of the requested participant or any other potential participant in front of the camera enabled client terminal 702 and/or in any other imaged space. For example, a face detection algorithm is used to detect a face in front of the camera enabled client terminal 702, for example see <nplcit id="ncit0001" npl-type="s"><text>Yao-Jiunn Chen, Simple Face-detection Algorithm Based on Minimum Facial Features, the 33rd Annual Conference of the IEEE Industrial Electronics Society (IECON) Nov. 5-8, 2007, Taipei, Taiwan</text></nplcit>, which is incorporated herein by reference. In another embodiment, the presence of the face of a particular requested participant in the captured image sequence is detected. For example, a face recognition algorithm is used to determine whether the face of the requested participant is in an imaged space, for example in front of the camera enabled client terminal 702 or not. In such an embodiment, data pertaining to facial features of the participant and/or a reference image thereof are stored, optionally on the respective client terminal, and/or sent with the request, to allow identifying that the face in the image sequence are of the requested participant. For example, see <nplcit id="ncit0002" npl-type="s"><text>H. Schneiderman, T. Kanade. "A Statistical Method for 3D Object Detection Applied to Faces and Cars", IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2000</text></nplcit>) and <nplcit id="ncit0003" npl-type="s"><text>Paul Viola, et. al., Robust Real-Time Face Detection, International Journal of Computer Vision 57(2), 137-154, 2004</text></nplcit>, which are incorporated herein by reference.</p><p id="p0179" num="0179">Now, as shown at 804, a multi participant video session is established between the requested participants via the camera enabled client terminals after presence indications are received from all the requested participants. In such a manner, none of the participants is imaged without giving his consent to participate in the multi participant video session. When the multi participant video session is established, a video sequence captured by each one of the camera enabled client terminals is forwarded to be presented on displays of some or all of the other camera enabled client terminals which are used for the multi participant video session. This video sequence<!-- EPO <DP n="42"> --> is not displayed when the multi participant video session is delayed. As the multi participant video session is established only when all the participants are actually present in imaged spaces, for example in front of the camera enabled client terminals and therefore imaged, the method assures reciprocal exposure among the participants. That is to say that a first participant may be displayed with a live image of a second participant if and only if the second participant sees the first participant.</p><p id="p0180" num="0180">Reference is now also made to <figref idrefs="f0008">FIG. 9</figref> which is a flowchart 900 of a method for managing a multi participant video session, according to some embodiments of the present disclosure. After a multi participant video session is established, for example as described in <figref idrefs="f0008">FIG. 8</figref> and depicted in 901, participation and/or participation level of some or all of the participants is monitored during multi participant video session, as shown at 902. It should be noted that participation may be considered as presence in an image space, such as the space in front of the camera enhanced client terminal, a presence with a certain level of activity, for example a level of movement and/or the frequency of speech detection, and/or a period of presence with an active rule in the multi participant video session. Optionally, the level of participation that is required from each participant may be defined by him, for example using a GUI that is presented thereto. For example, the participation may be set according to the level of privacy of the participant. A high level of privacy may require active participation in the multi participant video session and a low level of privacy may require presence only.</p><p id="p0181" num="0181">The monitoring of participation or a participation level of a participant is optionally performed by analyzing an image sequence that is captured by the respective camera enhanced client terminal. In such embodiments, the respective client module 702 may perform an image processing analysis, for example based on any of the face detection and/or recognition algorithms which are described above. The detection and/or recognition of a face gazing at a display of the respective camera enhanced client terminal is indicative that a person is currently viewing the image that is presented thereto, namely an image of one or more participants of the multi participant video session. This may be considered as an active participation in the multi participant video session. Optionally, if the eyes of the imaged face are closed and/or if the person that not look at the display for a certain period, an indication of luck of participation is received. As further described below, this may lead to the<!-- EPO <DP n="43"> --> termination of the multi participant video session or the participation of the respective participant in the multi participant video session.</p><p id="p0182" num="0182">Additionally or alternatively, the participation of each participant is optionally monitored by analyzing an audio sequence that is captured by the camera enhanced client terminal 702. For example, a speech analysis is made to detect whether the participant talks during the multi participant video session. The speech analysis is optionally continuous along the monitoring period so as to determine whether the participant takes an active part in the multi participant video session or not. Optionally, speech patterns are analyzed to determine if the participant talks with person(s) who do not take part in the multi participant video session. Such speech patterns are optionally indicative that the participant does not participate actively in the multi participant video session.</p><p id="p0183" num="0183">The participation monitoring allows detecting breaks in the participation of participants of the multi participant video session, for example as shown at 903. For example, a break of more than a certain period, for example 1 minute, 5 minutes, 15 minutes or any intermediate or longer period is detected according to an analysis of video and/or audio sequences. The break is detected when no participation or sparse participation is identified during a certain period. As used herein, a sparse participation means a detection of a participation for less than a minimal period, for example a participation for an interval of less than 1 minute, optionally during a monitoring period of more than a certain interval, for example more than 10 minutes.</p><p id="p0184" num="0184">As shown at 904, when a break is detected, the multi participant video session or the participation of the respective participant in the multi participant video session may be automatically terminated or a notification pertaining to the multi participant video session may be sent to the respective participant(s). For example, the sent notification is presented on the display and facilitates the participant to select whether she wants to participate with the multi participant video session or not. Optionally, if not answer is received, the multi participant video session or the participation of the participant is terminated. In another example, the multi participant video session is automatically put on hold, requesting some or all of the participants to reauthorize the resuming thereof. If no break is detected, the multi participant video session continues until it ends by one or all of the participants.<!-- EPO <DP n="44"> --></p><p id="p0185" num="0185">As the multi participant video session is terminated and/or put on hold when one or more of the participants do not take active part in the participation, the method reduces the timeslot during which a certain participant may be exposed to images of a another participant which are taken when the other participant did not notice.</p><p id="p0186" num="0186">Optionally, the management of the multi participant video session is determined according to the classification of the participants. In such an embodiment, social connections among participants may be extracted from a social network and/or a database mapping social connections among a plurality of users, such as subscribers. For example, if not all the participants are socially connected, the multi participant video session may be terminated automatically after a break of one minute; however, if all the participants are socially connected, a notification asking a non active participant to confirm his will to participate in the multi participant video session is displayed. Participants may also be classified according to one or more characteristics thereof, for example demographic characteristics which are taken from the participants' profiles.</p><p id="p0187" num="0187">As described above, the camera enhanced client terminal is optionally a television, an IPTV, a set-top-box or any other devices that is set to display media content in parallel to the conducting of the multi participant video session. Optionally, the management of the multi participant video session is determined according to which media content is currently presented on a display of the camera enhanced client terminals of the participants. This media content may be broadcasted, streamed and/or locally stored on the client terminal or on a database which is accessed by it. For example, if the media content, which is displayed on the client terminals 702 of the participants, is of a certain type, such as a football match, then the break period which induces a termination of the multi participant video session is increased, for example from a default of 5 min to 15 min. In another example, the multi participant video session is put on hold when the user zaps from one channel to another, pauses the content media, and/or otherwise performs an action which indicates that the content she is watching is not synchronized with the content other participants are watching.</p><p id="p0188" num="0188">It is expected that during the life of a patent maturing from this application many relevant methods and systems will be developed and the scope of the term a client terminal, a central unit, a network and a message is intended to include all such new technologies <i>a priori.</i><!-- EPO <DP n="45"> --></p><p id="p0189" num="0189">As used herein the term "about" refers to ± 10 %.</p><p id="p0190" num="0190">The terms "comprises", "comprising", "includes", "including", "having" and their conjugates mean "including but not limited to". This term encompasses the terms "consisting of" and "consisting essentially of".</p><p id="p0191" num="0191">The phrase "consisting essentially of" means that the composition or method may include additional ingredients and/or steps, but only if the additional ingredients and/or steps do not materially alter the basic and novel characteristics of the claimed composition or method.</p><p id="p0192" num="0192">As used herein, the singular form "a", "an" and "the" include plural references unless the context clearly dictates otherwise. For example, the term "a compound" or "at least one compound" may include a plurality of compounds, including mixtures thereof.</p><p id="p0193" num="0193">The word "exemplary" is used herein to mean "serving as an example, instance or illustration". Any embodiment described as "exemplary" is not necessarily to be construed as preferred or advantageous over other embodiments and/or to exclude the incorporation of features from other embodiments.</p><p id="p0194" num="0194">The word "optionally" is used herein to mean "is provided in some embodiments and not provided in other embodiments". Any particular embodiment of the disclosure may include a plurality of "optional" features unless such features conflict.</p><p id="p0195" num="0195">Throughout this application, various embodiments of this disclosure may be presented in a range format. It should be understood that the description in range format is merely for convenience and brevity and should not be construed as an inflexible limitation on the scope of the disclosure. Accordingly, the description of a range should be considered to have specifically disclosed all the possible subranges as well as individual numerical values within that range. For example, description of a range such as from 1 to 6 should be considered to have specifically disclosed subranges such as from 1 to 3, from 1 to 4, from 1 to 5, from 2 to 4, from 2 to 6, from 3 to 6 etc., as well as individual numbers within that range, for example, 1, 2, 3, 4, 5, and 6. This applies regardless of the breadth of the range.</p><p id="p0196" num="0196">Whenever a numerical range is indicated herein, it is meant to include any cited numeral (fractional or integral) within the indicated range. The phrases "ranging/ranges between" a first indicate number and a second indicate number and<!-- EPO <DP n="46"> --> "ranging/ranges from" a first indicate number "to" a second indicate number are used herein interchangeably and are meant to include the first and second indicated numbers and all the fractional and integral numerals therebetween.</p><p id="p0197" num="0197">It is appreciated that certain features of the disclosure, which are, for clarity, described in the context of separate embodiments, may also be provided in combination in a single embodiment. Conversely, various features of the disclosure, which are, for brevity, described in the context of a single embodiment, may also be provided separately or in any suitable subcombination or as suitable in any other described embodiment of the disclosure. Certain features described in the context of various embodiments are not to be considered essential features of those embodiments, unless the embodiment is inoperative without those elements.</p><p id="p0198" num="0198">Although the disclosure has been described in conjunction with specific embodiments thereof, it is evident that many alternatives, modifications and variations will be apparent to those skilled in the art. Accordingly, it is intended to embrace all such alternatives, modifications and variations that fall within the spirit and broad scope of the appended claims.</p><p id="p0199" num="0199">All publications, patents and patent applications mentioned in this specification are herein incorporated in their entirety by reference into the specification, to the same extent as if each individual publication, patent or patent application was specifically and individually indicated to be incorporated herein by reference. In addition, citation or identification of any reference in this application shall not be construed as an admission that such reference is available as prior art to the present disclosure. To the extent that section headings are used, they should not be construed as necessarily limiting.</p></description><claims mxw-id="PCLM90459158" lang="EN" load-source="patent-office"><!-- EPO <DP n="47"> --><claim id="c-en-0001" num="0001"><claim-text>A method for selecting at least one interactive application, comprising:
<claim-text>identifying a plurality of interactive applications which are available to a client terminal of a user;</claim-text>
<claim-text>identifying a media content item being currently presented on said client terminal;</claim-text>
<claim-text>automatically identifying at least one media content characteristic of said media content item, wherein each of said at least one media content characteristic is one of: a genre, a length, a rating, an age rating, a language, an origin country, a production source, a production date and indirect advertising content;</claim-text>
<claim-text>automatically selecting a group of said plurality of interactive applications according to said at least one media content characteristic; and</claim-text>
<claim-text>instructing a presentation of icons corresponding to members of said group on a display of said client terminal concurrently with presenting said media content item.</claim-text></claim-text></claim><claim id="c-en-0002" num="0002"><claim-text>The method of claim 1, wherein one of said at least one media content characteristic is a genre.</claim-text></claim><claim id="c-en-0003" num="0003"><claim-text>The method of any of the previous claims, wherein one of said at least one media content characteristic is a length.</claim-text></claim><claim id="c-en-0004" num="0004"><claim-text>The method of any of the previous claims, wherein one of said at least one media content characteristic is an age rating.</claim-text></claim><claim id="c-en-0005" num="0005"><claim-text>The method of any of the previous claims, wherein one of said at least one media content characteristic is a rating.<!-- EPO <DP n="48"> --></claim-text></claim><claim id="c-en-0006" num="0006"><claim-text>The method of any of the previous claims, wherein one of said at least one media content characteristic is a language.</claim-text></claim><claim id="c-en-0007" num="0007"><claim-text>The method of any of the previous claims, wherein one of said at least one media content characteristic is an origin country.</claim-text></claim><claim id="c-en-0008" num="0008"><claim-text>The method of any of the previous claims, wherein one of said at least one media content characteristic is a production source.</claim-text></claim><claim id="c-en-0009" num="0009"><claim-text>The method of any of the previous claims, wherein one of said at least one media content characteristic is a production date.</claim-text></claim><claim id="c-en-0010" num="0010"><claim-text>The method of any of the previous claims, wherein one of said at least one media content characteristic is indirect advertising content.</claim-text></claim><claim id="c-en-0011" num="0011"><claim-text>The method of any of the previous claims, wherein said media content item is selected from a group consisting of a broadcast and a video on demand (VOD) content selected by said user.</claim-text></claim><claim id="c-en-0012" num="0012"><claim-text>The method of any of the previous claims, wherein said media content item is locally stored on a memory selected from a group consisting of a memory of said client terminal and a memory device connected to said client terminal.<!-- EPO <DP n="49"> --></claim-text></claim><claim id="c-en-0013" num="0013"><claim-text>The method of any of the previous claims, wherein said plurality of interactive applications is stored on a member of a group consisting of said client terminal and a remote network node.</claim-text></claim><claim id="c-en-0014" num="0014"><claim-text>A system for selecting at least one interactive application, comprising:
<claim-text>a database (104) storing a plurality of media content records each indicative of one media content item and at least one corresponding media content characteristic, wherein each one of said media content characteristic is one of: a genre, a length, a rating, an age rating, a language, an origin country, a production source, a production date and indirect advertising content;</claim-text>
<claim-text>a central unit (103) that is configured to receive a request with an identifier of a media content item currently presented by a client terminal (102) and to automatically send a response with said at least one corresponding media content characteristic from said plurality of media content records; and</claim-text>
<claim-text>a client module (101) installed on said client terminal; said client module is configured to receive said response, to automatically select a group of a plurality of interactive applications available to said client terminal according to said at least one media content characteristic and to present icons corresponding to members of said group on a display of said client terminal concurrently with presenting said media content item.</claim-text></claim-text></claim><claim id="c-en-0015" num="0015"><claim-text>A computer program product for selecting at least one interactive application, said computer program product comprising:
<claim-text>a non-transitory computer readable storage medium having stored thereon:<!-- EPO <DP n="50"> -->
<claim-text>first program instructions executable by a processor to cause said processor to store in a database a plurality of media content records each indicative of one media content item and at least one corresponding media content characteristic, wherein each one of said media content characteristic is one of: a genre, a length, a rating, an age rating, a language, an origin country, a production source, a production date and indirect advertising content;</claim-text>
<claim-text>second program instructions executable by a central unit to cause said central unit to receive a request with an identifier of a media content item currently presented by a client terminal and automatically send a response with said at least one corresponding media content characteristic from said plurality of media content records; and</claim-text>
<claim-text>third program instructions executable by a client module installed on said client terminal to cause said client module to receive said response; automatically select a group of a plurality of interactive applications available to said client terminal according to said at least one media content characteristic; and present icons corresponding to members of said group on a display of said client terminal concurrently with presenting said media content item.</claim-text></claim-text></claim-text></claim></claims><drawings mxw-id="PDW20421895" load-source="patent-office"><!-- EPO <DP n="51"> --><figure id="f0001" num="1"><img id="if0001" file="imgf0001.tif" wi="165" he="201" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="52"> --><figure id="f0002" num="2A,2B"><img id="if0002" file="imgf0002.tif" wi="165" he="223" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="53"> --><figure id="f0003" num="2C,2D"><img id="if0003" file="imgf0003.tif" wi="165" he="227" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="54"> --><figure id="f0004" num="3"><img id="if0004" file="imgf0004.tif" wi="165" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="55"> --><figure id="f0005" num="4"><img id="if0005" file="imgf0005.tif" wi="165" he="226" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="56"> --><figure id="f0006" num="5,6"><img id="if0006" file="imgf0006.tif" wi="165" he="226" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="57"> --><figure id="f0007" num="7"><img id="if0007" file="imgf0007.tif" wi="165" he="210" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="58"> --><figure id="f0008" num="8,9"><img id="if0008" file="imgf0008.tif" wi="165" he="220" img-content="drawing" img-format="tif"/></figure></drawings><search-report-data><doc-page id="srep0001" file="srep0001.tif" wi="156" he="233" type="tif"/><doc-page id="srep0002" file="srep0002.tif" wi="156" he="233" type="tif"/></search-report-data><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
