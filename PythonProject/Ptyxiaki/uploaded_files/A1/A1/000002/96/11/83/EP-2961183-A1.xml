<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2961183-A1" country="EP" doc-number="2961183" kind="A1" date="20151230" family-id="51176302" file-reference-id="316857" date-produced="20180824" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="160451159" ucid="EP-2961183-A1"><document-id><country>EP</country><doc-number>2961183</doc-number><kind>A1</kind><date>20151230</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-14306020-A" is-representative="YES"><document-id mxw-id="PAPP193865286" load-source="patent-office" format="original"><country>EP</country><doc-number>14306020.0</doc-number><date>20140627</date><lang>EN</lang></document-id><document-id mxw-id="PAPP193865287" load-source="docdb" format="epo"><country>EP</country><doc-number>14306020</doc-number><kind>A</kind><date>20140627</date><lang>EN</lang></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC162030224" ucid="EP-14306020-A" load-source="docdb"><document-id format="epo"><country>EP</country><doc-number>14306020</doc-number><kind>A</kind><date>20140627</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL-1988522275" load-source="docdb">H04N  21/6587      20110101ALI20140930BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-1988522601" load-source="docdb">H04N  21/218       20110101ALI20140930BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-1988523864" load-source="docdb">H04N  21/4728      20110101AFI20140930BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-1988527783" load-source="docdb">H04N  21/2343      20110101ALI20140930BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-1984699065" load-source="docdb" scheme="CPC">H04N  21/4728      20130101 LI20160106BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1984701743" load-source="docdb" scheme="CPC">H04N  21/41407     20130101 LI20151231BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1984703187" load-source="docdb" scheme="CPC">H04N  21/6587      20130101 LI20160106BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1984704098" load-source="docdb" scheme="CPC">H04N  21/47205     20130101 FI20151231BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1984704634" load-source="docdb" scheme="CPC">H04N  21/42206     20130101 LI20151231BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987772042" load-source="docdb" scheme="CPC">H04N  21/21805     20130101 LI20140926BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987773071" load-source="docdb" scheme="CPC">H04N  21/234318    20130101 LI20140929BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987787394" load-source="docdb" scheme="CPC">H04N  21/234363    20130101 LI20140929BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT165544943" lang="DE" load-source="patent-office">Verfahren, System und entsprechende Auswahlvorrichtung zum Navigieren in Videoinhalten mit ultrahoher Auflösung</invention-title><invention-title mxw-id="PT165544944" lang="EN" load-source="patent-office">Method, system and related selection device for navigating in ultra high resolution video content</invention-title><invention-title mxw-id="PT165544945" lang="FR" load-source="patent-office">Procédé, système et dispositif de sélection associés pour naviguer dans un contenu vidéo ultra haute résolution</invention-title><citations><patent-citations><patcit mxw-id="PCIT404502640" load-source="docdb" ucid="EP-2645713-A1"><document-id format="epo"><country>EP</country><doc-number>2645713</doc-number><kind>A1</kind><date>20131002</date></document-id><sources><source name="SEA" category="IY" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335961674" load-source="docdb" ucid="US-20090284601-A1"><document-id format="epo"><country>US</country><doc-number>20090284601</doc-number><kind>A1</kind><date>20091119</date></document-id><sources><source name="SEA" category="Y" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT404502641" load-source="docdb" ucid="US-20090300692-A1"><document-id format="epo"><country>US</country><doc-number>20090300692</doc-number><kind>A1</kind><date>20091203</date></document-id><sources><source name="SEA" category="XI" created-by-npl="N"/></sources></patcit></patent-citations><non-patent-citations><nplcit><text>BORJI, A.; SIHITE, D. N.; ITTI, L.: "Quantitative analysis of human-model agreement in visual saliency modeling: A comparative study", IMAGE PROCESSING, IEEE TRANSACTIONS ON, vol. 22, no. 1, 2013, pages 55 - 69, XP011492232, DOI: doi:10.1109/TIP.2012.2210727</text><sources><source mxw-id="PNPL62638732" load-source="docdb" name="APP"/></sources></nplcit><nplcit><text>CHANGCAI LAI ET AL: "Efficient intra mode selection using motion affected region tracking", VISUAL COMMUNICATIONS AND IMAGE PROCESSING; 11-7-2010 - 14-7-2010; HUANG SHAN, AN HUI, CHINA,, 11 July 2010 (2010-07-11), XP030082239</text><sources><source mxw-id="PNPL62638733" load-source="docdb" name="SEA" category="A"/></sources></nplcit></non-patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR1103324516" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>ALCATEL LUCENT</last-name><address><country>FR</country></address></addressbook></applicant><applicant mxw-id="PPAR1103320267" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>ALCATEL LUCENT</last-name></addressbook></applicant><applicant mxw-id="PPAR1101646003" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Alcatel Lucent</last-name><iid>101464136</iid><address><street>148/152 Route de la Reine</street><city>92100 Boulogne-Billancourt</city><country>FR</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR1103340174" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>RONDÃO ALFACE PATRICE</last-name><address><country>BE</country></address></addressbook></inventor><inventor mxw-id="PPAR1103332116" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>Rondão Alface, Patrice</last-name></addressbook></inventor><inventor mxw-id="PPAR1101642229" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Rondão Alface, Patrice</last-name><address><street>c/o Alcatel-Lucent Bell NV Copernicuslaan 50</street><city>2018 Antwerpen</city><country>BE</country></address></addressbook></inventor><inventor mxw-id="PPAR1103336580" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>MACQ JEAN-FRANÇOIS</last-name><address><country>BE</country></address></addressbook></inventor><inventor mxw-id="PPAR1103303649" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>Macq, Jean-François</last-name></addressbook></inventor><inventor mxw-id="PPAR1101651844" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>Macq, Jean-François</last-name><address><street>c/o Alcatel-Lucent Bell NV Copernicuslaan 50</street><city>2018 Antwerpen</city><country>BE</country></address></addressbook></inventor><inventor mxw-id="PPAR1103309164" load-source="docdb" sequence="3" format="epo"><addressbook><last-name>VERZIJP NICO</last-name><address><country>BE</country></address></addressbook></inventor><inventor mxw-id="PPAR1103343397" load-source="docdb" sequence="3" format="intermediate"><addressbook><last-name>Verzijp, Nico</last-name></addressbook></inventor><inventor mxw-id="PPAR1101649976" load-source="patent-office" sequence="3" format="original"><addressbook><last-name>Verzijp, Nico</last-name><address><street>c/o Alcatel-Lucent Bell NV Copernicuslaan 50</street><city>2018 Antwerpen</city><country>BE</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR1101647712" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>ALU Antw Patent Attorneys</last-name><iid>101179751</iid><address><street>Intellectual Property and Standards Copernicuslaan 50</street><city>2018 Antwerp</city><country>BE</country></address></addressbook></agent></agents></parties><international-convention-data><designated-states><ep-contracting-states><country mxw-id="DS660682902" load-source="docdb">AL</country><country mxw-id="DS660604762" load-source="docdb">AT</country><country mxw-id="DS660682928" load-source="docdb">BE</country><country mxw-id="DS660680677" load-source="docdb">BG</country><country mxw-id="DS660680814" load-source="docdb">CH</country><country mxw-id="DS660604870" load-source="docdb">CY</country><country mxw-id="DS660604767" load-source="docdb">CZ</country><country mxw-id="DS660682929" load-source="docdb">DE</country><country mxw-id="DS660604883" load-source="docdb">DK</country><country mxw-id="DS660604884" load-source="docdb">EE</country><country mxw-id="DS660603584" load-source="docdb">ES</country><country mxw-id="DS660680678" load-source="docdb">FI</country><country mxw-id="DS660680683" load-source="docdb">FR</country><country mxw-id="DS660682930" load-source="docdb">GB</country><country mxw-id="DS660604885" load-source="docdb">GR</country><country mxw-id="DS660682935" load-source="docdb">HR</country><country mxw-id="DS660604768" load-source="docdb">HU</country><country mxw-id="DS660680819" load-source="docdb">IE</country><country mxw-id="DS660604886" load-source="docdb">IS</country><country mxw-id="DS660680684" load-source="docdb">IT</country><country mxw-id="DS660604895" load-source="docdb">LI</country><country mxw-id="DS660680687" load-source="docdb">LT</country><country mxw-id="DS660604769" load-source="docdb">LU</country><country mxw-id="DS660680688" load-source="docdb">LV</country><country mxw-id="DS660680689" load-source="docdb">MC</country><country mxw-id="DS660781933" load-source="docdb">MK</country><country mxw-id="DS660781934" load-source="docdb">MT</country><country mxw-id="DS660603585" load-source="docdb">NL</country><country mxw-id="DS660680685" load-source="docdb">NO</country><country mxw-id="DS660781935" load-source="docdb">PL</country><country mxw-id="DS660680820" load-source="docdb">PT</country><country mxw-id="DS660603586" load-source="docdb">RO</country><country mxw-id="DS660680821" load-source="docdb">RS</country><country mxw-id="DS660781936" load-source="docdb">SE</country><country mxw-id="DS660680822" load-source="docdb">SI</country><country mxw-id="DS660680686" load-source="docdb">SK</country><country mxw-id="DS660781937" load-source="docdb">SM</country><country mxw-id="DS660604896" load-source="docdb">TR</country></ep-contracting-states><ep-extended-states><ep-extended-state-data><country>BA</country></ep-extended-state-data><ep-extended-state-data><country>ME</country></ep-extended-state-data></ep-extended-states></designated-states></international-convention-data></bibliographic-data><abstract mxw-id="PA166479529" lang="EN" load-source="patent-office"><p id="pa01" num="0001">The present invention relates to a method, system and related devices for navigating in ultra high resolution video content under control of a user navigation command originating from a client device, at least portions of the ultra high resolution video content being transmitted from a server towards said client device, where said method comprises the steps of receiving a user navigation command, said user navigation command indicating a navigation trajectory through said ultra high resolution video content and determining a local video saliency on said navigation selection trajectory by analyzing said ultra high resolution video content on said navigation trajectory through said ultra high resolution video content and<br/>
adapting characteristics of said navigation selection trajectory in function of said local video saliency on said navigation selection trajectory.
<img id="iaf01" file="imgaf001.tif" wi="138" he="85" img-content="drawing" img-format="tif"/></p></abstract><abstract mxw-id="PA166759341" lang="EN" source="EPO" load-source="docdb"><p>The present invention relates to a method, system and related devices for navigating in ultra high resolution video content under control of a user navigation command originating from a client device, at least portions of the ultra high resolution video content being transmitted from a server towards said client device, where said method comprises the steps of receiving a user navigation command, said user navigation command indicating a navigation trajectory through said ultra high resolution video content and determining a local video saliency on said navigation selection trajectory by analyzing said ultra high resolution video content on said navigation trajectory through said ultra high resolution video content and 
adapting characteristics of said navigation selection trajectory in function of said local video saliency on said navigation selection trajectory.</p></abstract><description mxw-id="PDES98404230" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><heading id="h0001">FIELD OF THE INVENTION</heading><p id="p0001" num="0001">The present invention relates to the field of navigating in ultra high resolution video content under control of a client device.</p><heading id="h0002">TECHNICAL BACKGROUND OF THE INVENTION</heading><p id="p0002" num="0002">In current interactive high resolution video consumption applications where the user is able to navigate in this video content using Pan-Tilt-Zoom (PTZ) commands at e.g. a mobile device (such as Zoomable Videos, FascinatE project etc), users are able to define by a few interactions the position and zoom level of their preferred field-of-view at a certain time t. Moreover, typically, a user is able to navigate in the panoramic or high resolution video content that is available remotely in the network but whose resolution is too large to be displayed entirely on the user device. The user can then zoom in the content and track moving objects in the video. This means, that for panoramic content, the user may select a portion of the high resolution content and only watch this selected portion, but alternatively he may also move this field of view so as to follow or track a spatial portion of the high resolution video content, such as a portion containing the user's favourite soccer player or containing the ball.</p><p id="p0003" num="0003">Further, such high spatial-resolution video, also referred to as Ultra High Definition video, is becoming more and more common. This type of content ranges from High Resolution, hereafter abbreviated with HD, video with 1920x1080 pixels per frame to higher resolution video either directly acquired with advanced optics and image sensors or obtained from stitched views from multiple cameras. In such interactive high resolution video applications, it has been observed that interactions for selecting a certain portion of the high resolution video content, although very much appreciated, are not easy to perform. For instance, in case of moving content, such as a ball in a soccer game, while it is easy to zoom in static portions of the content such as some part of the field or some part of the tribunes, where the user intends to track a given player or the ball, this user perceives the interactions for selecting the meant portion of the high resolution video content to be tedious and cumbersome after some time, due to the<!-- EPO <DP n="2"> --> interaction delay or the sensitivity of the interactions in respect to the speed and trajectory of the desired (fast) moving object or person.</p><heading id="h0003">SUMMARY OF THE INVENTION</heading><p id="p0004" num="0004">An objective of embodiments of the present invention is to provide with a method, a system and related devices for navigating in ultra high resolution video content under control of a client device of the known type, but wherein the aforementioned shortcoming or drawbacks of the known solutions are alleviated or overcome.</p><p id="p0005" num="0005">According to an aspect of the invention, there is provided a method for navigating in ultra high resolution video content under control of a client device user navigation command, said method comprising the steps of receiving a user navigation command, said user navigation command indicating a navigation selection trajectory through, e.g. a frame of, said ultra high resolution video content towards a navigation goal of a user of said client device and determining a local video saliency on said navigation selection trajectory by analyzing said ultra high resolution video content on said navigation selection trajectory through said ultra high resolution video content and adapting characteristics of said navigation selection trajectory in function of said local video saliency on said navigation selection trajectory.</p><p id="p0006" num="0006">Still further embodiments of the present invention relate to a system for navigating in ultra high resolution video content under control of a user navigation command originating from a client device, at least portions of said ultra high resolution video content being transmitted from a server towards said client device, wherein said system comprises:
<ul><li>a reception means, configured to receive said user navigation command, said user navigation command indicating a navigation trajectory through said ultra high resolution video content ; and</li><li>a video saliency determination means, configured to determine a local video saliency on said navigation selection trajectory by analyzing said ultra high resolution video content on said navigation trajectory through said ultra high resolution video content; and<!-- EPO <DP n="3"> --></li><li>a characteristics adaption means, configured to adapt characteristics of said navigation selection trajectory in function of said local video saliency on said navigation selection trajectory.</li></ul></p><p id="p0007" num="0007">Another embodiment of the present invention relates to a Selection Device for use in a system according to claim 7, wherein said selection device is configured to support navigating in ultra high resolution video content under control of said user navigation command originating from said client device, said selection device comprises:
<ul><li>Reception means, configured to receive said user navigation command, said user navigation command indicating a navigation trajectory through said ultra high resolution video content ; and</li><li>Video saliency determination means, configured to determine a local video saliency on said navigation selection trajectory by analyzing said ultra high resolution video content on said navigation trajectory through said ultra high resolution video content; and</li><li>Characteristics adaption means, configured to adapt characteristics of said navigation selection trajectory in function of said local video saliency on said navigation selection trajectory.</li></ul></p><p id="p0008" num="0008">The present invention relates to a Server for transmitting at least portions of ultra high resolution video content towards a client device, for use in a system according to claim 7, wherein said server comprises a selection device according to claim 8.</p><p id="p0009" num="0009">The present invention relates to a Network element for use in a system according to claim 7, wherein said network element is coupled to said server and or said client device wherein said network element comprises a selection device according to claim 8.</p><p id="p0010" num="0010">Finally, the present invention relates to a Computer program product comprising software adapted to perform the method steps according to any of claim 1 to 7 when executed on a data processing apparatus.</p><p id="p0011" num="0011">In this way, optionally by a server, at receiving of a user navigation command, where the user navigation command indicates a navigation selection trajectory through, e.g. a frame of, said ultra high resolution video content in direction of a navigation goal of a user of the client device, a local video saliency on the<!-- EPO <DP n="4"> --> navigation selection trajectory is determined by analyzing said ultra high resolution video content on the navigation selection trajectory through the ultra high resolution video content and subsequently, in function of the determined local video saliency on said navigation selection trajectory, characteristics of the navigation selection trajectory are adapted in such manner that the navigation selection trajectory characteristics better matches the navigation goals of a user of the client device.</p><p id="p0012" num="0012">The local video saliency can be determined in a continuous mode, that is, be determined for, e.g. each frame of the content, hence the processing may be performed at the e.g. same rate as the frame rate of the ultra high resolution video content or be determined at a restricted number of discrete moments that is, the saliency may be determined at a lower rate than the frame rate, so for every N frames of the content, e.g.; every 5 frames for a 120 frames per second content.</p><p id="p0013" num="0013">Determining local video saliency at a lower frame rate than the ultra high resolution video content may be motivated by the fact that the client device cannot display video frames at the same frame rate as the input content (some sports content can be available in 120 fps or even 300 fps, while tablet PCs can typically only decode 25 to 60fps).</p><p id="p0014" num="0014">The user navigation command, such as a PTZ command, in view of a current location or starting point of the navigation command indicates a navigation selection trajectory, such as a path through ,e.g. a frame of, the ultra high resolution video content in direction of the navigation goal of a user of such client device envisions. The current location or starting point of the navigation trajectory is determined based on or in view of the, at least part of said ultra high resolution video content being transmitted from said server towards said client device and rendered at said client device CD.</p><p id="p0015" num="0015">In order to improve the navigation along the meant navigation selection trajectory, the ultra high resolution video content is analyzed for determining the local video saliency on this navigation selection trajectory. The local video saliency is a measure for the amount of detail present at the navigation selection trajectory in such video.</p><p id="p0016" num="0016">Such a low local video saliency, a moderate local video saliency or a high local video saliency respectively signify a low amount of detail in the video, such as the blue sky, uniformly painted walls, road, etc., a moderate amount of detail such as a<!-- EPO <DP n="5"> --> statistically uniform texture but rough (high frequency content, e.g. vegetation, grass, tree's leaves, some texture patterns for carpets, curtains, roofs etc) or a high degree of video saliency such as either spatially salient or salient due to its motion; e.g. people, faces, soccer ball etc.</p><p id="p0017" num="0017">Subsequently, in function of the determined local video saliency the characteristics of the navigation selection trajectory may be adapted to better match matches the navigation goals of a user of the client device.</p><p id="p0018" num="0018">In an embodiment of the present invention, the navigation selection trajectory can be traversed at an adapted velocity that optimum suits the level of detail in the video at the analyzed location at the navigation selection trajectory through the video content.</p><p id="p0019" num="0019">The navigation trajectory may be traversed at a standard velocity but advantageously additionally in an accelerated velocity or at a decelerated velocity in the respective situation of a low local video saliency, i.e. in case relatively little change in video information such as a blue sky, uniformly painted walls, road, etc. on the navigation selection trajectory, or in case of relatively high local video saliency , i.e. very much change in video information such as such as objects either spatially salient or salient due to its motion like e.g. people, faces, soccer ball etc. on the navigation selection trajectory.</p><p id="p0020" num="0020">A further embodiment of the present invention relates to a method for navigating in ultra high resolution video content according to claim 1, wherein in case of a low local video saliency on said navigation trajectory through said ultra high resolution video content, a navigation speed is increased, in case of a high local video saliency on said navigation trajectory through said ultra high resolution video content a navigation speed is decreased.</p><p id="p0021" num="0021">The navigation selection trajectory may comprise zooming in /out interactions or combinations of zooming and panning or tilting where, in case of zooming, the average saliency of the selection typically varies and the speed of zooming in or zooming out may be accelerated or decelerated in the respective situation of an average low local video saliency on the current selection or high local video saliency in the current selection, respectively.<!-- EPO <DP n="6"> --></p><p id="p0022" num="0022">Due to the fact that the ultra high resolution video content on the navigation selection trajectory is analyzed, the local video saliency may be determined by pixel-level analysis such as the density of edges (using classical Canny, Sobel, Prewitt etc operators, or more advanced image processing algorithms based on multi-scale or multi-resolution filter banks such discrete wavelets, Gabor filters, Haar wavelet, oriented spectral filters (i.e. designed based on a Fast Fourier Transform)), or feature point detectors or texture analysis algorithms.</p><p id="p0023" num="0023">In order to quantify the importance of saliency, the measured responses to the analysis filters cited previously, a switching point must be set between relatively low and relatively high saliency values, which typically this is done via kurtosis estimation or by means of pre-defined value ranges adapted to the type of ultra high resolution video content, see: <nplcit id="ncit0001" npl-type="s"><text>Borji, A., Sihite, D. N., &amp; Itti, L. (2013). Quantitative analysis of human-model agreement in visual saliency modeling: A comparative study. Image Processing, IEEE Transactions on, 22(1), 55-69</text></nplcit> which is include by reference.<br/>
Another embodiment of the present invention relates to a method for navigating in ultra high resolution video content according to claim 1, wherein said characteristics of said navigation selection trajectory comprise navigation speed and direction.</p><p id="p0024" num="0024">The characteristics of said navigation selection trajectory comprise navigation speed and direction.</p><p id="p0025" num="0025">An embodiment of the present invention relates to a method for navigating in ultra high resolution video content according to claim 1, wherein said analyzing said ultra high resolution video content on said navigation trajectory through said ultra high resolution video content comprises counting edge transitions on said navigation trajectory.</p><p id="p0026" num="0026">The analyzing of said ultra high resolution video content on said navigation trajectory through said ultra high resolution video content may comprise counting edge transitions on said navigation trajectory.</p><p id="p0027" num="0027">By determining the number of edge transitions on said navigation trajectory a degree of variance of the video on the meant trajectory is determined as in case only little number of edge transitions occur, very few changes in the video are present which is for instance the case in blue sky, uniformly painted walls, road, etc.<!-- EPO <DP n="7"> --></p><p id="p0028" num="0028">On the other hand, in case very high number of changes occur, many changes in the video are present which is for instance the situation in vegetation (trees, grass, flowers, etc.), crowds of people, moving or static object boundaries, fireworks in the night etc.</p><p id="p0029" num="0029">Depending on the algorithm used for measuring saliency used, higher values of saliency could be measured for high variations that are known to be semantically more interesting.</p><p id="p0030" num="0030">For example, the use of a face detection algorithm combined with a measure of edge variations would give a higher saliency for a person's face or faces in a crowd than for the leaves of a tree (although the leaves might have more variations in terms of pixel intensity). Furthermore, saliency can also integrate temporal aspects, that is, high variations can also occur in terms of motion (objects moving with wind, running people, rolling ball) in contrast with low variations in terms of motion (typically static objects, regions). Here again, the saliency measure could integrate a measure of semantic interest, by e.g. providing lower saliency values for temporally periodic motion (waves, wind, water falling) than for the motion of an object that is specific to a period of time (ball rolling in one direction, player changing direction, etc).</p><p id="p0031" num="0031">Still another embodiment of the present invention relates to a method for navigating in ultra high resolution video content according to claim 1, wherein said analyzing said ultra high resolution video content on said navigation trajectory through said ultra high resolution video content comprises determining transitions or the variance of luminance content on said navigation trajectory.</p><p id="p0032" num="0032">The analyzing of said ultra high resolution video content on said navigation trajectory through said ultra high resolution video content comprises determining transitions or the variance of luminance content on said navigation selection trajectory.</p><p id="p0033" num="0033">By determining the number of transitions in the variance of the luminance on the navigation selection trajectory the saliency is determined as in case of as in case only little number of luminance transitions occur very few changes in the video are present which is for instance the case in blue sky, uniformly painted walls, road, etc.</p><p id="p0034" num="0034">An additional embodiment of the present invention relates to a method according to claim 1, wherein said navigation selection command comprises a Pan-Tilt-Zoom command.<!-- EPO <DP n="8"> --></p><p id="p0035" num="0035">The method according to the present invention the navigation command comprises a Pan-Tilt- Zoom command. The navigation command may include Pan-Tilt-Zoom (PTZ) commands originating from a client device.</p><p id="p0036" num="0036">The navigation command in view of the at least part of said ultra high resolution video content, being transmitted from said server towards said client device entails that the navigation command, i.e. the PTZ command, is related to the current transmitted and presented video content and that the navigation and or /selection action corresponding to the PTZ command is performed on the video content currently being transmitted and played out.</p><p id="p0037" num="0037">A further embodiment relates to a method according to claim 1, wherein said navigation selection command comprises content's reference coordinates.</p><p id="p0038" num="0038">In another embodiment, the method according to the present invention the navigation command comprises a command including content's reference coordinates where each such coordinate points to a single pixel in the ultra high resolution video content. The navigation command may include content's reference coordinates originating from a client device of user where the user intends to indicate a certain element of at least part of the ultra high resolution video content.</p><p id="p0039" num="0039">It is to be noted that the described functional means of the system may be distributed over the first communications device and/or one or more further network elements such as a server device as described in the further appended claims.</p><p id="p0040" num="0040">The effects and advantages of the apparatus and systems according to embodiments of the present invention are substantially the same, <i>mutatis mutandis,</i> as those of the corresponding methods according to embodiments of the present inventions.</p><p id="p0041" num="0041">It is to be noticed that the term 'comprising', used in the claims, should not be interpreted as being restricted to the means listed thereafter. Thus, the scope of the expression 'a device comprising means A and B' should not be limited to devices consisting only of components A and B. It means that with respect to the present invention, the only relevant components of the device are A and B.</p><p id="p0042" num="0042">Similarly, it is to be noticed that the term 'coupled', also used in the claims, should not be interpreted as being restricted to direct connections only. Thus, the scope of the expression 'a device A coupled to a device B' should not be limited to devices or<!-- EPO <DP n="9"> --> systems wherein an output of device A is directly connected to an input of device B. This means that there exists a path between an output of A and an input of B which may be a path including other devices or means.</p><heading id="h0004">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p0043" num="0043">The above and other objects and features of the invention will become more apparent and the invention itself will be best understood by referring to the following description of an embodiment taken in conjunction with the accompanying drawings wherein:
<ul><li><figref idrefs="f0001">Fig. 1</figref> represents the functional structure of a system for navigating in ultra high video content, wherein said system comprises a client device CD and a Server S according to an embodiment of the present invention; and</li><li><figref idrefs="f0002">Fig. 2</figref> represents a functional representation of device SD according to an embodiment of the present invention; and</li><li><figref idrefs="f0003">Fig. 3</figref> represents the functional structure of a system for navigating in ultra high video content, wherein the selection device is included in a client device CD.</li></ul></p><p id="p0044" num="0044">The description and drawings merely illustrate the principles of the invention. It will thus be appreciated that those skilled in the art will be able to devise various arrangements that, although not explicitly described or shown herein, embody the principles of the invention and are included within its spirit and scope. Furthermore, all examples recited herein are principally intended expressly to be only for pedagogical purposes to aid the reader in understanding the principles of the invention and the concepts contributed by the inventor(s) to furthering the art, and are to be construed as being without limitation to such specifically recited examples and conditions. Moreover, all statements herein reciting principles, aspects, and embodiments of the invention, as well as specific examples thereof, are intended to encompass equivalents thereof.</p><p id="p0045" num="0045">It should be appreciated by those skilled in the art that any block diagrams herein represent conceptual views of illustrative circuitry embodying the principles of the invention. Similarly, it will be appreciated that any flow charts, flow diagrams, state transition diagrams, pseudo code, and the like represent various processes which may be substantially represented in computer readable medium and so executed by a computer or processor, whether or not such computer or processor is explicitly shown.<!-- EPO <DP n="10"> --></p><heading id="h0005">DESCRIPTION OF EMBODIMENTS</heading><p id="p0046" num="0046">In the following paragraphs, referring to the drawing in <figref idrefs="f0001">FIG.1</figref>, an implementation of the system for navigating in ultra high resolution video content under control of a user navigation command originating from a client device CD, where at least portions of the ultra high resolution video content being transmitted from a server S towards the client device CD, is described. Subsequently all relevant functional means of the mentioned client device CD and server S of this system as presented in <figref idrefs="f0001">FIG.1</figref> are described followed by a description of all interconnections.</p><p id="p0047" num="0047">In subsequent paragraphs, referring to the drawing in <figref idrefs="f0002">FIG.2</figref>, an implementation of a device SD being configured to support the navigating in ultra high resolution video content under control of a client device according to an embodiment of the present invention is described. Subsequently all relevant functional means of device SD of the system as presented in <figref idrefs="f0001">FIG. 1</figref> are described followed by a description of all interconnections.</p><p id="p0048" num="0048">In the succeeding paragraph the actual execution of the system is described.</p><p id="p0049" num="0049">A first essential element of the system is a server S that is configured to transmit ultra high resolution video content from a video repository included in - or coupled to the server S towards a client device CD.</p><p id="p0050" num="0050">The transmitting of the ultra high resolution video content by the server S may be streaming or more generally transmitting by means of any suitable video transport protocol of this video content towards at least one client device CD of a plurality of client devices.</p><p id="p0051" num="0051">The server S may be an element of a content cluster or service node in a multimedia content delivery network (see <u>http://en.wikipedia.org/wiki/Content delivery network).</u></p><p id="p0052" num="0052">The server may be a server in content delivery network or alternatively be a virtualization of the server functionality in a cloud environment, or a process distributed over several devices, or a GPU farm etc.</p><p id="p0053" num="0053">The client device CD in turn is configured to receive the ultra high resolution video content transmitted by the server S.</p><p id="p0054" num="0054">The client device CD may be an IP connected computer terminal being equipped with a screen and a set of speakers for rendering a multimedia asset streamed<!-- EPO <DP n="11"> --> by the server S towards the client device CD, or an IPTV connected television set coupled via a set-top box to the internet, where this device again is equipped with a screen with a set of speakers for rendering a multimedia asset streamed, or alternatively may be a connected television, a tablet PC, other PC such as a fixed PC or laptop PC, smart phone, a TV connected to a Kinect sensor and/or to a gamepad or joystick, or a gaming console etc.</p><p id="p0055" num="0055">The server S and client device CD may be coupled over any suitable communications network CN optionally containing a concatenation of an access network such as a digital subscriber line access network with coupled DSL modems or a cable network, a mobile communication access network with connected Smartphone or tablet devices or other suitable communications network and core internet network etc.</p><p id="p0056" num="0056">In this embodiment the video content repository VR is coupled to the server S over any kind of high speed reliable connection (due to the high resolution content, such connection would preferably be optical fibre technology or Ethernet cable). The content of the VR could also be cached on high speed access SSD drives on the server.</p><p id="p0057" num="0057">It is to be noted that although such system usually comprises a plurality of such client devices for reasons of simplicity only client device CD is disclosed.</p><p id="p0058" num="0058">A first essential means of the server S is the selection device SD that is configured to support navigating through the ultra high resolution video content, based on the navigation command of the client device CD in view of at least part of said ultra high resolution video content being transmitted, optionally from said server S, towards said client device CD. The server S further comprises a selection means SPSM that is configured to select said spatial portion from said ultra high resolution video content, based on the navigation command in view of at least part of said ultra high resolution video content being transmitted (from said server S) towards said client device CD in combination with content data pertaining to said ultra high resolution video content. Furthermore, the encoding means EM that is configured to encode the selected spatial portion of the ultra high resolution video content in a format that is suitable for the client device CD for playing out of the selected spatial portion.</p><p id="p0059" num="0059">The server S may include a video content repository VR that is adapted to maintain a plurality of ultra high resolution video content assets for transmittal to a client<!-- EPO <DP n="12"> --> device CD. The video content repository VR alternatively may be accommodated in another network element and be coupled to the server S.</p><p id="p0060" num="0060">The selection device SD, that optionally may be included in the server S, comprises a video content reception means VCRM that is configured to obtain said ultra high resolution video content</p><p id="p0061" num="0061">Further, the selection device SD may comprise a Reception means RM that is configured to receive the user navigation command where the user navigation command indicates a navigation trajectory through the ultra high resolution video content and a Video saliency determination means SDM that is configured to determine a local video saliency on the navigation selection trajectory by analyzing the ultra high resolution video content on the navigation trajectory through the ultra high resolution video content and a Characteristics adaption means CAM that is configured to adapt characteristics of the navigation selection trajectory in function of said local video saliency on said navigation selection trajectory. It is to be noted that the selection device SD, alternatively may be a separate network element or may be included in another network element such as a core network element or could even be located at the client device, or happen to be located close the client device, such as at a set-top-box, meaning that the local saliency determination could be performed at the client device rather than performing this determination at the server S. The adaptation of the command could then also happen at the device, the Server would then simply send the spatial portion selection as requested. The selection device SD located at the client device CD would simply send user commands (adapted based on saliency) to the server and the server would send back the selected portion encoded as a video which situation is illustrated in <figref idrefs="f0003">FIG 3</figref>.</p><p id="p0062" num="0062">The reception means RM of the selection device SD is coupled with an output to an input of the saliency determination means SDM and further has an input-terminal that is at the same time an input-terminal 10 of the selection device SD. The saliency determination means SDM of the device SD further is coupled with an output to an input of the characteristics adaption means CAM and has an input-terminal that is coupled to an output-terminal of the video content reception means VCRM. The video content reception means VCRM further comprises an input-terminal that is at the same time an input-terminal I1 of the selection device SD and an additional output that is the<!-- EPO <DP n="13"> --> same time an output-terminal O0 of the selection device SD. The characteristics adaption means CAM further has an output-terminal that is the same time an output-terminal O0 of the selection device SD.</p><p id="p0063" num="0063">The client device CD comprises a spatial portion selection means SSM_that is configured to make a selection of a spatial portion of said ultra high resolution video content for transmitting towards the client device.</p><p id="p0064" num="0064">The selection is performed by generating user navigation commands, e.g. Pan-Tilt-Zoom (PTZ) commands at the client device, which generating is performed under control of the user of such client device that is enabled to make selection of the ultra high resolution video content currently being transmitted towards the client device CD and be presented at the display of such client device CD.</p><p id="p0065" num="0065">The user navigation commands, i.e. the Pan-Tilt-Zoom (PTZ) commands and client status, i.e. the spatial portion of said ultra high resolution video content currently transmitted towards said client device CD for current rendering are obtained by the portion selection means SSM and link relative commands sent by the client in content's reference coordinates, the content's reference coordinates being the location within a currently displayed frame of the ultra high resolution video content. The reference coordinate system of the ultra high resolution video content typically associates one pair of 2D (x,y) integer coordinates to each pixel of the ultra high resolution video content, we therefore have a bijection between pixels of the content and pairs of integer coordinates in the reference coordinate system.</p><p id="p0066" num="0066">The computation of the content's reference coordinates from user interactions in the reference coordinate system does not need to be pixel-accurate; relative motion with a given speed will be translated into a new content's reference coordinate position in the content's reference coordinate system by the client portion selection means SSM with an error tolerance that can be parameterized, typically in case the estimated coordinates would lead to sub-pixel positions (that is non-integer coordinates in the reference coordinate system), a casting to the nearest pixel position (and hence integer coordinates) will be implemented.</p><p id="p0067" num="0067">The client device CD further comprises decoding means DM that is configured to decode the received selected spatial portion from said ultra high resolution video content, based on said selection information in view of at least part of said ultra<!-- EPO <DP n="14"> --> high resolution video content being transmitted, optionally from said server S, towards said client device CD in combination with content data pertaining to said ultra high resolution video content.</p><p id="p0068" num="0068">The client device CD further at least comprises a display and/or speakers for presenting the received selected spatial portion from said ultra high resolution video content and additionally available sound.</p><p id="p0069" num="0069">The client device CD additionally comprises means for selecting a spatial portion of the currently transmitted ultra high resolution video content. Such selection means may be a touch-screen, a mouse coupled to the client device, a gesture sensor or any other sensor for detecting Pan-Tilt-Zoom (PTZ) instructions of the user of the client device CD.</p><p id="p0070" num="0070">In order to explain the present invention first it is assumed that a user currently is watching a certain soccer game at a tablet or at the screen of an IPTV system. The corresponding ultra high resolution video content is being transmitted, by means of streaming, from the server S towards the client device CD. The user at a certain moment of time wishes to track the ball by applying PTZ commands. The user generates these PTZ commands by means of touching the (touch-) screen of the tablet PC or by making gestures which are detected by dedicated gesture sensors like a camera on the tablet with the necessary gesture detection and recognition processing, or by means of the accelerometer sensor that could be present on the tablet, or audio/speech commands.</p><p id="p0071" num="0071">In the prior art situation this selecting of spatial portions of the video for tracking an object such as the ball with the player touching the ball is although very much appreciated, not easy to perform. The user perceives the interactions for selecting the meant portion of the high resolution video content to be tedious and cumbersome after some times, due to the interaction delay or the sensitivity of the interactions in respect to the speed and trajectory of the desired (fast) moving object or person.</p><p id="p0072" num="0072">In the situation, of the present invention however the user again at a certain moment of time wishes to track the ball by applying PTZ commands. It is assumed that the user generates these PTZ commands by means of touching the (touch-) screen of the tablet PC or by making gestures which are detected by dedicated gesture sensors like structured light sensors such as Kinect, or accelerometer sensors available on the user<!-- EPO <DP n="15"> --> device or as wearable devices etc or by means of video-based gesture recognition algorithms. Such PTZ command for selecting the spatial portion of the ultra high resolution video content including the ball and the player at the ball, or in other words PTZ commands for tracking the ball with the player in ball possession are transmitted by the spatial portion selection means SSM of the Client device CD towards the reception means RM of the selection device SD, optionally included in server S that receives the user navigation commands from said client device CD to determine a navigation trajectory through said ultra high resolution video content.</p><p id="p0073" num="0073">Hence, the user navigation command, such as a PTZ command, in view of a current location or starting point, i.e. the spatial portion of said ultra high resolution video content currently transmitted towards said client device CD, of the navigation command indicates a navigation selection trajectory, such as a path through e.g., a frame of, the ultra high resolution video content in direction of the navigation goal of a user of such client device envisions.</p><p id="p0074" num="0074">Subsequently or at the same time, the video saliency determination means SDM determines a local video saliency on the navigation selection trajectory by continuously analyzing the ultra high resolution video content on the navigation trajectory through the ultra high resolution video content.</p><p id="p0075" num="0075">In order to improve the navigation along the meant navigation selection trajectory, the ultra high resolution video content is analyzed for determining the local video saliency on this navigation selection trajectory where the local video saliency is a measure for the amount of detail present at the navigation selection trajectory in such video.</p><p id="p0076" num="0076">A low local video saliency, signifies a low amount of detail in the video, such as the blue sky, uniformly painted walls, road, etc. A moderate local video saliency in turn signifies a moderate amount of detail such as a statistically uniform texture but rough (high frequency content, e.g. vegetation, grass, tree's leaves, some texture patterns for carpets, curtains, roofs etc) and a high local video saliency finally signifies a high degree of video saliency such as either spatially salient or salient due to its motion; e.g. people, faces, soccer ball etc.</p><p id="p0077" num="0077">It is assumed that the user with his PTZ command is trying to track the ball, first browses through a spatial portion including blue air, towards the ball, which blue<!-- EPO <DP n="16"> --> air does contain only few details and is evenly distributed. Hence, the saliency determination means SDM first analyzes the ultra high resolution video content on the navigation selection trajectory, i.e. the blue sky and based on the outcomes of the analyzing determines a low local video saliency on meant location of the navigation selection trajectory. Based on the determined low video saliency, of the blue sky on the navigation trajectory, the characteristics adaption means CAM adapts characteristics of the navigation selection trajectory in function of said local video saliency on said navigation selection trajectory. Hence based on the determined low video saliency, the characteristic of the navigation selection trajectory being the speed in this case is increased as the current portion of the navigation selection trajectory only contains little information, i.e. the blue air. The navigation trajectory hence may be traversed at an accelerated velocity due to the fact there is little information on the current traversed portion of the navigation selection trajectory.</p><p id="p0078" num="0078">Subsequently, it is assumed that the path of the ball touches down the ground at the soccer field and proceeds rolling over the grass. Now, the saliency determination means SDM further analyzes the ultra high resolution video content on the navigation selection trajectory at the current position, i.e. the spatial portion of said ultra high resolution video content, located on the selection navigation trajectory, being currently transmitted towards said client device CD and rendered at the current client device CD, and based on the outcomes of the analyzing determines an average local video saliency on the meant location of the navigation selection trajectory. Based on the determined average video saliency the characteristics adaption means CAM adapts the characteristics of the navigation selection trajectory in function of said local video saliency on said navigation selection trajectory. Hence based on the determined low video saliency, the characteristic of the navigation selection trajectory being the speed in this case is decreased back to a normal or average speed as the current portion of the navigation selection trajectory only contains an average amount of information at the current location on the trajectory, i.e. the grass with a structure comprising a moderate amount of detail, that is a statistically uniform texture but rough (being a high frequency content). The navigation trajectory hence may be traversed at a speed that is decelerated till an average velocity due to the fact there is an average amount of information on the current traversed portion of the navigation selection trajectory.<!-- EPO <DP n="17"> --></p><p id="p0079" num="0079">Alternatively, it is assumed that the user subsequently using PTZ command trying to track the ball, further browses through a spatial portion including the ball being surrounded by a plurality of soccer players, even of different teams, which scene and navigation trajectory through this meant scene comprises a high amount of information making it difficult to distinguish the right object in the scene being the ball with a player taking the control of the ball.</p><p id="p0080" num="0080">Hence, the saliency determination means SDM further analyzes the ultra high resolution video content at the current location on the navigation selection trajectory , i.e. the spatial portion of said ultra high resolution video content, on the selection navigation trajectory, currently transmitted towards said client device CD and currently be rendered at the client device CD, and based on the outcome of the analyzing further determines a high local video saliency on meant location of the navigation selection trajectory. Based on the determined high video saliency the characteristics adaption means CAM adapts characteristics of the navigation selection trajectory in function of said local video saliency on said navigation selection trajectory. Hence based on the determined high video saliency, the characteristic of the navigation selection trajectory being the speed in this case again is decelerated as the current portion of the navigation selection trajectory contains high amount information, i.e. a plurality of soccer players of different teams surrounding the ball. The navigation trajectory hence may be traversed at a decelerated velocity due to the fact there is a high amount of information on the current traversed portion of the navigation selection trajectory.</p><p id="p0081" num="0081">Hence, in this way, in function of the determined local video saliency the characteristics of the navigation selection trajectory may be adapted to better match the navigation goals of a user of the client device. In case there is much information present in the spatial portion of the ultra high resolution video content that is currently transmitted by the server S to the client device CD it is difficult for the user to decide whether the current spatial portion indeed contains the information the user is looking for. Hence the navigation speed over the navigation selection criterion is decelerated to enable the user to better decide whether or not the spatial portion indeed contains the information he/she is looking for.<!-- EPO <DP n="18"> --></p><p id="p0082" num="0082">The other way around, In case there is few information present in the spatial portion of the ultra high resolution video content that is currently transmitted by the server S to the client device CD it is not difficult for the user to decide whether the current spatial portion indeed contains the information the user is looking for as the image is more or less similar. Hence the navigation speed over the navigation selection criterion can be accelerated as the user immediately is aware the spatial portion does not contain the information the user is looking for.</p><p id="p0083" num="0083">Subsequently, the selection means SPSM, selects a spatial portion from said ultra high resolution video content, based on the current position on the navigation selection trajectory as handed over by the selection device SD where the spatial portion may be identified by the content's reference coordinates.</p><p id="p0084" num="0084">Hence, at first the selection means SPSM does interpret the i.e. the PTZ command received, i.e. the ball tracking command in view of the at least part of the ultra high resolution video content being transmitted from the server S towards the client device CD, which is the full - or a spatial portion of the ultra high resolution video content being transmitted from said server S towards the client device CD and presented at the screen of the client device CD. While taking into account the current view at the screen of the client device CD, the selection means SPSM applies the received PTZ command and applies the PTZ selection or tracking command at the full - or a spatial portion of the ultra high resolution video content being received and presented at the screen of the client device. A spatial portion indicated by means of the PTZ selection command is initially selected by the selecting means SPSM. As the selected portion, i.e. the ball with the player being in possession of the ball is very fast moving, possibly the selection is not yet optimum performed, i.e. the selection does include a part of the moving ball however the meant player is not visible within the selected spatial portion.</p><p id="p0085" num="0085">In case the user of the client device with the PTZ-selection command selects a spatial portion of the video content that includes - or is near to a portion of the ultra high resolution video content that is associated with a region of interest, e.g. the region of interest including the ball together with the player being in possession of the ball, the selection means SPSM directs the selection of the spatial portion in such manner that the spatial portion includes the meant region of interest including the ball together with the player being in possession of the ball.<!-- EPO <DP n="19"> --></p><p id="p0086" num="0086">The selection means SPSM, in turn generates a spatial portion of the ultra high resolution video content that is retrieved from a coupled video repository VR by means of the video content reception means VCRM, in correspondence with the meant region of interest including the ball together with the player being in possession of the ball.</p><p id="p0087" num="0087">Subsequently, the selection means SPSM outputs the spatial portion of the ultra high resolution video content, comprising the meant region of interest, where the meant region of interest includes the ball together with the player being in possession of the ball and is being forwarded to the Encoding means EM for encoding the spatial portion of the ultra high resolution video content into a format suitable for display at the client device CD.</p><p id="p0088" num="0088">In case of a tablet PC the encoded video format may be a broadcasting format such as H.264/AVC, H.265/HEVC, their scalable extensions, or VP8 or VP9 formats, or in case the client device CD is an IP connected television set may be a broadcasting format such as H.264/AVC, H.265/HEVC, or their scalable extensions, or VP8 or VP9 formats or any other suitable format.</p><p id="p0089" num="0089">It is to be noted that in an embodiment of the present invention the ultra high resolution video content may comprise 3-Dimensional video.</p><p id="p0090" num="0090">Finally the encoded spatial portion of the ultra high resolution video content including the ball together with the player being in possession of the ball is transmitted towards the client device decoding means DM that further hands over the portion of the ultra high resolution video content to means, of the client device, for display the portion of the ultra high resolution video content.</p><p id="p0091" num="0091">In an embodiment of the present invention, the navigation selection trajectory can be traversed at an adapted velocity that optimum suits the level of detail in the video at the analyzed location at the navigation selection trajectory through the video content.</p><p id="p0092" num="0092">The navigation trajectory may be traversed at a standard velocity but advantageously additionally in an accelerated velocity or at a decelerated velocity in the respective situation of a low local video saliency, i.e. in case relatively little change in video information such as a blue sky, uniformly painted walls, road, etc. on the navigation selection trajectory, or in case of relatively high local video saliency , i.e. very<!-- EPO <DP n="20"> --> much change in video information such as such as objects either spatially salient or salient due to its motion like e.g. people, faces, soccer ball etc on the navigation selection trajectory.</p><p id="p0093" num="0093">Further, it is to be noted that although the embodiment describes a client-server architecture wherein the present invention is implemented and executed, this also could have been implemented and executed in a peer-to-peer architecture, cloud architecture, hardware architecture, and each other form in between.</p><p id="p0094" num="0094">It is to be noted that the selection device SD, alternatively may be included in a separate network element or may be included in another network element such as a core network element see Fig. 4, or could even be located at the client device, or happen to be located close the client device, see <figref idrefs="f0003">Fig. 3</figref>, or such as at a set-top-box. This means that in the last case, the local saliency determination may be performed at the client device rather than performing this determination at the server S. The adaptation of the command could then also happen on the device, the Server would then simply send the selection as requested.</p><p id="p0095" num="0095">It is to be noted that the characteristics adaption provided by the CAM, which modifies the navigation selection trajectory in function of said local video saliency on said navigation selection trajectory, actually modifies the values of the content's reference coordinates to be selected by the SPSM. This modification of reference coordinates can be compared to the reference coordinates of the previous selected portion of the video content on the navigation selection trajectory.</p><p id="p0096" num="0096">In the example of a navigation trajectory corresponding to a translation in reference coordinates (pan and/or tilt interaction), the reference coordinates of the selected portion at time (t) are obtained by adding an offset to the reference coordinates of the selected portion at time (t-1). The adaption of the characteristics based on the local saliency will therefore have as a consequence an increase or decrease of the offset to be added on reference coordinates depending on the local saliency.<!-- EPO <DP n="21"> --></p><p id="p0097" num="0097">In another example of a navigation trajectory corresponding to a uniform scaling in reference coordinates (zoom in or zoom out interaction), the reference coordinates of the selected portion at time (t) are obtained by adding four offsets to the reference coordinates of the corners of the selected portion at time (t-1), resulting in a selection with an unchanged shape but with an offset to be added to the area with respect to the content's reference coordinate system. The adaption of the characteristics based on the local saliency will therefore have as a consequence an increase or decrease of the offsets to be added on the reference coordinates of the corners of the selection depending on the local saliency and subsequently an increase or decrease of the offset to be added to the area of the selection respectively.</p><p id="p0098" num="0098">It is further to be noted that earlier navigation selection commands, i.e. interaction commands at the device, may be evaluated for determining whether such user is performing chaotic interactions (like very rapid opposite interactions like a trembling finger at the touch screen), in which case the speed could be adapted by reducing the amplitude of the interactions by making use of the Kalman filter to reduce the effect of the series of chaotic navigation selection commands.</p><p id="p0099" num="0099">A final remark is that embodiments of the present invention are described above in terms of functional blocks. From the functional description of these blocks, given above, it will be apparent for a person skilled in the art of designing electronic devices how embodiments of these blocks can be manufactured with well-known electronic components. A detailed architecture of the contents of the functional blocks hence is not given.</p><p id="p0100" num="0100">While the principles of the invention have been described above in connection with specific apparatus, it is to be clearly understood that this description is merely made by way of example and not as a limitation on the scope of the invention, as defined in the appended claims.</p></description><claims mxw-id="PCLM90459159" lang="EN" load-source="patent-office"><!-- EPO <DP n="22"> --><claim id="c-en-0001" num="0001"><claim-text>A method for navigating in ultra high resolution video content under control of a user navigation command originating from a client device (CD), at least portions of said ultra high resolution video content being transmitted from a server (S) towards said client device (CD), said method comprising the steps of:
<claim-text>- receiving a user navigation command, said user navigation command indicating a navigation trajectory through said ultra high resolution video content; and</claim-text>
<claim-text>- determining a local video <u>saliency</u> on said navigation selection trajectory by analyzing said ultra high resolution video content on said navigation trajectory through said ultra high resolution video content; and</claim-text>
<claim-text>- adapting characteristics of said navigation selection trajectory in function of said local video saliency on said navigation selection trajectory.</claim-text></claim-text></claim><claim id="c-en-0002" num="0002"><claim-text>A method for navigating in ultra high resolution video content according to claim 1, wherein in case of a low local video saliency on said navigation trajectory through said ultra high resolution video content, a navigation speed is increased, in case of a high local video saliency on said navigation trajectory through said ultra high resolution video content a navigation speed is decreased.</claim-text></claim><claim id="c-en-0003" num="0003"><claim-text>A method for navigating in ultra high resolution video content according to claim 1, wherein said characteristics of said navigation selection trajectory comprise navigation speed and direction.</claim-text></claim><claim id="c-en-0004" num="0004"><claim-text>A method for navigating in ultra high resolution video content according to claim 1, wherein said analyzing said ultra high resolution video content on said navigation trajectory through said ultra high resolution video content comprises counting edge transitions on said navigation trajectory.</claim-text></claim><claim id="c-en-0005" num="0005"><claim-text>A method for navigating in ultra high resolution video content according to claim 1, wherein said analyzing said ultra high resolution video content on said<!-- EPO <DP n="23"> --> navigation trajectory through said ultra high resolution video content comprises determining transitions or the variance of luminance content on said navigation trajectory.</claim-text></claim><claim id="c-en-0006" num="0006"><claim-text>A method according to claim 1, wherein said navigation selection command contains a Pan-Tilt- Zoom command.</claim-text></claim><claim id="c-en-0007" num="0007"><claim-text>A method according to claim 1, wherein said navigation selection command contains content's reference coordinates.</claim-text></claim><claim id="c-en-0008" num="0008"><claim-text>System for navigating in ultra high resolution video content under control of a user navigation command originating from a client device (CD), at least portions of said ultra high resolution video content being transmitted from a server (S) towards said client device (CD), wherein said system comprises:
<claim-text>- a reception means, configured to receive said user navigation command, said user navigation command indicating a navigation trajectory through said ultra high resolution video content ; and</claim-text>
<claim-text>- a video saliency determination means, configured to determine a local video <u>saliency</u> on said navigation selection trajectory by analyzing said ultra high resolution video content on said navigation trajectory through said ultra high resolution video content; and</claim-text>
<claim-text>- a characteristics adaption means, configured to adapt characteristics of said navigation selection trajectory in function of said local video saliency on said navigation selection trajectory.</claim-text></claim-text></claim><claim id="c-en-0009" num="0009"><claim-text>Selection Device (SD) for use in a system according to claim 7, wherein said selection device (SD) is configured to support navigating in ultra high resolution video content under control of said user navigation command originating from said client device (CD), said selection device (SD) comprises:
<claim-text>- Reception means (RM), configured to receive said user navigation command, said user navigation command indicating a navigation trajectory through said ultra high resolution video content; and<!-- EPO <DP n="24"> --></claim-text>
<claim-text>- Video saliency determination means (SDM), configured to determine a local video <u>saliency</u> on said navigation selection trajectory by analyzing said ultra high resolution video content on said navigation trajectory through said ultra high resolution video content; and</claim-text>
<claim-text>- Characteristics adaption means (CAM), configured to adapt characteristics of said navigation selection trajectory in function of said local video saliency on said navigation selection trajectory.</claim-text></claim-text></claim><claim id="c-en-0010" num="0010"><claim-text>Server for transmitting at least portions of ultra high resolution video content towards a client device (CD), for use in a system according to claim 7, wherein said server (S) comprises a selection device (SD) according to claim 8.</claim-text></claim><claim id="c-en-0011" num="0011"><claim-text>Network element for use in a system according to claim 7, wherein said network element is coupled to said server (S) and or said client device (CD) wherein said network element comprises a selection device (SD) according to claim 8.</claim-text></claim><claim id="c-en-0012" num="0012"><claim-text>Computer program product comprising software adapted to perform the method steps according to any of claim 1 to 7 when executed on a data processing apparatus.</claim-text></claim></claims><drawings mxw-id="PDW20421896" load-source="patent-office"><!-- EPO <DP n="25"> --><figure id="f0001" num="1"><img id="if0001" file="imgf0001.tif" wi="128" he="209" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="26"> --><figure id="f0002" num="2"><img id="if0002" file="imgf0002.tif" wi="153" he="188" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="27"> --><figure id="f0003" num="3"><img id="if0003" file="imgf0003.tif" wi="141" he="206" img-content="drawing" img-format="tif"/></figure></drawings><search-report-data><doc-page id="srep0001" file="srep0001.tif" wi="160" he="233" type="tif"/><doc-page id="srep0002" file="srep0002.tif" wi="160" he="233" type="tif"/></search-report-data><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
