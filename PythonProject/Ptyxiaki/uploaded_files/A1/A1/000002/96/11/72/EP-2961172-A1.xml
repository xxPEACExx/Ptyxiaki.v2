<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2961172-A1" country="EP" doc-number="2961172" kind="A1" date="20151230" family-id="51710396" file-reference-id="302658" date-produced="20180824" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="160451170" ucid="EP-2961172-A1"><document-id><country>EP</country><doc-number>2961172</doc-number><kind>A1</kind><date>20151230</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-15173338-A" is-representative="YES"><document-id mxw-id="PAPP193865308" load-source="docdb" format="epo"><country>EP</country><doc-number>15173338</doc-number><kind>A</kind><date>20150623</date><lang>EN</lang></document-id><document-id mxw-id="PAPP193865309" load-source="patent-office" format="original"><country>EP</country><doc-number>15173338.3</doc-number><date>20150623</date><lang>EN</lang></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC162030122" ucid="CN-201410300209-A" load-source="docdb"><document-id format="epo"><country>CN</country><doc-number>201410300209</doc-number><kind>A</kind><date>20140626</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL-1988519767" load-source="docdb">H04N  21/41        20110101AFI20151109BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-1988521621" load-source="docdb">H04N  21/478       20110101ALI20151109BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-1988523080" load-source="docdb">H04N  21/4725      20110101ALI20151109BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-1988526288" load-source="docdb">H04N  21/4722      20110101ALI20151109BHEP        </classification-ipcr><classification-ipcr mxw-id="PCL-1988526708" load-source="docdb">H04N  21/431       20110101ALI20151109BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-1987764147" load-source="docdb" scheme="CPC">H04N  21/4722      20130101 FI20151029BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987769519" load-source="docdb" scheme="CPC">H04N  21/4126      20130101 LI20151029BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987776791" load-source="docdb" scheme="CPC">H04N  21/4725      20130101 LI20151029BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987781035" load-source="docdb" scheme="CPC">H04N  21/4316      20130101 LI20151029BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987788148" load-source="docdb" scheme="CPC">H04N  21/4122      20130101 LI20151029BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987797690" load-source="docdb" scheme="CPC">H04N  21/47815     20130101 LI20151029BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT165544976" lang="DE" load-source="patent-office">VERFAHREN UND VORRICHTUNG ZUR INFORMATIONSERFASSUNG</invention-title><invention-title mxw-id="PT165544977" lang="EN" load-source="patent-office">METHOD AND DEVICE FOR INFORMATION ACQUISITION</invention-title><invention-title mxw-id="PT165544978" lang="FR" load-source="patent-office">PROCÉDÉ ET DISPOSITIF POUR L'ACQUISITION D'INFORMATIONS</invention-title><citations><patent-citations><patcit mxw-id="PCIT335738857" load-source="docdb" ucid="CN-103888785-A"><document-id format="epo"><country>CN</country><doc-number>103888785</doc-number><kind>A</kind><date>20140625</date></document-id><sources><source name="SEA" category="X" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335741404" load-source="docdb" ucid="EP-2725541-A1"><document-id format="epo"><country>EP</country><doc-number>2725541</doc-number><kind>A1</kind><date>20140430</date></document-id><sources><source name="SEA" category="X" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT378323692" load-source="docdb" ucid="EP-2919135-A1"><document-id format="epo"><country>EP</country><doc-number>2919135</doc-number><kind>A1</kind><date>20150916</date></document-id><sources><source name="SEA" category="E" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335745690" load-source="docdb" ucid="US-20030174160-A1"><document-id format="epo"><country>US</country><doc-number>20030174160</doc-number><kind>A1</kind><date>20030918</date></document-id><sources><source name="SEA" category="X" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335738339" load-source="docdb" ucid="US-20040003406-A1"><document-id format="epo"><country>US</country><doc-number>20040003406</doc-number><kind>A1</kind><date>20040101</date></document-id><sources><source name="SEA" category="X" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335740456" load-source="docdb" ucid="US-20070157251-A1"><document-id format="epo"><country>US</country><doc-number>20070157251</doc-number><kind>A1</kind><date>20070705</date></document-id><sources><source name="SEA" category="X" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335741105" load-source="docdb" ucid="US-20090327894-A1"><document-id format="epo"><country>US</country><doc-number>20090327894</doc-number><kind>A1</kind><date>20091231</date></document-id><sources><source name="SEA" category="X" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335745176" load-source="docdb" ucid="US-20100319019-A1"><document-id format="epo"><country>US</country><doc-number>20100319019</doc-number><kind>A1</kind><date>20101216</date></document-id><sources><source name="SEA" category="X" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT335741854" load-source="docdb" ucid="US-20110052144-A1"><document-id format="epo"><country>US</country><doc-number>20110052144</doc-number><kind>A1</kind><date>20110303</date></document-id><sources><source name="SEA" category="X" created-by-npl="N"/></sources></patcit><patcit mxw-id="PCIT378323693" load-source="docdb" ucid="US-20140115622-A1"><document-id format="epo"><country>US</country><doc-number>20140115622</doc-number><kind>A1</kind><date>20140424</date></document-id><sources><source name="SEA" category="XI" created-by-npl="N"/></sources></patcit></patent-citations><non-patent-citations><nplcit><text>None</text><sources><source mxw-id="PNPL62251157" load-source="docdb" name="APP"/></sources></nplcit></non-patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR1103312199" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>XIAOMI INC</last-name><address><country>CN</country></address></addressbook></applicant><applicant mxw-id="PPAR1103321330" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>XIAOMI INC.</last-name></addressbook></applicant><applicant mxw-id="PPAR1101641932" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Xiaomi Inc.</last-name><iid>101432267</iid><address><street>Floor 13, Rainbow City Shopping Mall II of China Resources No. 68 Qinghe Middle Street Haidian District</street><city>Beijing 100085</city><country>CN</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR1103333683" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>LIU HUADONG</last-name><address><country>CN</country></address></addressbook></inventor><inventor mxw-id="PPAR1103334878" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>LIU, HUADONG</last-name></addressbook></inventor><inventor mxw-id="PPAR1101647868" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>LIU, HUADONG</last-name><address><street>Xiaomi Inc. Floor 13 Rainbow City Shopping Mall II of China Resources No. 68, Qinghe Middle Street Haidian District</street><city>100085 Beijing</city><country>CN</country></address></addressbook></inventor><inventor mxw-id="PPAR1103310827" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>SUN WU</last-name><address><country>CN</country></address></addressbook></inventor><inventor mxw-id="PPAR1103323219" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>SUN, Wu</last-name></addressbook></inventor><inventor mxw-id="PPAR1101643930" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>SUN, Wu</last-name><address><street>Xiaomi Inc. Floor 13 Rainbow City Shopping Mall II of China Resources No. 68, Qinghe Middle Street Haidian District</street><city>100085 Beijing</city><country>CN</country></address></addressbook></inventor><inventor mxw-id="PPAR1103332557" load-source="docdb" sequence="3" format="epo"><addressbook><last-name>WANG AIJUN</last-name><address><country>CN</country></address></addressbook></inventor><inventor mxw-id="PPAR1103318046" load-source="docdb" sequence="3" format="intermediate"><addressbook><last-name>WANG, AIJUN</last-name></addressbook></inventor><inventor mxw-id="PPAR1101645973" load-source="patent-office" sequence="3" format="original"><addressbook><last-name>WANG, AIJUN</last-name><address><street>Xiaomi Inc. Floor 13 Rainbow City Shopping Mall II of China Resources No. 68, Qinghe Middle Street Haidian District</street><city>100085 Beijing</city><country>CN</country></address></addressbook></inventor><inventor mxw-id="PPAR1103338963" load-source="docdb" sequence="4" format="epo"><addressbook><last-name>GAO RONGXIN</last-name><address><country>CN</country></address></addressbook></inventor><inventor mxw-id="PPAR1103310084" load-source="docdb" sequence="4" format="intermediate"><addressbook><last-name>GAO, Rongxin</last-name></addressbook></inventor><inventor mxw-id="PPAR1101650148" load-source="patent-office" sequence="4" format="original"><addressbook><last-name>GAO, Rongxin</last-name><address><street>Xiaomi Inc. Floor 13 Rainbow City Shopping Mall II of China Resources No. 68, Qinghe Middle Street Haidian District</street><city>100085 Beijing</city><country>CN</country></address></addressbook></inventor><inventor mxw-id="PPAR1103334596" load-source="docdb" sequence="5" format="epo"><addressbook><last-name>JI HONG</last-name><address><country>CN</country></address></addressbook></inventor><inventor mxw-id="PPAR1103305836" load-source="docdb" sequence="5" format="intermediate"><addressbook><last-name>JI, HONG</last-name></addressbook></inventor><inventor mxw-id="PPAR1101642574" load-source="patent-office" sequence="5" format="original"><addressbook><last-name>JI, HONG</last-name><address><street>Xiaomi Inc. Floor 13 Rainbow City Shopping Mall II of China Resources No. 68, Qinghe Middle Street Haidian District</street><city>100085 Beijing</city><country>CN</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR1101652351" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Sackin, Robert</last-name><iid>101268659</iid><address><street>Reddie &amp; Grose LLP 16 Theobalds Road</street><city>London WC1X 8PL</city><country>GB</country></address></addressbook></agent></agents></parties><international-convention-data><designated-states><ep-contracting-states><country mxw-id="DS660680980" load-source="docdb">AL</country><country mxw-id="DS660605111" load-source="docdb">AT</country><country mxw-id="DS660604914" load-source="docdb">BE</country><country mxw-id="DS660683168" load-source="docdb">BG</country><country mxw-id="DS660680911" load-source="docdb">CH</country><country mxw-id="DS660604919" load-source="docdb">CY</country><country mxw-id="DS660605112" load-source="docdb">CZ</country><country mxw-id="DS660680982" load-source="docdb">DE</country><country mxw-id="DS660604920" load-source="docdb">DK</country><country mxw-id="DS660604921" load-source="docdb">EE</country><country mxw-id="DS660680816" load-source="docdb">ES</country><country mxw-id="DS660683169" load-source="docdb">FI</country><country mxw-id="DS660680912" load-source="docdb">FR</country><country mxw-id="DS660680991" load-source="docdb">GB</country><country mxw-id="DS660604922" load-source="docdb">GR</country><country mxw-id="DS660680992" load-source="docdb">HR</country><country mxw-id="DS660605113" load-source="docdb">HU</country><country mxw-id="DS660680913" load-source="docdb">IE</country><country mxw-id="DS660604931" load-source="docdb">IS</country><country mxw-id="DS660683170" load-source="docdb">IT</country><country mxw-id="DS660604932" load-source="docdb">LI</country><country mxw-id="DS660683175" load-source="docdb">LT</country><country mxw-id="DS660603635" load-source="docdb">LU</country><country mxw-id="DS660683176" load-source="docdb">LV</country><country mxw-id="DS660683177" load-source="docdb">MC</country><country mxw-id="DS660603636" load-source="docdb">MK</country><country mxw-id="DS660603637" load-source="docdb">MT</country><country mxw-id="DS660680817" load-source="docdb">NL</country><country mxw-id="DS660781986" load-source="docdb">NO</country><country mxw-id="DS660680818" load-source="docdb">PL</country><country mxw-id="DS660603638" load-source="docdb">PT</country><country mxw-id="DS660680914" load-source="docdb">RO</country><country mxw-id="DS660603639" load-source="docdb">RS</country><country mxw-id="DS660680823" load-source="docdb">SE</country><country mxw-id="DS660605114" load-source="docdb">SI</country><country mxw-id="DS660781987" load-source="docdb">SK</country><country mxw-id="DS660781988" load-source="docdb">SM</country><country mxw-id="DS660683178" load-source="docdb">TR</country></ep-contracting-states><ep-extended-states><ep-extended-state-data><country>BA</country></ep-extended-state-data><ep-extended-state-data><country>ME</country></ep-extended-state-data></ep-extended-states></designated-states></international-convention-data></bibliographic-data><abstract mxw-id="PA166479540" lang="EN" load-source="patent-office"><p id="pa01" num="0001">The present disclosure generally relates to an information acquisition method and a device (110), pertaining to the field of Internet technology. The information acquisition method includes: acquiring associated information of at least one video element (21) in a video, each video element (21) being an image element, a sound element or a play clip in the video; and displaying the associated information at a specified moment; solving the problem of less efficient information acquisition, making it possible to display associated information of a video element in a terminal (110) at a specified moment, and improving the information acquisition efficiency.
<img id="iaf01" file="imgaf001.tif" wi="112" he="83" img-content="drawing" img-format="tif"/></p></abstract><abstract mxw-id="PA166759352" lang="EN" source="EPO" load-source="docdb"><p>The present disclosure generally relates to an information acquisition method and a device (110), pertaining to the field of Internet technology. The information acquisition method includes: acquiring associated information of at least one video element (21) in a video, each video element (21) being an image element, a sound element or a play clip in the video; and displaying the associated information at a specified moment; solving the problem of less efficient information acquisition, making it possible to display associated information of a video element in a terminal (110) at a specified moment, and improving the information acquisition efficiency.</p></abstract><description mxw-id="PDES98404241" lang="EN" load-source="patent-office"><!-- EPO <DP n="1"> --><heading id="h0001"><b>TECHNICAL FIELD</b></heading><p id="p0001" num="0001">The present disclosure generally relates to the field of Internet technology, and more particularly, to an information acquisition method and a device thereof</p><heading id="h0002"><b>BACKGROUND</b></heading><p id="p0002" num="0002">Video, such as teleplay (or TV drama), movie and the like, is an indispensable part for people's daily life. A video may comprise a lot of video elements, for example, a video may comprise different movie and television stars, scenic spots, articles, classic lines and interludes, etc.</p><p id="p0003" num="0003">When users are interested in a certain video element in a video, generally they need to manually acquire associated information of the video element. For example, when a user needs to view a blooper (or goof or an embarrassing error) in a video A, they need to locate and play the blooper by fast-forward, fast-backward buttons or adjusting a play progress bar in the process of playing the video A; for another example, when users need to know information relating to a racing car in video B, they need to manually input a key word relating to the racing car in a browser to conduct a search, and to find out the information relating to the racing car in a search result.</p><p id="p0004" num="0004">In the process of realizing the present disclosure, at least the following defects are found out in the above-mentioned manners: when users are interested in a certain video element in a video, generally they need to manually acquire information relating to the video element. In the whole acquisition process, users need to perform multiple operations, and thus the information acquisition efficiency is low.</p><heading id="h0003"><b>SUMMARY</b></heading><p id="p0005" num="0005">In order to solve the problem of lower efficiency of information acquisition in related technologies, the embodiments of the present disclosure provide an information acquisition method and a device thereof, and the technical solution is as below:</p><p id="p0006" num="0006">According to the first aspect of the embodiments of the present disclosure, an information acquisition method is provided, for example, at a terminal or at a client, comprising:
<ul><li>acquiring associated information of at least one video element in a video, each video element being an image element, a sound element or a play clip in the video; and</li><li>displaying the associated information at a specified moment.</li></ul><!-- EPO <DP n="2"> --></p><p id="p0007" num="0007">Preferably, the acquiring associated information of at least one video element in a video comprises:
<ul><li>downloading the associated information of at least one video element in a video from a server and saving the associated information at a scheduled moment; and</li><li>the scheduled moment comprising: a moment prior to playing the video, a moment during playing the video or an idle moment.</li></ul></p><p id="p0008" num="0008">Preferably, the specified moment comprises:
<ul><li>a moment playing a tail leader of the video; or</li><li>a moment receiving a pause signal during playing the video.</li></ul></p><p id="p0009" num="0009">Preferably, the acquiring associated information of at least one video element in a video comprises:
<ul><li>searching, from associated information of at least one video element in the video downloaded in advance, for associated information of a video element relating to the playback position in case of receiving users' information acquisition instruction when playing a certain playback position in the video.</li></ul></p><p id="p0010" num="0010">Preferably, the acquiring associated information of at least one video element in a video comprises:
<ul><li>sending an information acquisition request to a server in case of receiving users' information acquisition instruction when playing a certain playback position in the video, the information acquisition request being configured to acquire associated information of a video element relating to the playback position; and</li><li>receiving such associated information of a video element as relating to the playback position and fed back by the server.</li></ul></p><p id="p0011" num="0011">Preferably, the sending an information acquisition request to a server comprises:
<ul><li>acquiring a play message corresponding to the playback position, the play message comprising at least one of the following messages: image frame data relating to the playback position, audio frame data relating to the playback position, and play time point corresponding to play timeline of the playback position; and</li><li>sending the information acquisition request to the server, the information acquisition request carrying a video identification of the video and a play message corresponding to the playback position.</li></ul></p><p id="p0012" num="0012">Preferably, the specified moment comprises:
<ul><li>a moment after receiving associated information of a video element relating to the playback position.</li></ul></p><p id="p0013" num="0013">Preferably, the displaying the associated information at a specified moment comprises:<!-- EPO <DP n="3"> -->
<ul><li>displaying directly the associated information by means of a prescriptive model if the terminal is a player device and a remote control unit corresponding to the player device has no information display ability;</li><li>if the terminal is a player device and a remote control unit corresponding to the player device has information display ability, displaying directly the associated information by means of a prescriptive model or sending the associated information to the remote control unit, the remote control unit being configured to display the associated information by means of a prescriptive model;</li><li>if the terminal is a medium source device connected to a player device and a remote control unit corresponding to the medium source device has no information display ability, sending the associated information to the player device; the player device being configured to display the associated information by means of a prescriptive model; and</li><li>if the terminal is a medium source device connected to a player device and a remote control unit corresponding to the medium source device has information display ability, sending the associated information to the player device or the remote control unit , the player device or the remote control unit being configured to display the associated information by means of a prescriptive model;</li><li>wherein, the prescriptive model comprising: at least one of a split screen mode, a list mode, a tagging mode, a scrolling mode, a screen popup mode or a window popup mode.</li></ul></p><p id="p0014" num="0014">Preferably, the method also comprises:
<ul><li>when associated information of a video element displayed is triggered; jumping to a playback position corresponding to the video element in the video for playing or jumping to information content corresponding to an information link comprised in the associated information for displaying.</li></ul></p><p id="p0015" num="0015">According to the second aspect of the embodiments of the present disclosure, an information acquisition method is provided for or at a server, comprising:
<ul><li>generating associated information of at least one video element in a video, each video element being an image element, a sound element or a play clip in the video; and</li><li>providing a terminal with associated information of at least one video element in the video, the terminal being configured to display the associated information at a specified moment.</li></ul></p><p id="p0016" num="0016">Preferably, the providing a terminal with associated information of at least one video element in the video comprises:
<ul><li>providing the terminal with a downloads to associated information of at least one video element in the video at a scheduled moment;</li><li>the scheduled moment including: a moment prior to playing the video by the terminal,<!-- EPO <DP n="4"> --> a moment during playing the video by the terminal or an idle moment of the terminal.</li></ul></p><p id="p0017" num="0017">Preferably, the providing a terminal with associated information of at least one video element in the video comprises:
<ul><li>feeding, after receiving an information acquisition request sent by the terminal, back associated information of a video element relating to a playback position in the video to the terminal; wherein,</li><li>the information acquisition request being a request sent by the terminal after receiving users' information acquisition instruction during playing the video, and the playback position being a corresponding playback position when users' information acquisition instruction is received by the terminal during playing a video.</li></ul></p><p id="p0018" num="0018">Preferably, the generating associated information of at least one video element in a video comprises:
<ul><li>identifying at least one video element in the video; and</li><li>acquiring associated information of each video element.</li></ul></p><p id="p0019" num="0019">Preferably, the identifying at least one video element in the video comprises:
<ul><li>decoding the video and acquiring at least one frame of video data comprising image frame data or both image frame data and audio frame data;</li><li>identifying, concerning image frame data, image elements in the image frame data by means of image recognition technology; and</li><li>identifying, concerning audio frame data, sound elements in the audio frame data by means of speech recognition technology.</li></ul></p><p id="p0020" num="0020">Preferably, the identifying at least one video element in the video comprises:
<ul><li>acquiring, after receiving an information acquisition request sent by the terminal, a play message corresponding to a playback position carried in the information acquisition request, the play message comprising at least one of the following messages: image frame data relating to the playback position, audio frame data relating to the playback position, and play time point corresponding to play timeline of the playback position; and</li><li>acquiring, according to the play message, video elements corresponding to the playback position in the video;</li><li>wherein, the information acquisition request being a request sent by the terminal after receiving users' information acquisition instruction during playing the video, and the playback position being a corresponding playback position when users' information acquisition instruction is received by the terminal during playing a video.</li></ul></p><p id="p0021" num="0021">Preferably, the identifying at least one video element in the video comprises:
<ul><li>receiving at least one video element reported by other terminals with respect to the<!-- EPO <DP n="5"> --> video, the video element being one labeled by users of the other terminals.</li></ul></p><p id="p0022" num="0022">Preferably, the acquiring associated information of each video element comprises:
<ul><li>acquiring, concerning each video element, at least one information relating to the video element by means of information search technology;</li><li>sorting at least one information according to a preset condition, and extracting top n associated information as associated information of the video element, wherein n being a positive integer; and</li><li>the preset condition comprising: at least one of correlation with the video element, correlation with user location, correlation with users' history usage record, and ranking of manufacturers or suppliers of video elements.</li></ul></p><p id="p0023" num="0023">Preferably, the acquiring associated information of each video element comprises:
<ul><li>receiving associated information reported by other terminals with respect to the video element, the other terminals being terminals used by other users, or, the other terminals being terminals used by manufacturers or suppliers of the video element.</li></ul></p><p id="p0024" num="0024">According to the third aspect of the embodiments of the present disclosure, an information acquisition device is provided for a terminal or a client device for information acquisition, comprising:
<ul><li>an information acquisition module, configured to acquire associated information of at least one video element in a video, each video element being an image element, a sound element or a play clip in the video; and</li><li>an information display module, configured to display the associated information at a specified moment.</li></ul></p><p id="p0025" num="0025">Preferably, the information acquisition module is configured to download the associated information of at least one video element in a video from a server and to save the associated information at a scheduled moment; and
<ul><li>the scheduled moment includes: a moment prior to playing the video, a moment during playing the video or an idle moment.</li></ul></p><p id="p0026" num="0026">Preferably, the specified moment comprises:
<ul><li>a moment playing a tail leader of the video; or</li><li>a moment receiving a pause signal during playing the video.</li></ul></p><p id="p0027" num="0027">Preferably, the information acquisition module is configured to search, from associated information of at least one video element in the video downloaded in advance, for associated information of a video element relating to the playback position in case of receiving users' information acquisition instruction when playing a certain playback position in the video.</p><p id="p0028" num="0028">Preferably, the information acquisition module comprises:<!-- EPO <DP n="6"> -->
<ul><li>a request sending unit, configured to, when playing a certain playback position in the video, send an information acquisition request to a server in case of receiving users' information acquisition instruction, the information acquisition request being configured to acquire associated information of a video element relating to the playback position; and</li><li>an information receiving unit, configured to receive such associated information of a video element as relating to the playback position and fed back by the server.</li></ul></p><p id="p0029" num="0029">Preferably, the request sending unit comprises:
<ul><li>an information acquisition subunit, configured to acquire a play message corresponding to the playback position, the play message comprising at least one of the following messages: image frame data relating to the playback position, audio frame data relating to the playback position, and play time point corresponding to play timeline of the playback position; and</li><li>a request sending subunit, configured to send the information acquisition request to the server, the information acquisition request carrying a video identification of the video and a play message corresponding to the playback position.</li></ul></p><p id="p0030" num="0030">Preferably, the specified moment comprises:
<ul><li>a moment after receiving associated information of a video element relating to the playback position.</li></ul></p><p id="p0031" num="0031">Preferably, the information display module is configured to:
<ul><li>if the terminal is a player device and a remote control unit corresponding to the player device has no information display ability, display directly the associated information by means of a prescriptive model;</li><li>if the terminal is a player device and a remote control unit corresponding to the player device has information display ability, display directly the associated information by means of a prescriptive model or send the associated information to the remote control unit configured to display the associated information by means of a prescriptive model;</li><li>if the terminal is a medium source device connected to a player device and a remote control unit corresponding to the medium source device has no information display ability, send the associated information to the player device is configured to display the associated information by means of a prescriptive model; and</li><li>if the terminal is a medium source device connected to a player device and a remote control unit corresponding to the medium source device has information display ability, send the associated information to the player device or the remote control unit, the player device or the remote control unit is configured to display the associated information by means of a prescriptive model;<!-- EPO <DP n="7"> --></li><li>wherein, the prescriptive model comprises: at least one of a split screen mode, a list mode, a tagging mode, a scrolling mode, a screen popup mode or a window popup mode.</li></ul></p><p id="p0032" num="0032">Preferably, the device also comprises:
<ul><li>an information jump module, configured to, when associated information of a video element displayed is triggered, jump to a playback position corresponding to the video element in the video for playing or jump to information content corresponding to an information link comprised in the associated information for displaying.</li></ul></p><p id="p0033" num="0033">According to the fourth aspect of the embodiments of the present disclosure, an information acquisition device is provided for a server or a server device, comprising:
<ul><li>an information generation module, configured to generate associated information of at least one video element in a video, each video element is an image element, a sound element or a play clip in the video; and</li><li>an information providing module, configured to provide a terminal with associated information of at least one video element in the video, the terminal is configured to display the associated information at a specified moment.</li></ul></p><p id="p0034" num="0034">Preferably, the information providing module is configured to provide the terminal with a downloads to associated information of at least one video element in the video; and
<ul><li>the scheduled moment includes: a moment prior to playing the video by the terminal, a moment during playing the video by the terminal or an idle moment of the terminal.</li></ul></p><p id="p0035" num="0035">Preferably, the information providing module is configured to feed, after receiving an information acquisition request sent by the terminal, back associated information of a video element relating to a playback position in the video to the terminal; wherein,
<ul><li>the information acquisition request is a request sent by the terminal after receiving users' information acquisition instruction during playing the video, and the playback position is a corresponding playback position when users' information acquisition instruction is received by the terminal during playing a video.</li></ul></p><p id="p0036" num="0036">Preferably, the information providing module comprises:
<ul><li>an element identification unit, configured to identify at least one video element in the video; and</li><li>an information acquisition unit, configured to acquire associated information of each video element.</li></ul></p><p id="p0037" num="0037">Preferably, the element identification unit comprises:
<ul><li>a video data acquisition subunit, configured to decode the video and acquire at least one frame of video data comprising image frame data or both image frame data and audio frame data;<!-- EPO <DP n="8"> --></li><li>a first identification subunit, configured to, concerning image frame data, identify image elements in the image frame data by means of image recognition technology; and</li><li>a second identification subunit, configured to, concerning audio frame data, identify sound elements in the audio frame data by means of speech recognition technology.</li></ul></p><p id="p0038" num="0038">Preferably, the element identification unit comprises:
<ul><li>a play message acquisition subunit, configured to, after receiving an information acquisition request sent by the terminal, acquire a play message corresponding to a playback position carried in the information acquisition request; and</li><li>an element acquisition subunit, configured to, according to the play message, acquire a video element corresponding to the playback position in the video;</li><li>wherein, the information acquisition request is a request sent by the terminal after receiving users' information acquisition instruction during playing the video, and the playback position is a corresponding playback position when users' information acquisition instruction is received by the terminal during playing a video.</li></ul></p><p id="p0039" num="0039">Preferably, the element identification unit is configured to receive at least one video element reported by other terminals with respect to the video, and the video element is one labeled by users of the other terminals.</p><p id="p0040" num="0040">Preferably, the information acquisition unit comprises:
<ul><li>an information acquisition subunit, configured to, concerning each video element, acquire at least one information relating to the video element by means of information search technology; and</li><li>an information sorting subunit, configured to sort at least one information according to a preset condition, and to extract top n associated information as associated information of the video element, wherein n being a positive integer;</li><li>the preset condition comprising: at least one of correlation with the video element, correlation with user location, correlation with users' history usage record, and ranking of manufacturers or suppliers of video elements.</li></ul></p><p id="p0041" num="0041">Preferably, the information acquisition unit is configured to receive associated information reported by other terminals with respect to the video element, the other terminals are terminals used by other users, or, the other terminals are terminals used by manufacturers or suppliers of the video element.</p><p id="p0042" num="0042">According to the fifth aspect of the embodiments of the present disclosure, an information acquisition device is provided for a terminal, comprising:
<ul><li>a processor; and</li><li>a memory configured to store executable instructions from the processor;<!-- EPO <DP n="9"> --></li><li>wherein, the processor is configured to:
<ul><li>acquire associated information of at least one video element in a video, each video element is an image element, a sound element or a play clip in the video; and</li><li>display the associated information at a specified moment.</li></ul></li></ul></p><p id="p0043" num="0043">According to the sixth aspect of the embodiments of the present disclosure, an information acquisition device is provided for a server, comprising:
<ul><li>acquiring associated information of at least one video element in a video, each video element being an image element, a sound element or a play clip in the video; and</li><li>displaying the associated information at a specified moment.</li></ul></p><p id="p0044" num="0044">The technical solution according to the embodiments of the present disclosure may have the following beneficial effects:</p><p id="p0045" num="0045">By means of acquiring associated information of a video element in a video and displaying associated information acquired at a specified moment, it is solved the problem of less efficient information acquisition, making it possible to display associated information of a video element by a terminal at a specified moment, and improving the information acquisition efficiency.</p><p id="p0046" num="0046">A computer program product may be provided which when executed on a processor of a client performs the method as described above or when executed on a processor of a server performs the method described above as applicable.</p><p id="p0047" num="0047">It is to be understood that both the foregoing general description and the following detailed description are exemplary and explanatory only and are not restrictive of the disclosure.</p><heading id="h0004"><b>BRIEF DESCRIPTION OF THE DRAWINGS</b></heading><p id="p0048" num="0048">The accompanying drawings, which are incorporated in and constitute a part of this specification, illustrate embodiments consistent with the disclosure and, together with the description, serve to explain the principles of the disclosure.
<ul><li><figref idrefs="f0001">Fig. 1A</figref> is a structure diagram showing an implementation environment according to an exemplary embodiment.</li><li><figref idrefs="f0002">Fig. 1B</figref> is a structure diagram showing another implementation environment according to an exemplary embodiment.</li><li><figref idrefs="f0003">Fig. 2</figref> is a schematic diagram showing a video element and associated information according to an exemplary embodiment.</li><li><figref idrefs="f0004">Fig. 3</figref> is a flow chart showing an information acquisition method according to an<!-- EPO <DP n="10"> --> exemplary embodiment.</li><li><figref idrefs="f0004">Fig. 4</figref> is a flow chart showing an information acquisition method according to another exemplary embodiment.</li><li><figref idrefs="f0005">Fig. 5</figref> is a flow chart showing an information acquisition method according to a further exemplary embodiment.</li><li><figref idrefs="f0005">Fig. 6</figref> is a flow chart showing providing associated information by a server according to a further exemplary embodiment.</li><li><figref idrefs="f0005">Fig. 7</figref> is another flow chart showing providing associated information by a server according to a further exemplary embodiment.</li><li><figref idrefs="f0006">Fig. 8</figref> is a flow chart showing an information acquisition method according to a further exemplary embodiment.</li><li><figref idrefs="f0007">Fig. 9A</figref> is a schematic diagram showing displaying associated information by a terminal according to a further exemplary embodiment.</li><li><figref idrefs="f0007">Fig. 9B</figref> is another schematic diagram showing displaying associated information by a terminal according to a further exemplary embodiment.</li><li><figref idrefs="f0008">Fig. 9C</figref> is a further schematic diagram showing displaying associated information by a terminal according to a further exemplary embodiment.</li><li><figref idrefs="f0008">Fig. 9D</figref> is a further schematic diagram showing displaying associated information by a terminal according to a further exemplary embodiment.</li><li><figref idrefs="f0009">Fig. 9E</figref> is a further schematic diagram showing displaying associated information by a terminal according to a further exemplary embodiment.</li><li><figref idrefs="f0009">Fig. 9F</figref> is a further schematic diagram showing displaying associated information by a terminal according to a further exemplary embodiment.</li><li><figref idrefs="f0010">Fig. 9G</figref> is a further schematic diagram showing displaying associated information by a terminal according to a further exemplary embodiment.</li><li><figref idrefs="f0010">Fig. 10</figref> is a block diagram of an information acquisition device according to an exemplary embodiment.</li><li><figref idrefs="f0011">Fig. 11</figref> is a block diagram of an information acquisition device according to another exemplary embodiment.</li><li><figref idrefs="f0011">Fig. 12</figref> is a block diagram of an information acquisition device according to an exemplary embodiment.</li><li><figref idrefs="f0012">Fig. 13A</figref> is a block diagram of an information acquisition device according to another exemplary embodiment.</li><li><figref idrefs="f0012">Fig. 13B</figref> is a block diagram of an element identification unit according to an exemplary embodiment.<!-- EPO <DP n="11"> --></li><li><figref idrefs="f0013">Fig. 13C</figref> is a block diagram of another element identification unit according to an exemplary embodiment.</li><li><figref idrefs="f0013">Fig. 13D</figref> is a block diagram of an information acquisition unit according to an exemplary embodiment.</li><li><figref idrefs="f0014">Fig. 14</figref> is a block diagram of an information acquisition device according to an exemplary embodiment.</li><li><figref idrefs="f0015">Fig. 15</figref> is a block diagram of an information acquisition device according to an exemplary embodiment.</li></ul></p><p id="p0049" num="0049">Specific embodiments of the present disclosure are shown by the above drawings, and more detailed description will be made hereinafter. These drawings and text description are not for limiting the scope of conceiving the present disclosure in any way, but for illustrating the concept of the present disclosure for those skilled in the art by referring to specific embodiments.</p><heading id="h0005"><b>DESCRIPTION OF THE EMBODIMENTS</b></heading><p id="p0050" num="0050">Reference will now be made in detail to exemplary embodiments, examples of which are illustrated in the accompanying drawings. The following description refers to the accompanying drawings in which the same numbers in different drawings represent the same or similar elements unless otherwise represented. The implementations set forth in the following description of exemplary embodiments do not represent all implementations consistent with the disclosure. Instead, they are merely examples of apparatuses and methods consistent with aspects related to the disclosure as recited in the appended claims.</p><p id="p0051" num="0051"><figref idrefs="f0001">Fig. 1A</figref> and <figref idrefs="f0002">Fig. 1B</figref> show structure diagrams of implementation environment involved in the information acquisition methods according to embodiments of the present disclosure, and the implementation environment may include a terminal 110 and a server 120 connected to the terminal by wired or wireless network.</p><p id="p0052" num="0052">As shown in <figref idrefs="f0001">Fig. 1A</figref>, the terminal 110 may be a player device having play ability such as a television, a tablet computer, a desktop computer or a mobile phone and the like. The player device may, under the control of remote control equipment, directly acquire video resources from the server 120 and play the video resources acquired. Wherein, the remote control equipment may be connected to a television by infrared, Bluetooth or WLAN, and the remote control equipment may be either a remote control unit 130 as shown in <figref idrefs="f0001">Fig. 1A</figref> 's (a), or a smart terminal 140 as shown in <figref idrefs="f0001">Fig. 1A</figref>'s (b).</p><p id="p0053" num="0053">As shown in <figref idrefs="f0002">Fig. 1B</figref>, the terminal 110 may be a medium source device connected to<!-- EPO <DP n="12"> --> the player device. The medium source device may be a high-definition box, a Blu-ray player, a household NAS (Network Attached Storage) device and the like. Wherein, the player device may be a device having play ability such as a television, a tablet computer, a desktop computer or a mobile phone and the like. The player device can acquire, with the help of the medium source device connected with the player device, video resources from the server 120. The medium source device may acquire video resources from the server 120 and play the video resources acquired in the player device. Meanwhile, users may control the medium source device by means of the remote control equipment which is connected to a television by means of infrared, Bluetooth or WLAN, and the remote control equipment may be either a remote control unit 150 as shown in <figref idrefs="f0002">Fig. 1B</figref>'s (a), or a smart terminal 160 as shown in <figref idrefs="f0002">Fig. 1B</figref>'s (b).</p><p id="p0054" num="0054">In addition, the server 120 is connected with the terminal 110 by a wired network or a wireless network, and the server 120 may be a server, or a server cluster comprising a plurality of servers, or a cloud computing service center.</p><p id="p0055" num="0055">It should be explained that, in <figref idrefs="f0001">Fig. 1A</figref> and <figref idrefs="f0002">Fig. 1B</figref>, an implementation environment comprising foregoing devices are taken as an example; in some application scenarios for actual implementation, the implementation environment may also comprise a part of foregoing devices or other devices, to which the embodiment makes no restriction.</p><p id="p0056" num="0056">In addition, for the convenience of understanding, basic concepts involved in the embodiments are introduced herein.</p><p id="p0057" num="0057">A video element refers to an image element, a sound element or a play clip in a video. Wherein, the image element is an element in an image frame data, such as a figure (or person) or an object; the sound element is a sound, being an audio frame data or a plurality of consecutive audio frame data; the play clip is an image frame data corresponding to a play time point or a plurality of consecutive image frame data corresponding to a play time quantum (or a period of play time).</p><p id="p0058" num="0058">Associated information of a video element refers to information associated with the video element. For example:
<ul><li>when a video element is a star, associated information may be an individual resume of the star, a starred work list, the latest microblog news and news report and the like about the star.</li></ul></p><p id="p0059" num="0059">When a video element is a piece of clothing, associated information may be a buylink (or purchase link, buying link) of the clothing in an E-business website, a shop address for selling the clothing, a face fabric introduction of the clothing, and a matching recommendation of the clothing, etc.<!-- EPO <DP n="13"> --></p><p id="p0060" num="0060">When a video element is food, associated information may be a buying link of the food in an E-business website, a shop address for selling the food in the local place of users, and a cooking method of the food, etc.</p><p id="p0061" num="0061">When a video element is a background music, associated information may be a MV (Music Video) corresponding to the background music, lyrics of the background music, a singer of the background music, and a creation background of the background music, etc.</p><p id="p0062" num="0062">When a video element is a scenic spot, associated information may be a brief introduction of the scenic spot, a business link for providing tourism service of the scenic spot, cate (or good food) provided in the scenic spot, and other scenic spots belonging to the same types as the scenic spot, etc.</p><p id="p0063" num="0063">When a video element is a play clip, associated information may be image frame data, audio frame data, or image elements in the combination of both image frame data and audio frame data, or combination of the image elements and sound elements in the play clip.</p><p id="p0064" num="0064"><figref idrefs="f0003">Fig. 2</figref> shows video elements 21 in a video and associated information 22 of the video elements 21. It can be known from <figref idrefs="f0003">Fig. 2</figref> that, video elements may be image elements in image frame data, or sound elements in audio frame data, or all elements (dash area as shown in <figref idrefs="f0003">Fig. 2</figref>) in image frame data, or m frames of image frame data or m frames of audio frame data, to which the embodiment makes no restriction. Wherein, m is an integer greater than or equal to 2.</p><p id="p0065" num="0065"><figref idrefs="f0004">Fig. 3</figref> is a flow chart showing an information acquisition method according to an exemplary embodiment which is illustrated by applying the information acquisition method to a terminal 110 as shown in <figref idrefs="f0001">Fig. 1A</figref> or <figref idrefs="f0002">Fig. 1B</figref>, and the information acquisition method may comprise following steps.</p><p id="p0066" num="0066">In Step 301, associated information of at least one video element in a video is acquired, each video element is an image element, a sound element or a play clip in the video; and<br/>
in Step 302, the associated information is displayed at a specified moment.</p><p id="p0067" num="0067">In conclusion, the information acquisition method according to the embodiment comprises acquiring associated information of a video element in a video and displaying the associated information acquired at a specified moment, solving the problem of less efficient information acquisition, making it possible to display associated information of a video element in a terminal at a specified moment, and improving the information acquisition efficiency.</p><p id="p0068" num="0068">The mode for a terminal to acquire associated information of at least one video<!-- EPO <DP n="14"> --> element may comprise at least one of the following modes: downloading associated information of a video element from a server at a scheduled moment; in case of receiving users' information acquisition instruction, searching from such associated information of at least one video element as being downloaded in advance, for associated information of a video element relating to a video playback position when the information acquisition instruction is received; sending an information acquisition request to a server, and further receiving such associated information, which is fed back by the server, of a video element relating to a video playback position when information acquisition instruction is received. Reference will be made in detail to the foregoing three modes in different embodiments hereinafter.</p><p id="p0069" num="0069"><figref idrefs="f0004">Fig. 4</figref> is a flow chart showing an information acquisition method according to an exemplary embodiment which is illustrated by applying the information acquisition method to a terminal 110 as shown in <figref idrefs="f0001">Fig. 1A</figref> or <figref idrefs="f0002">Fig. 1B</figref> and the terminal 110 is able to download associated information of a video element from a server at a scheduled moment. The information acquisition method may comprise following steps.</p><p id="p0070" num="0070">In Step 401, associated information of at least one video element in a video is downloaded by the terminal from a server and saved at a scheduled moment.</p><p id="p0071" num="0071">The terminal may request to download, from a server, associated information of at least one video element and save the associated information at a scheduled moment. In actual implementation, the terminal may send at a scheduled moment, an information acquisition request for acquiring associated information of at least one video element in the video, to a server. Wherein, the scheduled moment includes: a moment prior to playing a video, a moment during playing a video or an idle moment.</p><p id="p0072" num="0072">In Step 402, a terminal may display associated information at a moment when playing a tail leader of a video or receiving a pause signal during playing a video.</p><p id="p0073" num="0073">After acquiring associated information of at least one video element, a terminal may display the associated information at a moment when playing a tail leader of a video or receiving a pause signal during playing a video.</p><p id="p0074" num="0074">In case that a terminal displays associated information at a moment of playing tail leader of a video, after the terminal finishes playing the video, the terminal may display associated information of at least one video element in the video. In this way, users may acquire associated information of all video elements in the video, thus simplifying user operation.</p><p id="p0075" num="0075">In the process of playing a video, in case of receiving a pause signal and displaying associated information, a terminal may pause the video after receiving the pause signal, and display associated information of at least one video element in the video.<!-- EPO <DP n="15"> --></p><p id="p0076" num="0076">In actual implementation, a terminal may also display associated information at a certain play time point, to which the embodiment makes no restriction.</p><p id="p0077" num="0077">In conclusion, the information acquisition method according to the embodiment comprises acquiring associated information of a video element in a video and displaying the associated information acquired at a specified moment, solving the problem of less efficient information acquisition, making it possible to display associated information of a video element in a terminal at a specified moment, and improving the information acquisition efficiency.</p><p id="p0078" num="0078">By downloading associated information of at least one video element from a server at a scheduled moment, the embodiment reduces complexity in interaction between a terminal and a server when associated information is displayed in the terminal, and improves the efficiency of the terminal in displaying the associated information.</p><p id="p0079" num="0079"><figref idrefs="f0005">Fig. 5</figref> is a flow chart showing an information acquisition method according to an exemplary embodiment which is illustrated by applying the information acquisition method to a terminal 110 as shown in <figref idrefs="f0001">Fig. 1A</figref> or <figref idrefs="f0002">Fig. 1B</figref> and the terminal 110 is able to, in case of receiving users' information acquisition instruction, search from associated information of at least one video element downloaded in advance, for associated information of a video element relating to a video playback position when the information acquisition instruction is received. The information acquisition method may comprise following steps.</p><p id="p0080" num="0080">In Step 501, a terminal receives users' information acquisition instruction, and searches, from associated information of at least one video element in a video downloaded in advance, for associated information of a video element relating to a playback position.</p><p id="p0081" num="0081">In the process of playing a video in a terminal, users may send an information acquisition instruction to the terminal by means of preset keys of the terminal or a remote control unit if they want to acquire associated information of a video element at the current playback position, correspondingly, users' information acquisition instruction is received by the terminal. Wherein, users may send out an information acquisition instruction by pressing preset keys of the remote control unit. Of course, users may also send out an information acquisition instruction by simultaneously pressing two keys such as '0' and 'Enter' keys, to which the embodiment makes no restriction.</p><p id="p0082" num="0082">In case of receiving information acquisition instruction, a terminal may search, from associated information of at least one video element in a video downloaded in advance, for associated information of a video element relating to a playback position. In actual implementation, a terminal may search, from associated information, for associated information corresponding to a playback position when an information acquisition instruction is received by<!-- EPO <DP n="16"> --> the terminal.</p><p id="p0083" num="0083">In Step 502, the terminal may display associated information at a moment after receiving associated information of a video element relating to a playback position.</p><p id="p0084" num="0084">The terminal may display associated information after receiving associated information of a video element relating to a playback position. In actual implementation, users want to acquire associated information when they send out an information acquisition instruction. Therefore, a terminal may immediately display the associated information acquired, to which the embodiment makes no restriction.</p><p id="p0085" num="0085">In conclusion, the information acquisition method according to the embodiment comprises acquiring associated information of a video element in a video and displaying the associated information acquired at a specified moment, solving the problem of less efficient information acquisition, making it possible to display associated information of a video element in a terminal at a specified moment, and improving the information acquisition efficiency.</p><p id="p0086" num="0086">In the embodiment, when users' information acquisition instruction is received, associated information of a video element relating to a video playback position at the moment that users' information acquisition instruction is received is searched from associated information of at least one video downloaded in advance, thus ensuring the terminal to quickly acquire associated information requested by users, and further improving the efficiency of the terminal in displaying associated information and enhancing the information acquisition efficiency.</p><p id="p0087" num="0087">It should be explained that in the foregoing two embodiments, before the terminal acquires associated information of a video element, the server needs to generate associated information of at least one video element, and provides the terminal with the generated associated information of at least one video element. As shown in <figref idrefs="f0005">Fig. 6</figref>, the server may execute the following steps:</p><p id="p0088" num="0088">In Step 601, associated information of at least one video element in a video is generated, each video element being an image element, a sound element or a play clip in the video;.</p><p id="p0089" num="0089">The server stores videos for playing in a player device, and generates associated information of at least one video element in videos for executing follow-up steps. Wherein, each video element is an image element, a sound element or a play clip in the video.</p><p id="p0090" num="0090">In Step 602, associated information of at least one video element in a video is provided to a terminal so that the terminal displays the associated information at a specified moment.</p><p id="p0091" num="0091"><figref idrefs="f0005">Fig. 7</figref> is a flow chart showing providing associated information by a server according to another exemplary embodiment. As shown in <figref idrefs="f0005">Fig. 7</figref>, the server may execute the following<!-- EPO <DP n="17"> --> steps.</p><p id="p0092" num="0092">In Step 701, at least one video element in a video is identified.</p><p id="p0093" num="0093">In actual implementation, the Step may comprise following two possible implementations.</p><p id="p0094" num="0094">In a first possible implementation, the Step may comprise:
<ol><li>(1) It is decoded a video and acquiring at least one frame of video data.<br/>
A server decodes a video, and further acquires at least one frame of video data in a video. Wherein, since in a video some playback positions may be configured with sound while other playback positions may be not configured with sound, the server may simultaneously decode and acquire both image frame data and audio frame data at the playback positions configured with sound, and may decode and acquire only image frame data at the playback positions not configured with sound.</li><li>(2) Concerning image frame data, it is identified image elements in the image frame data by means of image recognition technology.<br/>
Concerning image frame data acquired by decoding, a server may identify image elements in the image frame data by means of image recognition technology. In actual implementation, the server may match the image frame data acquired by decoding with images in an image database. If elements matching with images in the image database exist in the image frame data, the server takes the matched image elements as image elements in the image frame data. Wherein, the image database is a preset database comprising images including target objects such as figures, sceneries, articles for daily use, clothing, labels, trademarks, brands and keywords, to which the embodiment makes no restriction.<br/>
For example, if an image database has an image of'figure A' and an image of 2014 winter new clothing of XX brand that 'figure A' endorses, and an image frame data acquired by the server also includes an image of'figure A' and an image of a coat among 2014 winter new clothing of XX brand, the server may take the image of 'figure A' and the image of the coat as image elements in the image frame data.</li><li>(3) Concerning audio frame data, it is identified sound elements in the audio frame data by means of speech recognition (or voice recognition) technology.<br/>
Concerning audio frame data, a terminal may identify sound elements in the audio frame data by means of speech recognition technology. In actual implementation, a server may match audio frame data with a songbook (or a database of words and music), thus acquiring sound elements in audio frame data. Moreover, in order to more accurately identify a sound element, the server may combine an audio frame data with a preset length of audio frame data before the audio frame data, or with a preset length of audio frame data after the audio frame data, or with<!-- EPO <DP n="18"> --> a preset length of audio frame data before the audio frame data and a preset length of audio frame data after the audio frame data, thus acquiring a multi-frame audio frame data and matching it with a songbook, to which the embodiment makes no restriction. Wherein, the songbook includes a preset database comprising audio frequencies, to which the embodiment makes no restriction.</li></ol></p><p id="p0095" num="0095">Concerning at least one frame of video data acquired by a server by decoding, the server may take each frame of video data as a unit, thus identifying image elements or sound elements in each frame of video data; of course, the server may take two or more frames of video data as a unit, for example, take video data between the tenth minute and the eleventh minute in a video as a play clip, further take image elements or sound elements identified and acquired in the video data in the play clip simultaneously as video elements, to which the embodiment makes no restriction.</p><p id="p0096" num="0096">It should be explained that concerning a part of video data acquired by a server by decoding, the server may not identify and acquire image elements or sound elements from video frame data, and may only identify and acquire image elements or sound elements from another part of video data, to which the embodiment makes no restriction.</p><p id="p0097" num="0097">In a second possible implementation, the step may include:</p><p id="p0098" num="0098">As users may label video elements in a video, the step in which a server identifies at least one video element in a video may comprise: directly receiving at least one video element reported by other terminals with respect to the video, and the video element is one labeled by users of other terminals.</p><p id="p0099" num="0099">In Step 702, associated information of each video element is acquired.</p><p id="p0100" num="0100">After acquiring at least one video element, a server may acquire associated information of each video element. Wherein, the mode in which a server acquires associated information of a video element may comprise the two following possible implementations:</p><p id="p0101" num="0101">In a first possible implementation, the Step may comprise:
<ol><li>(1) Concerning each video element, it is acquired at least one information of a video element by means of information search technology.<br/>
Concerning each video element identified and acquired by a server, the server may acquire at least one information of a video element by means of information search technology. For example, when a video element acquired by a server is an image of'figure A', the server may search from a network server for information associated with the image of'figure A'.</li><li>(2) It is sorted at least one information according to a preset condition, and extracted top n associated information as associated information of a video element, wherein n being a positive integer.<br/>
A server may sort at least one information acquired according to a preset condition.<!-- EPO <DP n="19"> --> Wherein, the preset condition comprises: at least one of correlation with a video element, correlation with user location, correlation with users' history (or history of usage record), and ranking of manufacturers or suppliers of video elements.<br/>
Wherein:
<ul><li>Correlation with a video element refers to correlation between information searched and the video element. For example, if a video element is an image of a'figure A', and information searched respectively is 'figure A and figure B', 'the latest report about figure A', 'shape of figure A (or character A's shape)', 'adornments for figure A' and the like, the correlation between the information searched and the video element successively is, according to a sequence from high to low, 'shape of figure A', 'adornments for figure A', 'the latest report about figure A' and 'something about figure A and figure B'.</li></ul></li></ol></p><p id="p0102" num="0102">Correlation with user location refers to a distance between information searched and the user location. Wherein, the user location is a geographic location reported by a user to a sever when a user terminal requests to play a video in the server, for example, the geographic location reported by the user is No.5, Zhongshan Road, Wuxi City.</p><p id="p0103" num="0103">For example, if a video element is an image of 'a certain coat of XX brand', information searched is 'XX Exclusive Shop, No.8, XX Temple, Wuxi City', 'XX Outlet Shop, No. 7, Zhongshan Road, Wuxi City' and 'Shopping Plaza, No 10. Changjiang Road, Wuxi city', the correlation between the information searched and the user location successively is, according to a sequence from high to low, 'XX Outlet Shop, No. 7, Zhongshan Road, Wuxi City', 'XX Exclusive Shop, No.8, XX Temple, Wuxi City' and 'Shopping Plaza, No 10. Changjiang Road, Wuxi city'.</p><p id="p0104" num="0104">Correlation with users' history usage record refers to correlation between information searched and associated information triggered by and used in user history. For example, if users generally are concerned about clothing and food, and information searched by users is information relating to automobiles, scenic spots, food and clothing respectively, a server may determine that the correlation between the information searched and user historical usage records successively is, according to a sequence from high to low, clothing, food, scenic spots and automobiles.</p><p id="p0105" num="0105">Ranking of manufacturers or suppliers of video elements refers to a preset ranking of manufacturers or suppliers in a server, on the basis of which, the server may sort information searched.</p><p id="p0106" num="0106">After a server sorts information acquired, the server may extract top n information from information sorted as associated information of a video element. For example, the server selects top 10 information as associated information of a video element. Of course, in actual<!-- EPO <DP n="20"> --> implementation, the server may also take all information sorted as associated information of a video element, to which the embodiment makes no restriction.</p><p id="p0107" num="0107">In a second possible implementation, the Step may comprise:
<ul><li>As user may report associated information for each video element, the server may receive associated information reported by other terminals with respect to the video element. Wherein, other terminals are terminals used by other users, or, other terminals are terminals used by manufacturers or suppliers of video elements. Associated information reported by other terminals may be information sorted according to a certain sort order, to which the embodiment makes no restriction.</li></ul></p><p id="p0108" num="0108">It should be explained that, manufactures or providers of a video element may monopolize associated information of a video element in a certain play clip in a video, for example, from the tenth minute to the eleventh minute, a hero (or leading actor) in a video is selecting clothing for a news conference to be held in the next day, a manufacturer of 'a certain coat of XX brand' (a video element) may buy out the associated information of the video element from the tenth minute to the eleventh minute in the video. Under the circumstances, although a server may identify and acquire other video elements from video frame data from the tenth minute to the eleventh minute in the video, the server still sets 'a certain coat of XX brand' (information set by the manufacturer) as the associated information of the video element from the tenth minute to the eleventh minute in the video.</p><p id="p0109" num="0109">It should be further explained that, when video elements identified and acquired by a server are video elements corresponding to different locations of a video, after acquiring associated information of each video element, the server may determine a playback position corresponding to the associated information, and take the playback position determined as a piece of attribute information of associated information, to which the embodiment makes no restriction.</p><p id="p0110" num="0110">In Step 703, the server offers, at a moment prior to playing a video by the terminal, a moment during playing a video by the terminal or an idle moment of the terminal, the terminal with downloads to associated information of at least one video element in a video.</p><p id="p0111" num="0111">In actual implementation, the server may take the initiative to send associated information of at least one video element in a video to the terminal, or provide the terminal with downloads to associated information after receiving an information acquisition request sent by the terminal.</p><p id="p0112" num="0112">By taking the server taking the initiative to send associated information as an example, after generating associated information of at least one video element in a video, the server may directly send the associated information to the terminal, i.e., the server may provide the terminal with downloads to associated information at a moment before the terminal playing<!-- EPO <DP n="21"> --> a video; or, the server may send the associated information to the terminal when the terminal is playing a video; or the server may send the associated information to the terminal at an idle moment of the terminal, for example, midnight '12:00', to which the embodiment makes no restriction.</p><p id="p0113" num="0113">In conclusion, the information acquisition method according to the embodiment comprises generating associated information of at least one video element and providing a terminal with associated information of at least one video element so as to display associated information at a specified moment after the associated information is acquired by the terminal, solving the problem of less efficient information acquisition, making it possible to display associated information of a video element in a terminal at a specified moment, and improving the information acquisition efficiency.</p><p id="p0114" num="0114">The foregoing embodiments take an example in which the server generates in advance associated information of at least one video element. And the server generating associated information of a video element in real time according to an information acquisition request of the terminal will be illustrated in the following embodiments.</p><p id="p0115" num="0115"><figref idrefs="f0006">Fig. 8</figref> is a flow chart showing an information acquisition method according to an exemplary embodiment which is illustrated by applying the information acquisition method to a terminal 110 as shown in <figref idrefs="f0001">Fig. 1A</figref> or <figref idrefs="f0002">Fig. 1B</figref> and the terminal 110 is able to, upon receiving users' information acquisition instruction, send an information acquisition request to a server, the server feeds back associated information generated to the terminal, and the terminal receives such associated information of a video element relating to a playback position when the information acquisition instruction is received. The information acquisition method may comprise following steps.</p><p id="p0116" num="0116">In Step 801, a terminal receives users' information acquisition instruction.</p><p id="p0117" num="0117">In the process of playing a video by a terminal, users may send an information acquisition instruction to the terminal by means of preset keys of the terminal or preset keys of a remote control unit if they want to acquire associated information of a video element at the current playback position, correspondingly, users' information acquisition instruction is received by the terminal. Wherein, users may send out an information acquisition instruction by pressing preset keys of a remote control unit, of course, users may also send out an information acquisition instruction by simultaneously pressing two keys such as '0' and 'Enter' keys, to which the embodiment makes no restriction.<!-- EPO <DP n="22"> --></p><p id="p0118" num="0118">In Step 802, a terminal sends an information acquisition request to a server.</p><p id="p0119" num="0119">A terminal sends an information acquisition request to a server once it receives an information acquisition instruction. Wherein, the information acquisition request is configured to acquire associated information of a video element relating to a playback position.</p><p id="p0120" num="0120">In actual implementation, the Step in which a terminal sends an information acquisition request to a server may comprise:</p><p id="p0121" num="0121">Firstly, it is acquired a play message corresponding to a playback position.</p><p id="p0122" num="0122">A terminal may acquire a play message corresponding to a video playback position when an information acquisition instruction is received. Wherein, the play message comprises at least one of the following messages: image frame data relating to a playback position, audio frame data relating to a playback position, and play time point corresponding to play timeline of a playback position. For example, the play message corresponding to a playback position acquired by a terminal is 15:14.</p><p id="p0123" num="0123">Secondly, it is sent an information acquisition request to a server, the information acquisition request carrying a video identification of the video and a play message corresponding to a playback position.</p><p id="p0124" num="0124">After acquiring a play message corresponding to a playback position, the terminal may send the server an information acquisition request carrying a video identification of a video and a play message corresponding to a playback position. Wherein, the video identification may be the name of a video or ID (identification) assigned by the server to the video, to which the embodiment makes no restriction.</p><p id="p0125" num="0125">In Step 803, a server receives an information acquisition request sent by a terminal.</p><p id="p0126" num="0126">In Step 804, a server generates associated information of at least one video element relating to a playback position in a video, each video element being an image element, a sound element or a play clip in the video.</p><p id="p0127" num="0127">After receiving the information acquisition request, the server reads the video identification in the information acquisition request and the play message corresponding to a playback position, thus generates associated information of at least one video element relating to the playback position corresponding to the play message in the video indicated in the video identification. Wherein, the Step in which a server generates associated information of at least one video element relating to a playback position in a video may comprise:</p><p id="p0128" num="0128">Firstly, it is identified at least one video element in the video.</p><p id="p0129" num="0129">In actual implementation, the Step may comprise:
<ol><li>(1) after receiving an information acquisition request sent by a terminal, a server acquires a play message corresponding to a playback position carried in the information<!-- EPO <DP n="23"> --> acquisition request, the play message comprising at least one of the following messages: image frame data relating to the playback position, audio frame data relating to the playback position, and play time point corresponding to play timeline of the playback position; and</li><li>(2) it is acquired, according to the play message, video elements corresponding to the playback position in the video.</li></ol></p><p id="p0130" num="0130">Wherein, the information acquisition request is a request sent by the terminal after receiving users' information acquisition instruction during playing a video, and the playback position is a corresponding playback position when users' information acquisition instruction is received by the terminal during playing the video.</p><p id="p0131" num="0131">After acquiring a play message in the information acquisition request, a server may acquire, according to the play message, a video element corresponding to a playback position in a video. In actual implementation, the Step in which a server acquires a video element corresponding to a playback position in a video comprises:
<ol><li>(a) it is decoded a video and acquired at least one frame of video data.<br/>
A server decodes a video, and further acquires at least one frame of video data in a video. Wherein, in a video, some playback positions are configured with sound while other playback positions are not configured with sound. The server may simultaneously decode and acquire image frame data and audio frame data at playback positions configured with sound, and decode and acquire only image frame data at playback positions not configured with sound.</li><li>(b) Concerning image frame data, it is identified image elements in the image frame data by means of image recognition technology.<br/>
Concerning image frame data acquired by decoding, a terminal may identify image elements in the image frame data by means of image recognition technology. In actual implementation, the server may match the image frame data acquired by decoding with images in an image database. If elements matching with images in the image database exist in the image frame data, the server takes the matched image elements as image elements in the image frame data. Wherein, the image database is a preset database comprising images including target objects such as figures, sceneries, articles for daily use, trappings, labels, trademarks, brands and keywords, to which the embodiment makes no restriction.</li><li>(c) Concerning audio frame data, it is identified sound elements in the audio frame data by means of speech recognition technology.<br/>
Concerning audio frame data, a terminal may identify sound elements in the audio frame data by means of speech recognition technology. In actual implementation, a server may match audio frame data with a songbook, thus acquiring sound elements in audio frame data. Moreover, in order to more accurately identify a sound element, the server may combine an audio<!-- EPO <DP n="24"> --> frame data with a preset length of audio frame data before the audio frame data, or with a preset length of audio frame data after the audio frame data, or with a preset length of audio frame data before the audio frame data and a preset length of audio frame data after the audio frame data, thus acquiring a multi-frame audio frame data and matching it with a songbook, to which the embodiment makes no restriction. Wherein, the songbook includes a preset database comprising audio frequencies, to which the embodiment makes no restriction.</li></ol></p><p id="p0132" num="0132">It should be explained that it is similar to the identification mode of a video element in Step 701 in the foregoing embodiments, with detailed technical details referred to in the foregoing embodiments, not to be repeated any more herein.</p><p id="p0133" num="0133">Secondly, it is acquired associated information of each video element.</p><p id="p0134" num="0134">After acquiring at least one video element, a server may acquire associated information of each video element. Wherein, the mode in which a server acquires associated information of a video element may comprise the two following possible implementations:</p><p id="p0135" num="0135">In a first possible implementation, the Step may comprise:
<ol><li>(1) concerning each video element, it is acquired at least one information relating to a video element by means of information search technology.<br/>
Concerning each video element identified and acquired by a server, the server may acquire at least one information relating to a video element by means of information search technology.</li><li>(2) It is sorted at least one information according to a preset condition, and extracted top n associated information as associated information of a video element, wherein n being a positive integer.<br/>
A server may sort at least one information acquired according to a preset condition. Wherein, the preset condition comprises: at least one of correlation with a video element, correlation with user location, correlation with users' history usage record, and ranking of manufacturers or suppliers of video elements.</li></ol></p><p id="p0136" num="0136">In a second possible implementation, the Step may comprise:</p><p id="p0137" num="0137">As user may report associated information for each video element, the server may receive associated information reported by other terminals with respect to the video element. Wherein, other terminals are terminals used by other users, or, other terminals are terminals used by manufacturers or suppliers of video elements. Associated information reported by other terminals may be information sorted according to a certain sort order, to which the embodiment makes no restriction.</p><p id="p0138" num="0138">In Step 805, a server feeds back associated information of a video element relating to a playback position in a video to a terminal.<!-- EPO <DP n="25"> --></p><p id="p0139" num="0139">After generating associated information of a video element relating to a playback position in a video, a server feeds back associated information of a video element relating to a playback position in a video to a terminal.</p><p id="p0140" num="0140">In Step 806, a terminal receives such associated information of a video element as relating to a playback position and fed back by the server.</p><p id="p0141" num="0141">In Step 807, a terminal may display associated information at a moment after receiving associated information of a video element relating to a playback position.</p><p id="p0142" num="0142">In actual implementation, users want to acquire associated information of a video element of the current playback position when they send out an information acquisition instruction. Therefore, the terminal may immediately display the associated information relating to the playback position once it is acquired.</p><p id="p0143" num="0143">In conclusion, the information acquisition method according to the embodiment comprises acquiring associated information of a video element in a video and displaying the associated information acquired at a specified moment, solving the problem of less efficient information acquisition, making it possible to display associated information of a video element in a terminal at a specified moment, and improving the information acquisition efficiency.</p><p id="p0144" num="0144">The embodiment comprise: when receiving users' information acquisition instruction, generating an information acquisition request carrying positional information corresponding to a video playback position when an information acquisition instruction is received, sending the information acquisition request to a server, and further acquiring from the server associated information of a video element corresponding to positional information, ensuring the terminal to display associated information required by users as long as they conduct one operation of an information acquisition instruction, thus improving the information acquisition efficiency and reducing user operation complexity.</p><p id="p0145" num="0145">It should be explained that in the foregoing embodiments, the mode of the terminal in displaying associated information may comprise any one of the following modes:</p><heading id="h0006">Mode I:</heading><p id="p0146" num="0146">the associated information is directly displayed by means of a prescriptive model if the terminal is a player device and a remote control unit corresponding to the player device has no information display ability.</p><p id="p0147" num="0147">Wherein, the prescriptive model comprises: at least one of a split screen mode, a list mode, a tagging mode, a scrolling mode, a screen popup mode and a window popup mode.</p><p id="p0148" num="0148">For example, please refer to <figref idrefs="f0007">Fig. 9A</figref>, an example is taken in which the terminal is a television and a prescriptive model is a split screen mode, a scheduled position in a video is<!-- EPO <DP n="26"> --> played by the television. For example, the television continues playing a video in a first display area 91 in a screen, and displays associated information in a second display area 92.</p><p id="p0149" num="0149">Similarly, please refer to <figref idrefs="f0007">Fig. 9B</figref>, the television may also display associated information by using a list mode. In this way, after the terminal displays associated information, users may rapidly seek out information needed from associated information displayed in the terminal, thus improving the information acquisition efficiency and simplifying user operation.</p><p id="p0150" num="0150">Please refer to <figref idrefs="f0008">Fig. 9C</figref>, the television may also display associated information by using a tagging mode. Wherein, each tag is corresponding to video element, users may trigger a corresponding tag if they want to view associated information of a certain video element, and further view associated information corresponding to the tag. Wherein, a terminal interface may display a positioning cursor which is corresponding to a first tag by default, and users may switch positions of the positioning cursor in tags by means of Page Up and Page Down keys of a remote control unit. When the positioning cursor is corresponding to a tag required for users, they may trigger the corresponding tag by pressing Enter key of the remote control unit. In actual implementation, the terminal may number tags before displaying tags. In this way, users may select '1' on the remote control unit and further trigger a first tag if they want to view associated information corresponding to the first tag, to which the embodiment makes no restriction.</p><p id="p0151" num="0151">Please refer to <figref idrefs="f0008">Fig. 9D</figref>, the terminal may also display associated information by using a scrolling mode. In this way, users may view corresponding associated information by viewing a scroll bar at the bottom of the screen while they are watching a video. It should be explained that <figref idrefs="f0008">Fig. 9D</figref> only takes an example in which the scroll bar is at the bottom of the screen. In actual implementation, the scroll bar may also be set at the left side, the right side or the top of the screen, to which the embodiment makes no restriction.</p><p id="p0152" num="0152">Please refer to <figref idrefs="f0009">Fig. 9E</figref>, the terminal may also display associated information by using a screen popup mode. In order to prevent users from missing highlights of a video at the next moment, the terminal may display associated information in a screen popup mode. The terminal may pause the video and continue playing the video when users quit from display of associated information, to which the embodiment makes no restriction.</p><p id="p0153" num="0153">Please refer to <figref idrefs="f0009">Fig. 9F</figref>, the terminal may also display associated information by using a window popup mode. In this way, users may view corresponding associated information in a popup window displayed in the terminal while they are watching a video.</p><heading id="h0007">Mode II:</heading><p id="p0154" num="0154">If the terminal is a player device and a remote control unit corresponding to the player device has information display ability, associated information is directly displayed by means of a prescriptive model or the associated information is sent to the remote control unit configured to<!-- EPO <DP n="27"> --> display the associated information by means of a prescriptive model.</p><p id="p0155" num="0155">When the terminal is a player device, and a remote control unit corresponding to the player device is a device having information display ability, such as a mobile phone or a tablet computer and the like, the terminal may directly display the associated information by means of a prescriptive model, or send the associated information to the remote control unit configured to display the associated information by means of a prescriptive model, to which the embodiment makes no restriction.</p><heading id="h0008">Mode III:</heading><p id="p0156" num="0156">When the terminal is a medium source device connected to a player device and a remote control unit corresponding to the medium source device has no information display ability, the associated information is sent to the player device which can display the associated information by means of a prescriptive model.</p><p id="p0157" num="0157">When the terminal is a medium source device (such as 'XX box') connected to a player device and a remote control unit corresponding to the medium source device has no information display ability, the terminal may send the associated information to the player device, and then the player device may display the associated information by means of a prescriptive model.</p><heading id="h0009">Mode IV:</heading><p id="p0158" num="0158">When the terminal is a medium source device connected to a player device and a remote control unit corresponding to the medium source device has information display ability, the associated information is sent to the player device or the remote control unit configured to display the associated information by means of a prescriptive model.</p><p id="p0159" num="0159">Similarly, when a remote control unit corresponding to a medium source device has information display ability, the terminal may send the associated information to the player device or the remote control unit, and then the player device or the remote control unit may display the associated information by means of a prescriptive model, to which the embodiment makes no restriction.</p><p id="p0160" num="0160">The embodiment only takes an example in which associated information of at least one video element in a video is displayed at the same time. In actual implementation, if attribute information of associated information includes a playback position corresponding to the associated information, when a terminal is playing the playback position, the terminal may display associated information corresponding to the playback position, and further the terminal may respectively display associated information at two or more playback positions if there is associated information relating to two or more playback positions, to which the embodiment makes no restriction.<!-- EPO <DP n="28"> --></p><p id="p0161" num="0161">It should also be explained that when associated information is corresponding to two or more video elements, the terminal may display their associated information in a menu mode, for example, the display schematic diagram of the terminal is as shown in <figref idrefs="f0010">Fig.9G</figref> when the terminal displays in a split screen mode.</p><p id="p0162" num="0162">It shall be further explained that when associated information of a video element displayed on a terminal is triggered, the terminal may also execute the following steps:</p><p id="p0163" num="0163">jumping to a playback position corresponding to a video element in a video for playing; or jumping to information content corresponding to an information link comprised in the associated information for displaying.</p><p id="p0164" num="0164">After the terminal displays associated information, users may trigger to display the associated information according to their needs. For example, when associated information is displayed at a tail leader, users may trigger the associated information if they want to watch highlights (or wonderful clips) at a playback position corresponding to the associated information once more. After being triggered, the associated information jumps to the playback position corresponding to a video element in the video for playing. In this way, users need neither replay the video nor wait for the playback position corresponding to associated information to watch again the corresponding highlights, thus gaining convenience.</p><p id="p0165" num="0165">When associated information comprises an information link, users may trigger the associated information in order to view detailed information corresponding to the information link; after the associated information is triggered, the terminal jumps to information content corresponding to the information link comprised in the associated information for displaying. In this way, users may directly view detailed information corresponding to the associated information in an information display interface after the terminal is jumped, thus improving the information acquisition efficiency.</p><p id="p0166" num="0166">The Step in which a terminal jumps to information content corresponding to an information link comprised in the associated information for displaying comprises:
<ul><li>if the information link is an information introduction link, jumping to information introduction corresponding to the information introduction link for displaying;</li><li>if the information link is a shopping information link, jumping to shopping information corresponding to the shopping information link for displaying;</li><li>if the information link is a ticket information link, jumping to ticket information corresponding to the ticket information link for displaying;<!-- EPO <DP n="29"> --></li><li>if the information link is a traffic information link, jumping to traffic information corresponding to the traffic information link for displaying;</li><li>if the information link is a travel information link, jumping to travel information corresponding to the travel information link for displaying;</li><li>if the information link is a figure social information link, jumping to figure social information corresponding to the figure social information link for displaying; and</li><li>if the information link is a comment information link, jumping to comment information corresponding to the comment information link for displaying.</li></ul></p><p id="p0167" num="0167">For example, if the server determines associated information 'the latest report of character A' of an image of 'character A' as a link, when users select the associated information displayed in the terminal, the terminal may jump to figure social information corresponding to the link for displaying; and if concerning an image of'a certain coat of XX brand', information searched by the server also comprises a shopping link provided in an E-business network, when users select the associated information, the terminal may jump to shopping information corresponding to the shopping link for displaying.</p><p id="p0168" num="0168">The following is the embodiment of the device in the present disclosure, which may be configured to execute the embodiment of the method in the present disclosure. Please refer to the embodiment of the method in the present disclosure with regard to undisclosed details about the embodiment of the device in the present disclosure.</p><p id="p0169" num="0169"><figref idrefs="f0010">Fig. 10</figref> is a block diagram of an information acquisition device according to an exemplary embodiment; the information acquisition device can realize to become the terminal as shown in <figref idrefs="f0001">Fig. 1A</figref> or <figref idrefs="f0002">Fig. 1B</figref> in part or in whole by means of software or hardware or combination of both. The information acquisition device may comprise: an information acquisition module 1010 and an information display module 1020.</p><p id="p0170" num="0170">The information acquisition module 1010 is configured to acquire associated information of at least one video element in a video, and each video element is an image element, a sound element or a play clip in the video; and<br/>
the information display module 1020 is configured to display the associated information at a specified moment.</p><p id="p0171" num="0171">In conclusion, the information acquisition device according to the embodiment comprises acquiring associated information of a video element in a video and displaying the associated information acquired at a specified moment, solving the problem of less efficient information acquisition, making it possible to display associated information of a video element in a terminal at a specified moment, and improving the information acquisition efficiency.<!-- EPO <DP n="30"> --></p><p id="p0172" num="0172"><figref idrefs="f0011">Fig. 11</figref> is a block diagram of an information acquisition device according to an exemplary embodiment; the information acquisition device can realize to become the terminal as shown in <figref idrefs="f0001">Fig. 1A</figref> or <figref idrefs="f0002">Fig. 1B</figref> in part or in whole by means of software or hardware or combination of both. The information acquisition device may comprise: an information acquisition module 1110 and an information display module 1120.</p><p id="p0173" num="0173">The information acquisition module 1110 is configured to acquire associated information of at least one video element in a video, and each video element is an image element, a sound element or a play clip in the video.</p><p id="p0174" num="0174">The information display module 1120 is configured to display the associated information at a specified moment.</p><p id="p0175" num="0175">In the first possible implementation according to the embodiment, the information acquisition module 1010 is configured to download associated information of at least one video element in a video from a server and to save the associated information at a scheduled moment.</p><p id="p0176" num="0176">The scheduled moment includes: a moment prior to playing a video, a moment during playing a video or an idle moment.</p><p id="p0177" num="0177">In the second possible implementation according to the embodiment, the specified moment includes:
<ul><li>a moment playing a tail leader of a video; or</li><li>a moment receiving a pause signal during playing the video; or</li><li>a moment playing a scheduled position of a video.</li></ul></p><p id="p0178" num="0178">In the third possible implementation according to the embodiment, the information acquisition module 1110 is configured to search, from associated information of at least one video element in a video downloaded in advance, for associated information of a video element relating to the playback position in case of receiving users' information acquisition instruction when playing a certain playback position in the video.</p><p id="p0179" num="0179">In the fourth possible implementation according to the embodiment, the information acquisition module 1110 comprises:
<ul><li>a request sending unit 1111, configured to send an information acquisition request to a server in case of receiving users' information acquisition instruction when playing a certain playback position in a video, the information acquisition request being configured to acquire associated information of a video element relating to the playback position; and</li><li>an information receiving unit 1112, configured to receive associated information of a video element which is relative to a playback position and fed back by a server.</li></ul><!-- EPO <DP n="31"> --></p><p id="p0180" num="0180">In the fifth possible implementation according to the embodiment, the request sending unit 1111 comprises:
<ul><li>an information acquisition subunit 1111a, configured to acquire a play message corresponding to a playback position, the play message comprising at least one of following messages: image frame data relating to the playback position, audio frame data relating to the playback position, and play time point corresponding to play timeline of the playback position; and</li><li>a request sending subunit 1111b, configured to send an information acquisition request to a server, the information acquisition request carrying a video identification of a video and a play message corresponding to a playback position.</li></ul></p><p id="p0181" num="0181">In the sixth possible implementation according to the embodiment, the specified moment includes:
<ul><li>a moment after acquiring associated information of a video element relating to a playback position.</li></ul></p><p id="p0182" num="0182">In the seventh possible implementation according to the embodiment, the information display module 1120 is configured to:
<ul><li>if a terminal is a player device and a remote control unit corresponding to the player device has no information display ability, display associated information directly by means of a prescriptive model;</li><li>if a terminal is a player device and a remote control unit corresponding to the player device has information display ability, display associated information directly by means of a prescriptive model or send the associated information to the remote control unit configured to display the associated information by means of a prescriptive model.</li></ul></p><p id="p0183" num="0183">When the terminal is a medium source device connected to a player device and a remote control unit corresponding to the medium source device has no information display ability, the associated information is sent to the player device configured to display the associated information by means of a prescriptive model.</p><p id="p0184" num="0184">When the terminal is a medium source device connected to a player device and a remote control unit corresponding to the medium source device has information display ability, the associated information is sent to the player device or the remote control unit configured to display the associated information by means of a prescriptive model.</p><p id="p0185" num="0185">Wherein, the prescriptive model comprises: at least one of a split screen mode, a list mode, a tagging mode, a scrolling mode, a screen popup mode and a window popup mode.</p><p id="p0186" num="0186">In the eighth possible implementation according to the embodiment, the device also comprises:<!-- EPO <DP n="32"> -->
<ul><li>an information jump module 1130, configured to, when associated information of a video element displayed is triggered jump to a playback position corresponding to a video element in a video for playing or jump to information content corresponding to an information link comprised in the associated information for displaying.</li></ul></p><p id="p0187" num="0187">In conclusion, the information acquisition device according to the embodiment comprises generating associated information of at least one video element and providing a terminal with associated information of at least one video element so as to display associated information at a specified moment after the associated information is acquired by the terminal, solving the problem of less efficient information acquisition, making it possible to display associated information of a video element by a terminal at a specified moment, and improving the information acquisition efficiency.</p><p id="p0188" num="0188"><figref idrefs="f0011">Fig. 12</figref> is a block diagram of an information acquisition device according to an exemplary embodiment; the information acquisition device can realize to become the server as shown in <figref idrefs="f0001">Fig. 1A</figref> or <figref idrefs="f0002">Fig. 1B</figref> in part or in whole by means of software or hardware or combination of both. The information acquisition device may comprise: an information generation module 1210 and an information providing module 1220.</p><p id="p0189" num="0189">The information generation module 1210 is configured to generate associated information of at least one video element in a video, and each video element is an image element, a sound element or a play clip in the video.</p><p id="p0190" num="0190">The information providing module 1220 is configured to provide a terminal with associated information of at least one video element in a video, the terminal being configured to display the associated information at a specified moment.</p><p id="p0191" num="0191">In conclusion, the information acquisition device according to the embodiment comprises generating associated information of at least one video element and providing a terminal with associated information of at least one video element so as to display associated information at a specified moment after the associated information is acquired by the terminal, solving the problem of less efficient information acquisition, making it possible to display associated information of a video element by a terminal at a specified moment, and improving the information acquisition efficiency.</p><p id="p0192" num="0192"><figref idrefs="f0012 f0013">Fig. 13</figref> is a block diagram of an information acquisition device according to an exemplary embodiment; the information acquisition device can realize to become the server as shown in <figref idrefs="f0001">Fig. 1A</figref> or <figref idrefs="f0002">Fig. 1B</figref> in part or in whole by means of software or hardware or combination of both. The information acquisition device may comprise: an information generation module<!-- EPO <DP n="33"> --> 1310 and an information providing module 1320.</p><p id="p0193" num="0193">The information generation module 1310 is configured to generate associated information of at least one video element in a video, and each video element is an image element, a sound element or a play clip in the video.</p><p id="p0194" num="0194">The information providing module 1320 is configured to provide a terminal with associated information of at least one video element in a video, the terminal being configured to display the associated information at a specified moment.</p><p id="p0195" num="0195">In the first possible implementation according to the embodiment,</p><p id="p0196" num="0196">the information providing module 1320 is configured to provide the terminal with downloads to associated information of at least one video element in a video at a scheduled moment.</p><p id="p0197" num="0197">The scheduled moment includes: a moment prior to playing a video by the terminal, a moment during playing a video by the terminal or an idle moment of the terminal.</p><p id="p0198" num="0198">In the second possible implementation according to the embodiment,
<ul><li>the information providing module 1320 is configured to feed, after receiving an information acquisition request sent by the terminal, back associated information of a video element relating to a playback position in a video to the terminal; wherein,</li><li>the information acquisition request is a request sent by the terminal after receiving users' information acquisition instruction during playing a video, and the playback position is a corresponding playback position when users' information acquisition instruction is received by the terminal during playing the video.</li></ul></p><p id="p0199" num="0199">In the third possible implementation according to the embodiment, the information generation module 1310 comprises:
<ul><li>an element identification unit 1311, configured to identify at least one video element in a video; and</li><li>an information acquisition unit 1312, configured to acquire associated information of each video element.</li></ul></p><p id="p0200" num="0200">Referring to <figref idrefs="f0012">Fig. 13B</figref>, in the fourth possible implementation according to the embodiment, the element identification unit 1311 comprises:
<ul><li>a video data acquisition subunit 1311a, configured to decode a video and acquire at least one frame of video data comprising image frame data or both image frame data and audio frame data;</li><li>a first identification subunit 1311b, configured to, concerning image frame data, identify image elements in the image frame data by means of image recognition technology; and</li><li>a second identification subunit 1311c, configured to, concerning audio frame data,<!-- EPO <DP n="34"> --> identify sound elements in the audio frame data by means of speech recognition technology.</li></ul></p><p id="p0201" num="0201">Referring to <figref idrefs="f0013">Fig. 13C</figref>, in the fifth possible implementation according to the embodiment, the element identification unit 1311 comprises:
<ul><li>a play message acquisition subunit 1311e, configured to, after receiving an information acquisition request sent by a terminal, acquire a play message corresponding to a playback position carried in the information acquisition request; and</li><li>an element acquisition subunit 1311f, configured to, according to a play message, acquire a video element corresponding to a playback position in a video, the play message comprising at least one of the following messages: image frame data relating to a playback position, audio frame data relating to a playback position, and play time point corresponding to play timeline of a playback position.</li></ul></p><p id="p0202" num="0202">Wherein, the information acquisition request is a request sent by the terminal after receiving users' information acquisition instruction during playing a video, and the playback position is a corresponding playback position when users' information acquisition instruction is received by the terminal during playing the video.</p><p id="p0203" num="0203">In the sixth possible implementation according to the embodiment, the element identification unit 1311 is configured to receive at least one video element reported by other terminals to a video, and the video element is one labeled by users of other terminals.</p><p id="p0204" num="0204">Referring to <figref idrefs="f0013">Fig. 13D</figref>, in the seventh possible implementation according to the embodiment, the information acquisition unit 1312 comprises:
<ul><li>an information acquisition subunit 1312a, configured to, concerning each video element, acquire at least one information of the video element by means of information search technology; and</li><li>an information sorting subunit 1312b, configured to sort at least one information according to a preset condition, and to extract top n associated information as associated information of the video element, wherein n being a positive integer.</li></ul></p><p id="p0205" num="0205">The preset condition comprises: at least one of correlation with a video element, correlation with user location, correlation with users' history usage record, and ranking of manufacturers or suppliers of video elements.</p><p id="p0206" num="0206">In the eighth possible implementation according to the embodiment,</p><p id="p0207" num="0207">the information acquisition unit 1312 is configured to receive associated information reported by other terminals to a video element, and other terminals are terminals used by other users, or, other terminals are terminals used by manufacturers or suppliers of the video element.</p><p id="p0208" num="0208">In conclusion, the information acquisition device according to the embodiment comprises generating associated information of at least one video element and providing a<!-- EPO <DP n="35"> --> terminal with associated information of at least one video element so as to display associated information at a specified moment after the associated information is acquired by the terminal, solving the problem of less efficient information acquisition, making it possible to display associated information of a video element by a terminal at a specified moment, and improving the information acquisition efficiency.</p><p id="p0209" num="0209">With regard to the device in the above embodiment, detailed description of specific modes for conducting operation of modules has been made in the embodiment related to the method, no detailed illustration will be made herein.</p><p id="p0210" num="0210"><figref idrefs="f0014">Fig. 14</figref> is a block diagram of an information acquisition device 1400 according to an exemplary embodiment. For example, the device 1400 may be a mobile telephone, a computer, a digital broadcasting terminal, a message transceiver device, a games console, a tablet device, a medical device, a fitness facility, a PDA (personal digital assistant) and the like.</p><p id="p0211" num="0211">Referring to <figref idrefs="f0014">Fig. 14</figref>, the device 1400 may include one or a plurality of components as below: a processor component 1402, a memory 1404, a power supply component 1406, a multimedia component 1408, an audio component 1410, an input/output (I/O) interface 1412, a sensor component 1414 and a communication component 1416.</p><p id="p0212" num="0212">The processor component 1402 usually controls the overall operation of the device 1400, for example, display, telephone call, data communication, and operation associated with camera operation and record operation. The processor component 1402 may include one or a plurality of processors 1420 for executing instructions so as to complete steps of above method in part or in whole. In addition, the processor component 1402 may include one or a plurality of modules for the convenience of interaction between the processor component 1402 and other components. For example, the processor component 1402 may include a multimedia module for the convenience of interaction between the multimedia component 1408 and the processor component 1402.</p><p id="p0213" num="0213">The memory 1404 is configured to store data of different types so as to support the operation of the device 1400. Examples of the data include any application program or approach directive for operation of the device 1400, including contact data, phonebook data, message, picture and video, etc. The memory 1404 may be realized by volatile or non-volatile memory device of any type or combination thereof, for example, static random access memory (SRAM), electrically erasable programmable read-only memory (EEPROM), erasable programmable read only memory (EPROM), programmable read-only memory (PROM), read-only memory (ROM), magnetic memory, flash memory, magnetic disk or optical disk.<!-- EPO <DP n="36"> --></p><p id="p0214" num="0214">The power supply component 1406 provides power for components of the device 1400. The power supply component 1406 may include a power management system, one or a plurality of power supplies, and other components associated with generation, management and power distribution of the device 1400.</p><p id="p0215" num="0215">The multimedia component 1408 includes a screen between the device 1400 and a user and for providing an output interface. In some embodiments, the screen may include an LCD (Liquid Crystal Display) and a touch panel (TP). If the screen includes a touch panel, the screen may be realized as a touch screen for receiving input signal from users. The touch panel includes one or a plurality of touch sensors for sensing gestures on the touch panel, for example, touching and sliding, etc. The touch sensor not only can sensor trip boundary of touching or sliding, but also can detect the duration and pressure related to the touching or sliding operation. In some embodiments, the multimedia component 1408 includes a front-facing camera and/or a rear-facing camera. When the device 1400 is under an operation mode, for example, capture mode or video mode, the front-facing camera and/or the rear-facing camera may receive external multimedia data. Each front-facing camera and rear-facing camera may be a fixed optical lens system or have focal length and optical zoom capacity.</p><p id="p0216" num="0216">The audio component 1410 is configured to output and/or input audio signal. For example, the audio component 1410 includes a microphone (MIC); when the device 1400 is under an operation mode such as call mode, record mode and speech recognition mode, the microphone is configured to receive external audio signal. The audio signal received may be further stored in the memory 1404 or sent out by the communication component 1416. In some embodiments, the audio component 1410 also includes a loudspeaker for outputting audio signal.</p><p id="p0217" num="0217">The I/O interface 1412 provides interface for the processor component 1402 and peripheral interface modules, the peripheral interface modules may be a keyboard, a click wheel and buttons, etc. These buttons may include but not limited to: home button, volume button, start button and locking button.</p><p id="p0218" num="0218">The sensor component 1414 includes one or a plurality of sensors for providing the device 1400 with state evaluation from all aspects. For example, the sensor component 1414 may detect the on/off state of the device 1400, relative positioning of components, for example, the components are the displayer and keypads of the device 1400; the sensor component 1414 also may detect the position change of the device 1400 or a component thereof, the presence or absence of users' touch on the device 1400, the direction or acceleration/deceleration of the device 1400, and temperature variation of the device 1400. The sensor component 1414 may also include a proximity detector, which is configured to detect the presence of nearby objects in case of no physical touch. The sensor component 1414 may also include an optical sensor, for example,<!-- EPO <DP n="37"> --> CMOS or CCD image sensor for imaging. In some embodiments, the sensor component 1414 may also include an acceleration sensor, a gyro sensor, a magnetic sensor, a pressure sensor, or a temperature sensor.</p><p id="p0219" num="0219">The communication component 1416 is configured to facilitate wired communication or wireless communication between the device 1400 and other equipment. The device 1400 is available for access to wireless network based on communication standards, for example, WiFi, 2G or 3G, or combination thereof. In an exemplary embodiment, the communication component 1416 receives by means of a broadcast channel the broadcast signal or broadcast-related information from external broadcast management systems. In an exemplary embodiment, the communication component 1416 also includes a near field communication (NFC) module for promoting short-range communication. For example, the NFC module may be realized on the basis of Radio Frequency Identification (RFID) Technology, Infrared Data Association (IrDA) Technology, Ultra-wide Bandwidth (UWB) Technology, Bluetooth (BT) Technology and other technologies.</p><p id="p0220" num="0220">In exemplary embodiments, the device 1400 may be realized by one or a plurality of application specific integrated circuits (ASIC), digital signal processors (DSP), digital signal processing equipment (DSPD), programmable logic devices (PLD), field programmable gate arrays (FPGA), controllers, microcontrollers, microprocessors or other electronic components, configured to execute the above methods.</p><p id="p0221" num="0221">In exemplary embodiments, a non-transitory computer-readable storage medium including instructions is also provided, for example, a memory 1404 including instructions, above instructions may be executed by the processors 1420 of the device 1400 so as to achieve the above methods. For example, the non-transitory computer-readable storage medium may be ROM, random access memory (RAM), CD-ROM, magnetic tape, floppy disk and optical data storage device, etc.</p><p id="p0222" num="0222">A non-transitory computer-readable storage medium may, when instructions in the storage medium are executed by the processor of the device 1400, cause the device 1400 to execute an information acquisition method, and the method comprises:</p><p id="p0223" num="0223"><figref idrefs="f0015">Fig. 15</figref> is a block diagram of an information acquisition device 1500 according to an exemplary embodiment. For example, the device 1500 may be implemented as a server. Referring to <figref idrefs="f0015">Fig. 15</figref>, the device 1500 includes a processor component 1522, and further includes one or a plurality of processors, and memory resource represented by the memory 1532 and configured to store instructions that can be executed by the processor component 1522, for example, application program. The application program stored in the memory 1532 may include one or a plurality of<!-- EPO <DP n="38"> --> modules each of which is corresponding to a set of instructions. In addition, the processor component 1522 is configured to execute instructions so as to execute the foregoing information acquisition method.</p><p id="p0224" num="0224">The device 1500 may also include a power supply module 1526 configured to execute the power management of the device 1500, a wired or wireless network interface 1550 configured to connect the device 1500 to the network, and an input/output (I/O) interface 1558. The device 1500 can operate an operating system based on and stored in the memory 1532, for example, Windows ServerTM, Mac OS XTM, UnixTM, LinuxTM, FreeBSDTM or other similar operating systems.</p><p id="p0225" num="0225">It will be appreciated that the present invention is not limited to the exact construction that has been described above and illustrated in the accompanying drawings, and that various modifications and changes can be made without departing from the scope thereof. It is intended that the scope of the invention should only be limited by the appended claims.</p></description><claims mxw-id="PCLM90459171" lang="EN" load-source="patent-office"><!-- EPO <DP n="39"> --><claim id="c-en-0001" num="0001"><claim-text>An information acquisition method at a client, comprising:
<claim-text>acquiring associated information of at least one video element in a video, each video element being an image element, a sound element or a play clip in the video; and</claim-text>
<claim-text>displaying the associated information at a specified moment.</claim-text></claim-text></claim><claim id="c-en-0002" num="0002"><claim-text>The method according to claim 1, wherein the acquiring associated information of at least one video element in a video comprises:
<claim-text>downloading associated information of at least one video element in the video from a server and saving the associated information at a scheduled moment;</claim-text>
<claim-text>the scheduled moment comprising: a moment prior to playing the video, a moment during playing the video or an idle moment.</claim-text></claim-text></claim><claim id="c-en-0003" num="0003"><claim-text>The method according to claim 1 or claim 2, wherein the specified moment comprises:
<claim-text>a moment playing a tail leader of the video; or</claim-text>
<claim-text>a moment receiving a pause signal during playing the video.</claim-text></claim-text></claim><claim id="c-en-0004" num="0004"><claim-text>The method according to any of claims 1 to 3, wherein the acquiring associated information of at least one video element in a video comprises:
<claim-text>searching, from associated information of at least one video element in the video downloaded in advance, for associated information of a video element relating to the playback position in case of receiving users' information acquisition instruction when playing a certain playback position in the video.</claim-text></claim-text></claim><claim id="c-en-0005" num="0005"><claim-text>The method according to any of claims 1 to 3, wherein the acquiring associated information of at least one video element in a video comprises:
<claim-text>sending an information acquisition request to a server in case of receiving users' information acquisition instruction when playing a certain playback position in the video, the information acquisition request being configured to acquire associated information of a video element relating<!-- EPO <DP n="40"> --> to the playback position; and</claim-text>
<claim-text>receiving such associated information of a video element as relating to the playback position and fed back by the server.</claim-text></claim-text></claim><claim id="c-en-0006" num="0006"><claim-text>The method according to claim 5, wherein the sending an information acquisition request to a server comprises:
<claim-text>acquiring a play message corresponding to the playback position, the play message comprising at least one of following messages: image frame data relating to the playback position, audio frame data relating to the playback position, and play time point corresponding to play timeline of the playback position; and</claim-text>
<claim-text>sending the information acquisition request to the server, the information acquisition request carrying a video identification of the video and the play message corresponding to the playback position.</claim-text></claim-text></claim><claim id="c-en-0007" num="0007"><claim-text>The method according to any of claims 4-6, wherein the specified moment comprises:
<claim-text>a moment after acquiring associated information of a video element relating to the playback position.</claim-text></claim-text></claim><claim id="c-en-0008" num="0008"><claim-text>The method according to any of claims 1-6, wherein the displaying the associated information at a specified moment comprises:
<claim-text>if the terminal is a player device and a remote control unit corresponding to the player device has no information display ability, displaying directly the associated information by means of a prescriptive model;</claim-text>
<claim-text>if the terminal is a player device and a remote control unit corresponding to the player device has information display ability, displaying directly the associated information by means of a prescriptive model, or sending the associated information to the remote control unit configured to display the associated information by means of a prescriptive model;</claim-text>
<claim-text>if the terminal is a medium source device connectable to a player device and a remote control unit corresponding to the medium source device has no information display ability, sending the associated information to the player device, the player device being configured to display the<!-- EPO <DP n="41"> --> associated information by means of a prescriptive model; and</claim-text>
<claim-text>if the terminal is a medium source device connectable to a player device and a remote control unit corresponding to the medium source device has information display ability, sending the associated information to the player device or the remote control unit, the player device or the remote control unit being configured to display the associated information by means of a prescriptive model;</claim-text>
<claim-text>wherein, the prescriptive model comprising: at least one of a split screen mode, a list mode, a tagging mode, a scrolling mode, a screen popup mode and a window popup mode.</claim-text></claim-text></claim><claim id="c-en-0009" num="0009"><claim-text>The method according to any of claims 1-6, wherein the method further comprises:
<claim-text>when associated information of a video element displayed is triggered, jumping to a playback position corresponding to the video element in the video for playing, or jumping to information content corresponding to an information link comprised in the associated information for displaying.</claim-text></claim-text></claim><claim id="c-en-0010" num="0010"><claim-text>An information acquisition method at a server, comprising:
<claim-text>generating associated information of at least one video element in a video, each video element being an image element, a sound element or a play clip in the video; and</claim-text>
<claim-text>providing a terminal with the associated information of the at least one video element in the video, the terminal being configured to display the associated information at a specified moment.</claim-text></claim-text></claim><claim id="c-en-0011" num="0011"><claim-text>The method according to claim 10, wherein the providing a terminal with the associated information of the at least one video element in the video comprises:
<claim-text>providing the terminal with downloads to the associated information of the at least one video element in the video at a scheduled moment;</claim-text>
<claim-text>the scheduled moment comprising: a moment prior to playing the video by the terminal, a moment during playing the video by the terminal or an idle moment of the terminal.</claim-text></claim-text></claim><claim id="c-en-0012" num="0012"><claim-text>The method according to claim 10, wherein the providing a terminal with the associated information of the at least one video element in the video comprises:<!-- EPO <DP n="42"> -->
<claim-text>feeding, after receiving an information acquisition request sent from the terminal, back associated information of a video element of a playback position in the video to the terminal; wherein,</claim-text>
<claim-text>the information acquisition request being a request sent from the terminal after receiving users' information acquisition instruction during playing the video, and the playback position being a corresponding playback position when users' information acquisition instruction is received by the terminal during playing the video.</claim-text></claim-text></claim><claim id="c-en-0013" num="0013"><claim-text>A client device for information acquisition , comprising:
<claim-text>an information acquisition module, configured to acquire associated information of at least one video element in a video, each video element being an image element, a sound element or a play clip in the video; and</claim-text>
<claim-text>an information display module, configured to display the associated information at a specified moment.</claim-text></claim-text></claim><claim id="c-en-0014" num="0014"><claim-text>A server device for information acquisition, comprising:
<claim-text>an information generation module, configured to generate associated information of at least one video element in a video, each video element being an image element, a sound element or a play clip in the video; and</claim-text>
<claim-text>an information providing module, configured to provide a terminal with the associated information of the at least one video element in the video, the terminal being configured to display the associated information at a specified moment.</claim-text></claim-text></claim><claim id="c-en-0015" num="0015"><claim-text>A computer program product, which when executing on a processor of a client, performs a method according to any of claims 1-9, or when executing on a processor of a server, performs a method according to any of claims 10-12.</claim-text></claim></claims><drawings mxw-id="PDW20421907" load-source="patent-office"><!-- EPO <DP n="43"> --><figure id="f0001" num="1A"><img id="if0001" file="imgf0001.tif" wi="165" he="137" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="44"> --><figure id="f0002" num="1B"><img id="if0002" file="imgf0002.tif" wi="165" he="163" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="45"> --><figure id="f0003" num="2"><img id="if0003" file="imgf0003.tif" wi="165" he="98" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="46"> --><figure id="f0004" num="3,4"><img id="if0004" file="imgf0004.tif" wi="165" he="131" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="47"> --><figure id="f0005" num="5,6,7"><img id="if0005" file="imgf0005.tif" wi="165" he="201" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="48"> --><figure id="f0006" num="8"><img id="if0006" file="imgf0006.tif" wi="165" he="173" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="49"> --><figure id="f0007" num="9A,9B"><img id="if0007" file="imgf0007.tif" wi="157" he="231" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="50"> --><figure id="f0008" num="9C,9D"><img id="if0008" file="imgf0008.tif" wi="150" he="233" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="51"> --><figure id="f0009" num="9E,9F"><img id="if0009" file="imgf0009.tif" wi="144" he="216" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="52"> --><figure id="f0010" num="9G,10"><img id="if0010" file="imgf0010.tif" wi="142" he="193" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="53"> --><figure id="f0011" num="11,12"><img id="if0011" file="imgf0011.tif" wi="137" he="211" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="54"> --><figure id="f0012" num="13A,13B"><img id="if0012" file="imgf0012.tif" wi="130" he="205" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="55"> --><figure id="f0013" num="13C,13D"><img id="if0013" file="imgf0013.tif" wi="102" he="183" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="56"> --><figure id="f0014" num="14"><img id="if0014" file="imgf0014.tif" wi="165" he="174" img-content="drawing" img-format="tif"/></figure><!-- EPO <DP n="57"> --><figure id="f0015" num="15"><img id="if0015" file="imgf0015.tif" wi="141" he="144" img-content="drawing" img-format="tif"/></figure></drawings><search-report-data><doc-page id="srep0001" file="srep0001.tif" wi="163" he="233" type="tif"/><doc-page id="srep0002" file="srep0002.tif" wi="163" he="233" type="tif"/><doc-page id="srep0003" file="srep0003.tif" wi="163" he="233" type="tif"/></search-report-data><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
