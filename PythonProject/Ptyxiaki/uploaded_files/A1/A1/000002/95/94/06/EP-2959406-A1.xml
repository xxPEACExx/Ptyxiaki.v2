<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2959406-A1" country="EP" doc-number="2959406" kind="A1" date="20151230" family-id="50156924" file-reference-id="252649" date-produced="20180825" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="160453255" ucid="EP-2959406-A1"><document-id><country>EP</country><doc-number>2959406</doc-number><kind>A1</kind><date>20151230</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-14706185-A" is-representative="NO"><document-id mxw-id="PAPP193869478" load-source="patent-office" format="original"><country>EP</country><doc-number>14706185.7</doc-number><date>20140205</date><lang>EN</lang></document-id><document-id mxw-id="PAPP193869479" load-source="docdb" format="epo"><country>EP</country><doc-number>14706185</doc-number><kind>A</kind><date>20140205</date><lang>EN</lang></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC162034427" ucid="US-201313772640-A" load-source="docdb"><document-id format="epo"><country>US</country><doc-number>201313772640</doc-number><kind>A</kind><date>20130221</date></document-id></priority-claim><priority-claim mxw-id="PPC162027840" ucid="US-2014014763-W" linkage-type="W" load-source="docdb"><document-id format="epo"><country>US</country><doc-number>2014014763</doc-number><kind>W</kind><date>20140205</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL-1988525388" load-source="docdb">G06F  17/30        20060101AFI20140911BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-1987764780" load-source="docdb" scheme="CPC">G06F  17/30286     20130101 FI20150911BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987783101" load-source="docdb" scheme="CPC">G06T  17/00        20130101 LI20150911BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT165551231" lang="DE" load-source="patent-office">AUTOMATISCHE BILDENTZERRUNG FÜR VISUELLE SUCHE</invention-title><invention-title mxw-id="PT165551232" lang="EN" load-source="patent-office">AUTOMATIC IMAGE RECTIFICATION FOR VISUAL SEARCH</invention-title><invention-title mxw-id="PT165551233" lang="FR" load-source="patent-office">RECTIFICATION AUTOMATIQUE D'IMAGE POUR UNE RECHERCHE VISUELLE</invention-title><citations><non-patent-citations><nplcit><text>See references of WO 2014130237A1</text><sources><source mxw-id="PNPL67568154" load-source="docdb" name="SEA"/></sources></nplcit></non-patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR1103332909" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>QUALCOMM INC</last-name><address><country>US</country></address></addressbook></applicant><applicant mxw-id="PPAR1103342884" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>QUALCOMM INCORPORATED</last-name></addressbook></applicant><applicant mxw-id="PPAR1101648608" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Qualcomm Incorporated</last-name><iid>101331406</iid><address><street>5775 Morehouse Drive</street><city>San Diego, CA 92121-1714</city><country>US</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR1103330510" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>WAGNER DANIEL</last-name><address><country>US</country></address></addressbook></inventor><inventor mxw-id="PPAR1103343053" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>WAGNER, DANIEL</last-name></addressbook></inventor><inventor mxw-id="PPAR1101641511" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>WAGNER, DANIEL</last-name><address><street>5775 Morehouse Drive</street><city>San Diego, California 92121-1714</city><country>US</country></address></addressbook></inventor><inventor mxw-id="PPAR1103336591" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>PAN QI</last-name><address><country>US</country></address></addressbook></inventor><inventor mxw-id="PPAR1103311580" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>PAN, QI</last-name></addressbook></inventor><inventor mxw-id="PPAR1101644898" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>PAN, QI</last-name><address><street>5775 Morehouse Drive</street><city>San Diego, California 92121-1714</city><country>US</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR1101640848" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Carstens, Dirk Wilhelm</last-name><iid>100774030</iid><address><street>Wagner &amp; Geyer Gewürzmühlstrasse 5</street><city>80538 München</city><country>DE</country></address></addressbook></agent></agents></parties><international-convention-data><pct-or-regional-filing-data ucid="US-2014014763-W"><document-id><country>US</country><doc-number>2014014763</doc-number><kind>W</kind><date>20140205</date><lang>EN</lang></document-id></pct-or-regional-filing-data><pct-or-regional-publishing-data ucid="WO-2014130237-A1"><document-id><country>WO</country><doc-number>2014130237</doc-number><kind>A1</kind><date>20140828</date><lang>EN</lang></document-id></pct-or-regional-publishing-data><designated-states><ep-contracting-states><country mxw-id="DS660635587" load-source="docdb">AL</country><country mxw-id="DS660637753" load-source="docdb">AT</country><country mxw-id="DS660792338" load-source="docdb">BE</country><country mxw-id="DS660634303" load-source="docdb">BG</country><country mxw-id="DS660742912" load-source="docdb">CH</country><country mxw-id="DS660792339" load-source="docdb">CY</country><country mxw-id="DS660637754" load-source="docdb">CZ</country><country mxw-id="DS660635589" load-source="docdb">DE</country><country mxw-id="DS660792340" load-source="docdb">DK</country><country mxw-id="DS660792341" load-source="docdb">EE</country><country mxw-id="DS660717474" load-source="docdb">ES</country><country mxw-id="DS660634304" load-source="docdb">FI</country><country mxw-id="DS660742913" load-source="docdb">FR</country><country mxw-id="DS660635590" load-source="docdb">GB</country><country mxw-id="DS660792342" load-source="docdb">GR</country><country mxw-id="DS660635599" load-source="docdb">HR</country><country mxw-id="DS660637767" load-source="docdb">HU</country><country mxw-id="DS660717479" load-source="docdb">IE</country><country mxw-id="DS660792343" load-source="docdb">IS</country><country mxw-id="DS660634305" load-source="docdb">IT</country><country mxw-id="DS660792344" load-source="docdb">LI</country><country mxw-id="DS660634306" load-source="docdb">LT</country><country mxw-id="DS660714389" load-source="docdb">LU</country><country mxw-id="DS660634311" load-source="docdb">LV</country><country mxw-id="DS660634312" load-source="docdb">MC</country><country mxw-id="DS660714390" load-source="docdb">MK</country><country mxw-id="DS660714395" load-source="docdb">MT</country><country mxw-id="DS660714396" load-source="docdb">NL</country><country mxw-id="DS660742914" load-source="docdb">NO</country><country mxw-id="DS660714397" load-source="docdb">PL</country><country mxw-id="DS660717480" load-source="docdb">PT</country><country mxw-id="DS660723409" load-source="docdb">RO</country><country mxw-id="DS660717481" load-source="docdb">RS</country><country mxw-id="DS660714398" load-source="docdb">SE</country><country mxw-id="DS660635601" load-source="docdb">SI</country><country mxw-id="DS660742919" load-source="docdb">SK</country><country mxw-id="DS660742920" load-source="docdb">SM</country><country mxw-id="DS660792345" load-source="docdb">TR</country></ep-contracting-states><ep-extended-states><ep-extended-state-data><country>BA</country></ep-extended-state-data><ep-extended-state-data><country>ME</country></ep-extended-state-data></ep-extended-states></designated-states></international-convention-data><office-specific-data><eptags><ep-no-a-document-published>*</ep-no-a-document-published></eptags></office-specific-data></bibliographic-data><abstract mxw-id="PA139072623" ref-ucid="WO-2014130237-A1" lang="EN" load-source="patent-office"><p num="0000">Disclosed is a computing device that can perform automatic image rectification for a visual search. A method implemented at a computing device includes receiving one or more images from an image capture device, storing the one or more images with the computing device, building a three dimensional (3D) geometric model for one or more potential objects of interest within an environment based on at least one image of the one or more images, and automatically creating at least one rectified image having at least one potential object of interest for a visual search.</p></abstract><abstract mxw-id="PA139540272" ref-ucid="WO-2014130237-A1" lang="EN" source="national office" load-source="docdb"><p>Disclosed is a computing device that can perform automatic image rectification for a visual search. A method implemented at a computing device includes receiving one or more images from an image capture device, storing the one or more images with the computing device, building a three dimensional (3D) geometric model for one or more potential objects of interest within an environment based on at least one image of the one or more images, and automatically creating at least one rectified image having at least one potential object of interest for a visual search.</p></abstract><abstract mxw-id="PA139072624" ref-ucid="WO-2014130237-A1" lang="FR" load-source="patent-office"><p num="0000">La présente invention concerne un dispositif informatique qui peut effectuer la rectification automatique d'image pour une recherche visuelle. Un procédé implémenté dans un dispositif informatique consiste à recevoir une ou plusieurs images à partir d'un dispositif de capture, à mémoriser ladite ou lesdites images à l'aide du dispositif informatique, à construire un modèle géométrique tridimensionnel (3D) pour un ou plusieurs objets potentiels d'intérêt dans un environnement en fonction d'au moins une image de ladite ou desdites images, et à créer automatiquement au moins une image rectifiée ayant au moins un objet potentiel d'intérêt pour une recherche visuelle.</p></abstract><abstract mxw-id="PA139540273" ref-ucid="WO-2014130237-A1" lang="FR" source="national office" load-source="docdb"><p>La présente invention concerne un dispositif informatique qui peut effectuer la rectification automatique d'image pour une recherche visuelle. Un procédé implémenté dans un dispositif informatique consiste à recevoir une ou plusieurs images à partir d'un dispositif de capture, à mémoriser ladite ou lesdites images à l'aide du dispositif informatique, à construire un modèle géométrique tridimensionnel (3D) pour un ou plusieurs objets potentiels d'intérêt dans un environnement en fonction d'au moins une image de ladite ou desdites images, et à créer automatiquement au moins une image rectifiée ayant au moins un objet potentiel d'intérêt pour une recherche visuelle.</p></abstract><description mxw-id="PDES78476648" ref-ucid="WO-2014130237-A1" lang="EN" load-source="patent-office"><!-- EPO <DP n="3"/>--><p id="p0001" num="0001"> AUTOMATIC IMAGE RECTIFICATION FOR VISUAL SEARCH </p><p id="p0002" num="0002">BACKGROUND </p><p id="p0003" num="0003"> [0001] The present invention relates generally to a computing device that is capable of automatic image rectification for a visual search. </p><p id="p0004" num="0004">RELEVANT BACKGROUND </p><p id="p0005" num="0005"> [0002] Users are accessing different services such as a visual search service from a wide range of different computing devices (e.g., both mobile devices and non-mobile devices). For example, these different computing devices include home computers, work computers, mobile phones, mobile device, tablets, etc. Visual search has become a popular service. Users upload images to a server, which matches the images against other images stored in its database and eventually returns information about the uploaded images. The algorithms that match the query images against the database images are typically designed such that they can handle a certain amount of warpmg (i.e., translation, scale, rotation, and perspective effects). Also, these methods can detect objects in pictures that contain additional, irrelevant details (i.e., clutter). However, even though the algorithms are able to cope with these difficulties, the algorithms require more time and processing resources for coping with these difficulties. The irrelevant clutter in the camera image not only makes it harder for the server to find the object of interest, it also increases the size of the image that is sent to the server. </p><p id="p0006" num="0006">SUMMARY </p><p id="p0007" num="0007"> 10003] Aspects of the invention may relate to a computing device that can perform automatic image rectification for a visual search. The computing device may include a storage medium that stores one or more images and a processing circuit that is configured to execute instructions to build a three dimensional (3D) geometric model for one or more potential objects of interest within an environment based on at feast one image of the one or more images. The processing circuit is also configured to execute 
<!-- EPO <DP n="4"/>-->
 instructions to automatically create at least one rectified image having at least one potential object of interest for the visual search. </p><p id="p0008" num="0008">[80Θ4] Aspects of the invention may also relate to a method that is implemented at a computing device. The method includes receiving one or more images from an image capture device, storing the one or more images with the computing device, building a three dimensional (3D) geometric model for one or more potential objects of interest within an environment based on at least one image of the one or more images, and automatically creating at least one rectified image having at least one potential object of interest for a visual search. </p><p id="p0009" num="0009">ΙΘ005] Aspects of the invention may also relate to a computer progra product that is executed at a computing device. The computer program product includes a computer- readable medium that includes code for storing one or more images with the computing device, building a three dimensional (3D) geometric model with the computing device for one or more potential objects of interest within an environment based on at least one image of the one or more images, and automatically creating at least one rectified image having at least one potential object of interest for a visual search. </p><p id="p0010" num="0010">[0006] Aspects of the invention may also relate to an apparatus that includes a means for storing one or more received images, a means for building a three dimensional (3D) geometric model for one or more potential objects of interest within an environment based on at least one image of the one or more stored images, and a means for automatically creating at least one rectified image having at least one potential object of interest for a visual search. </p><p id="p0011" num="0011">[0007] Aspects of the invention may also relate to a server for performing a visual search. The server may include a storage medium that stores images and a processing circuit that is configured to execute instructions to receive at least one rectified image having at feast one potential object of interest from a computing device for a visual search and to extract descriptors representing features of the at least one rectified image. The extracted descriptors of the at least one rectified image may be designed to be invariant to rotation, scale, and lighting without needing to be invariant to perspective or affine distortion. The processing circuit can be further configured to execute 
<!-- EPO <DP n="5"/>-->
 instructions to match the extracted descriptors of the at least one rectified image with descriptors of the images stored in the database. </p><p id="p0012" num="0012">[8888] Aspects of the invention may also relate to a method that is implemented at a server. The method includes storing a plurality of images with the server, receiving at feast one rectified image having at least one potential object of interest from a computing device for a visual search, and extracting descriptors representing features of the at least one rectified image. The extracted descriptors of the at least one rectified image may be designed to be invariant to rotation, scale, and lighting without needing to be invariant to perspective or affine distortion, </p><p id="p0013" num="0013">[0009] Aspects of the invention may also relate to a computer program product that is executed at a server. The computer program product includes a computer-readable medium that includes code for storing a plurality of images, receiving at least one rectified image having at least one potential object of interest from a computing device for a visual search, and extracting descriptors representing features of the at least one rectified image. The extracted descriptors of the at least one rectified image may be designed to be invariant to rotation, scale, and lighting without needing to be invariant to perspective or affine distortion. </p><p id="p0014" num="0014">BRIEF DESCRIPTION OF THE DRAWINGS </p><p id="p0015" num="0015"> [8(518] FIG. 1 is a block diagram of a system having a computing device for automatically creating at least one rectified image. </p><p id="p0016" num="0016">[8811] FIG. 2 is a flow diagram to illustrate a process for automatically rectifying images captured by a computing device. </p><p id="p0017" num="0017">[8012] FIG. 3 is an image of a billboard advertisement as captured by a computing device. </p><p id="p0018" num="0018">[8013] FIG. 4 is a frontal view of the image of the billboard advertisement after the image is rectified. </p><p id="p0019" num="0019">[8014] FIG. 5 illustrates a server for performing a visual search. 
<!-- EPO <DP n="6"/>-->
 [8(515] FIG, 6 is a flow diagram to illustrate a process implemented at a server for performing a visual search, </p><p id="p0020" num="0020">DETAILED DESCRIPTION </p><p id="p0021" num="0021"> [8016] The word ''exemplary" or "example" is used herein to mean "serving as an example, instance, or illustration." Any aspect or embodiment described herein as "exemplary" or as an "example" in not necessarily to be construed as preferred or advantageous over other aspects or embodiments, </p><p id="p0022" num="0022">[0017] FIG, 1 is block diagram of a system having a computing device for automatically creating at least one rectified image. In particular, system 100 illustrates a computing device 101 that can automatically create at least one rectified image so that a visual search service has a higher chance of correctly detecting one or more objects of interest for a user. Computing device 101 may include a processing circuit 1 10, a storage medium 1 12 to store instructions 120 and images 122, a power device 1 14, a display device 116, a user interface 1 18, a transceiver 119, and an image capture device 144 (e.g., camera, video camera, etc.) for capturing images (e.g., digital still image, sequence of images that form a video). In another embodiment, the image capture device is located externally from the computing device. The image capture device may be associated with the computing device and be communicatively coupled to the computing device. For example, a computing device (e.g., mobile device) might be in a user's pocket and wirelessly connected to the image capture device (e.g., camera) that is mounted on a pair of the user's glasses. An exemplary storage medium (e.g., a computer-readable medium) is coupled to the processing circuit such that the processor can read information from, and write information to, the storage medium. In the alternative, the storage medium may be integral to the processing circuit. It should be appreciated that the display device 116 may be a typical display device on a computing device 101 such as a mobile device, cell phone, personal digital assistant, mobile computer, tablet, etc. User interface 1 18 may be a keyboard, touch-screen, or another type of user interface input de vice. Further, power device 114 may be a battery device 
<!-- EPO <DP n="7"/>-->
 to power computing device 101. Transceiver 119 may be used to transmit and receive calls and data through wireless link 130 to/from a wireless network 131. </p><p id="p0023" num="0023">[8018] In particular, computing device 101 may include a processing circuit 1 10 that is configured to execute instructions 120 to build a three dimensional (3D) geometric model for one or more potential objects of interest within an environment based on at least one image of one or more captured images and to automatically create at least one rectified image having at least one poieniial object of interest for a visual search. The processing circuit 1 10 can be further configured to execute instructions to automatically upload the at least one rectified image to a server for the visual search. For example, a user of the computing device may not provide a user input for uploading the reciiiied image to the server. Alternatively, the user may be aware that the rectified image is being uploaded to the server and the user may manually select an option for uploading the rectified image to the server for the visual search. </p><p id="p0024" num="0024">[0019] In one embodiment, the image capture device captures images during a background operation and at least one rectified image of a potential object of interest located in the captured images is automatically created for the visual search without receiving a user input. The image capture device may capture the images during the background operation without receiving input from the user for capturing the images. </p><p id="p0025" num="0025">[0028] In some aspects, the image capture device captures the images during a time period with the computing device moving for at least a portion of the time period. In other aspects, the image capture device is capable of providing depth information for the ai least one potential object of mteresi and captures the images while the computing device is not required to move because of the depth information. Alternatively, for an image capture device that is located externally from the computing device, the image capture device captures the images during a time period with the image capture device moving for ai least a portion of the time period. In other alternative aspects, the image capture device provides depth information for the at least one potential object of interest and captures the images while the image capture device is not required to move because of the depth information. 
<!-- EPO <DP n="8"/>-->
 [0021] It should be appreciated that aspects of the invention as will be hereinafter described may be implemented in conjunction with the execution of instructions by processing circuit 1 10 of computing device 101 and/or other circuitr '- of the computing device 101 and/or other devices. Particularly, circuitry of the computing device 101, including but not limited to processing circuit 1 10, may operaie under ihe control of a program, routine, or the execution of instructions to execute methods or processes in accordance with embodiments of the invention. For example, such a program may be implemented in firmware or software (e.g., stored in siorage medium 1 12 and/or other locations) and may be implemented by processors, such as processing circuit 1 10, and/or other circuitry of computing device 101 . Further, it should be appreciated that the terms processing circuit, processor, microprocessor, circuitry, controller, etc., refer to any type of logic or circuitry capable of executing logic, commands, instructions, software, firmware, functionality, etc. </p><p id="p0026" num="0026">[8(522] Further, computing device 101 may communicate via one or more wireless communication links 130 through a wireless network 131 that are based on or otherwise support any suitable wireless communication technology. For example, in some aspects computing device 101 may associate with a network including a wireless network 131. In some aspects the network may comprise a body area network or a personal area network (e.g., an ultra-wideband network). In some aspects the network may comprise a local area network or a wide area network. A wireless device may support or otherwise use one or more of a variety of wireless communication technologies, protocols, or standards such as, for example, CDMA, TDM A, OFDM, OFDM A, WiMAX, and Wi-Fi. Similarly, a wireless device may support or otherwise use one or more of a variety of corresponding modulation or multiplexing schemes. A wireless device may thus include appropriate components (e.g., air interfaces) to establish and communicate via one or more wireless communication links using the above or other wireless communication technologies. For example, a device may include a wireless transceiver with associated transmitter and receiver components (e.g., a transmitter and a receiver) that may include various components (e.g., signal generators and signal processors) that facilitate communication over a wireless medium. As is well known, a 
<!-- EPO <DP n="9"/>-->
 computing device 101 may therefore wirelessly communicate with other mobile devices, cell phones, other wired and wireless computers, Internet web-sites, etc. </p><p id="p0027" num="0027">[8023] With additional reference to FIG. 2, a flow diagram is shown to illustrate a process 200 for automatically creating rectified images. In one embodiment, this process improves visual search matching results by automatically creating rectified images into frontal views so that the visual search service has a higher chance of correctly detecting the object of interest. Additionally, this process can automatically combine parts of an object from multiple pictures into a single image. The basis for these improvements is a system that gathers 3D geometric knowledge about the scene in addition to merely using photometric measurements for a picture. This system builds a 3D geometric model of the environment (e.g., a dense 3D point cloud map of an environment). </p><p id="p0028" num="0028">[8(524] At block 202, an image capture device that is associated with a computing device captures one or more images. The image capture device may be integrated with the computing device or located externally from the computing device. At block 204, the computing device stores the one or more captured images (e.g., stores the images in a storage medium). At block 206, the process builds a 3D geometric model for one or more potential objects of interest within an environment based on at least one of the one or more the captured images. For a monocular camera, a structure-from-motion system provides such geometric information of the 3D geometric model. In some instances, the computing device captures the images during a time period with the computing device moving for at least a portion of the time period. For example, a user may pan the computing device within the environment to capture images of the environment. Other sensors, which may be found on a depth camera (e.g., RGB-D camera), can be used to directly provide depth without requiring motion. In these instances, the computing device provides depth information for the at least one potential object of interest and captures the images while the computing device is not required to move. A depth camera provides depth information for captured pixels. The depth camera may sense reflected light from the surface of each object. For practical purposes, a real-time system reconstructing the scene's geometry in real-time (e.g., instantaneously, nearly instantaneously) is needed. Recently Simultaneous Localization and Mapping (SLAM) systems have become efficient and robust enough for practical use on computing 
<!-- EPO <DP n="10"/>-->
 devices including mobile phones. With a SLAM system, the user points the camera at an object of interest and starts moving. While the user with the camera is moving, the SLAM system tracks details in the camera images and builds a geometric model of the environment. In the case of a device equipped with an RGB-D camera, a single image is enough to build an initial geometric model, which can be extended by motion. The object of interest does not have to be fully visible nor does the user have to be directly in front of it. It is sufficient that most parts of the object are visible at some point in the camera image. The SLAM system also takes pictures (e.g., keyframes), which it needs for its internal purposes, while the SLA M system is building the geometric model of the environment. The keyframes may be taken periodically (e.g., every 2-5 seconds) to determine a camera position in the environment. </p><p id="p0029" num="0029">10025] In one embodiment, the computing device captures the one or more images and automatically creates at least one rectified image of a potential object of interest that is located in the one or more captured images for the visual search without receiving a user input. For example, the user aims the camera towards an object of interest and the camera captures images of the object of interest as well as other potential objects of interest. The computing device then automatically rectifies the object of interest as well as other potential objects of interest and the rectified images can be used for a visual search. The user interface of the computing device may not indicate that automatically rectified images will be used for a visual search. </p><p id="p0030" num="0030">[Θ026] In some instances, the computing device captures the images during a background operation without receiving a user input for capturing the images. During the background operation, the user interface of the computing device may not indicate that images are being captured or that rectified images will be used for a visual search. At block 208, once the reconstruction of the environment is at least partially finished based on the 3D geometric model, which may occur in a short time period (e.g., up to a few seconds), the process searches the 3D geometric model for at least one planar structure (e.g., dominant planar structure) associated with one or more potential objects of interest within the environment. These potential objects of interest may include an object that was captured based on the user aiming the camera toward the object and also other objects located within the environment. In this manner, the process searches a 
<!-- EPO <DP n="11"/>-->
 broader number of potential objects of interest for planar structures than may have been intended or completely seen by the user, A partially finished reconstruction can be sufficient for searching and then a later search can search other parts of the environment that have been finished later. The computing device may have a confidence metric for each planar structure. At block 210, the process creates (e.g., automatically creates) at least one rectified image having at least one potential object of interest in a frontal or orthogonal view for a visual search. Creating the rectified output image may include unwarping the input image(s) of the planar structure from the pictures taken before by the SLAM system in order to create a rectified view of the planar structure. The user may have intended to capture some of the rectified output images while other rectified output images may not have been intended to be captured. The user may not know that any or some of the rectified output images will be used for a visual search or the computing device may not receive a user input for the visual search. </p><p id="p0031" num="0031">[8(527] After the rectified image has been created, the system can either present it to the user for confirmation or automatically upload it to a visual search server immediately at block 212. With the bandwidth typically available to mobile phones today, uploading an image and receiving the search result usually takes only a few seconds. Hence, the automatic method will usually be preferable. Using a rectified image can potentially speed up the descriptor extraction and matching required on the server side as discussed in conjunction with FIG. 5 and FIG. 6. </p><p id="p0032" num="0032">[0028] FIG. 3 and FIG. 4 illustrate rectifying an input image 300 to create an output image 400. FIG. 3 is an image 300 of a billboard advertisement 302 as captured by a computing device. The computing device is not orthogonal or normal with respect to the billboard advertisement 302. during the capture of the image 300, Rather, the computing device is tilted upwards at an angle in order to capture the image 300. FIG. 4 is a frontal view of the image 400 of the billboard advertisement 402 after the computing device has rectified the image 300. For this task, it is irrelevant whether a plane of the billboard advertisement is fully visible in a single image or if it spans multiple images. The computing device can send the image 400 to a server for a visual search. 
<!-- EPO <DP n="12"/>-->
 [0029] In an embodiment, a user builds a 3D geometric model of an entire room. For example, the room may include many small planar objects (e.g., pictures, posters, product boxes, magazines, etc.). The computing device that builds the 3D geometric model also locates planar structures of the small planar objects, rectifies these planar structures, and sends them to a server for a visual search without the user having to identify and select the objects. </p><p id="p0033" num="0033">[0038] In another embodiment, a user is not able to take a single picture that covers a large enough portion of the object of interest. This occurs when the camera does not have a wide field of view (as is the case with mobile phone cameras) and there is not enough space to move far enough away from the object so that it is fully visible in the camera image. For example, the computing device can reconstruct an environment that includes a narrow corridor with a large painting such that the camera of the computing device (e.g., mobile phone) cannot capture the whole painting in a single camera shot (without having too steep of an angle). The computing device detects the large plane covering the whole painting, rectifies the painting from many captured input images into one rectified output image, and sends it to the server for the visual search. </p><p id="p0034" num="0034">[©031] In one embodiment, automatically creating at least one rectified image having at least one potential object of interest for the visual search includes unwarping one planar stmcture into a frontal view for each output image. In another embodiment, automatically creating at least one rectified image having at least one potential object of interest includes rectifying portions of the at least one potential object of interest from multiple input images to create the at least one output image. </p><p id="p0035" num="0035">[0032] FIG. 5 illustrates a server 500 for performing a visual search. The server 500 includes storage medium 510 having a database 5.12 to store images and a processing circuit 520 that is configured to execute instructions 522 to receive at least one rectified image via a network interface 540. The network interface may be coupled with a wired or wireless link to a local or wide area, network. The at least one rectified image includes at least one potential object of interest as captured by a computing device for a visual search. The processing circuit 520 is configured to execute instructions to extract descriptors representing features (e.g., high contrast regions) of the at least one rectified 
<!-- EPO <DP n="13"/>-->
 image, A sequence of numbers (e.g., 128 numbers) may represent a feature. The extracted descriptors of the at least one rectified image are designed to be invariant to rotation, scale, and lighting without needing to be invariant to perspective or affme distortion. The processing circuit 520 is further configured to execute instructions 522 to match the extracted descriptors of the at least one rectified image with descriptors of any of the images stored in the database. The processing circuit 520 is further configured to execute instructions 522 to transmit information associated with at least one image stored in the database that has descriptors matching the extracted descriptors. In one embodiment, the extracted descriptors of the at least one rectified image are not invariant to perspective or affme distortion. An exemplar '- storage medium (e.g., a computer-readable medium having software code or instructions) is coupled to the processing circuit such that the processing circuit can read information from, and write information to, the storage medium. In the alternative, the storage medium may be integral to the processing circuit. </p><p id="p0036" num="0036">[0033] With additional reference to FIG. 6, a flow diagram is shown to illustrate a process 600 implemented at a server for visual searching. The process 600 includes storing a plurality of images in a storage medium of the server at block 602. The storage medium may include a database for storing the images. The process 600 includes receiving at least one rectified image having at least one potential object of interest from a computing device for a visual search at block 604. The process extracts descriptors representing features of the at least one rectified image at block 606. The extracted descriptors of the at least one rectified image are designed to be invariant to rotation, scale, and lighting without needing to be invariant to perspective or affme distortion. The process matches the extracted descriptors of the at least one rectified image with descriptors of images stored in the database at block 608. The process transmits information associated with at least one image stored in the database that has descriptors that match or substantially match the extracted descriptors at block 610. </p><p id="p0037" num="0037">[0034] Descriptors, which represent features on an image, are usually designed to be invariant to rotation, scale, lighting and a certain degree of perspective distortion. This invariance is at the cost of losing discriminative power, as by definition, changes in these variables should have little impact on the computed descriptor. Using a rectified 
<!-- EPO <DP n="14"/>-->
 image potentially allows the use of less invariant but more discriminative descriptors, which could also be faster and cheaper to extract and to match. Descriptors would still need to be rotation, scale and lighting invariant, but the most difficult mvariance to deal with - perspective distortion - would no longer be a requirement. A more discriminative descriptor would allow a larger number of objects to be detected, by allowing the disambiguation of descriptors which might otherwise be similar using, for example, a scale-invariant feature transform (SIFT). In one embodiment, the extracted descriptors of the at least one rectified image are not invariant to perspective distortion or affine distortion. </p><p id="p0038" num="0038">[8035] It should be appreciated that when the computing device or server is a mobile or wireless device that it may communicate via one or more wireless communication links through a wireless network that are based on or otherwise support any suitable wireless communication technology. For example, in some aspects computing device or server may associate with a network including a wireless network. In some aspects the network may comprise a body area network or a personal area network (e.g., an ultra-wideband network). In some aspects the network may comprise a local area network or a wide area network. A wireless device may support or otherwise use one or more of a variety of wireless communication technologies, protocols, or standards such as, for example, CDMA, TDMA, OFDM, OFDMA, WiMAX, and Wi-Fi. Similarly, a wireless device may support or otherwise use one or more of a variety of corresponding modulation or multiplexing schemes. A wireless device may thus include appropriate components (e.g., air interfaces) to establish and communicate via one or more wireless communication links using the above or other wireless communication technologies. For example, a device may comprise a wireless transceiver with associated transmitter and receiver components (e.g., a transmitter and a receiver) that may include various components (e.g., signal generators and signal processors) that facilitate communication over a wireless medium. As is well known, a mobile wireless device may therefore wirelessiy communicate with other mobile devices, cell phones, other wired and wireless computers, Internet web-sites, etc. </p><p id="p0039" num="0039">[8036] The techniques described herein can be used for various wireless communication systems such as Code Division Multiple Access (CDMA), Time 
<!-- EPO <DP n="15"/>-->
 division multiple access (TDMA), Frequency Division Multiple Access (FDMA), Orthogonal Frequency-Division Multiple Access (OFDMA), Single Carrier FDMA (SC-FDMA) and other systems. The terms "system" and "network" are often used interchangeably. A CDMA system can implement a radio technology such as Universal Terresiriai Radio Access (UTRA), CDMA2G00, etc. UTRA includes Wideband-CDMA (W-CDMA) and other variants of CDMA. CDMA2.000 covers Interim Standard (IS)- 2000, IS-95 and IS-856 standards. A TDMA system can implement a radio technology such as Global System for Mobile Communications (GSM). An OFDMA system can implement a radio technology such as Evolved Universal Terrestrial Radio Access; (Evolved UTRA or E-UTRA), Ultra Mobile Broadband (UMB), institute of Electrical and Electronics Engineers (IEEE) 802.1 1 (Wi-Fi), IEEE 802.16 (WiMAX), IEEE 802.20, Flash-OFDM.RTM., etc. Universal Terrestrial Radio Access (UTRA) and E- UTRA are part of Universal Mobile Telecommunication System (UMTS). 3GPP Long Term Evolution (LTE) is an upcoming release of UMTS that uses E-UTRA, which employs OFDMA on the downlink and SC-FDMA on the uplink. UTRA, E-UTRA, UMTS, LTE and GSM are described in documents from an organization named "3rd Generation Partnership Project" (3 GPP). CDMA2000 and UMB are described in documents from an organization named "3rd Generation Partnership Project 2" (3GPP2). </p><p id="p0040" num="0040">[8037] The teachings herein may be incorporated into (e.g., implemented within or performed by) a variety of apparatuses (e.g., devices). For example, one or more aspects taught herein may be incorporated into a phone (e.g., a cellular phone), a personal data assistant ("PDA"), a tablet, a mobile computer, a laptop computer, a tablet, an entertainment device (e.g., a music or video device), a headset (e.g., headphones, an earpiece, etc.), a medical device (e.g., a biometric sensor, a heart rate monitor, a pedometer, an EKO device, etc.), a user I/O device, a computer, a server, a point-of-sale device, an entertainment device, a set-top box, or any other suitable device. These devices may have different power and data requirements </p><p id="p0041" num="0041">[8038] In some aspects a wireless device may comprise an access device (e.g., a Wi- Fi access point) for a communication system. Such an access device may provide, for example, connectivity to another network (e.g., a wide area network such as the Internet 
<!-- EPO <DP n="16"/>-->
 or a cellular network) via a wired or wireless communication link. Accordingly, the access device may enable another device (e.g., a Wi-Fi station) to access the other network or some other functionality, in addition, it should be appreciated that one or both of the devices may be portable or, in some cases, relatively non-portable. </p><p id="p0042" num="0042">[8039] Those of skill in the art would understand that information and signals may be represented using any of a variety of different technologies and techniques. For example, data, instmctions, commands, information, signals, bits, symbols, and chips that may be referenced throughout the above description may be represented by voltages, currents, electromagnetic waves, magnetic fields or particles, optical fields or particles, or any combination thereof. </p><p id="p0043" num="0043">[8048] Those of skill would further appreciate that the various illustrative logical blocks, modules, circuits, and algorithm steps described in connection with the embodiments disclosed herein may be implemented as electronic hardware, computer software, or combinations of both. To clearly illustrate this interchangeability of hardware and software, various illustrative components, blocks, modules, circuits, and steps have been described above generally in terms of their functionality. Whether such functionality is implemented as hardware or software depends upon the particular application and design constraints imposed on the overall system. Skilled artisans may implement the described functionality in varying ways for each particular application, but such implementation decisions should not be interpreted as causing a departure from the scope of the present invention. </p><p id="p0044" num="0044">[8041] The various illustrative logical blocks, modules, and circuits described in connection with the embodiments disclosed herein may be implemented or performed with a general purpose processor, a digital signal processor (DSP), an application specific integrated circuit (ASIC), a field programmable gate array (FPGA) or other programmable logic device, discrete gate or transistor logic, discrete hardware components, or any combination thereof designed to perform the functions described herein. A general purpose processor may be a microprocessor, but in the alternative, the processor may be any conventional processor, controller, microcontroller, or state machine, A processor may also be implemented as a combination of computing 
<!-- EPO <DP n="17"/>-->
 devices, e.g., a combination of a DSP and a microprocessor, a plurality of microprocessors, one or more microprocessors in conjunction with a DSP core, or any other such configuration, </p><p id="p0045" num="0045">[8042] The steps of a method or algorithm described in connection with the embodiments disclosed herein may be embodied directly in hardware, in a software module executed by a processor, or in a combination of the two. A software module may reside in RAM memory, flash memory, ROM memory, EPROM memory, EEPROM memory, registers, hard disk, a removable disk, a CD-ROM, or any other form of storage medium known in the art. An exemplary storage medium is coupled to the processor such the processor can read information from, and write information to, the storage medium. In the alternative, the storage medium may be integral to the processor. The processor and the storage medium may reside in an ASIC. The ASIC may reside in a user terminal, ΐη the alternative, the processor and the storage medium may reside as discrete components in a user terminal. </p><p id="p0046" num="0046">[0043] in one or more exemplary embodiments, the functions described may be implemented in hardware, software, firmware, or any combination thereof. If implemented in software as a computer program product, the functions may be stored on or transmitted over as one or more instructions or code on a computer-readable medium. Computer-readable media includes both computer storage media and communication media including any medium that facilitates transfer of a computer program from one place to another. A storage media may be any available media that can be accessed by a computer. By way of example, and not limitation, such computer- readable media can comprise RAM, ROM, EEPROM, CD-ROM or other optical disk storage, magnetic disk storage or other magnetic storage devices, or any other medium that can be used to carry or store desired program code in the form of instructions or data structures and that can be accessed by a computer. Also, any connection is properly termed a computer-readable medium. For example, if the software is transmitted from a web site, server, or other remote source using a coaxial cable, fiber optic cable, twisted pair, digital subscriber line (DSL), or wireless technologies such as infrared, radio, and microwave, then the coaxial cable, fiber optic cable, twisted pair, DSL, or wireless technologies such as infrared, radio, and microwave are included in 
<!-- EPO <DP n="18"/>-->
 the definition of medium. Disk and disc, as used herein, includes compact disc (CD), laser disc, optical disc, digital versatile disc (DVD), floppy disk and blu-ray disc where disks usually reproduce data magnetically, while discs reproduce data optically with lasers. Combinations of the above should also be included within the scope of computer-readable media. </p><p id="p0047" num="0047">[8(544] The previous description of the disclosed embodiments is provided to enable any person skilled in the art to make or use ihe present invention. Various modifications to these embodiments will be readily apparent to those skilled in the art, and the generic principles defined herein may be applied to other embodiments without departing from the spirit or scope of the invention. Thus, the present invention is not intended to be limited io the embodiments shown herein but is to be accorded the widest scope consistent with the principles and novel features disclosed herein. 
</p></description><claims mxw-id="PCLM70076892" ref-ucid="WO-2014130237-A1" lang="EN" load-source="patent-office"><claim id="clm-0001" num="0001"><!-- EPO <DP n="19"/>--><claim-text/><claim-text>WHAT IS CLAIMED IS: </claim-text><claim-text> 1. A method implemented at a computing device, comprising: </claim-text><claim-text> receiving one or more images from an image capture device; </claim-text><claim-text> storing the one or more images with the computing device; </claim-text><claim-text> building a three dimensional (3D) geometric model for one or more potential objects of interest within an environment based on at least one image of the one or more images; and </claim-text><claim-text> automatically creating at least one rectified image having at least one potential object of interest for a visual search. </claim-text><claim-text>2. The method of claim 1 , further comprising: </claim-text><claim-text> automatically uploading the at least one rectified image to a server for the visual search. </claim-text><claim-text>3. The method of claim 1, further comprising: </claim-text><claim-text> uploading the at least one rectified image to a server for the visual search, </claim-text><claim-text>4. The method of claim 1, wherein the one or more images are captured with an image capture device that is associated with the computing device , wherein automatically creating at least one rectified image having at least one potential object of interest for the visual search occurs without receiving a user input. </claim-text><claim-text>5. The method of claim 1, wherein the one or more images are </claim-text><claim-text>automatically captured with an image capture device that is associated with the computing device during a background operation without receiving a user input. </claim-text><claim-text>6. The method of claim 1 , wherein the one or more images are captured with an image capture device that is associated with the computing device during a time period with the image capture device moving for at least a portion of the time period. 
<!-- EPO <DP n="20"/>-->
</claim-text><claim-text>7. The method of claim 1, wherein ihe one or more images are captured with an image capture device that is associated with the computing device, wherein the image capture device is capable of providing depth information for the at least one potential object of interest and to capture the one or more images while the image capture device is not required to move. </claim-text><claim-text>8. The method of claim 1, further comprising: </claim-text><claim-text> searching the 3D geometric model for ai least one planar structure associated with the one or more potential objects of interest within the environment, </claim-text><claim-text>9. The method of claim 1 , wherein the 3D geometric model is built using a structure --from-motion system, </claim-text><claim-text>10. The method of claim 1, further comprising: </claim-text><claim-text> searching the 3D geometric model for at least two planar structures associated with the one or more potential objects of interest within the environment </claim-text><claim-text>1 1. The method of claim 1 , wherein automatically creating at least one rectified image having at least one potential object of interest for the visual search comprises unwarping one planar structure into a frontal view for each rectified image, </claim-text><claim-text>12. The method of claim 1, wherein automatically creating at least one rectified image having at least one potential object of interest comprises rectifying portions of the at least one potential object of interest from multiple input images to create the at least one rectified image. </claim-text><claim-text>13. A. computing device comprising: </claim-text><claim-text> a storage medium to store one or more received images; and </claim-text><claim-text> a processing circuit coupled to the storage medium, the processing circuit is configured to execute instructions to build a three dimensional (3D) geometric model for one or more potential objects of interest within an environment based on at least one 
<!-- EPO <DP n="21"/>-->
 image of the one or more stored images and to automatically create at least one rectified image having at least one potential object of interest for a visual search. </claim-text><claim-text>14. The computing device of claim 13, wherein the processing circuit is further configured to execute instructions to automatically upload the at least one rectified image to a server for the visual search. </claim-text><claim-text>15. The computing de vice of claim 13, wherein the processing circuit is further configured to execute instructions to upload the at least one rectified image to a server for the visual search. </claim-text><claim-text>16. The computing device of claim 13, further comprising: </claim-text><claim-text> an image capture device coupled to the storage medium, the image capture device to capture the one or more images, wherein the storage medium to receive the one or more images from the image capture device. </claim-text><claim-text>17. The computing device of claim 16, wherein the processing circuit is configured to execute instructions to automatically create at least one rectified image ha ving at least one potential object of interest for the visual search without receiving a user input. </claim-text><claim-text>18. The computing device of claim 6, wherein the images are automatically captured with the image capture device during a background operation without receiving a user input. </claim-text><claim-text>19. The computing device of claim 16, wherein the one or more images are captured with the image capture device during a time period in which the image capture device is moving for at least a portion of the time period. </claim-text><claim-text>2.0. The computing de vice of claim 16, wherein the image capture de vice is capable of providing depth information for the at least one potential object of interest 
<!-- EPO <DP n="22"/>-->
 and to capture the one or more images while the image capture device is not required to move. </claim-text><claim-text>21. The computing device of claim 13, wherein the processing circuit is further configured to execute instructions to search the 3D geometric model for at least one planar structure associated with the one or more potential objects of interest within the environment. </claim-text><claim-text>22. The computing device of claim 13, wherein the 3D geometric model is built using a structure-from-motion system. </claim-text><claim-text>23. The computing device of claim 13, wherein the processing circuit is further configured to execute instructions to search the 3D geometric model for at least two planar structures associated with the one or more potential objects of interest within the environment. </claim-text><claim-text>24. The computing device of claim 13, wherein automatically creating at least one rectified image having at least one potential object of interest for the visual search comprises unwarping one planar structure into a frontal view for each rectified image. </claim-text><claim-text>25. The computing device of claim 13, wherein automatically creating at least one rectified image ha ving at least one potential object of interest comprises rectifying portions of the at least one potential object of interest from multiple input images to create the at least one rectified image. </claim-text><claim-text>26. A computer program product executed at a computing device comprising: </claim-text><claim-text> a computer-readable medium comprising code for: storing one or more images with the computing device; 
<!-- EPO <DP n="23"/>-->
 building a three dimensional (3D) geometric model with the computing device for one or more potential objects of interest within an environment based on at least one image of the one or more images; and </claim-text><claim-text> automatically creating at least one rectified image having at least one potential object of interest for a visual search. </claim-text><claim-text>27. The computer program product of claim 26, further comprising code for automatically uploading the at least one rectified image to a server for the visual search, </claim-text><claim-text>28. The computer program product of claim 26, further comprising code for uploading the at least one rectified image to a server for the visual search. </claim-text><claim-text>29. The computer program product of claim 26, wherein the one or more images are captured by an image capture device that is associated with the computing device, wherein automatically creating at least one rectified image having at least one potential object of interest for the visual search occurs withoui receiving a user input. </claim-text><claim-text>30. The computer program product of claim 26, wherein the one or more images are captured by an image capture device that is associated with the computing device during a background operation without receiving a user input. </claim-text><claim-text>3 . The computer program product of claim 26, wherein the one or more images are captured by an image capture device that is associated with the computing device during a time period with the image capture device moving for at least a portion of the time period, </claim-text><claim-text>32. The computer program product of claim 26, wherein the one or more images are captured by an image capture device that is associated with the computing device, wherein the image capture device is capable of providing depth information for the at least one potential object of interest and to capture the one or more images while the image capture device is not required to move. 
<!-- EPO <DP n="24"/>-->
</claim-text><claim-text>33. The computer program product of claim 26, further comprising code for searching the 3D geometric model for at least one planar structure associated with the one or more potential objects of interest within the environment. </claim-text><claim-text>34. The computer program product of claim 26, wherein the 3D geometric model is built using a structure-from-motion system. </claim-text><claim-text>35. The computer program product of claim 26, further comprising code for searching the 3D geometric model for at least two planar structures associated with the one or more potential objects of interest within the environment. </claim-text><claim-text>36. The computer program product of claim 26, wherein automatically creating at least one rectified image having at least one potential object of interest for the visual search comprises unwarping one planar structure into a frontal view for each rectified image. </claim-text><claim-text>37. The computer program product of claim 26, wherein automatically creating at least one rectified image having at least one potential object of interest comprises rectifying portions of the at least one potential object of interest from multiple input images to create the at least one rectified image, </claim-text><claim-text>38. A server comprising: </claim-text><claim-text> a storage medium to store a plurality of images; and </claim-text><claim-text> a processing circuit configured to execute instructions to receive at feast one rectified image having at least one potential object of interest from a computing device for a visual search and to extract descriptors representing features of the at least one rectified image, wherein the extracted descriptors of the at least one rectified image are designed to be invariant to rotation, scale, and lighting without needing to be invariant to perspective or affine distortion. 
<!-- EPO <DP n="25"/>-->
</claim-text><claim-text>39. The server of claim 38, wherein the processing circuit is further configured to execute instructions to match the extracted descriptors of the at least one rectified image with descriptors of the plurality of images stored in the database. </claim-text><claim-text>40. The server of claim 39, wherein the processing circuit is further configured to execute instructions to transmit information associated with at least one image stored in the storage medium that has matching descriptors. </claim-text><claim-text>41. The server of claim 38, wherein the extracted descriptors of the at least one rectified image are not invariant to perspective or affine distortion. </claim-text><claim-text>42. A method implemented at a server comprising: </claim-text><claim-text> storing a plurality of images with the server; </claim-text><claim-text> receiving at least one rectified image having at least one potential object of interest from a computing device for a visual search; and </claim-text><claim-text> extracting descriptors representing features of the at least one rectified image, wherein the extracted descriptors of the at least one rectified image are designed to be invariant to rotation, scale, and lighting without needing to be invariant to perspective or affine distortion. </claim-text><claim-text>43. The method of claim 42, further comprising: </claim-text><claim-text> matching the extracted descriptors of the at least one rectified image with descriptors of the plurality of images. </claim-text><claim-text>44. The method of claim 43, further comprising: </claim-text><claim-text> transmitting information associated with at least one image stored with the server that has matching descriptors. </claim-text><claim-text>45. The method of claim 42, wherein the extracted descriptors of the at least one rectified image are not invariant to perspective or affine distortion. 
<!-- EPO <DP n="26"/>-->
</claim-text><claim-text>46. A computer program product executed at a server comprising: </claim-text><claim-text> a computer-readable medium comprising code for: </claim-text><claim-text> storing a plurality of images; </claim-text><claim-text> receiving at least one rectified image having at least one potential object of interest from a computing device for a visual search; and </claim-text><claim-text> extracting descriptors representing features of the at least one rectified image, wherein the extracted descriptors of the at least one rectified image are designed to be invariant to rotation, scale, and lighting without needing to be invariant to perspective or affine distortion. </claim-text><claim-text>47. The computer program product of claim 46, further comprising code for matching the extracted descriptors of the at least one rectified image with descriptors of the plurality of images. </claim-text><claim-text>48. The computer program product of claim 47, further comprising code for transmiiting information associated wiih at least one image stored in a database that has matching descriptors, </claim-text><claim-text>49. The computer program product of claim 46, wherein the extracted descriptors of the at least one rectified image are not invariant to perspective or affine distortion. </claim-text><claim-text>50. An apparatus comprising: </claim-text><claim-text> means for storing one or more received images; </claim-text><claim-text> means for building a three dimensional (3D) geometric model for one or more potential objects of interest within an environment based on at least one image of the one or more stored images; and </claim-text><claim-text> means for automatically creating at least one rectified image having at least one potential object of interest for a visual search. </claim-text><claim-text>51. The apparatus of claim 50, further comprising: 
<!-- EPO <DP n="27"/>-->
 means for automatically uploading the at least one rectified image to a server for the visual search. </claim-text><claim-text>52. The apparatus of claim 50, further comprising: </claim-text><claim-text> means for uploading the at least one rectified image to a server for the visual search. </claim-text><claim-text>53. The apparatus of claim 50, further comprising: </claim-text><claim-text> means for capturing the one or more images, wherein the means for storing to receive the one or more images from the means for capturing. </claim-text><claim-text>54. The apparatus of claim 53, wherein the means for automatically creating at least one rectified image having at least one potential object of interest for the visual search occurs without receiving a user input. </claim-text><claim-text>55. The apparatus of claim 53, wherein the one or more images are captured automatically during a background operation without receiving a user input, </claim-text><claim-text>56. The apparatus of claim 53, wherein the one or more images are captured during a time period in which the means for capturing the one or more images is moving for at least a portion of the time period, </claim-text><claim-text>57. The apparatus of claim 53, wherein the means for capturing is capable of providing depth information for the at least one potential object of interest and to capture the one or more images while the means for capturing is not required to move. </claim-text><claim-text>58. The apparatus of claim 50, further comprising: </claim-text><claim-text> means for searching the 3D geometric model for at least one planar structure associated with the one or more potential objects of interest within the environment. </claim-text><claim-text>59. The apparatus of claim 50, further comprising: 
<!-- EPO <DP n="28"/>-->
 means for searching the 3D geometric model for ai least two planar structures associated with the one or more potential objects of interest within the environment, </claim-text><claim-text>60. The apparatus of claim 50, wherein the means for automatically creating at least one rectified image having at least one potential object of interest for the visual search comprises unwarping one planar structure into a frontal view for each rectified image. </claim-text><claim-text>61. The apparatus of claim 50, wherein the means for automatically creating at least one rectified image having at least one potential object of interest comprises rectifying portions of the at least one potential object of interest from multiple input images to create the at least one rectified image. </claim-text><claim-text>62. The apparatus of claim 50, wherein the three dimensional (3D) geometric model is built using a structure-from-motion system. 
</claim-text></claim></claims><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
