<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2959683-A1" country="EP" doc-number="2959683" kind="A1" date="20151230" family-id="48485143" file-reference-id="311904" date-produced="20180826" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="160452493" ucid="EP-2959683-A1"><document-id><country>EP</country><doc-number>2959683</doc-number><kind>A1</kind><date>20151230</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-13724778-A" is-representative="NO"><document-id mxw-id="PAPP193867954" load-source="docdb" format="epo"><country>EP</country><doc-number>13724778</doc-number><kind>A</kind><date>20130514</date><lang>EN</lang></document-id><document-id mxw-id="PAPP193867955" load-source="patent-office" format="original"><country>EP</country><doc-number>13724778.9</doc-number><date>20130514</date><lang>EN</lang></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC162035835" ucid="EP-2013059941-W" linkage-type="A" load-source="docdb"><document-id format="epo"><country>EP</country><doc-number>2013059941</doc-number><kind>W</kind><date>20130514</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL-1988519640" load-source="docdb">H04N  13/00        20060101AFI20141125BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-1641018283" load-source="docdb" scheme="CPC">H04N  13/122       20180501 FI20180512BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1642409237" load-source="docdb" scheme="CPC">H04N  13/204       20180501 LI20180510BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1642409239" load-source="docdb" scheme="CPC">H04N  13/111       20180501 LI20180510BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1642409240" load-source="docdb" scheme="CPC">H04N  13/296       20180501 LI20180510BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1642409241" load-source="docdb" scheme="CPC">H04N  13/189       20180501 LI20180510BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1962084890" load-source="docdb" scheme="CPC">H04N2213/005       20130101 LA20160305BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1962089002" load-source="docdb" scheme="CPC">H04N2013/0088      20130101 LA20160305BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT165548945" lang="DE" load-source="patent-office">VERFAHREN UND VORRICHTUNG ZUR BERECHNUNG EINES SYNTHETISIERTEN BILDES</invention-title><invention-title mxw-id="PT165548946" lang="EN" load-source="patent-office">METHOD AND APPARATUS FOR COMPUTING A SYNTHESIZED PICTURE</invention-title><invention-title mxw-id="PT165548947" lang="FR" load-source="patent-office">PROCÉDÉ ET APPAREIL DE CALCUL D'UNE IMAGE SYNTHÉTISÉE</invention-title><citations><non-patent-citations><nplcit><text>None</text><sources><source mxw-id="PNPL70737246" load-source="docdb" name="EXA"/></sources></nplcit><nplcit><text>See also references of WO 2014183787A1</text><sources><source mxw-id="PNPL70737247" load-source="docdb" name="EXA"/></sources></nplcit></non-patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR1103330085" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>HUAWEI TECH CO LTD</last-name><address><country>CN</country></address></addressbook></applicant><applicant mxw-id="PPAR1103344827" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>HUAWEI TECHNOLOGIES CO., LTD.</last-name></addressbook></applicant><applicant mxw-id="PPAR1101643906" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Huawei Technologies Co., Ltd.</last-name><iid>100970540</iid><address><street>Huawei Administration Building Bantian</street><city>LONGGANG DISTRICT SHENZHEN, GUANGDONG 518129</city><country>CN</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR1103325498" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>KONIECZNY JACEK</last-name><address><country>DE</country></address></addressbook></inventor><inventor mxw-id="PPAR1103320434" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>KONIECZNY, JACEK</last-name></addressbook></inventor><inventor mxw-id="PPAR1101641636" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>KONIECZNY, JACEK</last-name><address><street>Huawei Technologies Duesseldorf GmbH Riesstr. 25</street><city>80992 Munich</city><country>DE</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR1101651099" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Kreuz, Georg Maria</last-name><iid>101362137</iid><address><street>Huawei Technologies Duesseldorf GmbH Riesstrasse 8</street><city>80992 München</city><country>DE</country></address></addressbook></agent></agents></parties><international-convention-data><pct-or-regional-filing-data ucid="EP-2013059941-W"><document-id><country>EP</country><doc-number>2013059941</doc-number><kind>W</kind><date>20130514</date><lang>EN</lang></document-id></pct-or-regional-filing-data><pct-or-regional-publishing-data ucid="WO-2014183787-A1"><document-id><country>WO</country><doc-number>2014183787</doc-number><kind>A1</kind><date>20141120</date><lang>EN</lang></document-id></pct-or-regional-publishing-data><designated-states><ep-contracting-states><country mxw-id="DS660624299" load-source="docdb">AL</country><country mxw-id="DS660702776" load-source="docdb">AT</country><country mxw-id="DS660624301" load-source="docdb">BE</country><country mxw-id="DS660788547" load-source="docdb">BG</country><country mxw-id="DS660708878" load-source="docdb">CH</country><country mxw-id="DS660624917" load-source="docdb">CY</country><country mxw-id="DS660702777" load-source="docdb">CZ</country><country mxw-id="DS660623419" load-source="docdb">DE</country><country mxw-id="DS660624302" load-source="docdb">DK</country><country mxw-id="DS660624918" load-source="docdb">EE</country><country mxw-id="DS660702758" load-source="docdb">ES</country><country mxw-id="DS660788548" load-source="docdb">FI</country><country mxw-id="DS660788549" load-source="docdb">FR</country><country mxw-id="DS660623420" load-source="docdb">GB</country><country mxw-id="DS660624307" load-source="docdb">GR</country><country mxw-id="DS660624308" load-source="docdb">HR</country><country mxw-id="DS660624931" load-source="docdb">HU</country><country mxw-id="DS660708887" load-source="docdb">IE</country><country mxw-id="DS660624309" load-source="docdb">IS</country><country mxw-id="DS660788550" load-source="docdb">IT</country><country mxw-id="DS660624932" load-source="docdb">LI</country><country mxw-id="DS660623421" load-source="docdb">LT</country><country mxw-id="DS660702778" load-source="docdb">LU</country><country mxw-id="DS660623422" load-source="docdb">LV</country><country mxw-id="DS660623439" load-source="docdb">MC</country><country mxw-id="DS660723433" load-source="docdb">MK</country><country mxw-id="DS660723434" load-source="docdb">MT</country><country mxw-id="DS660702783" load-source="docdb">NL</country><country mxw-id="DS660702763" load-source="docdb">NO</country><country mxw-id="DS660702784" load-source="docdb">PL</country><country mxw-id="DS660702764" load-source="docdb">PT</country><country mxw-id="DS660702785" load-source="docdb">RO</country><country mxw-id="DS660702765" load-source="docdb">RS</country><country mxw-id="DS660702786" load-source="docdb">SE</country><country mxw-id="DS660623441" load-source="docdb">SI</country><country mxw-id="DS660708888" load-source="docdb">SK</country><country mxw-id="DS660708889" load-source="docdb">SM</country><country mxw-id="DS660723447" load-source="docdb">TR</country></ep-contracting-states><ep-extended-states><ep-extended-state-data><country>BA</country></ep-extended-state-data><ep-extended-state-data><country>ME</country></ep-extended-state-data></ep-extended-states></designated-states></international-convention-data><office-specific-data><eptags><ep-no-a-document-published>*</ep-no-a-document-published></eptags></office-specific-data></bibliographic-data><abstract mxw-id="PA143674164" ref-ucid="WO-2014183787-A1" lang="EN" load-source="patent-office"><p num="0000">The invention relates to a method (300) for computing a synthesized picture (s<sub>T</sub>') of a visual scene, based on a left depth map (s<sub>D,I</sub>) of a left reference view of the visual scene and right depth map (s<sub>D,r</sub>) of a right reference view of the visual scene, the method (300) comprising: projecting (301) the left depth map (S<sub>D,I</sub>) into a left projected depth map (S<sub>D,I</sub>')<sub/>and projecting the right depth map (s<sub>D,r</sub>) into a right projected depth map (s<sub>D,r</sub>'), and determining a left disoccluded area (s<sub>F,I</sub>') in the left projected depth map (s<sub>D,I</sub>') and a right disoccluded area (s<sub>F,r</sub>') in the right projected depth map (s<sub>D,r</sub>'); detecting object border misalignments between the left projected depth map (s<sub>D,I</sub>') and the right projected depth map (s<sub>D,r</sub>'); determining (303) a left reliability map information (S<sub>R,I</sub>') based on the left disoccluded area (s<sub>F,I</sub>'), and the detected object border misalignments, and determining a right reliability map information (s<sub>R,r</sub>') based on the right disoccluded area (s<sub>F,r</sub>'), and the detected object border misalignments; and computing (307) the synthesized picture (s<sub>T</sub>') by merging a left projected picture (s<sub>T,I</sub>') of the left reference view and a right projected picture (s<sub>Tr</sub>') of the right reference view using the left (S<sub>R,I</sub>') and right (s<sub>R,r</sub>') reliability map information.</p></abstract><abstract mxw-id="PA143969133" ref-ucid="WO-2014183787-A1" lang="EN" source="national office" load-source="docdb"><p>The invention relates to a method (300) for computing a synthesized picture (sT') of a visual scene, based on a left depth map (sD,I) of a left reference view of the visual scene and right depth map (sD,r) of a right reference view of the visual scene, the method (300) comprising: projecting (301) the left depth map (SD,I) into a left projected depth map (SD,I')and projecting the right depth map (sD,r) into a right projected depth map (sD,r'), and determining a left disoccluded area (sF,I') in the left projected depth map (sD,I') and a right disoccluded area (sF,r') in the right projected depth map (sD,r'); detecting object border misalignments between the left projected depth map (sD,I') and the right projected depth map (sD,r'); determining (303) a left reliability map information (SR,I') based on the left disoccluded area (sF,I'), and the detected object border misalignments, and determining a right reliability map information (sR,r') based on the right disoccluded area (sF,r'), and the detected object border misalignments; and computing (307) the synthesized picture (sT') by merging a left projected picture (sT,I') of the left reference view and a right projected picture (sTr') of the right reference view using the left (SR,I') and right (sR,r') reliability map information.</p></abstract><abstract mxw-id="PA143674165" ref-ucid="WO-2014183787-A1" lang="FR" load-source="patent-office"><p num="0000">La présente invention concerne un procédé (300) de calcul d'une image synthétisée (s<sub>T</sub>') d'une scène visuelle sur la base d'une carte de profondeur gauche (s<sub>D,l</sub>) d'une vue de référence gauche de la scène visuelle et d'une carte de référence droite (s<sub>D,r</sub>) d'une vue de référence droite de la scène visuelle, le procédé (300) consistant à : projeter (301) la carte de profondeur gauche (S<sub>D,l</sub>) sur une carte de profondeur projetée gauche (S<sub>D,l</sub>') &lt;sb /&gt; et projeter la carte de profondeur droite (s<sub>D,r</sub>) sur une carte de profondeur projetée droite (s<sub>D,r</sub>') , et déterminer une zone non occultée gauche (s<sub>F,l</sub>') dans la carte de profondeur projetée gauche (s<sub>D,l</sub>') et une zone non occultée droite (s<sub>F,r</sub>') dans la carte de profondeur projetée droite (s<sub>D,r</sub>') ; détecter des défauts d'alignement de bordures d'objets entre la carte de profondeur projetée gauche (s<sub>D,l</sub>') et la carte de profondeur projetée droite (s<sub>D,r</sub>') ; déterminer (303) une information de carte de fiabilité gauche (S<sub>R,l</sub>') sur la base de la zone non occultée gauche (s<sub>F,l</sub>'), et des défauts d'alignement de bordures d'objets détectés, et déterminer une information de carte de fiabilité droite (s<sub>R,r</sub>') sur la base de la zone non occultée droite (s<sub>F,r</sub>') et des défauts d'alignement de bordures d'objets détectés ; et calculer (307) l'image synthétisée (s<sub>T</sub>') en fusionnant une image projetée gauche (s<sub>T,l</sub>') de la vue de référence gauche et une image projetée droite (s<sub>Tr</sub>') de la vue de référence droite en utilisant les informations de carte de fiabilité gauche (S<sub>R,l</sub>') et droite (s<sub>R,r</sub>').</p></abstract><abstract mxw-id="PA143969134" ref-ucid="WO-2014183787-A1" lang="FR" source="national office" load-source="docdb"><p>La présente invention concerne un procédé (300) de calcul d'une image synthétisée (sT') d'une scène visuelle sur la base d'une carte de profondeur gauche (sD,l) d'une vue de référence gauche de la scène visuelle et d'une carte de référence droite (sD,r) d'une vue de référence droite de la scène visuelle, le procédé (300) consistant à : projeter (301) la carte de profondeur gauche (SD,l) sur une carte de profondeur projetée gauche (SD,l') &lt;sb /&gt; et projeter la carte de profondeur droite (sD,r) sur une carte de profondeur projetée droite (sD,r') , et déterminer une zone non occultée gauche (sF,l') dans la carte de profondeur projetée gauche (sD,l') et une zone non occultée droite (sF,r') dans la carte de profondeur projetée droite (sD,r') ; détecter des défauts d'alignement de bordures d'objets entre la carte de profondeur projetée gauche (sD,l') et la carte de profondeur projetée droite (sD,r') ; déterminer (303) une information de carte de fiabilité gauche (SR,l') sur la base de la zone non occultée gauche (sF,l'), et des défauts d'alignement de bordures d'objets détectés, et déterminer une information de carte de fiabilité droite (sR,r') sur la base de la zone non occultée droite (sF,r') et des défauts d'alignement de bordures d'objets détectés ; et calculer (307) l'image synthétisée (sT') en fusionnant une image projetée gauche (sT,l') de la vue de référence gauche et une image projetée droite (sTr') de la vue de référence droite en utilisant les informations de carte de fiabilité gauche (SR,l') et droite (sR,r').</p></abstract><description mxw-id="PDES83469764" ref-ucid="WO-2014183787-A1" lang="EN" load-source="patent-office"><!-- EPO <DP n="2"/>--><p id="p0001" num="0001"> Method and apparatus for computing a synthesized picture </p><p id="p0002" num="0002">TECHNICAL FIELD The present invention relates to a method and an apparatus for computing a synthesized picture of a visual scene, in particular in the field of computer vision, 3D video processing and 3D video synthesis. </p><p id="p0003" num="0003">BACKGROUND </p><p id="p0004" num="0004">3D video synthesis is utilized in applications that require rendering of a virtual view. This includes applications like Free-viewpoint Television (FTV) where the viewpoint can be selected according to the preferences of a viewer or e.g. 3D video coding of a multiview video where some of the views are synthesized from others, increasing the compression of such content by limiting the number of views to be transmitted. In 3D video, view synthesis is a process of creating a virtual view based on the available reference views (physical views, herein also referred as texture views) from which the visual scene was acquired. The most commonly used approach of view synthesis is so called Depth Image-Based Rendering (DIBR) method described by [L. McMillan, "An image-based approach to three- dimensional computer graphics", Doctoral thesis, University of North Carolina, Chapel Hill, USA, April 1997] that utilizes depth maps defining the distance of scene points from the viewpoint in order to project the corresponding texture information into virtual view position. </p><p id="p0005" num="0005">A depth map can be defined as information describing the distance of each part of the visual scene, e.g. represented in form of a grayscale image; alternatively a disparity map can be used, which values are inverse-proportional to the ones represented by the depth map. Among DIBR-based synthesis methods two main approaches can be distinguished: forward- and backward-projection algorithms. In forward-projection, coordinates of each sample in the picture from the reference view are projected onto a synthesized picture, resulting in non-integer sample coordinates. This means that actual values of samples in the synthesized picture must be somehow estimated from the closest samples projected from the reference view. On the other hand, in backward-projection approach, coordinates 
<!-- EPO <DP n="3"/>-->
 of each sample in the synthesized picture are projected into a reference picture. Consequently, the value of the sample is determined based on the samples in the picture from the reference picture that are close to the position of this projected sample. Both methods differ in aspects like disoccluded area detection and handling, possibility of simultaneous scanning of more than one reference view to produce the synthesized output picture or required picture interpolation methods. </p><p id="p0006" num="0006">In the following sections, it is assumed that reference views are aligned horizontally, i.e. left and right reference views can be distinguished that are displaced in the horizontal direction. The most efficient state-of-the-art virtual view synthesis algorithms based on the Depth Image-Based Rendering (DIBR) methods rely on forward-projection algorithms that combine pictures synthesized from a left and right reference pictures in order to produce the synthesized output picture. The current state-of-the-art solution - the HEVC Test Model adopted into JCT-3V (joint ITU-T/MPEG standardization effort for 3D) as described by [H. Schwarz, K. Wegner, "Test Model under Consideration for HEVC based 3D video coding", MPEG Doc. m12350, Nov. 201 1 ] uses a synthesis algorithm 100 as presented in Fig. 1. </p><p id="p0007" num="0007">In the algorithm 100 left and right view textures s<sub>T</sub>,i and s<sub>T</sub>,<sub>r</sub> and depths s<sub>D</sub>,i and s<sub>D</sub>,<sub>r</sub> are used to perform the forward-projection step 101 a, 101 b. In this step, samples from reference views are projected into a synthesized view using the DIBR algorithm. The outputs of this step are: s<sub>T</sub> , s<sub>T</sub>,<sub>r</sub>', s<sub>D</sub>, and s<sub>D</sub>, pictures and left and right texture and depths projected into the synthesized view. At the same time, the algorithm detects disoccluded areas in the output s<sub>T</sub> , s<sub>T</sub>,<sub>r</sub>', s<sub>D</sub>, and s<sub>D</sub>, pictures. These areas are represented in form of filling masks: s<sub>F</sub>/ and s<sub>F</sub> , identifying areas of synthesized pictures from each reference view that need to be filled. The further step is a reliability map creation 105a, 105b in which s<sub>F</sub>/ and s<sub>F</sub>/ filling masks are modified to produce s<sub>R</sub>/ and s<sub>R</sub>y reliability maps. Each reliability map specifies the contribution of every sample in the picture synthesized from the reference picture to the final value of the sample in the output picture based on an estimated probability that the value of the sample is correct. As a consequence, the values of the reliability maps can be manipulated to reduce synthesis artifacts, e.g. at the borders of the disoccluded area. In the prior art, reliability maps are adopted to reduce synthesis artifacts that result from inconsistency of texture and depth borders in a single reference view. The solution is applied to background areas neighboring the disoccluded area of the visual scene. The procedure was proposed in 
<!-- EPO <DP n="4"/>-->
 ["Description of 3D Video Technology Proposal by Fraunhofer HHI (HEVC compatible; configuration A)", MPEG m22570, Nov. 201 1 ] and can be described as follows. For each background pixel neighboring with the disoccluded area border within a pre-defined interval, called a transition region 201 , the reliability of the pixel 200 decreases according to a linear function 203 as can be seen in Fig. 2. As a result, the reliability of pixels positioned directly at the disoccluded area border is equal to 0 and increases linearly in a horizontal direction to a maximum reliability for pixels which distance from the border is equal to the width of the transition region ATR 201. Before the final step of combining 107 the synthesized pictures from left and right reference pictures, a plane discrimination map between left and right view s<sub>P r</sub>' is calculated 103, based on pre-defined criteria. For the purpose of the combination step 107, a sample from each of the reference views is compared with its corresponding sample from the other available reference view in order to determine if it belongs to the same plane of the visual scene or not. If a sample at the pixel position (x,y) synthesized from one reference view is much closer to the camera than the one in the same pixel position but synthesized from the other reference view, both samples are marked to belong to different planes of the visual scene. The decision if one sample is much closer to the camera than the other is made by comparing the difference between depth values assigned to both samples with a pre-defined threshold. The combination step 107 uses weighted averaging with reliability maps as weights for each combined sample to calculate the value of the synthesized output sample: </p><p id="p0008" num="0008"> v(x,y) = wi(x,y) v,(x,y) + w<sub>r</sub>(x,y) v<sub>r</sub>(x,y) </p><p id="p0009" num="0009">where: </p><p id="p0010" num="0010"> v(x,y) denotes the value of sample in the synthesized picture at position (x,y),</p><p id="p0011" num="0011">Vi(x,y) denotes the value of sample in picture synthesized from left reference picture at position (x,y), </p><p id="p0012" num="0012"> v<sub>r</sub>(x,y) denotes the value of sample in picture synthesised from right reference picture at position (x,y), </p><p id="p0013" num="0013"> w<sub>/</sub>(x,y) denotes the weight of v<sub>t</sub>(x,y) sample, </p><p id="p0014" num="0014"> w<sub>r</sub>(x,y) denotes the weight of v<sub>r</sub>(x,y) sample. </p><p id="p0015" num="0015">However, in case of two samples belonging to different planes of the visual scene, the value of the output sample is calculated based on the value of only one of the input 
<!-- EPO <DP n="5"/>-->
 samples, that is, the one that is closer to the camera. The decision is made based on the plane discrimination map Sp/ and the depth maps s<sub>D</sub>/ and s<sub>D,</sub> . </p><p id="p0016" num="0016">In Depth Image-Based Rendering (DIBR) methods used for virtual view synthesis inter- view inconsistency between depth maps of the different reference views may cause scene objects synthesis artifacts in form of an additional object border, if more than one reference view is used in the combination step to produce the synthesized output picture. An overcome to this problem is to use inter-view consistent depth maps. However, in existing multi-camera scenarios, the estimation or acquisition of inter-view consistent depth maps is very difficult or even practically unachievable with current technologies. The main problems are the large computational complexity, extreme difficulties to be achieved in a fully-automatic way due to errors in disparity estimation between two views. Semiautomatic or manual methods can solve the problem, but they are not always applicable. SUMMARY </p><p id="p0017" num="0017">It is the object of the invention to provide an improved technique for 3D view synthesis. </p><p id="p0018" num="0018">This object is achieved by the features of the independent claims. Further implementation forms are apparent from the dependent claims, the description and the figures. </p><p id="p0019" num="0019">The invention is based on the finding that an improved technique for 3D view synthesis that minimizes the synthesis artifacts for objects in the scene produced by weighted averaging of pictures synthesized from reference pictures can be provided by weighted averaging of pictures synthesized from reference pictures by reducing the weights for samples neighboring to the object borders in case the object borders in reference pictures are not aligned. Further improvement can be provided by appropriate specification of the conditions for applying the weights reduction and pattern to modify the weights. In order to describe the invention in detail, the following terms, abbreviations and notations will be used: </p><p id="p0020" num="0020">3D: </p><p id="p0021" num="0021"> three-dimensional, 
<!-- EPO <DP n="6"/>-->
 3D video: </p><p id="p0022" num="0022"> signal comprising two texture views and their corresponding depth or disparity maps, visual scene: </p><p id="p0023" num="0023"> real world or synthetic scene that is represented in the 3D video, </p><p id="p0024" num="0024">a gray scale picture in which value of every point of the picture determines distance to the camera of the visual scene represented by this poht. Alternatively, a disparity map may be used, which values are inversely proportional to the ones of the depth map and, thus, forms a depth map according to the present invention with inversed values, disoccluded area: </p><p id="p0025" num="0025"> area of the picture synthesized from a reference view that is not visible in this reference view, </p><p id="p0026" num="0026">area of the picture that refers to part of the visual scene with similar distance to the camera; a pixel is assigned to a particular visual plane based on the semantic analysis of the content represented in the visual scene or depth values assigned to each part of the picture, foreground object: </p><p id="p0027" num="0027"> an object in visual scene with smaller distance to the camera than the area of the scene that is neighboring the border of this object and does not belong to the same visual plane as this neighboring area, foreground and background areas neighboring the disoccluded area of the visual scene: </p><p id="p0028" num="0028"> in case of horizontal camera arrangement, picture areas neighboring left and right borders of the disoccluded area belong to visual planes with different distance to the camera. In that sense, background area is defined as the picture area that belongs to visual plane with larger distance to the 
<!-- EPO <DP n="7"/>-->
 camera, whereas foreground area is defined as the picture area that belongs to visual plane with smaller distance to the camera, virtual view (hereby also referred as synthesized view): </p><p id="p0029" num="0029"> a view of the visual scene generated in the freely selected position that is not restricted to the actual position of the cameras used to acquire the visual scene, synthesized picture: </p><p id="p0030" num="0030"> one frame of the virtual view, reference picture: </p><p id="p0031" num="0031"> one frame of the reference view. According to a first aspect, the invention relates to a method for computing a synthesized picture of a visual scene, based on a left depth map of a left reference view of the visual scene and a right depth map of a right reference view of the visual scene, the method comprising: projecting the left depth map into a left projected depth map and projecting the right depth map into a right projected depth map, and determining a left disoccluded area in the left projected depth map and a right disoccluded area in the right projected depth map; detecting object border misalignments between the left projected depth map and the right projected depth map; determining a left reliability map information based on the left disoccluded area, and the detected object border misalignments, and determining a right reliability map information based on the right disoccluded area, and the detected object border misalignments; and computing the synthesized picture by merging a left projected picture of the left reference view and a right projected picture of the right reference view using the left and right reliability map information. </p><p id="p0032" num="0032">By detecting object border misalignments between the left projected depth map and the right projected depth map and determining the left reliability map information based on the left disoccluded area and the detected object border misalignments, and determining the right reliability map information based on the right disoccluded area and the detected object border misalignments, the view synthesis errors resulting from inaccurate depth or disparity estimation between the two views can be reduced. 
<!-- EPO <DP n="8"/>-->
 In a first possible implementation form of the method according to the first aspect, the determining the left reliability map information and the right reliability map information comprises: determining the left reliability map information based on the left disoccluded area and the right reliability map information based on the right disoccluded area; and modifying the left reliability information and/or the right reliability map information when object border misalignments between the left projected depth map and the right projected depth map are detected. </p><p id="p0033" num="0033">By modifying the left reliability information and/or the right reliability map information in case of object border misalignment detection, quality of the synthesized picture can be improved. </p><p id="p0034" num="0034">In a second possible implementation form of the method according to the first </p><p id="p0035" num="0035">implementation form of the first aspect, the determining a plane discrimination map between the left projected depth map s<sub>D,r</sub>' and the right projected depth map based on the left projected depth map and the right projected depth map; determining a left plane discrimination map for the left projected depth map based on the left projected depth map; and determining a right plane discrimination map for the right projected depth map based on the right projected depth map; wherein the determining the left reliability map information is based on the left plane discrimination map and on the plane discrimination map, and the determining the right reliability map information is based on the right plane discrimination map and on the plane discrimination map. </p><p id="p0036" num="0036">By determining the left and the right reliability maps based on the plane discrimination maps, view synthesis errors resulting from inaccurate depth or disparity maps can be reduced. </p><p id="p0037" num="0037">In a third possible implementation form of the method according to the first aspect as such or according to any of the preceding implementation forms of the first aspect, the detecting object border misalignments comprises: detecting, whether samples in one of the left projected depth map and right projected depth map belong to an object border and at the same positions belong to a foreground plane in the other projected depth map. </p><p id="p0038" num="0038">By detecting the object border misalignment, visible and annoying view synthesis artifacts resulting from inaccurate and inter-view consistent depth or disparity maps can be significantly reduced. 
<!-- EPO <DP n="9"/>-->
 In a fourth possible implementation form of the method according to first aspect as such or any of the implementation forms of the first aspect, the object border misalignment is detected if samples in a first of the left projected depth map and right projected depth map belong to an object border and at the same positions belong to a foreground plane in the other second projected depth map of the left projected depth map and right projected depth map; wherein the determining the left reliability map information comprises assigning a reduced weight for samples in the left projected picture for the computing of the synthesized picture if the samples in the left projected depth map belong to an object border and at the same positions belong to a foreground plane in the right projected depth map; and/or wherein the determining the right reliability map information comprises assigning a reduced weight for samples in the right projected picture for the computing of the synthesized picture if the samples in the right projected depth map belong to an object border and at the same positions belong to a foreground plane in the left projected depth map. </p><p id="p0039" num="0039">By reducing the weights of the one of the left and right reliability maps corresponding to the one of the left and right projected pictures in which the influence is suppressed, synthesis artifacts can be reduced. In a fifth possible implementation form of the method according to the fourth </p><p id="p0040" num="0040">implementation form of the first aspect, the reduced weights are assigned according to a monotonically increasing or decreasing function over a transition region determined based on the positions of the samples belonging to the object border. Reducing the weights according to a monotonically increasing or decreasing function is easy to implement, e.g. by a lookup table. </p><p id="p0041" num="0041">In a sixth possible implementation form of the method according to the first aspect as such or according to any of the preceding implementation forms of the first aspect, the determining the left reliability map information comprises: assigning a reduced weight for samples in the left projected picture for the computing of the synthesized picture, if a first sample in the left projected depth map at a first position does not belong to the left disoccluded area, a second right neighboring sample to the first sample in the left projected depth map belongs to the left disoccluded area, the first sample in the left projected depth map and a first sample in the right projected depth map at the first 
<!-- EPO <DP n="10"/>-->
 position belong to a same plane of the visual scene, and the first sample in the right projected depth map and a second right neighboring sample to the first sample in the right projected depth map belong to the same plane of the visual scene. </p><p id="p0042" num="0042">Reducing the weights of the left reliability map information in such a way can be easy implemented by using logical operations. No complex computational processing is required. </p><p id="p0043" num="0043">In a seventh possible implementation form of the method according to the first aspect as such or according to any of the preceding implementation forms of the first aspect, the assigning a reduced weight for samples in the left projected picture for the computing of the synthesized picture, if a first sample in the left projected depth map at a first position and a second left neighboring sample to the first left sample in the left projected depth map do not belong to a same plane of the visual scene, a point in the visual scene corresponding to the first sample in the left projected depth map is closer to a camera than a point in the visual scene corresponding to the second left neighboring sample in the left projected depth map, the first sample in the left projected depth map and a first sample in the right projected depth map at the first position belong to a same plane of the visual scene, and the first sample in the right projected depth map and a second left neighboring sample to the first sample in the right projected depth map belong to the same plane of the visual scene. </p><p id="p0044" num="0044">Reducing the weights of the left reliability map information in such a way can be easy implemented by using logical operations. No complex computational processing is required. </p><p id="p0045" num="0045">In an eighth possible implementation form of the method according to the first aspect as such or according to any of the preceding implementation forms of the first aspect, object border misalignments are detected, and the determining the right reliability map information comprises assigning a reduced weight for samples in the right projected picture for the computing of the synthesized picture, if a first sample in the right projected depth map at a first horizontal and a first vertical position does not belong to the right disoccluded area, a second left neighboring sample to the first sample in the right projected depth map belongs to the right disoccluded area, the first sample in the right projected depth map and a first sample in the left projected depth map at the first 
<!-- EPO <DP n="11"/>-->
 horizontal and the first vertical position belong to a same plane of the visual scene, and the first sample in the left projected depth map and a second left neighboring sample to the first sample in the left projected depth map belong to the same plane of the visual scene. Reducing the weights of the right reliability map information in such a way can be easy implemented by using logical operations. No complex computational processing is required. </p><p id="p0046" num="0046">In a ninth possible implementation form of the method according to the first aspect as such or according to any of the preceding implementation forms of the first aspect, the determining the right reliability map information comprises assigning a reduced weight for samples in the right projected picture for the computing of the synthesized picture, if a first right sample in the right projected depth map at a first horizontal and a first vertical position and a second right neighboring sample to the first sample, in the right projected depth map do not belong to a same plane of the visual scene, a point in the visual scene corresponding to the first sample in the right projected depth map is closer to a camera than a point in the visual scene corresponding to the second right neighboring sample in the right projected depth map, the first sample in the right projected depth map and a first sample in the left projected depth map at the first horizontal and the first vertical position belong to a same plane of the visual scene, and the first sample in the left projected depth map and a second right neighboring sample to the first sample in the left projected depth map belong to the same plane of the visual scene. </p><p id="p0047" num="0047">Reducing the weights of the right reliability map information in such a way can be easy implemented by using logical operations. No complex computational processing is required. </p><p id="p0048" num="0048">In a tenth possible implementation form of the method according to the first aspect as such or according to any of the preceding implementation forms of the first aspect, the merging the left and right projected pictures comprises: weighting a sample in the left projected picture by the weight of the left reliability map and weighting a sample in the right projected picture by the weight of the right reliability map. 
<!-- EPO <DP n="12"/>-->
 When the merging the left and right projected pictures is applied on the modified weights, object synthesis artifacts can be reduced. </p><p id="p0049" num="0049">In an eleventh possible implementation form of the method according to the tenth implementation form of the first aspect, the method comprises: combining the weighted sample in the left projected picture and the weighted sample in the right projected picture to obtain a sample in the synthesized picture. </p><p id="p0050" num="0050">Combining the weighted samples can be easily performed, e.g. be using a simple addition operation. </p><p id="p0051" num="0051">In a twelfth possible implementation form of the method according to the eleventh implementation form of the first aspect, in case of a sample in the left projected picture and a sample in the right projected picture belong to different planes of visual scene, the sample in the synthesized picture is calculated based on only the one of the sample in the left projected picture and the sample in the right projected picture, which belongs to the closer plane. </p><p id="p0052" num="0052">By calculating the sample in the synthesized picture based on only one of the sample in the left projected picture and the sample in the right projected picture, the influence of the errors in the depth or disparity estimation to the view synthesis can be reduced. By using the sample which is located closer to a camera position, the reliability of the sample in the synthesized picture is increased. In a thirteenth possible implementation form of the method according to the first aspect as such or any of the implementation forms of the first aspect, the left and right projected pictures are projected texture pictures, the left and right projected pictures are the projected depth map pictures), or the left and right projected pictures are projected disparity pictures. </p><p id="p0053" num="0053">In a fourteenth possible implementation form of the method according to the first aspect as such or any of the implementation forms of the first aspect, the left depth map of the left reference view of the visual scene is a left disparity map of the left reference view of the visual scene, and the right depth map of the right reference view of the visual scene is a right disparity map of the right view of the visual scene; and wherein the left projected 
<!-- EPO <DP n="13"/>-->
 depth map is a left projected disparity map and the right projected depth map is a right projected disparity map. </p><p id="p0054" num="0054">According to a second aspect, the invention relates to computer program for performing the method of the first aspect as such or any of the implementation forms according to the first aspect, when executed on a processor or computer. </p><p id="p0055" num="0055">According to a third aspect, the invention relates to computer program product comprising a computer readable storage medium storing program code thereon for use by a programmable processor or computer system, the program code comprising instructions for executing a method according to the first aspect as such or any of the implementation forms of the first aspect. </p><p id="p0056" num="0056">The computer program or program code can be provided in form of a source code or machine-readable code, e.g. as firmware, software or any combination thereof. </p><p id="p0057" num="0057">The computer program can be provided on a digital storage medium, for example a hard disc, CD, DVD or blu ray disc,having an electronically readable control signal stored thereon, which co-operates with the programmable processor or programmable computer system such that a method according to the first aspect as such or any of its </p><p id="p0058" num="0058">implementation forms is performed, Alternatively the computer program or program code can be provided by downloading via a network. </p><p id="p0059" num="0059">According to a fourth aspect, an apparatus comprising a processor configured to perform the method according to the first aspect as such or any of the implementation forms of the first aspect is provided. </p><p id="p0060" num="0060">The methods, systems and devices described herein may be implemented as software in a Digital Signal Processor (DSP), in a micro-controller or in any other side-processor or as hardware circuit within an application specific integrated circuit (ASIC). </p><p id="p0061" num="0061">The invention can be implemented in digital electronic circuitry, or in computer hardware, firmware, software, or in combinations thereof, e.g. in available hardware of conventional mobile devices or in new hardware dedicated for processing the methods described herein. 
<!-- EPO <DP n="14"/>-->
 BRIEF DESCRIPTION OF THE DRAWINGS </p><p id="p0062" num="0062">Further embodiments of the invention will be described with respect to the following figures, in which: </p><p id="p0063" num="0063">Fig. 1 shows a block diagram illustrating a conventional synthesis algorithm 100 for 3D view synthesis; Fig. 2 shows a diagram 200 illustrating a reliability of pixels in the synthesis algorithm depicted in Fig. 1 ; </p><p id="p0064" num="0064">Fig. 3 shows a schematic diagram illustrating a method 300 for computing a synthesized picture of a visual scene according to an implementation form; </p><p id="p0065" num="0065">Fig. 4 shows a schematic diagram 400 illustrating synthesizing of an exemplary 3D scene to a synthesized view according to an implementation form; </p><p id="p0066" num="0066">Fig. 5 shows a schematic diagram illustrating conditions 500 for modification of the reliability map according to an implementation form; </p><p id="p0067" num="0067">Fig. 6 shows a diagram 600 illustrating exemplary patterns for reducing or modifying the values of a reliability map according to an implementation form; Fig. 7 shows a block diagram of an apparatus 700 for computing a synthesized picture of a visual scene according to an implementation form; </p><p id="p0068" num="0068">Fig. 8 shows a block diagram illustrating a reliability map creation block 705 in an apparatus 700 for computing a synthesized picture of a visual scene according to an implementation form. </p><p id="p0069" num="0069">Equal or equivalent elements are denoted in the following description of the figures by equal or equivalent reference signs. 
<!-- EPO <DP n="15"/>-->
 DETAILED DESCRIPTION OF EMBODIMENTS OF THE INVENTION </p><p id="p0070" num="0070">Fig. 3 shows a schematic diagram illustrating a method 300 for computing a synthesized picture of a visual scene according to an implementation form. For an easier </p><p id="p0071" num="0071">understanding, the method 300 is described with reference to Figs. 4, 7 and 8, although implementation forms of the method or apparatus, are not limited to such </p><p id="p0072" num="0072">implementations, for example can also be adapted to compute synthesized depth maps or synthesized disparity maps, which both form a kind of grayscale pictures, instead of synthesized texture pictures as depicted in Figs. 4, 7 and 8. </p><p id="p0073" num="0073">The method 300 computes a synthesized picture, for example a synthesized texture picture s<sub>T</sub>' as shown in Figs. 4 and 7, of a visual scene, based on a left depth map ¾,i of a left reference view of the visual scene and a right depth map So,<sub>r</sub> of a right reference view of the visual scene. The method 300 comprises the following. Projecting 301 the left depth map s<sub>D</sub>,i into a left projected depth map s<sub>D</sub>/ and projecting the right depth map s<sub>D,r</sub> into a right projected depth map s<sub>D,r</sub>\ and determining a left disoccluded area s<sub>F</sub>/ in the left projected depth map s<sub>D</sub>/ and a right disoccluded area s<sub>F,r</sub>' in the right projected depth map s<sub>D,r</sub>'. </p><p id="p0074" num="0074">Detecting 302 object border misalignments between the left projected depth map ¾, and the right projected depth map s<sub>D,r</sub>'. </p><p id="p0075" num="0075">Determining 303 a left reliability map information s<sub>R</sub>/ based on the left disoccluded area SF,I', and the detected object border misalignments, and determining a right reliability map information s<sub>R,r</sub>' based on the right disoccluded area SF/, and the detected object border misalignments. Computing 307 the synthesized picture s<sub>T</sub>' by merging a left projected picture s<sub>T</sub>/ of the left reference view and a right projected picture s<sub>Tr</sub>' of the right reference view using the left SR I' and right s<sub>R,r</sub>' reliability map information. </p><p id="p0076" num="0076">In an implementation, the determining 303 the left reliability map information SR/ and the right reliability map information s<sub>R,r</sub>' comprises the following. Determining the left reliability map information s<sub>R</sub>/ based on the left disoccluded area s<sub>F</sub>/ and the right reliability map information s<sub>R,r</sub>' based on the right disoccluded area SF/. Modifying the left reliability map information s<sub>R</sub>/ and/or the right reliability map information s<sub>R r</sub>' when object border 
<!-- EPO <DP n="16"/>-->
 misalignments between the left projected depth map and the right projected depth map are detected. </p><p id="p0077" num="0077">In an implementation, the method 300 further comprises the following. Determining a plane discrimination map s<sub>P</sub>,i<sub>r</sub>' between the left projected depth map s<sub>D,r</sub>' and the right projected depth map s<sub>D,r</sub>' based on the left projected depth map s<sub>D</sub>/ and the right projected depth map s<sub>D,r</sub>'. Determining a left plane discrimination map s<sub>P</sub>,n' for the left projected depth map s<sub>D</sub>/ based on the left projected depth map ¾/. Determining a right plane discrimination map s<sub>P,rr</sub>' for the right projected depth map s<sub>D,r</sub>' based on the right projected depth map s<sub>D,r</sub>'. Wherein the determining 303 the left reliability map information SR I' is based on the left plane discrimination map Sp,n' and on the plane discrimination map Sp ir', and the determining the right reliability map information SR/ is based on the right plane discrimination map s<sub>P,rr</sub>' and on the plane discrimination map s<sub>P</sub>,i<sub>r</sub>'. </p><p id="p0078" num="0078">In an implementation, the detecting 302 object border misalignments comprises detecting, whether samples in one of the left projected depth map ¾&gt;/ and right projected depth map s<sub>D,r</sub>' belong to an object border and at the same positions (x,y) belong to a foreground plane in the other projected depth map. </p><p id="p0079" num="0079">In an implementation, an object border misalignment is detected if samples in a first of the left projected depth map s<sub>D</sub>/ and right projected depth map s<sub>D,r</sub>' belong to an object border and at the same positions (x,y) belong to a foreground plane in the other second projected depth map of the left projected depth map s<sub>D</sub>/ and right projected depth map s<sub>D,r</sub>'; wherein the determining 303 the left reliability map information SR/ comprises assigning a reduced weight for samples in the left projected picture s<sub>T</sub>,i' for the computing of the synthesized picture s<sub>T</sub>' if the samples in the left projected depth map ¾&gt;/ belong to an object border and at the same positions (x,y) belong to a foreground plane in the right projected depth map s<sub>D,r</sub>'; and/or wherein the determining 303 the right reliability map information s<sub>R,r</sub>' comprises assigning a reduced weight for samples in the right projected picture Sr,<sub>r</sub>' for the computing of the synthesized picture s<sub>T</sub>' if the samples in the right projected depth map s<sub>D,r</sub>' belong to an object border and at the same positions (x,y) belong to a foreground plane in the left projected depth map s<sub>D</sub>/. </p><p id="p0080" num="0080">In an implementation, the reduced weights are assigned according to a monotonically increasing or decreasing function (603) over a transition region (601 ) determined based 
<!-- EPO <DP n="17"/>-->
 on the positions of the samples belonging to the object borderas described below with respect to Fig. 6. </p><p id="p0081" num="0081">In an implementation as described below with respect to Fig. 5a, the determining 303 the left reliability map information s<sub>R</sub>/ comprises: assigning a reduced weight for samples in the left projected picture s<sub>T</sub>/ for the computing of the synthesized picture s<sub>T</sub>', if a first sample V|(x,y) in the left projected depth map ¾<sub>,</sub> at a first position (x,y) does not belong to the left disoccluded area s<sub>F,</sub>i',a second right neighboring sample V|(x+1 ,y) to the first sample V|(x,y) in the left projected depth map ¾<sub>,</sub> belongs to the left disoccluded area SF/ , the first sample V|(x,y) in the left projected depth map ¾<sub>,</sub> and a first sample v<sub>r</sub>(x,y) in the right projected depth map s<sub>D,r</sub>' at the first position (x,y) belong to a same plane of the visual scene, and the first sample v<sub>r</sub>(x,y) in the right projected depth map s<sub>D,r</sub>' and a second right neighboring sample v<sub>r</sub>(x+1 ,y) to the first sample v<sub>r</sub>(x,y) in the right projected depth map s<sub>D,r</sub>' belong to the same plane of the visual scene. </p><p id="p0082" num="0082">In an implementation as described below with respect to Fig. 5b, object border </p><p id="p0083" num="0083">misalignments are detected and the determining 303 the left reliability map information SR I' comprises assigning a reduced weight for samples in the left projected picture s<sub>T,</sub>i' for the computing of the synthesized picture s<sub>T</sub>', if a first sample V|(x,y) in the left projected depth map s<sub>D</sub>/ at a first position (x,y) and a second left neighboring sample v,(x-1 ,y) to the first left sample V|(x,y) in the left projected depth map do not belong to a same plane of the visual scene, a point in the visual scene corresponding to the first sample v,(x,y) in the left projected depth map is closer to a camera than a point in the visual scene corresponding to the second left neighboring sample V|(x-1 ,y) in the left projected depth map, the first sample V|(x,y) in the left projected depth map ¾<sub>,</sub> and a first sample v<sub>r</sub>(x,y) in the right projected depth map s<sub>D,r</sub>' at the first position (x,y) belong to a same plane of the visual scene, and the first sample v<sub>r</sub>(x,y) in the right projected depth map s<sub>D,r</sub>' and a second left neighboring sample v<sub>r</sub>(x-1 ,y) to the first sample v<sub>r</sub>(x,y) in the right projected depth map s<sub>D,r</sub>' belong to the same plane of the visual scene. In an implementation as described below with respect to Fig. 5c, object border </p><p id="p0084" num="0084">misalignments are detected, and the determining 303 the right reliability map information SR comprises assigning a reduced weight for samples in the right projected picture s<sub>T,r</sub>' for the computing of the synthesized picture s<sub>T</sub>', if a first sample v<sub>r</sub>(x,y) in the right projected depth map s<sub>D,r</sub>' at a first horizontal x and a first vertical y position does not belong to the right disoccluded area s<sub>F,r</sub>\ a second left neighboring sample v<sub>r</sub>(x-1 ,y) to the 
<!-- EPO <DP n="18"/>-->
 first sample v<sub>r</sub>(x,y) in the right projected depth map s<sub>D,r</sub>' belongs to the right disoccluded area s<sub>F,r</sub>\ the first sample v<sub>r</sub>(x,y) in the right projected depth map s<sub>D,r</sub>' and a first sample V|(x,y) in the left projected depth map s<sub>D</sub>/ at the first horizontal x and the first vertical y position belong to a same plane of the visual scene, and the first sample (x,y) in the left projected depth map s<sub>D</sub>/ and a second left neighboring sample V|(x-1 ,y) to the first sample V|(x,y) in the left projected depth map ¾, belong to the same plane of the visual scene. </p><p id="p0085" num="0085">In an implementation as described below with respect to Fig. 5d, object border misalignments are detected and the determining 303 the right reliability map information SR comprises assigning a reduced weight for samples in the right projected picture s<sub>T,r</sub>' for the computing of the synthesized picture s<sub>T</sub>', if a first right sample v<sub>r</sub>(x,y) in the right projected depth map s<sub>D,r</sub>' at a first horizontal x and a first vertical y position and a second right neighboring sample v<sub>r</sub>(x+1 ,y) to the first sample v<sub>r</sub>(x,y) in the right projected depth map s<sub>D,r</sub>' do not belong to a same plane of the visual scene, a point in the visual scene corresponding to the first sample v<sub>r</sub>(x,y) in the right projected depth map s<sub>D,r</sub>' is closer to a camera than a point in the visual scene corresponding to the second right neighboring sample v<sub>r</sub>(x+1 ,y) in the right projected depth map s<sub>D,r</sub>\ the first sample v<sub>r</sub>(x,y) in the right projected depth map s<sub>D,r</sub>' and a first sample V|(x,y) in the left projected depth map ¾, at the first horizontal x and the first vertical y position belong to a same plane of the visual scene, and the first sample V|(x,y) in the left projected depth map ¾, and a second right neighboring sample V|(x+1 ,y) to the first sample V|(x,y) in the left projected depth map ¾, belong to the same plane of the visual scene. </p><p id="p0086" num="0086">In an implementation, the merging the left s<sub>T</sub>/ and right s<sub>T,r</sub>' projected pictures comprises weighting a sample V|(x,y) in the left projected picture s<sub>T</sub>/ by the weight of the left reliability map s<sub>R</sub>/ and weighting a sample v<sub>r</sub>(x,y) in the right projected picture s<sub>T,r</sub>' by the weight of the right reliability map s<sub>R,r</sub>'. </p><p id="p0087" num="0087">In an implementation, the method 300 comprises combining the weighted sample V|(x,y) in the left projected picture s<sub>T</sub>/ and the weighted sample v<sub>r</sub>(x,y) in the right projected picture s<sub>T,r</sub>' to obtain a sample v(x,y) in the synthesized picture. 
<!-- EPO <DP n="19"/>-->
 In an implementation, in case a sample V|(x,y) in the left projected picture s<sub>T</sub>/ and a sample v<sub>r</sub>(x,y) in the right projected picture s<sub>T,r</sub>' belong to different planes of the visual scene, the sample v(x,y) in the synthesized picture is calculated based only on the sample V|(x,y) in the left projected picture s<sub>T</sub>/ or the sample v<sub>r</sub>(x,y) in the right projected picture which belongs to the closer plane. </p><p id="p0088" num="0088">In an implementation, the sample v(x,y) in the synthesized picture is calculated based on the one of the sample V|(x,y) in the left projected picture s<sub>T</sub>,i' and the sample v<sub>r</sub>(x,y) in the right projected picture s<sub>T,r</sub>' which sample is closer to a camera. </p><p id="p0089" num="0089">Implementation forms may be adapted to compute a synthesized texture picture Sr',as synthesized picture, as for example depicted in Figs. 4, 5, 7 and 8, or may be adapted to compute a synthesized depth map picture s<sub>D</sub>' or both. Further implementation forms may be adapted to compute a synthesized disparity map picture for the synthesized view 405 instead of a synthesized depth map picture. Accordingly, in further implementation forms of the method 300, the left and right projected pictures are projected texture pictures (s<sub>T</sub>/, s<sub>T</sub>,<sub>r</sub>'), the left and right projected pictures are the projected depth map pictures (¾/, s<sub>D</sub>,<sub>r</sub>'), or the left and right projected pictures are projected disparity pictures. In further implementation forms of the method 300, disparity maps, which are depth maps with inverse values, are used instead of the depth maps as such. Accordingly, the left depth map s<sub>D</sub>,i of the left reference view of the visual scene is a left disparity map SD,I of the left reference view of the visual scene, and the right depth map So<sub>,r</sub> of the right reference view of the visual scene is a right disparity map of the right view of the visual scene; and wherein the left projected depth map ¾&gt;/ is a left projected disparity map and the right projected depth map s<sub>D,r</sub>' is a right projected disparity map. </p><p id="p0090" num="0090">Fig. 4 shows a schematic diagram 400 illustrating synthesizing of an exemplary 3D scene to a synthesized view 405 according to an implementation form. The exemplary 3D scene comprises a foreground object 409 and a background 407. </p><p id="p0091" num="0091">Inter-view inconsistency between depth maps of the different reference views 401 , 403 may cause a misalignment between object borders in pictures synthesized or projected from left and right reference pictures: s<sub>T,</sub> and s<sub>T,r</sub>'. s<sub>T,</sub> is also referred to as left projected picture of the left reference view, and s<sub>T,r</sub>' is also referred to as rigth projected picture of 
<!-- EPO <DP n="20"/>-->
 the right reference view. As s<sub>T</sub>/ and s<sub>T,r</sub>' pictures are further used in the combination step 307 of the method 300 for computing the synthesized picture 405 as described above with respect to Fig. 3, this misalignment may result in producing an additional border 41 1 for the object 409 in the synthesized output picture 405 combined from these two reference views 401 , 403. </p><p id="p0092" num="0092">In order to minimize this effect, the method 300 applies border misalignment detection for objects in the analyzed visual scene and suppresses the influence of samples in one of the ST/ or s<sub>T</sub>/ pictures in which the border 41 1 of the object corresponds to the area marked as foreground in the other picture. Samples from such a picture are assigned a smaller reliability in order to minimize their impact during the weighted averaging in the combination step for obtaining the synthesized output picture 405. </p><p id="p0093" num="0093">Fig. 5 shows a schematic diagram illustrating conditions 500 for modification of the reliability map according to an implementation form. Figures 5a and 5b describe a first and second case for the left s<sub>R</sub>/ reliability map and Figures 5c and 5d describe a first and second case for the right s<sub>R</sub>/ reliability map. </p><p id="p0094" num="0094">The following notation is applied: Vi(x,y) denotes a sample in the picture synthesized from the left reference picture Sy/ at position (x,y). v<sub>r</sub>(x,y) denotes a sample in the picture synthesized from the right reference picture s<sub>T</sub>/ at position (x,y). </p><p id="p0095" num="0095">In an implementation form, the conditions to determine if the modification of the reliability map s<sub>R</sub>/ or s<sub>R</sub>/ at position (x,y) is being applied are as follows: </p><p id="p0096" num="0096">For the left reliability map s<sub>R</sub>/ as depicted in Figures 5a and 5b, the following two cases (Case 1 and Case 2) apply: </p><p id="p0097" num="0097"> Case 1: (modification or assignment of a reduced value is applied only if all of the conditions are fulfilled), see Fig. 5a: </p><p id="p0098" num="0098">a. Sample v<sub>t</sub>(x,y) does not belong to disoccluded area. </p><p id="p0099" num="0099">b. Right neighboring sample Vi(x+1,y) belongs to disoccluded area. </p><p id="p0100" num="0100">c. Samples v<sub>t</sub>(x,y) and v<sub>r</sub>(x,y) belong to the same plane of the visual scene. </p><p id="p0101" num="0101">d. Samples v<sub>r</sub>(x,y) and v<sub>r</sub>(x+1,y) belong to the same plane of the visual scene. </p><p id="p0102" num="0102"> Case 2 (modification or assignment of a reduced value is applied only if all of the conditions are fulfilled), see Fig. 5b: 
<!-- EPO <DP n="21"/>-->
 a. Left neighboring sample Vi(x-1,y) does not belong to the same plane of the visual scene as the sample v<sub>t</sub>(x,y). </p><p id="p0103" num="0103">b. The point in the visual scene correspondent to the sample Vi(x,y) is closer to the camera than the one represented by the left neighboring sample Vi(x-1,y). </p><p id="p0104" num="0104">c. Samples Vi(x,y) and v<sub>r</sub>(x,y) belong to the same plane of the visual scene, d. Samples v<sub>r</sub>(x-1,y) and v<sub>r</sub>(x,y) belong to the same plane of the visual scene. </p><p id="p0105" num="0105">For the right reliability map s<sub>R</sub> as depicted in Figures 5c and 5d, the following two cases (Case 1 and Case 2) apply: </p><p id="p0106" num="0106">Case 1: (modification or assignment of a reduced value is applied only if all of the conditions are fulfilled), see Fig. 5c: </p><p id="p0107" num="0107">a. Sample v<sub>r</sub>(x,y) does not belong to disoccluded area. </p><p id="p0108" num="0108">b. Left neighboring sample v<sub>r</sub>(x-1,y) belongs to disoccluded area. </p><p id="p0109" num="0109">c. Samples v<sub>r</sub>(x,y) and v<sub>t</sub>(x,y) belong to the same plane of the visual scene. </p><p id="p0110" num="0110">d. Samples v<sub>t</sub>(x-1,y) and v<sub>t</sub>(x,y) belong to the same plane of the visual scene. </p><p id="p0111" num="0111"> Case 2 (modification or assignment of a reduced value is applied only if all of the conditions are fulfilled), see Fig. 5d: </p><p id="p0112" num="0112">a. Right neighboring sample v<sub>r</sub>(x+1,y) does not belong to the same plane of the visual scene as the sample v<sub>r</sub>(x,y). </p><p id="p0113" num="0113">b. The point in the visual scene correspondent o the sample v<sub>r</sub>(x,y) is closer to the camera than the one represented by the right neighboring sample v<sub>r</sub>(x+1,y). </p><p id="p0114" num="0114">c. Samples v<sub>r</sub>(x,y) and v<sub>t</sub>(x,y) belong to the same plane of the visual scene. </p><p id="p0115" num="0115">d. Samples v<sub>t</sub>(x,y) and v<sub>t</sub>(x+1,y) belong to the same plane of the visual scene. Information if the sample belongs to the disoccluded area or not is determined in the projection step 301 in which samples from the reference picture are projected into the synthesised picture. Such information, e.g. left and right disoccluded areas s<sub>F</sub>/ and s<sub>F</sub>/ are usually represented in form of binary masks, e.g. in left and right filling masks s<sub>F</sub>/ and SF/ according to the HEVC Test Model as described above. </p><p id="p0116" num="0116">The decision if the two samples belong to the same plane of the visual scene is made based on plane discrimination criteria. For that purpose, in an implementation form, plane discrimination criteria introduced in the prior art are used. Consequently, in case of the samples located at the same position (x,y) but belonging to different views, i.e. v<sub>t</sub>(x,y) and v<sub>r</sub>(x,y), the decision can be made based on the plane discrimination map s<sub>P</sub>/ calculated 
<!-- EPO <DP n="22"/>-->
 already in the plane discrimination step according to the prior art synthesis algorithm. On the other hand, for neighboring samples from the same view, e.g. Vi(x,y) and Vi(x-1,y), the same plane discrimination criteria is used, however, the input of the decision function is only one depth map of the analyzed view (s<sub>D,</sub> or 
<img id="imgf000022_0001" he="5" wi="8" file="imgf000022_0001.tif" img-format="tif" img-content="drawing" orientation="portrait" inline="no"/>
 and, consequently, a plane discrimination map is computed independently for each view, producing plane discrimination maps for left and right view: s<sub>P</sub>/ and s<sub>P</sub>_<sub>r</sub>r', also referred to as left and right plane discrimination maps s<sub>P</sub>/ and s<sub>P</sub>_<sub>r</sub>r - </p><p id="p0117" num="0117">Also, a distance of the point in the visual scene correspondent to each sample is determined based on the corresponding depth map, and the left projected depth map s<sub>D,</sub> is used for the modification or assignment of reduced values of the left reliability map s<sub>R</sub>/, and the right projected depth map s<sub>D,</sub> is used for the modification or assignment of reduced values of the right reliability map s<sub>R</sub>/. In an alternative implementation form, in any case of utilization of depth maps, disparity maps are used for the same purpose. </p><p id="p0118" num="0118">The modification or assignment of reduced values of the reliability map s<sub>R</sub>/ or s<sub>R</sub>/ according to the specified pattern is applied to all neighboring samples within the defined transition region ATR 601 if the appropriate above described conditions for sample at position (x,y) are fulfilled: </p><p id="p0119" num="0119">A. For the s<sub>R</sub>/ reliability map: </p><p id="p0120" num="0120"> Case 1: samples within range [x-ATR,x] are modified: R<sub>min</sub> reliability is assigned to s<sub>R</sub>/ at position (x,y) and R<sub>max</sub> reliability is assigned to s<sub>R</sub>/ at position (x-ATR,y). </p><p id="p0121" num="0121">Case 2: samples within range [χ,χ+ATR] are modified: R<sub>min</sub> reliability is assigned to s<sub>R</sub>/ at position (x,y) and R<sub>max</sub> reliability is assigned to s<sub>R</sub>/ at position (x+ATR,y). </p><p id="p0122" num="0122">B. For the s<sub>R</sub> reliability map: </p><p id="p0123" num="0123"> Case 1: samples within range [χ,χ+ATR] are modified: R<sub>min</sub> reliability is assigned to s<sub>R</sub>/ at position (x,y) and R<sub>max</sub> reliability is assigned to s<sub>R</sub>/ at position (x+ATR,y). </p><p id="p0124" num="0124">Case 2: samples within range [x-ATR,x] are modified: R<sub>min</sub> reliability is assigned to s<sub>R</sub>/ at position (x,y) and R<sub>max</sub> reliability is assigned to s<sub>R</sub>/ at position (x-ATR,y). </p><p id="p0125" num="0125">In the above description R<sub>min</sub> and R<sub>max</sub> are defined accordingly: minimum and maximum reliability values that are assigned to the samples of the reliability map within the transition region 601. 
<!-- EPO <DP n="23"/>-->
 Fig. 6 shows a diagram 600 illustrating exemplary patterns for modifying the values or assigning reduced values of the left and right reliability map s<sub>R</sub>/ or s<sub>R</sub> according to an implementation form. In an implementation form, the pattern specifying the values of the reliability map s<sub>R</sub>/ or s<sub>R</sub>/ inside the transition region 601 is any monotonically increasing function 603, which values are: </p><p id="p0126" num="0126"> R<sub>min</sub> assigned to the first sample in the transition region 601 , </p><p id="p0127" num="0127"> R<sub>max</sub> assigned to the last sample in the transition region 601 . </p><p id="p0128" num="0128">The first sample in the transition region 601 is the sample at position (x,y) for which the conditions for modifying the reliability map are fulfilled. The coordinates of the last sample in the transition region 601 are consequently equal to (x-ATR,y) or (x+ATR,y) depending on the case for which border misalignment was detected. ATR denotes the width of the transition region 601 . </p><p id="p0129" num="0129">In an implementation form, other steps of view synthesis are performed as in the prior art described above with respect to Figures 1 and 2. </p><p id="p0130" num="0130">Fig. 7 shows a block diagram of an apparatus 700 for computing a synthesized picture of a visual scene according to an implementation form. </p><p id="p0131" num="0131">The computing the synthesized picture s<sub>T</sub>' of a visual scene is starting from left s<sub>T,</sub>i and right s<sub>T,r</sub> reference pictures and their corresponding left SD,I and right s<sub>D,r</sub> depth maps. The apparatus 700 comprises a projector 701 configured for projecting the left reference picture s<sub>T,</sub>i into a left projected picture s<sub>T,</sub>i' and projecting the right reference picture s<sub>T,r</sub> into a right projected picture s<sub>T,r</sub>' and determining a left disoccluded area s<sub>F</sub>/ in the left projected picture s<sub>T</sub>,i' and a right disoccluded area s<sub>F</sub>,<sub>r</sub>' in the right s<sub>T</sub>,<sub>r</sub>' projected picture. The apparatus 700 comprises a determiner 705 configured for determining a left reliability map SR I' based on the left disoccluded area s<sub>F</sub>/ and a right reliability map s<sub>R r</sub>' based on the right disoccluded area s<sub>F,r</sub>'. The apparatus 700 comprises a modifier 805, see Fig. 8, configured for modifying weights of at least one of the left s<sub>R</sub>/ and right s<sub>R,r</sub>' reliability maps when misaligned object borders are detected in at least one of the left sr<sub>,</sub>i' and right s<sub>T,r</sub>' projected pictures. The apparatus 700 comprises a processor 707 configured for computing the synthesized picture s<sub>T</sub>' by merging the left s<sub>T,</sub>i' and right s<sub>T,r</sub>' projected pictures using the left s<sub>R</sub>/ and right s<sub>R,r</sub>' reliability maps. The projector 701 comprises a left 
<!-- EPO <DP n="24"/>-->
 projector 701 a for projecting the left reference picture s<sub>T</sub>,i and a right projector 701 b for projecting the right reference picture s<sub>T,r</sub>- The projector 701 is coupled to the determiner 705 which receives outputs of the projector 701. The determiner 705 is coupled to the processor 707 which receives outputs of the projector 701 and outputs of the determiner 705. </p><p id="p0132" num="0132">In an implementation form, the apparatus 700 comprises a plane discriminator 703 configured for receiving outputs of the projector 701 and providing outputs to the processor 707. </p><p id="p0133" num="0133">In an implementation form, the projector 701 , the determiner 705, the processor 707 and the plane discriminator 703 are functionally specified according to the description below: </p><p id="p0134" num="0134">In Blocks 701 a, 701 b, left and right reference pictures are projected into the synthesized picture, and disoccluded areas are detected. In block 703, plane discrimination map between left and right picture is calculated. In blocks 705a, 705b, the information received from blocks 701 a, 701 b and block 703 is combined to build up a reliability map. In an implementation, the reliability map is built up as in the prior art as described above with respect to Figures 1 and 2. A misalignment between object borders in pictures synthesized from left and right reference pictures is detected. For the areas with misalignment between object borders in pictures synthesized from left and right reference pictures detected, the reliability map is modified applying the method 300 as described above. In block 707, the combination step allows to complete the view synthesis by merging pictures synthesized from left and right reference views. </p><p id="p0135" num="0135">The following symbols are used in Fig. 7: s<sub>T</sub> and s<sub>T,r</sub> (left and right view textures), and s<sub>D</sub>,i and s<sub>D</sub>,r (left and right view depth maps), s<sub>T,</sub> , s<sub>T,r</sub>', s<sub>D</sub>/ and s<sub>D,</sub> are the left and right texture and depths projected into virtual view, s<sub>P</sub>_<sub>r</sub> is the plane discrimination map between left and right view, SF/ and s<sub>F</sub> are filling masks (identifying disoccluded areas that need to be filled), s<sub>R</sub>/ and s<sub>R</sub>/ are the reliability maps for the left and right views respectively. </p><p id="p0136" num="0136">Fig. 8 shows a block diagram illustrating a reliability map creation block 705 in an apparatus 700 for computing a synthesized picture of a visual scene according to an implementation form. The reliability map creation block 705 may correspond to the determiner 705 as described above with respect to Fig. 7. 
<!-- EPO <DP n="25"/>-->
 In an implementation form, the reliability map creation block 705 is functionally specified according to the following description: In block 801 , for every sample of an input disoccluded area, e.g. input filling mask or, a reliability weight is computed according to conventional algorithms as described above with respect to the description of Figures 1 and 2. In blocks 703a, 703b, plane discrimination maps for the left or right view are calculated. In block 803, an object border misalignment for the left and right projected views is detected based on the disoccluded areas or filling maps of the projected views s<sub>F</sub> and SF/, the plane discrimination map s<sub>P r</sub>' between left and right view and the plane discrimination maps s<sub>P</sub>/ and Sp<sub>:rr</sub>' computed independently for each view as described above. In block 805, for every sample of the reliability map created in block 801 , the reliability weight is modified if an object border misalignment is detected; the weights are modified according to the monotonically decreasing pattern as described above. Implementation forms may be adapted to first determine the left and right reliability maps or reliability map information according to conventional algorithms and afterwards to modify the left and right reliability maps or reliability map information, e.g. reduce the weights for the corresponding samples, when object border misalignments between the left and right projected depth map have been detected, as shown in Fig. 8 with regard to functional blocks 801 and 805, Alternative implementation forms may be adapted to omit the step or functional block 801 of first determining the left and right reliability maps or reliability map information according to conventional algorithms and to assign directly in step or functional block 805 reduced weights for the corresponding samples in the left and right reliability maps or reliability map information, when object border misalignments between the left and right projected depth map have been detected. </p><p id="p0137" num="0137">Implementation forms may be adapted to compute a synthesized texture picture s<sub>T</sub>',as synthesized picture, as for example depicted in Figs. 4, 5, 7 and 8, or may be adapted to compute a synthesized depth map picture s<sub>D</sub>' or both. Further implementation forms may be adapted to compute a synthesized disparity map picture for the synthesized view 405 instead of a synthesized depth map picture. </p><p id="p0138" num="0138">In implementation forms for computing a synthesized texture picture s<sub>T</sub>', the left and right projected pictures are projected texture pictures s<sub>T</sub>,i', s<sub>T,r</sub>' obtained from left and right reference texture pictures s<sub>T</sub>,i, s<sub>T,r</sub> by projection. 
<!-- EPO <DP n="26"/>-->
 In implementation forms for computing a synthesized depth map picture ¾', the left and right projected pictures are projected depth map pictures ¾&gt;/, s<sub>D,r</sub>' obtained, for example from left and right reference depth map pictures ¾&gt;<sub>,</sub>ι, s<sub>D,r</sub> by projection, or from left and disparity map pictures by projection and inversion of the map values or vice versa. </p><p id="p0139" num="0139">In implementation forms for computing a synthesized disparity map picture, the left and right projected pictures are projected disparity map pictures obtained from left and right reference disparity map pictures by projection, or from left and depth map pictures by projection and inversion of the map values or vice versa. </p><p id="p0140" num="0140">Implementation forms may be adapted to determine the whole left and right reliability map before computing the synthesized picture or adapted, for example to determine only parts process entire pictures and corresponding maps or only those parts of left and right reliability map which are required for computing the corresponding part of the synthesized picture, i.e. implementation forms are adapted to determine left and right reliability map information. </p><p id="p0141" num="0141">From the foregoing, it will be apparent to those skilled in the art that a variety of methods, systems, computer programs on recording media, and the like, are provided. </p><p id="p0142" num="0142">The present disclosure also supports a computer program product including computer executable code or computer executable instructions that, when executed, causes at least one computer to execute the performing and computing steps described herein. </p><p id="p0143" num="0143">Many alternatives, modifications, and variations will be apparent to those skilled in the art in light of the above teachings. Of course, those skilled in the art readily recognize that there are numerous applications of the invention beyond those described herein. While the present inventions has been described with reference to one or more particular embodiments, those skilled in the art recognize that many changes may be made thereto without departing from the scope of the present invention. It is therefore to be understood that within the scope of the appended claims and their equivalents, the inventions may be practiced otherwise than as specifically described herein. 
</p></description><claims mxw-id="PCLM75126667" ref-ucid="WO-2014183787-A1" lang="EN" load-source="patent-office"><claim-statement><!-- EPO <DP n="27"/>--> CLAIMS: </claim-statement><claim id="clm-0001" num="1"><claim-text>1 . A method (300) for computing a synthesized picture (s<sub>T</sub>') of a visual scene, based on a left depth map (s<sub>D,</sub>i) of a left reference view of the visual scene and a right depth map (s<sub>D,r</sub>) of a right reference view of the visual scene, the method (300) comprising: projecting (301 ) the left depth map (s<sub>D,</sub>i) into a left projected depth map (s<sub>D</sub>/) and projecting the right depth map (s<sub>D</sub>,<sub>r</sub>) into a right projected depth map (s<sub>D</sub>,<sub>r</sub>'), and </claim-text><claim-text>determining a left disoccluded area (s<sub>F</sub>/) in the left projected depth map (s<sub>D</sub>/) and a right disoccluded area (s<sub>F</sub>,<sub>r</sub>') in the right projected depth map (s<sub>D</sub>,<sub>r</sub>'); detecting (302) object border misalignments between the left projected depth map (S<sub>D</sub>,D and the right projected depth map (s<sub>D</sub>,<sub>r</sub>'); determining (303) a left reliability map information (s<sub>R</sub>/) based on the left disoccluded area (s<sub>F</sub>/), and the detected object border misalignments, and determining a right reliability map information (s<sub>R,r</sub>') based on the right disoccluded area (s<sub>F,r</sub>'), and the detected object border misalignments; and computing (307) the synthesized picture (s<sub>T</sub>') by merging a left projected picture (S<sub>T,</sub>D of the left reference view and a right projected picture (s<sub>Tr</sub>') of the right reference view using the left (s<sub>R</sub>/) and right (s<sub>R,r</sub>') reliability map information. </claim-text></claim><claim id="clm-0002" num="2"><claim-text>2. The method of claim 1 , wherein the determining (303) the left reliability map information (s<sub>R</sub>/) and the right reliability map information (s<sub>R r</sub>') comprises: determining the left reliability map information (s<sub>R</sub>/) based on the left disoccluded area (s<sub>F</sub>/) and the right reliability map information (s<sub>R r</sub>') based on the right disoccluded area (s<sub>F,r</sub>'); and modifying the left reliability map information (s<sub>R</sub>/) and/or the right reliability map information (s<sub>R r</sub>') when object border misalignments between the left projected depth map and the right projected depth map are detected. </claim-text></claim><claim id="clm-0003" num="3"><claim-text>3. The method (300) of claim 2, further comprising: 
<!-- EPO <DP n="28"/>-->
 determining a plane discrimination map (s<sub>P,</sub>i<sub>r</sub>') between the left projected depth map (s<sub>D</sub>,<sub>r</sub>') and the right projected depth map (s<sub>D</sub>,<sub>r</sub>') based on the left projected depth map (S<sub>D</sub>,D and the right projected depth map (s<sub>D</sub>,<sub>r</sub>'); determining a left plane discrimination map (s<sub>P,</sub>n') for the left projected depth map (S<sub>D</sub>,D based on the left projected depth map (¾/); and determining a right plane discrimination map (sp<sub>,rr</sub>') for the right projected depth map (s<sub>D</sub>,<sub>r</sub>') based on the right projected depth map (s<sub>D</sub>,<sub>r</sub>'); wherein the determining (303) the left reliability map information (s<sub>R</sub>/) is based on the left plane discrimination map (s<sub>P,</sub>n') and on the plane discrimination map (s<sub>P r</sub>'), and the determining the right reliability map information (s<sub>R,r</sub>') is based on the right plane discrimination map (s<sub>P rr</sub>') and on the plane discrimination map (s<sub>P,</sub>i<sub>r</sub>'). </claim-text></claim><claim id="clm-0004" num="4"><claim-text> 4. The method (300) of any of the preceding claims, wherein the detecting (302) object border misalignments comprises: detecting, whether samples in one of the left projected depth map (¾&gt;/) and right projected depth map (s<sub>D,r</sub>') belong to an object border and at the same positions ((x,y)) belong to a foreground plane in the other projected depth map. </claim-text></claim><claim id="clm-0005" num="5"><claim-text>5. The method (300) of any of the preceding claims, wherein a object border misalignment is detected if samples in a first of the left projected depth map (¾/) and right projected depth map (s<sub>D,r</sub>') belong to an object border and at the same positions ((x,y)) belong to a foreground plane in the other second projected depth map of the left projected depth map (s<sub>D</sub>/) and right projected depth map (¾/); wherein the determining (303) the left reliability map information (S<sub>R</sub>/) comprises assigning a reduced weight for samples in the left projected picture (s<sub>T</sub>/) for the computing of the synthesized picture (s<sub>T</sub>') if the samples in the left projected depth map (S<sub>D,</sub>D belong to an object border and at the same positions ((x,y)) belong to a foreground plane in the right projected depth map (s<sub>D,r</sub>'); and/or wherein the determining (303) the right reliability map information (S<sub>R</sub>/) comprises assigning a reduced weight for samples in the right projected picture (s<sub>T,r</sub>') for the computing of the synthesized picture (s<sub>T</sub>') if the samples in the right projected depth map 
<!-- EPO <DP n="29"/>-->
 (s<sub>D,r</sub>') belong to an object border and at the same positions ((x,y)) belong to a foreground plane in the left projected depth map (s<sub>D</sub>/). </claim-text></claim><claim id="clm-0006" num="6"><claim-text>6. The method (300) of claim 5, wherein the reduced weights are assigned according to a monotonically increasing or decreasing function (603) over a transition region (601 ) determined based on the positions of the samples belonging to the object border. </claim-text></claim><claim id="clm-0007" num="7"><claim-text>7. The method (300) of one of the preceding claims, wherein the determining (303) the left reliability map information (s<sub>R</sub>/) comprises: assigning a reduced weight for samples in the left projected picture (s<sub>T,</sub>i') for the computing of the synthesized picture (s<sub>T</sub>') , if a first sample (vi(x,y)) in the left projected depth map (s<sub>D</sub>/) at a first position ((x,y)) does not belong to the left disoccluded area (s<sub>F</sub>/), a second right neighboring sample (V|(x+1 ,y)) to the first sample (vi(x,y)) in the left projected depth map (s<sub>D</sub>/) belongs to the left disoccluded area (s<sub>F</sub>/), the first sample (vi(x,y)) in the left projected depth map (s<sub>D</sub>/) and a first sample (v<sub>r</sub>(x,y)) in the right projected depth map (s<sub>D</sub>,<sub>r</sub>') at the first position ((x,y)) belong to a same plane of the visual scene, and the first sample (v<sub>r</sub>(x,y)) in the right projected depth map (s<sub>D,r</sub>') and a second right neighboring sample (v<sub>r</sub>(x+1 ,y)) to the first sample (v<sub>r</sub>(x,y)) in the right projected depth map (s<sub>D,r</sub>') belong to the same plane of the visual scene; or assigning a reduced weight for samples in the left projected picture (s<sub>T,</sub>i') for the computing of the synthesized picture (s<sub>T</sub>'), if a first sample (vi(x,y)) in the left projected depth map (s<sub>D</sub>/) at a first position ((x,y)) and a second left neighboring sample (vi(x-1 ,y) to the first left sample (vi(x,y)) in the left projected depth map do not belong to a same plane of the visual scene, a point in the visual scene corresponding to the first sample (v,(x,y)) in the left projected depth map is closer to a camera than a point in the visual scene corresponding to the second left neighboring sample (V|(x-1 ,y)) in the left projected depth map, 
<!-- EPO <DP n="30"/>-->
 the first sample (vi(x,y)) in the left projected depth map (s<sub>D</sub>/) and a first sample (v<sub>r</sub>(x,y)) in the right projected depth map (s<sub>D,r</sub>') at the first position ((x,y)) belong to a same plane of the visual scene, and the first sample (v<sub>r</sub>(x,y)) in the right projected depth map (s<sub>D,r</sub>') and a second left neighboring sample (v<sub>r</sub>(x-1 ,y)) to the first sample (v<sub>r</sub>(x,y)) in the right projected depth map (s<sub>D,r</sub>') belong to the same plane of the visual scene. </claim-text></claim><claim id="clm-0008" num="8"><claim-text>8. The method (300) of one of the preceding claims, wherein object border misalignments are detected, and the determining (303) the right reliability map information (S<sub>R</sub>/) comprises assigning a reduced weight for samples in the right projected picture (s<sub>T,r</sub>') for the computing of the synthesized picture (s<sub>T</sub>'), if a first sample (v<sub>r</sub>(x,y)) in the right projected depth map (s<sub>D,r</sub>') at a first horizontal (x) and a first vertical (y) position does not belong to the right disoccluded area (S<sub>F</sub>/), a second left neighboring sample (v<sub>r</sub>(x-1 ,y)) to the first sample (v<sub>r</sub>(x,y)) in the right projected depth map (s<sub>D</sub>,<sub>r</sub>') belongs to the right disoccluded area (s<sub>F</sub>,<sub>r</sub>'), the first sample (v<sub>r</sub>(x,y)) in the right projected depth map (s<sub>D,r</sub>') and a first sample (vi(x,y)) in the left projected depth map (s<sub>D</sub>/) at the first horizontal (x) and the first vertical (y) position belong to a same plane of the visual scene, and the first sample (vi(x,y)) in the left projected depth map (s<sub>D</sub>/) and a second left neighboring sample (vi(x-1 ,y)) to the first sample (vi(x,y)) in the left projected depth map (S<sub>D,</sub>D belong to the same plane of the visual scene; or wherein the determining (303) the right reliability map information (S<sub>R</sub>/) comprises assigning a reduced weight for samples in the right projected picture (s<sub>T,r</sub>') for the computing of the synthesized picture (s<sub>T</sub>'), if a first right sample (v<sub>r</sub>(x,y)) in the right projected depth map (s<sub>D,r</sub>') at a first horizontal (x) and a first vertical (y) position and a second right neighboring sample (v<sub>r</sub>(x+1 ,y) to the first sample (v<sub>r</sub>(x,y)) in the right projected depth map (s<sub>D,r</sub>') do not belong to a same plane of the visual scene, 
<!-- EPO <DP n="31"/>-->
 a point in the visual scene corresponding to the first sample (v<sub>r</sub>(x,y)) in the right projected depth map (s<sub>D,r</sub>') is closer to a camera than a point in the visual scene corresponding to the second right neighboring sample (v<sub>r</sub>(x+1 ,y)) in the right projected depth map (s<sub>D</sub>,<sub>r</sub>'), the first sample (v<sub>r</sub>(x,y)) in the right projected depth map (s<sub>D,r</sub>') and a first sample (vi(x,y)) in the left projected depth map (s<sub>D</sub>/) at the first horizontal (x) and the first vertical (y) position belong to a same plane of the visual scene, and the first sample (vi(x,y)) in the left projected depth map (s<sub>D</sub>/) and a second right neighboring sample (vi(x+1 ,y)) to the first sample (vi(x,y)) in the left projected depth map (S<sub>D</sub>,D belong to the same plane of the visual scene. </claim-text></claim><claim id="clm-0009" num="9"><claim-text>9. The method (300) of one of the preceding claims, wherein the merging the left (S<sub>T</sub>,D and right (s<sub>T</sub>,<sub>r</sub>') projected pictures comprises: weighting a sample (vi(x,y)) in the left projected picture (s<sub>T,</sub>i') by the weight of the left reliability map (s<sub>R</sub>/) and weighting a sample (v<sub>r</sub>(x,y)) in the right projected picture (s<sub>T,r</sub>') by the weight of the right reliability map (s<sub>R</sub>/). </claim-text></claim><claim id="clm-0010" num="10"><claim-text>10. The method (300) of claim 9, comprising: combining the weighted sample ( (x,y)) in the left projected picture (s<sub>T</sub>/) and the weighted sample (v<sub>r</sub>(x,y)) in the right projected picture (s<sub>T,r</sub>') to obtain a sample (v(x,y)) in the synthesized picture. </claim-text></claim><claim id="clm-0011" num="11"><claim-text>1 1 . The method (300) of claim 9 or 10, wherein in case a sample (vi(x,y)) in the left projected picture (s<sub>T</sub>/) and a sample (v<sub>r</sub>(x,y)) in the right projected picture (s<sub>T,r</sub>') belong to different planes of the visual scene, the sample (v(x,y)) in the synthesized picture is calculated based only on the sample (vi(x,y)) in the left projected picture (s<sub>T</sub>/) or the sample (v<sub>r</sub>(x,y)) in the right projected picture (s<sub>T,r</sub>'), which belongs to the closer plane. </claim-text></claim><claim id="clm-0012" num="12"><claim-text>12. The method according to any of the preceding claims, wherein the left and right projected pictures are projected texture pictures (s<sub>T</sub>/, s<sub>T,r</sub>'), wherein the left and right projected pictures are the projected depth map pictures (s<sub>D</sub>/, s<sub>D,r</sub>'), or wherein the left and right projected pictures are projected disparity pictures. </claim-text></claim><claim id="clm-0013" num="13"><claim-text>13. The method of any of the preceding claims, wherein the left depth map (¾<sub>,</sub>i) of the left reference view of the visual scene is a left disparity map (S<sub>D,I</sub>) of the left reference view 
<!-- EPO <DP n="32"/>-->
 of the visual scene, and the right depth map (¾&gt;<sub>,Γ</sub>) of the right reference view of the visual scene is a right disparity map of the right view of the visual scene; and wherein the left projected depth map (s<sub>D</sub>/) is a left projected disparity map and the right projected depth map (s<sub>D</sub>,<sub>r</sub>') is a right projected disparity map. </claim-text></claim><claim id="clm-0014" num="14"><claim-text>14. Apparatus (700) for computing a synthesized picture (s<sub>T</sub>') of a visual scene based on a left depth map (s<sub>D,</sub>i) of a left reference view of the visual scene and right depth map (s<sub>D,r</sub>) of a right reference view of the visual scene, the apparatus (700) comprising: a projector (701 ) configured to project the right depth map (s<sub>D,r</sub>) into a right projected depth map (s<sub>D,r</sub>'), and to determine a left disoccluded area (s<sub>F</sub>/) in the left projected depth map (s<sub>D</sub>/) and a right disoccluded area (s<sub>F,r</sub>') in the right projected depth </claim-text><claim-text>a detector (803) configured to detect object border misalignments between the left projected depth map (s<sub>D</sub>/) and the right projected depth map(s<sub>D</sub>,<sub>r</sub>'); a determiner (705) configured to determine a left reliability map information (s<sub>R</sub>/) based on the left disoccluded area (s<sub>F</sub>/), and the detected object border misalignments, and determining a right reliability map information (SR/) based on the right disoccluded area (s<sub>F</sub>,<sub>r</sub>'), and the detected object border misalignments; and a processor (707) configured to compute the synthesized picture (s<sub>T</sub>') by merging a left projected picture (s<sub>T,</sub>i') of the left reference view and a right projected picture (s<sub>Tr</sub>') of the right reference view using the left (SR/) and right (s<sub>R,r</sub>') reliability map information. 
</claim-text></claim></claims><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
