<?xml version="1.0" encoding="UTF-8"?>
<patent-document ucid="EP-2959313-A1" country="EP" doc-number="2959313" kind="A1" date="20151230" family-id="49955465" file-reference-id="252649" date-produced="20180825" status="corrected" lang="EN"><bibliographic-data><publication-reference fvid="160452656" ucid="EP-2959313-A1"><document-id><country>EP</country><doc-number>2959313</doc-number><kind>A1</kind><date>20151230</date><lang>EN</lang></document-id></publication-reference><application-reference ucid="EP-13820997-A" is-representative="NO"><document-id mxw-id="PAPP193868280" load-source="docdb" format="epo"><country>EP</country><doc-number>13820997</doc-number><kind>A</kind><date>20131209</date><lang>EN</lang></document-id><document-id mxw-id="PAPP193868281" load-source="patent-office" format="original"><country>EP</country><doc-number>13820997.8</doc-number><date>20131209</date><lang>EN</lang></document-id></application-reference><priority-claims><priority-claim mxw-id="PPC162034887" ucid="JP-2013083534-W" linkage-type="W" load-source="docdb"><document-id format="epo"><country>JP</country><doc-number>2013083534</doc-number><kind>W</kind><date>20131209</date></document-id></priority-claim><priority-claim mxw-id="PPC162036738" ucid="US-201313770096-A" load-source="docdb"><document-id format="epo"><country>US</country><doc-number>201313770096</doc-number><kind>A</kind><date>20130219</date></document-id></priority-claim></priority-claims><technical-data><classifications-ipcr><classification-ipcr mxw-id="PCL-1988522122" load-source="docdb">G01S  13/90        20060101AFI20140910BHEP        </classification-ipcr></classifications-ipcr><classifications-cpc><classification-cpc mxw-id="PCL-1984702396" load-source="docdb" scheme="CPC">G01S2013/9052      20130101 LA20160107BHEP        </classification-cpc><classification-cpc mxw-id="PCL-1987764222" load-source="docdb" scheme="CPC">G01S  13/9035      20130101 FI20140822BHEP        </classification-cpc></classifications-cpc><invention-title mxw-id="PT165549434" lang="DE" load-source="patent-office">BILDERZEUGUNGSVERFAHREN</invention-title><invention-title mxw-id="PT165549435" lang="EN" load-source="patent-office">METHOD FOR GENERATING IMAGE</invention-title><invention-title mxw-id="PT165549436" lang="FR" load-source="patent-office">PROCÉDÉ POUR GÉNÉRER UNE IMAGE</invention-title><citations><non-patent-citations><nplcit><text>See references of WO 2014129059A1</text><sources><source mxw-id="PNPL67567898" load-source="docdb" name="SEA"/></sources></nplcit></non-patent-citations></citations></technical-data><parties><applicants><applicant mxw-id="PPAR1103322363" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>MITSUBISHI ELECTRIC CORP</last-name><address><country>JP</country></address></addressbook></applicant><applicant mxw-id="PPAR1103305904" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>MITSUBISHI ELECTRIC CORPORATION</last-name></addressbook></applicant><applicant mxw-id="PPAR1101640670" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Mitsubishi Electric Corporation</last-name><iid>101323123</iid><address><street>7-3 Marunouchi 2-chome Chiyoda-ku</street><city>Tokyo 100-8310</city><country>JP</country></address></addressbook></applicant></applicants><inventors><inventor mxw-id="PPAR1103312502" load-source="docdb" sequence="1" format="epo"><addressbook><last-name>LIU DEHONG</last-name><address><country>US</country></address></addressbook></inventor><inventor mxw-id="PPAR1103303629" load-source="docdb" sequence="1" format="intermediate"><addressbook><last-name>LIU, DEHONG</last-name></addressbook></inventor><inventor mxw-id="PPAR1101643290" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>LIU, DEHONG</last-name><address><street>7 Carol Ln</street><city>Lexington, Massachusetts 02420</city><country>US</country></address></addressbook></inventor><inventor mxw-id="PPAR1103335167" load-source="docdb" sequence="2" format="epo"><addressbook><last-name>BOUFOUNOS PETROS</last-name><address><country>US</country></address></addressbook></inventor><inventor mxw-id="PPAR1103344515" load-source="docdb" sequence="2" format="intermediate"><addressbook><last-name>BOUFOUNOS, PETROS</last-name></addressbook></inventor><inventor mxw-id="PPAR1101647559" load-source="patent-office" sequence="2" format="original"><addressbook><last-name>BOUFOUNOS, PETROS</last-name><address><street>4411 Symmes Cir</street><city>Arlington MA 02474-2997</city><country>US</country></address></addressbook></inventor></inventors><agents><agent mxw-id="PPAR1101647320" load-source="patent-office" sequence="1" format="original"><addressbook><last-name>Pfenning, Meinig &amp; Partner GbR</last-name><iid>100060642</iid><address><street>Patent- und Rechtsanwälte Theresienhöhe 11a</street><city>80339 München</city><country>DE</country></address></addressbook></agent></agents></parties><international-convention-data><pct-or-regional-filing-data ucid="JP-2013083534-W"><document-id><country>JP</country><doc-number>2013083534</doc-number><kind>W</kind><date>20131209</date><lang>EN</lang></document-id></pct-or-regional-filing-data><pct-or-regional-publishing-data ucid="WO-2014129059-A1"><document-id><country>WO</country><doc-number>2014129059</doc-number><kind>A1</kind><date>20140828</date><lang>EN</lang></document-id></pct-or-regional-publishing-data><designated-states><ep-contracting-states><country mxw-id="DS660711531" load-source="docdb">AL</country><country mxw-id="DS660626476" load-source="docdb">AT</country><country mxw-id="DS660711533" load-source="docdb">BE</country><country mxw-id="DS660727468" load-source="docdb">BG</country><country mxw-id="DS660626398" load-source="docdb">CH</country><country mxw-id="DS660704711" load-source="docdb">CY</country><country mxw-id="DS660626477" load-source="docdb">CZ</country><country mxw-id="DS660705482" load-source="docdb">DE</country><country mxw-id="DS660711534" load-source="docdb">DK</country><country mxw-id="DS660704712" load-source="docdb">EE</country><country mxw-id="DS660627325" load-source="docdb">ES</country><country mxw-id="DS660727469" load-source="docdb">FI</country><country mxw-id="DS660727470" load-source="docdb">FR</country><country mxw-id="DS660705487" load-source="docdb">GB</country><country mxw-id="DS660711539" load-source="docdb">GR</country><country mxw-id="DS660711540" load-source="docdb">HR</country><country mxw-id="DS660704713" load-source="docdb">HU</country><country mxw-id="DS660626407" load-source="docdb">IE</country><country mxw-id="DS660711541" load-source="docdb">IS</country><country mxw-id="DS660727475" load-source="docdb">IT</country><country mxw-id="DS660704714" load-source="docdb">LI</country><country mxw-id="DS660705488" load-source="docdb">LT</country><country mxw-id="DS660626478" load-source="docdb">LU</country><country mxw-id="DS660705489" load-source="docdb">LV</country><country mxw-id="DS660705490" load-source="docdb">MC</country><country mxw-id="DS660789370" load-source="docdb">MK</country><country mxw-id="DS660789371" load-source="docdb">MT</country><country mxw-id="DS660627326" load-source="docdb">NL</country><country mxw-id="DS660626487" load-source="docdb">NO</country><country mxw-id="DS660627335" load-source="docdb">PL</country><country mxw-id="DS660626488" load-source="docdb">PT</country><country mxw-id="DS660627336" load-source="docdb">RO</country><country mxw-id="DS660626489" load-source="docdb">RS</country><country mxw-id="DS660627337" load-source="docdb">SE</country><country mxw-id="DS660704723" load-source="docdb">SI</country><country mxw-id="DS660789372" load-source="docdb">SK</country><country mxw-id="DS660789373" load-source="docdb">SM</country><country mxw-id="DS660626408" load-source="docdb">TR</country></ep-contracting-states><ep-extended-states><ep-extended-state-data><country>BA</country></ep-extended-state-data><ep-extended-state-data><country>ME</country></ep-extended-state-data></ep-extended-states></designated-states></international-convention-data><office-specific-data><eptags><ep-no-a-document-published>*</ep-no-a-document-published></eptags></office-specific-data></bibliographic-data><abstract mxw-id="PA139077895" ref-ucid="WO-2014129059-A1" lang="EN" load-source="patent-office"><p num="0000">A spotlight synthetic aperture radar (SAR) image is generated by directing randomly a beam of transmitted pulses at a set of two or more areas using a steerable array of antennas. Each area is illuminated by an approximately equal number of the transmitted pulses. Then, a reconstruction procedure is applied independently to received signals from each area due to reflecting the transmitted pulses to generate the image corresponding to the set of areas.</p></abstract><abstract mxw-id="PA139544608" ref-ucid="WO-2014129059-A1" lang="EN" source="national office" load-source="docdb"><p>A spotlight synthetic aperture radar (SAR) image is generated by directing randomly a beam of transmitted pulses at a set of two or more areas using a steerable array of antennas. Each area is illuminated by an approximately equal number of the transmitted pulses. Then, a reconstruction procedure is applied independently to received signals from each area due to reflecting the transmitted pulses to generate the image corresponding to the set of areas.</p></abstract><abstract mxw-id="PA139077896" ref-ucid="WO-2014129059-A1" lang="FR" load-source="patent-office"><p num="0000">Selon la présente invention, une image de radar à synthèse d'ouverture (SAR) à saisie hyperfine est générée par acheminement de manière aléatoire d'un faisceau d'impulsions émises au niveau d'un ensemble d'au moins deux zones en utilisant un réseau orientable d'antennes. Chaque zone est éclairée par un nombre approximativement égal des impulsions émises. Ensuite, une procédure de reconstruction est appliquée indépendamment de signaux reçus en provenance de chaque zone en raison d'une réflexion des impulsions émises pour générer l'image correspondant à l'ensemble de zones.</p></abstract><abstract mxw-id="PA139544609" ref-ucid="WO-2014129059-A1" lang="FR" source="national office" load-source="docdb"><p>Selon la présente invention, une image de radar à synthèse d'ouverture (SAR) à saisie hyperfine est générée par acheminement de manière aléatoire d'un faisceau d'impulsions émises au niveau d'un ensemble d'au moins deux zones en utilisant un réseau orientable d'antennes. Chaque zone est éclairée par un nombre approximativement égal des impulsions émises. Ensuite, une procédure de reconstruction est appliquée indépendamment de signaux reçus en provenance de chaque zone en raison d'une réflexion des impulsions émises pour générer l'image correspondant à l'ensemble de zones.</p></abstract><description mxw-id="PDES78477521" ref-ucid="WO-2014129059-A1" lang="EN" load-source="patent-office"><!-- EPO <DP n="3"/>--><p id="p0001" num="0001"> [DESCRIPTION] </p><p id="p0002" num="0002">[Title of Invention] </p><p id="p0003" num="0003"> METHOD FOR GENERATING IMAGE </p><p id="p0004" num="0004"> [Technical Field] </p><p id="p0005" num="0005"> [0001] </p><p id="p0006" num="0006"> This invention relates generally synthetic aperture radar (SAR) imaging, and particularly to spotlight SAR. </p><p id="p0007" num="0007">[Background Art] </p><p id="p0008" num="0008">[0002] </p><p id="p0009" num="0009"> Spotlight SAR </p><p id="p0010" num="0010"> Synthetic aperture radar (SAR) uses moving sensors to form a large synthetic aperture that improves a resolution of an acquired image. In spotlight mode, the pulses emitted by the sensors are steered as a beam to always illuminate a single relatively small area (spot) of interest using pulses transmitted at uniform time intervals. Received signals are used to produce a significantly higher imaging resolution compared to physical aperture arrays, or strip-map mode synthetic arrays. The received signals are also known as echoes or reflections. The received signals that are measured have a complex waveform when compared with the pulses. </p><p id="p0011" num="0011">[0003] </p><p id="p0012" num="0012"> However, there is a tradeoff between imaging resolution and coverage. Compared to strip-map mode SAR, conventional spotlight mode cover a much smaller area because of its high sampling rate requirement and restrictions on its beam geometry. This is contrasted with strip-mode SAR where the beam is not steered. </p><p id="p0013" num="0013">[0004] </p><p id="p0014" num="0014"> Compressive Sensing </p><p id="p0015" num="0015"> l 
<!-- EPO <DP n="4"/>-->
 Compressive sensing (CS) is frequently used in sensing applications, including radar imaging. CS enables signal acquisition and accurate reconstruction using a significantly smaller number of measurements compared to the Nyquist rate. The rate reduction is due to randomized measurements, improved signal models, and non-linear reconstruction procedures. </p><p id="p0016" num="0016">[0005] </p><p id="p0017" num="0017"> Although CS significantly improves radar and radar imaging systems, a number of challenges still exist in applying CS to radar imaging, such as developing appropriate sparsity models of radar images, and managing computational complexity. </p><p id="p0018" num="0018">[0006] </p><p id="p0019" num="0019"> Fig. 1 generally shows conventional spotlight SAR imaging using a linear mono-static array. To image a scene 101, an array of sensors moves along a path 102. Pulses are transmitted at a uniform pulsing rate. Received signals are used to image the reflectivity of the scene. </p><p id="p0020" num="0020">[0007] </p><p id="p0021" num="0021"> In spotlight mode, the beam of pulses is steered such that the main lobe of the pulse beam is directed at the center 103 of the area. Each reflection from the area is effectively a convolution of the pulse with the reflectivity of the area covered by the pulse. Thus, the data acquisition process can be modeled as a linear system </p><p id="p0022" num="0022"> y = Φχ + n, (1) </p><p id="p0023" num="0023">where y denotes the received signals, x denotes the reflectivity of the scene, Φ models an array acquisition function of the array parameters, and n is noise. </p><p id="p0024" num="0024">[0008] </p><p id="p0025" num="0025"> The goal of the image formation process is to determine the reflectivity x from the received signals y given the acquisition function Φ . In other words, an 
<!-- EPO <DP n="5"/>-->
 inverse problem is solved. If the acquisition function Φ is invertible, then an obvious choice would be to use the inverse or the pseudoinverse ' of Φ to determine x as 
<img id="imgf000005_0001" he="9" wi="32" file="imgf000005_0001.tif" img-format="tif" img-content="drawing" orientation="portrait" inline="no"/>
 </p><p id="p0026" num="0026"> [0009] </p><p id="p0027" num="0027"> However in practical SAR systems, the acquisition function Φ is generally difficult to model accurately, and the inversion can be computationally complex. Typically, array image formation is achieved using well known procedures, such as a chirp-scaling procedure, or a wave-number procedure, which approximates the inversion. </p><p id="p0028" num="0028">[0010] </p><p id="p0029" num="0029"> U.S. Patent 7,973,703 describes an SAR system operating in stripmap mode that reduces the number of pulses by randomly removing some of the pulses to form an image. The reduction introduces blur describes in terms of sidelobes of a main beam. </p><p id="p0030" num="0030"> [Summary of Invention] </p><p id="p0031" num="0031">[0011] </p><p id="p0032" num="0032"> With a conventional spotlight mode synthetic imaging array as described above, pulses emitted by moving sensors are steered as a beam to illuminate one area with uniform timing pulses to acquire a high resolution image. </p><p id="p0033" num="0033">[0012] </p><p id="p0034" num="0034"> The embodiments of the invention provide a method and system for a steerable synthetic imaging array, in which the beam is randomly steered such that each pulses randomly illuminate a set of at least two areas of a scene to be imaged, with each area being of idential in size as the coverage of the conventional synthetic imaging array. 
<!-- EPO <DP n="6"/>-->
 [0013] </p><p id="p0035" num="0035"> Then, compressive sensing can be used to reconstruct images of both areas by imposing sparsity of reconstructed images, yielding image of identical resolution and doubled coverage compared to the conventioanal spotlight synthetic imaging array. </p><p id="p0036" num="0036"> [Brief Description of the Drawings] </p><p id="p0037" num="0037"> [0014] </p><p id="p0038" num="0038"> [Fig. 1] </p><p id="p0039" num="0039"> Fig. 1 is a schematic of a conventional synthetic aperture radar (SAR) system operating in spotlight mode; </p><p id="p0040" num="0040">[Fig. 2] </p><p id="p0041" num="0041"> Fig. 2 is is a schematic of a spolight SAR systrem according to embodiments of the invention; </p><p id="p0042" num="0042">[Fig. 3] </p><p id="p0043" num="0043"> Fig. 3 is a block diagram of a spolight SAR system according to embodimens of the invention; and </p><p id="p0044" num="0044">[Fig. 4] </p><p id="p0045" num="0045"> Fig. 4 is a block diagram of a method for spotlight SAR imaging according to embodimens of the invention. </p><p id="p0046" num="0046">[Description of Embodiments] </p><p id="p0047" num="0047">[0015] </p><p id="p0048" num="0048"> Randomly Steerable Spotlight Array </p><p id="p0049" num="0049"> As shown in an example in Fig. 2, the embodiments of the invention provide a method and system for a random steerable spotlight synthetic aperture radar (SAR) system. Our randomly steerable array also uniformly transmits pulses and receives signals, also known as echoes or reflections having a complex waveform when compared to the pulses. Our array increases the flexibility of the beam 
<!-- EPO <DP n="7"/>-->
 steering. </p><p id="p0050" num="0050">[0016] </p><p id="p0051" num="0051"> As shown in an example in Fig. 2, instead of steering the beam of pulses always at the same area, we illuminate a set of at least two areas 201-202 in a scene 315. Each area has about the same size as the single area in the conventional system shown in Fig. 1. The example shows that illuminating two areas results in illuminating an area of doubled size. As used herein the set includes at least two areas. The location and shape of the areas is arbitrary, depending, for example, on a structure of the antenna. Here for simplicity, we use rectangular adjacent areas. </p><p id="p0052" num="0052">[0017] </p><p id="p0053" num="0053"> At different transmitting or receiving locations, we randomly select one of the areas to illuminate with equal probability. In the example, each of the two areas is about the same size as the conventional array coverage, but is illuminated by only half the pulses, using the other half for the other area. Additional areas can be accomodated. </p><p id="p0054" num="0054">[0018] </p><p id="p0055" num="0055"> For each of the areas, the randomly steerable SAR system can modeled as conventional spotlight-mode SAR, except that some of the data are missing because some pulses are directed at the other area(s). Thus, we describe the data acquisition process as a linear operation with missing data. </p><p id="p0056" num="0056">[0019] </p><p id="p0057" num="0057"> Spotlight SAR System </p><p id="p0058" num="0058"> Fig. 3 shows a spotlight SAR system. The system includes a transmitter 310 and a receiver connected to a controller 330 and steerable antenna array 314. The controller determines the synchronization and steering of the pulses and received signals. As describe above, the scene includes multiple areas, and the pulses are transmitted to the areas randomly and uniformly in a spatial dimension. 
<!-- EPO <DP n="8"/>-->
 [0020] </p><p id="p0059" num="0059"> For clarity, only the received signals 321 for area 201 and the received signals 322 for area 202 are shown. The received signals are processed by processor 340 to produce a radar image 350 corresponding to the reflectivity of the scene 315. The processor executes a reconstruction method shown in Fig. 4. </p><p id="p0060" num="0060">[0021] </p><p id="p0061" num="0061"> Reconstruction Method </p><p id="p0062" num="0062"> Initialization set n u ^ a ^ &lt; 1 ~ x&lt;«°&gt; _ n (°) _ </p><p id="p0063" num="0063"> — u. y<sub>mr</sub>— y<sub>m ?</sub> where a is a threshold value, is an initial sparse component of the radar image to be reconstructed, and y<sup>(0)</sup><sub>w/</sub>- are initial measured and residual signals. The method iterates until a termination condition 490 is reached, e.g., K iterations or convergence, whichever comes first. </p><p id="p0064" num="0064">[0022] </p><p id="p0065" num="0065"> The output is a combination 495 of selected measured and sparse signals y<sub>mr</sub> sufficient to generate the radar image 350 using an acquisition function Φ and a selection operator E. </p><p id="p0066" num="0066">[0023] </p><p id="p0067" num="0067"> After initialization, the received signals 405, i.e., signals 321 and 322, are imaged 410 to produce an approximate (~) image according to </p><p id="p0068" num="0068"> si Etygr<sup>1)</sup>.<sup>'</sup> </p><p id="p0069" num="0069"> [0024] </p><p id="p0070" num="0070"> The imaging can use conventional radar imaging techniues as known in the art. </p><p id="p0071" num="0071"> [0025] </p><p id="p0072" num="0072"> The approximate image is thresholded 420 
<!-- EPO <DP n="9"/>-->
 = maxfl x&lt;*&gt; \) - a , 
<img id="imgf000009_0001" he="16" wi="95" file="imgf000009_0001.tif" img-format="tif" img-content="drawing" orientation="portrait" inline="no"/>
 </p><p id="p0073" num="0073">where d is a maximal value returned by the function max. thus, in the above equation the thresholded image is produced with threshold on . </p><p id="p0074" num="0074"> [0026] </p><p id="p0075" num="0075"> From the threshold image, simulted signal are generated 426 and scaled 431 according to 
<img id="imgf000009_0002" he="7" wi="43" file="imgf000009_0002.tif" img-format="tif" img-content="drawing" orientation="portrait" inline="no"/>
 </p><p id="p0076" num="0076">where a scaling factor is </p><p id="p0077" num="0077"><img id="imgf000009_0003" he="29" wi="57" file="imgf000009_0003.tif" img-format="tif" img-content="drawing" orientation="portrait" inline="no"/></p><p id="p0078" num="0078"> [0027] </p><p id="p0079" num="0079"> Simulated and scaled signals are subtracted 460 from the received signals to produce residuals 480. </p><p id="p0080" num="0080">[0028] </p><p id="p0081" num="0081"> The procedure iterates beginning at the imaging 410 step until the termination 490 condition is reached, while subtracting 460 the residuals from the approximate image. When the above iterative process terminates, the residuals 480 are used to generate the residual component x<sub>r</sub> 451. </p><p id="p0082" num="0082">[0029] </p><p id="p0083" num="0083"> Then after termination, the sparse component 450 and the residual component 451 are combined 495 according to 
<!-- EPO <DP n="10"/>-->
 to produce the final image 350, which reconstructs reflectivity of the scene 315. </p><p id="p0084" num="0084"> [0030] </p><p id="p0085" num="0085"> Random SAR Beam Steering </p><p id="p0086" num="0086"> If the array is always steered towards area i, the array acquires χ,· using the linear acquisition function Φ<sub>?</sub>· . However, some of the received signals are deliberately missing because some of the pulses are steered to other area(s) in the set. </p><p id="p0087" num="0087"> [0031] </p><p id="p0088" num="0088"> We denote this selection process by the selection operator Ε,·. The selection operator only selects the data actually received and measured. Further, we use the operator E; to denote the complementary selection operator, i.e., the operator only selects the data that are not acquired, i.e., missing or unmeasured signals. </p><p id="p0089" num="0089">[0032] </p><p id="p0090" num="0090"> Using y<sub>m</sub>i and y<sub>u</sub>i to denote the measured and unmeasured data, respectively, we have </p><p id="p0091" num="0091">J mi = <sup>Εφ</sup>ϊ<sup>χ</sup>ΐ + <sup>n</sup>&gt; (3) </p><p id="p0092" num="0092"> y<sub>ui</sub> = m<sub>i</sub>x<sub>i</sub> . (4) </p><p id="p0093" num="0093"> [0033] </p><p id="p0094" num="0094"> Note that the E, are complementary, i.e., the data measured from area cannot be measured from area j, i.e., j <sup>'</sup>≠ i . </p><p id="p0095" num="0095">[0034] </p><p id="p0096" num="0096"> Our goal is to image all the areas in the set, even with missing data, without compromising theoverall imaging resolution. That is the final image is a "dense" radar image, even though each area only reflects a fraction of the pulses. We do 
<!-- EPO <DP n="11"/>-->
 this by using compressive sensing (CS) based methods that exploit the structure of the scene, typically in the form of sparsity under some appropriate basis transformation, and randomness in the acquisition process to enable an accurate reconstruction. </p><p id="p0097" num="0097">[0035] </p><p id="p0098" num="0098"> The steering randomization ensures that the linear measurements are incoherent and fully acquire the scene. Thus, the measurements can be inverted using a non-linear reconstruction process, which uses a signal model to recover the acquired signal in the radar image 350. </p><p id="p0099" num="0099">[0036] </p><p id="p0100" num="0100"> CS Based Image Reconstruction </p><p id="p0101" num="0101"> We apply a reconstructing procedure to each area independently using only the received signals measured for this area. </p><p id="p0102" num="0102">[0037] </p><p id="p0103" num="0103"> Using the notation above, all data, including measured and unmeasured signals, can be represented as 
<img id="imgf000011_0001" he="16" wi="56" file="imgf000011_0001.tif" img-format="tif" img-content="drawing" orientation="portrait" inline="no"/>
 
<img id="imgf000011_0002" he="17" wi="26" file="imgf000011_0002.tif" img-format="tif" img-content="table" orientation="portrait" inline="no"/>
 </p><p id="p0104" num="0104"> [0038] </p><p id="p0105" num="0105"> In conventional CS, the image x is modeled to be sparse. As defined in the field, sparse means most of received signal energies are zero or very small, and only a few received signals have non-zero or significant energies. However, this model is generally inaccurate for radar imaging. While strong components in some domain might exist in radar imaging, the residual signals always seems large and difficult to take into account. </p><p id="p0106" num="0106">[0039] 
<!-- EPO <DP n="12"/>-->
 Therefore, we assume the radar image of reflectivity in the scene has a sparse component x<sub>s</sub> and a residual component x„ such that </p><p id="p0107" num="0107"> X = X<sub>s</sub> + x<sub>r</sub> . (6) </p><p id="p0108" num="0108"> [0040] </p><p id="p0109" num="0109"> Substituting equation (6) into equation (5), the received signals 311 and 321 are </p><p id="p0110" num="0110"> y<sub>m</sub> = ΕΦχ<sub>5</sub> + ΕΦχ,. (7) </p><p id="p0111" num="0111"> [0041] </p><p id="p0112" num="0112">Treating E Φ x <sub>r</sub> as noise, an estimate (<sup>Λ</sup>) of the sparse component x<sub>s</sub> is x, =argmin||y,<sub>n</sub> -ΕΦ x|| si. ||<sup>χ</sup>||<sub>0</sub>&lt;ΛΤ. <sub>(8)</sub> </p><p id="p0113" num="0113">[0042] </p><p id="p0114" num="0114"> Given the sparse estimate x<sub>s</sub> , we can estimate its contribution to the measured data ΕΦχ<sub>5</sub>. Assuming the measured data y<sub>m</sub> -ΕΦχ<sub>5</sub> is due to the residual component x<sub>r</sub> , we can obtain a least squares estimate using 
<img id="imgf000012_0001" he="9" wi="68" file="imgf000012_0001.tif" img-format="tif" img-content="drawing" orientation="portrait" inline="no"/>
 </p><p id="p0115" num="0115"> [0043] </p><p id="p0116" num="0116"> Then, we can obtain the estimate of the final image 350 by combining 495 equations (8) and (9) x = x<sub>s +</sub>x<sub>r</sub> =x<sub>s</sub> + (EO)t (y <sub>m</sub> - ΕΦχ, ). (10)</p><p id="p0117" num="0117">[0044] </p><p id="p0118" num="0118"> Note that the SAR image 350 is not sparse per se, but rather a combination of the sparse component, estimated using sparsity regularization, and the residual component estimated using the least-squares regularization. The least-squares 
<!-- EPO <DP n="13"/>-->
 regularization minimizes a sum of the squared residuals, a residual being a difference between a measured value and the fitted value according to some model. </p><p id="p0119" num="0119">[0045] </p><p id="p0120" num="0120"> Let y <sub>s</sub> denote all the received signals corresponding to x<sub>s</sub> , i.e., x<sub>5</sub> = <sup>†</sup> „ (11) </p><p id="p0121" num="0121">where† indicte the pseudoinverse. </p><p id="p0122" num="0122">[0046] </p><p id="p0123" num="0123"> Then, we can rewrite equation (10) as x = ty<sub>s</sub> + (EO)t(y<sub>m</sub> - EOx<sub>s</sub> ) . (12) </p><p id="p0124" num="0124"> [0047] </p><p id="p0125" num="0125"> This solution is equivalent to filling in the missing data using the reconstruction by only enforcing the sparsity model, and performing conventional least-squares imaging on the completed data. Note that E is the selection operator, i.e., E † ' = E T , i.e. the pseudoinverse uses zeros for the missing data. </p><p id="p0126" num="0126">[0048] </p><p id="p0127" num="0127"> (k-1)</p><p id="p0128" num="0128">During each iteration, the procedure uses the residual 480 of y^<sub>r</sub> ' to determine an estimate of the so-far unexplained signal . </p><p id="p0129" num="0129">[0049] </p><p id="p0130" num="0130">To obtain the strongest received signals, a threshold image is determined 420 as a fraction of the largest in magnitude signal component. The estimate of the strongest received signals is determined by imposing a hard threshold ί<sub>τ</sub> (·) on x^ , i.e., by setting all signal less than in magnitude to zero. 
<!-- EPO <DP n="14"/>-->
 [0050] </p><p id="p0131" num="0131"> This estimate is scaled using β such that the estimate explains most of the </p><p id="p0132" num="0132"> (k-D </p><p id="p0133" num="0133">residual energy in ^<sub>r</sub> ' . Then, the estimate is added to the overall signal estimate current signal estimate 
<img id="imgf000014_0001" he="21" wi="111" file="imgf000014_0001.tif" img-format="tif" img-content="drawing" orientation="portrait" inline="no"/>
 to produce the </p><p id="p0134" num="0134"> (k) </p><p id="p0135" num="0135">updated residual yj¾/ . As the last step, after the iterations are concluded, the procedure uses the estimated signal x^^ from the iteration to estimate the full data y from which to estimate the final image X 350 using a conventional imaging procedure. </p><p id="p0136" num="0136">[0051] </p><p id="p0137" num="0137"> In summary, our method expresses the sparse component as a linear combination of a spatially sparse components of decreasing intensity in the measurements, corresponding to the most intense reflectors. To efficiently determine the imaging process Φ † ' , we implement a wave number procedure, see U.S. Application 20120206292, "Synthetic Aperture Radar Image Formation System and Method," filed by Boufounos et al. on August 16, 2012. The acquisition function Φ can also be determined with the same efficiency with minor modifications. To achieve relatively good imaging performance and fast execution, a &gt; 0.5. </p><p id="p0138" num="0138">[0052] </p><p id="p0139" num="0139"> In our method, we do not determine the pseudoinverse of a subset of Φ. This is computationally complex because Φ is typically very large in imaging applications. Instead, similarly to the well known matching pursuit (MP), We use the signal value after thresholding, scaled by β , as an estimate of the sparse 
<!-- EPO <DP n="15"/>-->
 signal. This heuristic choice provides a good trade-off between speed and accuracy, compared to conventional CS procedures. </p><p id="p0140" num="0140"> [0053] </p><p id="p0141" num="0141"> Effect of the Invention </p><p id="p0142" num="0142"> The invention provides a randomly steerable synthetic aperture imaging system to increase the spotlight-mode SAR coverage without compromising the imaging resolution. Instead of steering the spotlight to only illuminate one area, the spotlight is steered randomly to illuminate as many areas as possible. The randomization removes ambiguities that lead to spatial aliasing and ghosting. </p><p id="p0143" num="0143">[0054] </p><p id="p0144" num="0144"> To form an image from the acquired data, we use an iterative reconstruction procedure, which combines compressive sensing and least squares estimation. Results indicate that it is possible to double the coverage area with a minimal resolution penalty. The methodology can easily be incoporated into existing synthetic aperture systems. 
</p></description><claims mxw-id="PCLM70077796" ref-ucid="WO-2014129059-A1" lang="EN" load-source="patent-office"><claim id="clm-0001" num="0001"><!-- EPO <DP n="16"/>--><claim-text/><claim-text>[CLAIMS] </claim-text><claim-text>[Claim 1] </claim-text><claim-text> A method for generating an image, wherein the image is a spotlight synthetic aperture radar (SAR) image, comprising the steps of: </claim-text><claim-text> directing randomly a beam of transmitted pulses at a set of two or more areas using a steerable array of antennas, wherein each area is illuminated by an approximately equal number of the transmitted pulses; and </claim-text><claim-text> applying independently a reconstruction procedure to received signals from each area due to reflecting the transmitted pulses to generate the image corresponding to the set of areas. </claim-text><claim-text>[Claim 2] </claim-text><claim-text> The method of claim 1, wherein the image is a combination of a sparse component and a residual component, and wherein the reconstruction method further comprises the steps of: </claim-text><claim-text> applying a compressive sensing procedure to generate the sparse component; and </claim-text><claim-text> applying a least square regularization to generate the residual component. [Claim 3] </claim-text><claim-text> The method of claim 2, wherein the compressive sensing procedure further comprises, until a termination condition is reached the iterative steps of: </claim-text><claim-text> imaging the received signals to produce an approximate image; </claim-text><claim-text> thresholding the approximate image to produce a thresholded image; </claim-text><claim-text> generating a simulated signal from the thresholded image; </claim-text><claim-text> scaling the simulated signal to produce a scaled signal; and </claim-text><claim-text> subtracting the scaled signal form the approximate image. </claim-text><claim-text>[Claim 4] </claim-text><claim-text> The method of claim 3, further comprising: 
<!-- EPO <DP n="17"/>-->
 subtracting the scaled image from the received signals to produce residual of the residual component. </claim-text><claim-text>[Claim 5] </claim-text><claim-text> The method of claim 2, further comprising: </claim-text><claim-text> imaging the received signals to produce an approximate image; </claim-text><claim-text> thresholding the approximate image to produce a thresholded image; </claim-text><claim-text> scaling the simulated signal to produce a scaled signal for the sparse component. 
</claim-text></claim></claims><copyright>User acknowledges that Fairview Research LLC and its third party providers retain all right, title and interest in and to this xml under applicable copyright laws.  User acquires no ownership rights to this xml including but not limited to its format.  User hereby accepts the terms and conditions of the Licence Agreement</copyright></patent-document>
